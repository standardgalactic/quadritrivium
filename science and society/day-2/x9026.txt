attack uh uh success rate um well on the

other side keep uh the accuracy for

problem solving so we publish it on iclr

uh this year that means safety and

development does not drag each other you

don't need to make a in many cases you

don't really need to make a balance you

just can develop system that is very

Advanced where on the other side if you

tune the large language model with this

this safety Vector you can keep the

system also very safe so don't be so so

as a technologist and scientist uh we

cannot cheat actually the the general

audience and that if you you're not

really speaking of AI safety you speak

for AI development this is not true you

can actually keep AI very safe or on the

other side to use it uh in a very

beneficial way I'll have to say that

well on the other side uh I think let me

complement uh with the effort in our AI

safety uh report for your uh question

how can you make actually make a balance

we haven't talked about you know AI

safety efforts in different geolocations

in this report but it doesn't mean this

is not important we have another uh work

called the global index for AI uh safety

we evaluate 40 countries and then when

people see the result like for oh they

say oh ye uh for these 40 countries

which what you said is that the level of

AI safety Readiness is positive relevant

to the economy of this country and I

said this is not what I said what I said

is this is not right the AI safety

Readiness for all the countries has to

be put into the same levels no matter

the economy is in which levels so AI

safety counts for each and every of the

countries so this I'll have to say that

and let me give you a secret actually

story about our report but but in face

of all the audience and also some

audience online it's no it's no longer

being a secret now then so one of we are

doing the I'm one of the expert advisory

panel members for this report so one of

in one of our uh advisory uh meeting so

