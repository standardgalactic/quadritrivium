don't simply want to maximize

productivity we want to think about the

benefits and if we make a machine that

imitates humans what we're doing is

driving down the labor share other

people may benefit now you got a real

distribution problem and I think that

can be create a trap because what it

does and and by the way this is

something that is not just hypothetical

this is something that's happened uh uh

historically I mentioned earlier that we

have seen growing dis uh inequality and

disparate incomes you look at the far

left one there you see uh wages this is

from David Otter's paper um for uh

people with graduate degrees like those

of you in this room mostly versus people

who are high school graduates or less

and you can see that those have spread

out we also see that it shows up in

non-economic ways like suicides and

alcoholism and drug

deaths and this can create a trap

because when you lose economic power you

may also lose political power and you

may be H in the limit you may have a

difficult time changing the system if

you no longer have any bargaining power

you no longer have any leverage to get

people to pay you or get people to uh

listen to your political voice and this

Turing trap could lead to an

irreversible situation that I think most

of us don't want to

see now let me just say that um right

now I think we have excess incentives to

sear that way in theory you'd like the

market to just settle this but in

practice technologists business

Executives and policy makers all have

too much of an incentive to um uh

imitate have ai that imitates humans

rather than uh extends or augments them

um actually I'm looking at the time so

I'm going to skip through this a little

bit uh actually I'll just I'll just do

the the um the government one um so in

my paper the Turing trap I describ more

details for the other groups but I see

