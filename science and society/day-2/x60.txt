don't know molecular modeling uh with a

model that is doing image generation

right and so once you define some tasks

you can also um compare models in terms

of Energy Efficiency and rank them in in

a relative way not saying well a bee is

more efficient than an elephant but just

saying well this elephant is a little

bit this cheetah is a little bit faster

than this

elephant the metaphor is going to stay

DAV it I think um so so anyway so

essentially this project hopefully I'm

not saying that we have all the right

data sets and all the right tasks

because of course if you're doing object

detection on an on a self-driving car

then it makes sense to define a a

benchmark for that car the hardware that

it has and the task that it's doing but

at least you can start talking about

energy consumption as part of the

discussion and not only um not only

performance and in terms of transparency

actually and said it really well um

current modern AI systems are not

inherently transpar transparent and

interpal it's it's actually pretty

shocking when you think about it because

these these models that are so complex

that you can't even like if you want to

talk to like a non-sp specialist and

describe how they work like really nuts

and bolts how a Transformer makes a a

prediction or generates a a token that's

like really really difficult and then

when they say well how do how do we like

pinpoint where something went wrong you

can't do that you can't do like

meaningful you know reverse engineering

right and so this is really an issue um

especially as we see these systems going

off into the real world and so um as

well um and i' I've worked a lot with um

folks working on reproducibility so we

actually organized a a machine learning

reproducibility challenge um for a

couple of years running and essentially

what we asked people to do is take um a

a published paper take something that

