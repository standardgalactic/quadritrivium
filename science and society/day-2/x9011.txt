so much and um they can they can help

you in a way that a search engine cannot

so for example you can interact with

these you can ask more details about a

particular step to achieve something in

fact I've seen a demo where um the the

person was using their um their tablet

and showing the the thei system

uh with a video like what they were

doing and asking questions well okay so

what do I do my with my pipet now which

button should I press in order to you

know move to the next step so this is

clearly something you can't do with u a

search engine but that being said when

we do these evaluations we have to be

careful to consider the marginal um harm

uh or risks that is brought by these

systems compared to existing systems um

on the malfunction side um and looking

you know further down the road there's

the uh concern about loss of control and

there's been some recent development uh

in the last few weeks papers came out

showing that uh some of these most

advanced systems if they they read in

the documents they have in input that

they're going to be replaced by a new

version of the AI will try to escape so

what is that mean well um they will try

to hack the the system so as to replace

the code and the weights of the um uh

next system by their own code and

weights uh now of course this is all set

up this these are control experiments uh

and so the AI didn't really Escape but I

think it shows signs of intention to do

things that we really don't want from

these systems in other words some kind

of um deceptive and self-preservation

behavior if you ask them later you know

why did you do this they will say uh you

know they will say oh uh I didn't do

anything um so yeah

we absolutely need to find ways to uh

mitigate these risks to understand how

they come about and make sure that we

build AI systems that don't um act

immorally that don't uh harm people in

ways that go against instructions that

