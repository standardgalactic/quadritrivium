and time to be uh

produced um another thing that the

report talks about is that we're

starting to see companies used using AI

itself as a tool to accelerate the

research and development of AI in the

engineering the programming and there's

an anticipation as as we move forward um

and these systems become more competent

closer to human researchers um that that

could accelerate the development of AI

as

well all right so I promised uh a little

bit of a the taxonomy that we used to

discuss risks um we've talked uh we've

divided that in three main categories

risks from malicious

use risks from malfunctions which are

basically unintentional problems and

systemic risks which uh are kind of a

category of you know the accumulation of

many small things that uh end up causing

problem whereas the malfunctions uh can

can be and and some of the malicious use

can be catastrophic you know

uh in and when one one bad event could

be really bad so on on all of these

fronts there are risks that are well

studied and well

understood um so on the malicious use of

course uh you know that there's already

a lot of scams and uh you know deep

fakes that are used either for political

reasons or criminal reasons on the uh

malfunctions the prevalence of biases

and discrimination is is well studied as

Sasha you know told us about um and on

the systemic side privacy violation is

something that's very current in in both

trying to understand uh how to mitigate

them and you know the legal status of

these things if we look a little bit

ahead of time uh on the malicious side

the thing that's really clearly short

term is the use of these systems by

people who don't have enough expertise

to really uh do things like de velop new

weapons um uh perform cyber attacks um

deploy

bioweapons um because these things know

