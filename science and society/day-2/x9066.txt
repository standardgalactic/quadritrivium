I mentioned Jason Ferman before um I

just saw him tweeting about this I don't

know if that's an official uh citable uh

paper but he also said that it was had a

number sort of roughly in this range but

like all of us I think all of us agreed

that there's a wide possible range of

Futures so let me talk about that range

of possible Futures because the possible

Futures are not just randomly assigned

to us to some extent they're based on

our choices and we are able to steer the

future in the future I heard Philipe

comparing it to riding a horse and we

can we can steer it a little bit so if

we don't do a good job I think we get a

really disappointing low productivity

future similar to what drone was

imagining I think he had in mind that

all these bad things happen that

actually AI ends up not being used in

very many places only a few large firms

and I won't go through the whole list

but if you want to see them um this

paper I have with uh Gabriel on the

macroeconomics of artificial

intelligence goes through them in a

little bit more detail um came out last

year so here are some of the bad things

that can happen um whoops um we also

have a list of good things that could

happen and obviously to the extent we

have choices we'd like to steer

ourselves towards the higher

productivity future if we get those

higher numbers it's amazing how much

better off our economy will be um if you

look at the US budget deficit for

instance it becomes much smaller if

productivity growth is just two or three

T of a percent higher um we can address

poverty and health care and the

environment much more easily if we get

these higher productivity uh numbers so

I think that these are choices we can

make in some of our uh legal framework

some of our training some of our policy

Frameworks that steer us towards that

again I'll refer you to the paper for

more details in the interest of time now

