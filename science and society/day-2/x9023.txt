is also a support supporter of this uh

uh this proposal as well and together

with many others um and within this

proposal we actually list out five

priorities here I want to just mention a

few in terms of what we think can help

in terms of risk management and so on so

this is combination of Science and

policy so on the policy side we strongly

believe that transparency uh adverse

event monitoring these are really

important to help us to Monitor and

understand how the AI systems uh are

improving and also with the the

dangerous capability monitoring and also

real world deployment post deployment

harm and so on and another aspect is in

terms of really need to advance the

scientific understanding of AI risks and

how we can mitigate them and I want to

just briefly mention a couple points so

in terms of understanding as we were

already discussing uh there are so many

a huge broad spectrum of different types

of risks and we really need to have

comprehensive understanding of all these

different types of risks and in

particular we propose a framework called

marginal risk assessment that we need to

really understand the marginal risk

brought by these uh uh Frontier AI uh

capabilities and as I mentioned uh in

particular as an example in the space of

cyber security for example we are doing

uh risk assessments uh analyzing the

impact of Frontier AI in the landscape

of cyber security and we want to

actually engage the community and do

this as a continuous monitoring uh and

longitudinal study uh with the community

to better understands the risk in the

space and uh the another aspect besides

understanding we also want to develop we

need to develop new a methods to

mitigate these risks so with that

actually with Yoshua and number of

others we have a new initiative on

quantitative uh AI safety so how we can

bring more RoR more prole guarantees uh

for Safety and Security of these AI

