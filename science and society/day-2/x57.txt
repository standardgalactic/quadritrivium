for future criminality and so if a a

white uh prisoner and a black prisoner

have very similar backgrounds but they

have different racial characteristics

the black prisoner will be penalized and

so this we talk about AI bias right but

essentially when you think about it it's

because in reality it's not because

someone is black that they have higher

chances of committing a crime right and

this is comes down to General

representativity and so when we think

about data uh used for training AI

models there's a couple of like iconic

data sets that that come to mind David

mentioned one of them imag net and this

this um actually the size of of of data

has been growing sharply um as as an

mentioned before and I still remember

this when you had to solve a problem you

would actually look at your data right

you would come and you would you would

do data analysis and it would take some

a couple of weeks or even a month and

that was fine and that was part of the

process well nowadays we talk about data

sets that are too large to document and

because we're talking about terab of

data both during the creation of the

data set and after the fact so we don't

even know what's in these data sets and

the bottom bottom plot is from a paper I

wrote with G Boku and Meredith Whitaker

and we plotted essentially training data

sizes of of of um popular popular data

sets us were training a AI models and

nowadays they're bigger than the amount

of people on the planet at this point um

and essentially what does this data

represent and so essentially there's

been research that show that's shown

that neither image nor text data sets

are actually rep representative whatever

you want that to mean but they represent

a select set of communities and of

populations and so for example there's

some really great work about text corpor

so there's a um documentation article

about uh C4 which is a common Text

corpus and that showed that essentially

