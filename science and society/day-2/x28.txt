of the world like is just not scalable

even for like open AI servers but that's

natur not the reason why you wouldn't

want to use it it's because chat GPT

just wouldn't be able to solve this

problem

there actually standard approaches from

um there are standard approaches from

computer vision like Vision Transformers

which are designed On Tools on to do

tasks like classifying images in imag

net and those are also quite big not

nearly as big as as as llms like maybe

100 million or a billion parameters

instead of a trillion parameters but

those are actually not the best tool for

the job the best tool for the job we

found is an algorithm that we developed

called cresto which has about a thousand

train parameters instead of a trillion

and again this is not better because

it's smaller though it is also better

because it's smaller and more scalable

it's also just better like numbers wise

it does a better job of mapping the

crops and we'll see why in a moment but

um this is the case in a lot of

situations where if you design a tool

for a specific task this is the right

tool for the job because you can build

in the the problem you're trying to

solve but I'm getting a little ahead of

myself this turns out to be best not

just for mapping crops but also for

assessing fuel moisture which is

important in uh assessing risk from

wildfires in tracking trees uh and in

measuring alol blooms uh which are made

worse by climate

change so how does this work how do you

get a thousand parameters to do better

than a billion parameters well um it's

because you use the structure of the

remote sensing data and in this case the

vision Transformers were designed to

work with natural images which means

like images on the internet uh like IM

and if you use the structure of remote

sensing data you can take advantage of

the fact that there are many different

