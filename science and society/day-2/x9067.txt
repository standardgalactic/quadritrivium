there's also a set of challenges um in

addition to potentially having great

productivity we also have a danger of

not being very fairly distributed

there's no economic law that says

everyone's going to benefit evenly

there's no economic law that says

everyone's going to benefit at all it's

possible for the gains to be

concentrated in a very small group um

perhaps Capital owners or perhaps

certain types of workers or perhaps

technology owners could capture many of

the benefits so we have to make some

choices um one of the ones I want to

emphasize and this builds a little bit

on what Danielle was saying in the talk

a little bit about an hour ago um I'd

like us to think more about how we can

use AI to augment humans rather than

simply replace humans the idea of that

AI should imitate humans and that the

measure of intelligence was what humans

have for intelligence can be traced at

least back to Alan Turing actually you

can trace it all the way back to Deus

3,000 years ago the mythical engineer

but Alan Turing literally said here's my

measure of intelligence can we imitate a

human so closely that we can't tell

whether it's a machine or a human they

behave so similarly so that I thought

was a great a great measure when I was a

child I thought that's amazing um you

know now we have a real measure of

intelligence I've since decided it's

actually a really bad measure of

intelligence and it's not only a bad

measure of intelligence it's also a

destructive direction for us to be

steering our our thinking and our

research so uh people like um uh my

former colleague Nils Nielson at

Stanford even though he doesn't say he's

pursuing the Turing test in his papers

he and many other people implicitly say

that they want something like that their

definition of what he calls strong

intelligence is intelligence that can do

all the tasks that humans can do so

