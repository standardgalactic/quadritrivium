completely and I think as we think about

the question of technology in the human

to have the case of notredam in mind and

to think about what it means for that

incredible artifact to exist over

centuries and have a place in human

hearts puts in perspective technology

puts in perspective the question of how

the social and the human interact with

each other the technical and the human

so I am going to extend the conversation

about AI ethics for my keynote I'm going

to extend beyond safety safety is

fundamental as we all know with

automobiles The Innovation opportunities

increased after safety became a serious

concern once brakes were added cars

could go faster than transport networks

could be broader and the like so it's

true that safety and Innovation do align

with each

other yet safety is not enough for us to

answer the ethical questions that we

currently face we are in a moment of

comprehensive sociopolitical

transformation driven by technology and

we need mental models to think about

that change my talk with you this

afternoon has the title of a time to

choose I think we are at a point where

we do have a time to choose with regard

to the Paradigm for technology

development that we put at the center of

our work before I get to that content

though let me just introduce myself a

little bit more I'm a combination of a

Harvard professor and democracy

Advocate I have done a variety of things

over time but when people ask me what I

work on I always give the same answer

just democracy

past present and future with no question

mark at the end of that and I say that

coming to you from the United States

okay there are a lot of us with that

deep and persistent

commitment and I also like to share that

I come by that commitment to

self-government for free and equal

citizens super honestly to start it's a

