electricity production in lwi income

countries um and even in places like the

US so there is there is a problem

here I'm not going to fully talk about

this graph and what contributes to it

and what we can do about some of the

pieces here um I know that that Sasha is

going to be speaking a bunch about these

different these different aspects both

in her uh talk after this and in her

keynote but I can touch on some of the

different ways that these energy costs

uh appear they appear from operational

emissions at the stage of at the stage

of um development of AI systems um which

happen relatively infrequently but take

a lot of energy then in your training a

system which typically get retrained

periodically if they're under deployment

um so that's that happens sometimes and

you also uses a lot of energy not quite

as much as development and then when

you're running the system so if you like

ask chat GPT a question that happens a

lot and the energy per run is less but

because these sort of counteract each

other each of these components is

significant and then there's the

embodied emissions as

well production uh of Hardware takes a

lot of energy mining that transporting

the materials and then when you need to

dispose of them that requires energy to

and it generates emissions directly so

all of these things all of these aspects

of computation in AI have significant

costs and as these these that that curve

goes up um all of these components are

getting more intense it's a big

issue so why do I think that this

framing is wrong well because it's posed

as a tradeoff

we can get the benefits but we have to

have these

harms and I don't think we need to

accept

that this tradeoff framing assumes that

AI is one

thing and in actuality AI is a managerie

of different

