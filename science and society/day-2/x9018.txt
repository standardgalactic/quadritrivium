think it's important while of course we

need to keep an eye on potential

speculative risks but it's important

that we don't forget that these risks

are there they are actually certainties

and uh we need to work on them and we

need to mitigate them I wanted to make a

a short comment about the capabilities

which I think is also interesting and

it's a little bit reflected on the

report which is we humans have hundreds

of years of work in developing models of

human cognition and we and therefore we

can determine the capabilities of humans

so if you want to solve a very complex

physic problem you first need to know

basic math because otherwise it would be

almost impossible for you to do that

right but that doesn't necessarily

happen with General propose AI models so

something that is very important for us

always to remember is that the fact that

they can do very well on some legal test

or on some math test doesn't necessarily

mean that they have all the necessary

capabilities that a human has to be able

to do that and we have numerous examples

of how brittle they are for example

failing on very simple arithmetic um um

operations just because they happen to

be rare in the training data I think

there was 42 * 43 for some reason they

were failing on that or even giving you

different answers depending on how you

ask depending on whether you include

random sentences in the prompt that have

nothing to do with a question that a

human wouldn't be confused about but

they get confused about or changing the

order of the questioning and then

providing completely different answers

so these are all um behaviors that would

not expect from a human that was able to

Ace the whatever SAT but that they do no

so I think we need to um try to unbias

ourselves from extrapolating from our

own capabilities when we evaluate and

try to understand the capabilities of

these powerful models because it's not a

onetoone mapping to human

