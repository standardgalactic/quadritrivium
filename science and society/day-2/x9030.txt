you know by abjuring the risk of uh

applying the powerful AI techniques we

have we might be in the situation right

of exposing ourselves to even more

present existential risks and we know

that there are other potential

existential risks or even putting aside

existential risks we are quite likely

con condemning millions of people to

painful and early deaths so I think uh

the precautionary principle I think is a

frud one fact it was used to slow down

the use of nuclear power in Germany for

example which had um arguably a quite

strong negative uh impact on climate

change so um you know is there a balance

of risk and benefit that uh is is more

difficult to make the now perhaps is

being expressed here so I I think these

are very good questions and require a

careful analysis of the different risks

and their severity and likelihood right

and their timeline um so um I'm

absolutely in favor of accelerating on

AI for science but one thing that people

don't realize is that the greatest risks

uh in terms of um malicious use Say by

terrorists or loss of human control they

all emerge from agency like systems that

have a lot of autonomy and all of these

scientific advances can be achieved

without that okay so what I'm trying to

say is things are not simply black and

white we can make choices in the kinds

of AIS that we want to push forward um

so that we can address things like you

know uh disease and uh climate issues

and so on and other scientific advances

that we would really like to use AI for

but we don't need to take some of the

crazy risks that are we are currently

engaging in for which there's much less

uh understanding of you know uh the

probability of these things happening

and the overwhite Horizon so I think we

can be smart about managing the

risks thank you very much and we'll have

one more

question okay so hi uh I want to repeat

one of the concerns that were uh was

