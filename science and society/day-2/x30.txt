be trading off

between optimizing for uh lower power

consumption and uh satisfying the

physics of the power grid so a naive AI

algorithm ends

up violating power flow constraints

which means that the entire grid might

break and people people die if the grid

breaks so nobody would ever use a

standard AI algorithm in this case

because it runs the risk of violating

the constraints of the engineered

system so we designed a way that makes

it possible to

um satisfy the engineering of the system

to not violate physics and this uses a

technique called implicit

differentiation to back propagate

through these constraints this is for

the computer scientists in the

room the upshot is that this solves this

problem or is of magnitude faster than

traditional methods without viting

violating constraints so it's safe to

use on a power grid and its orders of

magnitude faster again it's orders of

magnitude faster not just than AI

algorithms it's orders of magnitude

faster than the algorithms that are used

to solve this problem not using

AI so if we're talking about like

computational power this is saving

computational power

significantly Okay so we've seen a bunch

of different examples here and what I

want you to take away from this is that

AI can be designed for problem specific

goals

oftentimes there is the perception that

to innovate in AI we need to build

bigger more General systems and don't

get me wrong sometimes that's

useful but there's really a frontier in

AI for application driven Innovation for

taking new AI

breakthroughs in directions that are

needed by users to meet real to the

challenges of real world

tasks to meet application specific

evaluation metrics like instead of just

