been not fair because uh we put a lot of

other elements into the uh the

evaluation and I think one of the future

open topic is how to quantify that part

of the variables and uncertainties you

know uh in addition to the outcome

created by the

system um many Foundation models uh are

increasing increasingly performing well

in tasks different from image

classification or text generation uh we

could tell that they start to have

emerging agentic behaviors and we will

see this more and more in the future so

bu building on top of what you just said

uh how can we design these systems to be

robust reliable and align with human

values and goals um Dr Kama as you

worked on autogen would you like to

start my my lab has a big focus on

agentic AI but it's also a coincidence

that my PhD thesis many years ago was on

AI agents and it's another example of

past work coming into our world right

now and the translation work that needs

to happen to take those past ideas and

past techniques and ask the question of

how do they look like in this new world

with the foundation models in the

picture and how do we make them work in

a world where the foundation layer is

stochastic and sometimes unpredictable

so I want to talk about a few things a

few reasons why you might be hearing a

lot of interest in AI agents first of

all AI agents is really about providing

value to users in the sense that when we

are talking about an llm we are only

looking at language as the output and

the value of just producing language has

a limit when we get into many use cases

in the world whereas when we are talking

about AI agents we are talking about

autonomous or semi-autonomous entities

that can understand and conceive a high

level goal and decompose it into actions

to be able to carry them out with either

supervision of the person or

autonomously and this very much

correlates with a lot of the domains

