progress of text language model to to

see whether we can do the same with

speech after all speech is a sequence of

spoken words where text is the sequence

of written words uh and then going from

text to a language model so if you with

the class with the same tools as we have

for llms so the first problem with that

is that there is a very complicated

computational bottle bottleneck here

take this sentence qai is an a lab based

in Paris which is the case it's a 3

second sentence with a few words in

actually eight words and if the audio of

this sentence is classically simple that

72 khz then you have sorry 24 k then you

have 7 72 uh, samples to feed into your

model which is just urable for when you

think in terms of tokens it's 10,000

more tokens than the word tokens and in

terms of the complexity of the soal

attention which is quadratic you end up

we end you end up with something which

is 100 million

times more computationally complex which

is not feasible so the first thing you

have to do uh is to turn this waveform

this audio signal into something which

is amenable uh which is way slower so at

a much lower frame rate but still

retaining the richness of the original

audio and this is something that you can

do with uh with the codc I'm going to

show that in a minute and then if you

have that you can train an actual

language model the same way you train a

text model to to do Contin

uh and this is actually what you we do

we did so the name is actually Mimi not

what is written on the slide

um it's it's bit hard on the

figure let me try to explain um so you

have your the way form it goes through

the encoder that we built from scratch

which is based on the previous

state-ofthe-art in other labs and which

is able to actually uh process or

deliver at a very lower framework which

which is 12.5 Hertz which is 80

milliseconds per um per time frame and

