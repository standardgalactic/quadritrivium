some kagal competition it was you know

shown to be very very effective to win

kagal Etc so I would say that was a bit

the beginning of a trend to to create

Foundation models for pathology uh in 24

I mean end of 23 and 24 I think there's

been 20 Publications from academic Labs

companies pre-training Foundation models

for pathology in particular is tempting

to say well uh following what happens

elsewhere does it get better if you

scale it so if you have more data bigger

models uh this is tempting so this is

something we did at bi Optimus this year

uh we released open source model last

summer which uh at the time was the

biggest in terms of number of parameters

train on a propriatary data set the most

largest and most diverse data set and I

won't go to many results but basically

we observe that the scaling low apply

lies meaning that really we see better

results significantly better results on

many on many tasks if you better

pre-train the foundation models with

with this one for example okay so that's

one modality and no surpris I would say

this ID that works in other fields also

work works here if you can access

Millions tens of millions of

histopathology images to pre-train a

model then you can find un need and get

just better diagnosis and remember you

know these models they are used in the

clinics today so an improvement here

means that you save lives in the clinics

which is really what motivates

us okay something that we pushed on

arive last week or two two weeks ago uh

is an interesting I mean not completely

surprising but you know some of the

things that that is very hard when you

deploy the systems in the real world is

uh especially you know a system to

analyze images in the clinics is it has

to be super robust to differences in you

know small differences in the sample

preparation in the scanner in the you

know the quality of the image uh and so

we tried something which is a

