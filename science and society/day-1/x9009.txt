make sure that now we are getting into a

much bigger

transformation we go to it with the Open

Eyes

and maybe the risks from fake news

or AI generated content could be minimal

but I also see that we should we should

have open eyes and learn from the

mistakes or the experiences of the past

to think about can things be better this

time around yeah and I think the word

open that you said is is actually a big

important piece of this if we don't know

what model is in the data how do we even

valuate whether it's a problem that

there's all this AI generated content I

mean it's a from a cyber security

standpoint it's a really weird attack

surface that if you can just post

something on the public internet and it

might end up in the model that's that's

a very easy entry point so I don't think

that means that there's a problem with

AI it just means that we want to be very

careful about where we get our data from

and we want to vet it we want to have

mechanisms for ensuring that we're

getting good stuff and and I think we're

broadly past the era where everyone

would just slurp up everything and just

sort of use it un un unintended but you

can't if you can't know because you

can't see and I think again this gets to

your point as well that you know if we

can all see and we can all participate

then we can be saying hey look there's

this weird data that's been generated

that surely someone is doing it in an

adversarial way to to bias your model

towards a particular kind of outcome um

you know it it requires different care

and I think it requires different

transparency and I think those are

things we'd want to have anyway so to

that point I agree with you that like

you know maybe not a threat just

requires a certain kind of care that we

probably always should have

had a huge thank you to the speakers

thank you to the PhD students for the

