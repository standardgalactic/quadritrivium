will just spend more time performing

inference in other words they will think

about complex problems for longer than

simple ones for which the answer is

pretty obvious

um and this is really a very classical

thing to do in classical classical AI is

all about reasoning and uh search and

therefore optimization pretty much any

computational problem can be reduced an

optimization problem essentially or

search problem uh it's also very

classical in

probabilistic modeling like

probabilistic graphical models and

things of that type so this type of

inference would be more akin to what

psychologists call system 2 in uh sort

of human

mind if you want system two is when you

think about what action or sequence of

actions you're going to take before you

you you take them you think about

something before doing it and the system

one is when you can do the thing without

thinking about it you know it becomes

sort of subconscious so llms are system

one what I'm proposing is system two um

and then the appropriate um sort of semi

theoretical framework to um explain this

is energy based models which I'm not

going to have time to get into too much

detail but basically you capture the

dependency between variables let's say

observations X and uh uh outputs uh y

through an energy function that takes

low value where when X and Y are

compatible and then larger values when X

and Y are not compatible you don't want

to just compute y from X as we just saw

you just want an energy function that

measures the degree of incompatibility

and then you know given an X find a y

that has low energy

for that

X okay so now let's go a little bit into

the details of how this type of

architecture can be built so essentially

and how it kind of relates to um uh

thinking or

