to be better than jpd but we achieved

that it was safer and the reason because

we we train like somehow we we have

these 20 categories not a doctor not a

financial advisor uh not sexist not

racist no not that not that right and so

but you know and we were paying people

to label label those things and and it

worked right but eventually you know we

figure out that you could just ask your

pre-trained model already right you know

so let's say you say something sexist on

Twitter right somebody else will just

say oh you're sexist right so we and

obviously you know that l

uh already even pre-train LM just

recognize those things you know or

instruct train LM recognize those things

so in sense you know just you know

retrieving somehow knowledge that is

store something still very open for us

and so this is some of you know starting

to crack this like here we just we

actually know that skills that that llm

would have that capability but this is

somehow a way to access it it's like

this kind of like the you know

benevolent teacher that comes you you

know we we what we studied last week

maybe you should apply that right so

it's somehow like you know like somehow

the whispering which skills you could be

used well in based on that you can you

know select in context examples now you

don't select them based on your

embeddings and Rag and your vector

database and then compute the

answer and I forgot where is the all

right so this is the full over of method

super simple you label the skills you

know using llm you uh you uh cluster

them in categories

you rename your skill examplars that you

have you know that could be all the you

know your data you know with the skills

that you used and then at the test you

know instead of uh of uh of just using

your rack based on embeddings you try to

figure out somehow how is the skills you

know simplest ter is just using uh uh

