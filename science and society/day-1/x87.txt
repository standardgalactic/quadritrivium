program so I I think there's a little

bit of a tendency to want to like

personify things because it feels like

the right model and and in some cases I

think that model can be um can be

misleading it can can lead us into spots

where we get um sort of unexpected

behaviors and we rely on it in a way

that we perhaps shouldn't and then the

last thing I'll say about that is um it

also leads to a very weird world of

software where now instead of

maintaining code we're maintaining like

in many cases essays like an essay that

sort of tells you know the model its

backstory and and you know what it

should do and we're going to have to

evolve new ways to to deal with that I

came across a Reddit post where somebody

said if they included the Blade Runner

Tears In The Rain monologue everyone

seen Blade Runner at the end where he's

he's about to die and he says all his

memories will be lost like tears in the

rain if I include that in the end of our

my handoff to the next agent I get 3%

better performance on my task and I'm

like okay that's cool I interesting but

as like former computer science

Professor I don't like it um you know it

doesn't feel doesn't feel principled in

the right way so I think there's going

to be out of tension and I I I think one

thing that agents I mean obviously

automation is is is what we want we want

to take away the drudgery but I do worry

also that agents kind of put us in a

weak spot where we you know we want to

trust we want to treat it like a like a

thinking entity and in many cases that's

simply not what it is and pro and might

not be the the right parad for for doing

it so I think it's really important that

we all kind of take this broader View

and and look at what the problems might

be when we solve real world problems and

then embrace the the good parts of of

what we're calling atic today because

there's a lot of opportunity but there's

also you know a lot of blind spots as

