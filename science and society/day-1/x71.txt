right like they we can have a dialogue

with them which for many of us who

worked on AI for many years uh we never

thought was going to be at that level of

maturity within within our lifetime so

uh they're already very impressive but

you can also um trip them very very

easily um and I think for those models

to be truly useful um they need to be

multimodal and they need to uh really be

more understandable as well to your

point so for multimodal the multimodal

aspect uh we really saw it with met

Gemini so for those of you who missed

the talk met Gemini is Gemini our large

language model um the most powerful

we've built fine-tuned for the medical

domain and um to be able to you be you

need to do that because the medical

domain is is really an expertise domain

so you need to make sure that your your

model um understands medicine and

understands the the specificities to be

able to be helpful within that domain um

and the first thing is indeed to to feed

it uh very data so in in um in the

medical domain you have your electronic

health records that that's text you have

uh a lot of textbooks um but you also

have many images and they can be quite

different from the images you take with

your cell phone camera uh day in day out

so some of the the capabilities of the

mo of the foundational model the fact

that it knows what to do with those

daily uh images can be transferred to

the medical domain but not it's not

enough when you think about digital path

ology those are humongous slides um so

that that presents specific challenges

in terms of just the infrastructure to

be able to to train those models um and

then you have a a wide variety of of

types of data um so whole slide

pathology images but also Radiology

images MRI x-rays CTS Etc you have your

genomics information which is you know

an incredible source of information but

also quite idiosyncratic in terms of the

of the format and the structure of the

