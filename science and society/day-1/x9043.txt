and this is like across multiple layers

you see really and you project these

like say TSN style you you start to see

patterns where parts that are expressed

in genes and parts that that are not

start to appear and start to Cluster

okay so that's cool and obviously like

the idea here is you're going to try to

build this uh like uh self-supervised uh

representations to be able to capture

structure and eventually in the end take

a few down screen tasks on which you

have limited data but hope y even with

limited data get going and get results

and that's actually what we have seen

we've seen in terms of like

classification tasks or like regression

style tasks we could get to cool results

so these were some of our first uh

results uh you we see here we tried

multiple models as I said and the

interesting topic is the more data you

have the better the results even if it's

multi-species so imagine that you have

uh actually uh like you're looking at

like genome Human Genome tasks actually

you have a benefit for from having

multi-species data that was not an

obvious U point a more obvious point is

like okay if you have more compute you

have a bigger model this works but like

multi-species was actually interesting

and sort of like the fact that training

self-supervised on a single model allows

you to get state-of-the-art results on

many different tasks before this work

the standard in genomics was hey I'm

have specialized task U like for example

like predicting the you know the the

occurrence or not of like particular

promoter regions or regulatory regions

well here we showed that with a single

model across multiple tasks we could

just getting out of uh self-supervised

training get a state-ofthe-art on 11 out

of 18 Downstream tasks and even 15 if

you were fine tuning the whole model for

specific tasks so this shows you a

little bit the kind of potential we we

got and really the takeaway is and we

