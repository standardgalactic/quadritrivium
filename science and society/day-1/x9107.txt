it's actually very complicated and the

stuff that we think is uniquely human

like manipulating and generating

language playing chess playing go

playing poker producing uh poetry and

this kind of stuff does have to be easy

relatively okay and perhaps the reason

for this is this very simple calculation

um a typical llm nowadays is trained on

on the order of 30 trillion tokens 3 10

to the 13 uh

tokens that's two to the 13 words

roughly each token is about three bytes

um so the data volume is roughly 10 to

the 14

bytes uh it would take any of us uh

almost half a million years to read

through all that material it's basically

all the publicly available text on the

internet now consider her human child

for world has been awake a total of

16,000 hours which by the way is only 30

minutes of YouTube

uploads um we have 2 million optical

nerve fibers Each of which carries about

one BTE per second maybe a bit less but

it doesn't matter so the data volume is

about 10 to the 14 by in four years a

four-year-old child has seen as much

data uh as the biggest llm in the form

of visual perception and for blind

children is touch it's the same kind of

uh

bandwidth uh that tells you a number of

things we're never going to get to human

level intelligence by just turning on

text it's not just not

happening despite what you know some

people who are have a vested interest in

this happening are telling us that we're

going to reach you know PhD level

intelligence by next year it's just not

happening we might have PhD level in

some sub field in some area some uh um

problem like chess playing you know but

more of them as long as we train those

systems specifically for for those

problems as um as Bernard was explaining

with the visual Illusions um there are a

lot of problems of this type when you

