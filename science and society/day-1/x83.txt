that we actually need an autonomous

entity to carry out tasks so that we

don't have to oversee every single thing

that's being done or carry out the

actions ourselves

the second thing that's happening in the

agent space is that we are having agents

taking actions in the world which is

both changing the value we get but also

the risks so you asked the question

about how do we build these agents in a

reliable way I want to I want to give an

example of what I'm seeing from my lab

so with any changing AI technology as

the capabilities are improving there is

also a question of increasing risks

sometimes those risks are about the

adversarial use somebody not meaning

well to take a AI tool an agent or an

llm and use it for a purpose that is not

really well for our society but

sometimes it is really about unintended

consequences and one of the things

that's happening with the AI agents

right now is that the advances in the AI

agents are also very much coupled with

what's happening in reasoning and

planning capabilities and with models

like o1 R1 O3 coming out and being able

to take complex tasks and being able to

decompose them into actionable steps we

are seeing that these agents are

becoming more creative in terms of how

they are taking actions and they may

actually start acting beyond our

expectations or the operational

boundaries that we haven't really yet

defined for these autonomous systems so

a few weeks ago um we we built agents we

built agent teams and agent

orchestration platforms like gen

magentic one and such and I have given

one of my agents a very simple task I

said can you go to New York Times

crossword page and complete the uh

crossword puzzle for me and just submit

it which is something I cannot do

because I'm not a native English speaker

I always get stuck in some of the

questions on that page and what

