there's going to have to be a reckoning

of all of the security and Enterprise

thinking that we've had we have in our

current systems you're not allowed to

deploy systems that have private data in

them if you don't comply with these

things so that's going to have to all

come uh on top of the on top of these

agents um and then you know you have

things like tainting where like you

touch a piece of sensitive data taints

everything that follows down I mean llms

Transformers with with you know regular

softmax detension they're they taint

their entire cash but like the KB cach

everywhere so it's it's a really

interesting new set of challenges where

these things you know can you have uh

new kinds of vulnerabilities where you

know an agent touches a HR database to

get a particular number and now that

number is potentially can be gotten by

somebody else quering something with the

same you know history there so I I think

it's going to be a whole interesting set

of things that we have to address and

and basically read address and relearn

and maybe that's one of these the themes

that's emerging from this thing is

there's lots of things from olden days

that we we bring back in um the other

thing I will say is that not everything

that's useful that you can do with an

llm is actually an agent um we

encountered this paper which was a very

interesting paper called chain of Agents

where they took um a retrieval augmented

generation task and they sort of split

it up amongst a bunch of agents and the

Agents work together and they synthesize

the information and then a manager agent

took it and then it put out the final

summary and then we kind of looked at it

for a little while and then we're like

this is map reduce this is like the most

famous algorithm it's in the list manual

like there there's no like it doesn't

have any of the properties that you were

describing like the planning and and all

those things this is this is just a

