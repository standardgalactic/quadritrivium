these Foundation models over the last

few years uh and has focused you know

because there's lots of data in biology

there is genomics that was mentioned in

previous talks but there's also lots of

images lots of protein sequences lots of

patient data electronic health records

CT scans you name it so we have seen

over the years a number of groups trying

uh you know to adapt the Technologies

and these ideas of self-supervised large

language models to these different

fields and often you know made progress

sometimes spectacular progress sometimes

you know less spectacular but at least

the field is really pushing the limits

of what can be done to learn biology

from data so that it can be useful

so what I want to do now is just spent a

few minutes no not mentioning my work at

all but surveying a bit what has been

done just to give you a flavor uh FYI of

of which domains have been uh impacted a

lot I will not talk a lot at all sorry

about DNA it was perfectly covered

already uh but going a bit to the next

levels of bical organization so proteins

is related I will be short uh Alpha fold

is the best example of how to train a

big AI systems on lot lots of proteins

sequences structures and then one

problem solved is you can predi a 3D

structure interestingly of course this

is not the application now there are

tons of companies tons of academic Labs

who use that to design new proteins so

it's not only you have a sequence and

you predict the structure now it's also

you want a structure and can you design

a protein that would have this structure

this function so lots of activities

there it's also very good at predicting

if you have a mutation you know in the

DNA that then transforms a bit the

protein where the the protein changes

its properties it could you know it

could be damaging for the body it could

become resistant to a to a treatment Etc

so I think all of these things uh are

really progressing quickly and many

