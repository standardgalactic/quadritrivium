you can use llms as judge as a judge to

judge whether it was correct or not but

you can also use external tools to judge

if it's correct or not and um you know

if the if the questions you're

generating have verifiable answers then

you can you can certainly just use that

verifier directly and this is of course

related to what R1 is doing our our deep

seek R1 is an example of verifi you know

reinforcement learning with verifiable

responses um so that's basically the the

gist of how you do it so you then start

writing libraries so we can write a

library uh for granted that does grade

school math and and that's something

we've done and then on each of these I'm

just going to fly through these because

they're kind of boring to look at after

a while but just to make the point that

uh we're showing the granite models you

know if you find tune on these data sets

you can actually boost the performance

up to to a very high degree and I'm just

going to compare you know as I flash by

some of these examples we'll compare to

lots of other models um you know like it

should be said these are fine-tuning on

those tasks so when we mix it into the

whole Master mix of the model we have a

little bit of a choice of how much we

want to balance it but it just just goes

to show that a that a relative

AI unaware like a less AI skilled person

can write a library in their own domain

that they really understand and then

contribute it and then we can use it to

compile into data which we then compile

into model weights basically just like a

software compiler chain so we have

library for that Maps natural language

into SQL we have libraries that can help

with function calling we have libraries

that can pose linear optimization

problems uh with a particular software

package called clex that IBM cells which

is you know a very specific thing that

IBM might want to do but the point here

is is um it's not that there's a radical

innovation in doing this lots of people

