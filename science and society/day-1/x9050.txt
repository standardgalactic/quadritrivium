already over time for today my message

is this wouldn't have been possible

without all of us working together

people who are fighting for open source

and making it happen and so at instad

Deep I'm very proud to say that we are

open sourcing a lot of our work we open

source segment n the NT series and

Incredibly we were very pleased to see

that we're now Nearing million uh

downloads on hugging face it's one of

the most popular genomics models in the

world so this is really like a testimony

of the strength of the open source uh

sort of Open Source AI research

community so I want to thank my team and

thank everybody who's keeping that open

source Spirit uh alive thank you so

much thanks a lot Karim well we have

time for TW TW two questions sorry two

questions from the

audience don't hesitate a question

there hello um I'm sorry this is going

to be a really naive question but uh

basically why why does a model that is

trained with both the English language

and the nucleotide sequence work better

than one that only understands DNA

it it's it's it's a good question I I I

think I think it if it is in a better

understanding of the question when

you're formulating your question in

English it immediately gives context to

the model and it allows better transfer

learning from one task to another so you

you could you could train a model on a

specific task and it's that's only what

it does and it doesn't understand

English in any way but here the beauty

is there is transfer learning between

tasks and so how one task relates to

another well basically the language

allows you to do a better transfer

learning so think about it is like

you're you're uh I'm going to try to

give you an example think about code

okay you're programming do you program

yeah okay so imagine you have all the

instructions like say you're coding in

python or in your favorite coding

