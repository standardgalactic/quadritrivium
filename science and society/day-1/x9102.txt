need for understanding for Truth for

intention uh it's all about fluency

according to what's in our

collection

um now

the I I like that to give an

analogy U why this doesn't necessarily

imply understanding uh by showing a

picture of this guy here his name is

nitel Richards is a guy from New Zealand

uh who's was potentially the greatest

scrable player um in the world uh at

some point he got bored of being world

champion in Scrabble and he decided to

compete in the frankophone Scrabble

Scrabble

Championship um but he doesn't speak

French so he took the French dictionary

or maybe the scravel dictionary and

learned it by heart and also all the

inclinations declinations and uh sure

enough he became the frankophone

Scrabble World

Champion so right now our language

models are a little bit at this stage I

think and they're not even perfect

language models as described here there

are crude approximations of that we

don't have access to all possible

texts um very interesting sentences like

many of the sentences that are contained

in in Einstein's exposition of uh of

special

relativity uh have zero zero probability

based on the previous training set we

don't have IID sources of text uh but we

hope that the text share structure and

it seems to be the case that uh

Transformers can make use in some sense

of compositional properties of language

even if people have seen that they still

very much struggle with with

causality so with that I want to

conclude maybe also a little bit

connected to what Mike was saying that

l&m's are far from artificial general

intelligences they are cultural Learners

they learn from cultural artifacts of

humankind and this is something amazing

it makes them amazing they tell stories

