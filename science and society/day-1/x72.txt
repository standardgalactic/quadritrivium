data and so you need to really um factor

that in you also have data that is very

often not in the same abundance as you

can have with again your your dogs and

cats and and things that you know

everyone takes pictures of every single

day um so that requires you to think a

bit differently of of in in the ways

you're training your models um but you

ask about the challenges and I think the

biggest challenge for anything we do

especially in healthcare is how we

evaluate our models like what are the

benchmarks what are the multimod

multimodal benchmarks that are going to

allow us to be confident that our models

are getting better and that they're

getting to the level that they can

really be helpful so in the med Gemini

work uh we pushed a particular Benchmark

which is called Med QA which has been an

academic Benchmark that various groups

have have he climbed against um I

mentioned in my talk how it's important

to have an objective so that was our

objective really to to show good

performance on that Benchmark but then

we also demonstrated that we had set

ated it meaning the remaining couple of

percent were not really something

meaningful that we could continue to

improve against because the the the

nature of the questions were um those

questions were ambiguous that they don't

necessarily had a definite answer and in

in medicine this is something we've

learned over the years even in in the

previous uh phase of AI with narrow AI

we did a lot of work in diabetic

retinopathy and when we did that work to

be able to establish the grand truth we

work with many many

opthalmologists um to ask them to label

the same data again and again and again

so either themselves doing it the you

know a few times with um sometime in

between or having different experts do

it and then we compared and it's really

hard to establish a ground truth in in

medicine very often for that example uh

