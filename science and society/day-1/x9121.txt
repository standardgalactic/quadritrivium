um okay let me uh switch ahead skip

ahead a little bit in interest of time

because we wasted a bit of time um okay

so this a particular way of implementing

this audio distillation called IA

there's another one called called Dino

or Dino uh which I I skipped a little

bit um and um so Dino um is V2 people

are working on on V3 this is a method

produced by some some of my colleagues

at at Fair

Paris um team led by Max Maximo cab um

and then different version um called IA

V

JEA by also Fair people in in Montreal

and Paris mostly so no need for negative

samples there and those those kind of

those systems learn generic features

that you can then learn for any

Downstream task and the features are

really good um so this works really well

I'm not going to bore you with details

because I don't have time more recently

we worked on a version of this for video

so this is a system that takes a chunk

of 16 frames from video and you corrupt

you you take those 16 frames run them to

an encoder and then you corrupt those 16

frames by masking some parts of it run

them to the same encoder and then train

a predictor to predict the um

representation of a full video from the

one that is partially masked or

corrupted and the U so again this is a

group of researchers at at Fair in Paris

and

Montreal um and this works really well

in a sense that uh you learn features

that you can then feed to A system that

can classify actions in videos and you

get really good results with the with

this these these methods again I'm not

going to bore you with details but here

is a really interesting thing this is a

paper that we just submitted um if you

show that system

um videos where something really strange

happens that system actually is capable

of telling you my prediction error is

going through the roof there's something

