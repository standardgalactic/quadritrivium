these llm producing huge amount of uh of

this information and so on but I think

that kind of thing I mean most of us

know about it and I'm sure Yan is going

to have something to Yes um so llms have

been I've been around for a while

they've been available for quite quite a

long time um including an open source

you know starting with uh uh you know

several years ago

when I talk to my colleagues who do

content moderation and are there to

protect against attacks and you know

this information and Bots and things

like this they just have not seen a

flood of um generated data uh with BS

they just haven't seen it it's it's just

not happening and so there was this idea

somehow that we're going to be flooded

by this information that is generated by

by llms it's just not happening there is

disinformation but it's produced by

humans and you know groups like Kon

which had a huge impact on not this

selection but the uh the two before it's

two guys there no there's no AI um the

problem with this information is not uh

the quantity of this information you

generate but it's the network of

distribution so if you have sympathizers

and stuff like that then it becomes

influential and that has nothing to do

with like how much volume you produce so

that's even if it's even if at the end

it might be humans that are the

malicious actors AI certainly gives them

tools to multiply their impact Beyond uh

thank you for saying that I was going to

say that the best countermeasure against

uh attacks by AI is better AI um yeah

the most sophisticated AI systems

currently I me better AI but controlled

by whom exactly I mean that's the

question I mean there alignment of

Interest which is obvious so now that

addresses the question of of bias right

so as Mike said totally correctly you

cannot have a system that is not bias

you're always going to have a bias it's

always a tradeoff and so the way to uh

