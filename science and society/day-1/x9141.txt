or we should not and regulation can also

be a good thing of course for AI if you

look at I mean I remember when

self-driving cars were becoming hot

everybody was talking about what's going

to do what's going to happen if we have

a grandmother here and then

a mother and two children here and how

are these systems going to solve the

problem I remember at some point I

talked to an engineer from Bush and uh

he told me well look the way an airbag

works we can't guarantee that airbags

don't kill people airbags have killed

people in the past but there are testing

authorities that uh evaluate airbags and

at some point people who are skilled in

the art they come to the conviction that

over oil is a good thing to have airbags

and maybe eventually we'll be the same

with self- Drive cars and then we we can

have these authorities that then give

the stamp of approval and that also

protects the person who has programmed

the code and the company that sells

sells these things because we don't want

to end up in a situation where in the

end the role of the human is to serve as

a as a liability is serve that in the

end everything that's done by machines

has to be traced back to some human who

can be blamed for it it's a really

fascinating uh debate you know and I'm

convinced I need to change my standpoint

and how I'm looking at things you know

particularly uh for example if it comes

to bias stepan I wanted to bring you in

because uh We've touched on bias let's

go broader social manipulation for

example uh using AI um you know to to

propagate particular political views for

example how do you get around that how

dangerous is that and can we see it from

another standpoint as Mike suggested we

should do when it comes to

bias well I think here that probably

Yoshua uh tomorrow is going to speak

about all these different kind of risks

so I mean obviously there are deep fakes

there are uh the possibility of having

