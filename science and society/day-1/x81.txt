more reliable more trustworthy less you

know prone to sort of unintended biases

and that kind of stuff um I think that's

going to be you know really Define the

how this field evolves over the next few

years I think when we talk about the

evaluation in the AI system Foundation

models um it's more than a technical

problem it's also a social problem

because the people are so deeply

involved you probably people heard about

the Tesla story right so the the the the

electric car the self-driving car

actually are safer okay than the the the

human driver if you measure the

statistics but uh every time you know

when Tesla commit an accident it's a big

news in a headline and uh people forgot

about how badly we are as a driver right

so in a sense that number you know uh is

not just a code number there are

emotions and me other things human F

into that so that part is for me very

hard to quantify another example is AIS

output is uh solving maybe too hard a

problem uh under a too high expect ation

we forgot that in fact we are not uh

seeing generative results and the

computation results just from AI for the

first time if you look at a you know a

picture of the black hole from telescope

or you look at the picture of electron

from a electron microscope people forgot

that they are actually computational

results these are not what you see okay

these are literally computed from some

signals they picked up but why people

rarely challenge that somehow you feel

like you see it and it's easier to

believe but AI is producing a much more

intricate and complex outcome which is a

language uh you know a narrative and

maybe a solution which makes them feel

like you are part of the person to judge

it and to actually even push back it

gives you this more intimate Dynamics

between the outcome and people I think

right now when we design the validation

we suddenly push back and say oh it's

like evaluating a microscope but it's

