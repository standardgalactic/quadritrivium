need to have both of them.
Both need to be sparse.
So dense with sparse connections is not as good.
Yeah.
And the 2% number is also interesting.
That's sort of roughly the level of sparse city you see in a lot of areas of the brain
actually.
So that's another interesting factor.
Yeah.
So it's remarkable how much.
Yeah.
Go ahead.
Have you ever did any noise within the layers?
Yeah.
So dropout, for example.
So I tried training with dropout.
It hurts the sparse networks.
So another way to say it is you don't need to use dropout.
And the dense networks sometimes helps.
You have to really tune the dropout rate, but in no case is it anywhere close to the sparse
thing.
So dropout as a regularizer is known to help a little bit and sometimes help with test
set accuracy, but in terms of if you use sparse networks, you just don't need to worry about
dropout.
Okay.
I'm going to switch to the second topic here, which is unsupervised and continuous learning.
And here I'm going to dive back into the neuroscience briefly.
So here's our favorite neuron again, the pyramidal neuron.
It's got about 3,000 to 10,000 synapses, as I mentioned.
And these neurons have a very complicated kind of dendritic morphology here.
And they have different kind of functional properties in the different areas.
So in this green area near the center of the cell, the soma, is where most of the feed-forward
inputs go.
And this acts like your typical neuron that you're used to.
It's a weighted sum plus a nonlinearity.
These inputs tend to drive the cell, and it's sort of the classic point neuron.
But the amazing thing is this is actually only 10% of the synapses on the cell.
And 90% of the synapses are in these other distal areas, these blue areas.
And as I mentioned earlier, in these areas, as few as 8 to 20 clustered synapses can generate,
can detect a pattern.
And they generate what's known as a dendritic spike, an NMDA spike.
This spike travels to the center of the cell, but it does not cause the cell to fire.
So you get this event, this recognition event, that seems to have no impact on the cell in
terms of firing rate.
But if you look inside the cell, it turns out it does actually prime the cell to fire
more strongly in the future.
And these neurons can detect hundreds of these independent sparse patterns all throughout
the dendritic tree.
They're all completely independent.
And so for a long time, it was really puzzling, what is the point of all these synapses if
it doesn't have any direct impact like this?
And so what we think is going on is that these dendritic areas are playing different functions.
So you have the feedforward pattern.
This defines the basic pattern that the cell is recognizing.
And what's going on here is that the synapses in these lower distal areas are detecting
sparse local patterns of activity of nearby neurons, and these are acting as contextual
predictions.
So when some of these patterns are detected, it's going to then prime the cell to be firing
more strongly in the future.
And then the synapses up on the top are getting top-down inputs, mostly from regions above.
And these are also detecting sparse patterns, and they invoke top-down expectations.
So this is a slightly different kind of prediction, but it's also a type of prediction.
So what's going on is that you have this neuron that's trying to predict its own activity
in lots of different contexts.
And then if you look at the learning rules in here that people have discovered, there's
really three very basic learning rules outside of this green area.
And the basic things here are if a cell becomes active, if it fires for some reason, if there
was a prediction.
So in the past, if it fires because of the green input, if there happened to be a prediction
in the past, so some dendritic segment caused a prediction here, we're going to reinforce
that segment.
So we're going to reinforce only the synapses in that segment and not in the rest of the
cell.
There was no prediction, but the cell still fires, which is going to start growing connections
to some random segment on the cell.
And these connections will sub-sample from the input that's coming in.
It's going to be a sparse sampling.
If however the cell was not active, if there was a prediction, that means there was an
incorrect prediction, and we're going to slightly weaken the segment that caused that prediction.
The three very simple learning rules.
And here just to point out, learning consists of growing new connections, and each learning
event is creating a sub-sample consisting of a very sparse vector.
Each neuron can be associated with hundreds of these sparse contextual patterns, and essentially
each neuron is constantly trying to make predictions and learn from its mistakes.
Notice that there's no supervision here, there's no batch notion here.
These learning rules are constantly occurring, so everything is continuously learning.
And it turns out that because these vectors are sparse, and remember, if you're in the
right regime, they're going to be really far apart in this space and not interfere with
one another.
So as long as these vectors are really sparse, there's no interference, and you can keep learning
things without corrupting previous values or other learned things.
So this is another benefit of these highly sparse representations.
So this is a very simple kind of learning scenario here.
So it turns out you can take, you can build a network of these neurons we've done, and
you can get a very powerful predictive learning algorithm.
And I'm not going to walk you through the details of the algorithm, but essentially you
have groups of cells.
Each cell is associating some past activity as context for its current activity.
Just one time step in the past.
It learns continuously, and it turns out it generally does not forget any of the past
patterns because of the sparse representations.
These networks can actually learn really complex high markup order sequences, which means
you can impact the current state based on input that happened many time steps in the
past.
Even though the learning rule is Markovian, it's only looking at the previous state.
So there's a kind of a dynamic programming aspect to it.
And then everything is sparse, so not only can you learn continuously without forgetting,
but it's also extremely fault tolerant of these networks.
And so I'll just show one simple result, and this was published a couple of years ago.
This network works really well with streaming data sources.
So here's a case of New York City taxi demand.
So this is a data set that's released by the New York City Metropolitan Authority.
And you see a typical kind of weekly pattern here.
There's seven kind of bumps here.
And the basic task is to predict taxi demand in the future.
If you look at the error of prediction here, we've tested our network, which is these HTM
networks, which stands for Hierarchical Temple Memory, it's the name of our algorithm.
We've compared it against a bunch of other techniques.
And the error rate of the HTM is approximately the same as the best LSTM network.
So they're about the same error rate.
However, what's interesting is what happens when the statistics change.
And the HTM networks, because they're continuously learning, they adapt very
rapidly to changes in the statistics.
So this is error rate over time.
Here's the case where the statistics of the sequence has changed.
You can see that the error for both HTM and LSTM goes up pretty high.
But then the HTM error rapidly drops back to the baseline rate.
Whereas the LSTM takes quite a long time before it drops back.
And this is true even if you keep retraining the LSTM.
And you can play with the retraining window and all of that, and it doesn't matter.
And that's because LSTMs are fundamentally batch systems.
And there's no notion of recency in the samples.
And it takes a long time before the change statistics are a significant
percentage of the overall data set.
And if you don't train on enough, then the error rate's just high all over the place.
So the kind of continuous learning rule that I described is perfect for
adapting really quickly to the changing statistics.
So just as a summary again here, the way that neurons operate and
the way these dendritic segments operate leads to a very simple,
continuous unsupervised learning rule that can learn continuously without
kind of forgetting previous patterns.
Okay, so I've talked about robustness and continuous learning.
We have kind of a long roadmap of things to do, as Jeff alluded to.
So within robustness, we've only tried on relatively small problems here.
So I'd like to try it on much larger problems.
And it'd be really interesting to test with adversarial systems as well,
to see whether these sparse networks can actually hold up against many of
the adversarial attacks.
With continuous learning, this has not been integrated into a deep learning system.
The algorithm I showed you were just one layer system.
So I think it can be integrated in and
we can keep the same philosophy philosophies in there as we integrate in.
And we can implement these predictive learning rules within deep learning systems.
And I think that will may help enable continuous learning and
unsupervised learning in a very rich way in deep learning systems.
And then beyond that, there's the full 1000 Brains idea.
Jeff talked about the voting mechanisms and voting across sensory modalities and
across regions will add some really interesting robustness properties as well
as other properties.
We want to move to a case where there's many, many small models across
sensory modalities that are hypothesizing what their sensory inputs
are detecting and then voting to resolve ambiguity there.
And then I think it's critical to move to scenarios where at every layer
of a deep learning system, you have inherent object-specific reference frames.
And this is gonna allow much faster learning and much better generalization
because you'll be much more invariant to changes in perspective, for example.
If you can represent things in their own reference frames, okay?
One of the reasons we're here is to see if there's any opportunities for
collaboration and we'd love to discuss with any of you if you're interested in
any of these ideas and see how we can apply them together.
Here's some ideas for possible projects in the range of applications.
I mentioned this idea of testing robustness in adversarial systems.
This is not something we have a lot of expertise in.
It would be great to work with someone who's looking into that and security.
There are tons of security implications here as well.
I think we could test with different domains, such as robotics,
natural language processing, Internet of Things.
And as we incorporate these things as differentiable systems,
they can be applied to just about any deep learning architecture and paradigm,
including, of course, recurrent networks and reinforcement learning and so on.
So it would be great to work with people who have expertise in that and
really see how far we can scale these things.
And then specifically, in terms of larger problems,
MNIST and Google Speech Commands are still relatively toy problems.
We want to attack much larger problems.
As a small lab, it's really hard for us to do ImageNet style stuff.
So we'd love to work with anyone who wants to scale these networks.
There's a lot of really interesting things that can be done in terms of
acceleration and power efficiency.
I didn't really talk about the power advantages of sparse representations,
but they're pretty dramatic in here.
Unfortunately, sparse computations are not very well suited to GPUs.
And they're really well suited to FPGAs and other computations.
So I think accelerating these things are going to be quite challenging and
interesting, okay?
So hopefully some of you guys are interested in these things and come talk to us.
And then there's a picture of our research team and our contact info here.
So thank you.
So I don't know how you want to handle it now.
You want us to, I have people who want to hang out, what time is it by the way?
