It's about quarter to 12.
So we went over our hour.
We're here, so if people want to just hang out and answer questions, great.
There's actually one more question.
Sure.
This is adjet.
Learning also happens when we see and watch images and
movies about the world on a screen.
Why doesn't that confuse the coverage sensor motor system?
Is it understood how the brain is switching between the physical world and
these projections?
So I think the question, if I understand it correctly, is when we look at a flat
screen, even with maybe just one eye, so we don't even have stereophobic vision at
all, how is it that we build this depth model of the world and so on?
That's a great question.
We have some clues as the answers of that, that it looks as this, I talked about
those grid cells as representing location.
It looks like they are, not only are they driven by your internal motor commands,
but they can be driven by sensory clues such as flow.
And so the way, I use this example a lot.
Like matching you're watching someone play a third person's first person
shooting game, I never play these games.
But you're going through this maze and you're running around.
You have, you're following this thing and you know where that player is and
you know where they are on the map.
And so all that's happening, the whole grid cell thing and
all those location things are happening, even though there isn't this depth thing.
So it doesn't require, it doesn't require that you have some three-dimensional
camera, it doesn't require stereoptic vision.
And what it requires is that there are sensory clues such as flow.
And you look in the neocortex, these things are highly represented in the cortex.
So various types of vector flow fields that are occurring are driving the system,
even though there isn't a three-dimensional sensor.
It's an interesting question, why I'm looking at you right now,
why do you appear there and not on my retina, right?
My perception of you are there even though you're actually on my retina, right?
So it's the same problem really in some sense.
How does I know you're there and not here?
And it's because of these sensory clues that are really extracted early on from,
if you look at all the sensory streams, both tactile and vision,
they have this sense of motion and flow built into them.
So you have tactile senses which detect movement and your visual and your retina as well.
So I think that's a general answer to that question, but maybe not really super detailed answer.
The people who went to the cinema, or who were in the 20th century and the 30th century,
I'm not aware of the real thinking that this...
Oh, the train's going to come out of...
Yeah, they want you there and they say,
oh my god, the train's going to hit us, you know, yeah.
It's a fascinating thing, I just try to expand it to even make,
just realize how crazy it is that you perceive everything at a distance all the time.
How is that?
I mean, in hindsight, it's so obvious that everything has a location representation.
This was not obvious three years ago.
We just said, oh, I know it's out there, I'm not sure how, but how do you know it's out there?
What kind of neurons are representing it?
Anyway, it's a great question and we don't really have all the answers to it,
but that's the basic gist of the answer, yeah.
When you go to language, which is, I guess, less physical, what role do the columns play there?
So the question's about language and it's less physical,
how do we understand this theory in terms of that?
We don't really understand, but I'll give you a couple of clues here.
First of all, language consists of words and whether they're written words,
whether they're spoken words, whether they're sign language,
those are all physical objects that you can model.
So you've got columns in your auditory cortex that are building auditory models of words.
You've got columns in your visual cortex that are building visual models of the world
and they can vote, so that's why I can hear a partial thing and see something,
maybe watch your, and I can put these together.
So we start off with atoms of language that are really physical objects,
but then how do they get their conceptual nature?
We don't know the answer to that question yet,
but there's some very interesting things that happened recently in neuroscience.
We derive this theory based on the idea that how it is that I touch objects or see objects.
There's a whole other set of research that's just come on in the last couple of years
where they're studying humans using fMRI,
and they've shown that even when you're thinking about conceptual objects in your head,
you're imagining various things,
that there's evidence that there are grid cells underlying it.
So they've discovered this using very clever imaging techniques
where you can sit in an fMRI machine.
I had this slide that came up or like it showed you about birds,
but so no one really understands this yet,
but the evidence is very, very clear that this is what's going on.
So how do you map conceptual objects like words into this location space?
We don't really know yet.
I mentioned the issues of recursion, which is a big part of what language is,
if you read about Chomsky and so on.
So all these things are triangulating, saying that is what's going on.
We just don't understand it yet completely,
but we do know it's going to be based on location frames,
it's going to be based on recursion of location frames.
We have all this evidence which is triangulating on that,
and that's just a fascinating thing to think about, but-
And of course, the circuitry of the brain that is responsible for language
looks identical to the video art.
Yeah.
So it has to be the same basic function.
So to me, this feels more in the...
To me, the big hurdle we overcame was just understanding
how this reference frame concept applies throughout everything.
And now it's more turning the crank and going down these different pieces
and explaining how it is that we do all these different components
and how do we put together a broader theory of concepts in language
and abstract concepts.
We don't really know yet, but it's going to be...
It's all in front of us, all the pieces are there.
So you just have to put them...
Just think about them correctly.
That's my thinking.
So is there any part of HTM that talks about different brain regions
and why that structure exists?
When you say different brain regions outside of the neocortex,
or like the different old parts of them?
Well, in neocortex, certainly,
we don't explicitly state that, but it's essentially...
I kind of alluded to it earlier.
A column has some input, and it's going to model that input.
It's going to model the sensory model...
Build the sensory model model of that input.
That input can't be very large.
It has to be fairly small.
You can't have a very, very super high-dimensional input to that thing.
So what you see is that the topology in the brain
is that some part of the retina projects to a single column,
another part projects to a single column, and so on.
So if you could build a visual system with one column,
and it would be like looking through a straw,
and that would be a complete visual system,
and it would learn by moving the straw around,
and it would be like moving this little window around
and looking at stuff, and that would work.
It's pretty straightforward just to expand out
to have a whole bunch of those working at the same time.
And so I don't think we haven't modeled that, per se.
ARC focus has been on really what does the column do,
and with the belief that once you understand what the column does,
the rest of it becomes pretty easy.
It was really the tricky part to figure out what a column does.
So we're not able to scale up to that stuff.
We abandoned all of that a while ago.
We just said, let's focus on a column.
Let's focus on one column, and we just
got to nail that one column.
So all of our simulations have been very small.
I mean, small than tens of thousands of neurons,
all would be contained in a single column.
And to scale up to human brain size stuff,
A, it's not theoretically important at this point in time,
but also we don't really have the ability to do that.
But I think it'd be fairly simple to do.
OK, and on the flip side, do you have any notion of a mini column?
Yeah, we do.
I didn't talk about mini columns.
For those who don't know, a mini column is a structure.
These are physical structures.
You can see them in the neocortex.
They're somewhere between 30 and 80 microns wide.
That's really small.
There's several hundred of them in a cortical column.
Just one point to note that mini columns are only
visible in primates.
So people who study rats don't see them.
That doesn't mean they don't exist.
You just can't see them.
So the equivalent could be there,
but they just don't see them.
The network that Subitai mentioned earlier,
and he said he wasn't going to talk about it, which
is the one that sort of learned sequences and built
on this neuron model we have.
In fact, all the networks we talk about that I mentioned here,
how all this stuff works, it's built on mini columns.
And whoops, what was that?
That was my phone.
And I can tell you briefly what we think.
There's a whole bunch of parts of this.
But a mini column is essentially one
of the ways we use it, is that all the cells in the mini column
have the same basic feed forward response property.
So if I find a V1 neuron that's response to an edge,
this is known neuroscience, all those cells
have the same sort of visual response property.
But in context of real world animal moving about
and observing real things, it becomes very sparse.
And so at any point in time, only one of those cells
becomes active.
So it's a way of taking an input and sparsifying it
in context.
So you can take, if I had no context,
all the cells become active.
And I basically say I have some set of features.
In context, you say I have a unique representation
of that input.
It's the same input, but it's a very, very unique representation.
All this is in the 2016 paper.
All detailed and gory detail about how this works.
Yeah, and we're right in the moment,
I'm expanding the concept of mini columns
because I actually think, and I'm not certain of this yet,
I talked about these grid cell modules.
