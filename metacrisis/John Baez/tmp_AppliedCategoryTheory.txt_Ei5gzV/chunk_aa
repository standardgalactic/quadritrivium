Okay, so I guess we're there. So let's get started. So, well, gosh, what an influence John had on my life.
There I was a fledgling philosopher trying to interested in mathematics.
His writings in that in that got a long way, a long time ago in the 1990s, gave me the confidence to think that you could get access to the forefront of of mathematical and physical scientific knowledge through his writings.
I mean, what gosh, what a, what a joy that was to engage with his writings back at that time. Huge influence on me.
You know, a bunch of people will know that we started a blog together a while ago had a lot of conversations over over great many years.
It's a great pleasure to have him speak to us here today on on the play category theory. Thank you, John.
Well, thanks very much. Thanks for inviting me here. The influence was reciprocal. It's really exciting to think that what one is doing mathematics could actually be interesting to a philosopher so that one isn't just like fiddling around with obscure equations.
So I want to talk about applied category theory, which is the latest turn in this game.
And I'll talk more about the history of the subject and what people are trying to do than any mathematics per se.
I've given lots of talks about the mathematics and so of all the people will be referring to here.
So it's certainly easy to click on any of the links in my slides and get into the actual mathematics, but I'll try to not say as much about that as I sometimes do.
So we often have this picture of different disciplines or subject areas, talking to their neighbors and information flowing between pure math, which is some very abstract and to say the business world, which is maybe the very concrete
and in stages with each discipline talking mainly to its neighbors. So pure mathematicians talk to applied mathematicians, they give suggestions to applied mathematicians and they find out about problems from applied mathematicians
and learn techniques from applied mathematicians and similarly for each link down the chain with each discipline talking to its neighbors.
And in this model, which of course is very oversimplified and you can easily find a lot of faults in it.
In this model, we could think of category theory as the purest of pure, some super pure mathematics that only can talk to mathematicians who then relay their insights down the chain to the other or practical subjects.
I think that's what a lot of people implicitly feel about category theory or at least used to.
And so when people started talking about applied category theory, people laughed because it sounds like an oxymoron.
It just goes completely against this picture here. However, I think this picture is inaccurate.
For one thing, a very important fact is that starting maybe around 1980 or so, it became clear that computer science really cuts across this traditional flow of information.
Computer science interacts almost directly with every single piece of this chain.
Computer science has a big relation to category theory, which I'll explain, but it also has a huge relation to other aspects of pure mathematics and applied mathematics and so on down to business.
So businesses will need to keep abreast of developments in computer science and so on.
Basically, we now communicate and think with the help of these machines called computers that we have devised to help us and they change the whole game at every single step of the way.
Now, I have this crazy idea that maybe category theory actually really should be thought of in a somewhat similar way as interacting with all the different links in the chain from the pure end to the applied end rather than being tucked away at the super pure end of the spectrum.
Now, at first, this seems ridiculous or laughable. I mean, for starters, category theory is sort of nothing compared to computer science. Everybody's walking around carrying cell phones.
Nobody has even heard of categories by comparison. So category theory is an ant compared to the elephant of computer science.
However, I'm thinking about what could be not what yet is. And secondly, when you think about how computers have unified the whole chain, it's done so by means of the Internet, which is an enormous network.
And category theory is nothing if not the mathematics of networks or the science of networks. It's other things too. I shouldn't have said it quite that way. I mean, it is the science of networks, but it does many other things too.
So, so really devise good methods of getting computers to do what we want. We need a way to think about them. And I think category theory is one of the important ways to think about them.
So you may think this is ridiculous skill, because for example, if category theory was talking directly to business, you'd expect that people would be going into business doing category theory or something like that, setting up category theory businesses.
That sounds sort of silly, but in fact, it's true. So in fact, people are setting up category theory businesses. And that's part of the kind of thing I want to talk about. I want to talk about how category theory is now being used at all steps along the spectrum.
And for that reason, my talk will be less focused on the math than on the history of how category theory became applied, giving you a flavor of how it's being applied and pointing out some of the challenges that show up.
Before I dive in, I should say that this history is going to be extremely self centered. I am not really in a position to write a good or talk about a good history of category theory. So hopefully someone who eventually tries to write a history of applied category theory will listen to this talk and fold it in as one data point.
I'll talk about a lot of people, but I will also leave out a lot of people and I really apologize to all the people whose work on applied category theory I'm not mentioning.
There's just no way for me to do a fair treatment of this big subject.
Okay, so I'll start arbitrarily in 1963 when Bill LaBeer introduced a concept called functorial semantics. So it's a very general concept where you have a category that describes syntax, describes ways of writing things down.
And then you describe the process of interpreting those expressions or giving a meaning to those expressions via a functor.
So the functor will send expressions to their meanings, but a crucial aspect of this whole setup is there's not one God given functor F that does this.
You can choose various functors from the category C to various other categories G because there are different ways to assign meanings to expressions and that flexibility is very important.
And it became important in computer science.
So for example, there's a nice, there's a way to think about it where a sufficiently well behaved programming language may give a category where you think of the objects as types or data types, we've already heard about that idea.
So types X, Y, Z, etc. And then a morphism between objects like a morphism F from X to Y, we think of it as a program that accepts data of type X as input and outputs data of type Y.
And then the fact that you can compose morphisms tells you that you can hook up two programs to get a bigger program where the output of the first program becomes the input of the second and that combination is a program in itself.
So I could say there's like the relationship between the Lambda calculus, which is sort of an idealized programming language, simplified programming language, and Cartesian closed categories understood by Labbeck is an example of this paradigm of using functorial semantics for computer science.
But here I'm only so far talked about the category C. I haven't talked about the functor.
So what the functor could do, well, we could, for example, take a functor from our category to the category of sets, not each data type X to a set, and that would be the set of possible values of that data.
So like you could have a data type like real numbers and then F would map it to the actual set of real numbers.
And then each program gets mapped ideally to a function. And the key fact of a functor is that it preserves composition so that composing programs would give rise to composing the functions they compute.
And the identity program, which does nothing at all, you interpret it via this functor F, it gives you the identity function, which does nothing at all on a set.
So that's a paradigm that became important in theoretical computer science.
I wouldn't say that most computer scientists know or care about functorial semantics, but in a certain community of the more mathematical theoretical computer scientists, this idea has become quite important.
And there are certain languages like Haskell, for example, and others that really take advantage of this viewpoint.
In particular, Haskell uses a category theoretic construct called monads, which has sent many generations of young computer scientists running for help from category theorists to try to figure out what a monad is.
I don't want to explain what a monad is. It's a category theoretic construct, which, like many other constructs, become important when you start thinking about programming in this functorial semantics way.
But in the 1980s, something very different happened. Particle physicists realized that any quantum field theory specifies a category.
And now the objects are, roughly speaking, collections of particles, and the morphisms are, roughly speaking, ways for particles to interact and turn to other particles.
And in fact, Feynman drew pictures called Feynman diagrams for describing how particles interact with each other.
This was a bold move because, although it seems very intuitive here, you have a proton and an antiproton coming in from the left, and then they collide and all sorts of other particles shoot out.
In reality, particles are not little dots moving along little straight lines.
Quantum mechanics says that particles are wave-like in character. So when Feynman introduced this pictorial language, she got a lot of opposition from older quantum physicists like Heisenberg and Bohr.
And yet, it turned out Feynman was correct in doing this.
What Feynman diagrams actually are, later became clear, much later, is there are pictures of morphisms in specific categories, and each individual quantum field theory gives a category, and then that determines what allowed Feynman diagrams you can write.
So if you have a theory that doesn't have quarks in it, you're not allowed to write this Q-line for quark.
And then, what do you do with these pictures? Well, your goal in particle physics is to compute a bunch of numbers, like what's the probability that if I smack two particles into each other that some other particle sheets out?
So for calculating numbers, we need to interpret our Feynman diagram. That is in the functorial semantics attitude, we need to functor from our category to some other category which assigns meaning to the Feynman diagrams.
In this category, we could take the category of Hilbert spaces, a widely loved mathematical structure in quantum mechanics, and so then this functor will turn any Feynman diagram into a morphism in the category of Hilbert spaces, and that's called a linear operator between Hilbert spaces.
And so you can look at what physicists are doing with Feynman diagrams as basically using them as a syntax, which they then apply the semantics to, to then grind out numbers.
Now, Feynman probably would have laughed at this whole business because he knew what he was doing. He didn't need any category theorists to tell him what he was doing.
But by the 1980s, particle physics had become elaborate enough and deeply connected with enough pure mathematics that this attitude of thinking of quantum field theory in terms of functorial semantics became a really profitable attitude.
You could do things with category theory that particle physicists were struggling to do without category theory, and so it helped.
And this led to a whole line of work trying to relate category theory to quantum mechanics.
And in 2004, Samson Abramsky and Bob Kricker wrote a very influential paper showing that a certain quantum process that goes by the name quantum teleportation and also other processes could be understood using category theory and using diagrams that resemble Feynman diagrams.
But here, the edges in these diagrams, which now I guess we're reading from top to bottom rather than across, the edges are not describing elementary particles, but just states of an arbitrary quantum system.
So it could be an electron or it could be some larger system.
And I don't want to try to explain this in detail, but there are, but these are pictures of morphisms in some category.
And they're equal to each other.
And these morphisms describe some process where one participant who always is called Alice in cryptography communicates a message to another participant is called Bob.
And in quantum teleportation, you have the superficial appearance that you're communicating faster than light.
But in fact, what's really going on is that you've laid the ground for the communication by some classical process that has already transferred some information, and then the rest of the information is transferred on the basis of that.
In any event, quantum teleportation was a sort of magical, wonderful thing that you can do in quantum mechanics.
And this gave a kind of category theory, theoretic account for how it's working.
And that was quite exciting to people because it took the quantum applications of category theory out of the realm of elementary particle physics and into a new realm that was developing,
which is quantum information theory or quantum computation, which has the potential for being a quite practical thing.
And indeed, already quantum cryptography is used.
So, on the basis of this and other work, and also on the basis, I should say, of a huge amount of charisma, Bob Kirker and Samson Abramsky built a huge group of people at Oxford, sometimes called the quantum group,
working on category theory, the foundations of quantum physics and quantum computation.
One interesting thing about this enormous group here is that it's in the computer science department, so not a mathematics department, not even a physics department, but a computer science department.
Here's Samson Abramsky here, and here's Bob Kirker looking sort of disreputable over on the edge. That's completely intentional, he's like that.
And here are many, many people, including I see Jules Hedges, who has mentioned in the previous talk, he works on categorical cybernetics.
So, Kirker and co-authors developed this diagrammatic method for explaining quantum physics, and they eventually decided it would be very good to write a textbook on this.
So, here's one of the two textbooks that Bob Kirker helped write on pictorial methods of understanding quantum physics.
And the one interesting thing about this book, so first of all, I recommend this book if you're interested in learning category theory from an orthodox and sort of easier approach than the conventional one, because it's very pictorial.
But I mentioned it because part of what he wound up doing is hiding the category theory in the sense that you don't run around saying category and functor and all sorts of other jargon like that a lot.
Instead, you draw pictures of processes, and you explain these pictures in a hands-on way, and you explain how you can stick one picture onto the other, which is composing morphisms, but you don't say the word composing morphisms necessarily, because you don't need to.
And this is one of a generation, I should say, a new generation of category theory textbooks that are part of the applied category theory movement.
So, if a category theory is going to reach directly to many different communities and different stages of the knowledge chain that I drew at the top of the talk,
it means that you can't force people to first become mathematicians before they then start doing things with category theory.
The traditional approach to category theory treats category theories like some finishing school that you engage in after you've already learned abstract algebra and this and that and algebraic topology and so on.
That's just too onerous a path to category theory if you're trying to get computer scientists, much less business people, to get some inkling of category theory.
And it's not really necessary to take that elaborate route because category theory is something so fundamental that it can be explained more directly.
I especially recommend Eugenia Chang's book, The Joy of Abstraction, which is a really wonderful introduction to category theory for people who have not had much prior exposure to mathematics at all.
And it goes all the way up to the UNEDA embedding theorem.
So in 2021, Perke actually left Oxford University and he became the chief scientist of a company called Quantinium, which uses category theory for quantum computing and also natural language processing.
This is a picture of him on the Quantinium webpage.
As you can see, he's trying quite hard not to fall into the stereotypical academic image here.
He's a great guy, by the way, you shouldn't mind me teasing him like this.
I think though that it is important that having people with personalities who are willing to break out of the stereotypical mold of a math professor is important in this whole category theory application movement.
I should say that there's a lot of interaction between quantum computing ideas and natural language processing ideas, which I won't really have time to get into.
To some extent, they're invisible in the last talk, but if you want a real emphasis on the natural language processing aspect, the works of Tide and Ney Bradley are very good.
She's another newer explainer of category theory.
It's a non-category theorist and she is also working in a company that uses quantum methods and categorical methods for natural language processing.
But punctorial semantics is extremely general, so it's not just applicable to the topics that I've already mentioned.
In lots of areas of science and engineering, people use a syntax where you draw diagrams and then a semantics where you convert those diagrams into math, which is very often the systems of differential equations.
You're describing how things change in time, you're describing dynamical systems, so you use differential equations.
But the interesting part is that hooking up diagrams to each other is actually composing morphisms in a category, and the fact that you're working with punctorial semantics says that when you compose those morphisms in the syntax category,
your functor will map it, the resulting composite, to the composite of the two systems of differential equations that each picture separately is mapped to.
So in other words, there's another category working around here where the morphisms are actually systems of differential equations.
Systems of differential equations with some specified inputs and outputs to surface as the source and target of your morphism.
Here are some different pictures. You've seen a bunch of these types of pictures, I hope. So electrical circuit diagrams are one of the earliest and very widely used.
This thing here is called a petri net, and it's a petri net of a particular model for the AIDS virus and its interaction with blood cells, infection of white blood cells.
This here is a very small diagram in the subject of control theory, where you have some process in an industrial plant that you're trying to keep under control, and so you take feedback, you read off information from that process,
and you use it to feedback effect the process itself to keep it on track.
The very simplest example here would be like a thermostat, but in industrial chemistry, they become much more elaborate.
And so there's a whole diagrammatic language of control theory that you can read about in textbooks on that subject.
And this is a little diagram of some molecules in molecular biology, molecular biology or biochemistry.
They have so many different diagram languages that in fact they've set up a committee to standardize the diagram languages so that people reading different biochemistry papers can look at the diagrams
and not have to be explained each time what the diagrams mean.
But it's sufficiently broke that the committee wound up choosing three different diagram languages because they need multiple languages to describe different things they're interested in.
So these are very widespread, and the people in these different subjects don't think of what they're doing here as category theory.
They don't think of it as mathematics, they think of it as this is the stuff we draw to understand the differential equations that you can convert these pictures into.
The equations of the math, but these pictures are our own private little trick for understanding what's going on.
But I claim that these pictures are actually also mathematics. These diagrams are morphisms in various categories, which are using functorial semantics to convert to differential equations.
So I decided that had to be true and I wanted to work out the details around 2012.
So I asked Brendan Fawn, who eventually became my grad student, to tackle what I thought would be a very good first example, namely electrical circuits, because everybody knows about electrical circuits and the mathematics of them is in some sense very well understood.
Linear electrical circuits, for example, made out of just resistors or maybe capacitors and inductors as well.
So I asked him to create and study a category having open electrical circuits as morphisms. So these are electrical circuits which have certain things hanging out, which serve as inputs and outputs.
I think at the last start they were called cilia. So these are just these dots here.
It's not forever to do it, so it seemed, but it turned out that what he was doing was not just answering the question that I asked, but in fact answering a much more general question.
He invented a general theory, which he called decorated co-spans, for handling this problem, but also all the other problems that I described.
So essentially all the other kinds of diagram languages I showed can be understood using the theory of decorated co-spans.
Although the details have to be individually worked out in each case, this decorated co-span formalism is a recipe for getting categories of this general sort.
And so naturally it did take him a while to do a good job of it, and he finished this thesis on it in 2016.
I won't attempt to explain decorated co-spans any more than I just have. I've given lots of talks on decorated co-spans, and you can see on YouTube me giving talks about them if you're interested.
I just want to mention one little thing is that, well, first of all, here's Brendan Fong, and here's another student of mine, Blake Pollard, who together with Brendan applied this theory of decorated co-spans to the second example that we tackled, which was Markov processes.
So Blake did a lot of work on Markov processes.
And another thing I want to mention is that Brendan went to get his PhD at Oxford.
So he was in the enormous group that I mentioned of Kirke and Abramsky, and I believe Kirke was his de facto, it was his de jure advisor.
But in fact, I was the de facto advisor talking to Brendan about this problem.
And so nonetheless, it's really important that this large body of people at Oxford is spreading across the world, doing many things, and Brendan is one of them.
So after doing his PhD, Brendan went to MIT in 2016 to work as a postdoc with David Spivak.
So Spivak is another very important figure in applied category theory.
So among other things, he had helped to create a language for databases called Functorial Query Language, which has now become the basis of our company called Conexus AI with Ryan Wisnefsky as a head of our company, but David Spivak also involved.
This approach to databases really relies heavily on functorial semantics.
So the idea is that a database schema is an object in some category, and that by a functor, you can map it to a sort of populated or inhabited database schema where your table is actually filled with entries.
You can imagine like taking a spreadsheet and actually typing in the entries.
That's one possible interpretation of the abstract database that has not yet been interpreted with specific people's names and numbers.
And in 2014, David wrote a textbook on this idea and others called Category Theory for the Sciences.
So I also highly recommend this as yet another of this new generation of category theory textbooks is trying to reach out beyond the traditional confines of the category theory community of highly pure mathematicians toward other audiences.
And in 2018, Brendan Fong and David Spivak wrote another textbook explicitly on applied category theory, which is fondly called Seven Sketches, but its actual title is Here is Lager, emphasizing the principle of compositionality in many guises.
And they taught a course on it, which you can see on YouTube if you click on this link in my slides and the textbook is also available for free on the archive, as well as for purchase.
And I'm mentioning this stuff about things being available online for free, partially because when you're trying to reach out of the pure math realm into the rest of the world and teach the rest of the world category theory, you quickly realize that making things easily available for free is going to speed up the process a lot.
And so I think there's a general commitment so far on the part of a lot of applied category theorists to make things open source and easy to get at.
Now, in 2018, my graduate student Kenny Corsair there, and I came up with structured cospans, which is a simpler alternative to decorated cospans, turns out to be not quite as flexible as decorated cospans but in many cases, either formalism works and in those cases I'd say structured cospans are simpler.
In 2020, Christina Vassilicopoulou, who's standing to the left there, helped us understand how decorated and structured cospans are related.
For a while I thought structured cospans would replace decorated cospans, but it turns out we now see that they can't cover quite as much territory and that we really need decorated cospans in some cases.
So the full story is somewhat elaborate right now, and I've given talks about that, but it's actually very pretty.
So by now, structured and decorated cospans have been used to study open systems of many kinds.
So by open systems, I mean systems that have loose ends that are meaning systems that are morphisms in a category that you can stick together or compose to get bigger systems.
And open graphs are just simply a graph with loose ends, it's a very combinatorial structure.
That's a very simple example.
Open Petri Nets is a more useful example.
Here's a picture of an open Petri Net where you have things describing what they're called.
They're called places, they can represent populations of different kinds of chemicals or organisms, and then you have these blue boxes called transitions, which describe how things can come out of various places and turn into things of other kinds.
If you attach numbers to these transitions, describing the rate at which the transition tends to occur, you get something called an open Petri Net with rates,
or maybe an open chemical reaction network with rates.
And my student Blake Pollard worked on those.
Open electrical circuits I've mentioned, open Markov processes I've mentioned, open dynamical systems, those are the systems of differential equations interpreted as morphisms in some category.
So there are papers on all of these, and if you click on these brown things, you'll get to those papers.
So at a certain point, I thought that maybe someday all of this would lead to some unified language of the sciences.
And my ambition, which seems very limited in retrospect, was that by interacting with scientists, maybe eventually this unified language would help scientists in one discipline talk to scientists
in another discipline and share tricks of various sorts.
But then something quite different happened, which is much more exciting in my mind.
Namely, in 2019, James Fairbanks, who's an engineer, and Evan Patterson, who is a statistics PhD, began developing a computer system called Algebraic Julia.
It's a system for high performance scientific computing built on the language called Julia, which is designed for crunching numbers really fast.
But Algebraic Julia lets you program and using constructs from category theory.
So in Algebraic Julia, you can talk about categories, bunkers, and all these other things that category theorists like to talk about and write your programs using those concepts.
So it's a very, very high level system, but coupled to the raw computational power of Algebraic Julia.
So there are trying to revolutionize scientific computing in this way.
And in 2020, Evan implemented structured co-spans in Algebraic Julia.
And then using this system for the example of Open Petri Nets, he and Mika Halter reconstructed some of a COVID-19 model, which was currently being used by the UK government.
So the UK government had a very elaborate model of COVID-19 with many populations of different people with different conditions, possibly living in different locations, etc.
And then, I guess, sorry, the populations of these orange boxes and able to turn into other kinds of people via these transitions in blue.
The whole model is much larger than this. This is just a tiny fraction of it.
And what they wanted to demonstrate was that you could build the whole model by building smaller models and pieces and then subsequently sticking together those pieces, which is in fact something that had not been done before.
Models were sort of had to be constructed in whole cloth by essentially by one person keeping track of the whole thing.
But this was a new approach, compositional epidemiology.
And so it attracted the attention of some epidemiologists, especially since COVID-19 was a very live issue at the time.
Then, in a different direction, in 2021, Brendan Fong and David Spivak, who had been, remember, over at MIT, decided to quit traditional academia and start their own institute,
called the Topos Institute in downtown Berkeley.
