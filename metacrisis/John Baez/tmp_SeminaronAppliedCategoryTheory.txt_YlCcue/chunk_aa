Well, let's get going. So welcome everyone. Nice to see so many people. Well, it's online.
So this is an afternoon devoted to applied category theory. A lot of you in the audience
would have heard me speak about category theory before. What is applied category theory is
going to be the question. Okay, so I'm interested in getting philosophers on board. I fell
in love with category theory 30 years ago. When you fall in love with something, you
kind of want everybody to see the beauty of the thing you fall in love with. It's been
a bit of an uphill battle, perhaps, to get philosophers interested. So when Yale University
announced officially replacing the grad program logic requirement with a broader formal methods
requirement that they can go off and study logic probability stats game theory, I tweeted back,
teach them category theory. Why not? You can have all of those at the same time. If you just give
them a basic basic grounding in category theory, we can do all of the above with just a few little
add-ons. So, yeah, I mean, philosophers typically through their training almost inevitably will
encounter propositional logic. And some first order logic depends where you are, perhaps a
modal logic too, because they'll be dealing with metaphysics and I want to know about the issues
to do with this esteem possibility and so on. If some people will be exposed to second order
logic, perhaps some probability theory, decision theory and so on. Unlikely, perhaps, I mean,
this isn't a scientific survey, I guess, I hope people will pop up and say, oh, my department,
we do this, this, this. It may be, but I mean, I think in general, it's probably fair to say that
something like type theory would be unlikely to be studied in a philosophical training. And
category theory really very, very unlikely. Okay, now, of course, you can be exposed to these
things in different ways. And I'm kind of more interested in bringing about quite a shift in
attitude, shall we say, because if you approach things in a certain kind of way, if you approach
it from the top down, you could be exposed to category theory just by a well, you know,
I've learned some first order logic and now I can express category theory as some sort of first
order theory, you know, always to do with a collection of things, a collection of objects,
a collection of connections, arrows between these objects, and satisfies this and this and this
property. So you could see it as just a sort of specific theory within a kind of existing
formalism. But if you do that, you don't really kind of get at the heart, the heuristic heart of
the matter, you don't get the mindset that comes from the sort of correct destruction into
category theory. And that's more what I'm interested in. So we talked about, I mean,
there's a slight controversial, the lack of this language, we'll see what it's come to mean
this applied category theory later. But you know, there've been applications of category
theory right from the beginning, very beginning. So it gets going in the 40s, within mathematics
itself. There's this great effort to systematize sorts of situations when you've got a kind of
kind of entity, maybe, maybe like a category of spaces or collection of spaces. And you want to
know things about the spaces. And they're very hard to deal with in themselves. But if only you
could transfer them somewhere more amenable to you, maybe into some sort of some collection of
algebraic objects, you could resolve questions back in the geometric side, the spatial side,
by this transfer over to something algebraic. Okay, so you're finding these sort of patterns,
these common patterns appearing in different areas of mathematics. From the 40s onwards,
this becomes a popular approach through the 60s. I mean, these are, yeah, these approximate dates,
you'll find exceptions all over. But you start to get people thinking, you know, this category
theory is pretty good. Maybe I didn't need to see it in terms of, oh, it's just a kind of
a category that's sort of set with some properties. Maybe I can make it its own foundations.
I'm recently departed, William Levine in the 60s, who suggests exactly that the category theory
could provide its own foundations. And later on in the 60s, he's even so absolutely fundamental
construction. Adjoint adjunctions, adjoint punctures. So this is very much when you've got a
situation and you've got to sort of transfer in one direction from one space to another space.
And it might not be the case that you can just reverse that process and head yourself back
in the second place back to the first place. But then you could do something as good as you can
as the sort of best approximation to kind of reversing the process. These things are adjunctions.
And Levine discovers, well, they were there, even in your first order logic, they were there.
Right. Right. And you're very, very fundamental. Those quantifiers you dealt with, those universal
and existential quantifiers themselves are part of that process of this reversal.
Okay. So category theory is sort of seeping right into the roots of the very basic formalisms.
Okay. Then computer science gets going. That date's fair enough. I mean, maybe it's even earlier.
We've got computer scientists here who can tell us perhaps about that.
We'll kind of get a sense, perhaps a little bit of a sense of why they got interested in this.
And then physics perhaps from the 80s.
So we're going to have John Byers when he wakes up. He's in California. So I guess,
you know, we had to push his talk back to five to give him time to wake up.
So what is California? It's pretty early. So I think he's not with us at the moment.
So he wrote a paper with a student of his, Mike Stain, 2009. It's called, it's a Rosetta Stone.
Physics, topology, logic and computation. Just to see that, can you, perhaps the people
want to hear a bit more? You can, so category theory has been used to understand
ideas of physics, topology, logic and computation. So it's always about, you have a kind of entity
of a kind, and then you've got mappings between these entities. That's the thing that interests you.
So physics, you're interested in Hilbert space, you're doing quantum mechanics,
you're interested in Hilbert spaces, and you're interested in operators between Hilbert spaces.
Okay. If you're interested in topology, you might be interested in a space that has a boundary,
an input boundary and an output boundary, and you're interested in the manifold that
joins the input to the output. You're doing with logic, you're interested in having a proposition
and an inference through another proposition. With computation, you have data types, data inputs,
of various kinds, people put in their data and it gets processed, and after you come through the
other end into the output. Okay. And these parallels go on. I mean, so they'll be famously with,
when you put two quantum systems together, they're not just a straightforward product of
their parts, you can just separate them off again, because they're entanglement ideas.
But still, all the same, you put two quantum systems together and you want the space of
these two quantum systems, this tensor product. I mean, topology, you're going to form the
disjoint union, you're going to put your kind of input spaces together, next to each other,
and so on. In logic, it's exactly the same as forming conjunctions, X and Y, and in computation,
the product of data types, and so on and so forth. So you're getting these very similar ideas that
just being manifested right across the board. Okay, so that we got this fun expression at some
point. They've got a bit controversial. Somebody wanted to call it computational trinitarianism,
and some people didn't like the kind of spooky theological tone to it, so sometimes it gets
designated as computational trilogy. Okay, but this idea that these things are just part and
parcel, so it's not just that there's an analogy going on, it's that they really are three faces of
the same thing. Okay, so computation spaces and logic, they're just three sides of the same thing.
With the thought that therefore if you make an advance in any one of these areas, it ought to
manifest itself in one of the other other areas. It's really that tight if you see it from this
point of view. Okay, now we're going to still have to head off and start a different direction.
Very good things are still going on. I devoted quite a lot of my life to this sort of thing.
Okay, so book 2020, modal homotopy type theory, suggesting that it would be a very good thing if
philosophers got on board with this language. Yeah, all sorts of ways I think philosophers
could use these kind of ideas. I mean, people know, there's people work on category mistakes,
people with Wiles ideas have been updated. Everything the computer scientist wants to do
by controlling input data to be of the right type. And this is so close to the kind of
idea of categories that the Wiles were in back in the 30s and 40s and stuff.
Yeah, I'm going to be giving another talk in a couple of weeks on, I mean, it really lends itself
the kind of brand name in Robert Branden's approach to Frenchism and expressiveism.
I think it could be beautifully realized in this program, but that's not for today.
Yeah, another recent bit of work I did, which was really trying to sort of chase up the passage,
the path that takes us right up to the kind of cutting edge of category theory,
type theory meets physics. There's something expressed in this paper here, which is kind of
pointing to this work, just to point out, so this kind of work goes on, this really,
really kind of cutting edge modal type theory meets physics, right up in the highest, highest
heights of, there is a quantum gravity and whether you think that's going to work or not.
But it's coming much, much closer down to earth now, some of the work they're doing out there,
which is looking at quantum computation, sorry, quantum computation is down to earth.
But it's a closer to earth than quantum gravity anyway, using this linear
homotopy type theory, the linear or the linear logic. But again, this is not today's work,
because we're going somewhere slightly different. So yet a further set of applications starts to
take place, let's say from the 2010s, although maybe again you can find precursors. And what's
that looking at? Okay, well these are people scattered through the country, I'm sorry, through
the world, but pretty well represented in the UK. But they're looking at things like causality,
probabilistic reasoning, statistics, learning theory, deep neural networks, dynamical systems,
information theory, database theory, natural language processing, cognition, consciousness,
systems, biology, genomics, epidemiology, chemical reaction networks, neuroscience, complex networks,
game theory, robotics, quantum computing, and the list goes on. Okay, so we're away now from the
very high-end physics applications, and we're dealing with some sort of things that of course
philosophers should be very interested in. Okay, and in a sense it shouldn't be such a surprise,
because you're dealing with both, if you notice back there that list, they're dealing both with
physical processes, the various kinds of natural processes out there in the world, and then they're
also dealing with inferential processes. Okay, so kind of interestingly, the category theory
is good at dealing with both, because they're both to do with movement of some kind, from starting
place to a finishing place. If you want to go all Hegelian on us, you're kind of unifying that
subjective and objective logic. People tend not to use Hegel's language these days.
And yeah, I mean something all over the place, these string diagrams, if you
just click anywhere, any sort of applied category theory, you just get these endless
beautiful diagrams, these 2D diagrams, lots of wiring diagrams going on, the various kinds,
wiring things with nodes, right across the board. And in fact, this is kind of one of the ways that
well, there's certainly, I think, John Biles will tell us about it at five o'clock,
but he was just fascinated by the way you found these very similar diagrams across engineering,
and chemistry, and biology, and so on and so forth. And there had to be something in common
that unified it, and he thought category theory would be the way to find a common essence to
why these diagrams are all appearing across these different domains.
Okay, so you're going to find these all over the shop. Okay, a bit of a version of this
compositionality that that links you off, there's a journal now called compositionality,
which is a journal devoted to this applied category theory. And why it's so appropriate is,
well, there's various things you want to do, some very basic moves is, I mean,
we actually already saw it in that Rosetta stone thing, the idea that if you have one system
and some process of some kind going on that takes you from a beginning to an end,
we can put together two systems in parallel. Okay, we can compose systems in parallel,
and we have to, again, diagrammatically, it's all very obvious why you should do that, you're just
sort of joining two diagrams, and you put it next to each other. And you don't need very much
compatibility between the systems to do this. If, on the other hand, you want to put them
in series, if you want to make one process feed into the second process, you're going to have
to make sure that the output of the first one matches the input of the second one. Okay,
or they're not going to join together. Very, very category theoretic, it wants its inputs
to match its outputs. Yeah, or there could be something a bit more subtle going on,
there could be sort of several inputs, several outputs, and maybe only some of the outputs being
matched by the new input to some other new device, and you could just plug in those wires that match
into the new system. Yeah, or sometimes you can take a wire coming out and bend it around,
that could just move you might want to make as well. Sometimes also, you've got a system
with a networking system, and you've got a little chunk of it, and you want to replace,
you want to take a little of the box inside that system and plug in something more complicated
with the right inputs and outputs. So you can kind of compose by plugging one system inside another.
Okay, so this is, I'm sure we're going to be hearing a lot about this over the next two hours
and a bit. So Toby Smyth is talking first. I'll give John Byer a bit more of an introduction
when it's that time for him. So I was intrigued, I was very attracted to Toby's work,
looking around some of the papers he's made available, and this is his D-Phil thesis,
so that's what I just last year, I guess it was in 1922,
mathematical foundations for a compositional count of the Bayesian brain.
We'll be hearing about that today. So primary motivation in writing this thesis is to lay the
groundwork for well-typed cognitive science and computational neuroscience. So this is pretty
high, pretty interesting stuff. This isn't just simple physical processes just going around
in their simple way. It's tapping into, I feel like I've been looking into a bit of late,
this world of predictive processing, active inference, you know, free energy,
if we head to the Carl Friston, his big name in the field. There's some interesting stuff going
on there, kind of hierarchical Bayesian models involved in the way that we deal with the world.
We make all these predictions about the way that we, you know, most of the world is fantasized
by us, it's just slightly constrained by our influence in some sense. So there's all sorts
of ways, this very strong top-down component to our perception. Interesting stuff. So curious
stuff, I find myself, it would almost plunk the gap. So I've spent a lot of my life, as I'd say,
reaching, had a great theory and type theory, good spell being interested in machine learning,
Bayesianism. I had a former life that kind of pops up from time occasionally, which was an
early interest in psychoanalysis and then co-wrote a book on psychosomatic medicine.
So sort of extraordinarily, there could even be this kind of bridge that takes place between
those two. So there are plenty of people that are, there's a lot of psychotherapists now talking
to this active inference approach to the mind. You know, the brains are kind of optimizers,
the trouble is that very often they get kind of caught in some optimal optimizations. They get
locked in in a certain kind of way. And the heavy top-down processing sort of makes it very difficult
to sort of shift the system and gets kind of locked in in a certain way. I mean, for example,
delusions, for example, cases where there's such a sort of strong top-downness to the
perceptual apparatus that the input from the world does nothing to constrain it or not enough to
constrain from the delusions. That's a very extreme case. But all sorts of psychiatric
problems may be seen in this light.
Yeah, so gosh, if Toby can help us sort of plug the gap there,
kind of find if I could, if I could bridge the gap of my interest. So I'm certainly
very much looking forward to hear what he's going to say today.
I noticed this rather longer bit is taken from his thesis, this well-typed cognitive science
and computational neuroscience. And it's got, yeah, they say, so types, types of what render
these concepts precise, they allow categorical models to be cleanly compositional. So it's again,
it's very much things I mean, sort of plugging together if the interface is right. So I think
this is something that maybe from what I've seen of the active inference literature,
well, I've been true to see if he can make them something more category-theoretically
active inference. Really exciting project. Okay.
That's, yeah, I think that brings us to the end of the introduction because we're
keeping rigidly on time. And here we go. It's 10 to four. So let me close down my thing.
Can you share now, Toby?
