observation and it gives us back a number and in particular it could give us back this relative
entropy and one thing that is known about the relative entropy and in fact is quite easy to check
is that it also satisfies the chain rule the chain rule has this form but I you know don't
need to go into details about what it mean what what it except to say that effectively the composition
of the relative entropy for one lens if we think of this part and then this part
there's two lenses this we might have a relative entropy which lands in the postive reels for
here and a relative entropy up here another one up here this chain rule says that the composite
if you apply this kind of lens composition rule to it
that the composite relative entropy or the relative entropy of this composite lens
is equal to the kind of lens sum of the relative entropies of the kind of independent lenses
and so that's that's this locality that I was referring to
so this is a nice equality
again this is only a particular example of a loss function and because if you notice here
sorry I'll go back a slide just momentarily you notice here that the relative entropy depends
on this exact inversion well that means in order to be able to compute it you need to know
what that exact inversion is and actually often the reason we want to do a proximate
inference is because computing the exact inversions is quite hard and so yeah we don't want to try
to compute that thing and so we need to do something else and so these other loss functions are
available and the relative entry is one example but we could we could sort of pair a lens with
another example of a loss function and I've given the composition rule for lenses and I've sketched
the composition rule for the loss functions and so these things form these kind of pairings of
lenses with loss functions also form a category and I call this category the category of statistical
games and the reason I think of it as a kind of game is twofold the first is that it you know shares
a lot of structure with categories of economic games as I've indicated already but it also I you
know it also captures something that's quite nice you know to think about the use about these
processes which is that you know the way we improve our inference is by playing this game of you know
how can I do my inference better so that's this statistical game that you play that they say
these neural circuits play so what we've done here is we've attached loss functions to lenses
and so just as we had a vibration by attaching the the inversions to the channels themselves
we've done this attaching thing again so we've got another vibration and so we could ask okay so
what are the sections of this vibration so what are the ways of assigning in a kind of nice compositional
way to each lens a loss function there are various examples so one of them as I've said is the
relative entropy that's particularly nice because it makes this thing an equality
but there are lots of other examples that people use in applications because computing
relative entropy is difficult so we've got things which are like the free energy which
is a bound on the relative entropy and we've got things which is we've got something which
is slightly different we've got the maximum likelihood which is a way of saying okay well
how do I improve my predictions if I don't care so much about the actual the inferences that come
out of those the free energy I should note is basically the sum in fact it's defined as the sum
of the the relative entropy and maximum likelihood and it's nice that if you make that sum not only
do you get something that's a bit easier to compute but you also find a loss function which
kind of encourages you both to improve your predictions that's the maximum likelihood thing
as well as improve your inferences in machine learning a process which does both the improvement
of predictions and of inferences is called an auto encoder if you've heard that word
and then in neuroscience often it's necessary to make further approximations to get to something
that seems to be like or possible for the brain to compute and so one such approximation is known
as the Laplace approximation and if you apply that to the free energy you get another loss model
that is as I say lacks in the sense that there's some other term here to make this equation hold
so these things all form loss models possibly lacked loss models
and that means that they are nice kind of local compositional ways of attaching
um loss functions to these Bayesian lenses and indeed this Laplacian free energy loss model
is the kind of family of loss functions which underlies uh say the most prominent models of
predictive coding so we've started with these mark of kernels or channels as I call them
we've attached inversions to them first to give Bayesian lenses and then we've attached loss
functions to those lenses to give statistical games but there's not much freedom in that process
to actually improve the loss functions because once you've fixed the lens that's it the only thing
you can change is the inputs either the kind of belief the prior belief you start with or the
input you get from the world what if to improve the loss function you also need to change the lens
itself so we can use the same kind of idea that gave us state dependent channels here
and parameterize the the Bayesian lenses and the loss functions to give um parameterized lenses
and statistical games and in machine learning in particular it's updating these parameters is
what happens during you know the training of models and in models of neural circuits um it's
we can think of the sort of synaptic weights on the neurons as the parameters and parameterizing
a structure is something that is kind of um quite well well known in category theory and
particularly in categorical cybernetics um and the way I like to think of it is as a kind of choice
of process so you get something which takes in a theta and gives you a morphism and you can compose
those morphisms themselves and then learning amounts to kind of improving that choice process
so you know this is just a particular it's a general morphism in the category C but we can
make this category the category of statistical games and then we have a statistical game which
depends on some parameter and then we can optimize the loss functions which are of course part of
the morphisms of these games with respect to those parameters and we can do that you know with respect
to each parameter on each component in this kind of local way as neural circuits seem to do
and exactly this is how predictive coding models are obtained so as I said we've we've paired
predictive channels with state dependent inversions um these exact inversions constitute a section
and other other sections other lenses represent approximate inversions we can pair the lenses
with loss functions in the same kind of way to give statistical games and this formalizes the
chain rule of the relative entropy the free energy is another example of one of these loss models
and then we can make space for learning by introducing parameters I'm aware I don't have
much time left and so I won't spend an awful lot of time on dynamics I just want to say that the
same kind of idea of filling in boxes so earlier I drew a box and I added a parameter into it
we can use that to give a notion of kind of compositional dynamical system and I think
John's going to talk more about this later possibly I mean a lot of what John has done is about
dynamical systems and so what we can do is say okay well we've got a category that represents the
interfaces of our dynamical systems and then we can use the morphisms of that category to
represent how those systems are kind of wired together and this this this category of interfaces
and wiring is something that I'm going to call int and then on each interface so this is the
interface which has inputs x and inputs y we have a category of dynamical systems which
take in interfaces x and y and so here we can fill in one system here we can fill in another system
and you can see that this is the same again the same pattern that we saw earlier of an indexed
category and so here the re-indexing is the rewiring of systems and so what we can do is
apply this wiring to the systems themselves to get a sort of bigger system on this composite
you know on this on this out for this outer box a kind of composite system
then we can define dynamical systems which emit the data of Bayesian lenses
I call these these systems cilia because they're like the ciliary muscle of an eye they control
the lens I won't go into details about the structure I just wanted to write it down for
reference but a cilia the cilia have the same type as the lenses but they're now sort of
dynamical lenses and so a cilium of this type that goes from xa to yb it has a state space
it has a forward's output channel that's parameterized by the state space
backwards inversion that's also parameterized by the state space and then an update function or an
update map which is like a stochastic dynamical system which takes in a state space an observation
and a prior belief and gives a new element of the state space and so that's like the
the updated parameters that we used for learning and these things compose by
composing the lenses together and by forming like the the sort of product of the of the
parameter spaces so you have a parameter on each on each bit of the the composite system
and this so this story it starts to give us a sort of general recipe for predictive coding
systems which are you know we could think of as like local approximate inference systems
you know we have parameterized kernels we form lenses then we make statistical games the first
is the thing I call an inference system and the second is a loss model and then we've gone from
a parameterized statistical game into this dynamical category by say doing optimization
as David mentioned at the beginning on the loss functions and so a process that starts
in this category of stochastic maps and ends in dynamical systems that do inversion is something
I like to call an approximate inference doctrine it tells you a way to do approximate inference for
each channel in your original category so I will end briefly I just want to say
finally that this is all about approximate inference effectively perception we can extend
this to active systems by saying that the the agent say is trying to predict not only
um what it perceives but also what it should do effectively predict everything on its on its
interface the inputs as well as the outputs in the literature in neuroscience and related areas
this interface is sometimes known as its markoff blanket and so we can also package up systems
that do this kind of prediction into a category or if we call the interface p we get a whole category
agent p of agents with that interface to do this kind of prediction and indeed we can rewire these
things according to wiring of the kind I mentioned earlier so you could think of that as like if you
get in the car like the your your sort of interface changes because you you know you're you're now
contained within the car but the car itself has some intelligent behavior you could think of a
corporation which again is made up of lots of agents but it itself has this yeah legal personhood
and so at this point we start to consider how agents themselves compose
and this kind of gets to some subtleties which are kind of more philosophical questions
in particular um that agents yeah they need to predict not only how the environment causes
their sense data but they also need to predict not only their sense data itself but also how the
environment causes their sense data and that's something a bit like theory of mind and this
is something that's necessary to make this structure compositional um and then once we
have this you might think okay well two different agents may disagree about how they're wired together
and then we need we need a way of sort of coming to overcoming that that sort of disagreement
this is really a sign that these Bayesian models are kind of inherently subjective
and there are various ways we can deal with that in mathematics there's a lot of stuff a lot of
work done in cohomology to measure disagreements of various kinds and we can use diffusion to sort
of smooth out these disagreements or we can just have a higher level agent which imposes
resolution to the disagreement and because of the compositionality of all of this we can
do this or do each make each of these choices in a kind of nicely modular way
as I say the choice depends on the situation at hand and so finally this this kind of
points to the kind of broad ambition of what's known as the free energy principle which as I
said at the beginning asserts that kind of all adaptive systems um at least that maintain their
interface can be understood as performing approximate Bayesian inference and at least I
don't believe that this claim although it's been stated and there's lots of evidence has been supplied
to substantiated I don't think it's been sort of conclusively established and I think using
categorical tools and this formalism of compositional active inference is a nice framework in which
it might be possible to do and so what I've talked about is a mapping that goes from agents
as say statistical models to dynamical systems and the free energy principle claims that there's
a mapping in the other direction which goes from sort of dynamical systems in say of a sort of
physical kind to um agents or statistical models in a world that kind of has a more
sort of biological flavor and we can sort of think of this as a kind of mind-body dualism
and in particular one way that we might be able to formalize this claim is as an adjunction which
is something again I think David mentioned at the beginning um thank you I know that was quite
fast but I wanted to cover a lot of ground to say how how there's quite a lot of you know
great stuff to be you know found by using categorical methods for complex systems like the brain
great thanks so much for that
yeah philosophy talks they sort of always leave a very long time to each other for the audience to
sort of slash it the speakers arguments but um obviously we're not we're not in that domain here
but perhaps if we have one one or two questions which which actually I did I did there was a thought
because we've got somebody here who works on explainable AI PhD student and what do you do so
so say you've trained you've trained a neural net half and you've got these sort of different
different levels I mean if each level is to be seen as a Bayesian lens of some kind
I mean how do I get at what is what is the type that is the output of one layer and the input to
the next like how can I get to understand what it means it sounds like you've already got the type
articulated doesn't it if you're if you're composing these yes so that's I think
that gets to a point that the category theory is kind of more about composing systems and
decomposing them so I'm assuming yes that you started with um two lenses that represent say
your models of small parts of the system and you're trying to use that to build up a bigger system
but yes if you have a kind of big complicated neural network there might be various ways of
partitioning it into smaller components to try to understand it but I'm not sure I have a kind of
nice universal story for how to do that right now I'd love to have a good connection from this to
um to that kind of explainable AI but I think a sort of less ambitious aim that we start to get
from this kind of toolkit is one that says okay well at least we know how our systems are built
and we know what the different parts are if we work like this if you look at machine learning code as
it is um it it's often full of lots of you know very informal commentary because people need to
sort of be careful about where certain bits are which how the information flows effectively which
index goes to which other index um and so I think people actually don't understand the models as they
are right now um having some types on those interfaces might make that process a bit easier
okay great so thanks thanks very much it was one one question from we've got Mark here from a PhD
student yeah thank you so much for that it was a lot extruded that was a very very intense
I really did appreciate that um there's uh the there's something that I wanted to uh get on
first of all I'd like the uh an explanation of the um impregnatedness of the whole project
but the the question I want to ask you is it doesn't seem like there's
necessarily be a clear demarcation on the biological side the ancient biology side
to the the process of of uh going from um Bayesian lensing to the silly uh concede institutions
and I think you hinted on that corporations and uh um you know the the focus of of at the
silly level might end up being at uh so I want to know what your thoughts on that are
yeah it's very interesting so I yeah I this is a this is a kind of scale-free theory in some sense
um I don't mind I don't think of a particular neuron as being more like adaptive than a whole
brain or a corporation they can all be understood as doing this process at least on this account
and so there's nothing to say that say a corporation is somehow less like biological
than sort of a single or multi-celled small organism and in fact I think what we see of
the process of the evolution of life itself is a kind of growing um sort of growth of complexity
like you start with these single celled organisms you get multi-celled organisms you get you know
simple plant life animal life and now we've got societies and in biology you have smaller
societies like anthills and those things are all kind of you know sensitive sensible conglomerates
of their own kind they are adaptive systems um and I'm trying to capture this process in its
generality um you know corporations are part of that but you know nation states and the whole world
is one too um so I I'm not trying to make a distinction between biological systems as they're
commonly understood and these kind of broader economic systems I think of those things as all
kind of ecological in some sense and to be honest I think economics could do a lot better
