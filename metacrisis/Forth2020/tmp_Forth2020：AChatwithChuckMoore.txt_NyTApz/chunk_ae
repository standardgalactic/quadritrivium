C++ has memory management problems and things like that. And it causes all these expensive bugs
for like Microsoft and stuff. And they spend millions of dollars trying to fix bugs in their
operating system caused by the programming language. So now they're trying to come up with
Rust as a magic solution. What about forth? You could take forth that's really simple.
You could put in all that error checking that doesn't have. What do you think about that?
Yes, he certainly could. Fourth doesn't have to be a standalone language. It can be a module
in an operating system. It just doesn't seem to strike people's fancy.
That was all my questions. Okay. Thank you. So Gerald's next try.
Okay. Next try. Can you hear me now? Yeah.
Very sorry about the blur before. So Chuck, I wanted to ask just because you also mentioned
before that not a lot has changed in force regarding to the basic structure of having
a directory and having a stack. But I actually recall having a discussion with you where you
mentioned investigating multiple stacks and using locals even. Did you do any further research
or has this just been a short excursion for you? No, that doesn't lead anywhere useful.
What I have done in UHD forth, I've taken advantage of all the registers that the x86 has.
And you could almost say that you could make a forth
register based instead of stack based. And I explored that a bit and abandoned it.
And why? The stack is absolutely essential. You might not use it all the time.
You might take advantage of the registers. But if you don't have a stack on which you can pass
parameters, you're crippled. And why did you give up on having even more stacks?
I don't use floating point arithmetic. So there's no reason to have a floating point stack.
And I have never found a use for any other kind of stack.
Okay. Thank you.
Right. Thanks. So our next question comes from Greg.
Yeah. Hello, Chuck. It's a pleasure to meet you. Actually, I was curious about
something that was said earlier. You mentioned as a general rule,
just limit the number of things on the stack to maybe just two. And so just as a possible example,
if I were to develop a word that is to draw a rectangle and it takes two points,
top left, bottom right, let's say, as parameters, that would be four arguments on the stack.
So I might think, well, maybe I should start thinking about structures. So maybe I'll create
a structure that's a point object. And so I could put two points on the stack. And
that's only a couple of things placed on the stack. But now I have a structure.
That structure would be, I think in fourth would be typically global, which some people might
look at scans that and say it's a global variable. I could also think of it in terms of, well,
maybe I could create an object called a rectangle and the rectangle might have methods to set its
points and to display itself or whatever I decide makes sense. And that I think fits well with the
noun verb structure that fourth, I think, encourages object action type of thing, machine
on, machine off sort of thing. Just curious as to what your thoughts would be on how you might
structure and your thoughts, a problem like that. And what are your thoughts on structures and objects
and that level of abstraction, in addition to just the basics of what fourth gives you?
That's one way of doing things. What I do
is I have a word at that sets the cursor, takes two parameters, and specifies the location on the
screen. And then I have another word called rectangle. It has the dimensions of the rectangle
that I'm going to draw at the cursor. So I've broken it into two pieces instead of having one
large piece. And I can use the word at for triangles as well, or for circles.
Now, in the case of a triangle, it's a problem because you've got three points.
And I use a structure for that. A circle only has one parameter, the radius,
so it's on stack. So to generalize and say everything should be structures
is not right. And everything should be in a stack is not right either. You have to be flexible.
What are your thoughts on objects, having a variety of...
I created an object in fourth called the month. And this object had the starting point in the year
and the number of days or something like that. This was backed back very early.
That's the only object I've ever done. And it was useless. I had much better ways of doing months now.
So I think object-oriented programming is the mistake. There are not enough instances
of the object to make worth the generalization.
Interesting. Thank you for your thoughts on that. Appreciate it.
That's why they call it oops.
Okay, Francis, please ask your questions.
Hi, Chuck. Can you hear me?
Yes. Okay. Hi, Chuck. It's an honor to speak with you
following for a while. And I just wanted to thank you for this gift to us.
I was wondering if you could speak a little bit about the motivations for the circuit
simulation software you wrote, its performance, and its current status.
Say again. So I was wondering if you could speak a little bit about your motivations
for the circuit simulation software you used to do the layout and electrical simulations,
its performance, and its current status?
Yeah. That is one of my favorite applications. It's one of the things that I've spent
most time on. And I think I've done the best job of.
There's two aspects to it. One is the circuit logic description.
And the other is the layout. If you are laying out a circuit board, or whether you're laying out
a chip, basically the same problem with different geometries.
And what I have learned to do is, in both cases,
I do the layout. And from the layout, I derive the circuit, an array of transistors and interconnects.
It's extremely efficient, extremely intuitive, pretty simple to implement,
and gives wonderfully complete results.
I've done a lot of circuit boards, but I've done even more chips. And the chip layout,
well, conventionally, one has a logic description of gates that are connected,
then you derive the layout. And I do it the other way. The layout is predominant,
and the function of the layout is determined from it.
This is a strange side effect. There is no need to do a validation proving that the layout accurately
reflects the circuit. The layout is the circuit, and is by definition correct.
And it's a lot of fun. I enjoy working with rectangles and layouts.
Unfortunately, again, just like the world doesn't let you interface with
chips or boards or GPUs, the world doesn't let you interface with chips any longer.
You have to give it a GDS approved layout, which they will validate before they
construct a layout which vaguely resembles the one that you worked from.
It's a frustrating technological development. I would love to have a chip making machine,
something that will generate a prototype chip in a desktop environment.
But the world prefers to have billion-dollar fabs.
I asked that because I was in my daily job. I do this as a maker and a hobbyist of the
cyber. In my daily job, I do chip design and process development for one of the big
semiconductor companies, and this is a cool interest of mine. I thought I would ask about that.
Just another question. What are the most interesting one or two applications you've seen
in forth from others that you didn't see coming? The applications in forth think those.
You can go to their website for a list, but they've done communication networks, device handlers.
I did a Hollywood robot camera on cement making plants.
I would love to see a self-driving car in forth. That's a heavy thing though. As soon as you get
into applications that risk human lives, it's a whole new game, and I've never done one of those.
And just a last question. In hindsight, has anything done differently with the gods to forth
in setting it up, developing it, all that? Looking back after all these news.
No. In hindsight, I don't know that I've done particularly well,
but I don't know that there's anything I would have or could have done differently.
In back in what 1970 or so,
forth in a sense was competing with Microsoft. Not directly, but conceptually.
And if we at forth think had developed an operating system,
we could have competed with Microsoft. But we didn't. We couldn't.
And I'm perhaps glad we didn't. I'm much happier with where we are now than where with Microsoft
is now. Microsoft has to be compatible with the exception maybe of Windows 11
with everything they have ever done before. And that is a horrible burden to bear.
Fourth, as it stands,
well, forth is free to reinvent the wheel. And I think that is a marvelous concept
no one should ever be afraid to reinvent the wheel. And we do it every day.
Thank you, Chuck. Thank you.
Yeah, thanks. And Howard, your turn. And please open the mic.
Hi, Chuck. I've already had a turn chatting to you. But one more question about one's
compliments. The whole used to be very popular a long time ago. The IP Internet Protocol
uses a one's compliments checksum. And it has some interesting properties. I have a feeling
that it's a really good way to go. And I observed that you use one's compliments in the color
fourth. And I just wanted to hear your opinion. Do you think that the world went wrong when it
moved over to two's compliments? No, I worried about this. One of the main frames I
programmed early on was one's compliment arithmetic. But two's is much more convenient.
And it doesn't cost anything in hardware. So two's compliment is definitely the way to go.
Yeah, I can understand that point of view. The thing I like about one's compliment is that
you've got this extra state in the system. In normal two's compliments, you've got zero,
and you've got everything else. And in one's compliment, you've got plus zero and minus zero.
And it strikes me that it's very useful to have this extra
state that can be used so you can have a value as either zero, not zero, or not set,
or some such. And I think this whole idea of having three states in a value rather than two,
it brings it closer to the optimal number of symbols required to transmit
data, which I believe is E, somebody proved a long time ago. So it's closer to three than two.
Anyway, it's just, I think it's a good idea. You're talking about having code?
Yeah, yeah, yeah. Yes. The introduction on computer file about that two days ago,
about having codes, and the transition of following the edges of the square to get to that.
Okay, thanks for the link. I'll look into that. Okay, thanks, Chuck.
Okay. Right. So Bob, you raised your hand. Hello. I'm raising my other hand.
Okay, I have one thing I'm wondering when I heard you, you programmed a mainframe that was
one's compliment. What mainframe was that? You remember?
That's why I didn't name it.
Could it have been a Sperry Univac?
No, it might have been the...
Who needs this?
Was it when you did that at the regs?
The first Supercomputer, right? I can't come up with the name of it.
Oh, Kray? Or us?
Kray, or maybe one of its input terminals, something like that.
Cool. Second question. You mentioned compatibility, and how Microsoft has maintained
compatibility. And then, of course, you've just mentioned mainframes. I was thinking
ZVM, which is the current version of OSM-MBS, which is OSM-BT, which is OS360, has maintained
compatibility across since the 1960s when it first started. And evidently, you could compile
a program today on ZVM, ZOS, rather, I'm sorry, ZOS mainframe in a run.
And it just, you know, it was interesting that you'd mentioned compatibility.
IBM has had it maintained that for all these years.
Compatibility guarantees there won't be any progress.
Yes. What is the smallest fourth you've run across? What's the minimum?
Like, if you could, I don't know exactly, I can quantify it, but like the smallest amount of
memory, smallest amount of stack space. What is that? What would that be?
The smallest one I've done was called CM fourth, for the Novix, I think it was.
At fourth, I think we had micro-fourth and mini-fourth, which explored the range of having a small
kernel and everything else compiled. E-fourth does that, I believe.
But I've heard references to these, some micro-computer fourths that had very small kernels.
I would say a kernel should not be more than 4k. If you get it down to 1k, that would be nice.
Okay. Cool. You mentioned in talking, and I forget who it was, but you mentioned that the
two parameters stack, but you mentioned the stack that's only deep. Is that for like
as many levels as deep as you go, or is it deep? I bet we thought deep and so often small.
I would think in terms of the circular stack with eight elements, so that you could put as many
things on the stack as you want, but you only have access to eight of them. Now, for the
nice circuit tracing algorithms, I've needed to stack thousands deep, because as you trace
the circuit, you're recursing and recursing and recursing. That's a whole different concept
that I would have a software stack for. The hardware stack can be very small. Four is too small.
Eight is small. 16 is plenty. Okay. Cool. Two more. One is, did you know that
the current .NET implementation of languages produced something called IL, and IL is a fourth
like stack language? So they actually compile C into a fourth like language. I don't know if
you've known that. I would say no, because I haven't understood what you've said. Okay. Well,
.NET is the kind of the, I'm sorry, Microsoft's answer to Java, C sharp is Microsoft's answer
to Java. It's become very popular. It's actually very nice language. If you're writing that kind
of software, but when it compiles, it compiles down into something called intermediate language,
which is actually a very fourth like language. It's a stack based language. I thought that was,
I thought that was interesting. I didn't know if you'd heard of that. Well, all
infects languages have to compile into a stack. So, yeah. But the interesting thing is this,
it doesn't compile, it doesn't compile to a native. It compiles to IL. IL gets compiled to native.
An intermediate language. Yes. That is,
to me, that is grossly inefficient. Why not write an intermediate language? And
the last thing is that you've talked about assembler and you don't even know the
x86 op codes and such like that. In the 1130 assembler, you wrote an assembler. I mean,
in 1134, you wrote an assembler so you could write 1130 instructions in a fourth like notation.
I mean, there was right there right at the beginning. It was very cool.
Not only 1130, all of my computers had assembly words. And I now think that that was a waste of
time. It was hard to figure out how to construct the words. It was hard to remember how they were
constructed. It was inefficient to implement. The xop codes are on any computer are far the
simplest way of implementing it. It's interesting you're saying that because it was just like,
that was when we were looking at the code. That was one of the most intense parts of the code.
Starting to understand what you're doing here. And then like saying, wow, we thought we thought
brilliant. So it was fun. It was, it was clever. But it was at least as difficult as the xcodes.
Yeah. Okay, that's it. I'm out of here. At least I'm calling you. Thank you for your time.
Okay, thanks, Bob. Our next questions come from Jan Bramkamp or Jan Brankamp. I don't know.
If my microphone is working. Yes. Okay. So my question is, you've already rented about infix
notation and how it doesn't compose. And what do you think about a prefix notation like lisp?
I'm sorry. I lost my earpiece. Sorry. Let me repeat that. You've already given us your opinion on
infix notation and how bad it composes. What's your opinion on prefix notation languages like lisp?
Um, they made an unfortunate choice. I believe the human brain works on postfix.
