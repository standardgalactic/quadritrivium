Welcome, everybody, to the first webinar by the ISPA Industrial Statistics section.
And one of the purposes of this is to try and lay out a plan for the future of Bayesian
statistics in information technology.
We have always had a role in manufacturing.
Changepoint detection is sort of most naturally addressed through Bayesian methodology.
And we've also had Bayesian control charts and all sorts of stuff like that.
In the pharmaceutical world, Barry consultants has certainly staked out a very large Bayesian
real estate claim to methodology.
And Adrian Smith used to do a tremendous amount of consulting with the European pharmaceutical
companies.
But I think that sort of besides the point in the modern world, information technology
is driving things forward.
Now that's going to be where the action is instead of manufacturing our pharmaceuticals.
And so I think it's important for our profession to have a conversation about what role Bayseans
can play in the knowledge economy.
I think Bayesian statistics stands at the threshold for a new vision of industry.
And I hope that a lot of us will step forward.
I've seen about two and a half theoretical breakthroughs in my career, and I don't really
expect to see another.
There was Brad Efren's bootstrap.
There was Gelfand and Smith's Markov chain Monte Carlo.
The half revolution was the large P small and regression problems that occurred in the
mid 2000s.
But I don't expect to see anything comparable to that going forward.
My guess is that what we're actually going to see is a surge in what I call data engineering.
David.
Yes.
Are you, did you move the slide because we didn't see it change?
Oh, yes.
I've been advancing the slides.
Okay.
Can you see it?
Now.
Okay.
Great.
Thanks.
Thank you, McKellie.
And everybody, please.
I'd like this to be a conversational discussion rather than a didactic lecture.
When one talks about data science, well, if you're looking at lots of high energy particle
data and trying to infer the existence of the Higgs boson, then yes, you're doing data
science.
If you are looking at a distant star to see whether or not it wobbles and suggests the
presence of an extra solar planet, then you're doing data science.
But most of the PhD graduates from Duke are going off and working in industry, and they're
taking a lot of data and using some smart algorithms, and they are helping Uber pre-position
its cars, or they're helping Amazon do a slightly better job on its book recommendations.
And that isn't science.
There's no theorem there.
There's no generalized knowledge.
Instead, you're doing data engineering, and that's a great thing to do.
It makes our lives better.
So I strongly encourage us to think about opening the doors to that type of career perspective.
Data engineering is creating all sorts of new businesses and new services.
Google Maps has changed my life.
It's probably changed your life, too.
Ride sharing services are enormously convenient.
Recommender systems, TikTok, Povino, YouTube insurance, everything, Amazon, all this stuff
is fundamental to the information economy, and we need to be paying attention to this.
Industrial statistics focuses upon machine learning, and that does not map cleanly onto
the frequentist Bayesian distinction.
And I think the reason that it doesn't quite map cleanly onto it is what Jack Good called
type two rationality.
With type one rationality, you make the decision that maximizes your expected utility.
But with type two rationality, you make the decision that maximizes your expected utility
where your utility function takes account of the cost of computer memory, the cost of
computer time, the cost of data acquisition, the human time that it takes to set up the
problem, all of that stuff fits into your utility function.
And consequently, although a Bayesian might aspirationally want to do Markov chain Monte
Carlo, we recognize that that can take a long time to run, and maybe a variational approximation
is a good enough solution for the problem at hand.
One of the great values of the Bayesian perspective is interpretability.
Getting insight into what's driving a problem is very important.
Being learning often dismisses interpretability in an attempt to do sort of half a percent
better in terms of predictive accuracy.
And if you're Amazon or Google, that's important.
But if you're trying to start to analyze a new problem or address a novel situation,
understanding and interpretation are, I think, the very natural starting points.
And interpretability is closely related to parsimony and to regularization.
You'd like to have the simplest possible model that is fit to purpose.
And often that means that the model contains only a few terms, and you achieve that with
regularization.
Basically, it's Occam's razor, but it's fundamental to Bayesian thinking.
This type of parsimony takes many different forms, and if there is going to be a theoretical
breakthrough coming forward, my guess is it's going to be in the context of parsimony.
There are many different expressions of it.
One is that most of the explanatory variables in a regression are irrelevant.
Another statement of parsimony is that the weights in a neural network take only a small
number of distinct values.
In principle components analysis, a small number of latent factors explains most of
the observed variation.
A fourth example is that a non-negative matrix can be approximately factored into two low
rank matrices.
There are many different expressions of parsimony, and it would be great to see a unification.
I think information technology is going to be the future of industry.
It's a target-rich environment for Bayesian statisticians, and some of the key challenges
are going to include computational advertising, autonomous vehicles, large language models,
optimal control of manufacturing processes, financial industries, and a whole lot more.
I'm going to talk about the first three indicated in green in a little bit of detail, but I
will certainly point out that our PhD students are flocking to these industries and application
areas.
Working for Google, working for Amazon, working for LinkedIn is a very sexy career path, and
I think we need to help our students prepare for that type of role.
Let's talk for a minute about computational advertising.
It's an emerging field.
It's a $309 billion industry.
The ecology of ad buy in auctions is complicated, and companies with better information will
make more profit.
The field uses old tools of experimental design, process control, and sampling, as well as
engaging with many new areas of statistics, such as costal inference, predictive inference,
spatiotemporal modeling networks, all sorts of cool new tools.
Computational advertising is going to pose new and important research problems, especially
in connection with recommender systems, which have wider applications, and Bayesians can
make amazing contributions.
The field is moving quickly.
It's next year projected to be worth $982 billion, and it's the dominant revenue stream
for many of the major IT companies.
And it's complicated.
There are lots of moving parts in computational advertising.
Yes, I could talk a long time about this, but I should not.
One component of computational advertising is online ad clicks.
When you type pizza into your browser, it immediately triggers a virtual auction that
has to last, take place within 10 milliseconds or less.
Dominoes, Papa John's, and Pizza Hut will all bid to show you ads, and the highest qualified
bids are displayed with the highest bidder getting the top position.
The process is actually a lot more complicated.
Yes, Antoinette.
Antoinette, I'm having trouble hearing you.
You seem to be muted.
Sorry.
What's wrong?
I had no question.
I'm just listening.
Oh, okay.
No problem at all.
The qualified bidding process is interesting.
A company such as Google has a waiting system such that respectable companies get up-weighted
and more marginal, smaller companies.
Well, for example, if Pedro's pornographic pizza is trying to compete with Dominoes to
show its ad, it's going to have to bid a lot more than Dominoes does in order to win that
ad placement.
This qualification scheme is secret because Google doesn't want people to be able to gain
the system, but it's not a straightforward auction.
Here's a diagram of how the auction goes.
The pink rectangle at the bottom is the user, and his browser then reaches out and touches
a website, and that triggers a complex exchange that executes within 10 milliseconds.
So your browser might contact the publisher's website like CNN.com or The New York Times.
The publisher sends back ad content, including placements that need to be filled through
the ad server.
The browser contacts the publisher's ad server to fulfill the placements that are sort of
pre-designated.
So CNN will say, we want to have some advertising, perhaps for CNN itself, and they were going
to put that out on the website's real estate.
And number five is for placements that will be put out for auction.
So the browser will contact an ad exchange with placement information about the available
real estate on the website, and it will indicate whether a placement should go out to be for
a bid.
If the placement is marked for real-time bidding, then the exchange sets up an auction.
The exchange contacts demand-side platforms who are invited to participate in the auction,
and this all runs in parallel.
If a demand-side platform decides to bid, then it makes its bid offer, and a director
tag or return to the auction.
The winning bid from the auction and the information on the bidder is then sent to the exchange.
The exchange returns to the demand-side platform wrapped ad tag that contains everything you
need to track the ad.
The browser contacts the demand-side platform's director to obtain the ad service tag, which
basically determines what the content in the ad is going to be.
The browser reserves the ad server tag.
It uses the ad server tag to contact the advertiser requesting the impression.
The advertiser's ad server returns all the impression assets, and the creative contact
content back to the browser.
Almost always there's a third party that is contacted to verify that in fact the ad actually
was shown as the CNN has promised.
The third party sends back a handshake.
The ad tag contains the JavaScript that the browser app will load when the impression
renders, and this happens fairly late in the process because it's not important for the
immediate exchange, and then there are two handshakes that verify that everything happens
the way it's supposed to be.
This sounds complicated every step is necessary, and even this is an oversimplification.
Back a couple of years ago, nearly all of these auctions were second-price auctions,
victory auctions, but now they've nearly all become first-price auctions, and Bayesian
decision analysis has been used to determine the bids that companies place in these auctions.
I don't know how many companies are using Bayesian methods, but I know some are.
Computational advertising touches on many different aspects of statistics.
Important topics include Bayesian design of experiments, causal inference, recommender
systems, predictive inference, and time series modeling.
Let's unpack that for a moment.
Google runs thousands of experiments a year.
Famously, they experimented with 43 different shades of blue for their hyperlink connections,
and they are always doing small experiments, and these experiments are actually quite complicated,
and Google can acquire millions of observations in a few minutes, and so these experiments
are rapidly changing.
Causal inference is key because any advertiser wants to know what is the impact of their
ad, how much lift has their ad caused in their purchasing their products, and that is a
straight-up causal inference question.
It's complicated for a lot of reasons.
For example, my wife may be shown an ad on her cellphone, and she tells me, David, go
buy that product, and so it's very hard to directly infer that showing an ad to my wife
led to a purchase that I executed.
Recommender systems we're going to talk about later, but they got a very cool Bayesian representation.
