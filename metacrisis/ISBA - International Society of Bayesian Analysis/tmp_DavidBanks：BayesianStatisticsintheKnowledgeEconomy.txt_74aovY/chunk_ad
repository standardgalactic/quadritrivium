they will recognize that they have an experimental design problem, they will know what they need to learn,
and they'll go out and perhaps they will learn partially balanced ink-blot designs with K-associated classes,
because that's what they need to have for that problem.
Similarly, Duke doesn't have a class in cluster analysis, but I think four lectures on cluster analysis
that will get you to the point where you know what hierarchical glomerative sampling is,
what single linkage are, where you know what K-means clustering is, and where you know Kleinberg's impossibility theorem,
I think that would be tremendously valuable for our students.
Obviously, a PhD student needs to do a deep dive on something, but I think lots of shallow dives
that gives them a broad toolkit and a wide understanding of what they can do is more valuable
than teaching them about uniformly most powerful unbiased tests.
And I was startled to learn that many people still put that on qualifying exams for PhD students,
because really, none of us care about uniformly most powerful unbiased tests anymore.
Sadly, basins and statisticians have been slow to embrace big data and deep learning,
and even data science is something we still shy away from.
I urge us all to de-emphasize formal theory and ramp up on complex applications.
So that's the main message I have, but I have a secondary message.
And let me stop sharing.
I think it is very important for the industrial statistics section of ISBA to look outward towards these new challenges.
Historically, the industrial statistics section has been narrowly focused on traditional manufacturing industry,
and that's not where we need to be.
So one thing I strongly encourage is that all the people who are hearing this talk consider joining the industrial statistics section.
It's a trivial cost. I think it's less than $10.
And if the young people join, they will lead things forward in ways that will maintain the viability and relevance of our profession.
So that is my talk. Let me pause now and see if we can get any conversation going, or discussion or questions.
I will call on people. Sylvia, would you like to unmute and have a comment?
Yes. Hi, Sylvia.
Let me see whether this works.
Yes, it does. We can see you.
Well, thank you for this talk. This is really thought-breaking.
I'm not from the industrial section. I am an economist.
And I thought, let's say, at least in the basin in the econometric section,
we have some, let's say, high-dimensional data analysis going on, but it's basically based on machine learning.
And also these large language models, I think, are based on machine learning tools.
And so, yeah, I was wondering, also deep neural networks, so where do you see what, how would you enter this, let's say, the basin setup?
So how do you, so where does the basin, I don't know, prior come in?
So at which level do you see where you can have some basin update in there?
In these black blocks, black box machine learning tools, basically.
We need to validate a deep learning model, for example. And so you have a basin prior over the performance, the accuracy as it's given a set of tasks and those tasks may have features.
Recommending a book is one type of task. That's a different type of task than recommending a movie.
We would like to be able to learn how well a deep network does, and we can have priors and all sorts of relevant information.
So there's lots of opportunities there. In terms of the economics, there are all sorts of statisticians who are involved with the computational advertising firms trying to forecast what is going to be the economic impact of small changes.
And finally, I mentioned the dislocation that's going to be caused to the economy as autonomous vehicles become common.
We need to forecast what is going to be the economic impact of these vehicles and what is the appropriate sort of public policy posture to respond.
So I see tons of opportunities. If we're not engaged, then we are making our profession irrelevant, and that's just bad for everybody.
Let's see. Bobby, Bobby Grammys is on. Bobby, would you like to unmute?
Oh, gosh, David. Hi, everyone. Thanks, David, for a very nice presentation.
I've been thinking about a question in the last two or three minutes, and I haven't fully formulated it, but I wanted to pick up on a slide where you talk about computing skills.
You mentioned Spark, you mentioned PyTorch and TensorFlow, and my question is about the Python ecosystem as a platform for the development of science.
I know we're talking about industrial statistics here, but a frustration that I have about Python, compared to, say, R, is that I can't ever get anything to work in my environment.
I can duplicate their environment. I can use a container. I can use Python environment variables, but I'm speaking mostly as like a technometrics editor, which is where I'm like running most of these codes.
But I think sort of a downside to that ecosystem, compared to R, is that it's hard to share code.
It's hard to create a Frankenstein where you put all these little pieces together, and I think this is what we really need in order to advance industrial statistics.
I wonder if you have any thoughts on that, before we all jump on board to PyTorch and all these other tools, instead of working in R, which I think most statisticians do.
You make excellent points, and the answer that I have today may not be the right answer for the future, because large language models are getting steadily better at producing code, and there are translators that can take R code and turn it into Python, and they're getting better and better at doing that.
I think we will always have to teach somebody how to program in one language, but I can imagine that once they've learned how to break down a problem, how to think algorithmically, how to, you know, understand sort of weird if-then statements or whatever,
then I think that they can probably use prompt engineering to say, I want to program in SQL through this, I want to program in PyTorch through that, I want to program in R through this other thing.
And so I won't be surprised if, in five years, that's the way most programming is done. Already, the people who are doing statistical analyses are ghostwriting their code with co-pilot and then tweaking it to produce what they actually want.
So this is a rapidly changing environment, and so my suggestion that everybody be taught Spark and PyTorch is probably outdated or will be outdated at some point.
Right now, our graduate students know that they have to learn this if they want to get a job at Google or Amazon, and so they learn how to program in Spark or TensorFlow from online webinars,
which is not necessarily the ideal way for our educational programs to run.
I will mention that Bobby is going to be teaching the next ISPA Industrial Statistics webinar. It's going to be on surrogates or emulators and uncertainty quantification, and we'll be sending around an email with the instructions on where and when for that. Thank you, Bobby.
Thank you, David.
Anybody else care to speak up? Somebody, Guido Consonni, would you like to unmute and talk?
I think we have one minute before we're at the hour.
Yeah, so thanks, David. Also, nice talk, and I don't know whether... Okay, yeah, you mentioned the fact that we should not be thinking about learning statistics the way we did it, say, even 20 years or maybe also 10 years ago.
So in your opinion, however, if we have to set up a PhD course with the first year in which we have teaching inevitably, what would be the essential thing you would concentrate on?
If we are getting away from the standard mathematical statistics, that's okay. I mean, we understand that. But what would be the main broad topics on which we should have our PhD students to concentrate on so that they can better get to the challenges you mentioned?
That is a longer conversation and an exciting one to have, and I'm sure that many people would disagree with me. In the inference course, I would keep Ralph Blackwell, I'd keep, oh, Fisher Information, some of those.
But I would definitely give up on UMVUs, uniformed with powerful and biased tests, all the things that require deep belief in a model, which I think nobody in practice is ever going to really believe.
I think modeling is an important component. H.D.T. Shorani and Friedman is an important book for people to have. That would be where I would start the core, but I recognize that smart people will disagree for very good reasons.
Rafiq is chair, Rafiq is the incoming chair of the industrial statistics section. Rafiq, would you like to say a few words just to close things out now?
Yeah, sure. Yeah, David, I think this is a great initiative. I think I'm glad that Bobby will be continuing with another webinar.
But you know, based on some of the points that you made, I mean, obviously, when I hear about industrial statistics, I always think about engineering statistics.
And obviously, most of the developments in data science and machine learning are really in the engineering schools.
And at some point, I remember that you were thinking about maybe changing the name of the section and maybe, you know, bringing somehow the machine learning or some related concept into the section title.
I think that may be something, you know, to talk about, to think about.
That sounds good. If we can get an uptick in membership, then I think that would be the right time to have that conversation.
Thank you all very much for your time today. I'm past the hour, so I'm going to sign off now, but I really appreciate your time today. Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
