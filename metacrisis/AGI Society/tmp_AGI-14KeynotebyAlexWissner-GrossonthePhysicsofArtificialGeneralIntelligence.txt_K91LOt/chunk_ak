yes
so precisely it's not exploring so there's
another state which is
more difficult to be accessible
but with much higher energy
you won't find it
if there's another state
of much higher energy
but it's completely different from that
it's not looking for it
it's just trying to stay where it is
I'm sorry, what has a higher energy state?
like there's another bus somewhere
with all the balls
and instead of trying to put those two
balls in the same it could have
like 1000 balls in another
box
I mean it's just like a model question
where you're asking about the explorer
versus exploit tradeoff
so this comes back to the model
so this is starting with a model
basically a complete model of its universe
where the only uncertainty is being
introduced by its own actions
it doesn't know yet what it's going to do
that's the only uncertainty in the universe
otherwise the universe is completely deterministic
so there are no parts of its universe
like hidden balls that's unaware of
it's not doing any sort of exploration at all
it already knows what the universe looks like
it's just deciding what to do with it
so how does it deal with the exploration
and exploitation of tradeoff?
so in this universe it doesn't need to explore
because it knows everything
hopefully later, maybe offline
when we talk about the explorer versus
there's a really interesting heuristic argument
that learning should fall automatically out of this
the one sentence version of that heuristic is
if you live in a universe
where you don't have a complete model
of the universe that we live in
and you have a choice
you can either explore
discover more things about your universe
or not
then a causal entropy maximizer
would all other things be equal
with reasonable assumptions
reasonable prior assumptions about the universe
decide that it does want to learn more
because if it sort of rambles
through its universe
emitting a stream of actions
for a universe that it doesn't have a good model of
then it will probably do a bad job
of being able to access
future freedom of action
and that can give you specific concrete examples
like say the problem of diffusion
in the universe where there's a tiny
window where if you just manage to
put yourself through that window
then you have access to a much larger universe
it's sort of the fruit fly trap
that exploration
will generically
again, under a variety
of simple prior assumptions
results in larger future freedom of action
unless you live in a universe that punishes exploration
but we can talk more about the
the other side of it
so there's going to be some implicit balance
of exploration versus
exploration
if you live in a universe that doesn't punish exploration
broadly considered
then there will heuristically be a bias to
explore absolutely
without needing to put learning in from the start
yes
when the big problem is the two small walls in the cage
why does it keep moving around
so
excellent question
short answer is
it's the same answer as the question
of why did it let it all out in the first place
that this is only simulating on the order
of a thousand possible paths
and the space is enormous
you'll never enumerate all of them so
having simulated a hundred thousand paths
the simulation would have taken a lot longer
but it would have converged to being effectively stationary
this is just noise basically
from finite sample
since I probably have only five minutes left
let me play without interruption
the rest of this video and then we'll
rebut all our questions
so
this is back
third example social cooperation
again the standard animal behavior experiment
to see if two animals are willing to
we don't know each other are willing to cooperate
to accomplish a task
very standard experiment in animal behavior
and causal entropy maximizing engine
that only passes the test
but then starts to play with an object afterwards
Pong which we saw a lot of in the previous talk
in this case
it's playing Pong against itself
again it's able to successfully
play Pong
why is it doing this? because
if it lets go of the ball
then the ball in this universe gets stuck
in this case
a networking example
where people are falling in and out
of connectivity
it's able to dynamically wire up
a social network
because in this case it's easier
to have a social network decay than it is
to be forced to wire it up
here we see some
sort of fun
navigation examples
where speaking a bit
this isn't actually exploration
this is more coordination and logistics
we can still talk about that afterwards
and then finally I'd say
my favorite example
I'll just dwell for a minute on this one
so this is
not a real stock market
this is a simulated range traded stock
where you imagine you live in a universe
where you have a stock that's just a Gaussian process
that's stationary
and
the policy
choice here for the causal entropy maximizer
is what should my asset allocation be
between cash and the stock
that is just fluctuating
and I think this also speaks
to the wealth questions you can see here
as this subtitle fades
so red represents
total assets under management
green represents
the fluctuating
sorry green is cash
blue is fluctuating stock price
so you'll see here dynamically
it's varying its asset allocation
getting into and out of the stock
it spontaneously discovers
by low to sell high
so in this case
going back to several questions I was asked about
sort of narrower
narrower utility functions
where is the utility function
to accumulate money come from here
and the answer is very similar
that if you live in this sort of
financially noisy environment
it's much easier through trading
to lose money than it is
to gain money and so
we're always told strategically
career wise try to position yourself
upstream so that you can choose
what happens downstream saying I get here
that since it's
much easier to lose money
than it is to make money
the equivalent of being upstream here is accumulating
assets you have much greater future
of action if you have a lot more assets
under management than you can trade because you can explore
more of cash stock face
face than you can if you're very poor
so this comes spontaneously
buys low sells high and for fun
even does online learning of the stochastic
dynamics of this Gaussian process which isn't that difficult
to learn but just to demonstrate
