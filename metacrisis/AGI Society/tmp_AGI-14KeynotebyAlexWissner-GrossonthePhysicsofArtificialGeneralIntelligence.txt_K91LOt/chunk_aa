It's my pleasure to introduce our next keynote speaker, Alexander Wissner-Gross, who's a
scientist, inventor, and entrepreneur who's done more interesting things than I'm going
to be able to list here in a moment.
He's currently serving as an Institute Fellow at Harvard University at the Institute for
Applied Computational Science.
He's also a research affiliate at the MIT Media Lab.
His background is quite that Earth, but you see the work of physics up there.
He has a PhD in physics from Harvard, where his thesis on programmable matter ubiquitous
computing and machine learning was awarded the Hertz Doctoral Thesis Prize.
And in the recent past, he has achieved a lot of attention both in the intellectual community
and in the broader media for his hypotheses about the relations between causal and tropic
forces and general intelligence.
He had a TED talk on relayed ideas, which has been viewed something like one and a half
million times.
So now we get his views on the nature of general intelligence, the relation to physics, entropy,
and so forth.
I'm sure there will be some interesting questions and discussions following up this presentation.
Awesome.
Thanks so much for that.
Can everyone hear me?
Great.
Well, let's make this as interactive as possible.
Thank you for having me.
It's really a pleasure to be talking to AGI enthusiasts about this topic.
So as Ben mentioned, I'm a physicist.
I'm also a computer scientist.
I'd like to think a lot of my work is influenced by traditions on both sides of the physical
digital divide.
And I'll be talking for the next hour and a half about the physics of artificial intelligence.
And so as a physicist, sort of a cultural thing, one is always taught to ask about physical
limits and also about observables.
So observables are incredibly important.
So as a physicist, I can ask myself a question and I was speaking with a number of you earlier
about sort of the origin stories of this type of approach to AGI.
It's very natural to ask, what are the physical limits of artificial intelligence?
And from a physical perspective, it's very natural to examine time-like limits to AGI
and space-like limits to AGI.
So I'm going to devote the majority of this talk to exploring time-like limits to AGI
and a bit at the end if there's time to space-like limits as well.
But most of my recent work has been focused on time-like limits to AGI.
So this is an analogy that should be familiar to many people in the field.
Sometimes attributed to Dijkstra, but Dijkstra was partly alone in this concept.
So to abuse quote from Dijkstra, question of whether machines can think is now is relevant
to the question of whether submarines can swim.
So the way I think helpful or not to choose to interpret that notion is
it's always important to understand phenomenologies before you aspire to understand mechanisms
for complex systems.
It's interesting to perform a sort of thought experiment in the history of artificial flight.
Could we have accelerated the onset of artificial flight in our civilization
if we had had a greater focus on the physical phenomenology of flight earlier on
rather than mechanisms of flight?
It's always very tempting to try to imitate mechanisms from biology,
from other segments of the existing world because these are the examples that we have
in nanotechnology, in artificial flight, in artificial intelligence.
But I think history at the end of the day does try to teach us that understanding the
physical phenomenology of a complex system as early on as possible is a very powerful
meta-approach to trying to recreate phenomena that we observe in the natural world.
So I suppose this is a question more rhetorically than anything else.
Instead of trying to ask how can we fly like birds, maybe we should have been asking
earlier on what is the physical phenomenology of flight?
For example, understanding gliding.
And then by analogy, perhaps we should devote a greater emphasis.
Instead of just asking how can we build minds to perhaps an easier question,
which is what is the physical phenomenology of intelligence?
And what I mean by that is if you have an intelligence in a physical system,
so this is an embodied intelligence, what are the physical artifacts?
What are the physical processes?
What are the physical imprints that an intelligence leads on an environment?
Can we describe the physical impact of intelligence, whatever that is, in terms of physics?
I saw a question back there and I promised to make this interactive, so go ahead.
So I was going to see whether you really wanted it to be so or not.
So that was a free phrase, but you just said it in a different way.
I'm going to see if you're going to want it to be interesting.
So my understanding of bird intelligence is that it doesn't have to do with physical phenomenology,
but that you need to understand the principles behind what's going on.
It doesn't need to be physical, it may be computational, it may be other kinds of things.
And one of the best ways to understand the principles of something
is to understand systems that exhibit those principles.
So that studying birds is important.
The question is, what are the level of generalizations and how deep are the principles you get out of it?
So if you view it that way, then it doesn't say you shouldn't study birds,
you shouldn't try to replicate birds.
It just says you need to understand the right depth of principles to derive from them
in order to be able to apply that in other technologies.
So the question is, don't we want to understand principles
rather than just saying we want to understand phenomenologies?
So I think we're saying the same thing using slightly different language.
What I'm trying to articulate here is, let's understand the principles,
physical phenomenologies underline a complex system
before trying to duplicate mechanisms observed in the natural world.
And I think it is important to draw a dichotomy between the principles
and phenomenologies and the underlying mechanisms.
Mechanisms could be highly idiosyncratic, they could be specific
to wanting implementation of a general process.
There are many ways to achieve artificial flight and natural flight,
but there are relatively few ways to, to say, create lift in a hydrodynamic system.
And what I'm saying is that it's important to try to understand
the physical processes and phenomenologies first
before spending too much effort trying to exactly duplicate mechanisms.
That makes sense.
I don't want to extend this, but you often can't get that full understanding
in what you try to replicate.
And in the replication, you often understand the principles better
and you understand what aspects of the system really matter,
but don't, particularly when you're moving to a different technology.
So I don't think it's quite as simple a dichotomy in the team.
You can't afford to try to do all your understanding before you try to replicate.
I agree. There's absolutely a feedback loop.
And so what I would propose is to try to invest more energy,
more resources earlier on in understanding general principles,
physical principles, instead of just studying mechanisms.
So I think we're in violent agreement.
So if you take this sort of culture that we should try to understand
the physical phenomenologies of complex systems as early on as possible,
so what does this tell us about AI?
So I thought the morning tutorial was very instructive in that sense.
So sort of as a hobby for the first few years of us
living in the world of physics, the world of computer science,
I thought it was instructive to sort of keep my head to the ground
and look at a number of developments that we've seen over the past few years
and note potentially a very deep thread connecting them.
So I'll start with games first since the morning tutorial mentioned go-playing.
So I thought it was very interesting that in the discussion
there was so much discussion of the mechanisms of Go and Monte Carlo Tree Search,
MOGO, which was the 2006 Go player that got so much attention,
that there was so much discussion, I thought, of the mechanisms by which Go was playing,
but not actually the take-home lesson that we should be drawing and deriving
from the success of MOGO and then successor systems.
So let me speak first a bit about that.
What was really remarkable about MOGO and these MCTS Monte Carlo Tree Search systems
that for the first time are competitive with humans at go-playing.
So at the courses level, what these go-playing systems are doing
is they're considering all possible legal net moves
and then they're doing a Monte Carlo Tree Search from those net states out to the end of a game
and they're looking to see, okay, so maybe I'll have on the order of 100 possible legal net moves
and for each of those, one fraction of the time if I were to play a random game
against a random opponent with prunings applied by MCTS,
would I end up in a state where I win?
And at the course level, the approach is as simple as that,
nothing more complex, everything else is more or less pruning.
So taking the step back and saying, hey, wait a minute,
so this game, Go, that everyone went D2B, Gary Kasper up at 97,
everyone thought Go would be sort of this grand challenge for AI.
Why is this grand challenge falling to what is essentially just a valuation of every legal net move
and then checking to see what fraction of the random games that can be played
if it's a greater than about 80% or so, resulting in a win?
How could such a simple process, a simple algorithm be finally overcoming this barrier,
computational limits aside, the algorithm is so simple,
this is something we could have been doing decades ago.
So I would call that hint number one, that there's something profoundly interesting
and maybe this is a hint as to a greater phenomenology of AI,
that there's something profound about looking at possible actions.
So many of us from a control view right perspective would call this a policy.
There's something profound maybe about looking at possible legal actions in a control policy
and then evaluating Monte Carlo's title, a large number as densely as possible in path space
of paths that our universe can unfold along up until some future time runs in.
It's a very coarse observation, but I think what's profoundly interesting is
that several other fields seem to be converging on a similar concept.
So again, lesson number one there is there's some sort of, I would say,
profound insight emerging from the success with MOGO and its successors
as to choosing net actions that will leave open the maximum number of possible paths.
In the case of MOGO, paths to win, but Mike Ling is going to be that this is actually
an artifact of a more general principle.
Let's set an example in cosmology. So this may be a bit further afield for this particular audience,
but a major outstanding metaprogram in cosmology for the past 10 to 15 years has been the anthropic problem.
So why do we live in a universe that has the properties that it does
and a common anthropic answer to that question is we live in a universe that has the properties that it does.
Because if it didn't, we wouldn't be able to exist to ask the question
why does the universe have the properties that it does.
And one of the most successful approaches for addressing the anthropic principle
is Rafael Busoso's causal entropic principle, which holds that
universes that create the maximum amount of entropy over the course of their lifetime
clipping out certain inconvenient portions of the universe like black holes
which are causally disconnected from the rest of the universe
tend to reproduce certain critical values that we observe in our own moves
such as the cosmological constant.
And incidentally, one of his more interesting conclusions I think was this notion
that the largest source of entropy creation in our universe, again, clipping out black holes,
is starlight scattering off of enterstallar dust.
So he was able to arrive at a number of cosmological parameters
that are within a factor of two of the ones that we observe.
Now, I would say that this notion that maximizing causal entropy creation
for certain definitions of causal entropy is also, I would say,
sending us a signal from the cosmology community that there's potentially
some sort of deep connection between causal entropy creation
and intelligent observer concentrations.
So a normal anthropic approach to trying to derive from forced principles
the various cosmological parameters that we observe would be to say,
okay, so twiddling this knob here for this force constant
and twiddling this knob here for this force constant,
which combination of these null configurations would result
in the largest concentration of intelligent observer concentrations
who are able to ask these sorts of questions.
And I think what's so important about this development in cosmology
is for the first time it provides a firm either thermodynamic
or information theoretic, depending upon which school you come from,
foundation for formalizing this question.
No longer do we need to define intelligence
or to define what an intelligent observer is
to ask these cosmological questions.
