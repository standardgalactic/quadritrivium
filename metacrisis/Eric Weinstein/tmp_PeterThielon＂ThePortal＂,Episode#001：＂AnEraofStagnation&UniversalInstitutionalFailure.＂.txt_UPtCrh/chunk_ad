choices. It's not clear. And they probably are going to have some sort of psychological breakdown
in their future. The dating prospects aren't good. They're all these things that are a little bit
off. So in theory, if you had a super tightly controlled PhD program, that might work, but you
have to at least make those two changes. As it is, the people in graduate school, it's like
Trebles and Star Trek. We have just so many, and they all feel expendable and
unneeded. That's not a good place to be. Whereas I think the undergraduate concede is
still that it's more case-selected instead of r-selected, that it's more that everybody is
special and valuable. That's often not true either. So I'd be critical of both.
If we could have a real PhD that was much harder and that actually led to
sort of an academic position or some other comparable position, that would be good. One
of the questions I always come back to in this is, what is the teleology of these programs? Where
do they go? And one of the analogies I've come up with is, I think elite undergraduate education
is like junior high school football. Junior high school football. Did not see that coming.
Playing football in junior high school is probably not damaging for you, but it's not going
anywhere. Because if you keep playing football in high school and college and then professionally,
that's just bad. The better you are, the more successful you are, the less well it works.
Then the question is, what's the motivational structure? When I was an undergraduate in the
1980s, there was still a part of it where you thought the professors were cool. It might be
something you'd like to be at some point in the future. And they were role models just like in
junior high school football. And an NFL player would have been a role model 30 years ago.
But now it just looks like brain damage in both sense.
And now we think you're just doing lots of brain damage. And it's a track that doesn't work. And
therefore, the teleology sort of is broken down. So undergraduate part of the teleology was that it
was preparing you for graduate school. And that part doesn't work. And that's what's
gotten deranged. And then graduate school, well, it's preparing you to be a postdoc. And then,
well, that's the postdoc apocalypse or whatever you want to call it, postdoc ellipse.
Postdoc ellipse?
Postdoc ellipse.
You heard it here folks, postdoc ellipse.
But just at every step, I think the teleology of the system is in really bad shape. It's of
course, this is true of all these institutions with fake growth that are sociopathic or pathological.
But the university's, its striking is very bad. And I think this was already true in important
ways back in the 80s, early 90s, when I was going through the system. And when I think back on it,
I think I was most intensely motivated academically in high school, because the
teleology was really clear. You were trying to get into a good college.
And then by the time I was at Stanford, it was a little bit less clear. By the time I was at law
school, really unclear where that was going. And by the time I was 25, I was far less motivated
than at age 18. And I think these dynamics are just more extreme than ever today.
What I find so dispiriting about your diagnosis is, first of all, that I agree with.
Second of all, if we don't train people in these fields, if we don't get people to go into molecular
biology or bioinformatics or something like that, we're never going to be able to find the
low hanging fruit in that orchard. So it seems to me that we have to find some way that it makes
sense for a life to explore these questions. One of the things that I don't understand,
and I don't know if you have any insight, go ahead and use it.
Go ahead, keep going. Well, what I was going to say is that
it feels to me that almost all of our institutions are carbon copies of each other at different
levels of quality, and that there are only a tiny number of actually innovative institutions.
It used to be that Reed College was Sex, Drugs, and Goethe. And you had St. John's
with the Great Books curriculum that didn't look like anything else, or Deep Springs,
and the University of Chicago was crazy about young people. But the diversity of institutions
is unbelievably low. Is that wrong? I think that's fair. But I would say, yeah, the bigger problem
with a lot of these fields is, yeah, I think we have to keep training people. I think we need to
keep training people in physics, or even these fields that seem completely dead. It's super
important. But I think the question we have to always ask is, how many people should we be
training? And my intuition is you want the gates to be very tight. One of my friends is in the
Professor of the Stanford Economics Department. And the way he describes it to me is they have
about 30 graduate students starting PhDs in economics at Stanford every year. It's six to
eight years to get a PhD. At the end of the first year, the faculty has an implicit
ranking of the students where they sort of agree who the top three or four are. The
ranking never changes. The top three or four are able to get a good position in academia,
the others not so much. And we're pretending to be kind to people and we're actually being cruel.
Incredibly cruel. And so I think that if there are going to be, it's a supply demand
of labor. If there are going to be good positions in academia where you can have a reasonable life,
it's not a monastic vow of poverty that you're taking to be an academic. If we're going to have
that, you don't want this sort of Malthusian struggle. If you have 10 graduate students
in a chemistry lab and you have to have a fist fight for a Bunsen burner or a beaker,
and if somebody says one politically incorrect thing, you can happily throw
everyone out of the overcrowded bus. The bus is still overcrowded with nine people on it.
That's what's unhealthy. And so, yes, it would be a mistake to say we should dial this down
and have zero people go through these fields. This is what's scary to me.
That's not what I'm advocating or what's being advocated here. But there's a point where,
if you just add more and more people in a starvation Malthusian context, that's not healthy.
Well, this gets to another topic which I think is really important and it's a dangerous one to
discuss, which is it seems to me that power laws, those distributions with very thick tails,
where you have a small number of outliers that often dominate all other activity,
are ubiquitous, and that particularly with respect to talent, whether we like them or not,
they seem to be present where a small number of people do a fantastic amount of all of the
innovation. What do we do if power laws are common to make people more comfortable with
the fact that there is a kind of endowment inequality that seems to be part of species
makeup? I don't even think it's just limited to humans.
Well, I'm not convinced these sort of power laws are equally true in all fields of activity.
When the United States was a frontier country in the 19th century,
and most people were farmers, and presumably some people were better farmers than others,
everyone started with 140 acres of land, and there was this wide open frontier.
Even if you had some parts of the society that had more of a power law dynamic,
there was a large part that didn't, and that was what I think gave it a certain amount of health.
Yeah, the challenge is if we've geared our society saying that all that matters is education,
and PhDs, and academic research, and that this has this crazy power law dynamic,
then you're just going to have a society in which there are lots of people playing video games
in basements or something like that. That's the way I would frame it. I think there are
definitely some areas where this is the case, and then we need more growth for the whole
society. If you have growth, you have a rising tide that lifts all boats. It's the stagnation
is the problem. Well, I've joked about this as we are not even communistic in our progressivism,
because the old formulation of communism was from each according to his abilities to each according
to his needs, and the inability to recognize different levels of ability. Almost every
mathematician or physicist who encountered John Von Ormans just said, the guy is smarter than
I was. It's not necessarily the deepest, or he did all of the great work, but you know when you're
dealing with somebody who's able to employ skills that you simply don't have. I know I'm not a
concert pianist. I don't know how you solve the social problem if everybody has to be a mathematician
or a concert pianist. I want a society in which we have great mathematicians and great concert
pianists. That would be a very healthy society. It's very unhealthy if every parent thinks their
child has to be a mathematician or a concert pianist, and that's the kind of society we
unfortunately have. Well, this is why I try to sell you sometimes on a more progressive
view of the world, which is I want deregulated capitalism. I want the people who have the
rare skill sets to be able to integrate across many different areas. To be honest, this is the
thing that I wish more people understood about what you bring, which is that you're able to think
in 15 different idioms that most people only have one or two of. Whatever it is that you're
doing to integrate these things as an investor into direct research and direct work is really
something that I've watched firsthand for six years. The problem that I have is we are going
to have to take care of the median individual. I less think that the median individual is going
to be reachable by the market over time as some of these things that are working in silicon in
terms of machine learning. Then you're being more optimistic on progress in tech than is.
I think, yes, look, if we have runaway automation and if we're building robots that are smarter
than humans and can do everything humans can do, then we probably have to have a serious
conversation about a universal basic income or something like that. You're going to end up with
a very, very weird society. I don't see the automation happening at all. I think the question
of automation in my mind is identical to this question of productivity growth. We've been
automating for 200, 250 years since the Industrial Revolution, agriculture and manufacturing.
The society we have in the early 21st century is one in which most jobs are non-tradable service
sector jobs that are not easily automatable. It's like a waiter in a restaurant. It's a yoga
instructor. It's a nurse. It's a kindergarten teacher. That's what most jobs in our society are.
They've been so resistant to automation that this may be one of the reasons why
the productivity numbers are slowing down. Even if we're still innovating as fast in
manufacturing and even if we're still improving agriculture, they're a smaller and smaller part
of the economy. Even 5% a year productivity growth in manufacturing, that means a lot more
than manufacturing 60% of the economy than it does when it's, say, 20% of the economy.
That's roughly what I think would happen. If you just look at the current dynamic in the US is
we have unemployment like 3.6%, 3.7%. It's super low. Still, there doesn't seem to be that much
wage pressure. There doesn't seem to be that much growth. The productivity numbers still
aren't great. You'd think there'd be an enormous incentive. It's quite confusing to me.
But I think, again, my read on it is just the automation story has been oversold.
I agree that the automation story has been oversold. It's possible it's going to happen.
It's possible it's just around the corner and it's about to happen. That's what we've been told
in a lot of these areas over the last 40, 50 years. I have a couple of questions about this. One is
if I think about how common retail occupations are, is there something about retail that is
resistant to Amazonification, if you will, where people actually want to go shop in a
physical place and are willing to pay a premium that we haven't understood to have human contact?
Maybe there's some information exchange. Maybe there's a recreational aspect that's bundled.
That's one of my two questions. The other one surrounds the idea that we've always focused
on when is AGI coming and the robots that will do everything. Part of the lesson for me about
machine learning is how many things humans were doing that don't require anything like
artificial general intelligence. Just some specialized neural net seems to be good enough
to do the job. So those would be two questions in my mind as to how...
Yes, but I think all these things, you have to concretize. And yes, I think retail is a sector
that's under quite a bit of pressure and is going to stay under quite a bit of pressure.
That's maybe the top one I would... It looks vulnerable to me.
Like Amazon is the most threatening of the big tech companies and that it's
threatening a lot of other companies elsewhere in the industry and disrupting them and making
things more efficient, but probably with a lot of sheer forces at work in that process.
So I agree that that's a candidate for automation or productivity improvements or things like that.
I'm still not convinced that it's in the aggregate shifting things that much.
And then we can go through all sorts of individual job descriptions where
people used to have secretaries because typing was a skill. And with the word processor,
you don't quite need this. You can do short emails. You don't quite need a secretary.
People still have executive assistants that somehow do a slightly different set of responsibilities,
but it's not clear we have fewer executive assistants than we used to have secretaries.
And so when one actually concretizes it, it's not quite clear how much
how disruptive the automation that's happening really is. It's always...
It's a version of the tech stagnation thing. It's always... Last 40, 50 years, things have been
slow. We're always told it's about to accelerate like crazy. That may be true. In some ways,
I hope that's true. But if one was simply extrapolating from the last 40 to 50 years,
perhaps the default is that we should be more worried about the lack of automation
than excess automation. That's really interesting.
And again, I think if we had the sort of runaway automation,
I mean, you could get to like 3%, 4% GDP growth. And at 3% to 4% GDP growth,
we can solve these problems socially. You would be willing to have...
This thing that I've been talking to Andrew Yang about has been the idea of hypercapitalism,
which is a deregulated hypercapitalism where you can do more experimenting,
more playing, coupled to some kind of hypersocialism where you recognize that the
median individual might not be able in the future to easily defend
a position needed for family formation.
Well, let me rephrase this a little bit. You're not going to get a conversion
experience on your first podcast here, Harry.
You're going to make me wait for the next?
Maybe. Maybe a little longer than that too. But I would say
if we can get the GDP growth back to 3% a year on a sustainable basis...
Without fudging.
Without fudging, without lying about productivity numbers, etc.,
then there will be a lot more room for various social programs.
I wouldn't want them to be misdirected in all sorts of ways,
but there would be a lot of things that we could do.
I would be very uncomfortable starting with the social programs
without the growth. That's the sort of conversation that I often see happening
in Silicon Valley where we start with UBI because we're lying about automation.
If automation is happening, then we'll see in the productivity numbers,
and then eventually maybe we need something like UBI.
If automation is not happening and you do UBI, then you just blow up the economy.
Right. I should say, and you've come somewhat towards...
Coming them, doing them in parallel, I'm okay with that.
Not okay with starting with the socialism.
So I appreciate...
Even a Marxist wouldn't believe this. Even a Marxist thinks...
You have to first get the capitalist to do things before you can redistribute stuff.
Right. I know.
And you can't start with the redistribution before we've done the automation.
I'm not even a Marxist, Peter.
But the thing that I was going to say is that as you talk about
the fact that we can solve some of these problems socially,
I want to talk about from the progressive side,
I'm not interested in using social programs where markets continue to function.
