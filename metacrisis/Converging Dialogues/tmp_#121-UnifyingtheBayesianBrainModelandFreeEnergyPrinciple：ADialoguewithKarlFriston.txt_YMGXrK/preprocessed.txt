Hello, welcome to Converging Dialogues. This is Xavier Bonilla. Okay, on this episode, I
am very pleased and honored to have the extremely brilliant Carl Friston. Carl is a theoretical
neuroscientist and pretty much one of the major authorities on brain imaging. He is a professor
at the Institute of Neurology at University of College London, consultant for the National
Hospital for Neurology and Neurosurgery in the United Kingdom. He has invented many aspects
of brain imaging, including the statistical parametric mapping, voxel-based morphometry,
and dynamic causal modeling. Much of these were used in schizophrenia research, which we talk about.
He talks about this in terms of his day job, and then he has his weekend job, which is trying to
find these theoretical models and structures of the human brain. One of these theoretical
neurobiological models is what he titles the free energy principle, which we talk much about,
which also has some connections with the Bayesian brain model. He is a fellow of the Royal Society
of Biology, and he has many honorary doctorates. We have a wide-ranging conversation about many,
many, many topics. This conversation is over three hours, and I was absolutely privileged to
get over three hours with him. He was very generous with his time and his energy and his mind.
We talk about everything. We first start by talking about the history of models of the brain,
over time there have been many models of the brain, and so he gives a history of what that
looked like. We talk about the evolutionary components of the brain and how executive
functioning and abstraction work with various organisms. We give an overview of the Bayesian
brain. We talk about predictive coding or Bayesian filtering. We talk about the two classes of
neurons for prediction error and for predictions. He gives a very, very nice comprehensive explanation
of the free energy principle. We talk about the importance of a Markov blanket and the importance
of equilibrium and homeostasis. We talk about the free energy principle and a little bit of
Freudian psychoanalysis and some of the connection there. We talk about his views on consciousness
and how active inference is in play. We talk about AI. We talk about the various neuroimaging
techniques that I mentioned earlier. We talk about fMRIs and some of their challenges there.
We also then end towards the end of the conversation with how the free energy principle could be used
pragmatically. I have to say this conversation is long, but it's very engaging. I found the
conversation to be very engaging. Even though it's pretty dense in some areas, I found it pretty easy
to track and follow along. Carl does a really nice job of explaining very hard and difficult
concepts in pretty easy to understand ways without losing the integrity of the concepts.
It definitely requires some attention because these are some really complicated ideas,
but I think it's super important. He's doing really important work both in his day job and the
imaging for the brain and then also his weekend job, as he says, for trying to understand
a theoretical framework and to understand that the neurophysiology and neurobiology
of how things work together and how this can interact with engineering, AI,
kind of computational neuroscience, neuropsychology, etc. Again, it was an absolute
honor and privilege to have him on the podcast and to give me so much time and energy. I'm very
pleased to bring you Carl Friston. I'm here with Carl Friston. Carl, it is a big honor and
a privilege, sir. So I thank you so much for coming on the podcast and being willing to talk to us
about your very important work and all of the things you've been researching. So a big thanks to
you. Well, it's a pleasure to be here. Thank you for asking me. Of course. So for folks that don't
know who you are, kind of give your potted biography, just give us the snapshot of who you are,
what you do, what you study and all of the all the particulars.
Right. I have my day job and my day job is a professor of neuroscience at University College,
London, with a special expertise in human brain scanning. So I originally trained as a psychiatrist
and got into the field of imaging neuroscience in an attempt to understand
disorders like schizophrenia by literally looking at the brain as best we could or as best we can
using modern technology. And then I have a weekend job, which is more of a theoretical
neuroscientist. And laterally, one could generalize that to being a theoretical biologist or a
bio mathematician, trying to understand the fundamentals of sentient behavior, the principles
that underlie the way that we make sense of the world that informs and is informed by the day job.
So the more you know about what the brain must be doing, the more you can start to
look at the empirical results from the brain imaging and understand the message passing
and the fluctuations in your electivity in the service of sense making.
Yeah, that's very, very important. I guess I do want to ask you about the imaging piece.
How did you kind of, I guess, stumble into this kind of way of doing the day job and the weekend
job? This is something that you mentioned you were trained as a psychiatrist, but was this
something that you always wanted to do? You were always curious about the brain and looking at
different ways of understanding its functioning. And then did the theoretical stuff kind of come
later? Or how did this kind of, I guess, morph into where you're at now and what you're currently
doing? That's an excellent question, which I could answer quickly or take a very long time answering.
Whichever way you want. Let's do the quick one. Now, I always wanted to do this. So what I am
doing now is really the denouement of a series of serendipitous and lucky career choices that
actually started around the age of 15 wanting to be what in those days would have been known
as a mathematical psychologist. So a dual commitment to understanding the most interesting
thing, which of course was me and my brain at that time and other people's brain,
but using a formal calculus, your principal approach. So trying to maintain a training and
investment in physics and mathematics, a sort of dual early career in psychology and physics.
And then went into psychiatry as the most alluring and I have to confess the easiest
way to become a medic at that point in time because everybody else wanted to be a heart
surgeon at that time. Everybody wants to be a GP nowadays, but my cohort, they all wanted to be
heart surgeons. So I ended up in psychiatry and very much valued that experience, but of course
it was exactly in the direction of travel in terms of what I ultimately wanted to do,
which was research into what would nowadays I guess be thought of as theoretical neurobiology
or computational neuroscience, but essentially the formal principles that underwrite our ability
to engage with the world and make sense of that world. Yeah, it's interesting the way you put
it because I think that finding out kind of how you, as you say, there's this serendipitous way
of falling into these things, which is I think kind of true for a lot of people, right? They have a
one way in which they want to do things when they're younger and then they take the long way
up the mountain. But the other thing is having a desire or passion to want to do something
to understand the brain and many people want to understand the brain. But then having the IQ
points and the capacity to do that, you've written some pretty prolific papers. And so
having the ability to do the equations, to do the math, to be able to do these things,
that had to be all of just when it kind of fit together, had to have been pretty remarkable,
I guess, for yourself to be like, you know what, I have this interest and I can actually
cognitively do this, I can figure this out. What has that, I guess, just been like as you
progress through your life and be like, you know what, yeah, I've done a few things,
I've researched a few things, I've figured some things out about the brain. If you kind of look
back on that, how does that just all kind of sit with you, I guess? I would imagine it's the same
kind of sense that people have when they look back on their lives. It's a long journey.
When you look at the journey in retrospect, you are sometimes surprised by how far you have come.
But of course, in pursuing at any one moment in that journey, it all seems very incremental.
So it seems unremarkable during the travel. Unremarkable in the sense that things change quite
slowly and are the reflection of the way that you've invested in the early parts of the journey.
So coming back again to this early commitment to a formal way of expressing ideas. So knowing
that meant that you have to spend many years learning quantum physics and probability theory,
which then you immediately forgot as soon as you went into psychology. At least you left with the
legacy that you knew you could learn it and you couldn't do it if necessary. And of course,
in later life, it didn't become necessary. But I repeat, I've forgotten everything I learned
as a 20 year old. But with the boon, the gift of Wikipedia, I was soon able to get back up to
speed again. So all of this prolific writing that is often claimed to be quite inscrutable
mathematically difficult to access that from my perspective is a nonsense. You can get all the
maths you need from Wikipedia, because that's exactly where I got it.
The power of technology is remarkable in many ways. So that's great. So obviously, I want to get to
your your main, your main, I guess, theoretical claim to fame, if you will. I mean, many claims
to fame, but I definitely want to talk about the free energy principle and just have you download
that for us and just tell us everything about it. And as much details you'd like, I figure before
we get to that, it might be helpful. And you can tell me what you think of this might be helpful to
kind of look at a history and overview of various brain models that we've had,
and how leading up to the the current brain model that we know, and then we can branch off to that
into the kind of Bayesian brain model, which which is also more relevant and salient at the moment.
So maybe if you could just in your in your from your viewpoint, how do we understand a history
of various brain models? Where does it kind of first start and originate? And, you know, you
can just kind of kind of march us through how that gets us to current day and what the current brain
models are. Well, yeah, that in fact, that would be, I think, one fairly comprehensive and complete
way of understanding the free energy principle, which is just a new month of a long legacy of
ideas that I think you could probably trace back to the students of Plato, and shadows on
caves and the like. But for me, most clearly articulated by Helmholtz in the 19th century,
sort of polymath, who had a deep understanding of physics, but also perception and, you know,
various aspects of of sentience. And many of his ideas essentially summarized in the form of
unconscious inference. So the notion that the brain was a constructive organ that was inferring
the causes of its sensations. So the idea here is that what is out there is not directly accessible
from the skull bound brain, but has to be hypothesized, you have to have the cause of
your sensations in mind, in order to use the sensory impressions upon your eyes, your ears,
your skin as evidence for against that hypothesis. So as Andy Clark would put it, this is very much
an inside out approach to perception, as opposed to an outside in view, which actually dominated
in the 20th century, but then went away again, where the the world impresses itself upon your
sensory epithelia, and you somehow extract information from that to get to the conclusion,
oh, this is the cause of my sensations. Helmholtz had a much more nuanced and veridical survey by
21st century standards, veridical understanding of the mechanics of perception, where you had to
actually generate the hypothesis, and then you just used the sensory evidence at hand to update
your beliefs, adjust your explanation for those sensations and in that adjustment, in the updating,
on the inside, through neural activity, you were able to produce an approximate or
partially faithful reproduction of what could have caused your sensations, and he called that
unconscious inference, that notion remained in abeyance through 20th century behaviorism,
manifesting in many different ways. Things that come to mind include analysis by synthesis,
one key contribution from psychology was the notion of perception explicitly as hypothesis,
testing, this is Richard Gregory, a UK psychologist's notion, again reiterating the importance of
inference, so for Helmholtz it's really unconscious inference, for Gregory it would have been,
you know, the perceptual act is basically a test of a hypothesis, that this visual object
is the best explanation for this pattern of sensory impressions, say on my retina. Those ideas
came to fruition in machine learning and computational neuroscience, I would imagine the
80s and possibly the 90s, probably best exemplified by the Helmholtz machine,
deferring back to Helmholtz's original ideas by Geoffrey Hinton and colleagues and Peter Dianne
and colleagues, so leveraging those deep insights from Helmholtz and then putting them into a
recurrent neural network or a network of a particular kind of Boltzmann machine,
effectively training neural networks in a way that we would now understand the training of
deep neural networks in deep learning, for example, to infer. We now understand that as
amortization if you were in machine learning, it would be this notion that you can train the
connectivity of a neural network to make sense by inferring the causes of its inputs because,
you know, it's a simple move to understand this scheme or algorithm of the Helmholtz machine
as also applicable to neural networks, and at that point in time people were converging on
very similar ideas from a slightly different direction, namely that of predictive coding.
So predictive coding was originally devised in engineering as the most efficient way to
compress sound files in the 1950s. There's an interesting connection here between the notion
of compressibility and efficiency and the statistical efficiency of a good inference,
which we may well come back to in relation to the conversation, but at this stage in terms of
the history and the legacy, there was in the 90s a key convergence on the brain as an inference
machine and the brain as a predictive machine. So we then see the emergence of predictive
processing or predictive coding in particular, perhaps just for your listeners just to make
this a bit more explicit, the predictive coding is defined in terms of a scheme that is trying
to resolve prediction errors. So we have this notion now of the brain generating top-down
predictions on the basis of its currently preferred beliefs about the state of the world.
Those predictions then compared with the sensory input and then the mismatch or the
divergence between the predictions and the observations, the sensory samples, are then
denoted as a prediction error. And then that prediction error is a broadcast deep into the
brain's hierarchy to update and revise the hypotheses or the representations that are
generating the predictions. And I use the word generation there because all of this machinery
or this message passing with sense-making comes under a particular generative model
that is entailed by the architecture of the brain. So you have this picture now of the brain
broadcasting from the inside out descending down the hierarchy its predictions and there's
a counter stream of ascending prediction errors that are revising and updating the
predictions in virtue of changing the representations that can also be cast in
Bayesian terms as Bayesian belief updating. So now you've got another church of mathematicians,
theoreticians in the game, you've got the Helmholtz machine, you've got predictive coding people
from engineering and also people start people like Simon McLaughlin and
Raj Reo and Dala Ballard noted that these predictive coding principles were very apt to
explain a lot of the functional architectures of the brain. David Mumford I think was a key
contributor to those ideas in the early 90s and is not usually acknowledged as such but you know
if you go back in very early 90s you're very explicit and what proved to be a visionary account
of the neuronal architectures that did the job of the Helmholtz machine that did predictive coding,
did hierarchical Bayesian inference. So then you have the joint emergence of Helmholtz machines,
machine learning, the Bayesian brain hypothesis in the neurosciences and predictive coding as
a particular process theory that sort of enacted this. So that was a story at the end of the 20th
century at which point there was an enacted term, a turn back to the forees, the importance of
situated cognition, the importance of the fact that you have a body, that your perception is
an active thing. You actively help hate the world at every level, every sensory modality,
whether it's literally feeling a way around the dark room to confirm your hypothesis about
this is a telephone, this is the bed, this is my iPhone through to palpating the world visually
through active vision, moving your eyes around something. This part of the visual scene to test
this hypothesis or that hypothesis. So this embodied inactivist extended and by extended here
ones acknowledging that a lot of your cognitive abilities are downloadable into the environment.
The key thing here though is this inactive term. So how did predictive coding,
the Bayesian brain hypothesis survive the inactive turn? Well, very, very simply that there are two
ways that you could effectively resolve your prediction errors. You could either literally
change your mind in the good old fashioned predictive coding way, use your prediction errors
to drive a change of mind of Bayesian belief updating. So the predictions now were more fit
for purpose and expanding where the sensory inputs and thereby the prediction has effectively
canceling themselves, resolving themselves through this hierarchical message passing the brain.
Or, and here's the twist, you could literally go and resample the sensory input to make it match
your top down predictions. But now you have a really simple and a very plausible account of
active sensing, active vision, more generally active inference. There are two ways in which
you can resolve prediction errors. You can either change your mind or change the thing you're predicting
and thereby supplying the predicted outcomes. So this is a very simple account of action and
perception, and also speaks to the circular causality. You know, these are two processes working
hand in hand, your perception is causing action and action is causing perception. And this is how
we sense make. So that that sort of active inference perspective, which then I think
became sort of the dominant paradigm, the cognitive neurosciences under the root because
something called predictive processing, which was a sort of generalization of predictive coding to
accommodate this inactive aspect of perception. So the free energy principle on one reading
really is just a mathematical specification of this kind of active inference. The trick
here is to cast things in a most general and generic way as possible. And by things,
I just mean the resolution of prediction errors. And the way that you want does that is by appealing
to the maths of Bayesian inference, and noting that exact Bayesian inference is not physically
realizable. And you then have to turn to how can you physically realize
inference of this sort. And the solution was in fact
on offer from the 1950s from people like Richard Feynman in western
and physical sciences, but also hints at exactly the same solution in the early Russian literature
in terms of algorithmic complexity and comore graph complexity. Those two perspectives converge
upon exactly the same mathematical quantity, which is a variational free energy. This is
not a thermodynamic free energy. This is just a statistical way of measuring the thing that
you want to optimize in any active inference, whether it's your brain doing inference about
its sensations, or whether Richard Feynman, you're trying to infer the probability distributions
under the paths of small particles in quantum electrodynamics, whether you're trying to infer
the message that was sent in cryptography, for example, all of these kinds of problems
could be subsumed under one optimization process, which is the maximization of Bayesian model
evidence. It's literally the likelihood of these data being generated by the model that you're
currently considering. So that's in Bayes' statistics known as Bayesian model evidence,
and the variational free energy provides a tractable bound or approximation to that
marginal likelihood or model evidence, which means that in its most general form, the problem of
inference, and indeed the process of inference, if you don't want to consider a problem,
can be written down mathematically as any process that either maximizes marginal
likelihood, model evidence, or if you're in machine learning, maximizes free energy as an
evidence lower bound to also known as an elbow ELBO. There's a slight wrinkle here.
In machine learning, they use the negative of free energy that Feynman used. So if you
haven't talked to physicists, you would want to minimize your free energy. If I'm talking to
machine learning people, you want to maximize it. It doesn't matter from our point of view.
The key thing is that you're just writing down the functional, the mathematical form
of the quantity that underwrites the process of inference, that is a variational free energy
in optimizing, either minimizing or maximizing this, either by perception or through action,
then you are effectively self-evidencing. And that's a term which I like from Jacob Owen,
that comes from philosophy, that if we understand ourselves as making sense of the world,
through a process of inference, that implicitly what we are saying is that we are all in the game
of garnering sensory evidence for our models of that world. So we are literally self-evidencing,
and you can just write that down as the process of maximizing Bayesian model evidence for your model
entailed by your brain and your body, or you can write down as a physicist in terms of
minimizing a variational free energy, and that's the free energy principle. And that's roughly
where we stand at the moment, although there are lots of unanswered questions and construction.
You laid out very, very nicely. It's very easy to follow there. I do have many follow-ups here
about a few things. I'll try and keep them very general and reframe some of what you said.
So starting with Hemholz, you were talking about how there's this inside-out
and outside-in, that there's almost a dichotomy in how we understand the world. Do we understand it
from within ourselves and then based on what input, outputs, inputs, inputs, whatever way you
want to describe it? And maybe that's just how it's fallen out. Is it always kind of in these two
camps or categories? Or is there a third or fourth way? Is there another way where we could see
a kind of mixture where it's not exclusively outputs from the environment, or excuse me,
inputs from the environment, and then we output? Is there some way in which we can understand that
there's a third way or a fourth way or other ways in which these are combined and where it isn't just
input output, right? It's not just a kind of zeros and ones kind of thing. Is there another way in
which there's an integration of them, or potentially some way of the phenomenology of
how we're experiencing things? Is it always this kind of way and how it lays out? Because it seems
throughout time, as you were saying with Hemholz, there's this kind of dichotomy where people will
kind of look at the economy here and then all the way to the machine learning stuff in the 90s,
it kind of does this oscillating back and forth between where do we put the emphasis? Where do
we put it first? So I guess that's one component. The second piece here when you were talking about,
if I understand this, is the free energy principle from what you're saying sounds like it's the kind
of quantitative and statistical ways of understanding the Bayesian model of the brain.
And so they're kind of seen in tandem along with the active interference, which you explained.
Connected with that, there's this emphasis on perception, especially with humans.
So I wonder with the predictive types of elements that you were discussing,
where do we, this might be a little bit further out, and maybe some of this may be hard to know,
all of this is very human. I wonder if we understand some of these things for non-human
brains as well, such as with chimps or bonobos or even other types of, it might not even be
with primates, it could be what do we understand about how potentially
these workings of the brain could be for other brains that are non-human. So trying to look at
a kind of evolutionary structure and model. And then finally, curious about if you have any thoughts
about, you mentioned philosophy and as you were saying that there was this kind of in the 21st
century now, not just an over emphasis on the brain, but how the brain and how it works
is distributed through the body and how the body is a necessary component,
which automatically always makes me think of philosophy of Merleau-Ponty, who also
thought a lot about perception. And in many ways had very technical ways of thinking about
perception. He talked a lot about eyes, talked a lot about sensations. And I wonder
his estimation, he was looking at the phenomenology of things, of how do we understand
experiences through the body, that the body is a necessary or as a prerequisite of sorts as a
type of bridge for understanding our various perceptions. So those are my follow-ups. I
don't want to throw it all at you at once, but any thoughts about any of that, I guess.
Right. You've just thrown all three massive issues at once. All wonderful issues. So we have to
say at least something about each one of them. So in order then. So is there a third way that
does not commit to an inside-out information extraction or an inside-out construction versus
a constructivist approach versus an outside-in-extractionist approach? In a sense, that just
is the Bayesian brain. That just is the free energy principle, an active inference that is
entailed by the free energy principle, because that is explicitly saying you have to have this
two-way traffic. And this emerges in many different levels. So for example, we've already talked about
this sort of recurrent two-way traffic of message passing in the brain from the
the sensory parts of the brain to the deeper hierarchically organized levels of a
the brain's generative model. This whole belief updating, this whole Bayesian mechanics depends
upon this counter-stream of top-down predictions and bottom-up prediction errors on a predictive
coding architecture view. So you've got this recurrence, you've got this circular causality
for free, but even more generally, as you intermitted in the third issue, you brought to the table
here, the very dependency of perception on action and action on perception. So put simply,
I have to perceive and infer in order to plan what to do next. So action is predicated on my
perceptual synthesis and making sense of the current state of my body and the world and what I
want to query the world about, what kinds of questions, what kind of information do I want
to get by deploying my sense organs. So that is all the self-evident, but in the same way that
action depends upon perception. Perception also depends upon action. What I see depends upon
where I look, how I place my skin in relation to an object that I'm trying to palpate.
So there's this unbreakable circular causality and two-way street between action and perception.
So I would submit that your quest for the third way has been delivered
for you by the inactivist term, by the inactivist application of too predictive coding
to the brain hypothesis at the turn of the century. I think that is the third way.
You can't tease these two things upon, really. So that should be comforting and it should resolve
any angst that might be seen. It's very satisfying, yes. Good. Now the second issue,
what was the second issue? The second one was about the non-human brains, the evolutionary construct.
Yeah, the way that you asked that question makes me realize I've made a fundamental mistake here
in terms of telling the story and unpacking the narrative of
actually the inference in its 21st century version. So most of what I've just
talked about in terms of the mechanics of inference and optimal action
could be applied to a thermostat or a virus. So I think I would actually put the question
the other way around. Perhaps that's how you actually meant the question. I'm sure that we'll
come to this later on. What is special about the human brain that has some unique and definitive
properties that you would not find in a thermostat that you would not find in a virus,
you would not find in a mouse. You possibly wouldn't even find it in your most blood pet
or some of our closer companions and say monkeys in the evolutionary view.
So I think that that's the direction the question should be approached. It's less,
what's special about mice? It's more how do you make the move from mice to men under this kind of
architect. So most of the work that we do is at a much lower level. It's just trying to understand
the fundamentals of active self-organization through the lens of sense-making and inference
that can be written down as a process that usually is actually an emergent property of
any self-organizing system that preserves a distinction between itself and the environment
that doesn't decay, dissolve, dissipate, die. So looking really, trying to explain how on earth
does a virus survive and what must it do in terms of this circular third-way exchange between the
inside and the outside to preserve its very boundaries and demarketing from its external
milieu without worrying too much about what it is to be human. So we haven't got anywhere near a
sort of Marx-Semes-like set of questions yet. We are not talking about Bayesian beliefs as
propositional beliefs that you and I might hold and be able to articulate. We are not talking
about qualitative experience. We are just talking about the mechanics of belief updating on
neuronal circuits, neural circuits, chemical circuits, electrochemical circuits that we see
in every kind of biotic and possibly even nonbiotic self-organization. So that's a deep question.
And the answers to that question take you through a series of natural kinds of things
that all are doing some inference of possibly a weak kind and can all be, if you like,
described in terms of an ontology of generative models. If you remember before we're talking about
the underlying importance of a generative model in supplying the architecture under which you
generate your hypothesis, your top-down predictions, and you use basic, this is the thing that you are
securing evidence for, which means that if there is a difference between mice and men,
then there has to be something quintessentially different between the generative models that you
and I employ to navigate actively our world and those that mice and flies use. And once one starts
to think about it, one might ask what is the difference between a, let's take viruses, flies
are a little bit too sophisticated. What's the difference between a mouse and a mouse?
And what's the difference between a mouse and me or you? And normally the story goes that
it's all to do with the ability to plan. It may sound very, very simple, but once you've heard the
argument, you know, it is actually a very simple argument, but it's also quite a compelling argument
and has a degree of explanatory scope in the sense that the thing that distinguishes between a
thermostat or a virus or some single that cell organism succumbing to nutrition gradient through
chemotaxis relative to something like a mouse that does stuff in anticipation of consequences
is the ability of the mouse to plan. The mouse can think about and select those actions that
have consequences and that's absolutely profound when it comes to writing down or thinking about
the generative model that that mouse is using. It tells you immediately that the mouse has a model
of the consequences of its action. If it has a model of the consequences of its action,
given that the consequences occur after the action, then it also has a model of the future.
So it now has a model that has a temporal depth and this can be contrasted with the thermostat
or a virus. It does not, the thermostat doesn't have a model of the future. It doesn't have an
explicit hypothesis or question in its internal machinery of the kind. Or what would happen if
I switch this heat making device on or not? It just responds reflexly in the moment. But the mouse
will have a much more elaborate model, sometimes described as a model with temporal depth that
frees you from the moment, but also crucially underwrites ability to plan and thereby select
from one plan or another plan one course of action relative to another course of action.
That endows that middle agent with agency because now it is selecting amongst a number of different
courses of action that are entertained and can be supported by its generative model. So now together
you've got this sort of move from a thermostat to a mouse that entails the notion of agency and
temporal depth simply because this generative model has the ability to model the consequences of
action. So that's one move. Does that give you qualitative experience? Does that give you propositional
beliefs? Do we have mouse philosophers who spend their time puzzling about why they see red and
does one mouse see the same red as another mouse? No, absolutely not. So we still haven't answered
the question. What's the difference between a mouse and a man? Sorry, just on the mouse thing,
it sounds like what you're describing in the ability to have some planning sounds like there's
at least a low level type of what we would call executive functioning, where there's
abilities to plan, organize sequence, which we normally see in the prefrontal cortex for humans,
but it seems like it's a very low level ability, whereas as we get to humans, there's a much
deeper level of abstraction that we understand. Is this about right? No, that's exactly an
absolutely right. So all I'm talking about here is exactly the prefrontal cortex and all the attendant
executive machinery right down through some supplementary motor area, pre-motor cortex,
motor cortex down to the brainstem and all the executive components that are responsible for
executing the plans that are elaborated through selecting the right course of action in the
prefrontal cortex. So that's exactly right, and that's what mice can do. We don't have quite as
well developed a prefrontal cortex as we do, but they have the equivalent capacity to execute plans
simply because they need to have that because they have plans in their head, but having plans in
their head is a remarkable capacity. A thermostat, I repeat, does not need to have a plan. It just
responses a reflex as do many forms of life or biotech self-organization.
So you also used a hierarchically deeper levels of abstraction. I think that's the absolute key
here. And then this question would be, well, what are you hierarchically abstracting? And I think
most people would answer, well, you are now creating models of your executive process. So now a mouse
has the ability to plan and to execute those plans by selecting the plans that are most plausible
in the sense that they will resolve surprise or prediction error or free energy in the future,
we call that expected free energy technically, which has some interesting aspects to it.
So the mouse then has this ability. So what ability do we have because of our more evolved
prefrontal cortices with these deeper levels of abstraction? Well, it could simply be to
entertain the hypothesis that I am a person who is now selecting these plans, and it is me who is
actually executing these plans. So to a genitive model that now entertains the hypothesis, the
belief, the representation, that it's me doing these things. It is me who is embodied. It is me
who is the agent. So an agent doesn't need to know that it is an agent to actually plan and
execute those plans in the same way, though the thermostat doesn't even know it's a thermostat,
and that it's even acting. So I think that the levels of abstraction you're referring to here
are exactly the abstraction and the plausible hypothesis that in fact I am an object, and
indeed I am the subject of my own observations and actions, and having that hypothesis as part of
the genitive model now has to be explained. And how can it be explained? How could it be that I now
have a better genitive model or explanation of my sensorium that has been actively constructed
simply by having this notion that I am a person. And I think there are quite simple answers to that
because of course it's not just I am a person. I'm a person in this police state, on that police
state, on that emotional state, or this intentional proposition state. And once I recognize myself to
be in that state, and implicitly now I have a degree of qualitative experience of my inference
there in the hierarchy, then I can now bring to bear and contextualize all my message passing an
inference conditional upon my now recognized state. So for example, if I know that I am anxious,
or I am embarrassed, I know that there will be certain kinds of information to which I would
be paying attention. There will be certain sort of autonomic actions that I would normally be
engaging in this context of being embarrassed or being frightened, such as cardio acceleration,
or paying particular attention to auditory and visceral streams, for example. So there is
an easy to argue benefit for having these higher levels of more deeply abstracted representations
and explanations for the active inference and all the message passing that's going on
underneath. And I think if you go right to the top of the hierarchy, to the very highest form
of human life, which would be a philosopher, what you find there are representations and hypotheses
that just are quenia and qualitative experience. So this is touching on now
something which David Chalmers as popularizes, the meta-problem or the meta-hard problem,
is why do we puzzle about our qualitative experiences? I don't do that. So what special
aspects of our generative models can explain the very fact that we can entertain notions like
being a zombie, for example, thought experiments like brain and a vat. The very fact that we can
entertain these counterfactual outlandish hypotheses about self is the gift, if you like,
of having these deeply abstracted representations of how we engage with the world. First of all,
just having a representation of me or selfhood and then me as an actively inferring agent
that must in some sense have some internal action over the way in which I secure the evidence and
test my hypotheses. I'm trying to work here to something which I think Mark Somes may have
talked about, which is what underwrites the feeling part, the qualitative experience
that the philosophers talk about in terms of quenia. The essence that we think we can
entertain and have discourse about, that perhaps a mouse might not be able to talk about. It may
have, but it wouldn't be able to recognize it or talk about it. It's just not there. It just can't
see that kind of thing. In the same sense that a blind person can't see color, it may well be
that a mouse just does not have these hierarchical levels of abstraction. So it's just not perceivable
in the sense of health holds. You have to have it in mind before you can sense it.
The answer that somebody like Mark Somes, I think a lot of people would bring to the table here,
is the notion of confidence or precision or a representation of uncertainty in one's beliefs
and getting that right. That basically entails a kind of mental action. So now we're talking about
action, not on the outside, not autonomic actions like secreting something or cardio acceleration.
We're not talking about motor actions, motor reflexes, moving my limbs around with my
straightened muscles. We're talking about a covert internalized action,
where some very, very high levels of a hierarchy or very deep levels, perhaps at the center of the
brain from Mark Somes' perspective, have an influence on the belief updating that underwrites
the action selection. That influence is really a statement that we're able to represent our own
beliefs. We have beliefs about beliefs. A particular example here is we have certain beliefs about
our beliefs that pertain to the uncertainty. So if you have in mind the simple mathematical
description of a belief as a probability distribution, so when people talk about Bayesian
beliefs, they repeat, they're not talking about sort of ideological or theological commitment.
They're just talking about the brain as a sentient artifact that is somehow encoding a
probability distribution. Invariably, these kinds of beliefs, these Bayesian beliefs or
conditional probability distributions, have two cardinal aspects. They have a location,
so the most likely thing I believe, or the Bayesian belief entails,
is designated by the peak of the probability distribution, but there's another shape parameter,
another aspect of this probability density or distribution, which is its spread or dispersion,
and that's usually understood in terms of uncertainty. So a very broad distribution means
all of these things could be in play, whereas a very sharp, very precise distribution means that
I'm pretty confident that it's just underneath this very sharp distribution. So that precision
is a really important attribute of the belief, and if parts of the brain now have beliefs about
beliefs, they are now predicting precision, predicting predictability, and that may well be
the thing that calls for covert mental action and the need for recognizing that I'm in this
belief state, on this state of uncertainty, on that state of uncertainty, and then I can now deploy
the appropriate beliefs about beliefs or predictions of predictability or predictions of precision.
Yeah, it's interesting on that last point, because you're sounding like you're describing
as this type of metacognition that's interested in our own epistemology and also our ontology
as well, that we're very concerned about our beliefs and how we have these beliefs about them,
or even things about our own existence or things about us, who we are as beings.
One other point I wanted to make about the abstraction piece is that I totally agree,
obviously, but I think even more miraculous, if you will, or more wonderful is the fact that for
humans, not only can we have these levels of abstraction, but I always think of this example
of like, you know, I can know that I'm thinking about a concept or I can know that someone else
is potentially thinking about a concept, right? There's this way of abstracting with the other.
But even further, if you take works of fiction, let's say, let's say I'm reading a novel and the
central character is thinking about a thought he had in a dream that he had, and I'm the one
reading that thought that someone wrote. You have like six layers of abstraction there, right?
This is a very big, big, big, wide lens of things, which is incredible. It's incredible. Our mind
doesn't fold up because of how complicated or complex that is, and I don't know if other
animals on the planet can, you know, read novels and get the whole contractory if people watch a
movie, right? And they can see or observe all of these things. So it's very interesting about
the abstraction. And I liked how you linked with the various components of executive functioning
for detailing that. We've talked a lot about the Bayesian brain, and we've mentioned many components
of it. Maybe we can give for listeners the kind of overview of the Bayesian brain, and then that
will kind of dovetail into the free energy principle, and I'll give you a lot of runway for
that. You can talk all about that. So you correct me if I'm wrong. My limited understanding of the
Bayesian brain is that the brain is essentially equipped with an internal model of the environment,
and that gives us a plan for how we create sensory observations from hidden states, right?
That's one way of saying it. And that there are these hidden variables that are from a prior
distribution. You could say maybe, I don't know, if you want to use a Freudian term, the unconscious,
we can come to Freud at some point. And then also that these sensory observations
are have a distribution conditional on the hidden states. So then you have these priors,
and you have a likelihood combined to infer the hidden state given the observations.
So I think the clarifying point here is that these aren't specific claims about priors and
likelihoods for an individual, but more so on the consistency of them. That's my very limited
scope of the Bayesian brain. So maybe kind of branch off of that and just kind of give us the full
overview of what we mean by the Bayesian brain priors, likelihood, hidden states, and then we
can jump into the free energy principle. Right. And I mean, that description was spot on in itself.
So all I need to do is to connect what you've just described to what we're talking about. So
I think that we basically have done the Bayesian brain. And we've done the finest and most delicate
aspects of the Bayesian brain under a hierarchical genetic model when you started talking about the
other six degrees of hierarchical embedding. And I'm glad you use the word metacognition.
So that's what I was trying to imply when I was talking about beliefs about beliefs.
This is exactly it. And it is this hierarchical recursive embedding, which is quite remarkable.
I kind of will use the word fall down or unfold, but certainly at about six degrees of
recursion, my brain gives up. And I think at that point here, that may be the explanation
for the better hard problem that even philosophers can't quite handle that. And that residual
puzzlement, you know, inspires us to try and get to the seventh or the eighth. But it is exactly
that sort of beliefs about beliefs about beliefs. The other key thing you just brought to the table
before just unpacking the Bayesian brain in the language and the setting that we've already
established, you brought another really key thing to the table, which is inference about others.
And I was tempted to say, well, perhaps that's one aspect of the third way that we haven't talked
about. We haven't spoken about them. And perhaps we should have spoken about because
everything that we've spoken about thus far would work for a single agent in a universe that did
not have anything else like it in that universe. It's just making sense of a universe. But of
course, most of the interesting questions in terms of self understanding are in light of
or contextualized by the need to understand others. So we're now moving from the Bayesian brain and
beyond that to the embodied Bayesian brain, which is the third issue that we still yet to talk about.
But now to multiple Bayesian brains in an ensemble, all trying to infer each other.
And that brings some really interesting questions to the table about
self understanding in relation to others understanding. And there could be an argument
that the need for selfhood or an explicit ability to recognize I am a self and to have at least
a minimal selfhood is just a product of being required to disambiguate the causes of my sensations
in terms of did I cause that or did you cause that or perhaps more practically more relevant
would be during very early neonatal experience. Did I cause that or did mother cause that? So
mother being the key other and this being able to first of all recognize that mother is actually
an object out there that is distinct from me is a great move to be able to do and something that
takes you a long time for a neonate to and not every neonate recognizes that and can learn
the appropriate character models that explains interactions or our interactions with mom
in terms of mom being a creature. Because once you realize that mom is a creature on an object
out there, then the natural hypothesis might be to entail well perhaps I am a creature and why
would you need to do that? Well you need to do that to disambiguate did I cause that or did mom
cause that? So that elemental theory of mine that ability to distinguish between the causes of
sensations in terms of self versus other may be unique to creatures that have a universe or an
environment that is populated by creatures like them such as you and me. So I think this is a really
key aspect of this sort of self evidencing self evidencing yes but it's in the context of a whole
world comprised of things which are just like me so I have to now be very skilled and differentiating
me from you and in so doing of course that pressure is only evinced if you are sufficiently
similar to me and cause the same kinds of sounds and edited touches and sensations that I could
cause. I don't need to do that given that you are physically very similar to me but if you're
that similar to me I can now use my gelatine models my explanations of the world to explain
which I would normally use to explain my autonomic dispositions and you know my bodily
sensations or my movements. I can now use those prior beliefs selections of the plans that we
were talking about our intentions to explain your intentions or more specifically to explain
your behavior your facial configuration your micro expressions your physical stance
in terms of your intentions which would be the tensions I would have to have in order to witness
and you know to manifest the same kind of observable behaviors. So I think that you know that's a
really important thing you brought to the table when you know in terms of self-hood
and self-evidencing or being particularly acute and important in the context of you know a world
that has a culture that is born of the fact that we are we popular that world with lots of
conspecifics and we have a you know we have a shared eco niche in which to do that. So I just
wanted to put that on the table because it's a really important sort of thing when it comes to
sort of interpersonal exchanges yeah absolutely and but the base you know back to the basic
brain well you just summarized it I mean I don't you've done all the heavy lifting there I think
probably best is to say out loud at this point there is nothing that the Bayesian brain brings to
the table we haven't already spoken about it's just a way one way of articulating the kind of
sense-making where we have say prediction errors sending the hierarchy from the from the
sensory cortex the sensory parts of our brain and updating representations
that would be in a Bayesian sense regarded as posterior beliefs so what I'm going to do now is
just tell the Bayesian brain story from the point of view of somebody who likes to talk about
predictive coding we've already established predictive coding predictive coding I should
just add if I was talking to an engineer I wouldn't use the word predictive coding I would use the
phrase Bayesian filtering the simplest instance of a Bayesian filter is something called a
Kalman filter which is used widely in state estimation so predictive coding just is
Kalman filtering of an extended and nonlinear form sometimes known as an extended Kalman
bucey filter of a hierarchical sort so these things are all the same but different people
like to use different language so what would how would you understand Bayesian inference
from the point of view of predictive coding well as you say Bayesian inference is just
the process of belief updating how would you articulate that from the Bayesian brain hypothesis
well that update is just an update to your Bayesian beliefs your conditional probability
distributions prior to seeing some data to some beliefs after or a posterior so you're
just updating your prior belief to your posterior belief you're literally changing your mind
you're just moving through changing your activity or weights or connection strengths in your brain
you're changing the implicit or encoded Bayesian belief from a prior belief before you saw the
data to a posterior belief after you saw the data and that movement from one belief to another
belief literally changing your mind is the updating that is driven by the prediction
errors so the next question then would be well what is the nature of that updating
as we if you like mix together the prior belief and the light the information afforded by the
likelihood of these data to produce the posterior belief so that's just to explain to the listeners
why there were three kinds of beliefs there's a light distribution a prior belief and a posterior
belief and really the likelihood if you mix together the prior belief and the likelihood
and the likelihood then you get the posterior out so the likelihood stands in for the
pressure or the forces applied to changing your mind that drive a change in mind or
the belief updating that are afforded by the data and this is I think a useful view
because it allows us to come back to this notion of precision
it's difficult to do without a whiteboard or a blackboard
but let's have a go because this is I think an intuitive and really important
important observation which brings us back there's a mental action and the notion of
predictions of precision so if I had a very very vague imprecise prior belief
and I had some very definitive very precise sensory evidence that could be of an elemental
sort like the particular pattern of visual impressions in a well-lit room or it could
indeed a more abstract level be some definitive information from Wikipedia
but if it's very precise then that precise likelihood will have a very sharp narrow distribution
and will pull the soft flat prior distribution much closer to the likelihood
so that my posterior now is now dominated by the shape and the form of the likelihood
so I've induced a much greater degree of belief updating I've changed my mind considerably more
than I would have done simply because I ascribed a greater precision to these data
so it had a much more precise likelihood conversely if I have a very very precise
prior belief that is based upon lots and lots of experience then it's going to be much less
sensitive to any likelihood or any belief updating so my posterior is going to be
if you like tethered to my prior belief as I changed my mind and I moved from my
prior to my posterior when seeing the evidence doing my basing belief update in according to
baserall I will move a much smaller distance from the from the prior belief so the precision
afforded both the prior belief and the likelihood in fact it's the balance the ratio of the two
becomes a really important quantity in any basing brain or any basing scheme in engineering
this would be the Kalman gain for example is how much gain do I afford prediction errors
in updating my estimate of the hidden state that I can't see so that places this this notion of
the the encoding of and the predictions of the optimization of precision center stage in the
basing brain you see this in many many cases you can see it in the context of multisensory
integration so how much precision do I thought do I afford the visual evidence relative to the
auditory sensory data if I'm in a very very well lit room I might ascribe much more precision to
the visual information and that will dominate over my belief updating and my beliefs will be
driven by what I see and on what I hear but if I reduce the precision of that of that visual
information those visual prediction errors and switch off the lights are now in the dark room
that now becomes very imprecise and now the most precise influences of my posterior beliefs
are going to be the the auditory modality so I'm going to listen very very carefully in a dark room
I'm going to pay attention to the auditory sensations not the visual sensations so that
I've used the word attention deliberate because this from a psychological perspective what we're
talking about is deploying the precision in the right way in the right context just is attention
it's what we attempt to and that attention can operate at any level in the hierarchy can be
sort of attention grabbing stuff in a particular quadrant of my visual field some flutter which
is unexplained that can now draw attention at a very low level in the hierarchy or I could
be deploying attention to a very very high level of the hierarchy in terms of who I'm going to listen
to next or who I'm going to place an epistemic trust in what news channel I'm going to select
next so this process of selecting by assigning or affording precision to this or that is this
exactly this mental action that we were talking about before it's just deploying attention in the
right kind of way and that attention mediated through the precision of either prior or likelihood
beliefs has a profound effect on the degree to which I change my mind so it's a really important
aspect of this belief updating at the at the neuronal level the predictive coding theory
it has two classes of neurons which is the prediction neurons and the prediction error
neurons you've mentioned this already but I'm just asking at the neuronal level this is what's
happening within the neurons there you have these two classes of neurons that are essentially
weeding out is this a prediction and how are we parsing out some of the prediction error this
is what's happening at the neuronal level no absolutely and it's nice to you sort of ask
that question because that allows us to connect this predictions of precision or predictability
that underwrites optimal belief updating and Bayesian inference to pharmacology and to the
kinds of neurochemicals that may be aberrant saying things like schizophrenia or depression
or autistic autism and ASD and also implicate all the drugs that have a psychoactive aspect
from psychedelics through to the kinds of drugs that people prescribe for say psychotic depression
so yeah let's just unpack that so now we're going we've done the the Bayes rule and the Bayesian
brain with within our mind's eye free probability distributions or being mixed together in the
right kind of way according to their dispersion on their width but now let's say well how would
that be implemented in a in a Bayesian brain well the implementation just is a Kalman filter it's
just a predictive coding what would that look like well on one view as you say it would just
involve two kinds of populations one encoding the prediction error and the other encoding
the expectations or the hypotheses representations that are generating the predictions that are
sent down to form the prediction error so this again speaks in this recurrent message passing
between the the prediction neurons sometimes ascribed to the cells that live at a slightly
greater depth on the surface of the brain the cortical layers relative or distinct from populations
occurring the prediction error sometimes ascribed to superficial pyramidal cells simply because
they live very much closer to the to the to the surface of the brain so you've got this sort of
reciprocal exchange of messages where you can think of the deep pyramidal cells or the deeper
cells as encoding the position of the posterior so let's say some information comes in from the
sensory epithelia there is a prior belief encoded by the activity of a deep population of deep
cells and they provide a prediction that is now not an apt explanation for this new information
that's coming in there is a prediction error the prediction error is reported by the superficial
pyramidal cells that is then sent forward to change the deep and pyramidal cells at the next
level this is just the belief updating so the now the deeper pyramidal cells that were previously
encoding the prior expectation expectation here is just used as a word to mean the mathematical
average or the most likely value of our of our belief then the the prediction errors can now
be seen as doing this changing your mind doing the belief updating just by driving the activity of
the deep pyramidal cells in proportion to the precision of the prediction error so if you
ascribe a lot of newsworthiness a lot of precision to these kinds of prediction errors
from this modality in this point in time then what you are doing is effectively boosting them
in you know increasing their potency their gain or their drive so that they cause a bigger
belief updating or shift or change of your mind simply because they're driving the
deep pyramidal cells towards the likelihood to a greater extent in a way from the prior
than than had the prediction errors have been been assigned a much lower precision so what
would precision look like from a a neurophysiologist or a pharmacologist perspective well it's just
the excitability of these superficial pyramidal cells encoding prediction errors so that tells
you immediately anything that changes the excitability or the sensitivity of populations
encoding prediction errors under a predictive coding scheme is going to be the physical or
biophysical realization of the of this precision which then you ask well what kinds of things
could change the excitability or the post synaptic gain sometimes in use in neurophysiology
well in the brain there are certain brain chemicals on neurotransmitters whose role
is just to modulate the gain of these kinds of cells and what you then ask them well what
kinds of neurotransmitters well once which many people have heard of so classic
neurotransmitters of a neuromodulatory sort would be things like adrenaline, oxytocin, dopamine,
a certain oxytocin there for for a particular reason that dopamine would probably be the
sort of a post child of this kind of neurotransmitter whether or others you know
astral choline or cholinergic neurotransmission, serotonergic neurotransmission of the kind
that's influenced by say psychedelics and psilocybin for example so you can see immediately
if you've heard of any of these drugs you will know that they can have found effect on the way
you feel or the way that you update your beliefs or respond to changes in sensory contingencies or
changes in light circumstances and of course it is these neurotransmitter systems that are
responsible for setting the gain and computationally thereby the precision on the ability of prediction
errors to drive leaf updating higher in the hierarchy that are used in a therapeutic and also
recreational recreational setting. Yeah it's really important how you're connecting everything here
with not only the two classes of neurons but then also bringing in the neurotransmitters
and how they're also functioning here as well. I want to give you a lot of runway here many of
this will start to tie in together so hopefully listeners will be able to see that but give me
your detailed explanation and analysis and exploration of the free energy principle just lay
it all out for us just describe what it is how it works how it functions and then how it connects
with you know many of the things we've already discussed I'm sure it will come up with active
interference predictive coding theory and Bayesian brain model so just tell us your free
energy principle what it is and how it works and you can be as detailed as you would like.
Right I guess I don't want to exhaust you. No no it's great I it's funny because I feel like at
this point we've done all the warm-up so now we can get to the to the to the entree we get to
the main course here so tell us about the the free energy principle from from from yourself.
Right yeah I I have to confess you know that warm-up was probably a more substantive aperitif
than you might imagine. We've done 90% of the of the heavy lifting here.
In the sense that the free energy principle provides a first principle account of the
mechanics that we have been talking about so I'll try and explain what the free energy principle
is in a second but perhaps just preface that by noting that it plays the same role as Hamilton's
principle of least action and you could even argue the theories that undergo natural selection
evolution so in and of themselves they don't do much heavy lifting of an explanatory sort you know
for example knowing natural selection is a principle by which you and I are here it doesn't
tell me anything about why you've got eyes or a nice little beard or you've got your particular
accent it tells me nothing about that it just tells me there is a mechanism as to how these
things could have emerged so the free energy principle is a little bit like that I'll give you
another analogy Hamilton's principle of least action it's a you know a generic I would say
foundational and principle that underwrites all known physics arguably and yet it doesn't tell
me how on earth I go to throw this ball I can if you tell me all the processes all the mechanics
and the initial conditions of a particular instance of ball throwing I can certainly compute the
trajectory of the ball but in and of itself it doesn't it just tells you the principles
underwrite the actual process of ball throwing I'd actually have to become an expert in ball throwing
to actually realize and apply the method of the principle of least action and I use the
principle of least action because the free energy principle is just a principle of least action
so it's a principle that could be read as a method that could be applied to a particular
instance or circumstance of self-organization or active inference but you're going to have to
write down all the actual aspects of that circumstance in order to make the the principle
do any work and in a sense what we've been talking about in terms of various perspectives afforded
by predictive curling the basing brain embodiment all of these are really processed theories
accounts of a realization of the free energy principle so I just put it setting the scene
and to qualify my statement that the starter who was actually the main meal
all the hard work and the heavy lifting is really in testing these different process theories and
understanding how the free energy principle operates in this particular context with this
particular creature this particular institution this particular aspect of self-organization
so having said that then what is the free energy principle well it's sort of
transmuted to a certain extent depending upon how the story is told nowadays one would really
tell the story from the point of view of a physicist trying to understand
self-organization under a particular constraint and that constraint is that you are
trying to understand the dynamics and the physics and the principles of least action
that would apply to something now that may sound really trivial but it's in fact quite an important
starting point if you're if you want to talk about something then you have to say well what defines
a thing what separates the thing from nothing or from something else and immediately you get into
the game of defining how you'd separate the states of a thing from something else the states that
were external say to that thing and this leads you into the world of Markov blankets and conditional
independences statistical devices that enable you to say that there is some independence or
disentanglability between the states of this thing and the states of everything else and
basically what happens is when you apply Hamilton's principle of least action
to the dynamics of joint systems that possess a Markov blanket that separates the thing
we usually call it a particle from something else then what emerges is basically a Bayesian brain
or a Bayesian mechanics that could be applied to a brain but also to with them a stat all to a virus
which is why I was saying before the way that we deal with things isn't a much we usually start
at you know with very very simple systems so to cut a long story short what you are doing is
engaging the same sort of questions and formalisms that people in physics would engage if they're
trying to understand non-equilibrium steady state dynamics and why is that different from 20th century
physics well because most of 20th century physics was all about equilibrium systems it's all about
some idealized gases it's all about second laws that apply to closed systems and by closed systems
what I mean is that you've got this sort of system of exchangeable particles that's in a heat bath
or in a heat reservoir and I use the word heat bath here because the question that
somebody interested in open systems would be asking where did the heat bath come from
and what's outside the heat bath and how on earth did the heat bath maintain itself
so you now started to ask questions that people in the life sciences have been asking people like
Varela in terms of water poesis you know how on earth does the boundary from my perspective
the Markov blanket the heat bath that contains the idealized internal states of inquiry that
define the particle in question on the system in question how on earth is that maintained
and even more simply it's very existence and persistence what does that imply and if one
just follows through the maths that you would normally apply to an uncontained
states of the system to a contained set of states that are contained within a Markov blanket
that comprises sensory and active states and then what you end up with is a functional expression
or functional form for the dynamics that is formally exactly the same that you would find
in the other kinds of mechanics so you know you can think of the free energy principle as
just basically introducing a different kind of mechanics that is a complement to
on the one hand classical mechanics that would apply to heavenly bodies and massive bodies
where there were very few random fluctuations in play because they're so big or cold
you on the one hand the second kind of mechanics that you'll get in the absence of a Markov blanket
would be statistical mechanics thermodynamics fluctuation theorems that apply to lots of very
hot very small things that don't have conserved dynamics where the random fluctuations dominate
over the classical conserved dynamics of of Newtonian mechanics and you could even apply
to quantum mechanics and the move here is just to work with the complex root of probability
distributions Bayesian beliefs but the wave function squared now becomes a Bayesian belief
but you don't have any Bayesian nuts in either in any of the classical mechanics
or the quantum mechanics or the statistical stochastic mechanics and that's because
none of these mechanics have a separation between the inside and the outside and it
comes back to something you mentioned earlier on which is the notion of hidden states and you
remember you and I should have picked up on that when you were framing Bayesian thinking so the
whole point of Bayesian thinking is there has to be an inside and an outside so there has to be
observable consequences of causes that are unobservable so you know before you can even
talk about inference there has to be something about which you are making an inference and there
has to be some data some observable consequences of these hidden states or hidden causes that now
you plug into your Bayes rule and you know we can then go back to the story about moving a posterior
from a prior given the likelihood of your observable sensory data but just standing back from that
construct means you now have to have a physics that makes a distinction between stuff on the inside
the internal states of the system and stuff that is hidden states that are hidden that
will now support a Bayesian inference and of course this is exactly what is supplied by the
Markov blanket so the Markov blanket is a set of states that intervenes between the inside and the
outside that literally surrounds forms a blanket a shield a veil of a statistical sort that encompasses
entrails the internal states so now what plays out on the surface on the blanket states are now the
sensory data the observations of sensory evidence that are reporting the influence of the external
states on the outside that are hidden from the internal states because they are behind the Markov
blanket so you have to have a Markov blanket that separates the inside from the outside before you
can have a Bayesian mechanics and once you commit to and follow through the maths that would apply
to a partition of a universe into internal external and the intervening blanket states
that I repeat come themselves be divided into active and sensory states then you just get the
free entry principle and all that says is it looks as if any system that is equipped with a Markov
blanket and it has to be in order to define the thing in question will appear to infer
in virtue of the dynamics of its internal states the external states to put that more concretely
there will be an interpretation of the physical internal states as encoding the parameters
of beliefs Bayesian beliefs about external states and by parameters we're just talking
about these location parameters and shape parameters that that parameterize or describe
any belief so that's quite remarkable because it gives you a very different kind of take on
information because normally when people talk about sort of information theoretic treatments
or probabilistic treatments in self-organization on equilibrium steady state sort of treatments
that allow for this openness or exchange between the inside and the outside through the Markov
blanket and they're talking about the information inherent in any particular state you know how
surprising would it be to see this gas in this ensemble in this configuration what we're talking
about here is something much more subtle and it's a kind of information that is much closer to a
folk psychological or a lay notion of information it's information about things that can't be seen
so the internal states now hold Bayesian beliefs about hidden external states that are hidden from
them because of the Markov blanket that defines their existence so there's an existential imperative
here or one can read this existential imperative as this inference process which brings us back to
self-evidence that just to exist as a thing means that you have a Markov blanket which means that
there are hidden states which means that if you exist and persist you must be in some kind of
technically a generalized synchrony with the external states that means that I can read off
your internal states and infer only you can as the thing the configuration of external states
and this process in a dynamical setting now becomes a process of belief updating becomes
a an inference process that can be described technically as minimizing a path integral
of a physics called an action which is a time times energy
construct and Hamilton's principle of least action in our instance the action is the
the the marginal likelihood of the sensory states part of the Markov blanket which is
approximated by or may in some instances be identical to the free energy so hence the
free energy principle is just a principle of least action it's saying that the internal
states of anything that exists will have a description in terms of minimizing technically
a functional of beliefs about external states so that was a very brief
so let me let me try and let me try and summarize here if I can get this so what you're saying is
is that so all biological self-organizing systems they are ergodic they have the Markov blankets
they exhibit active inference and they are self for self-preservation or to put it another way
all of the quantities in a self-organizing system that can change will change to minimize free
energy do I have this right yep okay so how so I want to I want to go to this idea of hidden states
right so obviously you talked about equilibrium and I think maybe I would term it in my world
with something on home of stasis right you know people in psychology or people that do physiology
they like to talk about homeostasis so maybe you can chat a little bit more about the role of
homeostasis or equilibrium in preferred versus expected various physical states I do want to
introduce a little bit because I know we've mentioned him a few times you know mark solmes I
know you guys have worked together and I've talked to him he's he's fabulous so he has a
a psychoanalytic angle here which I'm very fond of as well about the impact of the Freudian model
of drive energy so maybe this is a I'm adding something here so maybe you want to talk about
homeostasis but my question about Freud is how does his conception of drives or drive energy
how is that consistent with your free energy principle right two really easy questions
right so you want to go from Bernard to frog
so but that was you know that that was I think a clever move to to introduce the notion of
homeostasis so what we're talking about here is just a generalized homeostasis so you know
you can regard this non-equilibrium steady state you use the word egodic which was interesting
um we try not to use that word because that brings all sorts of baggage right what we're implying
in terms of a non-equilibrium steady state is over a limited period of time
realizing that of course at a slower time scale things will evolve so we don't imply that the
system ever attains a steady state it's just that it has a steady state solution to its dynamics
but that solution may disappear after a short period of time but within a particular time scale
um what we are talking about is the fact that it has maintained its mark of blanket
which means that it must have established some kind of synchrony or balance between the inside
and the outside that we can now articulate as a principle of least action or a principle of least
free energy or maximum model evidence and then the question is well is this consistent with other
theories and other accounts of self-organization or global function of a system and the answer is yes
absolutely and so you know homeostasis is one of my favorite accounts but there are other
accounts you can also say well this fundamental objective function that appears to be minimized
remember this is a principle of least action it looks as a the system it looks as if the system
is trying to minimize something so that could be a cost function which could be a negative reward
function or utility function so you can now spin off all of reinforcement learning and economics
in terms of utility theory as one expression with a particular commitment to you know understanding
the mechanics and the the other metric of that field either in the economics or psychology sciences
but it's just really an expression of that there is something to be optimized or it looks as if
the system is optimizing something because it conforms to this principle of least action
where action is the negative log evidence or the free energy so all of reinforcement learning
and utility theory is just a statement I think I can describe the behavior of this
system as an optimization process all I need to do is to identify the function that's been optimized
and of course from our perspective that's going to be or minimize in our in our context that will be
a free energy or it's converse the marginal lighter and the evidence of my model the world
so you can rewrite all of reinforcement learning and utility theory as basically
an expression of or an optimization process of self-evidencing where you now start to interpret
the prior beliefs as or the logarithm of the prior beliefs as a reward functional preferences
so just because I am sitting in this configuration with my Markov blanket
means that if I now interpret my behavior in terms of basic mechanics I necessarily now have to
understand it or write it down in terms of a prior belief and a posterior belief and the updating
and it turns out that that prior belief just is the distribution of the study state solution
that we were talking about previously which means that just existing is a statement of your preferred
states of being and you can articulate that mathematically in many different ways you know
for example in the theory of random dynamical systems the set to which you will always return
will be called a pullback attractor or a global random dynamical attractor these are just the
states to which I'm attracted these are my preferred states and of course that's what's
being optimized from the point of view of reinforcement learning or utility theory you
can move them to the observation that the the negative of these utility functions or value
functions is surprise that's also known as self-information information theory it's just
the prediction error that we were talking about before which I'll minimize that and then from
that you can read up all sorts of information theoretic treatments of optimal behavior such as
maximum mutual information theory infamax theory you could even go as far to a certain extent as
integrated information theory if you wanted to but information theoretic accounts that that posits some
some metrics of functional information theory measure that is extremized of course the
free energy principle is just one of these it says the information theoretic measure is just
the free energy which is abound on the negative log model evidence or marginal likelihood but
then you come to your set of examples which would be more from the point of view of theories of
self-organization either of a sort of physical sort like cybernetics and then you get into things
like the good regulator theorem and or synergetics which are entirely consistent with this sort of
optimization sort of you know the Hamiltonian principle of least action but if you're a
physiologist or you're saying it's just homeostasis so this is just a generalized homeostasis it's
trying to place bounds upon or it looks as if you are in minimizing your prediction errors
if you now think of a particular kind of prediction error as the prediction error between
any autonomic physiological variable and your a priori set point or belief about what it should be
in minimizing the prediction error you are doing homeostasis so minimizing that surprise
in the particular setting of the surprise being about physiological states just is homeostasis
and if you just generalize that you're all you're doing when you're describing a particle
that keeps its states within particular bounds within its mark of blanket it you're necessarily
has to resist random fluctuations and gather itself up to evince a generalized homeostasis
and then the final interpretation cause is just in terms of self-evidencing and the Bayesian
bone hypothesis but these are just different perspectives on the same underlying dynamic
so having established the the privacy of homeostasis in its full and generalized sense
we just have to put Freud into the story which is not that difficult actually
and I say that because I should acknowledge that Mark Soames is the world expert on Freud
and I don't know if he spoke about his books on Freud and all the translations so my understanding
is childish and unscholarly to say the least but for what I understand that he's spoken to people
like Mark many of Freud's foundational ideas were coincident or shortly post dating much
of the work of Helmholtz so when when when what one might easily imagine that Freud thinking about
sort of his energy constructs in terms of a Freudian construct he probably had in mind the
same kind of thing that Helmholtz had in mind and one I haven't seen anything written or I haven't
read about this but certainly from secondary tertiary sources and Helmholtz did have a notion of a
neuronal free energy or a neuronal energy that was the thing that could be optimized or minimized in
order to explain unconscious inference he never really articulated or found it but he certainly
had the quest in mind that I fondly would now submit would be the variational free energy
it fills everything that he wanted and is entirely consistent with his more formal
formulations of perception and also much of physics and so my guess is that that basically
Freud was was taking that notion of an optimization in terms of an energy function
as it was articulated and conceived of at the time that these are the inception of these ideas that
you're bringing candid philosophy into physics but without the machinery afforded by Richard
Feynman to deal with it in a simple and graceful way in terms of mathematical equations and without
of course the high performance computing that machine learning subsequently enjoyed and was
able to sort of demonstrate proof of principle that this is the way to formulate the problem
so the Freud probably got as far as he could in the absence of Feynman-esque maths and
mathematical formulations and big computers but pursuing these kind of the same kinds of ideas so
it needs of no surprise to me when Mark tells me that there is a fundamental
conciliance between Freudian formulations and those that you would find that inherit from Feynman
and all the other contributors to these to this formulation of sense-making
and so I would imagine that Freud gets into the game quite gracefully.
The particular point I think that Mark Somes would emphasize here though brings us back to
this meta-cognition and beliefs about beliefs and in particular the ability of certain
hierarchically abstracted sophisticated particles like you and me to actually physically encode
and manipulate and do their Bayesian belief updating on beliefs about beliefs and specifically
the precision the uncertainty so no our own uncertainty to no our own minds and the deployment
of that in terms of this overarching homeostasis this the extremization of
minimization of prediction error or free energy or maximization of marginal likelihood or model
evidence underwrites that kind of mental action and may on Mark's view at least be the essential
quality of any feeling or any sentience so he has a lovely phrase called felt uncertainty
in the same way that we visually palpate the work that you know the visual scene with our eyes
what he's suggesting well the way that I interpret his poetry and you may be very cross
if you hear this but the way I interpreted is that you can palpate your your own uncertainty
palpate you can feel your own precision and furthermore you know and have prior beliefs about
the way that that uncertainty should be deployed or changed and you update your beliefs about
that precision and the mechanisms that do that may well be those that are at the heart of
the feelings and the right quality of experience of the kind that the mark would describe to
consciousness that felt uncertainty yeah it's interesting with Freud because obviously a lot
of it in terms of the the drives was this I'll say it was in an interesting way I mean the way he
framed it was in terms of the psychological hierarchy that he was trying to give as a model
was this element of tension reduction rooted in our our biological and evolutionary nature
if you were to make a comparative analysis here you would say that that was probably a passive
approach right because it's always something is happening how do we how do we resist how do we
how do we get rid of the tension reduction is it in a way a kind of passive way as opposed to maybe
say the you know philosophy of Frederick Nietzsche who had a more active way of trying to understand
to energy and drives and power things of that nature okay so some of the further questions I
want to ask you are since we've done a very nice or you've done a very nice job of explaining the
the free energy principle I would I want to ask about how it applies and then a little bit of
some criticism so I guess the one connection here is about consciousness so as we've been
alluding to people many people have ideas about consciousness where resides how it functions so
everyone from Chalmers to Demasio to obviously Mark has has made some pretty extraordinary
uh research on this in terms of finding it in the uh in the midbrain in the brain stem
which is fascinating stuff there um and all in a now set I mean there's a bunch of people that
have been talking about consciousness it's sort of trendy how do you based on everything we've
discussed um Bayesian brain free free energy principle how do how do we can this tell us
anything about consciousness more accurately or more clearly about what it could be where it could
be how it functions um what is I guess your your kind of uh stamp on on this topic in terms of
consciousness I think the first thing to say um which is often said by uh philosophers is that
the free energy principle is not a theory of consciousness that sounds um slightly deflationary
but in fact it's quite a useful thing because if it's not a it wasn't designed to explain
consciousness and um it's only people like me have no pretensions to try and get into that game
but it would be very interesting to see if it holds the um the formalism that allows people
to address certain hypotheses or questions about consciousness so that that is deeply engaging and
just for your interest um there's currently just been funded a um John Templeton Foundation
collaborative uh adversarial collaboration to play off uh active inference against information
integrated information theory so there are lots of academics and theoreticians out there who are
sort of um interested in what more formal accounts of sentient behavior will bring to the table in
terms of answering questions about consciousness um so everything I am um saying is contextualized
by the fact that you know the free energy principle is not there to explain consciousness but if you
had to answer some of the deeper or more challenging questions um such as um David Chalmers hard question
and or accommodate um some fundamental dialectics you know Cartesian dualism for example
what space is on offer um from the free energy principle and I think there are some quite clear
answers there and we can take this from a number of directions and I'm going to I'll take two because
they follow on from from um some of your pressing questions about sort of drives you know from
the Freudian perspective um so what what did what would drives look like um from the point of view
of the free energy principle but let's not talk about the free energy principle let's talk about
active inference as an actual process theory for you and me um that um that are if you like
conforming to the free energy principle um so the the first thing that um one has to note
is something we've spoken about before that we have a calculus for beliefs about something
that immediately introduces um a duality in terms of interpreting internal brain states
we can either talk about the probabilistic population dynamics and the information of
neural populations and their activity which would be um intrinsic to the brain you know how
likely is it that my neurons are going to fire in with this particular pattern of this particular
part of the brain in this particular circumstance which of course is you know more of the key
questions we address with neuroimaging or you can under the free energy principle or active
inference say well hang on a second there's another kind of probability structure a belief
space because we've just said for every pattern of neural activity there is encoded an implicit
representation of beliefs about the outside now what that means is technically that not only is
there um a probabilistic description of my neural activity but that neural activity
is equipped with something called a statistical manifold uh by by which I simply mean that every
point on this manifold that corresponds to a pattern of brain activity is equipped with a belief
structure a belief distribution a Bayesian belief about something else about the outside
you the causes of my sensations and that means that I can now talk about an information geometry
of a different sort which is now about the outside an extrinsic information geometry
and that's quite a nice picture because this notion of belief updating we've been talking
about Bayesian belief updating um is um corresponds to a movement on this statistical manifold so
you imagine that every pattern of activity in your brain corresponds to a point on this abstract
manifold this surface in a very high dimensional space and every time the pattern of activity changes
in virtue of your neural dynamics you make a movement on that space and that movement is
belief updating it is exactly the same as moving from the prior to the post year
that we were talking about before so sensations come in and they move the point on the
statistical manifold to produce the belief updating so you are literally now
describing mathematically in with an information geometry belief updating and the process of
inference and the key link here is that the the measures the the metrics that define this
information geometry or belief updating are something called a Fisher information metrics
and mathematically they correspond exactly to the precision we were talking about before
so technically it's the curvature of that space as measured by the uncertainty or the precision
of your belief updating so there's an intimate relationship now between the precision that
we were talking about in relation to um say mark zones and just to slip in here that the cells of
origin of those neurotransmitter systems that control the post-synaptic game that mediate the
precision are exactly in the mid-brain structures that mark things as the seat of consciousness
so this is all entirely internally consistent but it's also consistent with the Freudian notions
of drives because you can think about this movement on the statistical manifold this belief updating
has been driven by forces what are these forces they are the prediction errors they are the
the surprises they are the effect of the likelihood on the priors that force it or move
it to produce the posterior so now we have this notion very elemental notion of a drive
um probably uh is sort of oversimplified from a Freudian perspective but I think the mechanics
sort of holds true here the drive is literally the thing that the uh rule of the prediction
error is in driving belief updating from prior to posterior beliefs but crucially we now understand
this force this drive as being gated or nuanced or contextualized by the precision which brings
us again back to the fundamental importance of getting this sort of metacognitive beliefs about
beliefs or predictions of precision right in terms of enabling those particular forces and drives to
be manifest in the way that we both organize our neural activity but also explore our belief space
by moving around on the statistical manifold so you can write this down very precisely in terms
of information geometries there's lots of really interesting maths that gets right into the world
of gauge theories and they're like all telling the same story but the the met the the potency of
these drives depends upon the curvature and the curvature depends upon the precision or our
beliefs about the uncertainty the point here though from a from a sort of consciousness
point of view is that there are two descriptions of movement on this statistical manifold there's
a description from the extrinsic perspective in terms of the probability distributions encoded by
a point on the manifold and there's another intrinsic description which is the simpler one
just about the probability of being having this pattern of neural activity so there are people
I'm thinking about colleagues such as Vanille Weiss who together have put this forward
as a way of repairing dualism that you've basically got a a dialectic for free mathematically in the
information geometry that jointly ascribes a particular physical instantiation in terms of
neural activity and patterns of neural uh neural firing to any point on on the statistical manifold
that is accompanied by beliefs about something else which would be the sort of the more mindful
aspect of a cut cut easy divide so you've got this sort of a monistic account that has these
dual aspects of mindful belief updating and the physical embodiment of that and I think
would be a potentially useful way to talk about sort of dualism versus monism when it comes to
you know to some some possible to be a historic but to my limited understanding sort of you know
foundational issues in in consciousness research and that that would be that would be sort of
one if you like opportunity for the the Bayesian mechanics afforded by active inference and the
free energy principle to produce some quite clear predictions about the relationship between
mindful stuff and brainful stuff where there has to be if you like a convergence within this
within this information geometry the other thing it plays to the table is that it is the
movement on this manifold it is moving through a belief space that is the essence of inference
so if you remember the free energy principle is just trying to describe the dynamics of a system
that has a non-equilibrium steady-state solution for a certain amount of time
inherent in the use of the word dynamics is you're looking at a process that is unfolding in time
what that tells you is that if you want to talk about consciousness then it may be best to think
of consciousness as this process of belief updating in exactly the same spirit that we talk about
evolution as an evolutionary process we don't talk about the state of evolution at any particular
time that's divorced from the dynamics the paths and the process itself the the process of evolutionary
selection as opposed to say selecting a plan or a particular belief or you know you know
are updating my beliefs in terms of the process of inference in the under the Bayesian brain
hypothesis you know we talk about the process as unfolding in time so what that would mean
if you just translate that perspective which is inherently dynamical to consciousness research
is that questions about what is to be consciousness have to be recast in terms of what processes must
you evince in order to qualify as having a conscious process so states of consciousness
and levels of consciousness are only meaningful when they apply to something that is changing in
time essentially moving on this on the on the statistical manifold so that's from my point of
view a couple of things that are brought to the table by having a formal mechanics or calculus
underneath belief updating to have a calculus of sentience of physics of sentience
that tells you immediately you're talking about processes and of course if you think of you know
in terms of any optimization or casting things in terms of any optimization then you are talking
about the process of optimization and indeed even from the point of view the the semantics of things
like variational principles of least action you know the leastness the minimization aspect of it
talks again to a you know a process that is you know playing out over time so that that would
certainly be if you like one's constraint on offer for anybody who talks about consciousness
you know are they committed to a way of thinking about consciousness that just doesn't have any
any meaning in the sense that it's about a particular state of being
or can they recast or formulate their hypothesis in terms of of a process
the third level of the third sort of thing on offer with active inference brings us back again
to the geratin model so remember previously we were talking about differences between
thermostats flies mice and men and I was very comfortable talking about those differences
from a unique perspective which was simply what are the differences in the geratin models so if
you can boil everything down to the evidence for which you are trying to secure which is the
geratin model then you can start to talk about different kinds of consciousness in a graded way
in terms of different kinds of geratin models and we've already had this conversation in the
sense that you know I can have a geratin model for a thermostat which has which is temporarily
very thin it has just you know very very limited temporal horizon and then we graduate to particles
and creatures that have a more allostatic as opposed to a homeostatic
way of engaging actively with their environment that acquire a certain temporal depth and then
we move on to the opportunities when you now have a geratin model in the future for different
outcomes different counterfactuals and then we move into Anil Seth's notion of counterfactual
richness but noting the counterfactual richness as one way of understanding consciousness or a
conscious process is only allowable when your geratin model has a the capacity to model counterfactual
outcomes in the future and then we get to the remarkable counterfactual outcomes that underwrite
things like you know the philosophical zombie and brain of that and then we start to talk about
you know we can go from mice to men to philosophers and then start to engage
engage with that kind of conversation so that's another you know sort of structural
architectural formal thing or way of dealing with these questions that you get from the
physics and the mathematics which wouldn't otherwise be there if you're just using narrative
arguments historical arguments i was going to say you were talking about this convergence and as
you were describing that i was thinking about how there is a kind of multi-dimensionality
or a continuum aspect of this having a being a process of things as opposed to just a static
kind of state which i think um based on many of the things that are right on consciousness that
makes a lot of intuitive sense and i think the way that you're talking about this underlying
calculus to try and describe a kind of process makes a lot of sense in terms of artificial
intelligence so maybe we can make the the leap a little even further right mice to men to philosophers
to ai right how to obviously there's there's it's sort of connected with the consciousness
question although you could make artificial intelligence that doesn't need to be conscious
i don't think it's a prerequisite although some people may argue about this but
in terms of again the this underlying calculus that is there with the free energy principle what
what is it's i guess specifically or
something that gives it this uniqueness that can give us information about
artificial intelligence obviously artificial intelligence is a very broad
uh categorization so i mean my you know dishwasher and microwave is a form of artificial
intelligence right at a very very low level um and then there's artificial intelligence that we
see in science fiction stories such as you know humanoid robots that are sentient and they maybe
have feelings and you know things like that over time so there's the whole gamut here and of course
you could make the the the offshoot of well first you have to define intelligence which is a
very long uh footnotes which we don't have to do although if you want to i would
totally be fine with you explain that as well but just how do we understand the
elements of free energy principle for artificial intelligence now and how it could have potential
utility as we continue to grow and expand our mechanics or computational aspects of
artificial intelligence part of your question was your how how
does a free energy principle give you the opportunity to get more information about
the uh the nature of intelligence and as you uh innovate sort of artificial intelligence
interestingly that that that that getting information about is actually at the heart
of the answer i'm going to give you so the answer i'm going to give you um i'm going to
foreground though um one key thing which is um in response to a previous question here what's
a free energy principle for um uh very much like the theory of natural selection it doesn't really
do anything we're afraid it's it's it's very pretty and you can have philosophical debates
about it which i'm sure we'll come to um but you know why is it useful um and the answer is um
if you read the free energy principle as a um a mechanics that is apt to describe
systems that have solutions to the non-equilibrium study states in terms of an inference process
then the answer is it's pretty you know it is not useful however once you know the functional form
of the equations of motion the dynamics the updating
that have to be in play in order for the system to be intelligent or to be to show
a self-maintaining or auto poetic like behavior what you can do is um write into an artifact
the generative model and all the prior preferences entailed by that generative model
to simulate an artifact that has the same properties of self-maintaining and maintaining its
Markov uh blanket why would you want to do that well i think there are two cardinal reasons why
you might want to do that why would you like to build a Markov blanket maintaining building
machine that's doing inference that it basically is realizing the principle of least action that
prescribes the differential equations that you would write into a computed simulation or indeed
a robot or a your um an artifact that was supposedly showing artificial intelligence
well i think there are two reasons to do that one you might want to build um an active inference
agent an artifact that's actually doing active inference how would that differ from artificial
intelligence as we currently know it that's a really cool question there are very clear answers
and i'll and i'll give you the answers in a second but just to um conclude this part of the answer
with the second motivation that you might want to build synthetic agents with synthetic sentience
under the variational principle of least action that is the pre-energy principle
is you might want to make inferences about somebody else and i'm now thinking from the
point of view of a psychiatrist you might now want to try and simulate choice behavior and active
inference under a particular model and then adjust the preferences and the price of that
judging model until you reproduce the kind of observable behaviors that this patient has or this
particular cohort shows so what we're talking about here is essentially using the simulation
models as observation models of real world people you know and other creatures uh in order to try
and understand their internal dynamics and their internal mechanics there's something quite fundamental
about that particular take because remember before we we talked about the markoff blanket in
shrouding the internal states of something from the external states so that there is if you like an
impenetrability there's a fundamental statistical divorce between um the internal states and the
external states meaning that the external states are hidden from the internal states
but the converse is also true which means that from the outside the internal states of any creature
or person or loved one are forever hidden from you from the outside so you can only ever infer
the machinations and the dynamics and the belief updating on the inside which is interesting because
that means you know much of my day job in neuroimaging is trying to peek behind the markoff
blanket to see what's going on but you you can't do it properly otherwise you'd have to break that
you'd have to breach the markoff blanket to become invasive or study dead things in order to
try to infer what was going on so that means that you need to you need to use inference just to
understand the internal dynamics of the brain of a person which means that the only way you can do
it is to have a generative model of a generative model which means that now you've got another
use case for active inference in the free energy principle which is building models of people and
patients and then adjusting them until you use the adjusted model that renders the the behavior of
the model very similar to the behavior of the patient to infer this is how the patient works or
at least this is as if you're at as if explanation or counter mispatient so that there's my two
principle motivations you know to use these as a principled model of choice behavior or
neuronal responses that I could measure empirically to answer my hypotheses about how the brain works
there is another agenda which we've touched upon which is your more the fun of creating
artificial general intelligence or general intelligence or AGI and the distinction between
artificial intelligence and AGI or the next wave of you know artificially or intelligent artifacts
I personally do think is staring you in the face
in terms of what the difference is between active inference
and under more sophisticated generative models that have the ability to model the
consequences of action so if the end point of this argument is that if it is the case
that I have to minimize my prediction errors or free energy or at least look as if I am
minimizing my prediction errors or free energy just to exist if it is an existential imperative
for existence then a priority I must also believe that every action that I choose every choice that
I make must be that which is the most likely to minimize prediction errors or free energy
after I've made that action but the consequences of my action are now scored
in terms of their ability to reduce the free energy I expect following an action
so then what you can do mathematically is just look at the expected free energy
and ask how could I interpret that what does it look like what are the qualities how
what are the the first principal accounts of a good choice or a good action and when one does that
it looks like as you might expect there are a number of different interpretations of this
expected free energy which is a big thing that active inference takes the table so this is an
objective function that now replaces utility functions and reinforcement learning it also
replaces the the principles that underlie active learning and things like optimal Bayesian design
in the sense that it grant funds these things and puts both of those two aspects of good behavior
together and in putting them together this objective function that underwrites the right
choices the right behaviors is just expected surprise or uncertainty which means that all
I need to do is to choose those behaviors that minimize or resolve uncertainty or maximize
information gain under prior preferences inherent in my charity model so that last statement is quite
crucial and what what it transpires to be or say the expected free energy transpires to be a mixture
of two components one of which is an epistemic information hungry seeking component and the
other one is a more pragmatic preference seeking component and put them together they are just
then minimizing overall uncertainty or minimizing the expected expected free energy crucially
that epistemic information seeking component is the the thing that underwrites curiosity
so if you look at the artificial curiosity literature the the key problem is has been
how do you articulate and mathematically formalize the drives to resolve curiosity
the sensation seeking the inquisitiveness that characterizes all of us certainly in
certainly in this conversation but you know I think all of us as little scientists just need
to live we have to be curious creatures and the expected free energy is basically that curiosity
that intrinsic motivation that's another word in your neuro robotics developmental neuro
robotics also known as expected salience and it puts it together with the surprise minimizing
aspects endowed by having prior preferences in your charity model I I expect myself to do this
kind of thing or encounter these kinds of outcomes but because I'm contextualizing that with this
information curiosity seeking component I've now got a complete objective function
that essentially equips active inference agents with curiosity so that is what is missing in AI
that no Alexa or no iPhone is ever going to ask you a question because it's curious about you
so the next generation of artificial intelligence well if it complies with the
the you know the variational principles of least action as articulated under active inference
should show a genuine interest in you because it will act or it will select those questions and
those actions or look at these websites or these data engage in this kind of data mining
simply to resolve uncertainty about its charity model of the world and if its charity model of
the world contains you it'll want to know about you and it will ask the best kinds of questions
that will maximally resolve its uncertainty about you so it will be genuinely interested in you
and you know in that sense then I think because it's got this curiosity inherent in its
selection of its actions I think it will then show a kind of artificial intelligence that is
much closer to the generalized artificial intelligence that people have been been aspiring to
but it does rest upon this upon putting the curiosity in as part of the package by minimizing
the expected free energy I have this this chilling a fantasy in my mind as you're telling me this
about you know my my uh Alexa or my my serial my phone asking me questions about just a very
very chilling kind of thing about it but I do agree with you I do think that that's probably the
the next step the next place because of how good algorithms are at trying to predict
based on things that we're searching or looking or things like that you know it's trying to to to
accurately get something if I put a search in google now it takes you know not even two seconds
right you know 10 years ago it took longer and you have to find all these things and it's trying
to curate the things for you that you're searching I could imagine that there's more of a not just
that the the AI is is receptive but then expressive in what they're trying to ask and inquire of you
the the the person that's searching which is there's a little bit more you're right there's like a
uh more of a two-way street there which is um definitely uh it's a little bit of a scary
thought to think about I think there could be really cool utilities to it but I definitely
think there's obviously like many things an inherent danger before I want to ask you about
the imaging techniques you've done because that's I mean as you say your day job is is uh
that's what you do and obviously you've been prolific in in those those areas I just want to
ask one thing just because it's relevant now and I think as we continue moving throughout
this you know second decade I guess of the 21st century
it's about your work with COVID-19 and I know this is a big big area big topic and
a lot of noise about the pandemic in all aspects I just want to ask you just generally you can
briefly just summarize you know kind of how what what your work was I believe was with uncertainty
in predictive models and how we understand things and how we understand um certain types of immunity
and things like that just kind of how you became involved or how you how you think about uh about
you know the the pandemic and and COVID and how um how you've been doing work in in that area
yes of course so um you know the answer to that question does come from my day job
which is using brain imaging and empirical data acquired through a variety of different ways of
peaking or breaching the mark of blanket or looking inside people's heads so you can do that with
things like functional magnetic resonance imaging which gives you sort of whole brain images every
second or so and reports fluctuations in coarse grained neural activity in different parts of
the brain right through to things like magneto and ethnography and equivalent EEG procedures which
give you a much temporary resolved picture or signals reporting electromagnetic fluctuations
in neural activity over your fractions of a millisecond but the price paid is that you lose
the spatial resolution but the point being is that these are ways of looking at the brain in action
and affording data empirical evidence for various hypotheses about the underlying functional brain
architectures of which we have been talking a lot some of the hierarchical architectures that
recurrent message passing entailed by different sacred encoding or other theories and in particular
something from my perspective trying to understand the failures of those architectures in terms of
false inference that ensues from for example breaking the precision control that we've been
talking about and how that might show up in people for example with schizophrenia or depression or
other neurological or psychiatric conditions so that's my day job and the link to the COVID
research is quite easy to demonstrate in the sense that what you are talking about when looking at a
message passing architecture and your own message passing architecture that is doing the belief
updating that is enacting the drives afforded by prediction errors in doing the belief updating
and causing activity in different parts of the brain this obviously can also be expressed as a
communication and a dissemination of information or influences so you've got the spread of messages
and bits of information from one neural population to another neural population
in order to make sense of the brain imaging data you actually have to have an underlying
generative model of this process and now we're talking about a generative model of the brain
that I as a scientist are using to make sense of my excitatory empirical data that comes from
the brain imaging and I deliberately phrased the the fundaments of these generative models in
terms of spreading information among neural populations because of course that is exactly
the same kind of generative model you'd use when trying to model the spread of a virus amongst
the populations that constitute a country or a region or a city so my involvement in the
the modeling of the coronavirus epidemic comes straight from the the observation that the
generative models the states based models the convolution models is a just technical terms
and the kinds of models that we use to make sense of brain imaging time series generated by
populations of neurons could be very quickly and efficiently repurposed to make sense of the
epidemiological time series generated by populations of people that were in various states of infection
symptomatic you know vaccination and the like so for the past two years my weekend job has now been
split behind between something called Bayesian model selection or structural learning which is
basically fiddling with your generative model until it minimizes its free energy or maximizes its
marginal likelihood in relation to the the data that's incrementally becomes available
and different kinds of data on the one hand and then trying to do the free energy principle and
make it simpler and more accessible on the on the other hand so that's how I became involved
you know different levels of engagement working as a panelist on the independent
sage which was a sort of a public facing version was meant to be a compliment a public facing
compliment to the the scientific advisory group on emergencies that they were supplying the
cabinet office and the government with with advice we were much more in its original formulation
sort of public service facing information dissemination and public engagement sort of
initiative run by academics and you know I have been involved on other advisory bodies
largely motivated or resting upon the the predictions made by technical school dynamic
causal modeling of the time series data that allows you to optimize the parameters of that
generative model given all the data you have up until this point in time and then run the model
forward under you sometimes under different scenarios that allows you to make sort of
forecasts about what would happen if I did this or did that that can be useful for
um nuancing the advice given to to you know politicians and decision makers when considering
you know should we relax lockdown rules at this point should we encourage this age group to
take up vaccines for example yeah no that's that's super super salient and instrumental so that's
that's uh that's incredible work um so we've already kind of talked about it so let's let's
get into your day job you're you're with the imaging techniques um so the thing that I think is
your initial claim to fame here is the statistical parametric mapping and then I think also subsequently
the voxel based morphometry these are the two imaging techniques most people will know a CT scan
an MRI scan I do want to ask you about fMRIs some people may know about diffusion tensor imaging
there's all different types of ways of scanning the brain uh so maybe just tell us what these
two things are the statistical parametric mapping the voxels and then just kind of how that sits in
with mapping of the brain uh overall right well you're interested in the notion of a CT scan and
many people will also be familiar with x-rays your images um the peak behind the kerb and get on
you know give you a picture of what's going on on the inside um so statistical parametric mapping
uh can be conceived of as producing x-rays of significance of significant activation
and by activation I mean a change so going back to this notion that the interesting stuff is
in the processes the uh you know from the point of view of the free energy principle the belief
updating so you needed a way of forming x-rays of a certain kind that reported where the belief
updating and the neural activity and the hemodynamic or the blood flow consequences of that hemodynamic
activity where and when they were occurring in the brain so SPM or statistical parametric
mapping is just that it's just it's just the construction of x-rays or CT scans where the
values of the image at any point in the image usually known as a pixel or a voxel correspond
to a statistic testing a particular hypothesis about the pattern of the um the fluctuations in
neural activity over which you have usually some experimental control so when people talk about
activations what they basically mean is has there been uh have I been able to evoke
neuronal or belief updating and neuronal message passing and thereby neural activity
and or everything that supports that neural activity by presenting this kind of stimulus to
the subject uh relative to that kind of stimulus so you're just comparing the evoked responses
over time and then summarizing those differences in terms of a statistic and then putting that
statistic for that whole part of the brain into an image and thereby creating a whole brain map
or a your next statistical x-ray of the functional anatomy so it's now unlike a CT scan which is a
structural anatomy this is now the functional anatomy because you're you're if you like summarizing
a functional process and very similar approaches um you're taken to um in in EEG or electromagnetic
and electrophysiological um procedures and you mentioned voxel based morphology that is simply
the application of this statistical x-ray this SPM like technology to the special case of sequences
of structural images so you're normally in the game we're trying to infer to this group of patients
say with Alzheimer's disease or Parkinson's disease do they show a systematic difference in
their structural anatomy again in this instance uh using a SPM or statistical x-ray but in this
instance the statistic is reporting the significance of the difference in the composition of the anatomy
as measured with um with magnetic resonance imaging usually or could be CT scans um by uh
but using here not time series data but usually data points from multiple subjects that are care
that are carefully carefully selected so it sounds like there's a there's a there's an
integration of trying to have the integration of looking at the functional pieces in time of a
process for a structural picture is what it sounds like it's trying to do how you use this for
schizophrenia particularly how did you use these methods to understand more um schizophrenia and
how literally the images of the brain for for individuals with schizophrenia how it looks and
how it functions and maybe just talk about that as well I'll just as a as a as a footnote
I worked inpatient uh with individual and outpatient but inpatient with individuals that
have schizophrenia so I I've uh I've been around these folks for a good part of my career and
they're they're very very fascinating individuals um in terms of personality in terms of their
cognition in terms of their brain functioning and you know being on plenty of uh uh you know
treatment plans and big big big long meetings with psychiatrists and neuroscientists uh trying
to understand um schizophrenia but then also understand and how to try to provide clinical
services to individuals with schizophrenia so I'm curious as well personally almost of of
how how did you use these these techniques to try and understand specifically uh individuals
with schizophrenia right again that's an excellent question and it speaks to the motivation for much
of the theoretical work that we've been talking about so understanding um what has gone wrong in
certain people um qualifying this of course you know certain schizophrenia would not like you to
think that their brains have gone wrong that's right that's right they just have a different
reality that's all exactly um I found that's mathematically true by the complete class there
but that's another story um so so um the way that all this fits together is um in terms of
understanding much of psychiatry and many neurological syndromes in terms of false
inference and if you can understand the experiences of a psychiatric patient in terms of false
inference then now we already have a mechanics that is what we've been talking about active
inference the free energy principle and predicted coding base in brain we already have a mechanics
at hand to ask at what point has there been some aberrant um message passing or belief updating
that could lead to this uh this false inference so you may be asking well why on earth would you
want to cast all of psychiatry as false inference um well it's a very natural way of accommodating
that that's where the symptoms lie that's where the ontology of psychiatry lies it's in belief
updating it's in beliefs about the world so when I talk about false inference I imagine that you're
in a simple sense of type one and type two errors false positives and false negatives
so when you think about say an hallucination what is that what it's just inferring something is there
when it's not it's just a type one kind of false inference what about neglect syndromes like
nausea dissociative syndromes um they are just false inferences of a second kind inferring
something is not there when it is uh and I think you know if you think about it nearly all
psychiatric conditions can be construed in this way either falsely inferring something is there
when it's not and vice versa so what that means is you you now move on to the uh the more challenging
and pragmatic questions well what could account for this kind of um false inference and the questions
then um can be posed either to the structure of the implicit generative model that is
entamed so entailed by our brains or the the process theories that undergird the message
passing and the physiology of that message passing and what you're basically talking about is a form
of disconnection now this disconnection may sound odd to talk you know immediately about
disconnection but remember the architecture of any distributed system is defined by its connectivity
the very notion of a hierarchy depends upon the absence of certain connections that would otherwise
transcend levels in say a linear or subsumption hierarchy so connections are everything in terms
of sculpting and defining the architectures that endow the brain with an implicit generative model
of you know its lived world and furthermore the message passing that you know enacts the drives
and the belief updates um you know the precision weighted prediction has that we've been talking
about and those are just expressions of influences from one part of the brain to the other part of
the brain so it's all about the connectivity and that means that you need to now use the
empirical data in a way that enables you to answer questions about disconnections
and they can come in many flavors you know as a neurologist you know subscribing to
early ideas of disconnections from people like Geshwin in terms of lesions to the organs of
connection in the brain the white matter tracks that connect the other long range fibers that
connect different parts of the brain these can be sort of macroscopic disconnections
from the point of view of schizophrenia research that that idea was first proposed by Vernica
who was famous for you know his studies of specialization functional specialization
in the language system but his big gift in terms of psychiatry was the subjunction hypothesis that
you could understand dementia precoxa early formulations of schizophrenia in terms of disruption
to these the organs of connectivity the white matter tracks that we currently um that we currently
study with things like um diffusion weighted um I think resonance imaging or diffuse tractography
that didn't um based upon that that kind of imaging but there was another perspective which
most people are described to boiler um which spoke more about the sort of the fine grain
disintegration of the psyche the you know the loss of coherence and um
you know literally a dissolution at the level of mental life so from our perspective that would
be belief updating which one might nowadays understand much more as a microscopic disconnection
at the level of synapses the little um specializations the little buttons that or plugs that connect
one neuron to another neuron at the end of the um the axon or the long fibers that emanate from a
particular neuronal cell there's a whole bunch of pre and post-synaptic specializations called
called you know called synapses which you base it in the little planks which all the neurotransmitters
act and so in um clinical neuroscience you know a failure of or a disconnection or a failure of
integration at the synaptic level will be known as a synaptopathy a pathology of synaptic connections
so that's the kind of disconnection that most people have now in mind when thinking about the
abnormal message passing that might produce the false inference that is characteristic of
different psychiatric conditions that means you need to be able to measure this you need to have
an in vivo um in life way of measuring the synaptic efficacy the connection strength the gain
that we were talking about before that is modulated through the precision engineered
message passing getting the excitability right these are all different ways of expressing
the synaptic efficacy the strength of connections in the brain and if you think that things like
schizophrenia are manifestations of false inferences that inherit from a very pernicious
and particular kind of synaptopathy which precludes getting the precision right getting the
excitability of say for example neurons reporting prediction errors correct then you need to be
able to measure it and that's where the third technical um contribution to brain imaging comes
in which is the dynamic causal modeling that was used to study the the pandemic so we use the
the dynamic causal modeling to basically study the spread of viruses from person to person
but it was originally devised to study the synaptic efficacy that underwrite the spread of
signals from one member of a neuronal population to another one so that's where it's at at the
moment I mean it's difficult for me to really summarize you know what we were doing and what
we are doing in a nutshell because a bit like the your your first questions about how much we
and I have achieved in my career I think this field also it's a long journey and it's very
incremental and sometimes you're quite surprised by how far you've moved but if you look at the
progress from this year to last year it's almost zero you have to look over 20 years
inception of from my perspective at least dynamic causal modeling that was that was explicitly
done in order to understand disconnections and synaptopathies in schizophrenia because that's
where you know that's where I came from in psychiatry and then it's about now that people
are starting to take this technology seriously and start to apply it at scale and in a way that is
underwritten by companion studies and the same systems in different models in cell cultures for
example so you know there are if you've got one gerogen model under the hood that explains
disconnection of a certain kind due to this synaptopathy which we're now associating with
abnormal precision control of exactly the same kind that Mark was intimating when he's talking
about his broken midbrains because these are the ones that broadcast the signals that control the
synaptic efficacy you're in exactly the same way as you might imagine that happening in Parkinson's
disease where you've got abnormal you're a hypodopaminergic state the component in schizophrenia
being a high potentially hypodopaminergic state and many other conditions so those
that application of dynamic causal modeling at different scales and across scales is now
starting to emerge at least in proposal form no one yet has had the nerve to fund it
my hope is in the next year or two there are sufficient number there are a sufficient number
of proof of principle that it now becomes you know a viable way of proceeding and
to bring things to closure the two areas that seem to have really exploited this
way of making sense of data to get at synaptopathy are epilepsy research in particular childhood
epilepsy and some neurodeterative conditions so that's where the action is at the moment
yeah I could definitely see that I want to ask just just as a since this is your kind of more
closely you're closer to this is about fmri's just as a small side here many people were very
excited about fmri's when they came out you know this is very literally colorful and exciting in
some ways but over time I guess over 30 years now I mean there are some people that would say
that it's a kind of you know modern-day phrenology right um do you agree with that what's the utility
of fmri's if anything and you know how good is it really at translated into I guess better
treatments you know because you know some area because we know with diffusion tensor imaging
that there's all of the brain is connected all of it is linked up all of it is is is talking
with each other different parts of the brain cortical subcortical different lobes everything's
talking to each other so how do we understand I guess the utility of fmri's if at all um and
and how how could it translate I guess into to better treatments so you say that some people
are starting to call it a sort of latter-day uh phrenology in fact they were they were calling
it that at the inception of the new cartography the new the neo phrenology um which is a fair
a fair a fair critique um so I think the the answer to that question is a little bit like
this you know how far we come in our journey if you ask year by year yes the the advances
have been incremental at best but if you just look back with a temporal resolution of decades
fmri has had quite a profound impact on the little cognitive and translational neurosciences
so simple things which people of your gentle and tender age will not be aware of simple things
that you take for granted were just hypotheses in 1989-1990 for example the whole notion of
functional specialization in the brain that underwrote sort of fedorian modalities and
all sorts of hypotheses about in fact uh also um sub-tended neo phrenology the notion that one
part of the brain did this and another part of the brain did that so this is a notion of
functional specialization the particular segregation that this particular functionality
was segregated anatomically or spatially to this part of the brain uh and that therefore we had at
least a good hypothesis about the um predictions that would ensue foreign brain damage and we
can make some uh guesses about the importance of connectivity under the functional segregation
hypothesis no one knew though no one up until 1990 you know 1918-1989 knew what no one knew that
there was for example um color specialization in this particular part of v4 that was segregated
in the sense that there was no color alleged responses elsewhere and you couldn't do that
because you'd have to have electrodes everywhere in the brain in order to show that it was this
part of the brain responding to color and not that part of the brain so it's only in the early 1990s
that people could actually after about 200 years possibly 150 years um confirm the original hypothesis
about functional localization and specialization and segregation in the brain that was a profound
thing as I say from your perspective you know you just assume that people in the 1980s believed
that functional specialization was a principle of brain localization they didn't believe it but it
was just a hypothesis and there was doubt after fmi there was no doubt it was just part of the
foundation of neurophrenology um the the the second sort of big point to make is that you know
if you want to understand how a virus spreads um or how a meme spreads or how um messages spread
in a deep neural network or how belief updating operates in a functionally segregated and specialized
hierarchical brain you have to have a way of identifying the things that are connected so
if you are truly a cartographer when you go to a new country the first thing you do is identify
the landmarks before you start worrying about the communication the rivers or indeed if it's a
developed country the the routes of communication the rail links and all that good stuff the first
thing you do is have to identify what's happening where in terms of these functionally segregated
definitive aspects of any map or before you can talk about distributed processing well distributed
amongst what well amongst the functionally specialized areas or where are they we can now
identify those using fmi but of course that's just the first step so within about sort of five to
eight years people were tearing their attention to the real question which is back to the connectivity
it's a black it's back to the principles that underwrite the distributed processing as you say
understanding why every part of the basis could be connected at least with two degrees of freedom
to every other part of the brain so that that's where the big questions were and
subsequently addressed in terms of fundamental distinctions between things like functional
effective connectivity there was you know a period when all the excitement was about
some measuring correlations and functional connectivities in the brain but throughout that
period of course you know things like dynamic causal modeling were being developed in order to
measure the actual directed coupling that subtended these correlations that people
measuring with functional connectivity so was fmi or is fmi useful in that regard and has it had
any material effect on um sort of treatment i i i mean i can cite particular examples in terms of
epilepsy research and the identification of sort of elegant areas the use of imaging as a biomarkers
in say genetic studies a predisposition to various illnesses you know i could give you a number of some
sort of quite compelling but very um colloquial examples of where it has worked i would i would
sort of concur with you that there hasn't been an awakening of insights it's more a consolidation
of what we have known from centuries of careful neural anatomy and neurophysiology
ever-increasing fine-grainness that allows us now to talk about the particular sub receptors
involved in a particular syndrome that underwrite the synaptic or the synatopathy that's producing
the the discoloration in your in this particular system so the interceptive system involving the
anterior siglum and the anterior insular so it's really people really drilling down on the
fine-grained in certain quarters of neuroimaging that there's not a b-grade stuff as well um
but you know the a-grade mechanistically mechanistic um theory driven applications hypothesis driven
applications of neuroimaging you know really has advanced quite quite remarkably on in the basic
neuroscience is that you know whether that has yet to translate into clinical neuroscience
you know i think that's an open question but you know the answer i think will only reveal itself
when you look back and say what's happened in the past 10 years and then you probably get a much more
positive uh uh response than otherwise it's one final comment and it certainly is the case that
fMRI as um uh an imaging modality um has lost its shine in the sense of its appalling temporal
resolution um which means that most earnest imaging neuroscientists or cognitive neuroscientists or
indeed clinical neuroscientists would want to supplement the the cartographic gift of fMRI
with highly resolved electromagnetic electrophysiological responses so you know anybody doing
any serious imaging neuroscience nowadays would would also recourse to electromagnetic signals
and understanding distributed processing at that level guided by the cartography on offer from fMRI
yeah no that's that's that's important to to to also keep in mind as well well my my my last
question for you is uh i guess sort of a sort of a big one uh there's two parts to it so the first
part is you've talked about many of your um theoretical uh principles you've talked about
some of the stuff from the the imaging techniques so we've talked about the Bayesian brain which has
some utility but has many utilities but many people are are starting to talk more about it
mainstream um have been for for many years but in terms of your free energy principle and how you
use this with active interference inference excuse me um predictive coding theory how
how do you how do you think um this can be translated to the common person right how can
people use these wonderful theoretical structures and frameworks in a way that's applied and has
some pragmatic utility in ways that everyone can kind of grasp and say oh yes i got that and i see
how this is really important or use it in various clinical practices in whichever domain in psychiatry
neuroscience and psychology etc how how do you think um the ability to translate those models
and theories into practical applied use is is is key and and ways to do that and then larger frame
or larger or uh of this is for neuroscience as a whole you know how do you see um in neuroscience
you know its utilities maybe some of its limitations but how it's it's useful for for people to
continue to understand the complexities of neuroscience in a sense we've already um
sort of covered i think the the two key um practical applications um and perhaps it would
probably just to rehearse the point that there's a lot of similarity between the free energy principle
and um the theory of natural selection you know in and of themselves they do nothing for you you've
actually got to want to answer a question in a particular situation or to build something
um in a you know in a given circumstance um and then you know the free energy principle and its
attendant process there is will certainly provide you the functional forms and the
architecture and mechanics to do that quite quickly and efficiently and so the question now
is why would you ever want to build those things and how could you practically use them
in terms of um building sentient artifacts you what what you know i just remind myself and you
know recall an earlier part of the conversation that what we have now is a um an off-the-shelf set
of belief updating schemes that should in principle um create curious sentient robots and artifacts
that will be um to my mind the next step in artificial or machine learning and i say that
from a number of perspectives first of all in terms of you know what's um what is a use case
that will be appreciated by members of the public i i generally think that it's probably going to be
the the manufacture of little pets uh as much of of you know public basic ai has has has pursued
but the difference will be here these artificial pets will actually have a curiosity and and it
will be so it will be much easier to um project an anthropomorphosize and to um apply theory of
mind to these kinds of little curious pets and so they'll they'll become increasingly um
more like your actual favorite pet or your your pet or your dog simply because they now have
curiosity under the hood so that's how i personally think that people are going to make
money out of active inference it's just equipping these little robots with a curiosity uh or to use
Jürgen Schmidt who was phrasing artificial curiosity and interestingly mentioning Jürgen
Schmidt who but of course he you know he thinks that's the essence of creativity and fun this
this is curiosity this epistemic drive this information seeking part of resolving uncertainty
or maximizing information gain through actively soliciting evidence for your gelator models in
the world um in terms of machine learning um and the more um i think pressing uh a less trivial
issue of uh sustainability um the um the the whole point of active inference is that it is um
obeys optimal in the way that it gets data and assimilates those data and that optimality
expresses itself in a certain kinds of efficiency um which i think are going to be very important in
terms of sustainable computation and energy use so i've heard that in 2025 about 20 percent if not
22 percent of the total energy consumption globally will be um by data farms and uh you know e-commerce
and x-rays so this is a really you feel like um thermodynamically and climate change relevant
observation that there are good ways to make inference into data mine and there are bad ways
now the good ways are those that conform to Hampton's principle least action that's a free
energy principle that you minimize in your process of inference or active inference you maximize the
evidence which mathematically simply means minimizing the complexity with uh under accuracy
constraints where the complexity is the the cost you pay in terms of belief update is literally
that measure of movement from the prior to the posterior that costs energy via the Zhuninsky
equality which means if you use the wrong kind of um overly parameterized generative model say
with a billion parameters in a state of the art deep learning network you are doing it in the
statistically least optimal way and using a massive amount of electricity uh so another
way of stating that is the direction of travel in machine learning in particular deep learning
is exactly the wrong direction because it relies upon big data and overly parameterized
overly complex generative models so i'm hoping that active inference the free energy principle
will reverse that direction of travel through proof of principle so what we have instead now
is not throwing billions of data points at your deep learning machine and millions of dollars
to a team of engineers who are trying to um handcraft and tune the parameters of the of
their particular variational autoencoder along short-term memory layers in your convolutional
network instead you will spend you will let the machine itself decide what is the most
informative data it needs to resolve its uncertainty it will run either um on an edge computing device
but it's only running your laptop and it should finish and convert within minutes to days as opposed
to days to months and it will cost you a hundred dollars or even ten dollars as opposed to up to
a million dollars so i'm deliberately completely overstating the benefits but the you know that
reversal of direction of travel is mathematically obvious it hits you in the face when you start to
sort of articulate computation and intelligence in terms of the presence of inference and just
look at the underlying maths in terms of the information geometry and then using things like
the djinsky equality to understand that in terms of the both the computational cost but also the
thermodynamic cost of computation so i think that's going to be um in principle i'm sure i'm
completely wrong i'm talking complete rubbish but in my little fantasy world data mining is a
thing of the past you won't need data farms because instead of going for mining big data these curious
machines will go and mine just the sparse data they need to resolve their uncertainty for what
they are for the context in which they operate so we'll see a move to edge computing with sparse
data but it will be base optimal in a sense it's just returning to the basic principles of optimal
basing design established in the 1950s by people like david lindy sort of revisited by people like
david mckine in terms of active learning in the 1990s and then apparently completely forgotten about
until the active inference movement or pushback against the direction of travel and
sort of standard deep learning approaches or even reinforcement learning without the curiosity
it's it's it's it's incredible to think about all of the avenues that it that this has the
potential to to expand with well i mean i don't know what to say carl you've been so so generous
i mean more than generous with with your time and i i consider it a great privilege and honor
that you have given me over three hours of your time to explain this that's that's quite the gift
and i greatly appreciate that is there any final comments that you want to say or anything that
you want to summarize or anything like that and and then also i'm very impressed with your stamina
stamina and also there's some you know the patience with which you ask your questions
wait for about 20 minutes for an answer that that is quite remarkable so thank you
no i the the pleasure is is all mine you have been very very generous and i am quite sure that
listeners will be very very thrilled to to hear all of your wonderful work that you've been doing
so um can't say enough thanks appreciate it
you
you
