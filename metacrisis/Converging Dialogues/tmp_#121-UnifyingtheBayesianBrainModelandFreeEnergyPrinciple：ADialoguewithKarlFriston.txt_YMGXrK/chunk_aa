Hello, welcome to Converging Dialogues. This is Xavier Bonilla. Okay, on this episode, I
am very pleased and honored to have the extremely brilliant Carl Friston. Carl is a theoretical
neuroscientist and pretty much one of the major authorities on brain imaging. He is a professor
at the Institute of Neurology at University of College London, consultant for the National
Hospital for Neurology and Neurosurgery in the United Kingdom. He has invented many aspects
of brain imaging, including the statistical parametric mapping, voxel-based morphometry,
and dynamic causal modeling. Much of these were used in schizophrenia research, which we talk about.
He talks about this in terms of his day job, and then he has his weekend job, which is trying to
find these theoretical models and structures of the human brain. One of these theoretical
neurobiological models is what he titles the free energy principle, which we talk much about,
which also has some connections with the Bayesian brain model. He is a fellow of the Royal Society
of Biology, and he has many honorary doctorates. We have a wide-ranging conversation about many,
many, many topics. This conversation is over three hours, and I was absolutely privileged to
get over three hours with him. He was very generous with his time and his energy and his mind.
We talk about everything. We first start by talking about the history of models of the brain,
over time there have been many models of the brain, and so he gives a history of what that
looked like. We talk about the evolutionary components of the brain and how executive
functioning and abstraction work with various organisms. We give an overview of the Bayesian
brain. We talk about predictive coding or Bayesian filtering. We talk about the two classes of
neurons for prediction error and for predictions. He gives a very, very nice comprehensive explanation
of the free energy principle. We talk about the importance of a Markov blanket and the importance
of equilibrium and homeostasis. We talk about the free energy principle and a little bit of
Freudian psychoanalysis and some of the connection there. We talk about his views on consciousness
and how active inference is in play. We talk about AI. We talk about the various neuroimaging
techniques that I mentioned earlier. We talk about fMRIs and some of their challenges there.
We also then end towards the end of the conversation with how the free energy principle could be used
pragmatically. I have to say this conversation is long, but it's very engaging. I found the
conversation to be very engaging. Even though it's pretty dense in some areas, I found it pretty easy
to track and follow along. Carl does a really nice job of explaining very hard and difficult
concepts in pretty easy to understand ways without losing the integrity of the concepts.
It definitely requires some attention because these are some really complicated ideas,
but I think it's super important. He's doing really important work both in his day job and the
imaging for the brain and then also his weekend job, as he says, for trying to understand
a theoretical framework and to understand that the neurophysiology and neurobiology
of how things work together and how this can interact with engineering, AI,
kind of computational neuroscience, neuropsychology, etc. Again, it was an absolute
honor and privilege to have him on the podcast and to give me so much time and energy. I'm very
pleased to bring you Carl Friston. I'm here with Carl Friston. Carl, it is a big honor and
a privilege, sir. So I thank you so much for coming on the podcast and being willing to talk to us
about your very important work and all of the things you've been researching. So a big thanks to
you. Well, it's a pleasure to be here. Thank you for asking me. Of course. So for folks that don't
know who you are, kind of give your potted biography, just give us the snapshot of who you are,
what you do, what you study and all of the all the particulars.
Right. I have my day job and my day job is a professor of neuroscience at University College,
London, with a special expertise in human brain scanning. So I originally trained as a psychiatrist
and got into the field of imaging neuroscience in an attempt to understand
disorders like schizophrenia by literally looking at the brain as best we could or as best we can
using modern technology. And then I have a weekend job, which is more of a theoretical
neuroscientist. And laterally, one could generalize that to being a theoretical biologist or a
bio mathematician, trying to understand the fundamentals of sentient behavior, the principles
that underlie the way that we make sense of the world that informs and is informed by the day job.
So the more you know about what the brain must be doing, the more you can start to
look at the empirical results from the brain imaging and understand the message passing
and the fluctuations in your electivity in the service of sense making.
Yeah, that's very, very important. I guess I do want to ask you about the imaging piece.
How did you kind of, I guess, stumble into this kind of way of doing the day job and the weekend
job? This is something that you mentioned you were trained as a psychiatrist, but was this
something that you always wanted to do? You were always curious about the brain and looking at
different ways of understanding its functioning. And then did the theoretical stuff kind of come
later? Or how did this kind of, I guess, morph into where you're at now and what you're currently
doing? That's an excellent question, which I could answer quickly or take a very long time answering.
Whichever way you want. Let's do the quick one. Now, I always wanted to do this. So what I am
doing now is really the denouement of a series of serendipitous and lucky career choices that
actually started around the age of 15 wanting to be what in those days would have been known
as a mathematical psychologist. So a dual commitment to understanding the most interesting
thing, which of course was me and my brain at that time and other people's brain,
but using a formal calculus, your principal approach. So trying to maintain a training and
investment in physics and mathematics, a sort of dual early career in psychology and physics.
And then went into psychiatry as the most alluring and I have to confess the easiest
way to become a medic at that point in time because everybody else wanted to be a heart
surgeon at that time. Everybody wants to be a GP nowadays, but my cohort, they all wanted to be
heart surgeons. So I ended up in psychiatry and very much valued that experience, but of course
it was exactly in the direction of travel in terms of what I ultimately wanted to do,
which was research into what would nowadays I guess be thought of as theoretical neurobiology
or computational neuroscience, but essentially the formal principles that underwrite our ability
to engage with the world and make sense of that world. Yeah, it's interesting the way you put
it because I think that finding out kind of how you, as you say, there's this serendipitous way
of falling into these things, which is I think kind of true for a lot of people, right? They have a
one way in which they want to do things when they're younger and then they take the long way
up the mountain. But the other thing is having a desire or passion to want to do something
to understand the brain and many people want to understand the brain. But then having the IQ
points and the capacity to do that, you've written some pretty prolific papers. And so
having the ability to do the equations, to do the math, to be able to do these things,
that had to be all of just when it kind of fit together, had to have been pretty remarkable,
I guess, for yourself to be like, you know what, I have this interest and I can actually
cognitively do this, I can figure this out. What has that, I guess, just been like as you
progress through your life and be like, you know what, yeah, I've done a few things,
I've researched a few things, I've figured some things out about the brain. If you kind of look
back on that, how does that just all kind of sit with you, I guess? I would imagine it's the same
kind of sense that people have when they look back on their lives. It's a long journey.
When you look at the journey in retrospect, you are sometimes surprised by how far you have come.
But of course, in pursuing at any one moment in that journey, it all seems very incremental.
So it seems unremarkable during the travel. Unremarkable in the sense that things change quite
slowly and are the reflection of the way that you've invested in the early parts of the journey.
So coming back again to this early commitment to a formal way of expressing ideas. So knowing
that meant that you have to spend many years learning quantum physics and probability theory,
which then you immediately forgot as soon as you went into psychology. At least you left with the
legacy that you knew you could learn it and you couldn't do it if necessary. And of course,
in later life, it didn't become necessary. But I repeat, I've forgotten everything I learned
as a 20 year old. But with the boon, the gift of Wikipedia, I was soon able to get back up to
speed again. So all of this prolific writing that is often claimed to be quite inscrutable
mathematically difficult to access that from my perspective is a nonsense. You can get all the
maths you need from Wikipedia, because that's exactly where I got it.
The power of technology is remarkable in many ways. So that's great. So obviously, I want to get to
your your main, your main, I guess, theoretical claim to fame, if you will. I mean, many claims
to fame, but I definitely want to talk about the free energy principle and just have you download
that for us and just tell us everything about it. And as much details you'd like, I figure before
we get to that, it might be helpful. And you can tell me what you think of this might be helpful to
kind of look at a history and overview of various brain models that we've had,
and how leading up to the the current brain model that we know, and then we can branch off to that
into the kind of Bayesian brain model, which which is also more relevant and salient at the moment.
So maybe if you could just in your in your from your viewpoint, how do we understand a history
of various brain models? Where does it kind of first start and originate? And, you know, you
can just kind of kind of march us through how that gets us to current day and what the current brain
models are. Well, yeah, that in fact, that would be, I think, one fairly comprehensive and complete
way of understanding the free energy principle, which is just a new month of a long legacy of
ideas that I think you could probably trace back to the students of Plato, and shadows on
caves and the like. But for me, most clearly articulated by Helmholtz in the 19th century,
sort of polymath, who had a deep understanding of physics, but also perception and, you know,
various aspects of of sentience. And many of his ideas essentially summarized in the form of
unconscious inference. So the notion that the brain was a constructive organ that was inferring
the causes of its sensations. So the idea here is that what is out there is not directly accessible
from the skull bound brain, but has to be hypothesized, you have to have the cause of
your sensations in mind, in order to use the sensory impressions upon your eyes, your ears,
your skin as evidence for against that hypothesis. So as Andy Clark would put it, this is very much
an inside out approach to perception, as opposed to an outside in view, which actually dominated
in the 20th century, but then went away again, where the the world impresses itself upon your
sensory epithelia, and you somehow extract information from that to get to the conclusion,
oh, this is the cause of my sensations. Helmholtz had a much more nuanced and veridical survey by
21st century standards, veridical understanding of the mechanics of perception, where you had to
actually generate the hypothesis, and then you just used the sensory evidence at hand to update
your beliefs, adjust your explanation for those sensations and in that adjustment, in the updating,
on the inside, through neural activity, you were able to produce an approximate or
partially faithful reproduction of what could have caused your sensations, and he called that
unconscious inference, that notion remained in abeyance through 20th century behaviorism,
manifesting in many different ways. Things that come to mind include analysis by synthesis,
one key contribution from psychology was the notion of perception explicitly as hypothesis,
testing, this is Richard Gregory, a UK psychologist's notion, again reiterating the importance of
inference, so for Helmholtz it's really unconscious inference, for Gregory it would have been,
you know, the perceptual act is basically a test of a hypothesis, that this visual object
is the best explanation for this pattern of sensory impressions, say on my retina. Those ideas
came to fruition in machine learning and computational neuroscience, I would imagine the
80s and possibly the 90s, probably best exemplified by the Helmholtz machine,
deferring back to Helmholtz's original ideas by Geoffrey Hinton and colleagues and Peter Dianne
and colleagues, so leveraging those deep insights from Helmholtz and then putting them into a
recurrent neural network or a network of a particular kind of Boltzmann machine,
effectively training neural networks in a way that we would now understand the training of
deep neural networks in deep learning, for example, to infer. We now understand that as
amortization if you were in machine learning, it would be this notion that you can train the
connectivity of a neural network to make sense by inferring the causes of its inputs because,
you know, it's a simple move to understand this scheme or algorithm of the Helmholtz machine
as also applicable to neural networks, and at that point in time people were converging on
very similar ideas from a slightly different direction, namely that of predictive coding.
So predictive coding was originally devised in engineering as the most efficient way to
compress sound files in the 1950s. There's an interesting connection here between the notion
of compressibility and efficiency and the statistical efficiency of a good inference,
which we may well come back to in relation to the conversation, but at this stage in terms of
the history and the legacy, there was in the 90s a key convergence on the brain as an inference
machine and the brain as a predictive machine. So we then see the emergence of predictive
processing or predictive coding in particular, perhaps just for your listeners just to make
this a bit more explicit, the predictive coding is defined in terms of a scheme that is trying
to resolve prediction errors. So we have this notion now of the brain generating top-down
predictions on the basis of its currently preferred beliefs about the state of the world.
Those predictions then compared with the sensory input and then the mismatch or the
divergence between the predictions and the observations, the sensory samples, are then
denoted as a prediction error. And then that prediction error is a broadcast deep into the
brain's hierarchy to update and revise the hypotheses or the representations that are
generating the predictions. And I use the word generation there because all of this machinery
or this message passing with sense-making comes under a particular generative model
that is entailed by the architecture of the brain. So you have this picture now of the brain
broadcasting from the inside out descending down the hierarchy its predictions and there's
a counter stream of ascending prediction errors that are revising and updating the
predictions in virtue of changing the representations that can also be cast in
Bayesian terms as Bayesian belief updating. So now you've got another church of mathematicians,
theoreticians in the game, you've got the Helmholtz machine, you've got predictive coding people
from engineering and also people start people like Simon McLaughlin and
Raj Reo and Dala Ballard noted that these predictive coding principles were very apt to
explain a lot of the functional architectures of the brain. David Mumford I think was a key
contributor to those ideas in the early 90s and is not usually acknowledged as such but you know
if you go back in very early 90s you're very explicit and what proved to be a visionary account
of the neuronal architectures that did the job of the Helmholtz machine that did predictive coding,
did hierarchical Bayesian inference. So then you have the joint emergence of Helmholtz machines,
machine learning, the Bayesian brain hypothesis in the neurosciences and predictive coding as
a particular process theory that sort of enacted this. So that was a story at the end of the 20th
century at which point there was an enacted term, a turn back to the forees, the importance of
situated cognition, the importance of the fact that you have a body, that your perception is
an active thing. You actively help hate the world at every level, every sensory modality,
whether it's literally feeling a way around the dark room to confirm your hypothesis about
this is a telephone, this is the bed, this is my iPhone through to palpating the world visually
through active vision, moving your eyes around something. This part of the visual scene to test
this hypothesis or that hypothesis. So this embodied inactivist extended and by extended here
ones acknowledging that a lot of your cognitive abilities are downloadable into the environment.
The key thing here though is this inactive term. So how did predictive coding,
the Bayesian brain hypothesis survive the inactive turn? Well, very, very simply that there are two
ways that you could effectively resolve your prediction errors. You could either literally
change your mind in the good old fashioned predictive coding way, use your prediction errors
to drive a change of mind of Bayesian belief updating. So the predictions now were more fit
for purpose and expanding where the sensory inputs and thereby the prediction has effectively
canceling themselves, resolving themselves through this hierarchical message passing the brain.
Or, and here's the twist, you could literally go and resample the sensory input to make it match
