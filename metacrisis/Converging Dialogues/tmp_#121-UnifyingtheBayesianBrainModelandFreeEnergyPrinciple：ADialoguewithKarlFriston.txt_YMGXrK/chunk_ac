execute those plans in the same way, though the thermostat doesn't even know it's a thermostat,
and that it's even acting. So I think that the levels of abstraction you're referring to here
are exactly the abstraction and the plausible hypothesis that in fact I am an object, and
indeed I am the subject of my own observations and actions, and having that hypothesis as part of
the genitive model now has to be explained. And how can it be explained? How could it be that I now
have a better genitive model or explanation of my sensorium that has been actively constructed
simply by having this notion that I am a person. And I think there are quite simple answers to that
because of course it's not just I am a person. I'm a person in this police state, on that police
state, on that emotional state, or this intentional proposition state. And once I recognize myself to
be in that state, and implicitly now I have a degree of qualitative experience of my inference
there in the hierarchy, then I can now bring to bear and contextualize all my message passing an
inference conditional upon my now recognized state. So for example, if I know that I am anxious,
or I am embarrassed, I know that there will be certain kinds of information to which I would
be paying attention. There will be certain sort of autonomic actions that I would normally be
engaging in this context of being embarrassed or being frightened, such as cardio acceleration,
or paying particular attention to auditory and visceral streams, for example. So there is
an easy to argue benefit for having these higher levels of more deeply abstracted representations
and explanations for the active inference and all the message passing that's going on
underneath. And I think if you go right to the top of the hierarchy, to the very highest form
of human life, which would be a philosopher, what you find there are representations and hypotheses
that just are quenia and qualitative experience. So this is touching on now
something which David Chalmers as popularizes, the meta-problem or the meta-hard problem,
is why do we puzzle about our qualitative experiences? I don't do that. So what special
aspects of our generative models can explain the very fact that we can entertain notions like
being a zombie, for example, thought experiments like brain and a vat. The very fact that we can
entertain these counterfactual outlandish hypotheses about self is the gift, if you like,
of having these deeply abstracted representations of how we engage with the world. First of all,
just having a representation of me or selfhood and then me as an actively inferring agent
that must in some sense have some internal action over the way in which I secure the evidence and
test my hypotheses. I'm trying to work here to something which I think Mark Somes may have
talked about, which is what underwrites the feeling part, the qualitative experience
that the philosophers talk about in terms of quenia. The essence that we think we can
entertain and have discourse about, that perhaps a mouse might not be able to talk about. It may
have, but it wouldn't be able to recognize it or talk about it. It's just not there. It just can't
see that kind of thing. In the same sense that a blind person can't see color, it may well be
that a mouse just does not have these hierarchical levels of abstraction. So it's just not perceivable
in the sense of health holds. You have to have it in mind before you can sense it.
The answer that somebody like Mark Somes, I think a lot of people would bring to the table here,
is the notion of confidence or precision or a representation of uncertainty in one's beliefs
and getting that right. That basically entails a kind of mental action. So now we're talking about
action, not on the outside, not autonomic actions like secreting something or cardio acceleration.
We're not talking about motor actions, motor reflexes, moving my limbs around with my
straightened muscles. We're talking about a covert internalized action,
where some very, very high levels of a hierarchy or very deep levels, perhaps at the center of the
brain from Mark Somes' perspective, have an influence on the belief updating that underwrites
the action selection. That influence is really a statement that we're able to represent our own
beliefs. We have beliefs about beliefs. A particular example here is we have certain beliefs about
our beliefs that pertain to the uncertainty. So if you have in mind the simple mathematical
description of a belief as a probability distribution, so when people talk about Bayesian
beliefs, they repeat, they're not talking about sort of ideological or theological commitment.
They're just talking about the brain as a sentient artifact that is somehow encoding a
probability distribution. Invariably, these kinds of beliefs, these Bayesian beliefs or
conditional probability distributions, have two cardinal aspects. They have a location,
so the most likely thing I believe, or the Bayesian belief entails,
is designated by the peak of the probability distribution, but there's another shape parameter,
another aspect of this probability density or distribution, which is its spread or dispersion,
and that's usually understood in terms of uncertainty. So a very broad distribution means
all of these things could be in play, whereas a very sharp, very precise distribution means that
I'm pretty confident that it's just underneath this very sharp distribution. So that precision
is a really important attribute of the belief, and if parts of the brain now have beliefs about
beliefs, they are now predicting precision, predicting predictability, and that may well be
the thing that calls for covert mental action and the need for recognizing that I'm in this
belief state, on this state of uncertainty, on that state of uncertainty, and then I can now deploy
the appropriate beliefs about beliefs or predictions of predictability or predictions of precision.
Yeah, it's interesting on that last point, because you're sounding like you're describing
as this type of metacognition that's interested in our own epistemology and also our ontology
as well, that we're very concerned about our beliefs and how we have these beliefs about them,
or even things about our own existence or things about us, who we are as beings.
One other point I wanted to make about the abstraction piece is that I totally agree,
obviously, but I think even more miraculous, if you will, or more wonderful is the fact that for
humans, not only can we have these levels of abstraction, but I always think of this example
of like, you know, I can know that I'm thinking about a concept or I can know that someone else
is potentially thinking about a concept, right? There's this way of abstracting with the other.
But even further, if you take works of fiction, let's say, let's say I'm reading a novel and the
central character is thinking about a thought he had in a dream that he had, and I'm the one
reading that thought that someone wrote. You have like six layers of abstraction there, right?
This is a very big, big, big, wide lens of things, which is incredible. It's incredible. Our mind
doesn't fold up because of how complicated or complex that is, and I don't know if other
animals on the planet can, you know, read novels and get the whole contractory if people watch a
movie, right? And they can see or observe all of these things. So it's very interesting about
the abstraction. And I liked how you linked with the various components of executive functioning
for detailing that. We've talked a lot about the Bayesian brain, and we've mentioned many components
of it. Maybe we can give for listeners the kind of overview of the Bayesian brain, and then that
will kind of dovetail into the free energy principle, and I'll give you a lot of runway for
that. You can talk all about that. So you correct me if I'm wrong. My limited understanding of the
Bayesian brain is that the brain is essentially equipped with an internal model of the environment,
and that gives us a plan for how we create sensory observations from hidden states, right?
That's one way of saying it. And that there are these hidden variables that are from a prior
distribution. You could say maybe, I don't know, if you want to use a Freudian term, the unconscious,
we can come to Freud at some point. And then also that these sensory observations
are have a distribution conditional on the hidden states. So then you have these priors,
and you have a likelihood combined to infer the hidden state given the observations.
So I think the clarifying point here is that these aren't specific claims about priors and
likelihoods for an individual, but more so on the consistency of them. That's my very limited
scope of the Bayesian brain. So maybe kind of branch off of that and just kind of give us the full
overview of what we mean by the Bayesian brain priors, likelihood, hidden states, and then we
can jump into the free energy principle. Right. And I mean, that description was spot on in itself.
So all I need to do is to connect what you've just described to what we're talking about. So
I think that we basically have done the Bayesian brain. And we've done the finest and most delicate
aspects of the Bayesian brain under a hierarchical genetic model when you started talking about the
other six degrees of hierarchical embedding. And I'm glad you use the word metacognition.
So that's what I was trying to imply when I was talking about beliefs about beliefs.
This is exactly it. And it is this hierarchical recursive embedding, which is quite remarkable.
I kind of will use the word fall down or unfold, but certainly at about six degrees of
recursion, my brain gives up. And I think at that point here, that may be the explanation
for the better hard problem that even philosophers can't quite handle that. And that residual
puzzlement, you know, inspires us to try and get to the seventh or the eighth. But it is exactly
that sort of beliefs about beliefs about beliefs. The other key thing you just brought to the table
before just unpacking the Bayesian brain in the language and the setting that we've already
established, you brought another really key thing to the table, which is inference about others.
And I was tempted to say, well, perhaps that's one aspect of the third way that we haven't talked
about. We haven't spoken about them. And perhaps we should have spoken about because
everything that we've spoken about thus far would work for a single agent in a universe that did
not have anything else like it in that universe. It's just making sense of a universe. But of
course, most of the interesting questions in terms of self understanding are in light of
or contextualized by the need to understand others. So we're now moving from the Bayesian brain and
beyond that to the embodied Bayesian brain, which is the third issue that we still yet to talk about.
But now to multiple Bayesian brains in an ensemble, all trying to infer each other.
And that brings some really interesting questions to the table about
self understanding in relation to others understanding. And there could be an argument
that the need for selfhood or an explicit ability to recognize I am a self and to have at least
a minimal selfhood is just a product of being required to disambiguate the causes of my sensations
in terms of did I cause that or did you cause that or perhaps more practically more relevant
would be during very early neonatal experience. Did I cause that or did mother cause that? So
mother being the key other and this being able to first of all recognize that mother is actually
an object out there that is distinct from me is a great move to be able to do and something that
takes you a long time for a neonate to and not every neonate recognizes that and can learn
the appropriate character models that explains interactions or our interactions with mom
in terms of mom being a creature. Because once you realize that mom is a creature on an object
out there, then the natural hypothesis might be to entail well perhaps I am a creature and why
would you need to do that? Well you need to do that to disambiguate did I cause that or did mom
cause that? So that elemental theory of mine that ability to distinguish between the causes of
sensations in terms of self versus other may be unique to creatures that have a universe or an
environment that is populated by creatures like them such as you and me. So I think this is a really
key aspect of this sort of self evidencing self evidencing yes but it's in the context of a whole
world comprised of things which are just like me so I have to now be very skilled and differentiating
me from you and in so doing of course that pressure is only evinced if you are sufficiently
similar to me and cause the same kinds of sounds and edited touches and sensations that I could
cause. I don't need to do that given that you are physically very similar to me but if you're
that similar to me I can now use my gelatine models my explanations of the world to explain
which I would normally use to explain my autonomic dispositions and you know my bodily
sensations or my movements. I can now use those prior beliefs selections of the plans that we
were talking about our intentions to explain your intentions or more specifically to explain
your behavior your facial configuration your micro expressions your physical stance
in terms of your intentions which would be the tensions I would have to have in order to witness
and you know to manifest the same kind of observable behaviors. So I think that you know that's a
really important thing you brought to the table when you know in terms of self-hood
and self-evidencing or being particularly acute and important in the context of you know a world
that has a culture that is born of the fact that we are we popular that world with lots of
conspecifics and we have a you know we have a shared eco niche in which to do that. So I just
wanted to put that on the table because it's a really important sort of thing when it comes to
sort of interpersonal exchanges yeah absolutely and but the base you know back to the basic
brain well you just summarized it I mean I don't you've done all the heavy lifting there I think
probably best is to say out loud at this point there is nothing that the Bayesian brain brings to
the table we haven't already spoken about it's just a way one way of articulating the kind of
sense-making where we have say prediction errors sending the hierarchy from the from the
sensory cortex the sensory parts of our brain and updating representations
that would be in a Bayesian sense regarded as posterior beliefs so what I'm going to do now is
just tell the Bayesian brain story from the point of view of somebody who likes to talk about
predictive coding we've already established predictive coding predictive coding I should
just add if I was talking to an engineer I wouldn't use the word predictive coding I would use the
phrase Bayesian filtering the simplest instance of a Bayesian filter is something called a
Kalman filter which is used widely in state estimation so predictive coding just is
Kalman filtering of an extended and nonlinear form sometimes known as an extended Kalman
bucey filter of a hierarchical sort so these things are all the same but different people
like to use different language so what would how would you understand Bayesian inference
from the point of view of predictive coding well as you say Bayesian inference is just
the process of belief updating how would you articulate that from the Bayesian brain hypothesis
well that update is just an update to your Bayesian beliefs your conditional probability
distributions prior to seeing some data to some beliefs after or a posterior so you're
just updating your prior belief to your posterior belief you're literally changing your mind
you're just moving through changing your activity or weights or connection strengths in your brain
you're changing the implicit or encoded Bayesian belief from a prior belief before you saw the
data to a posterior belief after you saw the data and that movement from one belief to another
belief literally changing your mind is the updating that is driven by the prediction
errors so the next question then would be well what is the nature of that updating
as we if you like mix together the prior belief and the light the information afforded by the
likelihood of these data to produce the posterior belief so that's just to explain to the listeners
why there were three kinds of beliefs there's a light distribution a prior belief and a posterior
belief and really the likelihood if you mix together the prior belief and the likelihood
and the likelihood then you get the posterior out so the likelihood stands in for the
pressure or the forces applied to changing your mind that drive a change in mind or
the belief updating that are afforded by the data and this is I think a useful view
because it allows us to come back to this notion of precision
it's difficult to do without a whiteboard or a blackboard
but let's have a go because this is I think an intuitive and really important
important observation which brings us back there's a mental action and the notion of
predictions of precision so if I had a very very vague imprecise prior belief
and I had some very definitive very precise sensory evidence that could be of an elemental
sort like the particular pattern of visual impressions in a well-lit room or it could
indeed a more abstract level be some definitive information from Wikipedia
but if it's very precise then that precise likelihood will have a very sharp narrow distribution
and will pull the soft flat prior distribution much closer to the likelihood
so that my posterior now is now dominated by the shape and the form of the likelihood
so I've induced a much greater degree of belief updating I've changed my mind considerably more
than I would have done simply because I ascribed a greater precision to these data
so it had a much more precise likelihood conversely if I have a very very precise
prior belief that is based upon lots and lots of experience then it's going to be much less
sensitive to any likelihood or any belief updating so my posterior is going to be
if you like tethered to my prior belief as I changed my mind and I moved from my
