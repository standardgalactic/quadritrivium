early ideas of disconnections from people like Geshwin in terms of lesions to the organs of
connection in the brain the white matter tracks that connect the other long range fibers that
connect different parts of the brain these can be sort of macroscopic disconnections
from the point of view of schizophrenia research that that idea was first proposed by Vernica
who was famous for you know his studies of specialization functional specialization
in the language system but his big gift in terms of psychiatry was the subjunction hypothesis that
you could understand dementia precoxa early formulations of schizophrenia in terms of disruption
to these the organs of connectivity the white matter tracks that we currently um that we currently
study with things like um diffusion weighted um I think resonance imaging or diffuse tractography
that didn't um based upon that that kind of imaging but there was another perspective which
most people are described to boiler um which spoke more about the sort of the fine grain
disintegration of the psyche the you know the loss of coherence and um
you know literally a dissolution at the level of mental life so from our perspective that would
be belief updating which one might nowadays understand much more as a microscopic disconnection
at the level of synapses the little um specializations the little buttons that or plugs that connect
one neuron to another neuron at the end of the um the axon or the long fibers that emanate from a
particular neuronal cell there's a whole bunch of pre and post-synaptic specializations called
called you know called synapses which you base it in the little planks which all the neurotransmitters
act and so in um clinical neuroscience you know a failure of or a disconnection or a failure of
integration at the synaptic level will be known as a synaptopathy a pathology of synaptic connections
so that's the kind of disconnection that most people have now in mind when thinking about the
abnormal message passing that might produce the false inference that is characteristic of
different psychiatric conditions that means you need to be able to measure this you need to have
an in vivo um in life way of measuring the synaptic efficacy the connection strength the gain
that we were talking about before that is modulated through the precision engineered
message passing getting the excitability right these are all different ways of expressing
the synaptic efficacy the strength of connections in the brain and if you think that things like
schizophrenia are manifestations of false inferences that inherit from a very pernicious
and particular kind of synaptopathy which precludes getting the precision right getting the
excitability of say for example neurons reporting prediction errors correct then you need to be
able to measure it and that's where the third technical um contribution to brain imaging comes
in which is the dynamic causal modeling that was used to study the the pandemic so we use the
the dynamic causal modeling to basically study the spread of viruses from person to person
but it was originally devised to study the synaptic efficacy that underwrite the spread of
signals from one member of a neuronal population to another one so that's where it's at at the
moment I mean it's difficult for me to really summarize you know what we were doing and what
we are doing in a nutshell because a bit like the your your first questions about how much we
and I have achieved in my career I think this field also it's a long journey and it's very
incremental and sometimes you're quite surprised by how far you've moved but if you look at the
progress from this year to last year it's almost zero you have to look over 20 years
inception of from my perspective at least dynamic causal modeling that was that was explicitly
done in order to understand disconnections and synaptopathies in schizophrenia because that's
where you know that's where I came from in psychiatry and then it's about now that people
are starting to take this technology seriously and start to apply it at scale and in a way that is
underwritten by companion studies and the same systems in different models in cell cultures for
example so you know there are if you've got one gerogen model under the hood that explains
disconnection of a certain kind due to this synaptopathy which we're now associating with
abnormal precision control of exactly the same kind that Mark was intimating when he's talking
about his broken midbrains because these are the ones that broadcast the signals that control the
synaptic efficacy you're in exactly the same way as you might imagine that happening in Parkinson's
disease where you've got abnormal you're a hypodopaminergic state the component in schizophrenia
being a high potentially hypodopaminergic state and many other conditions so those
that application of dynamic causal modeling at different scales and across scales is now
starting to emerge at least in proposal form no one yet has had the nerve to fund it
my hope is in the next year or two there are sufficient number there are a sufficient number
of proof of principle that it now becomes you know a viable way of proceeding and
to bring things to closure the two areas that seem to have really exploited this
way of making sense of data to get at synaptopathy are epilepsy research in particular childhood
epilepsy and some neurodeterative conditions so that's where the action is at the moment
yeah I could definitely see that I want to ask just just as a since this is your kind of more
closely you're closer to this is about fmri's just as a small side here many people were very
excited about fmri's when they came out you know this is very literally colorful and exciting in
some ways but over time I guess over 30 years now I mean there are some people that would say
that it's a kind of you know modern-day phrenology right um do you agree with that what's the utility
of fmri's if anything and you know how good is it really at translated into I guess better
treatments you know because you know some area because we know with diffusion tensor imaging
that there's all of the brain is connected all of it is linked up all of it is is is talking
with each other different parts of the brain cortical subcortical different lobes everything's
talking to each other so how do we understand I guess the utility of fmri's if at all um and
and how how could it translate I guess into to better treatments so you say that some people
are starting to call it a sort of latter-day uh phrenology in fact they were they were calling
it that at the inception of the new cartography the new the neo phrenology um which is a fair
a fair a fair critique um so I think the the answer to that question is a little bit like
this you know how far we come in our journey if you ask year by year yes the the advances
have been incremental at best but if you just look back with a temporal resolution of decades
fmri has had quite a profound impact on the little cognitive and translational neurosciences
so simple things which people of your gentle and tender age will not be aware of simple things
that you take for granted were just hypotheses in 1989-1990 for example the whole notion of
functional specialization in the brain that underwrote sort of fedorian modalities and
all sorts of hypotheses about in fact uh also um sub-tended neo phrenology the notion that one
part of the brain did this and another part of the brain did that so this is a notion of
functional specialization the particular segregation that this particular functionality
was segregated anatomically or spatially to this part of the brain uh and that therefore we had at
least a good hypothesis about the um predictions that would ensue foreign brain damage and we
can make some uh guesses about the importance of connectivity under the functional segregation
hypothesis no one knew though no one up until 1990 you know 1918-1989 knew what no one knew that
there was for example um color specialization in this particular part of v4 that was segregated
in the sense that there was no color alleged responses elsewhere and you couldn't do that
because you'd have to have electrodes everywhere in the brain in order to show that it was this
part of the brain responding to color and not that part of the brain so it's only in the early 1990s
that people could actually after about 200 years possibly 150 years um confirm the original hypothesis
about functional localization and specialization and segregation in the brain that was a profound
thing as I say from your perspective you know you just assume that people in the 1980s believed
that functional specialization was a principle of brain localization they didn't believe it but it
was just a hypothesis and there was doubt after fmi there was no doubt it was just part of the
foundation of neurophrenology um the the the second sort of big point to make is that you know
if you want to understand how a virus spreads um or how a meme spreads or how um messages spread
in a deep neural network or how belief updating operates in a functionally segregated and specialized
hierarchical brain you have to have a way of identifying the things that are connected so
if you are truly a cartographer when you go to a new country the first thing you do is identify
the landmarks before you start worrying about the communication the rivers or indeed if it's a
developed country the the routes of communication the rail links and all that good stuff the first
thing you do is have to identify what's happening where in terms of these functionally segregated
definitive aspects of any map or before you can talk about distributed processing well distributed
amongst what well amongst the functionally specialized areas or where are they we can now
identify those using fmi but of course that's just the first step so within about sort of five to
eight years people were tearing their attention to the real question which is back to the connectivity
it's a black it's back to the principles that underwrite the distributed processing as you say
understanding why every part of the basis could be connected at least with two degrees of freedom
to every other part of the brain so that that's where the big questions were and
subsequently addressed in terms of fundamental distinctions between things like functional
effective connectivity there was you know a period when all the excitement was about
some measuring correlations and functional connectivities in the brain but throughout that
period of course you know things like dynamic causal modeling were being developed in order to
measure the actual directed coupling that subtended these correlations that people
measuring with functional connectivity so was fmi or is fmi useful in that regard and has it had
any material effect on um sort of treatment i i i mean i can cite particular examples in terms of
epilepsy research and the identification of sort of elegant areas the use of imaging as a biomarkers
in say genetic studies a predisposition to various illnesses you know i could give you a number of some
sort of quite compelling but very um colloquial examples of where it has worked i would i would
sort of concur with you that there hasn't been an awakening of insights it's more a consolidation
of what we have known from centuries of careful neural anatomy and neurophysiology
ever-increasing fine-grainness that allows us now to talk about the particular sub receptors
involved in a particular syndrome that underwrite the synaptic or the synatopathy that's producing
the the discoloration in your in this particular system so the interceptive system involving the
anterior siglum and the anterior insular so it's really people really drilling down on the
fine-grained in certain quarters of neuroimaging that there's not a b-grade stuff as well um
but you know the a-grade mechanistically mechanistic um theory driven applications hypothesis driven
applications of neuroimaging you know really has advanced quite quite remarkably on in the basic
neuroscience is that you know whether that has yet to translate into clinical neuroscience
you know i think that's an open question but you know the answer i think will only reveal itself
when you look back and say what's happened in the past 10 years and then you probably get a much more
positive uh uh response than otherwise it's one final comment and it certainly is the case that
fMRI as um uh an imaging modality um has lost its shine in the sense of its appalling temporal
resolution um which means that most earnest imaging neuroscientists or cognitive neuroscientists or
indeed clinical neuroscientists would want to supplement the the cartographic gift of fMRI
with highly resolved electromagnetic electrophysiological responses so you know anybody doing
any serious imaging neuroscience nowadays would would also recourse to electromagnetic signals
and understanding distributed processing at that level guided by the cartography on offer from fMRI
yeah no that's that's that's important to to to also keep in mind as well well my my my last
question for you is uh i guess sort of a sort of a big one uh there's two parts to it so the first
part is you've talked about many of your um theoretical uh principles you've talked about
some of the stuff from the the imaging techniques so we've talked about the Bayesian brain which has
some utility but has many utilities but many people are are starting to talk more about it
mainstream um have been for for many years but in terms of your free energy principle and how you
use this with active interference inference excuse me um predictive coding theory how
how do you how do you think um this can be translated to the common person right how can
people use these wonderful theoretical structures and frameworks in a way that's applied and has
some pragmatic utility in ways that everyone can kind of grasp and say oh yes i got that and i see
how this is really important or use it in various clinical practices in whichever domain in psychiatry
neuroscience and psychology etc how how do you think um the ability to translate those models
and theories into practical applied use is is is key and and ways to do that and then larger frame
or larger or uh of this is for neuroscience as a whole you know how do you see um in neuroscience
you know its utilities maybe some of its limitations but how it's it's useful for for people to
continue to understand the complexities of neuroscience in a sense we've already um
sort of covered i think the the two key um practical applications um and perhaps it would
probably just to rehearse the point that there's a lot of similarity between the free energy principle
and um the theory of natural selection you know in and of themselves they do nothing for you you've
actually got to want to answer a question in a particular situation or to build something
um in a you know in a given circumstance um and then you know the free energy principle and its
attendant process there is will certainly provide you the functional forms and the
architecture and mechanics to do that quite quickly and efficiently and so the question now
is why would you ever want to build those things and how could you practically use them
in terms of um building sentient artifacts you what what you know i just remind myself and you
know recall an earlier part of the conversation that what we have now is a um an off-the-shelf set
of belief updating schemes that should in principle um create curious sentient robots and artifacts
that will be um to my mind the next step in artificial or machine learning and i say that
from a number of perspectives first of all in terms of you know what's um what is a use case
that will be appreciated by members of the public i i generally think that it's probably going to be
the the manufacture of little pets uh as much of of you know public basic ai has has has pursued
but the difference will be here these artificial pets will actually have a curiosity and and it
will be so it will be much easier to um project an anthropomorphosize and to um apply theory of
mind to these kinds of little curious pets and so they'll they'll become increasingly um
more like your actual favorite pet or your your pet or your dog simply because they now have
curiosity under the hood so that's how i personally think that people are going to make
money out of active inference it's just equipping these little robots with a curiosity uh or to use
Jürgen Schmidt who was phrasing artificial curiosity and interestingly mentioning Jürgen
Schmidt who but of course he you know he thinks that's the essence of creativity and fun this
this is curiosity this epistemic drive this information seeking part of resolving uncertainty
or maximizing information gain through actively soliciting evidence for your gelator models in
the world um in terms of machine learning um and the more um i think pressing uh a less trivial
issue of uh sustainability um the um the the whole point of active inference is that it is um
obeys optimal in the way that it gets data and assimilates those data and that optimality
expresses itself in a certain kinds of efficiency um which i think are going to be very important in
terms of sustainable computation and energy use so i've heard that in 2025 about 20 percent if not
22 percent of the total energy consumption globally will be um by data farms and uh you know e-commerce
and x-rays so this is a really you feel like um thermodynamically and climate change relevant
observation that there are good ways to make inference into data mine and there are bad ways
now the good ways are those that conform to Hampton's principle least action that's a free
energy principle that you minimize in your process of inference or active inference you maximize the
evidence which mathematically simply means minimizing the complexity with uh under accuracy
constraints where the complexity is the the cost you pay in terms of belief update is literally
that measure of movement from the prior to the posterior that costs energy via the Zhuninsky
equality which means if you use the wrong kind of um overly parameterized generative model say
with a billion parameters in a state of the art deep learning network you are doing it in the
statistically least optimal way and using a massive amount of electricity uh so another
way of stating that is the direction of travel in machine learning in particular deep learning
is exactly the wrong direction because it relies upon big data and overly parameterized
overly complex generative models so i'm hoping that active inference the free energy principle
will reverse that direction of travel through proof of principle so what we have instead now
