absolutely necessary to use H and not H as our hypotheses, right? H and then the strict
logical negation of H. We can instead use competing hypotheses that are not strict
negations of one another. For example, we could use like theism and naturalism as our hypotheses,
even though naturalism isn't the strict negation of theism and theism isn't the
strict negation of naturalism. Of course, they can't both be true, right? So they're incompatible,
but they could in principle both be false. So they don't exhaust the space of possibilities,
and they also don't exhaust the probability space. Just note, and this is a very important note,
when you use the odds form of Bayes theorem, and when you don't have a hypothesis and the strict
negation of that hypothesis, and so when you don't have mutually exhaustive alternatives,
this last step will not go through, okay? Do not use this last step when that condition is met,
right? All you're going to be able to conclude when you use, for instance, theism and naturalism
is the ratio of the posteriors, that is the ratio between, say, the probability of theism
given some evidence and the probability of naturalism given some evidence. You won't then be able
to convert that to an absolute probability in the way described on the screen here. And again,
the reason is because like naturalism and theism don't exhaust the possibility or the probability
space. And so, for instance, like a one-to-one posterior ratio between them might, in principle,
correspond to, for example, theism and naturalism each having only an absolute probability of,
let's say, 25% given the evidence in question, right? So, both of them might be 25%, and the ratio
of 25% to 25% is one-to-one, right? And yet, if you use this method down here, you would get one
divided by one plus one, one divided by two, which is 50%, right? So, just be careful when
you're converting to absolute probabilities. You're going to want to make sure that you have
mutually exclusive and exhaustive hypotheses up here. All right, now we're on to evidence.
Show me the evidence, show me the evidence, show me the evidence, show me the evidence.
Okay, Bayesians generally conceive of evidential support as probability raising. In other words,
some piece of evidence or data E evidentially supports or confirms a hypothesis H, just in case
E raises the probability of H. More precisely, E is evidence for H, or E would be evidence for H,
just in case the probability of H given E is greater than the probability of H. You can see
here that E is raising or boosting or increasing the probability of H. And this, by the way,
is often known as the positive relevance account of evidence. And it's plausible too, right? Think
about this bi-conditional. This is saying E is evident for H if and only if this condition is
met. So, let's do the left or right hand side of the bi-conditional. If E is evidence for H,
well then E is going to raise the probability of H. Yeah, that's plausible, right? If something is
evidence for a hypothesis, surely it's then going to raise the probability of hypothesis. It's going
to make the hypothesis more likely than it would be otherwise. Evidence counts in favor of a hypothesis.
It supports it. It has to raise its probability. And similarly, you might think that the right
to left direction is also plausible. If some piece of data really does raise the probability of
hypothesis, well then surely it's evidence for the hypothesis. It's counting in its favor. It's
supporting it. It's giving it a probabilistic boost. So, the bi-conditional you might think
is plausible. How, though, does this relate to Bayes' theorem, you ask? Well, it's pretty
straightforward to see that this condition holds, this condition here, this condition holds just
in case the likelihood ratio is greater than 1. That is, just in case the probability of E given H
is greater than the probability of E given not H. To put it differently, E is evidence for H.
Just in case E is more expected under H than it is under the negation of H.
So, when E is more expected on a hypothesis or less surprising on a hypothesis or more
probable on that hypothesis than the evidence is on the negation of that hypothesis,
then and only then does that piece of data count as evidence for the hypothesis. This is why you'll
often hear people saying, hey, this piece of data is more expected on theism than it is under
naturalism, and so it counts as evidence for theism. Or you'll hear people say that, hey,
this data is less surprising on naturalism, that is, it's more expected under naturalism,
it's more probable under naturalism than it is under theism, and hence it's evidence for naturalism
over and against theism. So, yeah, E is evidence for H just in case E raises the probability of H,
that is, the probability of H given E is greater than the probability of H, and that happens just
in case the likelihood ratio is greater than 1. More technically, it's when the likelihood ratio
is greater than 1 when you have H in the numerator here. If you switched up these two and you put
not H in the numerator, well then E would be evidence for H when this likelihood ratio is
less than 1, because then the probability of H given E is going to be in the denominator,
and so you're basically flipping all these, and so then if E is more expected under H than it is
under not H, well then the likelihood ratio would actually be bottom heavy, and so the bottom number
would be greater than the top number, in which case the likelihood ratio as a whole would be
less than 1, but yet E would still be evidence for H. Okay, anyway, that's a technical aside.
You get my point, right? When you have H's on the top and not H on the bottom, well then E is
evidence for H just in case the likelihood ratio is greater than 1, and just think of that in terms
of E being more expected under H than it is under not H, or E being more likely under H, or E being
more probable under H than it is under not H. So anyway, to see why this is true, to see why the
probability of H given E is greater than the probability of H just in case the likelihood
ratio is greater than 1, we're going to have to recall the odds form of Bayes theorem. The
posterior ratio is equal to the likelihood ratio times the prior ratio. Suppose we have some fixed
value for the probability of H, okay, and we're going to call that fixed value K. So I'm just
plugging in K here, and of course when the probability of H is K, well then the probability
of not H is just 1 minus K, right? If the probability of H is 0.7, well then the probability that H is
false, that is the probability of not H, is going to be 1 minus 0.7 or 0.3. So if we have a fixed
value for the probability of H, if we fix that at K, well then the prior ratio is going to be the
fixed value of K over 1 minus K. So now we're going to let the likelihood ratio be exactly 1,
so then we have 1 times K over 1 minus K, and of course 1 times something is just that thing,
right? So we get the posterior ratio is equal to K divided by 1 minus K. But then the posterior
ratio is just the same thing as the prior ratio, right? And again if you want to turn the probability
of H given E into an absolute probability here, what you do is K divided by K plus 1 minus K,
right? So in order to convert this ratio or this relative proportion into an absolute proportion
or an absolute probability, you do the numerator divided by the numerator plus the denominator.
So you do K divided by K plus 1 minus K, and of course K divided by K plus 1 minus K is just
K divided by 1, and that's just K, right? And so the absolute value of the probability of
H given E is equal to K. But remember, we suppose that the probability of H was just K,
and so we just concluded that the probability of H given E is equal to the probability of H,
and that's just equal to K. So when the likelihood ratio is 1, right, that was our
supposition, we suppose that the likelihood ratio was 1, it follows that E isn't evidence for H,
right? Look, because E didn't raise the probability of H. The probability of H conditional on E
just is the same thing as the probability of H, so E didn't raise its probability.
This condition up here isn't met, and so when the likelihood ratio is 1,
E is not evidence for H. But now suppose that the likelihood ratio here is greater than 1,
say it's 2. 2 is just an arbitrary number, my point would apply to any number greater than 1,
but we're just going to pick one for E's, okay? So we're going to pick the number 2. So we're
going to suppose that the likelihood ratio is greater than 1, we're going to say that it's 2,
and that of course is going to give us 2 times K over 1 minus K, right? Remember, we're still
keeping the assumption that the probability of H is K, and so the ratio of the priors is still K
to 1 minus K. But this time instead of multiplying by 1, we're multiplying by 2 because the likelihood
ratio is greater than 1, we're supposing that it's 2. And this in turn gives us that the posterior
ratio is equal to 2K divided by 1 minus K. Notice what we've done here, we have the posterior ratio
here, we have the posterior ratio here, this is from the previous case that we looked at when the
likelihood ratio was 1, this is the current case when the likelihood ratio is 2. Notice
what we've done here, we've increased the numerator by a factor of 2, going from this case to this
case, while keeping the denominator exactly the same. We've therefore doubled the odds of the
probability of H given E in relation to the probability of not H given E. If the odds were,
say, 1 to 1 when the likelihood ratio is 1, the odds when the likelihood ratio is 2 become 2 to 1.
If the odds were, say, 1 to 100 when the likelihood ratio is 1,
they're now 2 to 100 when the likelihood ratio is 2. This in turn means that when we shift from
a likelihood ratio of 1 to a likelihood ratio of 2, the posterior odds become more favorable
to the probability of H given E, right, they become more top-heavy. And hence the probability of H
given E is higher when the likelihood ratio is 2 compared to when the likelihood ratio is 1,
right, because the posterior odds going from the former case to the present case
have become more favorable to the probability of H given E. The posterior odds have in fact
doubled in its favor. And this point, of course, easily generalizes to any likelihood ratio greater
than 1. If the likelihood ratio were 3, well, then when we compare this case to this case,
we would have tripled the odds in favor of the probability of H given E in relation to the
probability of not H given E. So this point, again, easily generalizes to any likelihood
ratio greater than 1. But we've already seen that when the likelihood ratio is 1, right,
the probability of H given E is equal to K, right, that's what we showed last time. When
the likelihood ratio is equal to 1, the posterior probability of H, that is the probability of H
given E, just equals the prior probability of H, which equals K. That's what happens when the
likelihood ratio is 1. But we just concluded that when the likelihood ratio is greater than 1,
right, we increase the odds in favor of the probability of H given E. And as a result of that,
the posterior probability of H, that is, the probability of H given E has increased,
And hence, the probability of h given e has to be greater than k, right?
If the probability of h given e was k in this case, and then going from here to here,
we've increased the probability of h given e, well, then the probability of h given
e in this case has got to be greater than k and hence, in this case,
the probability of h given e is greater than the probability of h and what that
means is that e has raised the probability of h.
E is evidence for h.
That's what happens when the likelihood ratio is greater than one and
the likelihood ratio is greater than one.
E is evidence for
h. And similar reasoning shows that the probability of h given e is less than the probability
of h when the likelihood ratio is less than 1. Instead of increasing the odds in favor
of the numerator here, you'll be decreasing the odds against the numerator here. And the
effect of that on the absolute probability of the numerator here will be to diminish
it. The result of this is that the likelihood ratio is the key to evidential confirmation
or disconfirmation. When the likelihood ratio is greater than 1, the probability of h given
e is greater than the probability of h. And hence, e is evidence for h. In such a case,
e confirms h, or supports h, or raises the probability of h. By contrast, when the likelihood
ratio is less than 1, the probability of h given e is less than the probability of h.
And hence, e is evidence against h. e disconfirms h, or lowers the probability of h. Equivalently,
in this case, e is going to be evidence for the negation of h. e is going to confirm the
negation of h, or raise the probability of the negation of h. And finally, when the likelihood
ratio is 1, the probability of h given e is equal to the probability of h. And hence,
e is evidentially irrelevant to h. It neither confirms nor disconfirms h. It neither increases
nor decreases the probability of h. So here, then, are some important Bayesian facts.
In the preceding reasoning, I actually only showed the left or right hand side of these
biconditionals, but it's very straightforward to show the right to left direction in basically
the same way that I just did. So, e is evidence for h if and only if the likelihood ratio
of h to not h is greater than 1. In other words, e is evidence for h if and only if
e is more expected, or more probable, or more likely on h than not h. In other words, e
is less surprising on h than it is on not h. e is evidence against h if and only if the
likelihood ratio is less than 1. e is less expected, or less probable, or less likely
on h than not h. In other words, e is more expected on the negation of the hypothesis
than it is under the hypothesis itself. Finally, e is irrelevant to h if and only if the likelihood
ratio is equal to 1. e is then equally expected, or equally probable, or equally likely on
both h and not h. And once again, this is why you hear people in philosophy say things
like, this data is more expected under one hypothesis than under the other, and hence
it counts as evidence for the former over the latter. Notice also how all of this is
comparative in nature. Right, for some piece of evidence or some piece of data to confirm
a hypothesis, that is to be evidence for the hypothesis, the evidence can still actually
be quite unlikely on that hypothesis. What matters is that the evidence is even more
unlikely on the negation of that hypothesis. Right, so some data could still be very surprising
on a hypothesis, and yet not count as evidence against that hypothesis, because that evidence
might very well be even more surprising under the negation of that hypothesis, or it might
be just as surprising. So take that to heart. The probability of some evidence given a hypothesis
can be very low. The evidence can be very surprising on the hypothesis, it can be not
at all what you expect on the hypothesis, and yet it doesn't automatically, it doesn't
thereby follow that that data, that that evidence is evidence against the hypothesis. Oftentimes
it will be, because the negation of that hypothesis will predict the data better, it won't be
as surprising, but perhaps not. Perhaps the data is equally unexpected, or even more unexpected
under the negation of that hypothesis. So keep that in mind, keep the comparative nature
of Bayesian confirmation in mind. I'll cover this later on, I'll talk about it in more
detail, but it's important to note here, because this is where it's directly relevant.
And also think about that intuitively, like it makes sense. Suppose that my roommate and
I, we take turns taking out the trash, I do it every Sunday, he does it every Wednesday
or something, and suppose we're both really diligent about this, my roommate knows that
I know about this, I know that he knows about this, I've been doing this for the past year,
let's say, and I haven't missed a single day. So we're both really diligent about this,
and we know this about each other. Now suppose I wake up on Sunday to see written on the
whiteboard in the corner, don't forget to take out the trash. And suppose we have two
hypotheses and we're trying to evaluate the probability of these hypotheses in light
of this evidence, in light of the fact that this message is written on the whiteboard.
One hypothesis says that my roommate did it, and he's reminding me, the other hypothesis
is just that like the marker magically flew up and took off its cap and then wrote that
by itself. Now given my setup, it actually does seem pretty surprising that my roommate
would write this on the board. My roommate knows that I know this, like I've never failed
to bring out the trash, why would he do this? And I mean that's my whiteboard, it's my marker,
he usually doesn't touch my stuff. So like this is really out of character for him, it's
really weird, I've been doing this for over a year, neither of us have ever forgotten,
so like why would he write that? It seems really surprising. But do you know what's
even more surprising? If the marker, if the marker magically did it itself. And so even
though it's very surprising, even though the evidence is very surprising, under the hypothesis
that my roommate did this, even though it's not at all probable under that hypothesis,
the evidence is still far more probable under that hypothesis than it is under this competing
hypothesis. And so we still have very powerful evidence for the former over the latter. And
so it makes sense that something can still be evidence for one hypothesis over another,
even though the evidence is unlikely or unexpected or surprising on the former. Finally, another
way to think of evidential support that's ultimately equivalent but differs in emphasis
from the ways that we've been looking at so far, takes its cue from the standard form
