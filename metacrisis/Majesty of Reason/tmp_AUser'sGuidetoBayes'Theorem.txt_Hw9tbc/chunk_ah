Well, what we're gonna do to show how e follows from that is we're basically just gonna show that e follows from each of the
disjuncts, right? Because again, whenever you have a disjunction and you can show that each of the disjuncts entails
something, well, then you can just conclude to that something, right?
So let's suppose that this disjunct is true e and h. Well, obviously if e and h is true, well, then e is true.
So we just showed that e follows from this disjunct. Well, does e follow from this disjunct? Well, of course it does, right?
Suppose that e and not h is true, well, then obviously e follows, right?
So under either horn of this dilemma, e follows.
And so since the disjunction as a whole is true, and since either horn of the dilemma entails e, we can conclude that e.
But look what we just did, right?
We suppose that the disjunction as a whole is true, and now we just derived from that that e is true.
And so we can say that if the disjunction is true,
then e follows. So we say if the disjunction is true, then e follows.
And notice now that we've shown the right to left side of the logical equivalence. We've shown that
this disjunction logically entails e. So we can put the little bi-conditional arrow here,
and we've shown precisely what we wanted to show, that e is logically equivalent to the disjunction of e and h, or e and not h.
Okay, all right, take a deep breath. I can promise you that was the most
technical part of this video. Apologies if I lost you. I tried explaining this as best as I could,
but yeah, that is probably the most technical part of this video.
But again, the goal of this video, the goal of majesty of reason, is not to back down from those challenges.
It's to rise up to the challenges. It's to exhibit that kind of intellectual perseverance, the intellectual curiosity, the intellectual responsibility
to find out these things for yourself, to see why the probability of e is equal to the probability of e given h times the probability of h,
plus the probability of e given not h times the probability of not h.
Okay, so anyway, think of this as an exercise in cultivating the intellectual virtues.
That's what you're getting with the majesty of reason experience.
You're not only getting philosophy, but I'm trying to build up your intellectual virtues along the way.
Still, you might be thinking like, okay, Joe, I get it. That's a lot of math and logic, but like, what's the point?
To what end? Well, what's the point of anything, honestly? Uh, no, okay. We're not getting into that topic here.
The point, the significance, is one I've already mentioned. Bayes' theorem gives us a way to calculate the posterior probability of a hypothesis conditional on evidence.
Together with the conditionalization principle, this gives us a recipe for rationally updating our credences and for confirming or disconfirming hypotheses,
that is, increasing or decreasing their probability as a result of data.
Here are some other important points pertaining to Bayes' theorem.
So we want to know how likely our hypothesis is in light of evidence e.
That's given by the probability of h given e. So if we learn that e is true, we should revise our confidence in h by changing it from
the probability of h to the probability of h given e, per the conditionalization principle that we went over.
Looking at the right-hand side of Bayes' theorem, we can see that three things determine the probability of h given e.
Under this form of Bayes' theorem, what we could call the standard form. First, the probability of h given e is proportional to the prior probability of h itself.
In other words, how likely h was to be true before we learned e, or how likely we would say h was if we didn't know e.
The more probable the hypothesis starts out, the more probable it ends up.
This also supports the slogan, extraordinary claims require extraordinary evidence.
In the sense that if we have a hypothesis that is super implausible to begin with,
then we're going to need significant evidence before the hypothesis becomes believable.
Whereas if you started out with a pretty plausible hypothesis, not as much or not as strong evidence is needed for believability.
Second, it's generally quite good if the likelihood of h, the probability of e given h,
is high. That's generally quite good if that's high. Intuitively, if you want to support a theory,
you want the theory to strongly predict some possible evidence, where the evidence then occurs.
To strongly predict something is to imply that that thing is quite likely.
At the very least, you want your hypothesis to predict the data better than the alternative hypotheses.
But we'll talk about that more when we get to the odds form of Bayes' theorem and when we get to evidence.
Right now, we're just speaking in general terms. Third, in general,
it's pretty good if the probability of e is low.
Right, you can see from the theorem that as the probability of e goes down, the probability of h given e goes up.
Right, whenever you divide by something, the smaller the denominator, the larger the resulting quantity as a whole is.
So yeah, it's generally quite good if the probability of e is low.
Because as the probability of e goes down, the probability of h given e goes up. Combining this with the previous point,
we can say that ideally and generally, you want a theory that strongly predicts evidence that is otherwise highly unlikely.
You want e to be much more likely if h is true than otherwise.
That's a straightforward path to a very strong confirmation of the hypothesis in question.
But alas, I'm getting ahead of myself because I've got a whole section of this video dedicated to confirmation and evidence.
And I'll speak in much more precise terms there rather than the general terms I've been doing here.
So anyway, that's the standard form of Bayes' theorem or the standard forms, again, two different ways that you can articulate it.
But there are other forms of Bayes' theorem.
The odds form is one of the most useful and it's definitely my favorite.
It's basically like my baby. I feed it. I nourish it. I pad it.
It spits on me. It calls me daddy. Uh, I need to stop.
It's pretty useful because when we're doing the calculations,
we don't need to worry about the probability of the evidence or data, right?
Notice that p of e doesn't show up anywhere in here.
Instead, we simply worry about the prior probabilities of h and not h, as well as how well each of h and not h predict the data.
That is, how likely they each render e.
So yeah, here is the odds form of Bayes' theorem. It's on screen here.
The probability of h given e divided by the probability of not h given e
is equal to the probability of e given h divided by the probability of e given not h
times the probability of h divided by the probability of not h.
This is called the odds form because it's expressed as odds.
Like, odds are always ratios, like two to one, and that's basically like the division that's going on here, right?
This is a ratio of one quantity to another.
But anyway, here's an explanation of odds from three blue, one brown.
If you've ever heard someone talk about the chances of an event being one to one or two to one, things like that, you already know about odds.
With probability, we're taking the ratio of the number of positive cases out of all possible cases, right?
Things like one in five or one in ten.
With odds, what you do is take the ratio of all positive cases to all negative cases.
You commonly see odds written with a colon to emphasize the distinction, but it's still just a fraction, just a number.
So an event with a 50% probability would be described as having one to one odds.
A 10% probability is the same as one to nine odds.
An 80% probability is the same as four to one odds. You get the point.
It's the same information. It still describes the chances of a random event, but it's presented a little differently, like a different unit system.
Probabilities are constrained between zero and one, with even chances sitting at 0.5.
But odds range from zero up to infinity, with even chances sitting at the number one.
So we can actually put the odds form of Bayes theorem in slogan form.
The slogan is that the posterior odds equals the likelihood ratio times the prior odds.
So on the left side here, this left term is called the ratio of the posteriors, or the posterior ratio, or the posterior odds.
The middle term is called the likelihood ratio, or the Bayes factor, or the relative likelihoods.
And finally, the right term here is called the ratio of the priors, or the prior ratio, or the prior odds.
Any of these terms are adequate.
Now you might be wondering, how does the odds form of Bayes theorem relate to the standard form of Bayes theorem?
Well, the odds form is actually a straightforward consequence of the standard form of Bayes theorem.
So we have the odds form up here, and look, we have the standard form of Bayes theorem right here.
The probability of h given e is equal to the probability v given h times the probability of h divided by the probability of e.
We also have another instance of the standard form of Bayes theorem here.
But instead of plugging in h, we've just plugged in not h as our hypothesis.
But these are both just instances of the standard form of Bayes theorem.
All you have to do is just divide the probability of h given e by the probability of not h given e.
And that'll give you the left hand side of this equation up here, the odds form.
And when you do that, since this is identical to this, and this is identical to this,
when you divide this by this, it just equals this divided by this.
And of course, when you divide these two right hand sides, the p of e in the denominator of both crosses out.
That's how division works with fractions. And when you cross off p of e, you get the odds form of Bayes theorem.
So the odds form is a straightforward consequence of the standard form of Bayes theorem.
Here then is a handy dandy example of the odds form of Bayes theorem in action.
I don't know why it's telling me that I spelled diseaseitis wrong. That's totally a legitimate disease. I got it last week.
It means inflammation of the disease. It's real. Fox News told me so.
So suppose you are a nurse screening patients for diseaseitis.
The screening test involves a tongue depressor that usually turns black for patients who have the sickness.
Suppose you know the following.
20% of the patients in the screening population actually have diseaseitis.
Among the patients with diseaseitis, 90% of them turn the tongue depressor black. Those are the true positives.
However, 15% of the patients without diseaseitis will also turn the tongue depressor black. Those are the false positives.
The question now is, what is the probability that a patient with a blackened tongue depressor actually has diseaseitis?
So to answer this, we can use the odds form of Bayes theorem.
Just let H be the hypothesis that the patient has diseaseitis.
And so then not H or the negation of H is going to be that the patient does not have diseaseitis.
And then we're going to let E or our data or our evidence be the evidence of a blackened tongue depressor. With this in hand, let's reason this out.
So because 20% of the population has diseaseitis, while 80% of the population doesn't, the ratio of the priors,
that is the ratio of the probability of H to the probability of not H,
is 1 to 4. Right? Because the probability of H is going to be 20%. The probability of not H is 80%.
And the ratio of 20 to 80 is just a 1 to 4 ratio. Another way to think about that is that we're starting off with four times fewer people with
diseaseitis as people without it. So we've got the ratio of the priors. Then each person with the disease
is 90% likely to make the depressor black. And each person without the disease
is only 15% likely to make the depressor black. So we're saying that the probability that someone makes the depressor black
given that they have the disease, so given H is 90%. While the probability that they make the depressor black, given that they don't have the disease
is only 15%. So these are our likelihoods, right? This is the likelihood of H and this is the likelihood of not H.
Again, keep in mind from earlier on in the video that that's unfortunately named because likelihood sounds like probability.
Again, think of the likelihood of H as just the probability of the evidence given that H is true.
And the likelihood of not H is the probability that the evidence would be true given the truth of not H.
So what then is the likelihood ratio? Well, all you got to do is 90% to 15%, right? The likelihood ratio is 90% up here to 15% down here.
90 to 15. That is 6 to 1, right? 90 divided by 15 is 6. So the likelihood ratio is 6 to 1.
Again, another way to think about this is that
each person with diseaseitis is 6 times as likely as a person without diseaseitis to make the tongue depressor black.
So then how do we determine the posterior odds? Well, all you got to do, right?
Remember our slogan, the posterior odds equals the likelihood ratio times the prior odds.
So all you got to do is the likelihood ratio 6 over 1 times the prior odds 1 over 4
gives us the posterior odds 6 over 4. And of course, you can simplify that to give us 3 to 2.
So what that tells us is that the ratio of the posteriors is 3 to 2. The ratio between the probability of H given E
and the probability of not H given E is 3 to 2.
To convert this relative proportion into an absolute probability that a random person who blackened the tongue depressor really does have diseaseitis,
we do 3 divided by 3 plus 2 to see that 3 fifths or 60% of those who blacken the tongue depressor
really do have diseaseitis. In other words, given that a random person did in fact
blacken the tongue depressor, the probability that they have diseaseitis is 60%.
So that gives us the probability of H given E.
And that's what we wanted to determine. Now, you might not immediately see why in order to convert this to an absolute probability
we do 3 divided by 3 plus 2. Think about it like this. When you have
mutually incompatible but exhaustive
hypotheses and the ratio of one to another in the probability space is like x to y,
well then to determine the absolute probability of the former just going to do x divided by x plus y.
So let's let's take an example. I made that a little bit too abstract.
Suppose we have a kindergarten class and in the kindergarten class, of course, there are males and females. Ignore intersex conditions.
Okay, I know some of you are like, well actually, so within this class, we've just got males or females.
No one is both a male or a female and no one is neither a male nor female.
Now, suppose that I told you that the ratio of males to females in this class is 3 to 2.
So for every three males, there are two females in this class. Now, suppose I ask you like,
what's the absolute probability that a random child chosen from this class is going to be a male?
Well, I mean, just just think about that intuitively. If the ratio of males to females is 3 to 2,
well, then what that means is that
3 out of every 5 students is going to be a male, right? Because it's three males,
two females, so 3 out of 3 plus 2, right? It's the males out of the males plus the females.
So it's 3 out of 3 plus 2 or 3 fifths or 60%.
So I hope that gives you a kind of intuitive sense of why we do this calculation here.
And notice that we can now see why the answer to the original problem posed at the beginning of my video is D.
Remember, only 1% of women her age have cancer and the test was 90% accurate.
So when we let cancer be H, no cancer be not H, and E be the evidence of a positive test result,
if we want to determine the probability that she has cancer,
given that she has a positive test result, we can use the odds form of Bayes theorem.
In particular, we want to find the posterior ratio by multiplying the likelihood ratio by the prior ratio.
So what's the ratio of the priors? Well, the ratio of the priors is 1 to 99, right?
Because 1% of women her age have cancer, so the probability that she has it before looking at this
evidence is 1%. And of course, what that means is that there's a 99% chance that she doesn't have it.
And so the prior ratio is 1% to 99% or 1 to 99. And then we can ask what is the likelihood ratio?
Well, in order to determine that, we need to know the numerator here and the denominator here.
Numerator here is the probability that she has a positive test result given that she has cancer.
Well, remember, the test is 90% accurate. So given that she really does have cancer,
there's a 90% chance that the test will indicate that she has cancer,
and that is give a positive test result. So the probability of e given h is 90%.
By contrast, the probability of e given not h is 10%, right? Because conditional on her not
having cancer, there's still a 10% chance that the test would go wrong. That is,
that the test would give a positive test result positive for cancer. So the probability of e
given not h is 10%. And what that means is that the likelihood ratio is 9 to 1, right? Because
the numerator here is 90%. The denominator here is 10%. And 90% to 10%, right? That's a ratio of
9 to 1. So then we multiply the likelihood ratio by the ratio of the priors in order to get 9 to 99
or simplifying 1 to 11. Again, keep in mind that this is the ratio of the posterior is
1 to 11 or 1 divided by 11. That is not the probability that she has cancer given that she
tested positive. This is the ratio between the probability that she has cancer given that she
tested positive on the one hand. And on the other hand, the probability that she doesn't have cancer
given that she tested positive. Okay, so this is just a ratio of these two posterior probabilities.
Again, if you want to convert that to an absolute probability, the absolute probability that she
has cancer given that she tested positive, we do 1 divided by 1 plus 11, right? That was the 3 divided
by 3 plus 2 in the last example. And in this case, we just do 1 divided by 1 plus 11, which is 112,
or in other words, 8%. So 8% is the probability that she has cancer given that she tested positive.
So she doesn't have too much to worry about. It's literally 92% probable that she doesn't have cancer
in light of this evidence. And of course, given that it's 8%, we know that D is the correct answer.
And then here's a final note about the odds form of Bayes theorem. Importantly, it isn't
