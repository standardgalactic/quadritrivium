And by the same token, if q logically entails p, then the probability of q is less than or equal to p.
And when you have a is less than or equal to b, but also b is less than or equal to a,
it just follows from that, that a and b are equal to each other, right?
Just think about that.
A further important consequence of Kolmogorov's axioms is finite additivity extended
to any finite set of mutually exclusive propositions.
So this says that for any finite set of mutually exclusive propositions, p1, p2, through pn,
the probability of the disjunction of those propositions is just equal to the sum of the probabilities of those individual disjuncts.
And this is basically just general additivity extended to cover any finite set of mutually exclusive propositions,
rather than just a two-membered set.
Now, you might be wondering, Joe, okay, you know, these axioms are cool and all,
but like, what's so irrational about flouting them?
Like, who cares if I flout these normative constraints on credences?
Like, so what if my credence in p is 0.6 while my credence in not p is also 0.6?
What are you gonna do about it?
Well, I mean, of course there's nothing in psychology that rules out the possibility that an agent at a time
might attach a credence of 0.6 to, say, the proposition that it'll rain tomorrow
and simultaneously credence of 0.6 to the proposition that it won't rain,
thus violating the immediate implication of the probability axioms that the probability of p equals 1 minus the probability of not p.
So yeah, there's nothing in psychology that rules that out.
But in addition to its just being seemingly self-evident that that's irrational, set that self-evidence aside,
in addition to that seeming self-evidence, there's an argument that any rational credences must conform to the axioms of probability,
even if someone's actual credences don't always do so.
And the argument is that anybody whose credences violate the axioms of probability can have a Dutch book made against them.
A Dutch book is a set of bets which guarantee that you'll lose money no matter what outcome occurs.
So by way of illustration, consider the person whose credence that it will rain is 0.6
and whose credence that it won't rain is also 0.6.
Well, this person will happily pay 60 cents to win $1 on its raining
and also will happily pay 60 cents to win $1 on its not raining.
They'd be willing to make those bets, those bets are perfectly fair by their lights.
But anybody who makes this pair of bets will be guaranteed to lose money no matter what happens, whether it rains or not.
Because they'll have paid out $1.20 in total and will only win $1 whether or not it rains, right?
It's either going to rain or it's not, if it rains we're only going to be making $1
and if it doesn't rain they're going to be making $1.
And yet they'd be willing to pay 60 cents on both of these bets
and so they'd be willing to pay out $1.20 even though they can only win $1 in this situation.
And so they're guaranteed to lose money here.
And in general, it's not that hard to prove that a Dutch book can be made against you
just in case your credences fail to satisfy the axiom of probability.
And since it seems clearly irrational to adopt attitudes that make it certain that you will incur a loss
it follows that any rational agent will have degrees of belief that do conform to the probability calculus.
And that also includes Bayes theorem by the way because that's a consequence of the axioms of probability theory.
There are other reasons for thinking that these axioms normatively constrain credences
so there are for instance accuracy based approaches to arguing for these rational constraints
that basically has to do with how well you're doing getting at the truth
and we basically assess your credences in terms of how close they are to the truth.
It turns out that by your own lights you maximize your chances of getting to truth if you obey the probability axioms.
So anyway, there are accuracy based approaches to arguing for these rational constraints
and there are lots of other approaches besides but we're not going to get into that here.
That's a huge literature unto itself.
We've covered the Kolmogorovs axioms enough
and now we're going to be turning to the fourth rational constraint on credences
or the fourth core normative rule of Bayesian epistemology.
And that is the ratio formula. Yes indeed.
So again, the ratio formula is the fourth core normative rule of Bayesian epistemology.
Before getting into it though, we need to get clear on conditional probability.
A conditional probability is the probability of one proposition being true
on the assumption of another proposition being true.
It's a probability that one proposition is true given that another proposition is true.
And we represent the probability of P conditional on Q as the probability of P given Q.
It's this little thing on screen here.
This is the probability of P given Q.
Okay, so again, this is the probability of P given that Q is true
or on the supposition that Q is true or assuming that Q is true
or on the condition that Q is true.
Okay, you get it.
Oh, and by the way, an unconditional probability is just a probability that isn't conditional.
So yeah, that is an unconditional probability there.
It's not conditional on anything, but alas, we introduced the conditional back
because that's how the slide was originally.
All right, with that out of the way, here is the ratio formula.
The ratio formula says that for any propositions P and Q,
the probability of P given Q equals the probability of P and Q
divided by the probability of Q,
where of course the probability of Q is greater than zero
because you can't divide by zero.
That is undefined.
So that's a bit abstract and it might be hard to see on its face why it would be true.
And that's where handy-dandy Venn diagrams come in.
So consider the following Venn diagram.
Again, the rectangle itself is going to be representing all logically possible worlds.
The probability of P is the fraction of that rectangle taken up by the P circle.
And by the way, the area of the rectangle is stipulated to be one.
And so the fraction of the rectangle taken up by the P circle
is just the area of the P circle divided by one,
which of course is just the area of the P circle.
So yeah, the probability of P is the fraction of the rectangle taken up by the P circle.
And the same thing goes for the probability of Q.
When we ask about the probability of a proposition conditional on the assumption that Q,
we temporarily narrow our focus to just those possibilities that make Q true.
In other words, we exclude from our attention the worlds shaded in within this diagram.
And we then consider only what's in the Q circle.
The probability of P given Q is then the fraction of the Q circle
occupied by the P worlds.
And so it's the area of the P Q overlap
divided by the area of the entire Q circle.
And notice that that's just the probability of P and Q
divided by the probability of Q.
And that of course gives us the ratio formula, right?
The probability of P given Q is equal to the probability of P and Q
divided by the probability of Q.
I just want you to think about this intuitively, right?
The probability of P given Q, the probability of P on the assumption that Q is true.
Well, what do we do there? What do we do to assess that?
Well, we narrow our focus to the worlds in which Q is true.
And then we ask, among the worlds in which Q is true,
what's the proportion of those in which P is also true?
And notice that that just is the probability of P and Q
out of the probability of Q, right?
So it's the probability of P and Q divided by the total probability of Q.
That is the probability of P given that Q is true.
I hope that that's intuitive.
To give a concrete example, in the scenario in which I roll a fair die,
the initial range of possibilities includes all six outcomes of the die roll.
I then ask for the probability that the die comes up six,
conditional on its coming up even.
That is the probability of six, given that it's even.
To assign this value, we exclude from consideration all the odd outcomes.
Note that we haven't actually learned that the die outcome is even.
We've simply been asked to suppose that it comes up even
and assign a probability to other propositions in light of that supposition.
We then distribute the probability equally over the outcomes
that remain under consideration, which is two, four, and six.
And so the probability of six, conditional on even, is one out of three, one-third.
And of course, we get the same result from the ratio formula.
The probability of six given E is equal to the probability of six and E
divided by the probability of E.
The probability of getting a six and even just is the probability of getting a six, right?
So that's one-sixth.
And then you divide that by the probability of even, which is, of course, one-half.
And one-sixth divided by one-half is one-third.
So importantly, the ratio formula allows us to calculate conditional probabilities
from unconditional probabilities, that is, probabilities relative to no suppositions
beyond perhaps our background information.
Again, keep in mind that the ratio formula is a rational constraint
on how an agent's conditional credences should relate to their unconditional credences.
And as a normative constraint, rather than a definition,
and as a normative constraint, it can be violated by assigning a conditional credence
that doesn't equal the specified ratio.
And if you violate it, you'll be susceptible to a Dutch book.
Anyway, onwards we march to the fifth and final core normative constraint on rational credence,
and that is the conditionalization principle.
So according to Bayesians, when you acquire new evidence,
you should update your beliefs that the evidence bears on by conditionalization.
So yeah, we have some hypothesis H that you have a certain credence in,
and we also have information E or evidence E that you learn.
According to the conditionalization principle,
you should update your credence in H by conditionalizing on the new information E.
And what that means is that when you learn new information E,
your new probability of H, after learning E,
should equal your old probability of H given E, before you learned E.
So that's what the new and the old represent.
Your new probability of H is new insofar as it's after you learn E,
and your old probability of H given E is old insofar as it's before you learn E.
Also, we don't necessarily need to cast this in terms of learning,
we could just cast it in terms of considering.
Maybe you knew E all along, but like, never stop to consider
how E bears on some of your beliefs or some of your credences.
So we could say when you newly consider information E within an epistemic context,
your new probability of H should equal your old probability of H given E.
So yeah, that's it.
That's the simplest articulation I can muster of the conditionalization principle,
or again, sometimes known as the principle of conditionalization.
And by the way, obeying the conditionalization principle
is often known as updating by conditionalization.
And hopefully you find this pretty intuitive.
Suppose you don't know whether it's raining or not right now.
I ask you, hey, if it's raining right now,
how likely do you think it is that it will still be raining in two hours?
Suppose you answer about 40%,
and then you look outside and see that it actually is in fact raining,
and that's all you learn.
I then ask you, well, now how likely do you think it is
that it will be raining in two hours?
Well, if you're rational, you're gonna answer 40%, right?
If that isn't intuitively obvious, it's also possible to construct a Dutch book
for anyone who fails to update by conditionalization,
but we won't get into that here.
So again, the conditionalization principle is a rational constraint on credences,
and in particular, it's a rational constraint on credences across time.
The Kolmogorov axioms and the ratio formula relate rational credences at a single time.
They're basically rational demands on consistent and coherent credences at any given time.
By contrast, conditionalization relates rational credences at different times.
It requires rational credences to line up in a particular way across time,
and the central idea is that rational agents should conditionalize whenever they gain new information.
So anyway, that's basically the least formal way that I could have stated the principle,
is that when you gain new information E,
your new probability of H should equal your old probability of H given E,
but I do want to give two slightly more formalized versions of the principle
while still retaining accessibility.
And to do that, I'll be continuing with concrete, tangible examples
to make things as comprehensible as possible.
So suppose that you have the following probability assignments,
and again, remember that we can helpfully treat probabilities as rational credences,
at least for the purposes of this section.
So the probability that Johnny goes to the party is one-half,
and the probability that Johnny goes to the party conditional on Jane's going to the party is two-thirds.
So yeah, suppose that those are your probability assignments.
Well, now you learn that Jane is going to the party.
The question then is, what should your new probability in Johnny's going to the party be?
