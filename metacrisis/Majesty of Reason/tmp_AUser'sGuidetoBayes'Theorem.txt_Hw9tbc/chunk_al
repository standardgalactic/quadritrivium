for theism, right? Given theism, so restricting your focus to the space of theism, three quarters
of that space is occupied by fine-tuning. So the conditional probability under this model here,
the conditional probability of fine-tuning given theism is going to be 3 fourths, not 3 eighths.
I just wanted to clarify that. The 3 eighths here is what he wrote, taking into account the
proportion of this space here to the total probability space. But the 3 eighths is not
the conditional probability of fine-tuning given theism, that's going to be 3 fourths.
I just wanted to clarify that. Now let's look at the final bar and the two probability assignments
there. So three quarters for theism and fine-tuning, and a quarter for atheism and fine-tuning.
These are known as the posterior probabilities. That is the probability after we've taken into
account the relevant evidence. With this jargon now explained, let's think about how the bar relates
to Bayes Theorem. Bayes Theorem says the probability of the hypothesis given the evidence is equal to
the probability of the hypothesis multiplied by the probability of the evidence given the hypothesis
divided by the evidence. So here you can see the formula written out in full with pr standing for
probability, h for hypothesis and e for evidence. The jargon we have just learned is also useful
when thinking about the formula with the probability of the hypothesis given the evidence relating to
the posterior probability, the probability of the hypothesis being connected to the prior probability,
and the probability of the evidence given the hypothesis linking with the conditional probability.
In order to think about how the formula works, let's ask the question, what is the probability of
theism given the evidence of fine-tuning? So in this case, h, a hypothesis, is going to stand for
theism and e, our evidence, will be fine-tuning. In order to find out the answer to this, we're
going to need to fill in the other half of Bayes Theorem. First of all is the probability of the
hypothesis, which in our case is theism. This is going to be a half and we can see this in our first
bar. Next is the probability of the evidence given the hypothesis, which in our case is the probability
of fine-tuning given theism. This has the value of three quarters, which we can work out from looking
at our second bar. In order to do this, look at the second bar and imagine removing the atheist
half of the bar so that all we have left is the theistic half of it. Now ask yourself how much
of the theist part of the bar does fine-tuning take up? The answer is three quarters and this
is the value we put here for the probability of the evidence, fine-tuning, given the hypothesis,
theism. So far we filled in the top part of the Bayesian formula and now we have to work out what
it is that we divide it by, which is the probability of the evidence. To get this value we have to
work out how likely the evidence is in our case fine-tuning on any hypothesis and to do this we
need another formula. This one says that we first find out the value of the probability of the evidence
given the hypothesis multiplied by the probability of the hypothesis and then also the value of the
probability of the evidence if the hypothesis is false multiplied by the probability of the hypothesis
being false and then we add these two values together. So in our case we get the probability
of fine-tuning given theism three quarters which we can work out from looking at our second bar
and multiply it by the probability of theism which is a half which we can see in our first bar.
We then work out the value of fine-tuning given the falsity of theism so in our case the probability
of fine-tuning on atheism as this is the only other hypothesis we're considering and this is
the value of a quarter which we can work out from looking at our second bar and then we multiply this
by the probability of the falsity of our hypothesis and so in our case the probability of atheism
and here we can see that the value is a half which we can see in our first bar. After getting these
values we add them together the result of this is a half and we can check this by looking at our
second bar for if you look at it and add up the two sections of the bar where there is fine-tuning
we can see that it takes up half the space of the whole bar with that done we have the three
values we need to fill in Bayes theorem so a half for the probability of the hypothesis
three quarters for the probability of the evidence given the hypothesis
and a half for the probability of the evidence so let's answer the question what's the probability
of theism given fine-tuning first we input the numbers we have so it's a half multiplied by
three quarters divided by a half since many people find it easier to perform calculations on decimals
rather than fractions that's the same as 0.5 multiplied by 0.75 divided by 0.5 and the answer
we get is 0.75 or three quarters and we can also check that this is right by looking at our third
and final bar where we can see that three quarters of the bar is for theism and fine-tuning just as
we got here so that's how the Bayesian bar relates to Bayes theorem whilst this has been a bit more
technical I hope you can see that the formula is easier to fill out when we're using the bar
and the bar is also a helpful way to show you what Bayes theorem is doing but remember as I
said to you in the previous video you can always think about probabilistic arguments in terms of
the bar without numbers if you prefer but knowing how the formula connects with the bar is helpful
so that you can use the more formal apparatus if you wish and translate more formal presentations
of arguments into the bar all right so we've gone over different ways to visually represent
Bayes theorem that was the purpose of this fourth section of my video if you just follow the steps
that three blue one brown laid out or that Ben Page just laid out you'll be able to solve probabilistic
problems a lot easier and you'll also start to refine and hone your intuitions to be in line
with proper probabilistic reasoning but onwards we march to perhaps the most important section
in the whole video we'll basically be taking what we've learned so far and seeing why certain
kinds of thinking are fallacious or mistaken so one common mistake is one we've already seen or at
least one we've already hinted at and it's the base rate fallacy this basically amounts to ignoring
prior probabilities when trying to assess how probable a hypothesis becomes in light of certain
evidence so recall the odds form of Bayes theorem the posterior ratio is equal to the
likelihood ratio times the prior ratio notice that the ratio of the posteriors is a function
not just of the likelihood ratio but also of the ratio of the priors oftentimes without recognizing
it will ignore the ratio of the priors when trying to determine the ratio of the posteriors
and will instead only focus on the likelihood ratio that's disastrous since even if the likelihood
ratio is very top heavy the prior ratio may be very bottom heavy and so if we ignored the prior
ratio we'd mistakenly conclude that the posterior ratio was significantly top heavy and hence that
the posterior probability of the hypothesis is very high after conditioning on the evidence in
question this is a mistake you need to take into account the priors this sort of reasoning is also
known as the base rate fallacy or base rate neglect when thinking about statistical problems
the base rate of a feature is basically just the prevalence of that feature within the
population at large oftentimes we neglect this prevalence in assessing the probability that
some hypothesis is true for instance in assessing whether or not someone has cancer we often neglect
that base rate and instead focus on the likelihood of the evidence on the hypothesis this may have
been what happened to you in the opening problem of this video you may have failed to take into
account the 1% prevalence of cancer in the population and focused instead on the probative
or evidential value of the positive test result this may then have skewed your assessment of the
probability that the woman had cancer towards it being much more likely that she had cancer
but as we've seen that's mistaken yes while the test is 90 accurate and so count says reasonably
good evidence that the woman has cancer the prevalence of this cancer in the population
is still very low and when you plug in all the numbers the overall probability that she has
cancer is only 8% and the reason is that among the people who test positive most of them in
fact 92 percent of them are false positives this shows the importance of taking into account
both the evidence and the base rates or priors but also of course don't be too focused on the
prior there is a kind of dogmatism where someone thinks that hypothesis is so implausible that
that they either don't consider evidence against it or they ignore evidence against it
or they downplay evidence against it or they think no amount of evidence could overcome their prior
those are also all mistakes so anyway that is the first mistake that we're going to cover
the cancer example also illustrates another common mistake in reasoning namely inferring
from the fact that there is a strong piece of evidence for a hypothesis that the hypothesis
must probably be true no that's incorrect right just because e is evidence for h indeed just because
e is very strong evidence for h it doesn't follow that e makes h probable h could still be very
improbable overall remember to say that e is evidence for hypothesis h is just to say that
e raises h's probability that doesn't mean that e makes the hypothesis probable before taking
the evidence into account the hypothesis might be only one percent probable and afterwards it might
be five percent probable notice that the evidence here has raised the probability of the hypothesis
but it clearly doesn't make the hypothesis probable in other words it didn't render the
hypothesis probably true or more probable than not or anything like that so never infer from the
claim that say fine-tuning is evidence for theism that theism is therefore probably true and
never infer from the claim that say evil is evidence for atheism that atheism is therefore
probably true those don't follow to determine whether theism or atheism is probably true you
need to take into account their prior probabilities and not only that but you also have to take into
account our total range of data our total range of evidence that bears on these hypotheses and
this too bridges into another common mistake in reasoning which is ignoring the total evidence
requirement according to the total evidence requirement also called the requirement of total
evidence when assessing the overall probabilities of hypotheses we should take into account all
of the relevant evidence at our disposal instead of just some proper part of that evidence you may
determine that after conditioning on some evidence e a hypothesis is more probable than its negation
but if that's the only evidence you're taking into account and there are other pieces of data
that bear on the probability of this hypothesis then you're not licensed to conclude after only
examining e that the hypothesis on the whole all things considered is more probable than
its negation to infer that you need to take into account the total range of data or evidence that
we have so for instance even if you have a Bayesian argument from evil against the existence of god
and even if you take into account both the likelihood ratio and the prior ratio and even if
you conclude from this that the ratio of the posteriors heavily favors atheism you can't then
conclude that atheism is probably true all things considered you need to take into account other
relevant evidence like fine-tuning divine hiddenness consciousness religious disagreement religious
experience and so on the same is true for Bayesian arguments for theism of course and closely related
to the total evidence requirement is the fallacy of understated evidence which is the next mistake
in Bayesian reasoning on our list and we're going to hand it over here to real a theology to explain
what the fallacy of understated evidence is and to offer a concrete tangible application thereof
let's say a couple with two small children moves in across the street from you they also drive a
brand new car now you just happened to be reading earlier that day that this particular model and
year scored the highest in its class in every single safety measure across the board you also
learned that this car costs significantly more than other cars in its class specifically because
of this high safety rating given the total evidence available to you at this time you reasonably infer
that your new neighbors probably care a great deal for safety for their family
you wait a few days allowing them to settle in before crossing the street to introduce yourself
however as you walk up their driveway you notice that the airbags have been tampered with and
disabled and that the child safety seats are both attached improperly with duct tape naturally you're
a bit puzzled observing the general fact that your neighbors purchased a car specifically
pricey for its safety features clearly seems to be more likely on the hypothesis that the
family cares about safety than on the hypothesis that the family does not care about safety and yet
given the general fact the additional observations the specific facts of the duct taped child safety
seats and disabled airbags are more likely on the hypothesis that the family doesn't care about
safety than on the hypothesis that they do now if say somebody was in a position to know all of
these facts the general and specific facts but yet they presented an evidential argument for the
hypothesis that the family cares a great deal for safety but appealing only to the general fact about
the car's high safety rating and related high cost they would be guilty of understating the evidence
philosopher paul draper argues that many evidential arguments for theism are similarly guilty of
appearing convincing only because they understate the evidence as they quote successfully identify
some general fact about some topic that is more surprising on naturalism than on theism but all
two conveniently ignore more specific facts about the topic facts that given the general fact are
significantly more surprising on theism than on naturalism there are many examples of arguments
for theism which fit this pattern one such argument sets its sights on religious experience
if we agree that the general fact of religious experience had apparently of god is more likely
on theism than on naturalism we can say it counts as some evidence for theism over naturalism
but paul draper reminds us that the general fact of the existence of religious experience
is not the only relevant fact we know about that topic draper reminds us of three specific
facts which given the general fact of religious experience are much more likely on naturalism
than on theism first quote not everyone has theistic experiences and those who do typically
have a prior belief in god or extensive exposure to a theistic religion secondly
the subjects of theistic experience pursue a variety of radically different religious paths
none of which bears abundantly more moral fruit than all the others and third victims of tragedy
are rarely comforted by religious experience again given the general fact of the existence of
theistic religious experience each one of these facts are more likely on naturalism than on theism
and so after considering all the relevant facts about religious experience it's not at all obvious
that relevant observations regarding the topic of religious experience actually favor theism over
naturalism just as when considering all the facts about your neighbor's car it's far from obvious
that they give a damn about their children according to draper many evidential arguments
for theism suffer similarly and what matters more here is more the fallacy of understated
evidence and at least understanding the content of that than whether or not you agree with draper's
assessment there another pretty important mistake that you should be aware of and avoid
is ignoring the comparative nature of Bayesian confirmation we already covered this but this
is worth keeping in mind as a separate mistake that you need to avoid right recall that e is
evidence for h if only of the ratio between the likelihoods of h and not h is greater than one
e is more expected or more probable or more likely on h than it is under the negation of h
notice that this is essentially comparative we're comparing how likely e is under h to
how likely e is under not h and again even if e is very improbable under h e can still be very
powerful evidence for h what matters is that e is still more probable under h than it is under
the negation of h another mistake which is kind of related is demanding strict precise numerical
likelihoods of the data conditional on the hypotheses in question the thing is when you
have the comparative nature of Bayesian confirmation firmly in mind you can see that that isn't strictly
necessary at least for many purposes we saw this actually when we watched ben page's video on the
bayesian bar right he still showed the utility of the bayesian bar and bayesian reasoning even if
you don't assign precise numerical credences and richard swinburne also writes that to accept
that bayes theorem governs all claims about the support given by evidence to hypotheses
does not involve holding that the various probabilities can be given exact numerical
values and as he noted earlier inductive probabilities do not normally have exact
numerical values one can think of them as having rough values values within certain limits and one
can think of the theorem as putting limits on the values of some probabilities given the limits on
others another mistake you might see in reasoning is that you might hear someone say that some data
e obtaining would be evidence for hypothesis h but e not obtaining wouldn't be evidence against h
but that is mistaken if e is evidence for h then not e is evidence against h you could also say if
e would be evidence for h then not e would be evidence against h importantly this just follows
from bayes theorem so for instance if seeing a limb grow back after prayer would be evidence for
the efficacy of prayer then not seeing a limb grow back after prayer would be evidence against
the efficacy of prayer so let's see why this is the case what i'm going to be calling the
evidential symmetry thesis if he is evidence for h then not e is evidence against h so that's our
goal our goal is to establish this thesis so suppose that e is evidence for h then it follows that the
likelihood ratio the ratio of the likelihoods of h to not h is greater than one e is more expected on
h than it is under not h so this ratio here is top heavy and hence when you divide the numerator
