machine being better and then we can and then we can say our observation is a one and here a one
and a zero and that just encodes in this case that the the hint that the left machine is better
and if this is our likelihood function then this observation here would pick out the top row
which is just saying that so left machine has a point nine probability of being the case given
that the you got the left hint or I said that backwards but but the probability of the left
machine better is point probability that the left machine is better is higher under the with the
left machine hint so we can just use those probabilities and to figure out the posterior
overstates here and just to show you how you would do that just to carry out that equation
we end up with this which then once you softmax it becomes that which is just saying that now
there's a point eight two probability that the left machine is more likely to pay out
so moving on from that to dynamic perception now requires that I make a kind of distinction
that's that's been a little tricky often when people are learning active inference to start with
and that's the fact that there's different types of time in active inference so the first notion of
time is indexed by this Greek letter tau and that's the time about which I have a belief so
for instance I might believe right now that I'm in a car but I might believe that I was in the
kitchen 10 minutes ago and I might believe that I will be at work in 20 minutes so those are
beliefs that I have about three different times but I have all of those beliefs right now in the
present so T is the time at which I have a new observation so the belief at which I have all
these beliefs about the different times so here we might say after turning on a light so I make
some observation that say T equals at T or at yeah at tau equals T then I believe now that I was in
the kitchen for the last five minutes so whatever tau minus one was so in other words I can get an
observation later and I can update my belief about where I was at an earlier time although I
didn't know that before turning on the light so I can update my little belief about all towels
the states at all towels with each new observation at each T so hopefully that's helpful and note
again that the variable Q here is just denoting our our approximate belief for best guess like I
mentioned before so and then the other thing and I mentioned this already but there's a different
thing between there's an important distinguish different state factors and outcome modalities
and the idea is that different factors can correspond to different types of states so like
one set of states might be beliefs about an object's identity whereas another set of states might be
about the object's location or one set of outcomes might be about vision and another set of outcomes
might be about audition so we separate different types of states into factors and different types
of observations or outcomes into modalities so so here when we're modeling dynamic perception
as a hidden Markov model all we're doing is we're just taking the single time point inference here
that I showed before and just kind of stringing them together and then we're connecting the states
over time with these B matrices here that just encode the probability of moving to some state
given that I was in some state at a previous time so we encode these are just the probability of
state transitions and these are essentially you can think about them as providing the prior beliefs
for states for all tows greater than one and the equation for solving this in active inference
is essentially the same in form as the one for the single for solving it for the single time
point the only difference is now so the likelihood here is exactly the same the difference here is
that our prior belief now includes for tau equals on now includes our beliefs from the past and also
beliefs about prior beliefs about where we'll be going in the future and and for tau greater than
one it's the exact same thing except for instead of D here our prior from the past is just the B
from the previous time point and our prior from the future is the same as it was here
so this idea of prior of having prior beliefs from the future is also something that people
often find a little confusing at first but this just goes back to this t versus tau distinction
I mentioned before where this allows you to update beliefs about earlier time points when
you're getting observations about later time points so this will allow you to kind of propagate
when you get an observation at time two will allow you to kind of propagate beliefs back
and update your beliefs about where you were at tau equals one now solving this now requires
because we have to do it with approximate inference gets in gets into message passing
algorithms and in this case with active inference the main way that we tend to do it is with
variational message passing or or an updated version called marginal message passing but
that's what the equations I just showed you implement and as we'll see in a second this
message passing scheme is actually what the neural process theory in active inference is based on
and so to just go into this the idea is is that message passing is essentially an efficient way
to do approximate posterior inference on a graph and so and it's based on minimizing a
quantity called variational free energy which I'll go into after kind of giving you a practical
example of how this how the dynamics work so essentially what you do is you just start by
encoding whatever observation is one so fixing fixing whatever observation is a tau equals one
and so let's say it's observation the top observation here so we'll just call that observation
one so now what you would do is you'd use that and you'd first try to update your belief about
whatever states are for tau equals one and we do that just by passing these messages so in other
words in this case it's just the log the natural log of the prior belief and the natural log of the
prior belief from the future time point and then our likelihood and we just put those together
and then we update our belief our approximate belief about states of tau equals one and in this
case if I were to do that with actual numbers it would just look like that so we'd update our
belief about s of tau equals one to now be a point five five point four five and then we would take
that new qs and we'd now use it to try to try to update our beliefs about states of tau equals two
and and then same thing we get our qs equals two then we do the exact same thing again pass
those messages and get our updated posterior belief for asset tau equals three and then we
just do that over and over again until eventually this will converge onto a stable updated prior
updated posterior belief about states at each of these time points and and crucially so that's
all based just on making up the first observation so once we do that we can assume that beliefs
have now converged and now we add the second observation in and then we just do the whole
thing again so after the new observation comes in we update our beliefs about all the different
time points so and then we just repeat it again iteratively until we reach convergence
and then we arrive at a final posterior belief ultimately about all time points after all
observations and and you can kind of plot out the way that beliefs change so in an easy inference
problem we have pretty fast convergence so in this in this graph we have six different traces
so it's beliefs about each of the two possible states so left the left machine being better
or the right machine being better we have beliefs about each of those over each iteration of message
passing and what you can see here is this is just showing that really quickly beliefs that the left
machine is better for all three time points converged being one really quickly if I were to
make the inference problem harder by making the transition beliefs more probabilistic for example
then you can see that the inference problem becomes harder and you have slower evidence
accumulation and so it takes a lot longer for the beliefs to to converge so and as I mentioned
before this also represents a possible way to think about the way that messages are passed
between neurons in the brain and this comes in part from the fact that we can think about
message passing or it can be formulated the equations can be formulated in terms of something
like minimizing a prediction error and the way you the way you do that and I won't go into this
in a in a ton of detail right now but you can just kind of shuffle around the variables here a little
bit and make it so that this is the fixed point for this is zero as an error which we represent
like this and then we're just moving the s over here to the end and then message passing is described
in an identical way except for now that what it's doing is kind of every time you iterate it it's
moving toward this error being as low as possible and the reason it you can think about it as a
prediction error is you have whatever over here the generative model after an observation and then
you have your new approximate posterior river states and the difference here is essentially
is essentially the error signal because you're trying to get these to match as well as possible
and then you can define a kind of membrane voltage that would be associated with with the
activity in a given neuron with this variable v where v is just the log of this posterior
state so it's just identical to this and and that can take on continuous values like a membrane
voltage whereas softmaxing this so normalizing it then becomes your beliefs about states
which can then be thought about as a normalized firing rate which can only take values between
zero and one so that's kind of the the really basic idea about that first part of the neural
process theory is just you can you can formulate message passing on a graph like I just showed
you in terms of a prediction or minimization process and there's a nice paper by Thomas Parr
I guess who's going to be talking to you at the next meeting showing how just illustrating how
you can connect a pretty small number of neurons together to to implement this just as a kind of
concrete illustration where the the state probabilities and the error signals are just
represented by the activity in a set of neurons where each one each pair of neurons corresponds
to beliefs about each moment in time so each tau whereas the conditional probabilities so the
likelihood and the prior beliefs are just encoded in the synaptic weights essentially the strength
of the excitatory and inhibitory connections between each of these neurons so that's kind of the
simplest aspect of the active inference the neural process theory and active inference
so to kind of illustrate how this works practically in the in the task so let's just say
that I have completely precise prior beliefs about transitions so if the left machine is
better at time point two then it will still be better at time point three so this is all this
is saying it's just probability of left at time point two is going to be is also going to be 100
probability of one at time point three so so if we do that then well what I'm showing here is just
a set of graphs here where for tau equals one tau equals two and tau equals three these are the
posterior beliefs that the left machine is better and the right machine is better and here's the
observations and so darker here is going to equal higher probability and the cyan dots here I'll
show you just correspond to whatever the true state or outcome or action is depending on the
specific plot but so let's say we start out and there's a null observation so it doesn't get any
information so its beliefs don't change at all everything just stays flat and gray but now at
the second time point it observes the the the hint that the left machine is better so now
the update the beliefs update and note that they update for each time point right so and now it
believes that the left machine was better at tau equals one it believes that it is better right
now at tau equals two when it got this observation for t equals two and it also now believes that
the left machine is better at time point three or will be still be better at time point three which
is when it would make the choice about which machine it would choose and then it doesn't make
any it just makes the null observation here but the beliefs basically stay the same about all time
points and this is just noting how the beliefs about both the past and the future change
but it makes the observation at time point two um so now if we were to do um if we were to just
plot this um each of these rows the way that um I did before um literally you can just treat
as I mentioned each of these each of these traces as corresponding to predicted firing rates um and
then what what leads um active inference to be able to make material um empirical predictions um in
terms of EEG studies is that you can um you can just take the those voltage um predictions or or
really it's something very equivalent would just be the rate of change in the posterior beliefs
and that will generate um ERP predictions um and what this basically saying is just the faster the
neural uh the neural firing rates change the larger the ERPs will be um and just to show how
that can differ given um different belief precision um we can make it so that the priors over states um
the transitions are um are less precise so this version of a B matrix would say that if the left
machine is better at time point two it'll still be better at time point three but only with probability
of point seven right so the left being better transitioning to the left being better is only
point seven um so in this case if I do the exact same thing then when it gets the left hint
now it's confident that the left machine is best at tau equals two but it's no longer that confident
that it was best at time point one and time point three because the probability the transitions are
only point seven so that's what makes the the difference there um when you have different
prior transition belief precisions
and again same thing with the neural process theory um we get precise changes for the traces
for tau equals two but much less precise for tau equals one and tau equals three um which is going
to predict a very different pattern of ERPs in an empirical study
and there are a few papers now that either in simulations or in empirical studies
that have shown evidence that these predicted ERPs match up well with empirically observed ERPs
which is promising but still there's only a few studies so far
um and these are just examples of the ways that these traces kind of match so like here's an
empirical PR ERP in an inattentional blindness paradigm and this is what a simulated ERP
looks like when you're modeling the same task
so the the next kind of important thing so I mentioned that um I mentioned that this message
passing um slash prediction error minimization sort of scheme was based on minimizing variational
free energy um so now I now that you have a sense of other dynamics work um wanted to walk
through um kind of explain formally what variational free energy is um so the idea is that you're
starting with some generative model and in this case I'm not including policies um just for for
simplicity so in which case your generative model is just your joint of observation probability of
observations in states which we know you can just represent as a conditional times marginal here
um and then what we're doing with variational free energy is we're um starting with a kind
of arbitrary qs that we somehow want to get to approximate the true posterior as closely as
possible um and then we formulate f like this so and what you'll note is that there's this part
here and there's this part and this part um is fairly intuitive in terms of the way that f
minimizing f ends up minimizing a prediction error um and the reason is is because this is just
putting our approximate posterior over our true posterior um so it follows that the closer that qs
gets to ps given o um the the smaller this whole thing will be right so in other words f gets smaller
as our approximate posterior comes to match our true posterior um so it's just the difference
between the approximate and the true posterior and then what's left over is just the log probability
of the observations under the model so just how surprising is the observation under my model in
general which is um equivalent to the the model evidence essentially how good is your model at
predicting observations overall um so as f approaches zero um or f approaches zero as your
approach as your posterior beliefs become more and more similar to your uh to the true posterior
um
and just to kind of show how that works in this simple kind of example um if I start out with
a prior belief that's just flat 0.5 0.5 and I have a likelihood of 0.8 and 0.2 um I can calculate
my joint probability here so just 0.4 and 0.1 um and this um step of calculating the marginal
is what's intractable in real world cases but if I were to do it I end up with a posterior of 0.8
0.2 so with this approximate inference with variational free energy what I would do is I just
start my qs my best guess at just 0.5 and 0.5 and then I can calculate an initial f value um so
here just based on this version of the equation for um variational free energy um which is just
a kind of uh shuffled around version of the variables from the one I showed you before um
I can calculate it as 0.916 um and then I can just move qs a little bit so now it's point
try it at 0.6.4 and I can see that f gets smaller so then I can keep moving it in that direction so
0.7.3 f is smaller still um and then when I get to 0.8.2 then f is 0.693 um and if I try to move it
farther to 0.9.1 then you'll see f goes up again um which means that this is going to be the value
of qs so the guess that best minimizes f um which in this case corresponds exactly
to the true posterior um but it won't often um match it exactly in um in many real world more
complex cases um so that's so that's the idea um now another way that you can represent variational
free energy that um that kind of brings out um part of why it's useful um aside from just being
attractable way to do Bayesian inference um is you can represent it as a kale divergence between
your approximate posterior belief and um and uh the um prior here your prior overstates um so
essentially this is saying how much do beliefs need to change so if I move from my prior belief to
