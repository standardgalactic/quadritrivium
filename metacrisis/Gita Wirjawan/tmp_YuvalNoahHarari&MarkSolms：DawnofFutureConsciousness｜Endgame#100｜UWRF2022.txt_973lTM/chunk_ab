like a nutcase to some of our audience, because certainly a good few years ago I would have
thought anybody saying this is crazy, but I'll leave aside all the scientific reasons why I now
do believe that it is possible for us to engineer an artificial form of consciousness. I say the
very same principle applies, which is that can be used for the better, which is what you are
hopefully nudging us towards. You're saying, you know, how might this be of benefit? How might
this make us more optimistic about the future of our species? But I'm sorry to say it equally
can be used to our detriment, and it also can develop in ways that are not under our control
to our detriment. So like so many advances in science, you know, think just of what we've learned
about nuclear weapons and nuclear energy. On the one hand it's something for the good, on the other
hand it's something that is absolutely catastrophic. So I'm, although I am involved in a project
which fascinates me and which I'm really deeply committed to, where we are trying to develop
an agent with artificial feelings, I'm very, very anxious about what the possibilities are
as to how this can be used, and also how it might backfire on us. So yes, there are fantastic
opportunities for an artificial general intelligence arising out of the now, I think, imminent
capacity to develop an artificial consciousness, but there also are terrible risks and we have to be
the kind of collective decision making and the collective
adhering around ideas that you've always talking about. I think we need to do this fairly soon
in terms of taking responsibility for the implications of artificial consciousness.
You know, the work on ushering new kinds of artificial intelligence seems to be moving in a
rather exponential manner, right? And this leads to, you know, the point that Yuval has
repeatedly raised in that, you know, we're likely to become more and more inorganic, right?
How do we deal with this future where humanity is going to become more inorganic? How do we make
it in such a way that there is more or a higher degree of manageability to this? I'll ask the
both of you. Well, that's probably your department more than mine. Well, I think it is extremely
dangerous and we should slow down because we don't understand the mind well enough and we don't
understand the body well enough to start manipulating them. And the danger is that if we give, you
know, corporations and armies and governments the technology to start manipulating the human
bodies and minds and create, say, connections between brains and computers and so forth,
we've learned so many times from history that they are likely to try and enhance
qualities that they need while ignoring many other important human abilities and characteristics,
and the result will not be upgraded humans. It will be downgraded humans to give an extreme
example from history of how it works. A lot of kings and emperors and sultans in history
had this problem that if they gave a lot of power to their ministers and generals,
these minister and generals might turn against them, kill them and try to establish their own
dynasty. And this was always a problem for every emperor. So many emperors around the world in
China in the Middle East, they came up with an amazing solution based on ancient biotechnology,
which was castration and the creation of a new kind of superhumans called eunuchs.
That if you, as the emperor of China, you take this group of men and you cut off their testicles,
then you have this wonderful tool now, people that you can appoint to be ministers and governors
and generals, and they cannot establish their own dynasty. So the danger they pose is much,
much smaller. And we see this all over the world. Now, from the viewpoint of the emperor,
this solves his problem. But from the viewpoint of the eunuchs themselves, this is, of course,
a terrible catastrophe, a downgrade to what they are, to the humanity. And this can happen again
in the future. Armies, for instance, if you think about the Russian army in Ukraine, so the Russian
army needs more disciplined soldiers who would never run away, maybe also needs more intelligent
soldiers who would make better decisions on the battlefield. But it has no interest in something
like compassion. It's actually better for the army if their soldiers lack all compassion. They never
object to any order, no matter how horrible it is. They don't need their soldiers to have any
autistic sensibility. They don't need their soldiers to have any spirituality. What does an
army need spirituality and soldiers for? So if we give armies, and this is also true of corporations,
the tools to start kind of re-engineering our bodies and brains and minds, the result could be
a new type of humans who might be much more disciplined than us, much more intelligent
than us, but have no compassion or very little compassion, very little autistic sensibility,
and very little spirituality, spiritual depth. So looking at the world as it is now,
at the political, military, and economic situation, I hope that we don't gain the ability
to start re-engineering humans or creating new kinds of cyborgs or inorganic humans any time soon.
Unfortunately, it seems that the technology is coming very fast, and this is a huge,
huge danger. This is, I would say, an existential danger to humanity, not in the sense that the
robots will rise up and kill all of us, but in the sense that our humanity will be destroyed
by all these manipulations and new technologies. This is where I think Mark's work
come in handy, because to the extent that you can actually
not alter, but hopefully do something about the mind that basically is all about feelings, thoughts,
experiences. I mean, you sound as if we need a future where humanity has more compassion
as to try to be able to manage this artificially created intelligence, which could go in a wrong
direction. Is there a way, Mark, to try to bring about more compassion and humanity artificially?
I'm just curious. That last word came as a surprise to me when you said,
can we enhance our compassion artificially? That, I don't think, is the best way to go
about doing it. But I want to say one thing prior to addressing that point directly, which is that
alongside everything that you've all just said about the very real imminent dangers,
because my fellow countryman Elon Musk, for example, is hell-bent on doing the sorts of things
that you've all been talking about. And these are not science fictions anymore. These are really
imminent, imminent technologies coming to the market. I want you to just mention one other
thing alongside that, which is currently artificial intelligence is deployed by
great corporations, for the most part, to perform tasks. They perform boring, exceedingly
complicated calculations over and over again in order to provide us with widgets or information
that we need. If we now develop an artificial consciousness so that these agents, these computers
and robots actually have feelings of their own, then we need to pause for a moment and think,
what about their rights? You're effectively creating a new type of slave, and we have to really
wonder why do we want to do that? Speaking of compassion, this might again sound odd,
but as soon as you start speaking about sentient computers and sentient robots, you need to start
thinking about their rights because now they are capable of suffering. And some of the apocalyptic
sort of images that we've been given by science fiction of battles between humans and artificial
intelligences become conceivable precisely on those grounds if we don't work together.
But again, I'm at risk of sounding like a nutter. So let me address your question directly
about compassion. I was talking earlier about our more basic instinctual dispositions, the things
that we share with other primates and indeed other mammals that lie below the cortical mantle.
Those are not all of them bad things. So for example, attachment bonding, the forming of
affectionate bonds, it's something that all mammals do. In fact, even birds do it. That's a
positive pro-social emotion, including not just that I want to be looked after and cared for,
but also I want to look after and care for vulnerable dependent others, that so-called
maternal instinct or nurturing instinct is just that, an instinct. It's also part of our human
nature. It causes us to stress, to see somebody else in pain, to see a baby crying, to not be able
to put matters to rights. And perhaps the best of all of these instinctual dispositions that are
pro-social in nature is play. I don't know how many people realize all mammals play,
rough and tumble play. You see it in squirrels, you see it in dolphins, you see it in dogs,
you see it in mice, and you see it in our own kids. And play is a, I mean, you just observe how much
fun it is and the glee and delight and the laughter that comes with it. This is an expression of an
instinctual disposition in human beings, and as I say, indeed, in all mammals. And play, the way
that it works, we've studied it very deeply, not only in humans, the way that it works is that
you have to cooperate. There has to be a mutuality and a reciprocity. There has to be turn-taking,
there's a thing called the 60-40 rule, which is that if the one playmate tries to dominate and
call the shots too much of the time and doesn't give the other one a fair chance, then they won't
play anymore. They say, it's not fair, I won't play with you. And then the game's over and then the
fun's over. So play is, I think, something that the better we understand that, because these
dispositions, let me remind you, are hard, wired into our brains, they're there. And because some
of them are pro-social, the better we understand them, I think the better we can utilize them for
the greater good. So I don't think that we need to develop artificial ways of enhancing our
compassion. I don't want to sound like I'm just being all kumbaya. We have alongside our really
horrid dispositions. We also have things like these playful, attachment-bonding,
nurturing, caring dispositions. And so my hope comes from there. If we can combine that with what
you've always talking about earlier, our ability to imagine futures, our ability to cooperate
through language and other symbolic systems, and to agree on ways in which we can live together,
giving expression to this aspect of our nature, I think that's where the hope lies, rather than in
something more artificial in the technological sense. What do you think you are? Yeah, I completely
agree. I mean, again, we know so little about how the mind really works, and also how the brain
really works, that we are very, very far from being able to artificially just produce compassion
in a human being. On the other hand, we have good ways that we developed over thousands of years
of how to develop compassion. Again, whether it's through play or meditation or psychoanalysis
or many other methods developed by many cultures over history, some of them very effective,
and we just need to make more use of them. I think that for every dollar and every minute
that we invest in developing artificial intelligence, we should also invest at least
a dollar and a minute in developing our own consciousness. Developing consciousness means
developing the good qualities of our own minds like compassion. I don't think that we need,
in this sense, to invent something completely new. We just need to pay more attention to what
we already know. Look, Yuval, I know you practice meditation. As a relatively new student of
meditation, I get this notion that if you meditate, you can tap into the subconscious,
you can tap into the unconscious. Would you share the view that this could be something
that could help bring about more wisdom? Meditation is basically bringing more attention
to what's already in us. It's not creating anything new. We have very little awareness
of what is most of what is happening in our mind and most of what is happening in our body.
Our attention most of the time is outside. Therefore, also, for instance, we tend to
blame all the problems in our life on somebody else. Meditation, in essence, it's very simple.
You just reverse the gaze. You bring more attention to observing what's happening inside me,
and inside me means both in the body. You pay more attention to your breath,
the sensations in your body, and also what's happening within my mind.
Like if some story arises in my mind about what somebody did to me, I don't start rolling in
that story. I'm just observing what's happening. Hey, I had this memory now coming up, and look,
suddenly a rage is also coming, and suddenly my breath is becoming much more stronger,
and I have all these unpleasant feelings in my body. Just by bringing more attention,
things that were previously subconscious or unconscious, they are now conscious.
It doesn't force you to do anything specific with them, but when you have a better understanding
of yourself, of who you are, of why you do things, then naturally, you tend to have a more,
how to say, a more complete view of your place in the world, a better understanding of yourself,
and your decisions tend to be better and, again, more compassionate, because in many
situations, you realize it wasn't them. It's something in me. So, yes, I still act in the world,
but I also pay much more attention to my own responsibility for situations.
You know, I want to talk about the role of social media and how it has polarized
conversations, globally speaking, and how it has affected the emotions of so many people around
the world, and I'm getting more and more concerned about the idea that the amplification of
narratives that are thick with hatred, divisiveness, anger, what have you, continue to get amplified
at the expense of narratives that would have been a lot more judicious, which are not necessarily
amplified, which are necessarily sitting within the silent majority. I kind of think that this has
some bearing on not the animalistic tendencies of humanity, but the imaginative or imaginary
capacities of humanity to think about the wrong kind of stuff. I'm curious of the views of the
both of you. Well, Mark, yeah. Yeah, I think you all will have more interesting things to say
than me on that topic. I think it's just, I want to comment on what he said before,
and then I'll hand over the baton to him to address the thing about social media. I really
want to hear what he has to say about it. I'll say only that it's a further example of how
advances in our technology and the intelligence that lies behind it can be used for better and
for worse. I mean, social media is a wonderful thing, but my God, it's really had some negative
consequences, and I look forward to hearing what you've all said about that. I just want to say
about meditation. This is an ancient tradition. It's again an example of how we don't need to
look only to technology and to science in order to advance the cause of humanity and indeed of
the planet as a whole. These are ancient wisdoms. Meditative practices are rooted in things we
learned thousands of years ago, and the remark that you've all made about us having to know
ourselves. This is know thyself is an ancient Greek dictum. It's not something new, and it's
been developed in western culture in psychoanalysis, which I want to mention here, because as you said
at the outset, one of the curious things about me is that I'm both a neuroscientist and a
psychoanalyst. The reason I trained in psychoanalysis was precisely because these sorts of things,
the contemplative, introspective, subjective aspects of our humanity, were not sufficiently
prioritized in my basic discipline in neuroscience and neuropsychology. There's too much focus on
the design of the functionality, the mechanisms, the information processing, etc., and not enough
focus on these things which are profoundly important as you can gather from what you've
always just said. Psychoanalysis is like meditation, a way of getting to know yourself
and to take better responsibility for yourself, to not look outwards. Freud said the mind is like
the esophagus. It wants to flow in only one direction. We want to just look outwards. We
don't want to look inwards. We strongly resist knowing ourselves, but it's an enormously powerful
tool. So while we're making all these advances, let's not forget these ancient and relatively
old practices which are extremely valuable for us. But over to you, Yuval. I really want to hear
what you have to say about the scourge of what's going on in our social media age.
Yeah, we can start from the end and say that it's very clear that something is broken in the
information system of much of the world. We see it in democracies all over the world in very
different situations. The US, Brazil, Israel, you see the same tendencies of the conversation
breaking down. People unable, political rivals, simply unable to hold a conversation, which is
terrible because democracy is simply a conversation. That's what it is. Dictatorship is a dictate.
Somebody dictates what to do. Democracy is a conversation between people with different views.
When people with different views cannot talk to each other, that's the end of democracy.
When they can't talk, the only thing left for them to do is to fight. Then you can
establish a dictatorship or you can have a civil war, but there is no democracy anymore.
And why is it happening? It's not because of greater ideological divides, because actually
the ideological differences in places like the US are smaller than they were 50 or 60 years ago.
When you look at the actual things people argue about in the US today, the differences are much
smaller than they were in the 1960s. So it seems to be something else is happening.
And one of the suspicions is that it's because of our information technology. And the usual theory
goes like this, that in the new information space, especially in social media, there is a constant
battle for attention. It's easier than ever to produce and broadcast, but then more and more
people are fighting for a limited resource, which is attention. And how do you grab somebody's attention?
And this goes back to what Mark was talking about, to all our deep animalistic tendencies.
The easiest way to grab attention is to press the anger button or the fear button or the hate
button. And people, you know, they learn this and they press these buttons more and more.
