So, so Black Mirror was not that sci-fi in reality. That guy was fricking brilliant, those
scenes he made. I don't know if you've watched them all.
I have not watched them all, but it's a mix of like spot on exactly and also a little chintzy
cheesy. And when I watched them, I'm like, Oh, this part, that's going to happen. That part's
a little silly. So, but are we strong enough emotionally, psychologically for this sort of
phase shift on top of everything else going on with climate and resource depletion and
the great simplification? I mean, isn't this just a cultural battle for the brainstem and
technology is going to turn society into an idiocracy where it's all self-medicating with
technology where our world becomes this, like you said, sugary, sweet,
immersive tech, Netflix marriage. I mean, I don't, I can't even process it, to be honest, Aza.
Yeah, this is a continuation of a process that started long ago, magicians, con artists,
discovering facts about how the human mind works, and then learning how to use them towards
whatever end that they have. So. Well, the end, the end is profits, right? Profits for the companies
that design these technologies. Yeah, that is, yes, that is exactly right. And because they
have an asymmetric amount of information about us, and are discovering new species of ways to
persuade us, unless they are acting as a fiduciary to us, that is, in our interests, we're sort of
sunk. We, as humanity, have told ourselves these just so stories. Creativity is the thing that
defines us and will save us. Empathy is that core part of the human experience that will save us.
And actually, isn't it surprising that creativity is sort of the first thing that the AI is coming
for? And that empathy, as beautiful as it is, and is a core part of my life, or, you know,
earth species is about, is also the biggest backdoor into the human mind. And that loneliness
is going to be every country's largest national security threat. Oh, my God. Okay.
I definitely want to carve out a chunk of time to go into your big project, earth species,
because I really believe in it. But you also wear another hat as the co-director of the Center
for Humane Technology. How does AI merge into these risks of polarization, social media, hijacking
our attention, and then we get further and further apart on the political spectrum,
so that we can't even really have a discourse about our reality? How is AI going to change
your work at CHT? Yeah, well, there's sort of like narrow AI and this more like general sense of AI
that we're talking about now. Can you define narrow AI? Yeah, narrow AI, I just really mean is like
the dumb stuff. Like, if you click on something, show you more of those things. If other people
like click on something like you do, show you more of what they click on. It's not, this is not
advanced AI in the same sense of Dolly, but it's pernicious because you end up having
a trillion-dollar market cap company like Facebook pointing... Not anymore, literally.
500 billion, but go on. 500 billion. Things in part to like, well, maybe some of our work to
Francis Hogan. No, definitely. They're like TikTok eating their lunch. You never know exactly what
makes what happen. But $500 billion of market cap, powering quite literally the largest deployed
AI systems in the world, looking for whatever generates the most engagement. And actually,
that's not exactly right. In the beginning of 2018, Facebook switched to using a metric called
meaningful social interaction. And what does that mean? They were measuring, they're up-leveling the
content, which causes the most reaction from your friends. You post something, if your friends react
to it, and if they react to it with an angry face, it gets a 5x boost, then that is the content that
gets promoted. Wait, if my friends hate what I said because it gave them an angry face, that gets a
5x vote in the algorithm? Yeah. Now, I don't know if that's still true, but this is some of the
documentation that came out from Francis Hogan's Facebook disclosures. What about a love icon?
At that case, I think it was ranked less. But now, I don't remember.
Well, I'll have to look on that because if hate is valued more as an engagement than love,
that's a fundamental problem with our entire system.
I completely agree. And Jonathan Haidt just pointed out some new research that the most
viral thing, the thing that gets the most engagement, the most reaction on social media,
is hate against outgroups. That is number one, the most viral thing.
He's going to be on the show after his book is done, so I love his research. But that is who
we are as tribal animals, right? Is ostracizing outgroups is a core, conserved aspect of our
genome. And we're seeing it unfold in real time. Yeah. But human beings are complex.
And the thing, I think, to take away, it's like, are we narcissistic and tribalistic?
Or are we creative and altruistic? And the answer is like, well, neither. It's that we're both.
And it's that the environment that we are living within can imagine these aspects
of ourselves as resonant tuning forks. And if the environment outside is humming at a
certain frequency, it'll activate different tones within us. And so if we live in an environment
where we are literally getting paid in likes and follows and in engagement for hating on the outgroup,
it's that part of us that's going to be most activated. And it's not that technology is
an existential threat. It's the worst of society is an existential threat. And technology is
activating the worst of society. So I wanted to give one really concrete example
of the way that these sort of narrow AIs cause a kind of global psychosis where we cannot hear
each other or even believe that we're coming in good faith. And it sort of works like this.
It's like a trauma inflation. So let's say you have something that you're particularly sensitive
to, let's say it's Asian American hate. You're scrolling on Twitter, you see an example of the
video of Asian American hate. And of course, that activates you that activates your trauma.
And so you click on it. And because you've clicked on it, it's very activating for you.
Your feed starts to become the very worst thing you've ever clicked on, you start getting shown
more and more first person examples of videos of Asian American hate.
So you now know, your trauma is inflating, this thing is happening everywhere. Why can't
other people see it? On the other side, you might have someone who is, their trauma is hit when they
see say protesters throwing things or beating police, like inflicting violence against police.
And so they click on that because there are certain examples of that out there. They see a
first person video, their feed starts getting filled with the worst thing they've ever clicked on.
And now they have a never ending infinite feed of videos of protesters beating police.
So everyone has their own little nightmares expanded on Facebook as a,
if those things are all happening as 1% of our reality that each of us think that it's 20% of
our reality, whatever we're most triggered by. And so we all have a different sense of what's
really going on. All those things are happening, but at a lower percentage than our perception
from using social media. Yeah, that's exactly right. It's like a fisheye lens and things are
distorted. So it's really happening, but you're getting a incorrect view, a non representative
view of what's happening in the world. And now when I come to talk to you, I know what I've seen.
I have seen these first person perspectives. And so if you tell me that's not an issue,
I know that you're disconnected from reality. You're not really seeing the real world, or maybe
you're just coming in bad faith. And you know the exact same thing from me. And so you can see
how we now cannot come together. We disagree. We both say the other person is not based in
reality. If you're not based on reality, how can we even have a conversation in the first place?
And that's happening along every division at scale with that $500 billion market cap AI, finding,
you know, as Tristan likes to say, finding the fault lines of society and then fracking them for profit.
