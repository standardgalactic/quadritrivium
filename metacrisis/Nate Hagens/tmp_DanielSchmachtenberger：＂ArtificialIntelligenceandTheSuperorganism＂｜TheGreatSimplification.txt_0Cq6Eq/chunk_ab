Tibet and it was kind of the end of Tibetan culture as it had been uh was that because
Tibet was a less good culture meaning it provided less fulfilling life for all of its people than
china and nature was selecting for the truly good thing for the people or the world or like no we
can see that whether we're talking about Genghis Khan's intersection with all of the people he
intersected with or alexander the greats or whatever that but that was worrying yes yes
that those who innovated in the technology of warfare the technology of extraction the technology
of surplus the technology of growing populations coordinating them and being able to use those
growing coordinated populations to continue to advance that thing relative to others there were
cultures that might have lived in more population sustainability with their environment maybe more
long-term harmony maybe said let's make all our decisions factoring seven generations ahead and
they were just going to lose in war every time and so um the naive techno negative direction
just chooses to not actually influence the future right is going to say i'm going to choose something
because it seems more intrinsically right even if it guarantees we actually have no capacity for
enactment of that for the world and that's why i'm calling it naive i don't i don't understand that
if that last thing could you give an example yeah if someone says i think a particular advancement
of i think advancement of tech in general focuses on the upsides that are easy to measure because
we intended it for that purpose doesn't focus on all the long-term second third fourth order
downsides that are going to happen i don't want to do that we want to have a much slower process
that fact that pays attention to those downsides only incorporates the things with the right
use and guidance and incentives it will lose in a war it will lose in an economic growth to
the other cultures that do the other thing if you want to take a classic example and go back
to um and it didn't happen exactly this way anywhere because it happened in such a different
ways in the fertile crescent and in india and whatever but but as a kind of thought experiment
illustration the plow emerges animal husbandry for being able to use the plow now we have to
domesticate a bowl turn it into a or a buffalo turn it into an oxen and um and that involves all
the things it does it involves castrating it it involves having a whip and you stand behind it to
get it to pull you know the plow for row cropping whatever so certain animistic cultures were like
i don't want to do this we'll hunt a buffalo but we also will protect the baby buffalos we'll make
sure that our body goes into the ground to become grass for the future ones we're part of a circle
of life we believe in the spirit of the buffalo i can't believe in the spirit of the buffalo and
beat one all day long and do things to it where i wouldn't want to trade places with it but the
culture that says now we're not going to do that thing is not going to get huge caloric surplus
it's not going to grow its population as much it's not going to make it through the um hard
weather times as well and so when the new technology emerges those who use it if the technology
converse confers competitive advantage it becomes obligate because whoever doesn't use it
or use at least some comparable technologies loses when you get into rivalrous interactions
let me take a brief uh rabbit hole side side step here um but while it's fresh in my mind
i think this dynamic that you're talking about now and i know we're going to get to artificial
intelligence um but in my public discussions people are recognizing the validity of the systemic
risk that that i'm discussing and that we're headed for at least potentially a great simplification
simplification is the downslope of a century plus of intensive complexification based on energy
but those communities and you could talk about countries that simplify first because it's the
right long-term thing to do in the meantime they're going to be out competed by communities that don't
because those communities will have more access to government stimulus and money and technology
and other things but it almost becomes a tortoise in the hare sort of story uh had a podcast a few
weeks ago with um Antonio Turiel from spain and he said europe is in much worse shape than the
united states because the united states has 90 of its own energy so europe is going to face this
simplification simplification worse first in a worse way so the united states has another decade
so you guys are off the hook and i was thinking to myself really because yes the united states
is mostly energy independent but europe will be forced to make these changes first and maybe
they will have some learnings and adaptations that will serve them in the longer run when
we just ride high in the superorganism for a while longer i mean that's that's really a
complicated speculation but what do you think about all that is that relevant or
well this so this is why we talk about the
the
need to be able to make agreements that get out of the race to the bottom type dynamics the
multipolar trap the social trap because of course if anybody starts to cost resources properly
price resources properly meaning pay for what it would cost to produce that thing renewably
via recycling and whatever it is and not produce pollution in the environment through
known existing technology they would price themselves out of the market completely relative
to anyone else not doing that so either everybody has to or nobody can right and whether we're
talking about pricing carbon or pricing copper or pricing anything as as you say well we price
things at the cost of extraction plus a tiny margin defined by competition and that was not
what it cost the earth to produce those things or the cost to the ecosystem and other people of
doing it so the proper pricing at pricing is really very deep to the topic of perverse incentive
and yet if we talked about how do we ensure that in our and this is core to the progress
narrative right because the thing that we're advancing that drives the revenue or the or the
profit is the progress thing the cost to the environment of that we're extracting something
unrenewably that is going to cap out that we're turning into pollution and waste on the other
side and we're doing it for differential advantage of some people over other people and affecting
other species in the process if you were to the stakeholders that benefit you get a progress
narrative the stakeholders that don't benefit you you get a non-progress narrative but until
industrial tech like it's important to get that before industrial tech we did extinct species
right we over hunted species in an area and extincted them we did over we did cut down all
of the trees and cause desertification that then changed local ecosystems led to flooding ruin the
topsoil we did over farm areas so environmental destruction causing the end of civilizations
as a thousands of year old story but it could only be just now global so until we had industrial
tech we could not actually we just weren't powerful enough to mess up the entire biosphere
so how powerful we are is proportional to our tech because we can see that a polar bear cannot
mess up the entire biosphere no matter how powerful it is corporeally right the thing that can mess up
the entire biosphere is our massive supply chain technologically mediated things starting with
industrial tech and so given that we are for the first time ever running up on the end of the
planetary boundaries because we figured out how to extract stuff from the environment much faster
than it could reproduce and turn it into pollution and waste much faster than it could be processed
and we're hitting planetary boundaries on both sides of that on almost every on almost every
type of thing you can think about right in terms of biodiversity in terms of trees in terms of fish
in terms of pollinators in terms of energy in terms of physical materials in terms of the chemical
pollution planetary boundary so the things that are getting worse are getting very near tipping
points that were never true before those tipping points will make it through the things that are
getting bad better won't matter even for the stakeholders they're intended and that's a key
change to the story is it can no longer be that the winners can win at the expense of everybody
else it is that we are actually winning at the expense of the life support systems of the planet
writ large and when that cascade starts obviously you can't keep winning that way which is optimize
narrow goals at the expense of very wide values you've you've described the naive progress optimist
and the naive oh yes progress pessimist is there such a thing as a progress realist yes
yes so i am a techno optimist meaning there are things that i feel hopeful about that require
figuring out new ways to do things new technique both social tech and physical tech but i'm cognizant
that the market versions of that tech are usually not the best versions the because of the incentive
the because of the incentive landscape in the same way that if facebook hadn't had an ad model
it would have been a totally different thing right if we're just talking about the technology
of being able to do mini to mini communication but you had something that was not a market force
driving it could you have had something that was much better that was not trying to turn people
into a commodity for advertisers which means behaviorally nudge them in ways that manufacture
demand and drive the emotions that manufacture demand maximize engagement x which causes the
externality of every young person having body dysmorphia and ubiquitous loneliness and
confusion about base reality and polarization could we have done it where rather than drive
engagement the goal was to actually look at metrics of cognitive and psychological development
and interconnectedness across ideologic divides and do that thing yeah of course right so the
same technology can be applied to wider goals rather than more narrow goals and you get a very
different thing so the base technique it's the technology and the motivational landscape that
develops its application space we have to think about together so there is a there there are
ways that we can repurpose existing technologies and develop new ones both social and physical
technologies that can solve a lot of problems but it does require us getting this narrow
goal definition versus wide goal definition and the if intelligence guiding technology
is as powerful as it is and actually exponentially powerful what and we're defining
intelligence here as the ability to achieve goals what is it that defines what good enough goals
are that being able to optimize them exponentially is not destructive
that's how you would get a progress narrative that is post naive and post cynical
in contrast i'm probably a techno pessimist or at least a mild one because i see how technology
is acted as a vector for more energy and more climate co2 and and degradation of nature at
the same time i think it's how we choose what technology we use like a golden retriever is
probably the best technological invention ever of our species even though it's really more of a
co-evolution but you know what i mean it's it's something that that we came about and and sexually
selected and for companionship and they don't they give us the complete suite of evolutionary
neurotransmitters for not a lot of resource input and there's lots of other technologies
that are appropriate that help us make meet basic needs and give us well-being that don't
destroy the biosphere but this gets back to i don't think individuals wait wait this is
let's just important yeah okay the superorganism thesis that you put forward
shows that the superorganism is oriented on a path that does kill a toast and thus itself
right it does destroy the space reality the substrate that it depends on
the metacrisis narrative that i put forward says a similar thing is why we did this whole five
series to kind of show the relationships and so i would say as long as the axioms of that thing
are still in place yes i am a technopessimist meaning i think that the good things that come from the
new tech don't outweigh the fact that the new tech is in general more often than not accelerating
movement towards catastrophic outcomes factoring the totality of its effects so but this is why i said
there is a post naive and post cynical version in which i'm a techno optimist but it requires
not being on that trajectory anymore it requires that the technology is not being built by the
superorganism in service of itself but is being built by something different in service of something
different well in that way i'm also a techno optimist because after growth ends and after
superorganism is no longer in control efficiency will no longer be a vector for jevons paradox
because then efficiency is going to save our vegetarian bacon because as things as the economy
is shrinking efficiency is going to be really important and and innovation just right now it's
feeding more energy and stuff into the hungry maw or the people who haven't heard the previous
stuff on jevons paradox will you do that briefly why efficiency because obviously ai can cause
radical efficiencies which can help the environment that's part of the story of why it's an environmental
hope so would you explain why as long as jevons paradox is the case yeah so humans get smarter
on how we use energy around 1.1 percent a year so we get more energy efficient every year
um because we're smarter coal plants use less coal to generate the same amount of electricity
we invent solar panels um our our televisions are a little bit more energy efficient in our
laundry machines and one would think on the surface that that would allow us to use less energy
but what ends up happening is that money money savings get spent on other things that use energy
and writ large new innovation ends up system-wide requiring a lot more energy since 1990 we've had
a 36 percent increase in energy efficiency at over the same time we have a 63 percent increase
in energy use so as long as growth is our goal and our cultural aspiration is profits and GDP
more energy efficiency will paradoxically unfortunately result in more energy and environmental
damage that's called jevons paradox it was based after a 19th century economist who
observed this walter stanley jevons who uh observed this in steam engines that steam engines wouldn't
reduce our energy use but they would scale because they helped everyone and and were so useful so
let's talk about first versus second third and the order effects here because jevons paradox is um
it's important to understand that we make a new technological daniel what are what are the um what
are the odds that we actually don't get to artificial intelligence on this conversation uh low
okay keep going first second third order go for it so if we create a new technology that
creates more energy efficiency on something whether it's a steam engine or a more energy
efficient energy generation or transportation or storage technology the first order effect of it is
we use less energy the second order effect is now that it takes less now that we have more available
energy and energy costs less there's a bunch of areas where there was not positive energy return
profit return that now become profitable and so now we open up a whole bunch of new industries and
use more total energy but it's a second order effect or even a third order effect because it
makes some other technology possible that does that this is one of the asymmetries that we have to
focus on in the progress narrative is the progress narrative is and technology in general when we
make a new technology and by technology i mean a physical technology or even say a law or a business
to achieve a goal where we're generally making something that is trying to have a first order
effect on a narrow goal that is definable in a finite number of metrics for a small set of
stakeholders the stakeholders are called the total addressable market of that thing
and very rarely is the total addressable market everything right and so
we're making things whatever it is so i'm using technology in the broadest sense of human innovations
towards goal achievement here we're making technologies to achieve first order effects
meaning direct effects for a defined goal for a defined population even if we're talking about a
non-profit trying to do something for coral it's still focused on coral and not the amazon and
everything else right and so it can optimize that at the expense of something else throughout
in terms of the second third order effects of whatever putting that thing through does
and so we put out a communication to appeal to people to do a thing politically well it appeals
to some people it really disappears to other people one of the second order effects is you
just drove a counter response the counter response is people who think that the thing you're benefiting
harms something they care about and now you just up-regulated that is that being factored
and so the progress narrative the technology narrative and all the way down to the science
narrative and this is where we get to the human intelligence versus wisdom and then how this
relates to artificial intelligence is it is easier to think about a problem this way here's a
definable problem it affects these people or these beings it is definable in these metrics we can
measure the result of this and we can produce a direct effect to achieve it we did we got progress
awesome and the progress was more GDP the progress was people who could communicate faster the progress
was less dead people in the ER the progress was less starving people the progress was whatever the
thing was that we were focused on even if it seems to be a virtuous goal but that same thing that you
did maybe polarized some people who are now going to do other stuff that is a second order and maybe
third order effect maybe it had an effect on supply chains maybe it had a so the second third
and third order effects on a very wide number of metrics that you don't even know what they are to
measure on a very wide number of stakeholders that you don't even know how to factor is harder
in kind to think about so it is it is logically cognitively easier as we talk about intelligence
to figure out how to achieve a goal than it is to make sure that goal doesn't fuck other stuff up
so efficiency too has a narrow boundary and a wide boundary lens with which to be viewed
