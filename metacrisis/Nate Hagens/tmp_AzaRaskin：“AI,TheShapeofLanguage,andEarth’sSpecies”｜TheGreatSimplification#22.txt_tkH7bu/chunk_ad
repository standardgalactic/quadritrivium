But I think to a lot of people, this actually may be a welcome next step from Netflix and
the Oculus Rift. And if I have a synthetic human who is kind of built via AI to conform to my
emotional needs, what's not to like about that? It might be hugely popular, yes?
I think it will be incredibly popular. And Daniel Smoktenberger has this really incredible point
that in a world of hyponormal stimuli, that is in a world where we've already replaced real
connection with the sort of brittle synthetic connection we get when we interact with humans
on our phones, when you are feeling understimulated, then your hyponormal stimuli
are a lot more powerful. That is if you live in a world of crappy food, then really sugary food
is going to taste even better than if you lived in a world of really nutritious, great food.
So this could be a culture-wide coping mechanism to the end of growth and the great simplification
in my terms that's ahead of us. I think so. And I'll just add as another part of the coping mechanism.
What happens when the human mind encounters like entities or systems that have a complexity,
you know, at its scale or bigger that it can't understand? Well, it like the human mind turns
towards religion or spirituality or mysticism to explain that which it can't explain. China,
as of this year, made the first model, like massive model, that I think had 178 trillion
parameters, which is for the first time the same order of magnitude, trillion, that's the same
number as a number of synapses of the human brain. So we are crossing these fundamental
thresholds. And so we are going to encounter more and more things in our reality that we
have trouble understanding. In some sense, I think we've hit peak understanding because
previously, we've understood more and more of the complex systems in our world, even as we've
built more and more complex systems, but now there are more complex systems that we're generating
than we're understanding. So expect to see a massive shift in the next 20 years
to increasing spirituality and religious. I expect that anyways, because of the stuff that
I work on. But I just wonder, Aza, and, you know, I know we're going to get to some of the positive
possibilities from AI, but I just wonder if society is going to bifurcate in such a way that
once this is understood, maybe this gets back to your, we have to hit rock bottom
before we find our way. I wonder if 10%, 20%, 30% of society will just say no mass and give up
all this technology, despite what it offers us in the sugary sweet distraction and release.
And if those people aren't the ones that maintain the semblance of human sanity and
true north compass of humanity, I don't know, I'm just musing, but all of your last half hour
makes me not want to use this much if at all. And yet, and yet I am in my attempt to change
other people's hearts and minds about the future, I'm compelled to use these resources. And I've
actually been using them more than I ever have because I'm trying to get people to watch my
videos and listen to podcasts, etc. But do you have any thoughts on what I just said?
I mean, I think you've articulated what's so inhumane, which is that we are forced to use
systems for the things that we need that are fundamentally unsafe.
The beautiful hope, right, is that we could be living through the golden era of humanity,
where we use these tools, you know, to increase our ability to perceive because our ability to
understand is limited by our ability to perceive. And then to really understand what it is to be
human, like, let's understand our ergonomics, understand our cognetics, like how our bodies
bend or fold, how our minds bend or unfold, you know, the way you could sum up, like the
interdependent and escalating cascading catastrophes that are about to hit us,
is that we, as a society, our collective power using our technology is being,
is outpacing our collective wisdom to wield that power. This is that Ia Wilson quote, we have
paleolithic motions, medieval institutions, and godlike technology. And so, but another way of
saying it is, we could understand sort of the ergonomics, like how collective intelligences,
intelligences bend and fold, we could have a field of collective intelligence interaction design,
so that we could match the wisdom that we wield collectively with the power that we wield collectively.
That is within reach. It's just on the other side of a set of perverse incentives and systems.
Another way of saying it, you know, in sort of your language is that if you could give the
Super Amoeba a mirror that it could look at itself in, not at the individual human level,
but at the Super Amoeba level, so it could understand what its attributes are, what it's good at,
what it's bad at, and we started designing at the Super Amoeba level, well, the Super Amoeba
doesn't want to kill itself if it became aware of itself. That's the kind of thing that we could
be working on if we could get to the other side of this sort of like perverse incentives valley.
Yeah, that's fascinating. So, before we get to Earth Species Project, are there any other
really exciting positive possibilities from AI that you can envision or are aware of?
And we've talked a lot about the risks. Are there any really cool positive things that
you can think of? Well, I mean, starting at the simple level, the ability to create art that
really speaks to you and the people around you, that I think is wonderful. The ability to
be in dialogue with the system so you can start visualizing the things that you're thinking about,
seeing them and reacting. I think of our jobs as communicators is there's a big sphere of
things that we can think about, and outside of that are things that are unthinkable,
and then inside of the thinkable sphere, there are things that are imaginable that we can visualize,
that we can touch and taste, and it's our job as communicators to run across the line
from the thinkable to the unthinkable, grab an idea and bring it back. That's what metaphor does.
And then to go from the thinkable into the tangible, touchable, feelable.
Because once it's tangible, touchable, feelable, it's a thing you can share and we can work on
together. We have a phrase that Tristan and I share, which is that it's not just enough to
make the invisible visible. You have to make the invisible visceral, like feelable. AI,
these tools are going to increase the frame rate at which we can think about something
and then visualize it, which means it's going to decrease the time between you can start to
think about something and make it happen in the world. So that's exciting.
Then my friend Jeremy Howard, who started Fast AI and Kaggle, started doing research on
like, essentially, all of the geniuses like the Einstein's and the Von Neumann's and people
like that. And the question that he was asking is like, what's the same across all of them?
And a lot of the best thinkers in the past 500 years or more all shared the property.
This is his research and not mine. So I might be butchering it a little bit, but the overall
contours are right. They all had tutors, people that were specialized, sitting with them,
teaching them to whatever the current developmental stage was, bring them to their
adjacent possible. And he told me some stat, and again, I'm not going to get exactly right, but
having a tutor for your child puts them in the 98th percentile of kids.
What I think is interesting about this is, of course, you impossible to get tutors for everyone,
but this is an area that AI can excel at. Imagine you're transferred of an Einstein bot
or Von Neumann bot based on all of their work, plus great pedagogy. Now,
any child or any human, me included, can have a kind of tutor that understands like where I am,
ask the right questions and give me the right problems to get me to my adjacent possible. And
that gets us closer to this idea of a agent that sits alongside of me that can help me in the
journey of Bildung, of lifelong human development. And I think that is all really exciting if it
doesn't get captured by perverse incentives. Yes, agreed. And one final question on this,
you have followed along a little bit with my story about resource depletion and growth and
the fact that we're doubling our debt every eight or nine years, and we're doubling our GDP,
which is the income stream to support the debt every 25 years. And that is a problem. And that's
before oil starts to decline in this maximum production. How energy intensive is AI? And
even if we do have a 20 to 30% drop in the size of the global energy availability,
is that plenty to scale some of the initiatives that you've been talking about?
Well, Nate, I just wanted to say thank you to you because it was
your work that really opened me up to realizing how energy and material blind my worldview has been.
And honestly, I'm still integrating all of your lessons into my own thoughts.
These things are, of course, very energy intensive, although not nearly as energy
intensive as Web3 Crypto World. But there is a lot of work now going into
making these large models more energy efficient. I am not up to speed on all the latest numbers,
so I'm not the best person right now to talk about, which honestly speaks exactly to your point that
even as I'm thinking about these systems, I'm still operating from a place of energy blindness.
But if someone's going to use Dolly or GPT-3 or in the future, my personal
artificial or synthetic human as my friend, where does the energy reside on a server somewhere or in
my house because it's attached to my phone or some centralized location? Where does the energy
come from? I would assume it's similar to the way we use the internet now or what?
Yeah, that's exactly right. So the bulk of the energy use is in training these models,
so that is collecting an internet's worth of data, taking tens of billions to now trillions of
parameters and teaching them how to make good predictions. Once you have one, it's actually
much cheaper to ask them to make an inference to make a guess. Often you can now take these models
and download them, say to your local computer or to your phone and smaller versions and have
the calculations happen locally. A lot of work is going into making neural net computations happen
directly on chip, so it's not even happening in software. So you'll see these things becoming
lightweight enough to be not just in Apple Watches, but on little backpacks that you put onto
animals to measure their audio, what they're saying and how they're moving.
Okay, thank you for that excellent, wide-ranging introduction to your current project and one
that I am fully in support of and I find fascinating, which is the Earth Species Project,
one of the many hats you wear. And so now if you could go back to your example of Japanese
and German mapping and let me know what you're working on and what your hopes are and what's
going on with the Earth Species Project. Yeah, and just before I dive into the full Earth Species,
I wanted to finish a final punchline with Dali and how that works because we've now talked about
how you can take languages and turn them into shapes, match them together to do translations,
but how Dali works is actually very similar. You build the shape for images, you build the shape
for language, you then run over the internet and you look at images and captions and you say,
okay, this point in image space goes to this point in language space and you do that again and
again and again. It's not a rotation, but you're finding a way of mapping, of aligning the shapes
of images and the shapes of language. And from here, you just say whatever you want,
portrait of Chile as a person. That goes into a point in language space, which then gets converted
to the point in image space and you ask the computer, make the image that represents this
point and it does. That's how the technology works. And why I find this so profound is it's
not just that you can map one language to another, it's that you can even do translation
across modalities because what is translation? Translation is a transformation that leaves
meaning the same. And why this is so important is, you know, just to give an example from
sperm whale, a number of, I should say, some scientists, this is definitely not the consensus
view. I just like to think about it because it broadens, it expands the aperture of when we say
language, what could we possibly mean for non-humans that when sperm whale, you know,
they have these incredibly powerful clicks, so powerful that if they want to, they could just
shake your body to death. But when they click and then they do echolocation on you, they get back
a full 3D model of you, right? They see where your bones are, they see how much you've eaten,
they see where your organs are, that maybe when they speak, they are speaking not as sort of
representational language, but they're just beaming back and forth sort of 3D sound holograms,
just images. They see an orca, they beam the orca to the other, the sperm whale, and so it's
important because the punchline of you can take English and Japanese and Esperanto and finish
and Urdu and Aramaic and fit them into one universal meaning shape is that as we gain the
ability to build these shapes for animal communication, you can see which parts overlap.
Does say sperm whale or beluga or raven or orangutan do, does that, does the shape of
their communication fit anywhere into the universal human meaning shape? And if it does, we can get
direct translation to the human experience and we'd expect some part to do that because animals,
they share grief, like pilot whales will carry around their dead young and push them up to
the surface for weeks. There are five species that go through menopause, one human, four whale,
narwhal, pilot whale, orca, and beluga. All of those species like the have culture that gets
passed down. They have dialects. Grandmothers are the culture holders. So if you have a really
knowledgeable grandmother, their grand offspring survive more. So we have that kind of family
structure like apes, if you show them magic tricks, they will show joy and incredularity when you
make a ball disappear, when they didn't realize it. So we share that. There is a lot. Actually,
lemurs will take centipedes and bite on them to get high. And they go through this whole
trance like crazy thing. It's incredible to watch as Google like lemurs getting high.
Dolphins will inflate puffer fish and pass them around to get high.
Oh, my God.
It's like the ultimate puff puff pass. And let's see. There's one more. Oh, and of course,
like you put like dolphins in front of a mirror and you paint a white dot on them,
they will look into the mirror and see the dot, which they hadn't seen before. And they'll try to
like rub it or get it off. They'll look inside of their own mouths. Magpies do the same thing.
Elfins pass. So they have a rich interiority, a self-awareness. You have to look in a mirror
and understand that that thing I'm looking at is me in order to pass the mirror test.
So there's a lot that's the same. So we should expect part of that shape to overlap.
And of course, part of that shape is like their world is just so different than us. Dolphins can
speak to two different animals at the same time. They can bifurcate their communication stream.
That's something we cannot do. We expect some part to not overlap.
So it would be like I was talking to you right now, but also talking to my
program manager and talking about our project and doing both simultaneously.
Yeah. Well, to be very specific, what is known is that they can bifurcate their stream and hit
two different targets at the same time. It is unknown whether they're using that as a full
communication channel for both streams. So I have a ton of questions. This is a naive hypothesis,
wouldn't? So you said that Japanese maps to German maps to Aramaic, etc.
And your project is to try and understand what these other languages in non-humans
look like. First of all, and then how do they relate to human languages?
And ultimately, I think your goal and one of the reasons that I'm keen to help you
is wouldn't that be a change in consciousness for our culture if people started to recognize
deeply, emotionally, that we share this planet with 10 million other species? Many of them
are self-aware, conscious, and have rich vocabularies and languages and daily interactions the same
way we do. So then we extend the boundary of our empathy to other humans. That's a long shot,
but that is the shot that we have to take in the coming century, in my opinion.
So Godspeed to you on that. But my question is, wouldn't it make sense that from an evolutionary
standpoint, the nearer in time historically that we diverged from our nieces, nephews,
and cousins in nature, the closer our language would be. In other words, the other great apes,
Bonobos, Gorillas, chimps would map the closest relative to dolphins and cetaceans,
which is what, 70 million years ago, the split or something like that of a common ancestor.
Do you have any hypothesis or information on that, or what do you think?
I think you're likely correct that the closeness of communication between primates and humans,
like we share an Umveld more closely than we do with say whales. So there are communication,
it seems like a good hypothesis. An Umveld is like your worldview, like how you experience
your world through your sensory apparatus. And that's obviously very different for say a bat
than a human, because a bat is mostly seeing, especially at night, in echolocation and sound
imprints. And dogs, like a major portion of their Umveld is via smells, how they relate to the world.
And so our different ways of relating to the world means we're going to have different
representations, which means we're going to communicate about it differently.
And yet this is why I started with that example from sperm whales communicating maybe
