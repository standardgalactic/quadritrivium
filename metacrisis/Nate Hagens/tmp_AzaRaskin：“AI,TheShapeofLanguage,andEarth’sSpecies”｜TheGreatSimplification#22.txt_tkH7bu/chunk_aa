Greetings, humans around the world tuning in to this show.
As frequent listeners know, I believe we live as part of a system, and we have to understand
how the parts and the processes of the system fit together in order to understand the roadmap
and what to do ahead.
I understand a lot about ecology, energy, human behavior, but there are quite a few
topics that I know very little about, and there's probably a lot of topics I don't
even know that I don't know about.
But one topic increasingly relevant in our lives is machine intelligence and artificial
intelligence, AI.
It does seem that AI and big data are a poise to play a much bigger role in our lives.
With us to unpack this today, we're fortunate to have a pretty special human being and
one I consider a good friend, Asa Raskin.
Asa is the son of Jeff Raskin, the developer of the Macintosh computer.
Asa is the co-founder of the Center for Humane Technology and also the co-founder of the Earth
Species Project.
Today Asa is going to give us a general overview of what artificial intelligence is, how it
is about to become much more embedded in our lives, and specifically how he and his team
plan to use AI as a sort of a Rosetta stone to translate the languages of other species
to perhaps hopefully expand human consciousness, empathy, and awareness of the 10 million other
species we share this planet with.
Thank you all for joining me on this journey of learning and informing what's possible.
I present Asa Raskin.
Jumbo, how are you Asa, how are you?
Hey Nate, I am doing fantastically, how are you?
I am good.
Spring is finally here.
I've never spoken Swahili to you, but you mentioned to me when we were last together
that you spent time with the Pygmies, I believe in Congo, so you probably do speak a little
bit Swahili.
Well, but mind you, so I did spend a little time with the Bayaka tribes when I was in
the Congo rainforest studying forest elephants.
Most people speak French, but there is a trade language whose name I don't remember
that the Bayaka speak, but they have their own language, very independent from Swahili,
and interestingly enough, a lot of their culture centers around music.
So I was sort of surprised discovered when they are flirting their song for that.
There was a moment that we were driving in a truck, there are only three in that area
the Congo, as we passed this group of Bayaka, all 17 of them piled into the back with me
and as soon as we started moving, they started singing, which eventually I joined in with
a poor rendition, but it's very polyrhythmic, polyphonic, and they kept singing all the
up until the time they jumped out of the car.
So it's not just language, it's the full spectrum of human experience that they communicate
with.
And meanwhile, in the developed United States and inner cities, we have replaced all of
our tribal tapestry of rich human experiences with monetary markers and technology, and
oh, to just sing and experience nature like that.
I mean, there is a certain part of me that really longs for that, and it makes me happy
to hear your stories as the same one when you were chased by an elephant.
That's a different sort of experience.
All right, my friend, so you are a colorful human being, and so I've worn a colorful
shirt for our conversation today.
There's a lot that I would like to unpack.
What I really want to get to is your work, your new initiative called the Earth Species
Project, which is applying artificial intelligence to understand the language of other species,
but before we get there, we have a winding road.
For people who don't know you, maybe you could explain why there is a daily activity in most
people's lives that you were responsible for and your current feelings about that.
This fits into the camp of you will always be defined by the one worst thing that you
ever did.
If you cast your minds back 2006, this was an era when MapQuest was just ending where
you click a little button to move to see the next part of the map.
Google Maps had come out, you could start to scroll around, and I was working on a lot
of technologies back then.
This was just before I joined Help Found Mozilla Labs at a geolocation to the web, did a lot
of the very first prototypes for what a browser on mobile would even look like.
One of the things I was thinking about was, well, why are there those little buttons at
the bottom of search pages that say more?
Why do I have to click on them?
Isn't there already a meaning to scrolling, which means I have yet to find the thing I'm
looking for?
I had this very simple idea of using, at that point, a very new technology, something called
AJAX, to let you load new content without refreshing a web page, to as you scrolled
and got to the bottom of a page, it just automatically loaded more content.
That was the invention of the infinite scroll.
I think interesting about that is that as a designer, I was doing my job, I think, very
well.
Every time as a designer, you ask the user to do something they do not care about, make
a decision they don't need to think about, you have failed.
It made perfect sense to remove that stopping cue, to say, if you're scrolling, just keep
loading more.
What I didn't realize as I went around to Google and Twitter and talked to them about
this great new better interface is that me optimizing for an individual user might be
breaking something at the collective level.
That is, I did the calculation a couple of years ago when somebody challenged me to how
many hours does that one invention waste, and it's very conservatively over a million
human lifetimes per day, that it's convincing people to scroll more.
I think this is, to me, a really important waking up realization that if you don't understand
the context into which something you invent is going to be used, then whatever perverse
incentives of that larger system are, are going to co-opt that good intention of the
thing you create.
That applies to so many things.
That's a microcosm for a lot of aspects of our current world and our aspirations.
While you were telling that story, it made me think, not only does it waste in air quotes
a million human lifetimes, but what about non-human lifetimes?
Depending on the boundaries, 15 to 20% of our total electricity in the world is linked
to device use and the servers and the technology that underpins it all.
Extra time online and scrolling ends up being more coal-fired servers around the planet
which have interspecies intergenerational impacts as well.
That's also making me think about the large-scale effects, as you said, intergenerational of
technology is, well, how have civilizations succeeded?
How do they work?
You have to have additive cumulative cultural knowledge transfer.
Unless, you know, via language, you can communicate what you've learned to the next generation,
civilizations quite literally do not exist.
What is technology doing?
It's sort of taking scissors and it's cutting the transmission lines from one generation
to the next because it source everyone into their own generation.
That very thing that lets civilization continue is the thing that our current round of technology
is snipping.
That's, I hadn't thought about that that way.
Okay, so let's transition into the current zeitgeist of advanced technology, which is
artificial intelligence.
To be blunt, as you know from my work that we've discussed, I know a lot about energy
and systems ecology and climate.
I don't know a lot about artificial intelligence.
I would guess 80% of what I know I've learned from you.
So let's unpack this a little bit.
I think a lot of people watch Hollywood movies like Deus Ex Machina and Terminator and things
like that, but could you explain what is AI, artificial intelligence, what is it?
Let's just start there.
So it turns out that AI is not terribly complex.
It's massively parallel matrix multiplication that does smart trial and error.
Even if you don't understand the massively parallel matrix multiplication part of that
sentence, the thing to hold in your mind is that the computer is doing billions to trillions
of calculations to do smart trial and error to figure out what works and what doesn't.
Another way of thinking about it for people who have a little bit more of a math background
is these techniques have a property called universality, meaning that no matter what
function you draw, these algorithms can approximate them.
So what does that mean?
That means no matter what shape you draw, the computer can recreate that shape.
And I think I don't want to go from here.
That's sort of a very theoretical way of saying it.
Often the way this works in practice is you're asking the computer to do something like fill
in the blanks or predict the things that comes next.
Almost all of the major advances that you hear about, whether it's GPT-3 and these language
models that, as of a couple months ago, can now generate text that can pass the Harvard
essay entrance exams, that those are all trained by saying, look, read over the entirety of the
internet and see if you can predict the word that comes next or if I give you a sentence,
if I drop out a couple of the words, that you can predict the words that were there.
And to do that, the computer has to do a whole bunch of things.
It has to begin to understand grammar.
It has to begin to understand syntax, what word comes after another.
If you have a word like ice, you should expect that the word ice will appear next to the word
cold more often than ice will appear next to the word fashion.
So you're starting to get hints about meaning in the co-occurrence of words.
And because the computers are able to do trillions of trial and errors to be able to fit the shape
of what language looks like, eventually it learns how to approximate English very, very well.
So why didn't this happen?
That made sense what you just said.
It's kind of common sense that we would ask eventually computers to accomplish this.
Why didn't this happen 10 or 20 years ago?
What was the limiter?
Quite simply, it was compute.
It was the ability to do it fast enough.
There have been very few major theoretical breakthroughs.
There have been ideas like attention networks.
Let me say that again.
There are ideas like attention and attention heads so that the AI can know what in a signal
is important to pay attention to.
But the big change was the rise of one GPUs developed for gaming that let you do
these matrix multiplications very efficiently.
And two, it was the rise of bigger standardized data sets, the most common being or the most
famous being ImageNet created originally by Fei-Fei Li, which created the benchmark by which
or the yardstick by which everyone was measuring themselves.
So big data sets because as Peter Norvig says, data ends up being 10 times smarter than algorithms.
The more data you have, the better you can fit it, the better your predictions.
And cheap compute, those were the changes.
Okay, so what is the current state of artificial intelligence in 2022?
And how does it work?
Kind of break that down for us.
I think it's instructive to walk through a 2017 breakthrough, which was the starting
mark for why we said now is the time to start working on translating non-human languages.
Because walking through this example, I think we'll give the audience, everyone listening,
the conceptual tools to start to reason and think about AI on your own, which I think is exciting.
So here was the insight.
We've already been talking about how you can model language.
But I want to go a little deeper.
One of the things you can ask the computer to do is build a shape that represents language.
And this shape is special.
So imagine in your head a galaxy where every star is a word.
And words that mean similar things are near each other.
And then words that share semantic relationships become and turn into geometric relationships.
So an example, king is to man as woman is to queen.
Common analogy, which means that the relationship between queen, king, and man
is sort of the same as the relationship between woman and queen.
So because you're in a shape, that semantic relationship becomes a geometric relationship.
So there's a distance and direction from king to man.
And if you sort of imagine that as a vector and you add that vector to woman, it'll equal queen.
If you add that vector to boy, it'll equal prince.
When you say vector, you mean a small binary computer language representation of that concept?
Yeah, but I think you could certainly represent it that way.
But I like to think of it geometrically.
So what is a vector?
A vector is just an arrow with a direction and a distance.
Like I'd say you go this far in this direction.
So if you start at man and you walk so far in such a direction, you'll end up at king.
If you start now at girl and you walk the same distance and direction,
you're going to end up at the point, which is princess.
So was that in 2017?
Was that using the English language?
Yeah, well, actually, what I'm talking about right now is still back in 2013,
