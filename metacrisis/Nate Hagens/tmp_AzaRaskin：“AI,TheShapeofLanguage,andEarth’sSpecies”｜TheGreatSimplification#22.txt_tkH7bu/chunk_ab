the ability to build these shapes was an invention called Word2Vec.
You could do it efficiently.
And it was you could take language and create a shape that encodes all of the semantic relationships.
And the first thing I tried when I got my hands on this data set was like,
okay, hipster minus authenticity plus conservative.
And that just equaled electability.
Computer, you're not allowed to write better jokes than I can.
But you know, this is a very general tool.
So you can do like smelly minus malodorous.
And malodorous is sort of the pretentious way, if you will, of saying smelly.
You add that to book an illegal tome.
You add that to clever and illegal adroit.
And when you say when you add that, that means the human interfacing with the computer
would put that in the prompt or the text or the voice or something like that.
Correct. You say, okay, there is a point which is smelly and a point which is malodorous.
You sort of look at the distance and direction between them.
And once you have that relationship, which is pretentiousness as a distance and direction,
you just add that to any other word and you get the pretentious version of the word.
Because that semantic relationship of pretentiousness became a geometric relationship.
In English or across all languages.
And this works across every language.
And where we're going to get to, and it's sort of the mic drop,
is that it's not even just language that this works for.
This works for every modality.
And that's the sort of the eye opening, mind opening realization
is that deep learning AI sort of has this one weird trick.
And the one weird trick is it can turn whatever data set into points in space,
where those points in space turn semantic relationships into geometric relationships.
So let's think about faces for a second.
If you train an AI in a whole bunch of faces, where you end up are like you now have a galaxy
where every point is a face, points that are near each other are similar looking faces.
And there is a direction which is make this face smile more.
There is a direction which is make this face more male or more female.
There is a direction which is make this face older or younger.
What the AI has figured out is how to turn all of these semantic relationships
that we know how to reason about in our minds into geometries that we can work with on the computer.
Okay, let's take a step back and go back to our Pygmies in Congo example.
Back in the day, all of us in our ancestral times had pattern recognition.
We had our own reality neural net on our relationships of the Dunbar's number in our
tribe on the plants and animals and which things we could eat and which things were poisoned.
And now that whole pattern recognition trial and error is sped up
many, many, many, many orders of magnitude when we combine the compute, which is the
Moore's law reducing the size of semiconductors and chips so that we get more power per
unit of area plus the breadth and depth of global knowledge that we have access to,
the data set as it were.
So we're applying the same neural net that humans used to do in a manual look at our reality very
slow day to day sense with massive compute and data set applied to it.
Something like that?
Yeah, I think that's a good way of saying it.
It's no doubt that the neural nets we are creating now are nowhere near as efficient
as the human brain.
But we're able to, just in terms of power, required a number of examples that we need
to give a computer before it starts to learn, but we can feed in a lot more data a lot quicker.
The payoff that I'm getting to with these, why am I asking people to imagine these geometric
shapes and hold these multidimensional things in their mind?
It's because we're about to get two really powerful payoffs.
One, and this was the 2017 breakthrough.
And it was, okay, so now we're thinking back in language, imagine dog.
Dog has a relationship to man, dog has a relationship to wolf, to being a guardian,
to howls, to fur.
If you think about all the relationships that dog has, it sort of fixes it in a point in space.
And if you solve every concept's relationship to every other concept, it's like solving a
massively multidimensional Sudoku puzzle and outcomes sort of a rigid structure that
represents a language.
It's already really cool.
And the insight from 2017 was like, well, the shape which is German and the shape which is Japanese,
these can't possibly be the same shape because we have different histories and different cultures,
different ways of thinking about the world, different ways of relating to each other and
the natural world, different cosmologies.
And yet what they discovered is that when you take German and you take Japanese,
you can rotate one on top of the other.
And the point which is dog ends up in roughly the same spot in both.
And that lets you translate without a dictionary or a set of stone.
Explain what you mean rotate it so that dog is in the same place.
What do you mean by rotate it?
Ah, so, you know, we've been talking about these galaxies, these shapes that represent
well, any data set but language.
They're, you know, it's easier to think of them in three dimensions.
They're generally in 300 to a thousand dimensions, but they have some shape.
There's an overall structure to them.
And you just take one and you will line it up with the other.
You just move it around until the two shapes match.
And then the concepts that relate in the same way overlay with the concepts that relate
in the same way across actually not just German and Japanese, but Finnish,
which is a really weird language in Turkish and Aramaic and Urdu.
It appears that, you know, almost all human languages share a kind of universal
meaning shape.
And of course there are words in one language that don't appear in another,
but the, and that means like there's a point in Japanese that's not in the exact same spot
as the point in English, but the overall shapes in your blurry eyes are the same.
And I just think that's so beautiful.
It is beautiful because it almost, to me, it conjures up our shared past of tens of
thousands of generations on the Pleistocene before we spread out around the world.
There is a common brain structure.
And then the differences would obviously become over time due to cultural differences.
And it's good to know that the relationship between dog and humans is roughly the same
across all cultures.
I'm encouraged to hear that.
Yeah.
Okay.
Keep going.
Fascinating.
Okay.
So, I mean, that's interesting.
And I think where you're going is exactly right in the natural inclination to say that,
well, it must be something about our brain structures that is causing the shape to be the
same.
And of course, the punchline where we're going to go with Earth's species is,
can we figure out how to use this kind of technology to translate animal communication
by building the shape for their language and seeing if it fits.
But the way I think about language is that it is a model of the world and how we feel about it.
It's not just telling us about our brain shape and structure.
It's telling us something about how the relationships in the world work.
And so, I mean, it's going to jump to another like fascinating, much more recent breakthrough
because we've been talking about how languages align in the same shape,
but how about images?
So, I don't know if your listeners have seen Dolly or Dolly 2 or another thing called clip
guided image diffusion, but Dolly 2 just came out from open AI and it has this incredible uncanny
ability to you type whatever it is you want, any prompt you can think of.
Faces underwater by Salvador Dolly.
And within around a minute, it will generate that image.
And it's not just generating an image by finding an image that's similar on the internet.
You can come up with things that are absolutely new that the internet has not seen before.
Or, you know, a unicorn in a spacesuit talking with Elon Musk while playing the piano,
whatever you want in the style of Chagall and it'll generate it.
This totally blew me away when you showed me this at Joni's.
I'll post a couple of the things that you came up with.
Was that Dolly that you used to give me those images?
That was not Dolly.
That was something called disco diffusion, which actually any listener right now,
if you just Google that, you will find a Google co-lab that if you can code just a little bit,
you can start playing with this technology on your own.
And I actually used that piece of software to make a music video with my partner,
Alice, as you know, Nate, which just got shown at TED.
And it surprised me, you know, it took $3 of compute and 48 hours.
And it surprised me because the first time I've seen AI art that didn't feel amorphous and blobby,
but made me feel emotionally.
It was beautiful.
We'll put that video in the show notes, submarines.
But here's my reaction to all this.
I find it so so when we were at a little cocktail party and you were using the that
software that you just mentioned, and there was an owl on the porch.
And we said owl in about a hunt for the evening and Jasper John style.
And it spit out this beautiful abstract art image of an owl, yellow and black.
And it was really cool.
And my my instant reaction was binary.
It was two bookends of a reaction.
One is this is stunningly cool and beautiful and fun.
And I love it.
And the other was a little bit of horror.
Because first of all, as you know, I just did an Earth Day talk where I hired one of my
former students who's a beautiful artist to make 80 tarot cards.
And I paid her a decent amount of money for that because they were beautiful.
I could have done it for free using that software and just generated a bunch of tarot cards to
represent the image that I wanted.
So what does this mean for artists?
What does this mean for income and wealth equality?
If what does it mean for junior level programmers?
I mean, one of the things of AI is that AI can actually do basic and intermediate level
programming for you.
And maybe you could talk about that a little bit.
So I was simultaneously excited and petrified of the possibilities of what you just described.
That feeling of excited and petrified is my normal nervous system default state about the
future. It is simultaneous utopia and dystopia.
And that's what makes it so confusing.
We are about to have the greatest golden era humanity has ever seen, both in terms of
understanding ourselves, reverse engineering, how we work, being able to create art, having
anyone be able to make music and visual creations beyond what we could possibly have imagined.
And also that power will be used to increase asymmetric power inequality, wealth inequality,
and to exploit because this is the fundamental paradox of technology is the better we understand
ourselves, the better we can serve and protect, and the better that we can exploit.
So well, and the problem is, is the power law is, I believe in general human goodness.
And which is why I'm really glad that you are deeply in this AI community and I believe in
your power for good. But I do think one or two out of a hundred people that seek power to use
things for non pro social ends, end up capturing some of this disproportionate amount of the space.
So I do worry about that. So getting back, that's exactly right. Yeah, getting back to this though.
So what are the, what are the applications of the, the Dalai sort of thing, but then beyond art
what are the applications of that sort of thing? And how soon will that be available for the general
public? Yeah. So I think it's just important for listeners to realize because it's I've tried to
explain this a number of times now, like what Dali is without people getting to see it. And it's
hard to grasp how good it is until you go look at it and realize that literally anything you type,
it can visualize. And once you have that, then everything about to say will make more sense.
And how far are we as from instead of typing it, you just say, Dolly, make me a Jasper
Johns of an owl on your phone. Like how far are we from from that? Nothing technically
stopping us from doing that. That could be a right now thing. It's just that people haven't
actually hooked up the pipes. In fact, you know, if I wanted to, or anyone that had the skills
could go home and within one evening of hacking could have a version of that running. So the first
thing to realize is that language is going to become a joystick by which we control everything.
We have a major paradigm shift in computing, where things will become like creation will become
conversational. So very soon, we're going to move away from this very sort of old school way of
listening to music, where if you don't like the music that you're listening to, you're going to
have to go find the right song or maybe a playlist that has the vibe, you're just going to start
saying things like, well, that's great, but make this song a little bit more desert house with
the feeling of purple and nostalgic sunsets and sparkles and will either generate it or
find you the music that you're looking for. We're going to see a massive shift.
It would generate music like that's not by Rush or Porcupine Tree or Ann Murray,
it'll generate new music. Yeah, totally, because it's not so much further to go from,
I say something to it generates an image that's never existed before, but that we find aesthetic
and powerful and profound to, I say something and it generates music that I find beautiful and
profound. And what happens is a higher dimensional space, so it'll take longer.
