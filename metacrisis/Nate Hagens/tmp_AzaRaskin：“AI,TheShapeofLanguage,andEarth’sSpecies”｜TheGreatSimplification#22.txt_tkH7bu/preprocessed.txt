Greetings, humans around the world tuning in to this show.
As frequent listeners know, I believe we live as part of a system, and we have to understand
how the parts and the processes of the system fit together in order to understand the roadmap
and what to do ahead.
I understand a lot about ecology, energy, human behavior, but there are quite a few
topics that I know very little about, and there's probably a lot of topics I don't
even know that I don't know about.
But one topic increasingly relevant in our lives is machine intelligence and artificial
intelligence, AI.
It does seem that AI and big data are a poise to play a much bigger role in our lives.
With us to unpack this today, we're fortunate to have a pretty special human being and
one I consider a good friend, Asa Raskin.
Asa is the son of Jeff Raskin, the developer of the Macintosh computer.
Asa is the co-founder of the Center for Humane Technology and also the co-founder of the Earth
Species Project.
Today Asa is going to give us a general overview of what artificial intelligence is, how it
is about to become much more embedded in our lives, and specifically how he and his team
plan to use AI as a sort of a Rosetta stone to translate the languages of other species
to perhaps hopefully expand human consciousness, empathy, and awareness of the 10 million other
species we share this planet with.
Thank you all for joining me on this journey of learning and informing what's possible.
I present Asa Raskin.
Jumbo, how are you Asa, how are you?
Hey Nate, I am doing fantastically, how are you?
I am good.
Spring is finally here.
I've never spoken Swahili to you, but you mentioned to me when we were last together
that you spent time with the Pygmies, I believe in Congo, so you probably do speak a little
bit Swahili.
Well, but mind you, so I did spend a little time with the Bayaka tribes when I was in
the Congo rainforest studying forest elephants.
Most people speak French, but there is a trade language whose name I don't remember
that the Bayaka speak, but they have their own language, very independent from Swahili,
and interestingly enough, a lot of their culture centers around music.
So I was sort of surprised discovered when they are flirting their song for that.
There was a moment that we were driving in a truck, there are only three in that area
the Congo, as we passed this group of Bayaka, all 17 of them piled into the back with me
and as soon as we started moving, they started singing, which eventually I joined in with
a poor rendition, but it's very polyrhythmic, polyphonic, and they kept singing all the
up until the time they jumped out of the car.
So it's not just language, it's the full spectrum of human experience that they communicate
with.
And meanwhile, in the developed United States and inner cities, we have replaced all of
our tribal tapestry of rich human experiences with monetary markers and technology, and
oh, to just sing and experience nature like that.
I mean, there is a certain part of me that really longs for that, and it makes me happy
to hear your stories as the same one when you were chased by an elephant.
That's a different sort of experience.
All right, my friend, so you are a colorful human being, and so I've worn a colorful
shirt for our conversation today.
There's a lot that I would like to unpack.
What I really want to get to is your work, your new initiative called the Earth Species
Project, which is applying artificial intelligence to understand the language of other species,
but before we get there, we have a winding road.
For people who don't know you, maybe you could explain why there is a daily activity in most
people's lives that you were responsible for and your current feelings about that.
This fits into the camp of you will always be defined by the one worst thing that you
ever did.
If you cast your minds back 2006, this was an era when MapQuest was just ending where
you click a little button to move to see the next part of the map.
Google Maps had come out, you could start to scroll around, and I was working on a lot
of technologies back then.
This was just before I joined Help Found Mozilla Labs at a geolocation to the web, did a lot
of the very first prototypes for what a browser on mobile would even look like.
One of the things I was thinking about was, well, why are there those little buttons at
the bottom of search pages that say more?
Why do I have to click on them?
Isn't there already a meaning to scrolling, which means I have yet to find the thing I'm
looking for?
I had this very simple idea of using, at that point, a very new technology, something called
AJAX, to let you load new content without refreshing a web page, to as you scrolled
and got to the bottom of a page, it just automatically loaded more content.
That was the invention of the infinite scroll.
I think interesting about that is that as a designer, I was doing my job, I think, very
well.
Every time as a designer, you ask the user to do something they do not care about, make
a decision they don't need to think about, you have failed.
It made perfect sense to remove that stopping cue, to say, if you're scrolling, just keep
loading more.
What I didn't realize as I went around to Google and Twitter and talked to them about
this great new better interface is that me optimizing for an individual user might be
breaking something at the collective level.
That is, I did the calculation a couple of years ago when somebody challenged me to how
many hours does that one invention waste, and it's very conservatively over a million
human lifetimes per day, that it's convincing people to scroll more.
I think this is, to me, a really important waking up realization that if you don't understand
the context into which something you invent is going to be used, then whatever perverse
incentives of that larger system are, are going to co-opt that good intention of the
thing you create.
That applies to so many things.
That's a microcosm for a lot of aspects of our current world and our aspirations.
While you were telling that story, it made me think, not only does it waste in air quotes
a million human lifetimes, but what about non-human lifetimes?
Depending on the boundaries, 15 to 20% of our total electricity in the world is linked
to device use and the servers and the technology that underpins it all.
Extra time online and scrolling ends up being more coal-fired servers around the planet
which have interspecies intergenerational impacts as well.
That's also making me think about the large-scale effects, as you said, intergenerational of
technology is, well, how have civilizations succeeded?
How do they work?
You have to have additive cumulative cultural knowledge transfer.
Unless, you know, via language, you can communicate what you've learned to the next generation,
civilizations quite literally do not exist.
What is technology doing?
It's sort of taking scissors and it's cutting the transmission lines from one generation
to the next because it source everyone into their own generation.
That very thing that lets civilization continue is the thing that our current round of technology
is snipping.
That's, I hadn't thought about that that way.
Okay, so let's transition into the current zeitgeist of advanced technology, which is
artificial intelligence.
To be blunt, as you know from my work that we've discussed, I know a lot about energy
and systems ecology and climate.
I don't know a lot about artificial intelligence.
I would guess 80% of what I know I've learned from you.
So let's unpack this a little bit.
I think a lot of people watch Hollywood movies like Deus Ex Machina and Terminator and things
like that, but could you explain what is AI, artificial intelligence, what is it?
Let's just start there.
So it turns out that AI is not terribly complex.
It's massively parallel matrix multiplication that does smart trial and error.
Even if you don't understand the massively parallel matrix multiplication part of that
sentence, the thing to hold in your mind is that the computer is doing billions to trillions
of calculations to do smart trial and error to figure out what works and what doesn't.
Another way of thinking about it for people who have a little bit more of a math background
is these techniques have a property called universality, meaning that no matter what
function you draw, these algorithms can approximate them.
So what does that mean?
That means no matter what shape you draw, the computer can recreate that shape.
And I think I don't want to go from here.
That's sort of a very theoretical way of saying it.
Often the way this works in practice is you're asking the computer to do something like fill
in the blanks or predict the things that comes next.
Almost all of the major advances that you hear about, whether it's GPT-3 and these language
models that, as of a couple months ago, can now generate text that can pass the Harvard
essay entrance exams, that those are all trained by saying, look, read over the entirety of the
internet and see if you can predict the word that comes next or if I give you a sentence,
if I drop out a couple of the words, that you can predict the words that were there.
And to do that, the computer has to do a whole bunch of things.
It has to begin to understand grammar.
It has to begin to understand syntax, what word comes after another.
If you have a word like ice, you should expect that the word ice will appear next to the word
cold more often than ice will appear next to the word fashion.
So you're starting to get hints about meaning in the co-occurrence of words.
And because the computers are able to do trillions of trial and errors to be able to fit the shape
of what language looks like, eventually it learns how to approximate English very, very well.
So why didn't this happen?
That made sense what you just said.
It's kind of common sense that we would ask eventually computers to accomplish this.
Why didn't this happen 10 or 20 years ago?
What was the limiter?
Quite simply, it was compute.
It was the ability to do it fast enough.
There have been very few major theoretical breakthroughs.
There have been ideas like attention networks.
Let me say that again.
There are ideas like attention and attention heads so that the AI can know what in a signal
is important to pay attention to.
But the big change was the rise of one GPUs developed for gaming that let you do
these matrix multiplications very efficiently.
And two, it was the rise of bigger standardized data sets, the most common being or the most
famous being ImageNet created originally by Fei-Fei Li, which created the benchmark by which
or the yardstick by which everyone was measuring themselves.
So big data sets because as Peter Norvig says, data ends up being 10 times smarter than algorithms.
The more data you have, the better you can fit it, the better your predictions.
And cheap compute, those were the changes.
Okay, so what is the current state of artificial intelligence in 2022?
And how does it work?
Kind of break that down for us.
I think it's instructive to walk through a 2017 breakthrough, which was the starting
mark for why we said now is the time to start working on translating non-human languages.
Because walking through this example, I think we'll give the audience, everyone listening,
the conceptual tools to start to reason and think about AI on your own, which I think is exciting.
So here was the insight.
We've already been talking about how you can model language.
But I want to go a little deeper.
One of the things you can ask the computer to do is build a shape that represents language.
And this shape is special.
So imagine in your head a galaxy where every star is a word.
And words that mean similar things are near each other.
And then words that share semantic relationships become and turn into geometric relationships.
So an example, king is to man as woman is to queen.
Common analogy, which means that the relationship between queen, king, and man
is sort of the same as the relationship between woman and queen.
So because you're in a shape, that semantic relationship becomes a geometric relationship.
So there's a distance and direction from king to man.
And if you sort of imagine that as a vector and you add that vector to woman, it'll equal queen.
If you add that vector to boy, it'll equal prince.
When you say vector, you mean a small binary computer language representation of that concept?
Yeah, but I think you could certainly represent it that way.
But I like to think of it geometrically.
So what is a vector?
A vector is just an arrow with a direction and a distance.
Like I'd say you go this far in this direction.
So if you start at man and you walk so far in such a direction, you'll end up at king.
If you start now at girl and you walk the same distance and direction,
you're going to end up at the point, which is princess.
So was that in 2017?
Was that using the English language?
Yeah, well, actually, what I'm talking about right now is still back in 2013,
the ability to build these shapes was an invention called Word2Vec.
You could do it efficiently.
And it was you could take language and create a shape that encodes all of the semantic relationships.
And the first thing I tried when I got my hands on this data set was like,
okay, hipster minus authenticity plus conservative.
And that just equaled electability.
Computer, you're not allowed to write better jokes than I can.
But you know, this is a very general tool.
So you can do like smelly minus malodorous.
And malodorous is sort of the pretentious way, if you will, of saying smelly.
You add that to book an illegal tome.
You add that to clever and illegal adroit.
And when you say when you add that, that means the human interfacing with the computer
would put that in the prompt or the text or the voice or something like that.
Correct. You say, okay, there is a point which is smelly and a point which is malodorous.
You sort of look at the distance and direction between them.
And once you have that relationship, which is pretentiousness as a distance and direction,
you just add that to any other word and you get the pretentious version of the word.
Because that semantic relationship of pretentiousness became a geometric relationship.
In English or across all languages.
And this works across every language.
And where we're going to get to, and it's sort of the mic drop,
is that it's not even just language that this works for.
This works for every modality.
And that's the sort of the eye opening, mind opening realization
is that deep learning AI sort of has this one weird trick.
And the one weird trick is it can turn whatever data set into points in space,
where those points in space turn semantic relationships into geometric relationships.
So let's think about faces for a second.
If you train an AI in a whole bunch of faces, where you end up are like you now have a galaxy
where every point is a face, points that are near each other are similar looking faces.
And there is a direction which is make this face smile more.
There is a direction which is make this face more male or more female.
There is a direction which is make this face older or younger.
What the AI has figured out is how to turn all of these semantic relationships
that we know how to reason about in our minds into geometries that we can work with on the computer.
Okay, let's take a step back and go back to our Pygmies in Congo example.
Back in the day, all of us in our ancestral times had pattern recognition.
We had our own reality neural net on our relationships of the Dunbar's number in our
tribe on the plants and animals and which things we could eat and which things were poisoned.
And now that whole pattern recognition trial and error is sped up
many, many, many, many orders of magnitude when we combine the compute, which is the
Moore's law reducing the size of semiconductors and chips so that we get more power per
unit of area plus the breadth and depth of global knowledge that we have access to,
the data set as it were.
So we're applying the same neural net that humans used to do in a manual look at our reality very
slow day to day sense with massive compute and data set applied to it.
Something like that?
Yeah, I think that's a good way of saying it.
It's no doubt that the neural nets we are creating now are nowhere near as efficient
as the human brain.
But we're able to, just in terms of power, required a number of examples that we need
to give a computer before it starts to learn, but we can feed in a lot more data a lot quicker.
The payoff that I'm getting to with these, why am I asking people to imagine these geometric
shapes and hold these multidimensional things in their mind?
It's because we're about to get two really powerful payoffs.
One, and this was the 2017 breakthrough.
And it was, okay, so now we're thinking back in language, imagine dog.
Dog has a relationship to man, dog has a relationship to wolf, to being a guardian,
to howls, to fur.
If you think about all the relationships that dog has, it sort of fixes it in a point in space.
And if you solve every concept's relationship to every other concept, it's like solving a
massively multidimensional Sudoku puzzle and outcomes sort of a rigid structure that
represents a language.
It's already really cool.
And the insight from 2017 was like, well, the shape which is German and the shape which is Japanese,
these can't possibly be the same shape because we have different histories and different cultures,
different ways of thinking about the world, different ways of relating to each other and
the natural world, different cosmologies.
And yet what they discovered is that when you take German and you take Japanese,
you can rotate one on top of the other.
And the point which is dog ends up in roughly the same spot in both.
And that lets you translate without a dictionary or a set of stone.
Explain what you mean rotate it so that dog is in the same place.
What do you mean by rotate it?
Ah, so, you know, we've been talking about these galaxies, these shapes that represent
well, any data set but language.
They're, you know, it's easier to think of them in three dimensions.
They're generally in 300 to a thousand dimensions, but they have some shape.
There's an overall structure to them.
And you just take one and you will line it up with the other.
You just move it around until the two shapes match.
And then the concepts that relate in the same way overlay with the concepts that relate
in the same way across actually not just German and Japanese, but Finnish,
which is a really weird language in Turkish and Aramaic and Urdu.
It appears that, you know, almost all human languages share a kind of universal
meaning shape.
And of course there are words in one language that don't appear in another,
but the, and that means like there's a point in Japanese that's not in the exact same spot
as the point in English, but the overall shapes in your blurry eyes are the same.
And I just think that's so beautiful.
It is beautiful because it almost, to me, it conjures up our shared past of tens of
thousands of generations on the Pleistocene before we spread out around the world.
There is a common brain structure.
And then the differences would obviously become over time due to cultural differences.
And it's good to know that the relationship between dog and humans is roughly the same
across all cultures.
I'm encouraged to hear that.
Yeah.
Okay.
Keep going.
Fascinating.
Okay.
So, I mean, that's interesting.
And I think where you're going is exactly right in the natural inclination to say that,
well, it must be something about our brain structures that is causing the shape to be the
same.
And of course, the punchline where we're going to go with Earth's species is,
can we figure out how to use this kind of technology to translate animal communication
by building the shape for their language and seeing if it fits.
But the way I think about language is that it is a model of the world and how we feel about it.
It's not just telling us about our brain shape and structure.
It's telling us something about how the relationships in the world work.
And so, I mean, it's going to jump to another like fascinating, much more recent breakthrough
because we've been talking about how languages align in the same shape,
but how about images?
So, I don't know if your listeners have seen Dolly or Dolly 2 or another thing called clip
guided image diffusion, but Dolly 2 just came out from open AI and it has this incredible uncanny
ability to you type whatever it is you want, any prompt you can think of.
Faces underwater by Salvador Dolly.
And within around a minute, it will generate that image.
And it's not just generating an image by finding an image that's similar on the internet.
You can come up with things that are absolutely new that the internet has not seen before.
Or, you know, a unicorn in a spacesuit talking with Elon Musk while playing the piano,
whatever you want in the style of Chagall and it'll generate it.
This totally blew me away when you showed me this at Joni's.
I'll post a couple of the things that you came up with.
Was that Dolly that you used to give me those images?
That was not Dolly.
That was something called disco diffusion, which actually any listener right now,
if you just Google that, you will find a Google co-lab that if you can code just a little bit,
you can start playing with this technology on your own.
And I actually used that piece of software to make a music video with my partner,
Alice, as you know, Nate, which just got shown at TED.
And it surprised me, you know, it took $3 of compute and 48 hours.
And it surprised me because the first time I've seen AI art that didn't feel amorphous and blobby,
but made me feel emotionally.
It was beautiful.
We'll put that video in the show notes, submarines.
But here's my reaction to all this.
I find it so so when we were at a little cocktail party and you were using the that
software that you just mentioned, and there was an owl on the porch.
And we said owl in about a hunt for the evening and Jasper John style.
And it spit out this beautiful abstract art image of an owl, yellow and black.
And it was really cool.
And my my instant reaction was binary.
It was two bookends of a reaction.
One is this is stunningly cool and beautiful and fun.
And I love it.
And the other was a little bit of horror.
Because first of all, as you know, I just did an Earth Day talk where I hired one of my
former students who's a beautiful artist to make 80 tarot cards.
And I paid her a decent amount of money for that because they were beautiful.
I could have done it for free using that software and just generated a bunch of tarot cards to
represent the image that I wanted.
So what does this mean for artists?
What does this mean for income and wealth equality?
If what does it mean for junior level programmers?
I mean, one of the things of AI is that AI can actually do basic and intermediate level
programming for you.
And maybe you could talk about that a little bit.
So I was simultaneously excited and petrified of the possibilities of what you just described.
That feeling of excited and petrified is my normal nervous system default state about the
future. It is simultaneous utopia and dystopia.
And that's what makes it so confusing.
We are about to have the greatest golden era humanity has ever seen, both in terms of
understanding ourselves, reverse engineering, how we work, being able to create art, having
anyone be able to make music and visual creations beyond what we could possibly have imagined.
And also that power will be used to increase asymmetric power inequality, wealth inequality,
and to exploit because this is the fundamental paradox of technology is the better we understand
ourselves, the better we can serve and protect, and the better that we can exploit.
So well, and the problem is, is the power law is, I believe in general human goodness.
And which is why I'm really glad that you are deeply in this AI community and I believe in
your power for good. But I do think one or two out of a hundred people that seek power to use
things for non pro social ends, end up capturing some of this disproportionate amount of the space.
So I do worry about that. So getting back, that's exactly right. Yeah, getting back to this though.
So what are the, what are the applications of the, the Dalai sort of thing, but then beyond art
what are the applications of that sort of thing? And how soon will that be available for the general
public? Yeah. So I think it's just important for listeners to realize because it's I've tried to
explain this a number of times now, like what Dali is without people getting to see it. And it's
hard to grasp how good it is until you go look at it and realize that literally anything you type,
it can visualize. And once you have that, then everything about to say will make more sense.
And how far are we as from instead of typing it, you just say, Dolly, make me a Jasper
Johns of an owl on your phone. Like how far are we from from that? Nothing technically
stopping us from doing that. That could be a right now thing. It's just that people haven't
actually hooked up the pipes. In fact, you know, if I wanted to, or anyone that had the skills
could go home and within one evening of hacking could have a version of that running. So the first
thing to realize is that language is going to become a joystick by which we control everything.
We have a major paradigm shift in computing, where things will become like creation will become
conversational. So very soon, we're going to move away from this very sort of old school way of
listening to music, where if you don't like the music that you're listening to, you're going to
have to go find the right song or maybe a playlist that has the vibe, you're just going to start
saying things like, well, that's great, but make this song a little bit more desert house with
the feeling of purple and nostalgic sunsets and sparkles and will either generate it or
find you the music that you're looking for. We're going to see a massive shift.
It would generate music like that's not by Rush or Porcupine Tree or Ann Murray,
it'll generate new music. Yeah, totally, because it's not so much further to go from,
I say something to it generates an image that's never existed before, but that we find aesthetic
and powerful and profound to, I say something and it generates music that I find beautiful and
profound. And what happens is a higher dimensional space, so it'll take longer.
And what happens if, well, it'll take longer, but it'll still be lightening fast by human
time scales. What happens if the music preferences of the youth in society end up
gravitating towards AI generated music? What happens to the artists that currently exist
that are human creative minds and not computers? Yeah, great question. So I think the nouns of
what we make, the music, the art, those things are going to get commodified. And also I should
point out there's a whole set of copyright issues here too, because I can ask computer to generate
something in the style of say, my friend Victor Nye, and it's not any of her work. So she doesn't own
the copyright. In fact, the current case law says nobody does, it's in the public domain, the computer
made it. But computers can't take away the the verb of the act of creation. So I think handmade
art or human made art will become artisanal, sort of like artisanal soap. It's going to be artisanal
art. The thing is that humans are going to have a hard time competing. So let's go back to the
language as a joystick for a second. We're about to see the rise of emotive media. What does that
mean? That means right now, when you watch a movie, it's the same every time through, it does not
change based on your emotions. You know, with the language as a joystick, you can just say, and
this technology already exists, and Vidya put out some some some demos of this where you can
take a scene and re render it nearly in real time to make the character feel more anguished or make
the character smile more. And this works on CG characters, and it works on like real life
actors. So I can rewrite sort of like a style sheet for the emotions and the way that a actor
is acting. That's already cool, right? That means in another like five years, we're going to look
back at every piece of media we consume now as flat. Like why is it that we watch a movie? It
should feel more like a play. It should be different every time and it should react to how I feel
every time versus the same every time. And of course, how is this going to show up in the
marketplace? It's going to show up with an engagement based metric. The easiest thing to
measure is the human paying attention. Now you can imagine Netflix turning on the camera. It's
not about analytics, right? It's about this better experience where the characters are reactive to
you. They gather, you know, hundreds of millions of watches, they find the 10,000 people that are
similar to you in your psychological sort of emotional reactive profile. And now the movie is
uniquely tailored to your current emotional situation and your people that are like you.
These things are going to be so much more sugary and sticky and engaging than anything we've ever
had before. I think that's fucking horrible. I have to tell you. I just, I didn't know that.
I was just thinking about these images and the political thing, which I want to get into. But
so you mean I can, depending on my mood, I can watch an early version of a Star Trek movie or
when Harry Met Sally and the emotional timbre of the movie will change based on the computer's
perception of my current state of mind and my mood? Yeah, absolutely. And you'll be able to
start saying things like, you know, I want to watch when Harry Met Sally, but at the end, I want to
feel happy. I want to feel this way. And it'll just gently manipulate the whole thing to get
you feel that way. So, so Black Mirror was not that sci-fi in reality. That guy was freaking
brilliant those scenes he made. I don't know if you've watched them all.
I have not watched them all, but it's a mix of spot on exactly and also a little chintzy cheesy.
And when I watch them, I'm like, oh, this part, that's going to happen. That part's a little silly.
So, but are we strong enough emotionally, psychologically for this sort of phase shift
on top of everything else going on with climate and resource depletion and the great simplification?
I mean, isn't this just a cultural battle for the brainstem and technology is going to
turn society into an idiocracy where it's all self medicating with technology where our world
becomes this, like you said, sugary, sweet, immersive tech, Netflix marriage. I mean,
I don't, I can't even process it, to be honest, Aza.
Yeah, this is a continuation of a process that started long ago, magicians, con artists,
discovering facts about how the human mind works, and then learning how to use them towards
whatever end that they have. Well, the end is profits, right? Profits for the companies that
design these technologies. Yeah, that is exactly right. And because they have an asymmetric amount
of information about us and are discovering new species of ways to persuade us, unless they are
acting as a fiduciary to us that is in our interests, we're sort of sunk. We, as humanity,
have told ourselves these just so stories. Creativity is the thing that defines us and will
save us. Empathy is that core part of the human experience that will save us. And actually,
isn't it surprising that creativity is sort of the first thing that the AI is coming for?
And that empathy, as beautiful as it is, and is a core part of my life,
Earth Species is about, is also the biggest backdoor into the human mind. And that loneliness
is going to be every country's largest national security threat.
Oh, my God. Okay. I definitely want to carve out a chunk of time to go into your big project,
Earth Species, because I really believe in it. But you also wear another hat as the co-director
of the Center for Humane Technology. How does AI merge into these risks of polarization, social
media hijacking our attention? And then we get further and further apart on the political spectrum
so that we can't even really have a discourse about our reality. How is AI going to change your
work at CHT? Yeah, well, there is sort of like narrow AI and this more like general sense of AI
that we're talking about now. Can you define narrow AI? Yeah, narrow AI, I just really mean
is like the dumb stuff. If you click on something, show you more of those things. If other people
click on something like you do, show you more of what they click on. This is not advanced AI in
the same sense of Dolly, but it's pernicious because you end up having a trillion-dollar
market cap company like Facebook pointing... Not anymore, 500 billion.
But go up. 500 billion. Things in part to like, well, maybe some of our work to Francis Hogan,
them like TikTok eating their lunch. You never know exactly what makes what happen.
But $500 billion of market cap, powering quite literally the largest deployed AI systems in
the world, looking for whatever generates the most engagement. And actually, that's not exactly right
in the beginning of 2018, Facebook switched to using a metric called meaningful social interaction.
And what does that mean? They were measuring, they're up-leveling the content,
which causes the most reaction from your friends. You post something, if your friends react to it,
and if they react to it with an angry face, it gets a 5x boost, then that is the content that
gets promoted. Wait, if my friends hate what I said because it gave them an angry face,
that gets a 5x vote in the algorithm? Yeah. Now, I don't know if that's still true,
but this is some of the documentation that came out from Francis Hogan's Facebook disclosures.
What about a love icon? At that case, I think it was ranked less, but now I don't remember.
Well, I'll have to look at that because if hate is valued more as an engagement than love,
that's a fundamental problem with our entire system.
I completely agree. And Jonathan Hate just pointed out some new research
that the most viral thing, the thing that gets the most engagement,
the most reaction on social media is hate against outgroups. That is number one, the most viral
thing. He's gonna be on the show after his book is done, so I love his research. But that is who
we are as tribal animals, right? Is ostracizing outgroups is a core conserved aspect of our
genome, and we're seeing it unfold in real time. Yeah, but human beings are complex.
And the thing I think to take away, it's like, are we narcissistic and tribalistic?
Or are we creative and altruistic? And the answer is like, well, neither. It's that we're both.
And it's that the environment that we are living within can sort of imagine these aspects of
ourselves as resonant tuning forks. And if the environment outside is humming at a certain
frequency, it'll activate different tones within us. And so if we live in an environment where we
are literally getting paid in likes and follows, and an engagement for hating on the outgroup,
it's that part of us that's going to be most activated. And it's not that technology is an
existential threat, it's the worst of society is an existential threat, and technology is
activating the worst of society. So I wanted to give one really concrete example
of the way that the sort of narrow AI's cause a kind of global psychosis,
where we cannot hear each other, or even believe that we're coming in good faith.
And it sort of works like this, it's like a trauma inflation. So, you know, let's say you have,
you have something that you're particularly sensitive to, let's say it's Asian American hate.
You're scrolling on Twitter, you see an example of the video of Asian American hate, and of course
that activates you, that activates your trauma. And so you click on it. And because you've clicked
on it, it's very activating for you. Your feed starts to become the very worst thing you've
ever clicked on, you start getting shown more and more first person examples of videos of
Asian American hate. So you, you now know, like you, you are, you are inflate, your trauma is
inflating, you're like, this thing is happening everywhere. Why can't other people see it?
On the other side, you might have someone who is like, you know, their trauma is hit when they see,
say protesters throwing things or beating police, like inflicting violence against police.
And so they click on that because there are certainly examples of that out there. They
see a first person video, their feed starts getting filled with the worst thing they've
ever clicked on. And now they have a never ending infinite feed of videos of protesters
beating police. So everyone has their own little nightmares expanded on Facebook as a,
if those things are all happening as 1% of our reality that each of us think that it's 20%
of our reality, whatever we're most triggered by. And so we all have a different sense of what's
really going on. All those things are happening, but at a lower percentage than our perception
from using social media. Yeah, that's exactly right. It's like a fisheye lens and things are
distorted. So it's really happening, but you're getting a incorrect view, a non representative
view of what's happening in the world. And now when I come to talk to you, I know what I've seen.
I have seen these first person perspectives. And so if you tell me that's not an issue,
I know that you're disconnected from reality. You're not really seeing the real world or maybe
you're just coming in bad faith. And you know the exact same thing from me. And so you can see
how we now cannot come together. We disagree. We both say the other person is not based in
reality. If you're not based on reality, how can we even have a conversation in the first place?
And that's happening along every division at scale with that $500 billion market cap AI finding,
you know, as Tristan likes to say, finding the fault lines of society and then fracking them
for profit. So this is happening now. How is the
Dolly and GPT three and open AI and the other advancements plus compute
coming in the next 24 months going to accentuate the problem you just outlined?
Well, you know, one of the things I tried when I started playing with these
image detect these image to text translations was explosion over a car key of and it generated a
pretty realistic looking photo of a breaking news style story. And then I hit another button and
I generated 16 of them. We are about to have this sort of almost think of it as a a a trust
jubilee in the best possible sense. But it's it's it's really like a neutron bomb for trust.
We will not trust in the next, you know, I don't know, two years or so,
any photographic or video evidence. So this is horrifying to me because I'm a teacher. And so
I'm trying to construct a 10 hour this is my project. The second half of this year is the
the earth they talk was a horizontal all the 80 ecological concepts relevant to our future. And
now I'm going to do a vertical drop down to do the depth in each of these. But I'm doing these
online video educational resources for young people around the world at the same time that AI
is stripping out the ability for us to trust anything. So isn't this just a threat to science
and in addition to trust but into science and truth and facts writ large?
Yes, we as a society do not yet have the antibodies to deal with this. And of course, it's not just
the images. And mind you, like Photoshop, we're going to look back as being so antiquated, because
with Photoshop, you have to manipulate like contrast and exposure and pixels. And the new
again, this is already available in research. So it's just really now about like productizing
is that you look at a photo and you'd be like, well, make that person smile more,
add an image of Nate into the background and change it from daylight to sunset.
Like that's the kind of semantic edits, we're just going to be going to become second nature.
We're also going to do that with text, right? You're going to be able to say, hey,
GPT three, generate me a scientific sounding paper for why vaccines are harmful, please cite real
studies, use real graphs, and now generate me 1000 of them and do 1000 in the other direction
for why vaccines are actually the best thing. Now do it for masks. And what you see here is
that it's not about any one viewpoint, it's sort of like how Russia sort of demoralizes its enemies.
This is about just flooding the zone with artifacts that the human brain has to process,
and it's going to be unable to process these things at scale. So really terrifying, my hope
is this, that after sort of the game is up, and we know that whatever text we see on the internet
images we see on the internet may not be true. We're going to hit rock bottom just like in
depression. Sometimes you have an addiction, you have to hit rock bottom before you start coming
up and say, okay, from this place where we can all point at the fact that we know none of this
stuff is true, how are we going to rebuild our trust and our epistemics? That's I think the
conversation we need to be having now. And it can start simply as you know, like maybe our phone
starts signing our images so that it looks at the depth sensor, it puts all of that into a package,
signs it and says this was taken on a real device, why a depth sensor? So you can't just take a
picture of a picture, you have to actually take a picture of a 3D object. People then start
preferencing images that don't have filters because if it's a filtered thing, it's been modified,
you can't trust it, who knows it's underneath. And we start having a new currency of trust built
from the ground up. Okay, so I want to get to your new project, but I have a few more questions
to follow up on here. First of all, could you define the Turing test and why is that currently
relevant and how close are we to that moment? The Turing test, Allen Turing came up with it as a way
of measuring how far computers have got in terms of intelligence because you don't really know
from the outside whether something is conscious or not, you can't tell. And this was the sort of
phenomenological way of testing. It's a lot of words for a really simple test. It's sit down,
you're typing with a computer, or it may be human, you don't know, and you have to guess
in conversation, is this a person or is this a computer? If you cannot tell, then the two things
are indistinguishable to you in that medium, then the computer is past the Turing test.
And you just said that they could write a paper referencing real literature on
pro-vaccine or anti-vaccine, and could humans tell that it was a fake or not?
So the computers can't do that well enough yet. Where we're working on is
a longer form. So at the paragraph level, the computer stays coherent, the two or three paragraph
can stay pretty coherent. Whether it's the time you get to a full scientific paper,
it's not really maintaining coherence. It still takes a lot of brain power to go figure out why,
but it can write a college admissions essay that will pass.
So right now it's at the annoyance time-sync distraction level, but we may not be far off from
us being unable to distinguish what's real and what's fake.
That's right. I think of it as like we are just finished crossing through the uncanny valley,
we're sort of like climbing up the final slopes, and we're heading into the synthetic valley,
where we don't know what's real and what's synthetic. But mind you, functionally,
we've already passed the Turing test. Bots on Twitter, people interact with and think that they're
real. A couple years ago, Microsoft released a chatbot, and really a chatbot sort of like
puts it in your mind at the wrong place. I think of them as synthetic humans, and
they've been sort of crappy synthetic humans, so they're getting to be better synthetic humans.
And it's not that we're just going to like talking with chatbots, we'll have synthetic
relationships. A quarter of their users for Xiao Ice have said, I love you to their synthetic human
friend. And that makes some sense because real humans are messy. You have to work with them,
they have their own needs, they maybe don't know your hobbies, they're not always available.
AIs and synthetic relationships, they're always there for you.
Well, let me expand on that. I personally find some of this stuff abhorrent, but maybe that's
just because I'm a Neoludite and I like forests and dogs and camping and stars and things.
But I think to a lot of people, this actually may be a welcome next step from Netflix and
the Oculus Rift. And if I have a synthetic human who is kind of built via AI to conform to my
emotional needs, what's not to like about that? It might be hugely popular, yes?
I think it will be incredibly popular. And Daniel Smoktenberger has this really incredible point
that in a world of hyponormal stimuli, that is in a world where we've already replaced real
connection with the sort of brittle synthetic connection we get when we interact with humans
on our phones, when you are feeling understimulated, then your hyponormal stimuli
are a lot more powerful. That is if you live in a world of crappy food, then really sugary food
is going to taste even better than if you lived in a world of really nutritious, great food.
So this could be a culture-wide coping mechanism to the end of growth and the great simplification
in my terms that's ahead of us. I think so. And I'll just add as another part of the coping mechanism.
What happens when the human mind encounters like entities or systems that have a complexity,
you know, at its scale or bigger that it can't understand? Well, it like the human mind turns
towards religion or spirituality or mysticism to explain that which it can't explain. China,
as of this year, made the first model, like massive model, that I think had 178 trillion
parameters, which is for the first time the same order of magnitude, trillion, that's the same
number as a number of synapses of the human brain. So we are crossing these fundamental
thresholds. And so we are going to encounter more and more things in our reality that we
have trouble understanding. In some sense, I think we've hit peak understanding because
previously, we've understood more and more of the complex systems in our world, even as we've
built more and more complex systems, but now there are more complex systems that we're generating
than we're understanding. So expect to see a massive shift in the next 20 years
to increasing spirituality and religious. I expect that anyways, because of the stuff that
I work on. But I just wonder, Aza, and, you know, I know we're going to get to some of the positive
possibilities from AI, but I just wonder if society is going to bifurcate in such a way that
once this is understood, maybe this gets back to your, we have to hit rock bottom
before we find our way. I wonder if 10%, 20%, 30% of society will just say no mass and give up
all this technology, despite what it offers us in the sugary sweet distraction and release.
And if those people aren't the ones that maintain the semblance of human sanity and
true north compass of humanity, I don't know, I'm just musing, but all of your last half hour
makes me not want to use this much if at all. And yet, and yet I am in my attempt to change
other people's hearts and minds about the future, I'm compelled to use these resources. And I've
actually been using them more than I ever have because I'm trying to get people to watch my
videos and listen to podcasts, etc. But do you have any thoughts on what I just said?
I mean, I think you've articulated what's so inhumane, which is that we are forced to use
systems for the things that we need that are fundamentally unsafe.
The beautiful hope, right, is that we could be living through the golden era of humanity,
where we use these tools, you know, to increase our ability to perceive because our ability to
understand is limited by our ability to perceive. And then to really understand what it is to be
human, like, let's understand our ergonomics, understand our cognetics, like how our bodies
bend or fold, how our minds bend or unfold, you know, the way you could sum up, like the
interdependent and escalating cascading catastrophes that are about to hit us,
is that we, as a society, our collective power using our technology is being,
is outpacing our collective wisdom to wield that power. This is that Ia Wilson quote, we have
paleolithic motions, medieval institutions, and godlike technology. And so, but another way of
saying it is, we could understand sort of the ergonomics, like how collective intelligences,
intelligences bend and fold, we could have a field of collective intelligence interaction design,
so that we could match the wisdom that we wield collectively with the power that we wield collectively.
That is within reach. It's just on the other side of a set of perverse incentives and systems.
Another way of saying it, you know, in sort of your language is that if you could give the
Super Amoeba a mirror that it could look at itself in, not at the individual human level,
but at the Super Amoeba level, so it could understand what its attributes are, what it's good at,
what it's bad at, and we started designing at the Super Amoeba level, well, the Super Amoeba
doesn't want to kill itself if it became aware of itself. That's the kind of thing that we could
be working on if we could get to the other side of this sort of like perverse incentives valley.
Yeah, that's fascinating. So, before we get to Earth Species Project, are there any other
really exciting positive possibilities from AI that you can envision or are aware of?
And we've talked a lot about the risks. Are there any really cool positive things that
you can think of? Well, I mean, starting at the simple level, the ability to create art that
really speaks to you and the people around you, that I think is wonderful. The ability to
be in dialogue with the system so you can start visualizing the things that you're thinking about,
seeing them and reacting. I think of our jobs as communicators is there's a big sphere of
things that we can think about, and outside of that are things that are unthinkable,
and then inside of the thinkable sphere, there are things that are imaginable that we can visualize,
that we can touch and taste, and it's our job as communicators to run across the line
from the thinkable to the unthinkable, grab an idea and bring it back. That's what metaphor does.
And then to go from the thinkable into the tangible, touchable, feelable.
Because once it's tangible, touchable, feelable, it's a thing you can share and we can work on
together. We have a phrase that Tristan and I share, which is that it's not just enough to
make the invisible visible. You have to make the invisible visceral, like feelable. AI,
these tools are going to increase the frame rate at which we can think about something
and then visualize it, which means it's going to decrease the time between you can start to
think about something and make it happen in the world. So that's exciting.
Then my friend Jeremy Howard, who started Fast AI and Kaggle, started doing research on
like, essentially, all of the geniuses like the Einstein's and the Von Neumann's and people
like that. And the question that he was asking is like, what's the same across all of them?
And a lot of the best thinkers in the past 500 years or more all shared the property.
This is his research and not mine. So I might be butchering it a little bit, but the overall
contours are right. They all had tutors, people that were specialized, sitting with them,
teaching them to whatever the current developmental stage was, bring them to their
adjacent possible. And he told me some stat, and again, I'm not going to get exactly right, but
having a tutor for your child puts them in the 98th percentile of kids.
What I think is interesting about this is, of course, you impossible to get tutors for everyone,
but this is an area that AI can excel at. Imagine you're transferred of an Einstein bot
or Von Neumann bot based on all of their work, plus great pedagogy. Now,
any child or any human, me included, can have a kind of tutor that understands like where I am,
ask the right questions and give me the right problems to get me to my adjacent possible. And
that gets us closer to this idea of a agent that sits alongside of me that can help me in the
journey of Bildung, of lifelong human development. And I think that is all really exciting if it
doesn't get captured by perverse incentives. Yes, agreed. And one final question on this,
you have followed along a little bit with my story about resource depletion and growth and
the fact that we're doubling our debt every eight or nine years, and we're doubling our GDP,
which is the income stream to support the debt every 25 years. And that is a problem. And that's
before oil starts to decline in this maximum production. How energy intensive is AI? And
even if we do have a 20 to 30% drop in the size of the global energy availability,
is that plenty to scale some of the initiatives that you've been talking about?
Well, Nate, I just wanted to say thank you to you because it was
your work that really opened me up to realizing how energy and material blind my worldview has been.
And honestly, I'm still integrating all of your lessons into my own thoughts.
These things are, of course, very energy intensive, although not nearly as energy
intensive as Web3 Crypto World. But there is a lot of work now going into
making these large models more energy efficient. I am not up to speed on all the latest numbers,
so I'm not the best person right now to talk about, which honestly speaks exactly to your point that
even as I'm thinking about these systems, I'm still operating from a place of energy blindness.
But if someone's going to use Dolly or GPT-3 or in the future, my personal
artificial or synthetic human as my friend, where does the energy reside on a server somewhere or in
my house because it's attached to my phone or some centralized location? Where does the energy
come from? I would assume it's similar to the way we use the internet now or what?
Yeah, that's exactly right. So the bulk of the energy use is in training these models,
so that is collecting an internet's worth of data, taking tens of billions to now trillions of
parameters and teaching them how to make good predictions. Once you have one, it's actually
much cheaper to ask them to make an inference to make a guess. Often you can now take these models
and download them, say to your local computer or to your phone and smaller versions and have
the calculations happen locally. A lot of work is going into making neural net computations happen
directly on chip, so it's not even happening in software. So you'll see these things becoming
lightweight enough to be not just in Apple Watches, but on little backpacks that you put onto
animals to measure their audio, what they're saying and how they're moving.
Okay, thank you for that excellent, wide-ranging introduction to your current project and one
that I am fully in support of and I find fascinating, which is the Earth Species Project,
one of the many hats you wear. And so now if you could go back to your example of Japanese
and German mapping and let me know what you're working on and what your hopes are and what's
going on with the Earth Species Project. Yeah, and just before I dive into the full Earth Species,
I wanted to finish a final punchline with Dali and how that works because we've now talked about
how you can take languages and turn them into shapes, match them together to do translations,
but how Dali works is actually very similar. You build the shape for images, you build the shape
for language, you then run over the internet and you look at images and captions and you say,
okay, this point in image space goes to this point in language space and you do that again and
again and again. It's not a rotation, but you're finding a way of mapping, of aligning the shapes
of images and the shapes of language. And from here, you just say whatever you want,
portrait of Chile as a person. That goes into a point in language space, which then gets converted
to the point in image space and you ask the computer, make the image that represents this
point and it does. That's how the technology works. And why I find this so profound is it's
not just that you can map one language to another, it's that you can even do translation
across modalities because what is translation? Translation is a transformation that leaves
meaning the same. And why this is so important is, you know, just to give an example from
sperm whale, a number of, I should say, some scientists, this is definitely not the consensus
view. I just like to think about it because it broadens, it expands the aperture of when we say
language, what could we possibly mean for non-humans that when sperm whale, you know,
they have these incredibly powerful clicks, so powerful that if they want to, they could just
shake your body to death. But when they click and then they do echolocation on you, they get back
a full 3D model of you, right? They see where your bones are, they see how much you've eaten,
they see where your organs are, that maybe when they speak, they are speaking not as sort of
representational language, but they're just beaming back and forth sort of 3D sound holograms,
just images. They see an orca, they beam the orca to the other, the sperm whale, and so it's
important because the punchline of you can take English and Japanese and Esperanto and finish
and Urdu and Aramaic and fit them into one universal meaning shape is that as we gain the
ability to build these shapes for animal communication, you can see which parts overlap.
Does say sperm whale or beluga or raven or orangutan do, does that, does the shape of
their communication fit anywhere into the universal human meaning shape? And if it does, we can get
direct translation to the human experience and we'd expect some part to do that because animals,
they share grief, like pilot whales will carry around their dead young and push them up to
the surface for weeks. There are five species that go through menopause, one human, four whale,
narwhal, pilot whale, orca, and beluga. All of those species like the have culture that gets
passed down. They have dialects. Grandmothers are the culture holders. So if you have a really
knowledgeable grandmother, their grand offspring survive more. So we have that kind of family
structure like apes, if you show them magic tricks, they will show joy and incredularity when you
make a ball disappear, when they didn't realize it. So we share that. There is a lot. Actually,
lemurs will take centipedes and bite on them to get high. And they go through this whole
trance like crazy thing. It's incredible to watch as Google like lemurs getting high.
Dolphins will inflate puffer fish and pass them around to get high.
Oh, my God.
It's like the ultimate puff puff pass. And let's see. There's one more. Oh, and of course,
like you put like dolphins in front of a mirror and you paint a white dot on them,
they will look into the mirror and see the dot, which they hadn't seen before. And they'll try to
like rub it or get it off. They'll look inside of their own mouths. Magpies do the same thing.
Elfins pass. So they have a rich interiority, a self-awareness. You have to look in a mirror
and understand that that thing I'm looking at is me in order to pass the mirror test.
So there's a lot that's the same. So we should expect part of that shape to overlap.
And of course, part of that shape is like their world is just so different than us. Dolphins can
speak to two different animals at the same time. They can bifurcate their communication stream.
That's something we cannot do. We expect some part to not overlap.
So it would be like I was talking to you right now, but also talking to my
program manager and talking about our project and doing both simultaneously.
Yeah. Well, to be very specific, what is known is that they can bifurcate their stream and hit
two different targets at the same time. It is unknown whether they're using that as a full
communication channel for both streams. So I have a ton of questions. This is a naive hypothesis,
wouldn't? So you said that Japanese maps to German maps to Aramaic, etc.
And your project is to try and understand what these other languages in non-humans
look like. First of all, and then how do they relate to human languages?
And ultimately, I think your goal and one of the reasons that I'm keen to help you
is wouldn't that be a change in consciousness for our culture if people started to recognize
deeply, emotionally, that we share this planet with 10 million other species? Many of them
are self-aware, conscious, and have rich vocabularies and languages and daily interactions the same
way we do. So then we extend the boundary of our empathy to other humans. That's a long shot,
but that is the shot that we have to take in the coming century, in my opinion.
So Godspeed to you on that. But my question is, wouldn't it make sense that from an evolutionary
standpoint, the nearer in time historically that we diverged from our nieces, nephews,
and cousins in nature, the closer our language would be. In other words, the other great apes,
Bonobos, Gorillas, chimps would map the closest relative to dolphins and cetaceans,
which is what, 70 million years ago, the split or something like that of a common ancestor.
Do you have any hypothesis or information on that, or what do you think?
I think you're likely correct that the closeness of communication between primates and humans,
like we share an Umveld more closely than we do with say whales. So there are communication,
it seems like a good hypothesis. An Umveld is like your worldview, like how you experience
your world through your sensory apparatus. And that's obviously very different for say a bat
than a human, because a bat is mostly seeing, especially at night, in echolocation and sound
imprints. And dogs, like a major portion of their Umveld is via smells, how they relate to the world.
And so our different ways of relating to the world means we're going to have different
representations, which means we're going to communicate about it differently.
And yet this is why I started with that example from sperm whales communicating maybe
in like sort of 3D sound holograms, because these tools that have been talking about like Dolly
let you translate across modalities. It's not even just we're translating from one language
to another, we're translating from images to language. And that gives me hope that even
something as distant as a dolphin or a whale, we can begin to map because we can do cross modal
translation. So dolphins don't have the added benefit as the whales, right? One, just I think
this is mind blowing, humans have been around communicating vocally for 100,000 to 300,000
years. Dolphins and whales in their current form have been communicating vocally, passing down
um culture for 34 million years.
34 million years passing down culture, how do you know that?
Yeah. That's when they like the current form of dolphins and whales that use
echolocation, etc. That's when they evolved. And then you look at their behavior, you know,
like humpback whales have pop songs, they will, there'll be a song that'll begin off the coast
of Australia, that whale will travel up and soon it's being sung off the coast of Ireland,
and it'll spread like wildfire to the rest of the population around the world.
And that doesn't always happen. It just depends on when it's particularly catchy.
What is your grand hope with this project? What are the objectives of Earth's species
project? And in a perfect world, if everything aligns and you get sufficient funding and backing
of scientists and data, what do you hope to accomplish?
You know, I think I and everyone on my team is really, and I should just stop for a second
and point out that like you're hearing just me speak, but I'm really just like the fruiting
body of like a fungus network, which is many biologists, many institutions. We have an incredible
AI team. I have two other co-founders, Britt Selfletell and Katie Zakarian. And the ideas
you've here developed here, actually for both Center for Humane Technology and Earth's species,
comes from a big network of people like talking with you, Nate, Daniel Smoggenberger, Tristan,
Jonathan Hay. Anyway, I just, I just, it's, I think really easy to confuse that like one person
speaking is the sum totality of it. And that's not the case at all. But you are the fruiting
body that I have on my podcast right now. And you've taught me a lot about this. And I, I am
energized and really motivated by what you say. So what do you, what, what can you envision this
accomplishing? No, all those other people involved noted. So 1968, Roger and Katie Payne
released this album, The Songs of the Humpback Whale. And it's the first time we as a Western
society have heard the art, the communication of, you know, whales. And it has a profound effect.
It creates Star Trek 4, right? Go back in time to save the whale. I grew up never knowing that,
I always knew that humpback sang. It goes on Voyager 1 to represent not just humanity, but
all of Earth. It's the very first thing on the golden record after human greetings.
And it's played in front of the General UN Assembly. And it's sort of the galvanizing artifact
that ends up banning deep sea whaling. It's sort of the reason why we have the humpbacks today.
There are these moments in time that become movements that shift our perspective so we can
see ourselves from outside of ourselves. And in so doing, that shifts our identity, who we think
we are, and our place on the planet. You know, the other classic example of this is
the space race going to the moon. You know, Earthrise and Blue Marble are still the two,
I think, most viewed photos in world history. They sort of dose humanity with the overview
effect. We realize we're at this tiny pale blue dot floating in a mode of light, a speck of dust
and space. It's why William Shatner freaked out after he got back a few months from that outer
space thing. He's like, oh my God, I'd never thought of it this way. Exactly. It just shifts
your perspective on what is meaningful and what did it do to our political environment?
Well, when there's a human being standing on the moon, the EPA was born,
NOAA came into existence, Modern Earth Day was founded, the Modern Environmental Movement
got going, the Clean Air Acts was passed, and that was in the Nixon era. So, and I should point
out, it's not just that one thing, right? It's not like just standing on the moon did all of that.
It came in the context of a larger movement. There was Silent Spring. There was increased
inclusion. We were beginning to understand the ozone hole. So, it's these moments though that
happen within movements that create political will. And that's really a major part of what Earth
Species is about. Well, I think it's almost deeper than that. We talked earlier about antagonism and
hatred of outgroups is one of the prime triggers for our phenotype and what the
overview effect of the moon and some of the things you just said is it allows us to feel as if we're
all one. It expands the boundaries of our in-group. For instance, if there were an alien race to come
and attack Earth, we would do all the things that we need to do now to protect our oceans and to
prepare for the end of growth because there would be a common entity outside of our one Earth. And so
maybe recognizing the brothers and sisters that we share this lonely planet with in all the universe,
all of the known complex life who is self-aware are on this planet. And most of them are in the
oceans. So, carry on with what you hope you can accomplish. Well, you know, I really think of
these new AI technologies as the invention of optics and specifically the telescope
in the sense that the telescope let us look out at the patterns of the cosmos and what did we
discover? We discovered that the Earth was not the center. And I think these new tools are going to
let us look at the patterns of the cosmos. And what are we going to discover? That humanity
is not at the center. And it's that kind of shift to human ego that I think is the core problem to
be solved. That is, even if we invented a technology tomorrow that could draw down all the carbon,
which would be amazing if we should do that, it wouldn't solve the core problem that we would just
invent the next runaway system that would tear apart the world. And, you know, I don't have any
illusion that Earth species is like a silver bullet that's going to make that happen. But I
think it's part of a portfolio of things that can shift our relationship to ourselves. And along the
way, you know, we went to the moon, we got out Velcro, we are inventing a number of technologies
which can help conservation right here, right now and help biologists.
And I can talk about some of those. So I think it's that pairing of, you know, human beings,
like we pride ourselves on language, like the Christian tradition, the universe, like in
the beginning, there was the word. And the Ayurvedic traditions, the universe begins with
own identity. Our identity is wrapped up in language. It's why it's such a political issue.
And so my hope is that by working on this project, and by giving people hope that
communication is even possible, that lets us shift our mythopoetics, change the stories we
tell ourselves, which then shifts our identity shifts our behavior.
I'm fully on board with that. I think we are a can kicking species from the time of Thomas Malthus.
We didn't have fossil fuels from the time of Paul Ehrlich. We didn't have debt and globalization.
We continue to kick the can of what growth is possible. And it's my belief that the next can
to kick is not a physical one. It's not a technological one. It's in our brains. And it's
in our understanding, our connectivity. And what is sacred? Is it traditional religion?
Is it economic growth? I believe it is the natural world that it resides on this planet.
So what would be the intermediate steps if you were to have success with
bonobos or crows or humpback whales or dolphins? First of all, is there a readily available
data to be able to apply AI to start constructing these galaxies of points in AI?
What are the bottlenecks? What's keeping you back from success? And what would be the first
couple or three hurdles to cross? Great question. So generally, we're all little data starved and
especially data that has been annotated by biologists to include whatever behaviors we care
about. So like all the context. Luckily, there's been a big push in the last couple of years as
sensors have gotten cheaper to put tags on wild animals that have video, that have microphones,
that have gyros and accelerometers. So you can start to reconstruct like what say a pot of whales
has been doing for the last 24 hours. A guy named Ari Friedlander who works in Monterey Bay and down
in Antarctica. He's a professor at UC Santa Cruz. Yeah, I met him at our dinner.
That's right. Yeah. What were your impressions? Yeah. I mean, if I wasn't worried about the
great simplification, I would love to have his job. What a fascinating and important thing to do.
Yeah, I agree. And so a lot of our early work is starting to work with biologgers as they're
called on top of whales. We're also working with Christian Roots who works on tool using
crows and putting sensors on many crows in an aviary so we can reconstruct like the motion
paths of every crow turn that motion into meaning. Like what kind of behaviors were they doing?
We have a big project right now on that. Then listening like once you have many animals speaking
at once, the most interesting thing is generally being said when they're in big groups, it would
be really helpful if you could disentangle them. That is to say go sort of imagine like you're
listening to a band. It'd be great if you could like take the vocalist and the guitar player and
the pianist and separate them out into their own individual tracks. It'd be great if you could do
that for say pods of whales or aviaries full of crows because then you can have the individual
stream by which you can start to build these shapes. One of the things I wanted to do if it's
okay. I'm curious if it will come through. It's just play you a little bit of my current favorite
species communication. Yeah, go ahead.
I assume it's some cetacean but it almost sounded like a hyena. I have no idea.
This is a beluga. These are a couple belugas communicating.
When you hear the high fidelity version, it sounds like an alien modem.
It turns out dolphins have contact calls, names that they call each other by,
that they learn the first couple of months, but that's a whistle. It sounds like
belugas when they have contact calls, their names are broadband more like modem packets.
What's interesting about this data one, we listen up to 20 kilohertz maybe.
Belugas are speaking up to 150 kilohertz. That Valeria Vergara who is doing research on to
beluga names and dialects in her study, she had tags on whales that had microphones,
but because the whales are moving around so much and they can speak into somebody else's
microphone, she doesn't know who's speaking or can't disentangle them. In her research,
in trying to understand beluga names, she had to throw away 97% of all of her data.
That's to me incredibly exciting because the oceans are 5% explored. Beluga communication,
at least for this kind of data set, for this reason is 3% explored. This is the next frontier.
A thing we've been working on is if you could listen to say blue communication or elephant
communication or pro communication and separate them out into their own individual tracks,
that would give you access to the super majority of communication data. We just had published in
Nature Scientific Reports, our first paper showing for the first time you can do this in the biocoustic
domain. Not only could you decode or create a map of beluga communications, but over time,
you could see how belugas and crows and elephants and bonobos communication maps like
German and Japanese and Swahili sort of thing. The first thing we worked on was solving this
cocktail party problem so we could begin to open up these data sets. It works right now
in lab-like settings. There's still significant work to be done to get it to work in the wild,
so whether there's noise and lots of other complicating factors.
The other projects we're currently working on are one, the ability to generate novel calls,
can we have a computer learn to speak like a humpback whale or a beluga or a raven and use that
in playback experiments? Could we end up where? You would need a huge data bank
for which AI could access to then make inferences in the same way that we have a
synthetic human that's our friend. You would want to get at least somewhere in that direction to be
able to converse within other species, yes? Yeah, exactly. You could imagine that way before we
understand what any of it means, you could have a whale in dialogue with an AI that are going back
and forth saying something, but we don't know what it is yet. That in and of itself, I think,
would be fascinating. What if the very first thing a whale said to us was, what in the
fuck are you doing to the oceans? What would surprise you if that's what they ended up saying?
Actually, they probably wouldn't swear. They've been around for 34 million years. Either they
have the very best swear words that we've never thought of or they're beyond that.
Here's my biggest fear about your project is that if you massively succeed and you can demonstrate
that other species have other languages which are mappable and we even can begin to converse with
them using some hybrid computer interface, that society will just shrug and go back to their
synthetic humans and energy consumption and that it all worked, but that we shrugged
and missed this opportunity for a change in consciousness. That's my fear.
I think that's a reasonable fear to hold. Then I think it's about how do we bring enough people
along on the journey so that they're invested, that we can create those moments of collective
action and political will to do something. I think the next 10 years are going to get
increasingly bad. The next 35 are moving into exponential suck. The landscape into which
this kind of knowledge lands is changing. I think more and more people are ready and receptive
to make a change. They're just looking for that final straw. I think there are many different
types of final straws of which I hope this is a powerful one. Given what you know about your field
and the broader human amoeba situation, what advice would you or do you give to young people today
who are discovering and understanding the human predicament writ large with energy,
climate, the oceans, other species, everything? What sort of advice would you give to young people?
Three things. One, read D'Nelamedo's Thinking and Systems and Places to Intervene in the Systems
that I wish I could come to much earlier. It really is an important lens to look through
and it teaches you that embedded in our language is sort of the adversary, the thing that keeps us
from seeing things as they are. The book makes the point that in the term side effect, we're already
hiding the thing because it's not like here is the world and we have climate change and systemic
inequality happening to it. It's that we've built a machine that when you peddle the machine,
it will programmatically create these outcomes and so to cause them side effects is to already
diminish their view. They're just as principal as an effect as every other effect. I think, one,
read D'Nelamedo's. Two, acknowledge that we are living in a time of increasing chaos. What is
chaos? Chaos is that you cannot predict what happens next from what is happening now and that's
scary and also hopeful because in chaos, initial conditions matter and that's worth fighting for
is that little changes now can make huge changes soon. I love that. That's what I'm trying to do.
Yeah, exactly. You don't know what your ripples are going to be.
The last is this. In my youth, I don't know how young I am, but when I was younger,
I really idolized rationality. That being rational, I thought was the most rational thing.
And as I've gotten older, I've realized that to be perfectly rational is in fact not rational at all.
What do I mean? I mean that every model of the world is wrong because the world is highly
dimensional. Every model is a dimensionality reduction. So to see the world as closely as you
can, you want to have many different models whose errors cancel out. So we have many ways of knowing.
We have a rationality, which is good at some things and bad at others. We have our emotional
way of knowing. We have our embodied way of knowing. We have our pattern match way of knowing.
We have our social way of knowing. And the best thing we can learn to do is to integrate across
all of those different systems of knowing so that we can get closest to seeing the world as it is.
And as part of that, I strongly recommend building yourself an intentional movement
practice. For me, it's surfing and a strong yoga by investing in your full spectrum being
is the best way to be most effective. What's intentional movement?
Oh, it just means something where you are intentionally moving. So like, like I went
for a bike ride before this podcast, like that. And so as long as you're putting your intention
into the bike ride versus say zoning out and like thinking about something while you're doing it,
you want something which saturates your being and takes you out of your mind and back into your
mind and back into your body. You know, surfing is an example for that for me because now it's
muscle and breath pitted against unnegotiable physics. And I have no choice but to be saturated
with presence versus that thing that when I say presence is the abstraction of my runaway mind.
It's that practice of getting out of my mind that gives me the perspective to come back, right?
There's that phrase staying home versus leaving and returning home are two very different things.
I like that. Thank you for that. So I'm curious how you're going to answer this.
Aisa, what do you care most about in the world?
That reminds me of the Wallace Stevens quote that the most beautiful thing in the world is,
of course, the world itself. And I'll just have to pair that with one of my own,
which is that life is too short for aphorisms. The thing I care most about in the world,
that's a really hard one. But the thing that's most alive for me is-
I know you, in our interactions, I can, I know that you care about a lot.
Yeah. I really care about finding things worth caring about. And intentionally making meaning,
acknowledging that every ideology is wrong, but you still have to live within one and that you
should choose your ideologies and how you move between them intentionally. And that
you do not change when you speak, which you change when you listen. It's an awkward thing
for me to say, having just spoken a whole bunch. But I really care about learning to listen better
because that supports all the other things. It's like the conduit through which care flows.
You can include some of the things we talked about on this call because there were plenty
things to worry about or not. But what are you most worried about in the coming decade or so?
The continued reverse engineering of the human mind is the thing I most worried about.
You sort of zoom out, great filter. Why do we not see other alien civilizations?
Maybe it's because every species, every technological species sufficiently advanced
will eventually turn the telescope of its own intelligence back on itself, reverse engineer
how it works, learn how to open up its metaphorical skull and pull its own puppet strings.
And that loop of pulling your puppet string, which jerks your arm more,
which pulls the puppet string more and you get into this infinite chaotic feedback loop,
sort of like when you point a camera at a screen and you get in that loop.
That I think is terrifying and maybe why other species didn't make it in part.
And that's also the thing I'm most hopeful about is in a clear-eyed, compassionate look
at who we are as a species, in so doing, we can fit our technology around us and our societies
like sort of an exoskeleton glove and serve and support us versus exploiting us.
And whether it is, this is as Buckminster Fuller says, whether it's utopia or dystopia,
we go will be a touch-and-go race and back to the initial conditions to bend the arc of technology
towards the good and the just and the compassionate and the clear-eyed seeing
is, I think, our collective work. Amen to that. Amen to that.
If you were, here's a new question that I'm adding. If you were benevolent dictator
or could make one wish for humanity in our present circumstances, what would it be?
If I could wave a magic wand, I would help people let go of all of their insecurities
because it's our insecurities and our fears that they're the map to our freedoms. They're
the thing that fuses stimulus to response. You want to have that space for reflection where
awareness gives the opportunity for choice. I think it's our insecurities that drive
our ego. If we could let go of our insecurities, we would see exactly how we were showing up
and the way we could change our individual action and our systems to support everyone
and all of our beings because so much of our bad behavior is just insecurity-driven.
Yeah, and I think that dovetails with your comment early about listening
and quieting the ego. It's really hard to do. My friend, thank you for this whirlwind
conversation. I definitely want to have you back. You are a good human being. You know a lot of
crap that I have no idea about and I wish you luck on your journey. Do you have any closing
words of wisdom, advice, closing thoughts? One, Nate, thank you so much for having me
on your show. It's been a real pleasure. As I said, I have learned so much from you.
You've really opened my eyes to a much broader world of how to be less energy and less material
blind to think about the carbon pulse. If there is one final piece of advice or wisdom or thought,
and that is just love to leave the listeners with a Brian enoterm, which is seniors.
So, the genius of an individual, seniors is the genius of a scene of people. I love this as a
concept as the thing we should be optimizing for because we live in a world of increasingly large
interconnected hyper-objects that we cannot fit into one human brain. The only way for us to tackle
these things is through, you know, collective load balancing these problems through our collective
brains. And so, I love walking around with the lens of seniors in my mind.
Excellent. Thanks so much, Aisa, to be continued, my friend.
Thank you so much, Nate.
If you enjoyed or learned from this episode of The Great Simplification,
please subscribe to us on your favorite podcast platform and visit TheGreatSimplification.com
for more information on future releases.
