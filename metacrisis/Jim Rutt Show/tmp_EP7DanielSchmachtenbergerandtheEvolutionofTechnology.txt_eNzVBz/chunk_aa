Howdy, this is Jim Rutt, and this is The Jim Rutt Show.
This is The Jim Rutt Show, and I'm your host, Jim Rutt.
Today's guest is Daniel Schmottenberger.
Daniel's an independent thinker, focusing on the future of civilization,
the sensitivity and potential of our current situation,
and how we may navigate the path forward.
He's also director of R&D and co-founder of the Neurohacker Collective.
Welcome, Daniel.
Thanks for having me, Jim. I'm looking forward to this conversation.
Yeah, I followed your work for some time, and while I keep my eye on several thinkers
who are thinking about the future of our society,
your perspective is perhaps both the most dire and the most hopeful.
Interesting that you can be both.
Yeah, I call that kind of a hard fork hypothesis.
I like that. It's a good way to describe it.
On the dire side, you say pretty explicitly,
you believe humanity is going to end relatively soon.
We don't address some of our fundamental design issues in our social operating system.
Yeah, I basically say that when we look at history,
we see that most of the previous civilizations, obviously they don't still exist,
and they underwent internal decay that led to how their collapse occurred.
And we can look at the way that Tainter studies this, the way Jared Diamond did,
or the way that kind of Strauss Howe, or Baudrillard,
or different models of civilization will collapse to describe it.
But they're just like people have a life cycle.
There seem to be these life cycles of civilization,
and there are certain things in common that lead to their breakdown.
The difference now is that we have a fully globalized civilization,
and rather than just causing local environmental harm that can lead to
a limits of growth issue, we can affect the habitability of the biosphere writ large.
Obviously, we didn't used to have weapons of mass destruction,
so there's a total difference of the capacity for warfare, etc.
So technology, both the globalization and technology,
have changed the magnitude of the issues in a way
where the change of magnitude actually becomes a change in kind.
And yet we haven't figured out not civilizational collapse.
So if we forecast all of the different possible catastrophic risks or existential risks,
there's a lot of them.
And what I would say is that they all are the result of some underlying
common generator functions.
And so as a result, if we just tried to deal with a particular AGI scenario,
or a particular climate change, or a particular biodiversity loss,
or a World War III scenario, we don't buy ourselves that much time
before another scenario emerges because the situation is basically overdetermined.
So we actually have to address the generator functions.
We have to address it categorically rather than just instances.
And if we do that, that becomes the kernel of a new civilizational model
that is radically different than any civilizations here too for,
which is the more optimistic picture.
And this is kind of like a hard fork between very different scenarios.
Yeah, that was what I was going to say.
On the hopeful side, you were basically trying, at least,
to define a new social operating system.
And at least for me, in my kind of naive way of looking at things,
it's still a very rough sketch.
But I can see that if you are able to fill this in,
it may make human life vastly better and more humane than it's ever been before.
Before we get to your specifics, though,
I would like for our audience, and keep in mind that our audience
are smart people, I hope, but they're not necessarily experts on the way you and I
and Jordan and some of our friends talk.
So I want to make sure that neither of us get too far afield in jargon
and that we make sure that we bring substrate issues up before we dive in deeper.
Specifically, I've heard you talk in the past very eloquently
about how human created technology is a fundamental change in the dynamics of the world
and that technology, i.e. human invented technology,
is fundamentally different than evolution
and produces fundamentally different dynamics.
You want to talk about that a little bit
before we jump into the more specifics of where we're at?
Yeah, it's definitely a kind of central thing for us to figure out,
especially when if we don't realize this,
we try and use evolutionary biology and evolutionary theory
to model human systems like reifying theory of markets
based in evolutionary theory and social Darwinism writ large
and that actually in my assessment doesn't work.
A lot of this insight on the fundamental difference of tech and evolution
and highlighting it was something Forrest Landry helped me understand,
but the model goes like this.
In evolution, in evolved systems,
we can kind of think of evolution as defined by three primary characteristics,
which is mutation occurs and then selection occurs,
but selection is two things.
Does the agent survive and does it reproduce?
So survival selection made selection.
And then obviously that is survival and mating within evolutionary niches.
Now, something to understand about that is that the mutation pressures
that are affecting everything in an ecosystem,
there's a kind of evenness of the distribution of mutation pressures,
whether we're talking about gamma rays or oxidation or just copying errors or viruses,
they're affecting all of the lions pretty similarly
and the lions and the gazelles and the plants.
So we don't have radical mutation occurring in one place
and no mutation occurring somewhere else.
And so as you have a mutation that would make a lion faster or any predator faster,
you have similar mutations that have a distribution in the fastness
and slowness of the prey animals.
So then of course, if you get a little bit faster in one
and they say the lion eats the slower gazelles,
then the fastest gazelles reproduce and that leads to doubling down on those genes.
So that's the next part is not just a evenness in the distribution of mutation,
but also co-selective pressures.
And so the advances anywhere lead to a pretty strong symmetric coupling of power across the whole system.
And so this leads to a situation where you do have rival risk dynamics in nature.
You do have something like individual agents doing self-maximization.
Of course, it's not purely that we have a lot of symbiosis.
We have animals that are paying attention to their young
and animals that wouldn't survive if not for the whole group of animals.
But you can model individual self-optimizing agents
and get a certain successfulness if you have this symmetry of power.
So you have this lion and this gazelle are in rival risk dynamic,
but all lions and all gazelles are symbiotic with each other,
meaning the lions would die without the gazelles,
the gazelles would die without the lions.
And as either one makes an advancement,
it drives the other one to make an advancement.
So this is kind of where when we think of social Darwinism,
we think of the idea that competition drives innovation and advancement and those types of things.
The difference when tech comes about is,
so again, these changes in the animals are happening mediated through genetics,
mutation of the genes and then survival and then recombinatorics of the genes.
So the genes are physically instantiated pattern replicators.
When technology, technology, I don't just mean physical tech.
I also mean language.
I also mean social tech, coordination tech.
But so tech in the Sanskrit sense of consciously mediated methods of doing things,
basically things that come from the capacity for abstraction
and creating abstract pattern replicators.
The abstract pattern replicators can change much faster than the instantiated ones can,
and they can change with an uneven distribution.
So when we think about toolmaking starting with, you know,
homo habilis and stone tools, right, which is very different than a chimp using a rock that it finds,
but not whittling a sharper, you know, or chipping a sharper rock,
which is that the chimp or the bird or the whatever it is that's using something can
experientially notice that this thing is better at doing what it wants than this thing is in the
moment. But it can't understand that between all three rocks,
why this one is better at cutting the thing is because of the abstract principle of sharpness
and then say, oh, I understand what mediates sharpness and I can design something with more
sharpness. That abstraction capacity seems to be part of how we define early humans and then
got doubled down in homo sapiens. And it's a different process than evolution of bringing
new stuff into existence. It's not occurring through kind of random mutation and just selective
dynamics. It's occurring through an agent that's actually understanding something abstractly and
intentionally creating it. And so if you think about evolution as the stuff that emerges,
there wasn't a conscious choice to have something emerge. It emerged as the result of
complexity dynamics. So it's unconscious. It's radically parallel. It's radically distributed.
It's radically combinatoric. It's slow. Almost everything fails. But you get a interoperability
of everything. So what makes it through are very self stabilizing complex systems with technology.
It's actually consciously created. It can happen in a local way, not everywhere. So it's not
radically parallel and decentralized. It happens more in a serial fashion. And it creates parts
that are not necessarily in equilibrium with whole systems. And so it really is mathematically
almost an opposite kind of creative process. And the thing is, if you have an evolutionary agent,
like a human that has evolutionary motives, but is now able to say human operating as apex predator
can increase its predatory capacity, orders of magnitude rapidly faster than the environment
can increase its resilience to that predatory capacity. Now we have a fundamental problem.
This is a lion getting 1000 times faster in a hurry without gazelles being able to
make a mutation in adequate time and the lion's eat all the gazelles and then go extinct. And so
we have a situation where technology has broken the power cemetery that is what is necessary for
the metastability of evolved systems. And so you see that not only is there a symmetry of power
between the lion and the gazelle, there's also a symmetry of power between lions and lions and
gazelles and gazelles. The most badass lion is only, you know, two X or one and a half X more
in the median lion. But if we look at Putin's killing ability or Trump's compared to yours or mine,
it might be billions or trillions of times more. And same we could say for economic capacity. And
if you look at sapiens writ large compared to the rest of the biosphere, it's similar. And so when
you think about like, you know, one lion just even if it went rogue and didn't just kill to survive,
just start killing everything it could, it has such limited destructive capacity. And that's not
true. And especially as we get into decentralized exponential tech, one actor or a small group
of actors has really radical amplification of agency. So if you keep having rival risk agency,
rival risk basis for agency, but with very high power relative to the overall playing field,
you end up getting a basis for fundamental instability.
And of course, it's not all all about destruction either, you know, two data points that jump out
at me that we are doing things that we think of as constructive that have to be getting well
near our limits are, you know, for instance, the fact that of the large mammals on earth,
it's now thought that the majority of the biomass is humans plus our domesticated animals. And when
it comes to birds, it's even more radical. It's thought that the domesticated birds represent
70% of the biomass of all birds on earth. And so nothing destructive, specifically destructive
about catching and killing, but we've essentially engineered a technology which has co-opted a
majority or 70% of the energetics and biomass of the bio and it's continuing to grow exponentially,
which strikes me as a very strong signal, which is very little talked about.
Yeah, so this is, you know, kind of a limits of growth thing, as opposed to say a warfare or
terrorism or, you know, intention destructive thing. So think about this, and we think of apex
predators, they evolved to fit a niche. And because their adaptive capacity is mediated
through genes, through concrete pattern replicators, they don't do very well outside of that niche.
And so polar bears don't leave the Arctic, right? And cheetahs don't leave the savanna and orcas
don't get out of the ocean. But because our apex predator capacity was mediated by tools,
and we could make different tools, including different coverings for ourselves, and in
different environments, when we would overkill an environment, rather than have our population
stabilize, we would just move to a new environment and become the apex predator there. And so we
went and became apex predator everywhere, over hunted, and over farmed environments everywhere,
over fished, etc. That is really different than every other animal. And like, again,
if we think of the examples you were just giving was like total biodiversity loss and the relationship
of total animal life in domestication versus wild, if you think about an apex predator like an orca
or a great white shark in the ocean, and how many say fish, it can kill in an hour. And then you
think about a ocean trawler with a mile long drift net. It's just not even like, obviously,
we aren't apex predators, they can't destroy whole ecosystems, they also can't genetically
engineer new creatures. So we have to stop modeling ourselves as apex predators competing
with each other to be better apex predators and take the top because the destructive capacity,
even of not intending to destruct, just of intending to extract, is well beyond the replenish rates
of the system. And on top of that, in our first episode with Simon Dedeo, we talked fair amount
about the rate of social evolution is accelerating. The rate of invention of new technologies, new
capabilities is way faster now than it was just 30 years ago. And if we're already approaching the
