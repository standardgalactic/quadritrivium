Howdy, this is Jim Rutt, and this is The Jim Rutt Show.
Music
Listeners have asked us to provide pointers to some of the resources we talk about on the show.
We now have links to books and articles referenced in recent podcasts that are available on our website.
We also offer full transcripts.
Go to JimRuttShow.com. That's JimRuttShow.com.
Music
Today's guest is Daniel Schmacktenberger.
Daniel's central interest is long term civilization design, developing better collective capacities for sense making and meaning making
to form higher quality choice making towards a world commensurate with our higher values and potentials.
Daniel's an early guest on the show back in EP7 where we explored a wide range of Daniel's thinking, all kinds of interesting topics.
If you're stimulated by this conversation, go check out EP number 7.
Today we're going to be a bit more focused talking about sense making.
And we won't forget that sense making is principally important due to its relationship to decision making and action taking.
So Daniel, welcome back.
It's really good to be back Jim. Thank you for having me looking forward to the discussion today.
Yeah, I think this is going to be great and needless to say it's highly timely.
So why is sense making so important right now?
What I think sense making is always important is we can look at all of the object level problems in the world,
whether we're talking about environmental problems or war or pathways to war or infrastructure issues as coordination issues.
Why are humans choosing the things that they do and particularly large scale behavior type issues?
And that if we want to solve climate change or wealth inequality or whatever,
we have to have humanity coordinating quite differently.
The basis of large scale or collective choice making is collective sense making and our ability to communicate effectively.
And I think that for instance, if we're trying to solve climate change and we're not looking at the attendant issues that are associated,
say the economic issues or the geopolitical issues.
So we come up with a solution that say if the US and Europe were to implement a particular kind of carbon tax and China wasn't
and there was no enforcement mechanism, it would have geopolitical ramifications that are also very problematic.
As long as the solutions we're coming up with to problems are based on that kind of partial sense making,
then you'll have lots of people who care about the thing that is being harmed by the very partial solution that is trying to benefit one thing that actively resist it.
And even if it's not that, even if we had a fairly good solution but we didn't have high quality sense making,
generally where a lot of people didn't understand the issues and were against it.
It's very hard to do anything at scale when you're fighting very high friction of a lot of people disagreeing and not wanting to implement a particular solution.
And right now I would say we're kind of at peak bad sense making.
We're on almost every consequential issue.
Either people have no idea what's true or they're very fervent about what's true in total polar opposition to other people that think nearly opposite things.
You see that in the COVID time with mask wearing and hydroxychloroquine and lockdowns that these got to the level of massive civil tensions in the U.S.
and in other places in the world.
And the question of, you know, is COVID actually an exaggerated mostly hoax or is it a very serious pandemic?
Is lockdown the appropriate solution or does that cause problems that are much worse than it?
Or is systemic racism the biggest issue in America or really a kind of non-issue?
And what are Chinese intentions with regard to the world and how should U.S. relate to it?
Pretty much across all the spectrum of all the most critical issues, there is nothing like shared coherent sense of what is true and what should happen.
And so not only can we not solve any of the problems but then the inherent polarization of the different views on it becomes its own source of civil breakdown.
We're watching a very rapid civil breakdown right now.
And if we can't do a better job of getting people to be able to make sense of the world in a more coherent way and communicate in a more effective way,
then I think we see civil breakdown continue to unravel.
Yep. I'm afraid you're right.
A couple of points I'll toss in is you mentioned scale.
And that's something that I think is fundamental when we think about the problem and that the world is now finally coupled on a global basis at high density.
And that's really only been true since maybe the 1980s.
You look at the growth of, for instance, trade.
World trade previously peaked in 1914 and didn't recover to 1914 levels as a percentage of GDP until the 80s.
Kind of a surprise but true.
Of course, it's continued to grow since and of course the globalization of finance, etc.
And the fact that we are apparently at or beyond the carrying capacity of the earth for our civilization has made the earth itself a global player, right?
And so those things make the game much more difficult.
Hard enough to coordinate in your family, right?
What are we going to watch on TV tonight?
Imagine trying to have to coordinate at a global scale.
And the other is, as you alluded to, the high dimensionality, or we could even call it the complexity of the problems that humanity is dealing with.
These aren't like, how do we make iron into steel more effectively?
And we come up with the Bessemer furnace.
You know, that was a kind of a narrow, limited shot, very big innovation that made a big difference for humanity.
But it's, you know, pretty much one or two dimensions, right?
How to deal with climate change or inequality or how do pandemic spread on a globally highly interconnected network?
Problems of high complexity and problems of high complexity typically are not resolvable by formal analytical methods because the dimensionality of the space of possibilities is too high, right?
We have to proceed by experiment, by heuristics, etc.
Because there are no closed form solutions.
There is no Bessemer furnace for solving climate change, for instance.
Particularly not if we have to address the various domains that you mentioned.
The other, and I think this is somewhat underappreciated by many people, but clearly some of the experts are starting to understand it,
is we have stumbled into a communications ecosystem that was not called for, not designed, that it just emerged, right?
I'm old enough to remember when there were three TV networks and the typical American household watched one of those three at any given hour in the evening
and something like 60 or 70% of Americans got their news from those three TV networks.
What's replaced that has been a cacophony of voices, none of whom have any high status with any high percentage of the population.
I think the other day we were having a chat and I looked up online that Breitbart, for all of its influence, reaches about 5 million unique people directly per month.
So in the old days, that would have been considered a fringe network, but because of its ability to propagate on these social networks
and email and talk radio and all these coupled, highly fractionated networks, we're living in an unprecedented information ecosystem.
I think this is a theme I'm going to come back to, I'd be interested to get your thoughts on it, that this communications ecosystem is just what you'd think any ecosystem would be.
It's a platform for evolution and stuff's evolving very rapidly. That's why I said it was not called for, it was not designed, it's just evolving.
You know, no one directed from on high for Zuckerberg to design Facebook, who God knows what exact reason he actually did it for.
Maybe it was just to get laid, who knows. But it's ended up by good execution and by being at the right place and right time to have created an unprecedented way for people to communicate on a global basis,
which we have no experience in dealing with. So I would put those themes out there as ones that would be interested in getting your thoughts on is global scale, complexity,
and the fact that we have an evolved and radically new communications platform in which to try to do sense making.
Yeah. Okay, we'll come back to the complexity. I'll start with the communications platform.
So, interesting thing about human communication is, even if we're trying to share true information, it's hard to decouple it from agentic interest.
So, if I'm sharing something with you, you're taking it as something that could inform your better choice making, but I'm also taking it as an opportunity to influence your choice making in a direction that's possibly beneficial for me.
So, lying is not a new thing. People have lied or at least just created spin or marketing since forever.
And you can read Sun Tzu and see that the whole idea of narrative warfare and info warfare is a thousands of year old idea and that people actually really crafted how do you get deception right to win war and run kingdoms and things like that.
And then as the media technology changed, the ability to do effective influence increased. Obviously, with the written word, you could scale a message much further and then with the Gutenberg press and then with various forms of broadcast.
And then whoever it is that controlled broadcast has such an unprecedented influence over the whole population. There's so much power to that that those who are seeking to win at the game of power seek to capture and influence the broadcast.
And so we can see that when we look at like broadcast stations being consolidated financially right now by Murdoch or Koch brothers or whatever, that's also not new, right? You see Henry Luce setting up the media empire a century ago seeking to do a similar thing.
Let's own all the magazines. So even when you had that broadcast scenario, there was manipulation that was involved. But from a social coherency point of view, as you mentioned, when there were three channels, it's pretty likely that even if what everyone is seeing has some distortion, they're at least seeing the same thing.
And so they can agree or they can disagree and they did fervently, but they had some basis of shared information about the world to agree or disagree on because most of us have no information about most of the topics that we are passionate about through direct info.
We weren't in Beirut. We weren't in Wuhan. We weren't in DC or Portland when the process happened. All of our beliefs about it are being mediated to us by media.
And in the current information environment, I can find, you know, a Trump supporter and a Biden supporter in two different parts of the country who can scroll their Facebook feed for 10 hours and not necessarily see a single piece of news in common, even though they're seeing news the whole time.
So there's basically no shared reality basis for them to even be in reaction to and democracy just can't work in an environment where people can't have effective conversations and they don't have any shared base reality.
And so we can see that in the US there is no real kind of sense of who are our countrymen where we feel some fealty across, for instance, a left-right divide at this moment that creates national unity and the ability to have something like a democracy or a public or participatory governance.
We have instead so much internal enmity and in-group-out-group dynamics that, for the most part, more enmity than we have towards any external forces, that that's, of course, driving the breakdown and lack of coherence of that system as a whole.
And so when we look at the movement from broadcast to internet, and one of the things we see is like, you were there, you remember well, there was this kind of libertarian idea that that would be awesome because it would remove the ability of a few people who held the monopoly on broadcast
to control the message, everyone could put out their own stuff through YouTube, and maybe the best ideas would emerge to the top, which was like a naive, hopeful thing because when so much content gets produced that there's a billion search results for any topic
and no one could even, like it would take your whole life just to go through the search results for one topic. Then, of course, how do we create algorithms that curate all of this content becomes the central topic.
And so we see that with the YouTube recommendation algorithm and the Facebook newsfeed algorithm, massive machine learning indexing technologies that can actually sort through that.
And then the question is, what is their basis to sort through the information and put it in front of you. And when we had broadcast, the TV couldn't get a lot of information about me directly.
So it had to have very generalized kind of marketing. It could tell more ratings or less ratings. But when I'm on my newsfeed and it can pay attention to what I click on, what I share, how long my mouse hovers over things.
By the time I have liked 300 things on Facebook, the algorithm can predict what I'm going to like better than my spouse can, and then develop a psychographic model of me that is actually better than any kind of psychologist psychographic model of me could be.
Then it curates all the content to my interest, which in a way, but my interest in a very specific sense because these platforms are businesses that have their own agentic interest.
And their agentic interest is that they have a business model that's based on selling advertising, and they sell more advertising by maximizing user engagement, mostly meaning time on site and also sharing and things like that.
And most people don't plan, I'd like to spend six hours on Facebook today, and their life would be better if they got off and went and did something else.
So time on site is usually maximized by getting people to not be in their prefrontal cortex remembering what their plans are, but to get hooked somehow.
So how to put the content in front of me that will maximally hook me ends up being a combination of appealing to emotional triggers and cognitive bias.
When there's so much information and I don't know most of it, my relevance filters are going to pay attention to the things I already know are important, which is going to have me double down on bias.
And the things that scare me or anger me are worth more of my time for kind of evolutionary protective reasons.
So as there's so much content, and there's micro targeted psychographic information about me, and it's curating that feed uniquely to me, not even to a demographic profile, but n equals one optimization to maximize time on site for everyone.
Then everyone gets more bias, and everyone gets more emotionally hijacked.
So you end up in a world where you have not just two competing points of view, but increasingly more fractured narrative camps.
All of whom have less shared Venn diagram overlap with each other.
And everyone is both more certain and more outraged while simultaneously being more wrong because the complexity is such that no one can really do epistemology.
People believe yes or no on climate change or whatever the topic is and almost nobody has tried to read all of the data and model it themselves.
So there's a kind of epistemic nihilism of I can't possibly really make sense of it.
So if I can't make sense of it, there's almost more of an unconscious move to a tribalism of like who are the leaders that I want to be led by and who are the in groups that I want to identify with.
So this environment, this media technology in particular, I think is destructive to shared sense making and to individual sense making in a way that is totally unprecedented in the history of the world and the scale at which it happens.
And then that environment, and it's not that Facebook is trying to make people more radically left or more radically right.
That's a second order effect that's an externality of it trying to maximize their time on site, but using a profoundly powerful AI to do so that's really effective at it that has these very tight empirical feedback loops.
But as it's doing that and everyone is kind of getting more certain and more bias, it becomes easier for other actors that want to move people in a direction to just kind of push them further in the direction they're already trending.
And so then it becomes very easy for other state actors or other kind of, you know, non state actors but that have interest to be able to come and make the right become more right make the left become more left by just feeding them more of the stuff that they're already oriented to going into the chat rooms and being able to exacerbate certain types of dynamics.
And so the narrative and info warfare to turn the enemy against itself becomes radically easy in that information ecology.
Indeed, indeed. Yeah, let me respond to several different points you made, which are good. One, you're right. I've been doing this since 1980. I worked for the source, the very first consumer online system.
And I can tell you, we all thought we were doing great work for democracy and that in the future, everybody might have access to all the information they need and democracy would be better than it ever been before.
How naive we were. On the other hand, I would suggest that there was a phase change that occurred in the economics of online that actually caused it to trend towards the direction that you so vividly outlined.
And that was prior to 2004, 2005, most information sources on the Internet that were of any quality or depth were paid. And so there was an alignment between the person that operated the service and the user to get you the most value as quickly as possible
and get you the hell off because they didn't want to pay for your time online, which was also more expensive in those days.
Around 2004, 2005, the economics changed such that platforms and bandwidth became cheap enough that you could actually fully fund a service at scale by advertising alone.
And suddenly the dynamic that you described came into being where the business model wasn't in alignment with the customer, which is to provide them as much value for as little time online as possible, but quite the opposite.
The revenue source was tightly coupled to time online. So now the platforms, think of them, you know, Google, Facebook, Twitter, etc., have a overriding business incentive to maximize your time online.
And as you say, you add in the new capability to do group of one micro targeting on what hooks you the most, what hijacks your attention to keep you online for as long as possible.
And then to loop back with, I guess you'd call it dopamine hijacking, which is to provide the most vivid, the most insane.
There's been a lot of work on the fact that, for instance, that fake news, which is intentionally designed to be high impact will spread five or six times farther than true news on a similar topic.
And we all know how easy it is to get sucked into, you know, violent arguments on the internet rather than a thoughtful discussion about the pros and cons of a piece of literary fiction.
And so, again, these were not designed in the sense that someone said, hmm, I think we should hijack people's dopamine to make them feel bad about themselves and their neighbors, so that we can have a great business.
It went step by step in kind of a natural evolutionary way from the introduction of fully advertising based products in the 2004 and 2005 timeframe.
And now we get to the next step, which I haven't seen that much about yet.
If we have a system based on dopamine hijacking, if you know anything at all about drug addiction or not so much addiction, but, you know, the adverse effect of certain illegal drugs, there's the concept of dopamine exhaustion.
You know, why do people who inject amphetamines day after day eventually go insane and see their life fall apart?
It's because of dopamine exhaustion.
Dopamine no longer sends a meaningful signal.
You build up a tolerance and you end up in despair, essentially, and depression.
You wonder why things like suicides are on the uptake and why drugs that calm that kind of despair like heroin and other kinds of depressive drugs, you know, a exponential uprise.
Because one of the results of this kind of dopamine hijacking platform is dopamine exhaustion and the related despair.
So I thought I'd put those things in and then again, just sort of point out maybe name something.
The fact that non-state actors and people who are operating in bad faith can use the same tools that evolved for advertising.
I think about that as the affordances of the platforms.
And again, if we think of the platforms as evolutionary contexts, one of the things that starts to shape what gives life in an ecosystem are the affordances, i.e. what can be done.
So once you have micro-targeting that was designed for, you know, rather mundane, you know, trying to sell you a stereo that you don't need or a slightly fancier version of ketchup or something,
those same affordances can now be used for ways that they probably were not anticipated in originally, you know, for non-state actors or state actors or political actors of any sort.
So again, step back a little bit and think about the ecosystem and the evolutionary context in which it provides.
So yeah, it's actually worth just taking a moment on this topic of hypernormal stimuli and dopamine to just simplify radically.
Dopamine is a molecule associated with motivational networks, other things as well, pattern matching and things that we would have motivations,
but kind of feels good to do it again, type dynamics.
And so the things that give dopamine hits evolutionarily are things that also would confer a selective advantage.
And so let's say in a natural hunter-gather environment, pre-agriculture, most of, you know, human evolutionary time has been, it was pretty hard to get salt.
It was pretty hard to get a lot of fat, pretty hard to get sugar because, you know, small amount of berries, lean meat.
And so salt, fat and sugar conferred evolutionary advantage because of caloric density and electrolytes to make it through famine.
So there was an increased dopamine hit on that over, say, leafy stuff that was quite abundant, but didn't have the same kind of caloric density.
Obviously salt doesn't have caloric density, but the other ones.
And so those people who worked hardest to get those things would have made it through more.
So there would have been also a selection for kind of strong dopaminergic response to that.
But that was evolutionarily useful in a time where it was very hard to get those things.
So then we move forward to modern environments where we can make fast food that is just combinations of salt, fat and sugar.
And like run the experiments for maximum palatability, make it not stuff that doesn't require chewing too much.
And we get obesity epidemics because the dopaminergic dynamics haven't changed, but they're no longer evolutionarily adaptive.
Now they're actually anti-adaptive.
And so we basically extracted the dopamine part from the associated evolutionary context and the kind of nutrient part.
And now that creates its own kind of catastrophic risk.
And what fast food is to food and nutrition is the same thing that porn is to sexuality and relationship.
Take something that has a normal dopaminergic process associated with something that has evolutionary advantage for raising kids and bonding and etc.
And just extract the hypernormal stimuli parts devoid of any of the things that would actually be relevant to human life.
And the same is true for what social media relationships are to social dynamics and relationships in general.
And we can see that from a kind of marketing perspective or from a business perspective,
every business owner wants to maximize the lifetime value of the customer and maximize the number of customers.
And addiction is a really good way to maximize the lifetime value of a customer.
And so from the supply side, figuring out how to get marketing that manufacturers demand and even to the point of manufacturing addiction is a straightforwardly profitable thing.
And so we can see a McDonald's or a hostess or a Phillips Morris or whatever could do that well in the domain of chemistry.
But now we have dopaminergic hits that are just as powerful as that that are photon mediated rather than chemically mediated,
can be sent out to everyone, can be personalized to them based on empirical feedback,
and that we can start giving kids with the screens that they're looking at and touching as children
and not control in the way that we would control for you have to be 18 for a cigarette or 21 for alcohol or whatever else.
So I think understanding our susceptibility to hypernormal stimuli and the perverse incentives to optimize hypernormal stimuli
and then for each company on its own to optimize hypernormal stimuli but then for a company that is a curator of other things
where its motive is to maximize your engagement and your engagement with all the things that are maximally sticky for you maximize your engagement for it in total
and to really get that the kind of machine learning AI that's running the Facebook algorithm or the Google YouTube algorithm is a more powerful AI than the one that beat Casparov at chess
that that is maximizing for hypernormal stimuli across every axis for you that it can in the platform.
It's an important piece of context to understand and for us to really think seriously about how do we as individuals and parents and whatever create be cognizant of that
and create some resilience and protection to it factoring how profound it is and as a society how do we start to remove the perverse incentive for hypernormal stimuli
because when we talk about what is a healthy civilization what are the right indices we know it's not just GDP per capita.
I would say one of the inverse indices is addiction the more addiction a society has the less healthy it is writ large and so this is a this a meaningful part of the conversation.
I think that's a very deep insight I don't think I've ever heard it described quite that way but a measure of addictive behavior across all modalities is actually kind of a measure of anti sovereignty.
Yeah exactly.
That's actually deep I'm actually gonna think about that for a second at least in the background but while I'm processing it in the background.
I also want to kind of go to slightly different direction which is you know the result of all this one of the results is fragmentation and destruction of all authority or at least any consensus about authority and replacing it with nothing so far at least
but it's also worth remembering that the good old days were necessarily so good.
Remember there was a book called the best and the brightest talking about the really smart people that worked in the Johnson and Kennedy administrations.
Of course the title was meant to be ironic because those best and the brightest led us into the idiotic quagmire the Vietnam war right and one of the problems with too much agreement is not enough checks and balances in our sense making
and people who think they're the best and the brightest can march us right off a cliff.
I think that's worth keeping in mind too so how to deal with this new emergent world where there is no authority and it's been replaced by nothing.
Probably we don't want to replace it with a single definitive authority the status quo that was so powerful in the top heyday of broadcast say 1965 seems as close as any of the high watermark.
Let's see what other comment that I want to have on that.
Another is that of course this network world that we've created or that has emerged.
I think again I continue to say that nobody planned this thing.
It's just emerged co evolved in a game theoretic sense with a bunch of players that were operating around maximizing money on money return in the context of what is technologically and economically possible has resulted in a lot of good things.
We have now high dimensional exploration of the design space of possible alternative civilizations.
People I have on my show the peer to peer network people talk to have Michelle balance coming on tomorrow again for the second time you know regenerative ecology people.
Political metamodernism like Hansi Freinach who I've had on three times actually did the third episode last week and it'll be out in a couple of weeks and even our game be project which both of us have been involved with at various times.
So we should also always keep in mind that this wide open information ecosystem provides a substrate for good as well.
So when we're thinking about interventions to down regulate the bad we also have to make sure that we don't eliminate the good at the same time.
Okay this is yeah but this very interesting.
I'll address the authority part first and then the things getting better and worse and how you'd address that.
The reason we don't want a single monolithic authority on what is true is the same reason we don't want a single top down world government is because we don't trust anybody with that much power and we shouldn't.
And so one of our best ways of dealing with the corrupting nature of power is to at least keep it in check with other powers.
And so this is one of the reasons why free speech issues are so tricky is should speech be absolutely free.
Meaning should we not bind any kind of speech and we know that like libel and slander and yelling fire in an open building and fake bomb threats are problematic enough things that we actually want to regulate them in some way.
But what about in an environment where the original considerations around free speech in this country were in a time where at most if I was going to say something that was.
Not true and dangerous I might be able to have a couple hundred people hear it in a town hall and somebody else could get up and talk I couldn't have it scale to millions or billions of people through kind of viral type dynamics.
And so in a situation where the things that actually appeal to bias and emotional hijack will get up regulated.
In a way that they could never have been before.
Based on the algorithms and the platforms free speech there's a such a different consequentiality around the wrong information.
Well we should have fact checkers or something like that but then the problem becomes who is the arbiter of what is actually true and what is not true and is there anyone that we would actually trust with that power.
And I would say like a way that I think about it going back in time as you were mentioning to previous administrations where we have a government authority that is going to be the arbiter of truth in an area or.
You know academia or going back to when it was the church is whenever something becomes the legitimate authority on truth for a topic it's extraordinarily powerful.
Because what everyone else thinks is real which is the basis of how they're going to behave is actually like at the bottom of the stack of power.
And so even if a legitimate authority emerges rightly because it's actually earnest and doing better empiricism and whatever.
As soon as it starts to get that power there will be maximum incentive for all of the power players to try to corrupt it and influence it.
In various ways which they usually can because which science is going to get funded is is going to be based on someone who has funds putting money into something that will continue to.
Support or advance them having funds and so even if say a piece of science is technically accurate it's not wrong it might be that only certain topics within a domain that have ROI more associated get funded other ones don't like for instance you know.
Patentable small molecules and pharma compared to peptides or biologics or plant based things and so then the preponderance of research doesn't actually map to the overall space well.
So even things that are true can still be misrepresentative or misleading so this problem of that legitimate authority within a.
Economic game theoretic environment will always get captured or influenced to various degrees and so how do we address that.
I think that's getting damn close to the center of the problem and as people listen to the podcast know I consider myself a Madisonian James Madison somewhat neglected but in my mind deepest of all the founding fathers who.
Set up our system of checks and balances probably not quite the optimal system for the 21st century but his fundamental belief was sooner or later.
You're going to have bad people capture the levers of power and you better build that into your design or you'll regret it.
In the same way when you talk about one world government number of my friends think we should have a world government and I say when we have five planets that I'll be okay with having a world government.
So if one of them fucks up there'll be four others to recover and to provide alternative models for each other so again the very very very important design characteristics.
I want to just say one thing on the one world government.
We need to have governance I'm gonna separate governance as a process and government as a established top down enforcement of rule of law with monopoly of violence.
We need to have governance at the level that we're having effects meaning we have to be able to actually make sense of the effects we're having in factor that into the choices that we're making.
And when we have planetary effects on the atmosphere in the ocean and etc but we don't have planetary governance then we just get multipolar traps.
Where okay we don't want to fish all the fish out but if we can't make an agreement that China or somebody else is going to also follow.
And they're gonna get ahead economically in the ocean still gonna get ruined and they're gonna use that economic benefit to damage us not only.
Will we not make an agreement to manage the comments we actually have to race to fish all the fish out faster than they do or make weapons faster than they do or whatever else it is it's exploitive.
And so not having global governance when we're having global effect leads to catastrophe but having global government of the types that have only ever become corrupted and then as a result.
Broke down also leads to catastrophe and so we need something that is different than either of those things that have been imagined so far.
I think that's pretty much bang on or we need to be very clever in creating emergent networks that essentially produce coordination without actually having mechanisms of governance and that's a fairly subtle job.
But as an example I think you actually mentioned it somewhere earlier.
Suppose China doesn't conform to carbon neutrality and the rest of the world does.
The rest of the world could use massive tariffs on implicit carbon to stifle trade from China until they do come along.
So there's a way to essentially set up a signaling system in which we get the coherent behavior without actually having formal institutions of governance or mechanisms of governments.
So again that's at least one area to think about a little bit.
We talked about free speech and this is something we really do have to think about.
Again as a Madisonian there's a reason the First Amendment is the first one in the U.S. Constitution.
And I do believe that free speech is hugely important and that giving large powers the ability to suppress speech is dangerous.
But nonetheless I think there's at least one line that I think most of us can agree on.
And unfortunately this is what's propagating most rapidly now on the nets.
And that is speech that is made in bad faith.
I actually remembered something that you said about what is good faith.
And then I'm going to read this back to you and maybe you can react to it.
That there is a correspondence between the signal that you're commuting cating to me and what you believe is true.
That strikes me as a good definition of good faith.
And yet we have people like the Russians meddling in our elections or the oil companies putting out false narratives about climate change,
which seem pretty clearly to be bad faith discourse.
And it strikes me that bad faith discourse is to the mimetic sphere what pollution is to the ecosystem.
And that if there were a way to detect bad faith discourse, that would be the first line to draw.
Yeah, I mean, yes.
And it's tricky.
I would say that the information ecology is polluted both intentionally by what you call bad faith discourse where someone is sharing something they know isn't true.
And unintentionally where people are sharing something they think is true that's just really wrong.
And both of those end up damaging the information and epistemic commons.
But who's going to then be the arbiter of what is actually true and how do I know what someone else's actual intent was?
Maybe if I find a whole paper trail that shows that that person knew the thing wasn't true and was setting the thing up as a psyop, sure.
But oftentimes it's very hard to prove intent, especially when the actors are hidden behind several layers of sock puppets.
So now we have to say, OK, well, is it about a judge or some kind of centralized authority that should be able to tell if something's bad faith or not?
Or is it about increasing the collective intelligence that is aware of and sensitive to these things where everyone is doing it?
And those things simply don't trend in the same way.
And this starts to get into the kind of answer and theory of chains that I'm particularly focused on these days is we have this system, you know, a republic or a democratic type system of participatory governance that wants everyone to be able to participate in governance
rather than just be ruled by one or a few people.
And if we look from the beginning of what we call civilization, we exclude Dunbar number tribes because it's a very different phenomena, very few civilizations since the beginning of civilization till now have been republics or democracies.
They've almost all been feudalistic or autocratic of some kind.
And that actually makes sense because one guy ruling everything or some very small number of people that can talk coming up with a consensus and then being able to rule is way easier than getting a huge number of people,
mostly who are anonymous to each other to all actually be able to make sense of the world and coordinate like a large number of people coordinating is actually a very expensive tricky thing.
And from the way I see it throughout history, the few times democracies emerged, they emerged following cultural enlightenments that had a few things in common.
When we look at the Athenian democracy coming out of the Greek Enlightenment, stoicism plus the Aristotelian school and you know a few things had caught on to the place where they had a cultural value around education that everyone would learn formal logic and everyone would learn
rhetoric and history and you know those types of things plus the kind of stoic culture where they're all learning emotional regulation
and the Socratic method where they're learning how to take each other's perspectives debate any side of a conversation.
Well, if I have a bunch of people who are trained to be able to assess base reality clearly on their own,
they have emotional regulation so they are not as susceptible to emotional and cognitive hijacks and group think and have the courage to disagree and things like that.
And they can take each other's perspective and they're actively seeking to.
Well, those are the prerequisites to something like a democratic system being able to emerge because those people can have a good quality conversation about shared sensemaking,
recognize that some compromises to agree are better than warfare with each other and come up with solutions so collective choice making emerges out of the collective sensemaking,
meaning making and conversation ability.
And our country similarly coming out of the post European Renaissance Enlightenment phase was, you know, the idea of Renaissance men, Renaissance people who could have expertise across a lot of topics,
not just be specialists, because specialists across different domains have a hard time being able to communicate really effectively towards governance that requires looking at a lot of those things.
But the idea that we could become Renaissance people that we could all have empirical capacity, the scientific method and the Hegelian dialectic that we could hear a view and then seek the antithesis to that thesis and then seek a synthesis,
some higher order reconciliation, that again gives rise to the possibility of participatory governance.
And you can see when you read the documents and the letters of the founding fathers and of course there was a lot wrong with the Athenian democracy and a lot wrong with our country that had genocide and slavery as parts of its origin,
but the whole world had genocide and slavery as parts of what were going on at the time and it was at least moving in the direction of increasing participatory style governance.
The thing that the founding fathers talk about so much is the need for very high quality universal public education and very high quality fourth estate that's independent or news as the prerequisites of democracy.
George Washington said, I'm not going to quote exactly, it's something to the effect of the single most important goal of this government should be the comprehensive education of every single citizen in what he called the science of government.
And I think the science of government is such an interesting phrase because we've separated science and the humanities so formally.
And the science of government would be history and game theory and political theory and the things that people need to know the shenanigans that happen so that they can prevent them.
And Franklin said, if I could have a government without news or news without a government, I would take news because if the people really know what's going on, they can self organize and overthrow government.
If the people don't know what's going on, they can only be captured.
And our public education or education of any kind here in the kinds of civics that people would need to really understand what's happening in government and understand regulatory capture and be able to bind it obviously is close to non existent.
And the news has been mostly captured by economic and political interests.
So there is no chance for a bunch of people that identifies being in almost tribal warfare with each other who aren't sense making reality well who don't understand governments who don't really understand markets, who only have pejorative straw
man's of each other and don't seek each other's opinion, those people can't do a republic or democracy.
So it will simply devolve back to an autocracy, which we see happening.
And the way I think of it is like, if there's a bodybuilder has a huge amount of muscle, the moment they stop working out, they start losing it because it's very expensive metabolically to keep that much muscle.
They have to kind of keep working at it.
It's very expensive to keep an entire population comprehensively educated and actively engaged.
And once it seems like the government's working well and a generation passes and the kids didn't go through the pain of the Revolutionary War and the grandkids didn't that it becomes very easy to just get engaged in your own stuff and not keep participating in the governance.
And then you stop having a government of foreign by the people and you start having a class of people that do government.
And when the people stop checking the state, the state stops being able to check the predatory aspects of the market, which is what it's really intended to do.
And then the market ends up capturing it.
You get regulatory capture and then rather than a liberal democracy, you get a kleptocracy that eventually becomes an autocracy.
And that's what I see that we have right now.
And so do I trust any particular authority to arbitrate truth or good faith or whatever right now?
No, do I trust a collective intelligence that's actually increasing in its authentic intelligence?
I would trust that much more.
It's an expensive hard proposition, but I don't see any other good choices.
Yeah, and I think I agree with you.
A key part of my own thinking that's been formulated over the last year or two is that as we talked about earlier, we live in a era of scale and complexity, which is completely unprecedented in human affairs.
And I think it's reasonable to assert that the combination of scale and complexity has made the ability for an individual person to make sense, no matter how smart and educated they are, inadequate to the task at hand.
I read a lot.
I know a lot.
I've been through a lot, but I don't feel myself competent at all to make certain kinds of decisions.
And nor in this era of informational nihilism is it easy to find who the right people are to make these decisions.
That's less true.
If you do some work, you can find people who actually know more than you do.
And so I'm wondering if the founding fathers enlightenment view that we can bring everybody up to the level to be able to make good sense in high complexity and high scale is realistic.
Or whether we ought to be thinking about new institutional structures.
I've been informed quite a bit in the last year by the writings of Hansi Freinacht in his political metamodernism, two very good books, the listening society and the Nordic ideology.
And he makes the distinction between hierarchical complexity.
You can think of that as kind of mental capacity and code, which is our institutions and operating systems.
And, you know, he'll admit when you push him and I pushed him some in interviews that hierarchical complexity can only be moved a little bit in any one generation while code can be moved quite a bit very substantially.
We have things like the French Revolution or the Russian Revolution where totally new codes were developed, not necessarily always for the better, but code is much more malleable than hierarchical complexity.
And so maybe in addition, because I do agree, we absolutely have to upgrade the education and thinking tools for people, but might not.
We also have to think carefully about new institutions that take into consideration the fact that we're dealing with unprecedented complexity and scale.
And what I've talked about a fair amount and I continue to believe might be an answer is so-called liquid democracy, where instead of myself having to become a good enough expert on 30 different domains to make some form of decision about it,
I can proxy my vote to someone who I believe knows more than I do and is aligned with me on values and then under liquid democracy that person can reproxy the same way.
And so that the preponderance of our decision making power, at least in the political realm, gets concentrated towards more informed people and yet people who are still aligned with us on values.
And of course, the other nice thing about liquid democracy is to degree you believe that one of your people holding a proxy is no longer doing a good job for you.
You can change your proxy at any time or you can reclaim it and just for a single issue if you want.
While I may, you know, proxy my defense vote to my uncle who was an Air Force colonel, I may choose to hold for myself the question on whether we should go to war in Iraq or not.
And I'm thinking that code may be more malleable than actual individual human hierarchical complexity.
So, in terms of exploring how much can we change at the level of the individual how much at the level of the communication protocols for collective intelligence and how much at the level of the actual types of shared choice making systems that might be different than just kind of current representative democracy.
What we're talking about here is the context because we've set the context of the damage to the information ecology, but we're also talking now about the increased complexity of the issues.
And I think we should actually just build out the understanding of that problem a tiny bit more because it affects the way I think about it.
The solution is all right.
Absolutely.
Because you brought this up at the beginning and I wanted to come back to it.
So, partly it has to do with scale for sure, which is the founding fathers thing here.
There was an idea that everybody could go to the town hall and discuss the issues that were mostly geographically close to them that everyone could sense base reality on their own.
And you could have a small enough number of people in the town hall that for the most part the people who had something to say could actually say something about it.
And when we move to a place of most of the issues are globalized, whether we're talking about finance or supply chains or environmental issues or geopolitical ones,
obviously that's a level of complexity where people can't depend on their own base sense making and they can't process that much information and second and third order effects and confounding effects as well.
And one topic I'll just enter here because we haven't discussed it yet is the concept of hyper objects, which is connected to but a little bit distinct from just raw complexity that we evolved to be able to apprehend and understand objects that were available to our senses.
And when I'm talking about something like climate change, I can't see climate change.
I can't taste it.
I can't hear it.
I can only conceptualize it.
I can see a drought.
I can see a fire.
There've always been droughts and fires, but to understand climate change, I have to think about some kind of statistics and complex mathematical models on the droughts and the fires.
I also can't see world hunger.
I can see a hungry person somewhere, but I can't actually directly apprehend.
I can only do it conceptually, which also means I don't have the same felt visceral experience of the things.
And the same is true with I can't actually directly see or apprehend AI risk or biotech risk or nanotech risk or the nature of markets.
And so we have a world where the most influential things are mostly all not apprehendable to the senses.
And so we have not just the issue of can we have a better felt sense or intuitions are more right.
There are kind of sensibility of what's likely true, as well as our kind of formal and analytic thinking.
Can we get hyperobjects, but then can we get the connection of lots and lots of hyperobjects, markets interacting with social media environments, interacting with climate and things like that.
And I think it's just important to kind of state that to have a sense of how different the problem space of the things that we need to understand and think about are now compared to the evolutionary problem space.
Most people had to think about and how different the kinds of collective sense making need to be and choice making need to be.
And then I'll also step back and say, even in environments where we weren't dealing with as much in the way of complexity and hyperobjects,
our sense making was actually usually still adequate to solve local problems in ways that very often caused other problems somewhere else or down the road.
And this is an important part of understanding this is like the model that we can look at all of our problems as a result of either conflict theory or mistake theory.
Conflict theory, meaning we know we're going to cause harm somewhere and we're doing it anyways for game theoretic purposes.
Mistake theory, as you were mentioning with Facebook, we didn't know this was going to happen and it was simply an unintended externality.
So we have to deal with both moving forward.
How do we remove the basis of conflict theory so no one is motivated to do things that will knowingly harm something else?
And how do we also deal with the mistake theory of being able to anticipate externalities and internalize them into the design processes better?
And so the mistake theory side, you can go back to, we didn't necessarily know that the development of stone tools would lead to us becoming apex predators that were increasing our predatory capacity faster than the environment could become resilient.
That led us starting to extinct species at scale and then becoming the apex predator in every environment and start the Anthropocene.
Or you can come to a closer one and say, when we were making the internal combustion engine to solve the problem of the difficulty of horse husbandry pulling buggies,
we didn't anticipate that in solving the horse husbandry problem that we'd be causing climate change and oil spills and wars over oil in the US petrodollar.
And so typically, if we're going to make a solution that solves a problem, the solution has to be somehow bigger than the problem, faster, whatever, to be able to scale and overtake it to really solve the problem.
But if we define the problem in terms in a narrow way, there's one or two or some small number of metrics and the solution we're trying to create has a first order effect on a small number of known metrics.
But it might have second and third order effects on a very large number of unknown metrics.
We can see that the safety analysis is actually harder and kind than the solution analysis.
And this is something that we actually have to start factoring is, I don't just need to understand the problem I'm trying to solve.
I have to understand the problem embedding landscape of the adjacent problems and the adjacent topics and the adjacent meaningful things.
And I have to start thinking through second and third order effects better, whether I'm designing a proposition or designing a piece of technology or designing a company to solve a problem to say, if that solution is effective, what other things is it likely to do?
And what harms could that cause to complex environments?
And then how do we actually factor that into the design process?
Yeah, all true. But how the hell do you get a human to actually be able to process at that level?
And again, the humans aren't going to get smart enough to do that. None of us can do that, right?
And so the answer has got to be, as you keep pointing to some form of collective sense making and collective decision making that's high fidelity and in congruence with reality, I think.
I mean, I don't feel any sense that education plus a better child rearing environment at home is going to get anybody to be smart enough to deal with that constellation of issues.
Well, so notice, as you said that, you know, you and I are probably more oriented to try to sense make the world an average population and have better educational resources, but still can't make sense of everything.
But you also notice that when we talk, I know that you know things that are important that I want to know that I don't and vice versa.
So I'm actively seeking to try to understand your opinion.
And so there's an interesting balance that is important to understand that is that one of the dispositions beyond empiricism that orients towards the capacity for collective sense making to emerge.
I'm neither oriented for agreeability nor disagreeability with you, because I'm actually oriented toward respect relationally, but then also respect to reality objectively.
So there's like a intersubjective and an objective respect.
So my objective respect for reality is I'm not going to agree with you if you're wrong, but I'm also not going to listen to you where you might be right.
And so I want to listen in good faith, seek to understand what you understand, push back where that's relevant, not because I have a disagreeable personality and I want to push back or have an agreeable personality and I want you to agree.
But because I care about what is true enough and I'm in good faith with you enough that we can seek better understanding together.
So the enlightenments that I'm talking about are not just people being able to have better objective sense making, but also better intersubjective capacity that leads to higher quality conversation so that collective intelligence can start to emerge.
So you're mentioning being able to find somebody that knows.
And first, let me just say, before we discuss a perfected system, we can just discuss how to stop some of the most egregious things about the current system.
Current system, people are radically certain about things that they have no basis to be certain about, and it's actually their false certainty that causes most of the problems.
If they simply acknowledge that it was too complex and they didn't know, they at least wouldn't be going to war over dumb stuff.
And so to simply be able to have people be like, I don't know yet, but I'm interested and I'm going to try to seek to know better would actually slow the rate of breakdown tremendously.
I believe that the phrase I don't know is one of the most important phrases in human collaboration.
It's interesting when you read scientific papers, the word it is not yet known appears at high frequency and the better the science, the more frequently it appears.
Right. This is one of the things that is a value I really want to have come across as people having a mature relationship to the topic of certainty.
And I think it's easy to get it wrong in both directions, which, you know, a disposition to want to be more certain because either I think the certainty gives me security or I seem smart or something like that just makes us bad sense makers and makes us dangerous.
And so the fear of uncertainty and the desire for excessive certainty, excessive meaning more than the desire for certainty that has us jump to it before we've done the right epistemic process is dangerous.
But the compensation, right, there's a kind of postmodern trend that takes any certainty is probably some kind of imperialism and only holding uncertainty as virtue also doesn't give the basis to act.
So what I want is to say I'm comfortable being certain and my certainty will never be 100% but it might be 99.9% depending upon how much experimentation I've done relative to the thing.
The fact that it's never 100% means that I'm always open to the possibility that there's data I didn't factor that's important.
But I also need enough certainty to act where inaction is also consequential.
So factoring that action and inaction have consequence and I have an ethical binding both to the quality of my action and the results of my inaction.
Then I want to say, Well, how do I get enough confidence to make the right choice for this particular thing factoring the consequentiality of the thing.
And do I want to be comfortable with uncertainty and I want to be comfortable with relatively higher certainty through the right epistemic process that informs right action.
Absolutely. And I would also say that the very important one that you mentioned that most people do not build into their sense making the decision making is the cost of inaction.
You know, and I had a long and interesting and fun business career and I think I was more successful than most and one of the reasons was I very carefully calibrated about that.
How much information and how much certainty did I need to pull the trigger?
You know, if this was something where if you don't decide you're fucked, then you decide when you're at 40% because the alternative is worse.
There are many times when you're at 52% you should pull the trigger because frankly the downside isn't that bad.
Maybe you'll lose some money.
So what if the stakes were higher, maybe it's 60%.
So anyway, to calibrate how much certainty you need to pull the trigger is one of the great skills of decision making, which is not taught by anybody that I've ever seen.
I fortunately was able to sort of pick it up by getting my MBA with real bullets, so to speak, in the real business battlefields.
But if we made that part of our, you know, education and epistemology, that by itself would be huge, right?
And of course, it would totally attack the fundamentals of American politics in which it's always the right thing to do to kick the can down the road, not confront it, no matter what the costs are for kicking the can down the road.
Yeah, now this is a tricky thing is there's almost a negative gradient problem here where the people that do less good thinking come to certainty faster and then make actions faster.
So if someone doesn't want to make the wrong kinds of choices, so they want to actually do deeper sense making first, then if someone takes that too far, they're just seeding the control of the world to people with the worst sense making.
In the most action bias. And yet that doesn't we don't want a multipolar trap where everyone just says okay I'm pretty sure I'm right so I'm going to go for it.
So this is why that balance of there is responsibility for inaction as well as action and different things have different consequentiality like what confidence do I need that this is going to be a better recipe to experiment with how much spice I put in the food,
not that much because at worst I ruined the meal, but how much confidence do I need that a particular application of AI is actually a good one for the world.
Well it should be a fuck ton higher confidence based on much better processes of looking at second third order effects because the consequence is so high and the and the reversibility might be so low.
And this is where we're in a situation where there are market incentives to be first mover, which means to move as fast as possible in some of the areas of highest consequence where we should actually be moving slow and doing really good safety analysis.
And yeah, that's that's a problem.
Yeah, that's it. Unfortunately, you know, it's baked into the current operating system which is hill climbing incrementalism right every player in the AI world has lots of incentives to make a move every quarter at least the shows they're making progress drive their market cap or the world's perception of their importance etc.
And usually the moves aren't that big, you know, GPT three, which is the buzz in AI at the moment, it's a pretty good size move but it's not huge, but it's incremental and nobody stops to really think what a whole series of incremental moves over 10 years is going to result in.
There is no meta system to evaluate these kinds of risks and to keep people from playing the hill climber game theoretic game of incremental moves.
Okay, so this is interesting. Let's let's look at kind of the ascendancy or return to power depending upon the perspective you want to take the China's going through and the kind of.
Increasing fragmentation and descendancy you can see in the US.
Descendancy and coherence at least.
So term limits make long term planning quite difficult.
And we know why we like term limits was we didn't want people to get too much power and corruption and start thinking dynastically of foreign by the people rotating.
But it also does create an incentive for people to do stuff where either for their reelection or simply for their new economic opportunities getting out of the way that they're judged.
They're only going to be oriented to do stuff that will create positive return within the time of their term limit.
Obviously it's even a shorter time limit for directors of corporations that have quarterly decision profit cycles.
And so a dynastic monarchy that is thinking not only about the person's whole life but about their kids can actually do better long term planning.
And if I have left versus right differences where when anyone does something for four years the next four years somebody will undo it.
It's also and whatever the internal coordination costs of the disagreement are so high.
It's also very hard to unify enough to do stuff which is why the US has had a hard time fixing its infrastructure since the 50s in China has built high speed trains all around the world.
And so for a lot of reasons we can say well monarchy dynastic monarchy is just a better system because getting a lot of people to coordinate is really really hard.
And having someone that can do long term planning be able to actually implement with some coherence because there's not much internal descent seems like a better system.
And that system can check its own AI that system can do a lot of things.
Whereas the system where all the companies are competing against each other in a quarterly way and the parties are competing against each other seems to be stuck on a multipolar trap governed situation.
And so this is I actually know a lot of people who've thought about multipolar traps a lot.
Whose only answer is we actually return to monarchy and most of them think a global monarchy run by a benevolent AGI.
And so I think if we right now it's pretty easy to see that if the US continues the kind of left right and all the divides that it has its shaping of the world continues to decrease in relevance.
Probably China's continues to grow and we see that not just China but like Turkey and Venezuela and Brazil and a lot of places have moved to less participatory more autocratic style of governance.
I think we lose the 21st century to that.
And while that is because it's more effective in a bunch of ways.
And I think the only way to be able to have something like a republic or a participatory governance be more effective is if the many coordinating with each other actually produces higher quality results than just a few being able to control the thing.
And that's only going to happen if it can harvest the collective intelligence and there actually really is some high collective intelligence.
So now this comes back to your metamodern question.
Do I think that we can get the hierarchical complexity or the ability of people to process information up?
Yes.
Even before that if I can start getting them a medic immune system to where they aren't just cognitively and emotionally hijacked.
Right now it's mostly not even can they do good epistemology.
It's that they're just captured by narrative warfare.
If I can simply get them a medic immune system where people start to notice how rustle conjugation and lake off framing happens.
Yes that scientific article said something but the news article put spin on it.
Can they notice how the spins occurring?
Yes that's a true statistic but it's cherry picked.
When you look at all the other statistics it doesn't look like that same picture at all.
And people start noticing those kind of info and narrative weapons and become inoculated enough that it's not like absolute lowest common denominator collective intelligence.
That will make a huge shift so we have to factor the kind of mimetic emotional immunity and cognitive immunity topic.
Then better epistemology for the individuals and better orientation towards Socratic dialogue, Hegelian dialectic like seeking shared understanding because of understanding the need to coordinate being less bad than warfare not coordinating.
Then I think we start to get emergent collective intelligence where more sovereign and intelligent people in better conversation start to produce systems of coordination.
To bottom up effect where those systems of coordination produce a top down effect that continues to incentivize that bottom up effect better and you get a recursive process.
Between better systems of collective sense making and choice making and better development of individuals and their communication capacity with each other.
That's a beautiful picture but it's got to fight hyper normal stimulation. How does it escape that trap?
Well that's one of the immune systems that I'm talking about. How do we fight the trap of group identity?
That's a fucking hard one there's a courage required to not agree with the thing where my friends are saying silence is complicity and you're either with us or against us.
To actually be willing to be honest and say I'm not sure I haven't looked at the statistics I haven't made good enough sense of this requires a kind of profound courage and epistemic commitment.
The ability to mistrust my own certainty realizing like this is one of the insights that kind of really got me into this was I was certain about things where I later realized I was wrong enough times that I became very dubious of my own certainty.
And then I recognized fuck I'm clear where I think a lot of other people are wrong.
And I'm clear where almost everyone historically believe stuff fervently that I'm pretty sure they were wrong about flat earth or which God is true or whatever.
And I'm clear where I was wrong in the past.
But there isn't a single belief that I hold now that I can say that I'm probably wrong about even though statistically I'm probably wrong about most of them.
And when I go forward into the future there will probably be some I recognize that asymmetry is really problematic and this is what got me to start wanting to calculate what is my basis for belief and what is the confidence margin.
And where do I believe things more fervently because it's a good story and I get a sound smart or I get to be part of a group or because it gives me security and how can I start to have.
A psychology that is more independent of those things so my belief system is not bolstering me identity wise or existentially.
So that's a kind of psychological emotional mimetic social immune process that has to be part of the enlightenment we're talking about and so basically I'm saying participatory governance is hard.
Autocracy is just easier for a bunch of reasons either we should start designing the monarchies we want to be part of or participatory governance only ever emerged out of and was successful as long as there was a cultural enlightenment that made it possible.
So we either have to redrive a cultural enlightenment to be able to revivify participatory governance or we should start steering the kind of autocracy we want.
The enlightenment we want to drive is not just a cognitive enlightenment.
It is the susceptibility to hypernormal stimuli.
It is a value system around respectful engagement with other people and seeking their points of view.
It's all those things together.
Yep.
Let me get on a couple of point topics and I'm going to turn it over to you because I know you've thought about this more than most.
What are the next moves that need to be done?
First, let's hit on two other topics.
One, we talked earlier about bad faith discourse and then you alluded to the fact that not only is there bad faith discourse, but there's good faith discourse that's just wrong.
And I will say that our current evolved information infrastructure seems to have produced an evolutionary context which produces some very virulent forms of being wrong.
You know, anti-vaxxer being an interesting one, right?
It's like, what the fuck?
A hundred people have died from bad vaccines in the United States since 1950.
Millions have been saved.
How could this even be an issue?
And yet, evolutionarily, a memeplex has been created that has attracted millions and millions of people.
QAnon's another interesting one, a classic example of a evolved artifact that, you know, by any objective measure just seems fucking insane.
And yet, not only do millions of people believe parts of it, hundreds of thousands at least seem to have it as a main hobby in their life trying to do the research, figure out the clues, etc.
And so something, and I guess I would point out, compared to 1965, you are not going to see either anti-vaxxers or QAnon on the CBS Evening News with Walter Cronkite.
The gatekeepers of that era, if nothing else, were good at keeping absolute nonsense out of widespread public circulation.
Then the second point, which you just hit on, is tribalism seems to be what we fall back on when we're so overwhelmed by an information-evolved platform which is driven by bad incentives, plus complexity, plus scale.
And we now just say, throw up our hands and say, fuck it, I can't figure it out.
So I'm Team Blue. Whatever Team Blue believes, I'll believe.
I'm Team Red. Whatever Team Red believes, I'll believe.
We've all seen those big posters with all the logical fallacies on them.
I've come to believe that this epoch of tribalism has made one logical fallacy dominant all over the rest, and that's confirmation bias.
Everything I hear, I would say not me. I'm the one exception.
But let's say the laughing here, ironically, that the mass people who are in the tribes, they compare every fact or item they hear against what's the tribal take on all this, rather than trying to look at something objectively and decide whether they should believe it or not.
So, Daniel, what can be and should be done starting tomorrow morning? What do we do?
Should we start at the level of what individuals can do on their own, or what we could do to try to attack these issues project-wise?
I would suggest a bit of both. And what's, of course, best is where project-wise cycles back to the individual and then back to the project.
But go with what you think is the priorities.
I want to just say one thing first, and this is a funny thing to say, but if we talk about anti-vax or QAnon or any particular view like that, I can really empathize with those, and I think it's important that everyone can.
Because I think most people sense that there are a lot of things wrong with the world and moving towards catastrophically worse,
that those who are in most power both politically and financially don't seem to be doing a good job with, though they seem to be increasing in their own personal wealth or power or whatever else.
So there's a sense of corruption that most everyone senses. It's just then they want to fit it into very simplistic narratives where there's good guys and bad guys and they can be on team good and that kind of thing.
So the right all thinks that the left's news is fake. And the left thinks that the right's news is fake. They each think that the other one's politicians are corrupt.
So the idea that politicians could be corrupt or news could be fake. Well, that's actually true. It's just not true that it falls just along those partisan lines.
It's more that you've got to understand as for anyone to ascend the stack of power, they had to do well at the game of power and there's a lot of things that that involves to do well at the game of power.
And so I think the idea that there is are these institutional authorities and we should just totally trust them has pretty much broken. You were mentioning, you know, in 1965.
In 1965, the people who were live paying attention to the news directly remembered World War Two and their life experience, right?
And that had a kind of unifying basis, a patriotic and unifying basis and an empirical basis. We had to really double down on science and technology to be able to win the war.
But then there starts to be an institutional decay where not that many people who are live paying attention to the news now or very large numbers of them weren't around in World War Two.
And they don't have any real embodied sense of what breakdown in the developed world could look like. And so similarly, they have much more sense of the enemy that is near than the enemy that is far and those types of things.
And then when we so when we look at vaccines, for instance, it's actually a bit of a complex topic because if you're making something that is a drug that's intended to have long term effects as opposed to most small molecule drugs that stop acting after they've left your body.
Could they have long term consequences? And if we've done mostly the studies on individual vaccines and yet they're given in schedules with lots of them together, do we really know what the collective effect of that much immune modulation long term on lots of them together is?
And if at the same time that they've been going up, polio and whatever's been going down, but hygiene and antibiotics have also been happening during that time.
And then autoimmune disease and other things like that seem to be going up is the autoimmune disease and the infertility going up because of the vaccines or is it going up because of the glyphosate or ubiquitous environmental toxins or stress.
Those are actually complex topics. And so it's very easy to say all vaccines are bad or all vaccines are good anti-vaxxers are stupid and neither of those are complex enough to actually make good sense of it.
But the need to take a very strong position because the the other view is so bad and dangerous we have to fight it ends up being the tribalism confirmation bias.
And so and then people only have a pejorative straw man or even worse a villainized version of the other.
They can't even imagine how anyone could be that stupid or bad as to believe that thing.
And of course you can't have participatory governance when that's how you think about the other people you're supposedly part of a republic with or part of a civilization at all with.
So where people start to doubt the institutional authority, there's something good in that.
But then oftentimes what happens is rather than really learn the epistemology needed to make sense of it, they just jump to the new authority and usually the new authority is whoever it is that's telling them to doubt the other one.
And so that's inadequate, they're not actually moving up vertically into more hierarchical complexity, they're just shifting authorities.
I just wanted to say that as preface.
Yeah, that's I think that's a good preface and I will confess that I'm a real neat joker on anti-vaxxer.
Have I done enough research to be absolutely sure about it?
No.
And so I will plead to a little bit of tribalism on that one.
It's the only topic which I have, at least when I was running the show over in Rally Point Alpha, the only topic I which I banned discourse on was anti-vaxxer.
So may Koopa continue.
So and this is tricky because let's say a new person is coming into a topic that has been very well addressed, but they don't know.
Do the people who've well addressed it have to re-go through it every time?
That's actually a tricky topic, right?
From the good use of time point of view.
So in terms of collective intelligence, if a group has done really earnest dialectic to come to a certain confidence margin on something,
the path there, not just the conclusion, but the path there should be left in some intact way that other people can walk.
And then if someone has critiques that are legitimate object level critiques of the actual path there, the conclusions, we should listen.
And that's, I think, how science can continue to evolve is where we can continue to critique our best understanding and have dissent around it without having to repeat the things that have actually been done well many times.
Okay, so your question, what do we do tomorrow?
At the level of the individual.
Forgive me, I'm going to make a religious reference.
The commandment in the Bible to not have any false idols.
The way that I take that, I take it very similarly to the first verse of the Tao Te Ching.
So I think a lot of cultures said something wisdom wise, and maybe maybe I'm just reading it the way I want to read it.
So no false idols.
Any model I make of reality isn't reality.
It's me trying to info compress the complexity of reality into some small number of variables and operators on those variables where I can model the outcome with hopefully enough numerical accuracy that it's useful.
So this is the all models are wrong.
Some of them are useful.
The moment I make a model truth.
Now I'm not in direct relationship with reality anymore.
I'm in relationship with the simulacra.
And so the idol of the models that I have of reality, I want to hold them as useful and see which ones are more useful will never actually having any identity attached to them.
Never having any sense of sacredness attached to them because I know that better ones will come along.
And I want to be seeking those.
So if people can like deepen their commitment to a direct relationship with reality, which binds them to a certain amount of uncertainty.
As a result, be dubious of being over devoted to any models of reality.
That's very helpful.
Like is almost like a sacred oath at the foundation of it.
And then if that's the case, that's what will motivate them to be dubious of their own cognitive biases and emotional traps and when they feel very outraged and when they feel very certain and when they feel a very clear repulsion to a group that seems obviously bad
or a very clear identity with an in group, they should just be dubious of all of that and step back and say, what's the chance?
And what are the possibilities that I'm being emotionally or cognitively hijacked?
And I'm not seeing the whole thing.
If people can just start to actually have a bias checker in themselves as a value, as a discipline, because they want to be in better connection with reality and truth.
And they know that more than more than anything else, it's their own misassessment of it to check.
That's very helpful.
Then they can start to learn tools that will help them of like, okay, let me actually learn some of how narrative warfare works.
Let me understand how Russell conjugation is used by the left and the right or how Lake off framing is used in marketing and on all sides.
Let me see how cherry picking of data works and how the funding of science works in a way that makes the preponderance of data not necessarily fit the whole picture.
As I start to learn that more, I start to be less manipulated by what occurs in the media environment.
And I'll also simultaneously I want to seek dissenting views that seem earnest on everything.
So when you are mentioning that you will seek people that know more than you about a topic, I will try to seek the people that I think know the most and who disagree.
But who seem in good faith about their disagreement because the dialectic between them, I have more faith in than I do in either of the positions singularly held.
And so if I can see where the IPCC has a standard model on climate change, but both James Lovelock on one side and Freeman Dyson on the other side have done quite thoughtful analysis and come to different conclusions.
I want to say, do I understand why each of them came to the conclusions they do well?
Can I facilitate a dialogue between those perspectives to try to maybe have more epistemic flexibility and come to better understanding?
So these are just examples of a few things individuals can do on their own.
One of the things that looks like is just obviously remove the social media apps from your phone so you don't have a continuous drip of micro targeting.
And if you keep it on your computer at all, curate your own feed so that you're using it as a tool more and it's using you less.
So unfollow all of the things that you're automatically following that are not actually enhancing your sense making and then intentionally follow things that represent different views on every topic.
So there are far left moderate left moderate right far right conspiracy theorist other countries views on every topic I follow.
Because I want to get the parallax on all those views one because I want to understand why huge amounts of humanity are thinking those things.
And two, I want to make sure I'm not missing anything where there's partial signal in what they're saying.
OK, those are good. Let me respond here a little bit.
Let's start with social media. You missed one, which I think is key.
I had Renee Derista on the podcast yesterday.
She's a researcher at Stanford on social media exploits by bad actors mostly.
And she pointed out the one thing that we could all do is ask ourselves three times before we share something.
Is this actually good for the world to share this right because what you read is important.
But we're also in social media.
We are actors in the formation of the epistemic commons.
And when we share something or like on a Reddit platform, we upvote something or like something.
We are making a shaping of the commons.
And so at that point, think three times before you act at all.
I would suggest that's useful.
And now in terms of here, will we pivot to more institutional things?
I would also like to comment that, OK, yeah, I understand that if we really want to think through climate change fully and understand, you know, built-in biases, you know, where are the error bars, etc.
It's very good to start with love luck on one side.
Dyson in the middle and a bunch of guys in between process all that data and come to some conclusion on what might be true and what the error bars actually are.
But let me tell you, that's a job over the pay grade of almost every single human being.
Yeah, maybe if I did nothing else for two years, I might be able to do that.
Realistically, I don't see very many people being able to process high scale, high complexity issues in that kind of way, which then pivots me to what can be done institutionally or as artifacts or in groups to accomplish the same thing so that people can consume the result of a process.
Well, as you know, I'm part of a group that's working on building a project to try to do some of this.
And so I can tell you the thing that we're trying to do that compared to the scope of the entire information ecology and the algorithmic bias on these major platforms, what we're doing is actually pretty small and humble compared to everything that needs to happen.
But it's the highest leverage easiest to achieve things I'm aware of as a starting place to then hopefully be able to have more stuff come.
So for instance, let's take that particular topic, the climate change one.
There's both how do we make sense of the realities of climate change?
Then there's how do we make sense of the right choice for climate change factoring the adjacent issues like US China issues and other geopolitical issues and market issues and things like that.
So one of the things that we're doing is in this project that is trying to kind of upgrade and fix the media ecology and remove the effectiveness of the narrative and info weapons by pointing them out.
So as we make the covert things over to they have more ability to be resisted.
So hosting not debates but dialectic conversations between the best thinkers on topics who are earnest who are willing to engage in a non rhetorical authentic kind of sense making process together and who disagree.
Where the facilitator is both skilled in dialectical facilitation but also understands the topic well enough to be able to facilitate it between these people who understand it exceptionally well and represent the variance in views.
And if someone is oriented to just want to win a debate or be rhetorical we don't invite them on they'd have to agree to the kind of dialectic process.
And then we do things like well what do we all agree on like what what is known what is unknown do we agree on what's known do we agree on what things are unknown and then.
Do we have a different weighting on the things that we think are known or unknown but have some probability on why do we have those weightings that lead to why we have different senses of things.
And so can the can the listener who's watching this.
See what the how the best thinkers think about it see where the differences are see where they should have some certainty and where there's where there's uncertainty and get up to kind of the best general sense of where the topic is at.
We're doing one of those right now with different experts on immunity looking at what is likely to occur for covert immunity long term.
And so topics that are both consequential and debated being able to facilitate a process like that that's one example.
And so this does like you said make it where if it's beyond the pay grade of a person.
Can we make an institution that is doing that that doesn't have any other institutional incentive doesn't have a economic.
Or political or whatever kind of bias and is really seeking to simply be a steward of the information commons and is making their process transparent enough that it can be held to that.
And then things so like one of the things that another kind of thing that we're working on is for any topic that is highly polarized but also trending and consequential where it's not just that we can't solve it if we don't have a shared understanding
but where the disagreement itself becomes a source of open violence in the streets which has obviously gotten worse in recently than it has been in recent history and can get much more worse moving forward if we're not very effective at changing that trajectory.
So one of the things is pick a topic and we do this kind of meta news so an assessment of the landscape of narratives sometimes there's really just two narratives left and right one that are dominant but sometimes there's like.
Seven narratives that are really trending that are really fundamentally different from each other.
So do an assessment of here's the primary narratives in the landscape here's a number of different kind of publications or news sources that are clustered together kind of pushing each of these.
And then let's actually steelman each one let's kind of make the best argument for it so that people who don't believe that narrative can see why some other people who do believe it are compelled by it and have a.
Version of other people that is not just villainizing.
Then and where people are starting to learn to seek other people's perspectives and learn to steelman them.
And then an analytic process that so that first process is kind of inter subjective the next one is objective can we break the narrative into individual propositions and can we try to see what evidence was put forward to support the propositions and then can we look at all the
evidence we can find that either support or refute them and what we'll then do is find where is their identifiable signal in all of the positions.
And then where they're clearly falsifiable things and then where is there a bunch of stuff that has to sit as neither falsifiable nor ver verifiable currently is just conjecture for which we should have no confidence one way the other.
And so this is this process is people go through it helps them do things like learn propositional logic learn how to break down a narrative and not.
Reject or accept the whole thing but be able to see there's probably some signal probably some noise and a lot of conjecture and how to calibrate their confidence margins.
And then how to step back and say based on the things that we can identify that are true across these spaces across these narratives what can we probably say about the space as a whole which is a synthesizing process for the earlier one was a analysis process.
So there's a kind of interpersonal narrative intelligence than an analytic empirical intelligence than a synthesizing intelligence all of which are needed to make sense.
So if we can do that with people that get highly trained in that and it's their full time job to do but then also walk people through the steps.
It'll help them make sense of what's going on and to understand why the conflict is there and diffuse the conflict.
And then also show where each of the different sources are employing whether it's intentional or not narrative and info weapons show where they're putting spin on things of what the original thing.
And that was true was and then the way they framed it show where they're doing statistical cherry picking and if they looked at these other statistics how it would change the overall picture.
So that people start noticing the narrative and info weapons and not being and they start to look for them and they look for them across the political spectrum and ideological spectrum rather than just in a tribal way.
If we can do that for people but also walk them through the steps of how we're doing it so they learn how to do it on their own if we stopped being able to do it they could keep doing it.
These are examples of processes that I think can help upgrade the info ecology quite a bit also when we're doing kind of the news itself just base sense making on a topic before we look at the meta news of how everybody else's sense make my representing it.
When we say what we're able to assess will also show our process of what data are we factoring in what epistemic models are we including so if someone wants to see how did we come to that how did we calculate our confidence they can see it and then they can learn the epistemic models.
So can we make it to where you know you and I both know that understanding tainter helps in the way we understand a lot of things in the world or understanding McLean or Gerard or Bayesian analysis.
Things that people didn't get and they're not going to go read all the books to get them can we just can press the epistemic models into the shortest kinds of essays that then also show how to apply and give sense making reifying power.
And then link them where they're useful so that people can start to increase almost like an optimized public education and how to make sense of the world that will empower civic engagement.
So these are these are some examples of basically how do we start to do a kind of broadcast where people aren't trusting it because of some authority they're trusting their own ability to make sense of reality better because we're showing the transparent process and we're increasing their epistemic capacity and not just making sense of base reality but also making sense of the way it's being represented in the narrative landscape.
I think that this has the ability if we're successful and to start de-arming the effectiveness of the narrative and info weapons and the tribalism and the outrage certainty and increasing people's own epistemic capabilities.
Then if that becomes a strange attractor for a group of people that are attracted to that who start to also engage in higher quality conversation you start to get a cultural attractor that could become very meaningful.
Ah, it sounds really good. I really hope you're able to get this going. And then I think then there's a second order effect and third order effect, which is if these artifacts that are created are compelling and have sufficient production values that they can spread virally and
mimetically, then they can compete in the idea marketplace and perhaps push back some less well formed ideas.
Yeah, and I would say even more excited than viral sharing because viral sharing is mostly not thinking right, it's just being mimetic repeaters.
Um, and I know you and Jordan have talked about this, you know, simulated thinking, but for the most part people especially in say the Facebook environment aren't actually thinking they're just looking at the thing and saying does this conforms to my current thinking ideas that I should repeat it or not.
And if it does, then I hit, you know, share or whatever. So most people are just acting as kind of mimetic filters and propagators where thinking would be, is this true? What are the other opinions? How do I know what kind of deeper process do I do?
Research is just the vetting. Is it true? Thinking is also not just looking externally, but looking internally at what is meaningful about this? How would I go about making sense of this?
And so while viral replication has some value, I would actually hope that a success of what we would do would be eventually the end of viral replication in that way.
And instead say some people who started to get much better at facilitating high quality dialogue, at facilitating dialectical thinking and steelmaning different positions as well as empiricism.
And that those people become parts of everybody's friend group and just start to facilitate not just we're sharing this piece of content, but we're facilitating authentically better conversation in all these other environments.
Yeah, I think that's good. But I also think it's a little bit wishful thinking, I suspect because of the issues of the distributions of hierarchical complexity, the number of people who could really deeply think about these large scale complex issues is small.
But there'll be some number that can engage in it and having more engaged in real thinking and modeling real thinking as opposed to simulated thinking will also help up regulate the credibility of the artifacts for people who are going to be consumers rather than thinkers for themselves.
But this sounds like really exciting stuff. I look forward to watching you guys progress. And I think on that note, we should wrap it up. We're over our normal timeline, but this has been such a fascinating and interesting discussion.
As it always is with Daniel. So thanks for coming on board and sharing your thoughts.
It's just fun. Thank you for this sense making platform that you have shared so much with for everybody and having me on.
Production Services and Audio Editing by Jared Janes Consulting Music by Tom Muller at Modern Space Music.
