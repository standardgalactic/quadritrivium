I also want to kind of go to slightly different direction which is you know the result of all this one of the results is fragmentation and destruction of all authority or at least any consensus about authority and replacing it with nothing so far at least
but it's also worth remembering that the good old days were necessarily so good.
Remember there was a book called the best and the brightest talking about the really smart people that worked in the Johnson and Kennedy administrations.
Of course the title was meant to be ironic because those best and the brightest led us into the idiotic quagmire the Vietnam war right and one of the problems with too much agreement is not enough checks and balances in our sense making
and people who think they're the best and the brightest can march us right off a cliff.
I think that's worth keeping in mind too so how to deal with this new emergent world where there is no authority and it's been replaced by nothing.
Probably we don't want to replace it with a single definitive authority the status quo that was so powerful in the top heyday of broadcast say 1965 seems as close as any of the high watermark.
Let's see what other comment that I want to have on that.
Another is that of course this network world that we've created or that has emerged.
I think again I continue to say that nobody planned this thing.
It's just emerged co evolved in a game theoretic sense with a bunch of players that were operating around maximizing money on money return in the context of what is technologically and economically possible has resulted in a lot of good things.
We have now high dimensional exploration of the design space of possible alternative civilizations.
People I have on my show the peer to peer network people talk to have Michelle balance coming on tomorrow again for the second time you know regenerative ecology people.
Political metamodernism like Hansi Freinach who I've had on three times actually did the third episode last week and it'll be out in a couple of weeks and even our game be project which both of us have been involved with at various times.
So we should also always keep in mind that this wide open information ecosystem provides a substrate for good as well.
So when we're thinking about interventions to down regulate the bad we also have to make sure that we don't eliminate the good at the same time.
Okay this is yeah but this very interesting.
I'll address the authority part first and then the things getting better and worse and how you'd address that.
The reason we don't want a single monolithic authority on what is true is the same reason we don't want a single top down world government is because we don't trust anybody with that much power and we shouldn't.
And so one of our best ways of dealing with the corrupting nature of power is to at least keep it in check with other powers.
And so this is one of the reasons why free speech issues are so tricky is should speech be absolutely free.
Meaning should we not bind any kind of speech and we know that like libel and slander and yelling fire in an open building and fake bomb threats are problematic enough things that we actually want to regulate them in some way.
But what about in an environment where the original considerations around free speech in this country were in a time where at most if I was going to say something that was.
Not true and dangerous I might be able to have a couple hundred people hear it in a town hall and somebody else could get up and talk I couldn't have it scale to millions or billions of people through kind of viral type dynamics.
And so in a situation where the things that actually appeal to bias and emotional hijack will get up regulated.
In a way that they could never have been before.
Based on the algorithms and the platforms free speech there's a such a different consequentiality around the wrong information.
Well we should have fact checkers or something like that but then the problem becomes who is the arbiter of what is actually true and what is not true and is there anyone that we would actually trust with that power.
And I would say like a way that I think about it going back in time as you were mentioning to previous administrations where we have a government authority that is going to be the arbiter of truth in an area or.
You know academia or going back to when it was the church is whenever something becomes the legitimate authority on truth for a topic it's extraordinarily powerful.
Because what everyone else thinks is real which is the basis of how they're going to behave is actually like at the bottom of the stack of power.
And so even if a legitimate authority emerges rightly because it's actually earnest and doing better empiricism and whatever.
As soon as it starts to get that power there will be maximum incentive for all of the power players to try to corrupt it and influence it.
In various ways which they usually can because which science is going to get funded is is going to be based on someone who has funds putting money into something that will continue to.
Support or advance them having funds and so even if say a piece of science is technically accurate it's not wrong it might be that only certain topics within a domain that have ROI more associated get funded other ones don't like for instance you know.
Patentable small molecules and pharma compared to peptides or biologics or plant based things and so then the preponderance of research doesn't actually map to the overall space well.
So even things that are true can still be misrepresentative or misleading so this problem of that legitimate authority within a.
Economic game theoretic environment will always get captured or influenced to various degrees and so how do we address that.
I think that's getting damn close to the center of the problem and as people listen to the podcast know I consider myself a Madisonian James Madison somewhat neglected but in my mind deepest of all the founding fathers who.
Set up our system of checks and balances probably not quite the optimal system for the 21st century but his fundamental belief was sooner or later.
You're going to have bad people capture the levers of power and you better build that into your design or you'll regret it.
In the same way when you talk about one world government number of my friends think we should have a world government and I say when we have five planets that I'll be okay with having a world government.
So if one of them fucks up there'll be four others to recover and to provide alternative models for each other so again the very very very important design characteristics.
I want to just say one thing on the one world government.
We need to have governance I'm gonna separate governance as a process and government as a established top down enforcement of rule of law with monopoly of violence.
We need to have governance at the level that we're having effects meaning we have to be able to actually make sense of the effects we're having in factor that into the choices that we're making.
And when we have planetary effects on the atmosphere in the ocean and etc but we don't have planetary governance then we just get multipolar traps.
Where okay we don't want to fish all the fish out but if we can't make an agreement that China or somebody else is going to also follow.
And they're gonna get ahead economically in the ocean still gonna get ruined and they're gonna use that economic benefit to damage us not only.
Will we not make an agreement to manage the comments we actually have to race to fish all the fish out faster than they do or make weapons faster than they do or whatever else it is it's exploitive.
And so not having global governance when we're having global effect leads to catastrophe but having global government of the types that have only ever become corrupted and then as a result.
Broke down also leads to catastrophe and so we need something that is different than either of those things that have been imagined so far.
I think that's pretty much bang on or we need to be very clever in creating emergent networks that essentially produce coordination without actually having mechanisms of governance and that's a fairly subtle job.
But as an example I think you actually mentioned it somewhere earlier.
Suppose China doesn't conform to carbon neutrality and the rest of the world does.
The rest of the world could use massive tariffs on implicit carbon to stifle trade from China until they do come along.
So there's a way to essentially set up a signaling system in which we get the coherent behavior without actually having formal institutions of governance or mechanisms of governments.
So again that's at least one area to think about a little bit.
We talked about free speech and this is something we really do have to think about.
Again as a Madisonian there's a reason the First Amendment is the first one in the U.S. Constitution.
And I do believe that free speech is hugely important and that giving large powers the ability to suppress speech is dangerous.
But nonetheless I think there's at least one line that I think most of us can agree on.
And unfortunately this is what's propagating most rapidly now on the nets.
And that is speech that is made in bad faith.
I actually remembered something that you said about what is good faith.
And then I'm going to read this back to you and maybe you can react to it.
That there is a correspondence between the signal that you're commuting cating to me and what you believe is true.
That strikes me as a good definition of good faith.
And yet we have people like the Russians meddling in our elections or the oil companies putting out false narratives about climate change,
which seem pretty clearly to be bad faith discourse.
And it strikes me that bad faith discourse is to the mimetic sphere what pollution is to the ecosystem.
And that if there were a way to detect bad faith discourse, that would be the first line to draw.
Yeah, I mean, yes.
And it's tricky.
I would say that the information ecology is polluted both intentionally by what you call bad faith discourse where someone is sharing something they know isn't true.
And unintentionally where people are sharing something they think is true that's just really wrong.
And both of those end up damaging the information and epistemic commons.
But who's going to then be the arbiter of what is actually true and how do I know what someone else's actual intent was?
Maybe if I find a whole paper trail that shows that that person knew the thing wasn't true and was setting the thing up as a psyop, sure.
But oftentimes it's very hard to prove intent, especially when the actors are hidden behind several layers of sock puppets.
So now we have to say, OK, well, is it about a judge or some kind of centralized authority that should be able to tell if something's bad faith or not?
Or is it about increasing the collective intelligence that is aware of and sensitive to these things where everyone is doing it?
And those things simply don't trend in the same way.
And this starts to get into the kind of answer and theory of chains that I'm particularly focused on these days is we have this system, you know, a republic or a democratic type system of participatory governance that wants everyone to be able to participate in governance
rather than just be ruled by one or a few people.
And if we look from the beginning of what we call civilization, we exclude Dunbar number tribes because it's a very different phenomena, very few civilizations since the beginning of civilization till now have been republics or democracies.
They've almost all been feudalistic or autocratic of some kind.
And that actually makes sense because one guy ruling everything or some very small number of people that can talk coming up with a consensus and then being able to rule is way easier than getting a huge number of people,
mostly who are anonymous to each other to all actually be able to make sense of the world and coordinate like a large number of people coordinating is actually a very expensive tricky thing.
And from the way I see it throughout history, the few times democracies emerged, they emerged following cultural enlightenments that had a few things in common.
When we look at the Athenian democracy coming out of the Greek Enlightenment, stoicism plus the Aristotelian school and you know a few things had caught on to the place where they had a cultural value around education that everyone would learn formal logic and everyone would learn
rhetoric and history and you know those types of things plus the kind of stoic culture where they're all learning emotional regulation
and the Socratic method where they're learning how to take each other's perspectives debate any side of a conversation.
Well, if I have a bunch of people who are trained to be able to assess base reality clearly on their own,
they have emotional regulation so they are not as susceptible to emotional and cognitive hijacks and group think and have the courage to disagree and things like that.
And they can take each other's perspective and they're actively seeking to.
Well, those are the prerequisites to something like a democratic system being able to emerge because those people can have a good quality conversation about shared sensemaking,
recognize that some compromises to agree are better than warfare with each other and come up with solutions so collective choice making emerges out of the collective sensemaking,
meaning making and conversation ability.
And our country similarly coming out of the post European Renaissance Enlightenment phase was, you know, the idea of Renaissance men, Renaissance people who could have expertise across a lot of topics,
not just be specialists, because specialists across different domains have a hard time being able to communicate really effectively towards governance that requires looking at a lot of those things.
But the idea that we could become Renaissance people that we could all have empirical capacity, the scientific method and the Hegelian dialectic that we could hear a view and then seek the antithesis to that thesis and then seek a synthesis,
some higher order reconciliation, that again gives rise to the possibility of participatory governance.
And you can see when you read the documents and the letters of the founding fathers and of course there was a lot wrong with the Athenian democracy and a lot wrong with our country that had genocide and slavery as parts of its origin,
but the whole world had genocide and slavery as parts of what were going on at the time and it was at least moving in the direction of increasing participatory style governance.
The thing that the founding fathers talk about so much is the need for very high quality universal public education and very high quality fourth estate that's independent or news as the prerequisites of democracy.
George Washington said, I'm not going to quote exactly, it's something to the effect of the single most important goal of this government should be the comprehensive education of every single citizen in what he called the science of government.
And I think the science of government is such an interesting phrase because we've separated science and the humanities so formally.
And the science of government would be history and game theory and political theory and the things that people need to know the shenanigans that happen so that they can prevent them.
And Franklin said, if I could have a government without news or news without a government, I would take news because if the people really know what's going on, they can self organize and overthrow government.
If the people don't know what's going on, they can only be captured.
And our public education or education of any kind here in the kinds of civics that people would need to really understand what's happening in government and understand regulatory capture and be able to bind it obviously is close to non existent.
And the news has been mostly captured by economic and political interests.
So there is no chance for a bunch of people that identifies being in almost tribal warfare with each other who aren't sense making reality well who don't understand governments who don't really understand markets, who only have pejorative straw
man's of each other and don't seek each other's opinion, those people can't do a republic or democracy.
So it will simply devolve back to an autocracy, which we see happening.
And the way I think of it is like, if there's a bodybuilder has a huge amount of muscle, the moment they stop working out, they start losing it because it's very expensive metabolically to keep that much muscle.
They have to kind of keep working at it.
It's very expensive to keep an entire population comprehensively educated and actively engaged.
And once it seems like the government's working well and a generation passes and the kids didn't go through the pain of the Revolutionary War and the grandkids didn't that it becomes very easy to just get engaged in your own stuff and not keep participating in the governance.
And then you stop having a government of foreign by the people and you start having a class of people that do government.
And when the people stop checking the state, the state stops being able to check the predatory aspects of the market, which is what it's really intended to do.
And then the market ends up capturing it.
You get regulatory capture and then rather than a liberal democracy, you get a kleptocracy that eventually becomes an autocracy.
And that's what I see that we have right now.
And so do I trust any particular authority to arbitrate truth or good faith or whatever right now?
No, do I trust a collective intelligence that's actually increasing in its authentic intelligence?
I would trust that much more.
It's an expensive hard proposition, but I don't see any other good choices.
Yeah, and I think I agree with you.
A key part of my own thinking that's been formulated over the last year or two is that as we talked about earlier, we live in a era of scale and complexity, which is completely unprecedented in human affairs.
And I think it's reasonable to assert that the combination of scale and complexity has made the ability for an individual person to make sense, no matter how smart and educated they are, inadequate to the task at hand.
I read a lot.
I know a lot.
I've been through a lot, but I don't feel myself competent at all to make certain kinds of decisions.
And nor in this era of informational nihilism is it easy to find who the right people are to make these decisions.
That's less true.
If you do some work, you can find people who actually know more than you do.
And so I'm wondering if the founding fathers enlightenment view that we can bring everybody up to the level to be able to make good sense in high complexity and high scale is realistic.
Or whether we ought to be thinking about new institutional structures.
I've been informed quite a bit in the last year by the writings of Hansi Freinacht in his political metamodernism, two very good books, the listening society and the Nordic ideology.
And he makes the distinction between hierarchical complexity.
You can think of that as kind of mental capacity and code, which is our institutions and operating systems.
And, you know, he'll admit when you push him and I pushed him some in interviews that hierarchical complexity can only be moved a little bit in any one generation while code can be moved quite a bit very substantially.
We have things like the French Revolution or the Russian Revolution where totally new codes were developed, not necessarily always for the better, but code is much more malleable than hierarchical complexity.
And so maybe in addition, because I do agree, we absolutely have to upgrade the education and thinking tools for people, but might not.
We also have to think carefully about new institutions that take into consideration the fact that we're dealing with unprecedented complexity and scale.
And what I've talked about a fair amount and I continue to believe might be an answer is so-called liquid democracy, where instead of myself having to become a good enough expert on 30 different domains to make some form of decision about it,
I can proxy my vote to someone who I believe knows more than I do and is aligned with me on values and then under liquid democracy that person can reproxy the same way.
And so that the preponderance of our decision making power, at least in the political realm, gets concentrated towards more informed people and yet people who are still aligned with us on values.
And of course, the other nice thing about liquid democracy is to degree you believe that one of your people holding a proxy is no longer doing a good job for you.
You can change your proxy at any time or you can reclaim it and just for a single issue if you want.
While I may, you know, proxy my defense vote to my uncle who was an Air Force colonel, I may choose to hold for myself the question on whether we should go to war in Iraq or not.
And I'm thinking that code may be more malleable than actual individual human hierarchical complexity.
So, in terms of exploring how much can we change at the level of the individual how much at the level of the communication protocols for collective intelligence and how much at the level of the actual types of shared choice making systems that might be different than just kind of current representative democracy.
What we're talking about here is the context because we've set the context of the damage to the information ecology, but we're also talking now about the increased complexity of the issues.
And I think we should actually just build out the understanding of that problem a tiny bit more because it affects the way I think about it.
The solution is all right.
Absolutely.
Because you brought this up at the beginning and I wanted to come back to it.
So, partly it has to do with scale for sure, which is the founding fathers thing here.
There was an idea that everybody could go to the town hall and discuss the issues that were mostly geographically close to them that everyone could sense base reality on their own.
And you could have a small enough number of people in the town hall that for the most part the people who had something to say could actually say something about it.
And when we move to a place of most of the issues are globalized, whether we're talking about finance or supply chains or environmental issues or geopolitical ones,
obviously that's a level of complexity where people can't depend on their own base sense making and they can't process that much information and second and third order effects and confounding effects as well.
And one topic I'll just enter here because we haven't discussed it yet is the concept of hyper objects, which is connected to but a little bit distinct from just raw complexity that we evolved to be able to apprehend and understand objects that were available to our senses.
And when I'm talking about something like climate change, I can't see climate change.
I can't taste it.
I can't hear it.
I can only conceptualize it.
I can see a drought.
I can see a fire.
There've always been droughts and fires, but to understand climate change, I have to think about some kind of statistics and complex mathematical models on the droughts and the fires.
I also can't see world hunger.
I can see a hungry person somewhere, but I can't actually directly apprehend.
I can only do it conceptually, which also means I don't have the same felt visceral experience of the things.
And the same is true with I can't actually directly see or apprehend AI risk or biotech risk or nanotech risk or the nature of markets.
And so we have a world where the most influential things are mostly all not apprehendable to the senses.
And so we have not just the issue of can we have a better felt sense or intuitions are more right.
There are kind of sensibility of what's likely true, as well as our kind of formal and analytic thinking.
Can we get hyperobjects, but then can we get the connection of lots and lots of hyperobjects, markets interacting with social media environments, interacting with climate and things like that.
And I think it's just important to kind of state that to have a sense of how different the problem space of the things that we need to understand and think about are now compared to the evolutionary problem space.
Most people had to think about and how different the kinds of collective sense making need to be and choice making need to be.
And then I'll also step back and say, even in environments where we weren't dealing with as much in the way of complexity and hyperobjects,
our sense making was actually usually still adequate to solve local problems in ways that very often caused other problems somewhere else or down the road.
And this is an important part of understanding this is like the model that we can look at all of our problems as a result of either conflict theory or mistake theory.
Conflict theory, meaning we know we're going to cause harm somewhere and we're doing it anyways for game theoretic purposes.
Mistake theory, as you were mentioning with Facebook, we didn't know this was going to happen and it was simply an unintended externality.
So we have to deal with both moving forward.
How do we remove the basis of conflict theory so no one is motivated to do things that will knowingly harm something else?
And how do we also deal with the mistake theory of being able to anticipate externalities and internalize them into the design processes better?
And so the mistake theory side, you can go back to, we didn't necessarily know that the development of stone tools would lead to us becoming apex predators that were increasing our predatory capacity faster than the environment could become resilient.
That led us starting to extinct species at scale and then becoming the apex predator in every environment and start the Anthropocene.
Or you can come to a closer one and say, when we were making the internal combustion engine to solve the problem of the difficulty of horse husbandry pulling buggies,
we didn't anticipate that in solving the horse husbandry problem that we'd be causing climate change and oil spills and wars over oil in the US petrodollar.
And so typically, if we're going to make a solution that solves a problem, the solution has to be somehow bigger than the problem, faster, whatever, to be able to scale and overtake it to really solve the problem.
But if we define the problem in terms in a narrow way, there's one or two or some small number of metrics and the solution we're trying to create has a first order effect on a small number of known metrics.
But it might have second and third order effects on a very large number of unknown metrics.
We can see that the safety analysis is actually harder and kind than the solution analysis.
And this is something that we actually have to start factoring is, I don't just need to understand the problem I'm trying to solve.
