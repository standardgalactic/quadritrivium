So the topic of technological automation creating jobs issue, there's a couple perspectives.
One primary perspective is technological automation will obsolete certain jobs, but it will create new jobs.
It's always been the case we don't have elevator operators anymore, but there's plenty of new jobs.
And then there's the other perspective.
No, actually advanced robotics and AI are different in kind in some of the earlier industrial technologies.
And they're different in speed that as new jobs are created they will still be able to beat humans at doing it for market purposes,
which I think is much more true.
So if you take an AI like Google's AI, you take AlphaGo, you can train it on chess and how to beat everybody in chess.
You can train it on Go and how to beat everybody at Go.
You can train it on StarCraft and how to beat everybody at StarCraft.
It can gain the capacity very quickly to be humans at any finitely definable game.
And so AI is different in kind than other previous technologies.
It's more like the difference between us and all the other animals with our ability to innovate, you know, creating recursive technology on technology
that allowed us to become apex predators in every environment and then more than that, the AI is kind of like that jump again.
And so it does portend a break of capitalism and market structures as we know it and that most of, not just labor,
but most of the jobs that we currently have and even the new jobs that emerge in the niches that it creates, it's better at than we are.
That sounds pretty terrible if you keep the existing political economy where people need the jobs,
but one of the main reason we created a system where the people need the jobs is because the jobs needed the people to do them.
And if you, to make a civilization run well, if you had to get the people to do the jobs and a market seemed like a better answer than the state forcing the people to do it.
So let's let the market force people to do it and they can kind of self-organize.
But as soon as the jobs don't need the people to do them anymore, you can also start thinking about economies where the people don't need the jobs,
which is why now a lot of people are thinking about universal basic income and like different ways of thinking about that.
There's early naive thoughts on universal basic income.
Of course, it's the beginning of thinking about it.
But there's a really deep question which is, what is the role of humans in a world of advanced robotics and AI?
Because the advanced robotics and AI will be better than us at most of the things that we're used to being good at.
So what is the role of humans in that world?
What are we still uniquely good at?
And then what is also intrinsically fulfilling and meaningful?
And there becomes a steep question of what does education become in a post-technological automation world where you're not preparing people for the workforce in the same way?
What is the role of education and human development?
But obviously to answer that, you have to say not just education, but and obviously there's the economics component.
How do we do resource allocation and access in that world?
But there's a really deep civilizational question of what is the role of human life?
And if we for a moment avoid the topic of sentient AI, which is a whole theoretically difficult question, and we just talk about functional AI,
meaning AI that we're not saying there's something that it is like to be it.
We're simply saying it's very good at figuring out how to do stuff.
Then right away the key, what is uniquely different about humans and it is sentience.
Is the capacity to actually have there be something that it is like to be you at all?
Is subjective experience and then inner subjective, connective capacity?
And what's interesting is things related to sentience are what is where our intrinsic motive,
if we're not being behaviorally controlled by extrinsic motive, i.e. being paid to do a thing or external deterrence.
And so mostly you have to pay people to do shit they don't want to do, right?
And if the shit that people don't want to do is increasingly getting automated,
can you then have a world where largely what humans are spending time doing also more deeply coincides with what they have the deepest intrinsic motive to do,
particularly if you then have a developmental system and developmental society oriented to find out what the unique human motivations and capacities of each person are and develop them in light of that.
And so not only does AI portend something in terms of the obsolescence of humans for lots of labor roles and repetitive things,
one of the things Tomas was probably referencing was the topic of AI in human tutoring is pretty amazing.
It's also scary as fuck because again, you have to get this thing right.
If you have an AI that has so many orders of magnitude, more information processing in terms of being able to model your micro expressions to see how you're learning,
you can also have undue influence in a way that no cult leader has dreamed of, right, in terms of asymmetries of power of influence.
So who controls that and how do they control that?
These actually become the cultural questions, the theoretical philosophic questions that are so fundamental.
If you can genetically engineer humans and have designer babies, don't we all want to be like tall and beautiful and thin and is that actually the right idea?
As soon as you have the ability to actually design intelligent machines and design self-replicating machines and change biology,
the philosophic questions of what is good and desirable become so fundamental because so much becomes possible, right?
But if you do it right, imagine, everybody's heard about deepfakes, the ability to train an AI.
You can make basically pictures that aren't real, faces that aren't real, from AI images that look totally real.
You can also make a video of me speaking where it looks exactly like me, sounds like me, but it's totally AI generated, it's not real.
That technology already exists, it's not that good.
Some people have made deepfakes of me that are audio that sound like me, but the deepfake videos are currently about three years away from being Turing test passing,
you can watch a video of Obama or Bernie Sanders or whoever say something and have no idea if it was real or not,
and you won't have the human capacity to tell if it's real or fake.
You can imagine what that does to our ability for collective sense-making.
But that same deepfake capacity can be positively purposed because what that means is it's trained on the semantic patterns and the vocal patterns
enough to be able to generate novel answers like a chatbop, but where you can't tell that it's not real.
So now imagine an educational environment where you train that same AI, this is large language models as the type of AI,
say you train it on all the writings of Thomas Jefferson or all the writings of Socrates through Plato or whatever and writings about them,
such that I can go into a metaverse environment and say I want to pull up Einstein and von Neumann and Kurt Girdel and be able to have a talk with them about formal logic,
and not only can it seem like I'm actually having a conversation with them where they're sharing differing views based on their actual views, writing, etc.
But I could also just have an avatar that is like the voice of chemistry, that is the holistic knowledge of all chemistry that no human could be,
and yet all of them are the AI's best attempt to model what that person would do in terms of semantic coherency with what they did and said in the past.
So now imagine a future where every kid has access to be able to study with Einstein and Gandhi and Socrates and von Neumann and whatever directly,
where those AI's can model our theory of mind and titrate the learning directly to us associated with our learning dynamics,
but then also because the jobs have largely been automated, what humans spend way more of their time with is things like being educators and being nurses and being musicians
and the things that have kind of high connectivity value because those are the things that the machines don't do as well as the actual sense of shared interiority.
So now imagine that we have way more teachers per capita that are way more well trained, so all the teachers are PhD level trained,
there's one of them per 10 kids as opposed to one per 30, and now I get out of my AI environment where I was just studying physics with Einstein
and my tutor asks me a question like, what do you think was different about what the AI Einstein said than what an actual Einstein alive today might have said?
So then helping us to try to understand the difference between human intelligence and artificial intelligence and what it means to be sentient,
and what effect does consciousness have on intelligence, so not only are they getting that level of educational access,
but the AI can do, but the differential of what is unique about human intelligence and artificial intelligence.
So this is one of a million examples we can give of how those technologies could do mind-bendingly amazing things.
I'll say one quick thing about this is there is a study done on super genius of the past or polymaths,
who advanced many different fields beyond what the specialists in those fields did, and was there anything that the great polymaths had in common,
and the single thing that stood out the most was that they were all the result of aristocratic tutoring.
And this was actually a very taboo topic because when we ended feudalism and tried to create democratic states,
the idea, like if you think of meditations by Marcus Aurelius, Marcus Aurelius spends the entire first chapter just thanking all of his tutors,
but when you're being raised to be the emperor of Rome, the best mathematician, the best poet, the best grammarian, the best historian,
literally in all of Rome are your private tutors, and you can't learn to think like a mathematical genius from someone who wasn't a mathematical genius,
so your average math teacher cannot teach you to think like that because they don't think like that.
And yet, how do you make that accessible to everyone? You don't.
So the aristocratic tutoring in the past was a nice patronage job for the smartest people, but it was also so radically unequal,
but it's what created the best minds. So could that possibly be made popular?
Well, we can see in a third attractor kind of world the application of these technologies where you could actually have better tutoring than Marcus Aurelius had for everybody,
you know, et cetera, et cetera. Now, for each of these wonderful scenarios are like a million ways it goes wrong,
and so how we steward that properly is the key defining thing over the next while.
Thank you, Daniel.
Thank you.
