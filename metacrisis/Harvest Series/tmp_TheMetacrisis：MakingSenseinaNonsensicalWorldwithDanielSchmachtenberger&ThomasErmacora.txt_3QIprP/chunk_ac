So I am optimistic about that. The enactment to get there takes a lot of work.
So just briefly mentioned the third attractor.
I'll move afterwards towards some hopeful scenarios that we might encounter.
So that people don't leave this room with a sense of fear and catastrophe as being dominant.
But in order for us to create a third attractor, we have to put some energy towards developing one.
And that's not a simple thing to do.
But first we have to understand what it is and how they could drive us away from those two attractors.
Decentralized catastrophic capability and centralized capacity to control which is kind of dystopia.
There is not a term. There is not like a term for a type of political economy or system that makes that third attractor.
And we actually don't know.
So specifically what I mean by the third attractor is literally something that can prevent all the catastrophic possibilities
where the control mechanisms required to do so have the types of checks and balances that they prevent centralized power issues.
So we are actually defining in terms of what it isn't.
It's not catastrophes and it's not that the solution of the catastrophes involves dystopias.
Exactly what that looks like, there's both how would we design it from scratch which is a nice question
but ends up being kind of a nonsense question because we don't get to design it from scratch.
There's this enactment issue of with all of the vested interests that the world currently has in play how do we actually get there.
So I can give you a few examples of things that give the sense of what can make a third attractor possible.
So I'm just going to mention one which I think you'll probably refer to.
We have a common friend in Will Marshall.
Were you going to mention Planet Labs?
I wasn't but we can.
Okay.
Well I mean so Planet Labs, I'll let you talk about it but effectively I think it's interesting to see also that some of those third attractors
reside in the domain of intelligence plus or human intelligence plus technology applied to a new level of
what you've actually yourself called force of transparency.
And that probably is not, it doesn't define exactly what the third attractor is but it's a sort of hopeful way of looking at technology
that can constitute an underlying, let's say, conversation between different actors whether they're state or civic actors
or technology bodies that can start to formulate more of those.
So I think we both agree that there needs to be a proliferation of these examples and force transparency is a really important tool
because we've got very weak international governance and law.
Yeah.
So maybe you can address the third attractor by giving some examples.
Yeah so market forces like incentive by itself doesn't solve all the problems.
So you end up having to use both incentive and deterrent.
If we didn't have law protecting national forests, we wouldn't have national forests.
You'd have market forces that continue to turn everything into commodities.
But as far as international law, it's tricky because law mostly exists where you have a monopoly of violence that can enact the law.
A police state inside of a nation state so where we have global issues like the oceans or the atmosphere, this is where we have a really tricky time
because how do you, if you're going to make a law, it requires multinational agreement and then the ability to see if it's being violated
and then the ability to enforce some enactment and the ability to enforce it where it's not more expensive to do so than the benefit you get, right?
So let's say that we have an agreement about oceans and China's violating it and so we say, okay, we're going to sanction you for that.
But the sanction is on supply chains that we depend upon and if you escalate, they also have nukes.
So it's like there's a tricky thing with all that.
But one of the places where a lot of environmental issues, global environmental issues don't get legal support is where we just don't even know what's happening.
It's hard to know what's happening in the middle of the Amazon.
It's hard to know what's happening in the middle of the open oceans.
So this particular example is where technology can be repurposed in a positive way.
There's a satellite imagery of the Earth is a pretty amazing technology.
There's a friend of ours who runs a company called Planet Labs and they image the entire surface of the Earth every day.
30 terabytes of compressed data but they're increasing the spectral and temporal resolution of that and spatial resolution
such that it'll be pretty much real time human level video capture of the surface of the Earth in about three years.
Which is amazing and one of the things it means is the ability to see where logging is happening
and where mining is happening and where dumping is happening and where legal fishing is happening
and even to be able to see in a dead zone in the ocean the effluent, how much of it came from which source,
how much came from which port and all those types of things.
The ability to see all that and use machine learning to process it means that there's a whole bunch of international law
that we've never even bothered to create because there'd be no way to know if it was being violated or enforced.
Now we'd have the ability to create international law that says,
no we actually don't have plausible deniability anymore.
We know exactly how much of the trash or the nitrogen effluent came from there because we can see the whole thing.
It also has the ability to do spectral analysis that can see an invasive species entering an area
or soil microbes in an area to be able to actually support the environment when critical issues are starting to happen.
But this is itself very concerning because probably many of you, even as I'm describing this, are like,
wow, that's really hopeful for the environment to be able to have that level of transparency that could create law
so we could support the environment.
But fuck, who gets to have access to video level data of the entire surface of the Earth all of the time?
That sounds like pretty massive surveillance capability, which it is.
So that can prevent certain catastrophes but can totally create dystopias depending upon how it's managed.
So how do we create the governance of that information such that it doesn't get used for nefarious purposes
and that people get to know what it's being used for?
This is not trivial, right?
Because it's easy to deploy the technology to solve those problems.
It can be quite hard to create the governance to ensure that it's used properly.
Well, the official version that Will gives me is that it's 50 centimeter resolution so you can't see a face.
It's easier to count trees and cars and tanks in Ukraine when the Russians pretend that they're leaving a certain battle area.
But let's agree that, you know, that power is something that needs to be at least checked.
So what I guess I was trying to get at is there is some hope in terms of how we can leverage technology
in order for us to sort of monitor and then have some checks and balances
and also create the international agreements and legal frameworks to enforce some form of limits, if you want to call it that.
So something I'd like to say is there is a naive techno-optimism that I think is super dangerous
that just tech will solve all the problems and the very worst version of it is we're only a few years from generalized AI
and then that'll be able to solve all the problems.
If you study the alignment issue of how do we ensure that truly generalized AI is aligned with our interests,
it's a really, really tricky problem.
There's also a naive anti-tech, a kind of naive Luddite perspective that's like,
man, all these problems are because of excessive tech, quality of life is actually better at a lower level of technology.
Let's get back to the land and permaculture and that kind of thing.
But if you study the history of the world, any time there is an intersection of a less technologically advanced society
with a more technologically advanced society, it doesn't go well for the less technologically advanced.
So the China-Tibet type interaction always happened and so whatever this group of people are saying,
we're going to do the less technologically advanced will not actually influence the direction of the way the future goes
because the technology is power which does mean influence.
So the future will be high tech but it has to be also high nature and high connectivity or it will self-terminate.
So you have to say, we don't get to put the Pandora's box of tech closed,
but we have to actually become wise stewards of it.
So what does a high tech, high nature, high connectivity future actually look like?
And if we don't have the technological capacity for outsized influence over the current systems,
the current systems will be what dominates.
And so I am a techno-optimist but not a naive techno-optimist,
meaning I know that all the existential risks we couldn't do without tech.
Stone Age people cannot destroy the planet.
So I'm acutely aware that all the catastrophic risks are results of human activity extended through technological levers.
But I'm also aware that the solutions to those things can't avoid technological elements,
but the technology alone is not sufficient.
So one way we think about this, there's an anthropologist named Marvin Harris,
and he said you can think about civilizations as these triples of what he called the infrastructure,
the social structure, and the superstructure.
The infrastructure is the tech stack that the civilization depends upon and meets all of its needs with.
The social structure is the collective agreement field, so economics, governance, law, and the institutions.
And the superstructure is basically the culture, the values, the identity, the definition of what the good life,
what we're motivated by are.
He particularly argued that they are interconnected, but the tech changes in tech drive the other ones.
And he gave a heap of examples from the plow to the wheel to on and on,
where a change in tech meant that whoever used that tech, now they're behaving differently, right?
Driving a plow is a different set of behaviors than hunting.
But no tech catches on if it doesn't provide adaptive advantage.
If it does provide adaptive advantage, it changes pattern of human behavior by using it.
By changing human behavior, you also change human values,
and then everybody else has to adopt it, or they lose in war to whoever has that increased adaptive advantage.
So he basically said cultures and political systems change because tech changes.
There are other deep anthropologists and sociologists who say,
no, actually, and give a heap of examples of how cultural changes make us innovate in different ways,
aligned with our values, or have us bind our technology, like the Sabbath, or things like that,
and say that cultural changes are the deepest.
And then there are plenty of others who say,
no, ultimately the economy and law is the deepest thing,
because ultimately whatever you incentivize financially is the technology that will be developed.
If you change the subsidies and the taxes and the incentives, the tech stack would evolve differently.
I would say that all three of these, the infrastructure, the social systems,
and the superstructure or culture, are equally fundamental and inner affecting,
and you have to think about changes to all three simultaneously.
So if you dismiss any of them out of hand, like,
ah, cultural changes don't matter that much, or technological changes, or government doesn't,
you're definitely not thinking comprehensively.
The favorite one, like, we can just do culture change and everything else will automatically happen.
That's also not thinking comprehensively.
They're all necessary and only thinking about them together and the way they inter-effect each other is sufficient.
So we could think about, if we want a future that avoids all these catastrophes,
what does the infrastructure have to look like?
Pretty quickly we can say we can't keep using nature unrenewably and turning it into pollution and waste unrenewably,
so it has to look closed loop and it has to look post-growth,
because you can't grow it exponentially on a finite planet.
So what types of technologies would mediate that?
And what things should be global and what things should be local has a lot to do with the social structure interaction of
there are things that you want to be global in so long as you're wanting to bind the well-being of those people to each other
through supply chains and interdependence and that kind of thing.
What would the social systems of a future look like and what would the culture?
There have been conversations today around in-group, out-group and identity systems that's culture questions, right?
I think there's a lot of probably focus on the well-being picture here at Harvest and its virtual picture of planetary identity.
And obviously the planetary identity has to be not just humans but all life forms,
because you can advance all humans at the expense of the biosphere for a little while, but then it goes pretty badly for the humans.
So when we think about Third Attractor, we have to think about what is the culture of it, what must it be?
What must the coordination systems and the distribution and allocation of resources,
and you start to get into things like, well, man, doesn't interest by itself,
even if we don't think about central bank policy or interest rates or fractional reserve banking or anything,
doesn't interest itself compounding interest force exponential growth of finance?
Yeah, it does.
And then to not debase the currency, doesn't that mean you have to have an exponential growth of goods and services?
Yeah, it does. Doesn't that mean you basically have an exponential materials economy on a finite planet?
Yeah, so interest has to go.
Well, that's really fundamental. We don't know how to make that world.
And then as long as most access to resources based on private property, doesn't that mean rival risk interest
where I can do better at the expense of the environment and others based on private property?
Probably a lot of stuff has to be rethought around property law.
And then even when you get to, I can appreciate the atmosphere.
In fact, my life depends upon it, but I don't have to pay for it.
And so if I cut a tree down, I get immediate benefit from the timber.
And the little tiny damage it causes to the atmosphere, I don't really notice.
But when everybody thinks that way, it does have that effect.
But locally, I have way more incentive to cut it down than to leave it up,
because the extraction value that I get from turning it into lumber gives me game theoretic value.
Whereas if I put my resources towards planting more trees that I don't have economic interest in,
I do less well in the economic system, this means that there is a fundamental rethinking of the value equation.
Because whoever ends up valuing extractable, exchangeable wealth ends up doing game theoretically much better than those who don't,
which means they influence the world and culture more.
Those who pay more attention to common wealth have less influence over the whole thing.
So the changes that we're talking about at the level of economics are things like interest, private property, fungible currency,
even deeper than whether we have nation states or not.
And the same in terms of thinking through what is the future of the tech stack look like.
So we share a lot of views, and thank you for laying it out.
I hope everyone could follow with these, you know, this way of presenting where we're at.
A lot of people are quite naturally fearful of where we're going in terms of the labor force because of AI, for example.
And so in one of your talks, I don't know if it was very recent, and we share this view about this by the way,
you talked about education or educators and nurses.
I think it's a good way to present a hopeful opportunity for us to do something where humans are uniquely designed to do something different than machines.
And where efficiency is not what matters. It's more about qualitative than the quantitative.
And our computational capability is not challenged by that.
So I thought maybe I'd switch gears a little bit, but it's giving a little bit of hope again in terms of how we can address concretely
some of these challenges that we're facing, whether we're techno-optimists or techno-scepticists.
So I worked with the G7 on a scheme to try and infuse into national security in the G8 countries a concept of benevolent AI.
And we were just studying with 80 scientists from all over the world how we could potentially put that into motion
and start to educate government bodies and leaders.
And the main failure point was purely geopolitical.
So the arms race and AI just made it so that it made every single suggestion stalemate.
So we have to address it on a population level and also in terms of how, in terms of society, we adapt to the change that's coming towards us.
So we've adapted to bringing cars into our life, arguably imperfectly.
We've adapted to many changes in our society in terms of healthcare and pandemics and how we travel and etc. etc.
Give us a little, you know, I share this view with you, by the way.
How you think educators and nurses could become a little bit of a new orientation for mankind as AI steps in.
