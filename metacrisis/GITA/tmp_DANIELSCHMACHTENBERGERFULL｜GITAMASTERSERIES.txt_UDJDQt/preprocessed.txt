We're very happy to have here, so thank you so much for making time for us here, Daniel.
I think most of us have been following your work for a long time and we're really looking
forward to sharing some time and discussing what we've learned and what we could take
away from this now with you, because we've more or less to build on the conversation
that I hope everybody has had a chance to look at.
You've had with Liv Berri around meditations of Malak, we have understood that their downward
spiral negative dynamics emerging from Malak, emerging from what's probably in your words
very close to the reason for all of the issues we're having to deal with, which is our idea
of money-over-money return, of trying to optimize towards financial profits.
We've all understood that, but now we're faced specifically because we're coming to the end
of this series with the question of, okay, what are we going to do with this?
How are we going to carry this forward into our everyday lives, into our realities in
which we have to deal with the pressures of managing money or simply explaining to others
how we think about the world?
This is difficult.
This is really difficult.
And so this is this one avenue that we'd like to explore.
How can we maintain this for ourselves?
How can we deepen this?
How can we not let this slip after we've embarked on this journey together here?
And maybe we can also touch on some ideas of how to put this into action in the world,
don't put ways of putting this into action, which is difficult, because you have to make
some very clear and probably uncomfortable decisions, but I don't want to give your talk
to Daniel, so I'm going to give you some space to unfold some of your ideas around this,
like we exchanged earlier.
And then we open a conversation and have some fun.
Daniel, do you feel something coming up that you would like to pick up on and we take it
from there?
You said that people here had watched some part of that talk that I gave with LiveBorey
and obviously I went through this whole Gita series and heard a lot of things and you mentioned
that many of the people here are familiar with things that I say that I don't care to
repeat previously.
So I guess this is especially the last of the series and hopefully people take something
meaningful away.
I want to share what is most useful.
So I guess I'm curious to hear what is top of mind for people and maybe speak into that.
Okay, let's begin.
Let's open with that.
If you all reflect, and I think Patrick, you might have, no, Patrick, some music.
If you all reflect on what happened during this series and some of our sense-making
conversations in between the sessions with our guests and you map that onto the rest
of your life as you were going through the series, what comes up for you, something you'd
like to share as a foundation for this conversation today?
Is it sealed?
Maybe one thing that is, I think Thomas mentioned it already, but to me as a person who sits
on the crossroad between capital and technology, knowing what we know now and also based on
this series, it would be very beneficial to understand not only what is our next step
as individuals, because I think we'll each take it to our own lives and implement it
in different ways, but what is it that we can do individually or collectively to take
a step in the direction that will better us and everyone?
Maybe that's 30,000 feet, but this is really where I'm struggling to really put some concretization
into it.
You feel like in the conversation so far with everyone who spoke on Gita Series, you have
a different view about what the intersection of capital and technology portends for the
future on the current track?
I feel like we have to build two parallel worlds where the current track somehow needs
to be tweaked and continued, but the new track needs to come about and work in parallel.
I don't think we can switch.
And it's about how we treat capital or what we think about it in terms of being a resource
or whatever, like anything else, and what we can direct people who are technology people
or people who think around the philosophy of technology, maybe, of what should be done
in order to address these challenges that were raised here about the energy and the
minerals and resources, and that's a bit what I feel like.
It's a parallel situation which can take a long time or a short time, but somehow needs
to start happening, or maybe it is happening already and I'm just late in the game.
So the big question that you're asking, I think, is the question of this call, which
is, what can we tangibly do individually and collectively towards all that needs done
as people who are sitting in the place of investment in technology?
What can be done that moves the current system in a better direction, at minimum, not in
a worse direction, and is there stuff that can be done with capital that helps develop
new systems that are more fundamentally adequate?
Hopefully we'll unpack that over the course, but you said a couple things that were just
little tangents I wanted to speak to first.
You mentioned what can we do with capital that is a resource like any other.
This may be obvious to everybody, but if not, it's really worth saying.
I would not say that capital, meaning fiscal capital, the way we think of it, is a resource
like any other.
I think it is a optionality token for all forms of extractable and exchangeable resource
without actually being a resource itself.
I think it is a technology, it's a social technology that is arguably the most powerful
technology humanity has ever created, and that it is fundamentally both constructive
and destructive, but more importantly destructive for this phase.
That's not based on how we use it, it's intrinsic to the nature of the technology itself, no
matter how we use it.
If this is not understood, there's nothing that can be done.
Just indulge me a moment on it.
Just the concept of resource, I had a feature of anthropology that would have been like
a hundred and ten now when I was young, he was very old, and he had the fortune of getting
to be the first Western person to contact many indigenous tribes or one of the first
that were still separate from Western civilization and modern civilization writ large, and he
was doing cultural analysis on seeing how much the current modern society model had
become ubiquitous conditioning, and all of our studies of human nature were inside of
ubiquitous conditioning, so you can't really call it nature, and so he wanted to see the
things that hadn't been conditioned in that way, and if human nature actually expressed
differently.
He was looking at the most violent and least violent cultures, and looking at what they
are that's a function of, and one of the key things was looking at how it was a function
of language.
I actually had a couple teachers that had looked at this deeply.
One of the most profound insights was they said that in some of the island Polynesian
cultures and some of the Amazonian cultures that were still, that were extremely nonviolent,
both in inter and intra tribe, they didn't have the word mine in their language, first
person possessive just wasn't even a word.
And in other ones, they had the word, but it was extremely de-emphasized.
It was like a strange word to refer to a bad idea.
And they had ours, but even ours possession didn't mean the same thing.
It had the concept of stewardship built into the semantic itself.
And mine is actually one of the first words that most kids in our culture learn.
And one of the things that they found was that the cultures that didn't have the word
mine also didn't have the word or the prevalence of the words greed, selfish or jealousy.
Because those were not just innate human emotions that are always there.
They were actually memetic constructs.
If you have a shared ownership situation in a tribe, but it's not ownership because
you don't have massive surplus.
So you don't have radical wealth and equality.
Everybody shares stuff.
Whoever goes fishing, that's for everybody, whoever is picking berries is you just don't
build those same constructs in terms of I want what they have.
It just doesn't occur in the same way.
So there are so many constructs that we have that we take for granted as just human nature
that we have to work with that are actually at the foundation of our problems.
So I mentioned that because the word resource is an inherently violent word.
The way we think of it, the way we've defined it, human resources is how do we see sentient
human beings who are somebody's baby, who are going to be on their deathbed reflecting
upon their purpose in life and if they use their time, how do we see them as a resource
for a company that has a fiduciary responsibility to profit maximize?
They're not fucking human resources.
They're human beings.
And talking about natural resources is a whale a natural resource because it is.
If you're running a whaling boat, a whale is a natural resource.
Is an inesentient animal is an ecosystem that we devastate a natural resource.
Black people used to be natural resources, meaning part of the chattel the same way
we treat cows.
So the word and concept resource has to go.
Like it just fundamentally the idea man's dominion over everything is here for us.
If we can control it and extract it, it's about its utility value rather than intrinsic
value for us at the heart of the ideas that has to go is that.
So I want to throw out the concept of resource to begin with.
And I want to say that words like mine and resource and like they're colonized colonizer
mind concepts.
And so just there's that now let's talk about natural resources.
I've got steel, I've got copper, I've got lumber.
I don't really fucking have those things because to get that copper, I had to clear cut a forest
and then dig a giant hole, kill all the life that was there, have that mining tailings
go into the water and kill all the fresh water.
Like this is why we have to not think of it as a resource.
It's also important to get that like the biosphere is mostly six atoms.
It's mostly hydrogen, carbon, oxygen, phosphorus at six atoms.
It took a billion years of geology and then another billion years of single cell organisms
to take all the mercury and cadmium and like toxic shit and bind it in rocks way down here
and build up a biosphere layer up here.
And that was good because a tree could turn into a frog could turn into a moss could turn
into a mushroom could turn into anything right the same ingredients were recycling.
And so there was no waste.
There was no unrenovable resource extraction every dead thing was made of the same building
blocks until we started mining, right?
We start mining and we took it took billions of years to get the super toxic shit that
was buried down here and locked up in rock.
We pull it up, we separate it out through smelting and whatever.
And then we put the super toxic shit in the biosphere that is mostly biotoxic to all life
whether we're talking about lead or arsenic or mercury or whatever and to get the copper
or the steel we have to make a lot of this stuff.
We have the municipal solid waste all of the trash that goes out from our house and from
the restaurants and everything is so much the world is grounding in municipal solid waste.
There's 2 billion tons per year.
But there's 2 billion tons of municipal solid waste per year.
There's 190 billion tons of mining waste per year upstream from our choices to get the
metals that made this laptop and everything else.
I get to take the portion of the rock I want the portion that I don't want goes into a
giant ass tailings dam that always breaks and goes into the water.
And so to just get like upstream from our concept of natural resource is so much biocidal insanity.
I really would just want to emphasize that.
Okay.
And then the tree is lumber is a natural resource.
No, that's a 3000 year old redwood.
That's a 500 year old whatever like, okay, but let's go ahead and pretend that's a reasonable
concept to call those natural resources for a minute.
Money is still not like those because I cannot instantly exchange those right if I've got
a bunch of lumber or I've got a bunch of metal.
The transport of that is difficult.
Once I have as much as I can use I get a diminishing return on the value of that thing.
It stops being worth having more than I can use and it starts being worth less per unit
because now I just got too much of it.
And so it has a low liquidity value, but as soon and so once I've got more lumber than
I can use, now it just needs protected from termites and stuff.
I want less of it, but if I can sell it on the market quickly and keep getting capital
and that capital doesn't become worth less as I get more.
In fact, I add interest and it becomes worth more as I get more.
Now I want to cut all the trees.
I want to mine all the stuff.
There's no diminishing return.
There's only upside, there's only accelerating return.
Money has no tangible value, right?
It's nobody, you can't eat it, you can't build stuff with it.
It's pure optionality token, but it has maximum liquidity, maximum fungibility for speed of
optionality towards every other real type of value, but not every real type of value
because nothing that somebody wants on their deathbed can you actually buy with money only
towards the types of value that can be extracted, quantified and exchanged.
But what that means is that there's a lot of types of real value we will destroy in
the pursuit of this optionality value.
So the fact that the money means that now I have no diminishing return basis to not cut
down, kill, monetize everything, where on any other resource we did and the speed of
optionality means that if anyone else is getting more money, they'll beat me out of
war, political war or a medic war or actual war.
So I have to raise to get more of it.
And then the money has its own mechanics as soon as I get interest in financial services,
where it exponents itself and to not debase the value of the currency, we have to extract
more shit from the earth and turn it into pollution and trash.
That is unique to money.
It's unbelievably powerful, right, a universal optionality token that has no intrinsic value
but can give me instantaneous choice for any type of value that I want but is inherently
destructive to real value in the process.
So I just want to say it will be a while before the primary way we mediate choices about physicality
is not money.
We all know this.
It's not going to switch overnight.
We have a hundred trillion dollars exchanging every day being printed in central banks and
ran through a complex global financial system backed by nation state militaries to secure
the rule of law and all those contracts.
That means every one of those dollars is paying for those militaries and the issues that they
cause and the supply chains behind them and everything of the hundred trillion dollars
that trades hands every day.
Not one of those dollars really does not cause some harm across the supply chain because
it's utilizing resources or it depends upon hardware and other things.
So the long-term solution, if humanity is to keep existing, it will not have the thing
we call money or capital.
It will not have an idea that qualitative value can get turned into quantitative value
and that all different quantified metrics can be made fungible, intercommentable into
a single value metric that has intrinsic exponentiation built into it.
If those concepts don't go, I bet everything that I know that humanity goes extinct.
And so money as a system has to go.
Now, in the next little while, that's not going to happen.
So we have to use it better.
But it is like using the ring of Sauron, like it just is.
As a structure, it is the one resource to rule all resources that intrinsically has
power asymmetries and stuff built in.
It is an intrinsically powerful fucked technology.
With that in mind, one has to understand that it is not itself benign and it's just...
You do good things or bad things with it.
You can't do good things without depending upon supply chains that do lots of bad things.
And if you grow those things, you grow the other things, that's implicit to the structure.
Anyone who is stewarding capital, if they don't understand this, will not be a good
steward of capital.
I wanted to start with that.
So let's say one of the places where I recognize this, I worked on a project in my early 20s
that was trying to make a universal life cycle assessment for universal value assessment.
So that a big foundation could say, I put this much donation money here and it saves
this many trees, but this much donation money feeds this many kids, this one protects this
many rhinos, this much sequesters this many tons of CO2.
I want to optimize my input across the scopes of output so that I know how to do that.
So let's make metrics where I can decide how many rhino lives are worth, how many children
lives are worth, how many tons of CO2 or pounds per, parts per million of mercury.
Fucking insane, right?
It just is actually fucking insane.
We understand why we want to do that because we only have one input metric.
So we want one output metric, right?
The one input metric is money.
So we would like to save money in one, but okay, so quantify the value of those children's
lives.
No, don't do that.
Hold it as boolean.
If we fail at saving them, we failed and it was irreplaceable, it was priceless, it was
replaceable, it was an unacceptable failure and we just failed, period.
And you try to quantify it and right now we quantify it.
You all know through insurance and reinsurance and the way it's valued at depository trust
corporation and shit like that, we quantify it based on the amount of taxes that person
will pay and the amount that they'll contribute to GDP and shit like that.
Like it is that concept of resource built into the whole thing.
So right now, this is the thing everybody's excited about with AI.
Oh, the AI will be able to make a global resource optimization system that can, okay.
So the value of the rhino's life is worth this much, but what if the rhino's become
slightly more in danger versus it becomes slightly more of them relative to the other
things around it versus we have to be continuously changing the weighting functions.
It's just a nonsense actual way to do it.
The way to think about it is I can't inter exchange rhinos for mercury for children.
They're different things.
They're not interchangeable.
They're not fungible.
So I have to think about each of them with their own accounting.
How do we tend to rhinos is a thing we must succeed at.
How do we tend to children?
How do we tend to mercury?
So if I think about the materials economy, I can't make copper out of mercury.
We just don't have that alchemy.
Like I can, I have a certain amount of mercury.
If I don't make new mercury out of old mercury, then the new, the old mercury will be toxic.
And so, and if I have to keep getting the new mercury from mining, that's going to be toxic.
So how do I make sure that I have closed loop accounting on mercury, closed loop accounting
on nitrogen, closed loop accounting on copper, because each of those are in reality not fungible
for each other.
So they need their own accounting system where that you don't have a token that gets traded
in a way that isn't based on the non fungible physics of them.
So the future economic system will be much, it'll be much more real, but also more complex.
We don't try to reduce everything to a single thing because reduce it all the currency is
reduced at all the paper clips.
It is what is a single silly ass metric that does not correspond to real value.
And you know, the whole reason that money makes sense is because it does correspond
to real value because what the market will bear and we're rational actors and we want
real shit and the best product or service at the best value, but that's obviously nonsense,
right?
Nobody who's serious can take that seriously because all of the externalities are priced
out.
And so the commons gets destroyed running that thing and behavioral econ has made it
very clear that we don't have rational actors make rational choices and on.
So the invisible hand of the market is a bad God, right?
It is a God that takes complex value and makes simple value optimized out of it.
And when you take a very complex thing and run an entropy pump on it, make it very simple,
you're in the process of growing one thing while debasing what it depends upon towards
a death.
We see an exponential curve on money on tech on lots of things on caloric consumption.
Exponential curves don't continue in nature.
So they do one of three things.
You either get a logistic curve, you get a curve up and then a curve down, or you get
a curve up and then you hit a cliff.
The idea that the UN and everybody wants to tell us about how we'll have a 9.5 billion
person sustainable population that does this thing is just not based on real math and hopefully
Nate and other people got that across.
It's just not based on real math, nor does the economic system even allow for it because
it says to keep up with interest, money has to keep doing this forever, but to not debase
the value of the currency have to be more goods and services.
Oh, we can make them all digital.
No, you can't because the digital goods and services still relate to physical ones or
human time and attention, right?
The software bits value either is moving atoms around in the real world more efficiently
or it's for human attention, but human attention is finite.
So if I start to get a lot more software than human attention can engage, I get diminishing
return.
So there is no money go up forever, there's no thing where that's possible, right?
That's a silly thing.
So the current path we're on is this and so money is, this is why I said it is a powerful
like the one ring of power, fundamentally destructive because it will convert the complex
power of nature that is not on anyone's balance sheet into game theoretic optionality tokens
on someone's balance sheet.
That's what it does.
And it will drive innovation for how to do that thing more powerfully.
So given that right now, if we want people working on projects and we want creativity
and we want resources, it's going to equal money.
I want people who are stewarding money to do better rather than worse things or they
totally want that.
I want to talk to you all about how to do that.
But we can't lose sight of the fact that we are using a fundamentally not just broken
instruments but something that is at the heart of what is breaking the world or we won't take
deeply enough the externalities built into the thing that looks like maybe a good thing
superficially.
He raised her hand early here and maybe do you have something to build on?
Yeah.
Yeah.
Thanks.
I'd love to build on that.
And I think just from that last point, Daniel, if any of us kind of work, I also work with
UBS was private wealth with people who recognize this point.
And yet they have access to this capital.
And so it's always a dilemma to engage or not to engage with people of access to a lot
of this controlling technology that they don't even they don't believe it anymore.
And so do you see and we're all talking about impact investing and climate finance and different
kind of approaches.
And yet the incentives that we're talking about the whole structure is as we see it.
So do you have any ideas to follow up on that so what kind of money activity can actually
help change the systems where we wanted to go in addition to just for less bad things
and trying to address more, more intrinsic value and to change you on a C.
Yeah.
So one thing I would offer for everybody is to just really do your own kind of deep first
principles, thinking on a particular impact investment hypothesis and see if it really
makes sense.
Just the fact that lots of people are talking about how exciting it is at Weff does not mean
it makes sense.
Climate financing is so goofy in the fundamental idea.
Because if I create CO2 out of hydrocarbons, I get net energy.
I can't take CO2 and turn it into hydrocarbons and get net energy.
I have to use energy to do that.
It's a long line of fundamental thermodynamics.
So I can force people to internalize that cost with law, but that's actually then not finance
its law.
And that would be a good thing to do.
I can make a carbon credit as a kind of token that people can do if they want to without
it being law, which basically means it's like a fashion statement of some kind, but it won't
fundamentally in the multipolar traps.
But there isn't like a way to say, oh, there is a real market in the under market dynamics
for a thing that is net when you break it down to the physics takes energy to do and
doesn't give energy because there's a fundamental deep correlation between the capital and free
energy flow.
So there's so much profound non-thinking gibberish in the system that it's just another thing
that props up the rest of the gibberish of the system.
And I'm not saying that we, like with regard to climate, delton chens, carbon coin ideas
or whatever, could we actually get the price of carbon forced to be internalized to cost
through a multinational agreement?
I'm into things like that, but that really is law more than finance.
And so much of the impact investment thesis also is I'm going to define impact in a narrow
way.
This metric gets better, but in the process of that metric getting better does the thing
that I created interact with a lot of other things and doesn't make other things worse.
So if I had to give people one thought, it would be do try to do a good job with any
proposed investment of what its externalities are.
If you're trying to do impact investment, it's going to do some good thing.
What are the externalities of that thing really succeeding?
And when you factor the externalities, is it still a good thing?
The externalities will be physical.
It's going to take a lot of new hardware materials, et cetera, it's going to create some pollution
waste, use some resources to make that thing.
It's going to drive some arms races.
If it's successful, does it threaten a current industry or a current political party?
What do they do in response?
Their response, if driven by the thing we did, is part of the effect of the thing that
we did, the factor.
There's going to be possible psychosocial externalities.
Obviously, you make a thing like Facebook, you change the minds of the entire planet.
So understand physical and psychosocial externalities plus how other entities are forced to respond
to a thing you do.
Some of them align the same direction, some align very opposite directions.
And that's how you do externality calculus.
Really try to do a deep job of that.
We've put together a framework for what we call yellow teaming.
A classically blue teaming is how do I make the thing succeed, red teaming is how might
it fail.
We use the red teaming to solve the problem so it might fail for these reasons.
Let's recursively design so how it doesn't fail.
But then the yellow teaming is how might it succeed and actually suck for something else.
So how do we use red teaming?
We have a problem we want to solve, let's make sure it doesn't fail.
And yellow teaming, let's make sure it doesn't cause some other problem to recursively do
better design on the blue teaming of how we solve that problem without causing other problems
and without failing.
So if people want to prototype a framework like that of consideration that becomes part
of due diligence and impact thesis, that would be my top level thing to offer.
Another top level thing I would offer is think about the underlying generative dynamics that
give rise to the many fold problems in the world and things that you can do that address
that.
So we know that for all planetary boundaries, all ecological overshoot issues, a linear materials
economy rather than the closed-loop materials economy attached to a exponential growth
financial system is the driver of that whole thing, right?
Linear materials economy meaning it takes resources from nature and after production
distribution, it turns them into a combination of pollution and trash.
So how do you make a system where all the pollution and trash are captured and become
the new input and the input does not require new virgin resources that happen faster than
nature can replenish.
So closed-loop writ large in the packaging industry and the mining industry and the appliance
industry and the everything closed-loop is fundamental.
We get closed-loop or we die.
If you can invest in closed-loop technologies, that's a category to invest in, but then really
pay attention to the difference between the sales pitch.
This is closed-loop and the reality of it, like really look.
Are you capturing one part of your waste stream?
So for instance, plasma gasification for waste management is not really closed-loop.
It's in the right direction in some ways, but I'm taking very complex forms of waste
and just getting gas out of it that I burn, which means at least it's not just trash.
I got something out of it, but all this stuff that was the trash, I did not create a new
co-product.
It means I don't have to take this from nature again.
So it's still highly entropic and doesn't close the loop.
So really think through, is this actually closed-loop technology or loop closing?
Anything that is now, don't think about them individually because no piece of tech exists
individually, right?
What can I really do with a hammer by itself?
Not much.
I need the saws that made the lumber in the first place.
I need the smelting equipment that makes the nails in the first place.
I need lots of things.
The hammer's pretty fucking useless.
It's part of a tech ecosystem, right?
And what is this computer without the satellite system that we're talking to each other?
Like it doesn't do the same stuff without the entire complex supply chain of computer
systems that does the lithography and makes up this thing.
So one of the major problems is that we focus on parts.
We do a good job of those parts.
Everybody focuses on the whole, so we fuck the whole in the process, right?
So we actually have to focus on new holes.
So your investment thesis should be more complex and say there's some hole, like the
whole of the supply chain of packaging, right?
How we make the packaging, what materials are used, how much hydrocarbon we use, how
much energy, how much water, how much PFAS we put on it, et cetera, to that it winds
up in the oceans, that it, all those things.
I want to actually get the closed loop on that whole thing, because I can de-necessitate
the PFAS and create a new market sector for a new kind of fluorinated surfactant that's
just as bad or worse.
Eh, let's say, let's actually define how to get a self-sustaining system that is right.
It doesn't have to be the everything system, but at least something, right?
And I want to do now a series of investments where none of them on their own fully did that,
but together I actually get loop closure.
So this is another principle of impact investing I'm offering, is invest in ecosystems of
technologies, which can, that collectively do something that meets a minimum threshold
that on their own, none of them maybe did.
And some of those will be not just physical technologies, but social technologies, some
of which will not be for-profit, right?
And this is where you have a blended finance portfolio, where you're non-profit stuff and
you're for-profit stuff and you're lobbying stuff, because those are three types of money,
right?
Government money, market money, and non-profit money.
You'll do much better if you think of those three together.
And so can I use some non-profit money to tend to some part of the comments that none
of the market things will, because nobody will pay for it, and or to de-risk a thing
that changes the investable portfolio or whatever.
Can I use some percentage of the money to do legal stuff, because the laws have to change,
because if I don't make a certain thing, a legal, the insensible, stay fucked, even
with the new technology, and some for-profit stuff, where that entire bundle can be thought
about in a regenerative way, right?
This is a much better way to think about it.
So for instance, let's say I want to transition mining, some category of mining.
And let's say in a particular category of mining, the net profit is relatively low,
because we've had a lot of diminishing return, but the total volume is high, right?
We're talking like trillions in volume, but maybe at a 2% margin.
And the alternate way to get that metal, which is right now, we're not recycling it out of
the waste stream, and we're not mining the landfill for it, because it's still slightly
more profitable to extract it.
But there's also perverse subsidy still fucking going on, right?
We're still doing the perverse subsidy on the dumb thing, okay?
So let's, I got trillions that are flowing from pension funds, you should enter the toxic
bank thing, and not into this other thing.
Baby, a parent for our time.
What's that?
Oh, maybe somebody should mute.
So I want to change the market parity, where the toxic thing is just under profitability,
so all the money wants to divest even for the wrong reasons.
And the other thing becomes just above profitability, so I moved trillions, but maybe I can use
a few million of the right nonprofit lobbying money to change that topology.
So for instance, can I do lobbying that moves the subsidy from the bad thing to the new
good tech?
And can I do a bunch of public awareness that makes it to where the politicians have to
do that because their people want?
So they'll do the public awareness with the nonprofit, I do the research with the nonprofit,
I do some lobbying to change the subsidies.
I also do some activist stuff that makes it to where more of the purchasers say we're
not going to purchase stuff that comes from conflict metals or from polluting metals or
mountain top removal or whatever it is.
As a result, I drive the cost of this thing up, because it didn't have a huge margin,
I drive it up above the margin, now money wants to divest from it naturally.
If I simultaneously took something below market parity, the money will naturally follow the
change gradients, right, it changed the topological gradient.
Now I might be able to spend a few million nonprofit, maybe a few tens of millions of
lobbying money to move a trillion dollars of market capital that I don't actually even
have to talk to the people and they don't have to have the right values, sociopaths
will make that change because it's in self-interest.
This is an example of how to think about the whole ecosystem of types of finance, types
of capital, the whole ecosystem of projects and ecosystem of types of leverage together.
So in the same way that we think of parts, we optimize the parts, we break the whole.
One of the things to do on the other side is think about how to benefit the whole, how
to use capital across a number of types of capital, a number of types of interventions
to build more robust, complex, anti-fragile ecosystems.
This of course requires more understanding, but this is something I would really like
to offer.
So even in just the impact investment, invest in a few technologies that have synergies.
I'll give you examples, I'll give you another example.
Take any time that something happened that caused an environmental externality that actually
ended up hurting another market, but whatever market did that didn't care because they
weren't invested in the other thing.
We didn't bother paying the extra money to do good sewage management because financially
we didn't have the money, we didn't care.
And so on our balance sheet as a state or whatever, dumping the sewage and the developing
world into the river was cheaper than building the $10 million waste facility or whatever.
But now that happened to kill a whole bunch of fisheries downstream that don't even happen
to be in our country, right?
Because the river crossed a country line.
But those fisheries were making $10 million a year and we just lost all those industries.
And now I get to say, if I make a sewer here, do I get the fisheries back here?
And can I amateurize the future value on those fisheries and own the futures on them to be
able to invest in making this thing here because it's going to open up a new industry and I'll
actually be able to do that thing profitably.
I don't have to do this as a pure nonprofit project because I look at ecosystems of interconnectivity.
So you can use financial capital to rebuild ecosystems if you can sing with more complexity
than the current system does.
So I jump to the practical stuff because I know people, and the practical is hard because
if it was easy, everyone would be doing it and the Molok machine is oriented in the wrong
direction.
But there is practical stuff.
Do really deep yellow teaming for any technology that you might invest in.
Look at what it's going to fuck up and either don't invest in it or figure out how to change
the technology to not fuck that stuff up.
That's number one.
To look at domains of investment that are fundamental to everything that needs to happen.
Closing the materials economy is a domain that has to happen.
That includes not just the inorganic fraction, but the organic fraction, right?
Moving the loop on agriculture, waste management and soil regeneration is also a loop we have
to close.
Moving to sustainable sources of energy while factoring that the sustainable energy has
material supply chains that have to be factored, that has to happen, right?
And especially when you think about these things together.
So think about domains that have to happen for the world very deeply and look at those
domains.
Look at multiple technologies together that have synergy values that they don't have on
their own.
And not just only for profit technologies, but for profit things, law things, public opinion
things that collectively would do the right thing, where the portfolio as a whole actually
can make profit.
Even though not all the money in it is for profit.
And already major corporations fund nonprofits and lobbying to do fucking shit on their behalf.
That's not that's a thing.
Just only military contractors and big pharma and big oil do financial warfare like this
and they do it for fuck purposes.
So they will end up doing lobbying on their behalf to buy the sovereignty of a small country
and whatever.
I want that level of financial engineering, global level financial engineering to be done
on behalf of the commons by people who actually understand how to do that.
I want Soros level financial engineering for not the privatization of wealth, but the continuity
of the wealth that is needed to keep having access to do that before the benefit of the
commons.
There are more things, but those are a few directional tangible things about how to think
about capital allocation that still has some profit binding to it that is directionally
right.
I think that's a good moment for Patrick to come back in.
You had your hand raised for a while and you're one of the few people who actually know actually
do this kind of work.
So Patrick, I put my hand down again because I wasn't sure if that's the question is really
valid because I obviously agree with anything I heard and it's broken down brilliantly.
I was struggling when Daniel was talking about comparing of the rhino lives and the children's
lives and I was struggling because in reality, that's what we do every day.
There's no way around because, okay, now I have a for-profit company for impact investing
and I have a nonprofit charitable foundation.
So basically every euro I spent in one of those two, I cannot spend for something else
because we only have that one input metric, as you said, that's the money.
And the only reason I can do the impact investing and Mr. Müller from the neighborhood cannot
is because he does not have the money that I have.
So I'm having this problem also with the foundation of trying to explain holistic and systemic
changes to people nobody wants to hear, but even if they would want to hear, what does
it mean?
At one point, I have to focus on something and I have to find one project, one organization,
one network, whatever, and I make a decision that, I don't know, the education, the alternative
education program in Mali is the thing I want to do.
And the circular economy lab in Accra is the thing I want to do, which means I cannot do,
I don't know, the human rights thing in Brazil.
So in the end, I always take that decision if I want or not.
And that always leads me to the point that I have to try to measure that impact and to
bring it down and to measure how, what do I get for that euro that I spent?
So maybe I'm here, but I still don't get what else could I do.
I know it's not the right thing to do, but I still didn't really get how what else I
could.
I want to talk about very near the core of the driver of the metacrisis is our relationship
to measurement and standardization and even the philosophy of science.
And I am going to address some golden caps in the process.
We're asking a practical question I want to come back to, but I want to mention what's
wrong with some of the pragmatics frameworks because it, yeah, I wrote a paper early on
that talked about as long as the value of a tree is worth more dead than alive on people's
balance sheet or a whale as we will continue deforestation and whaling.
And it's clear that the whale in the ocean is not on anybody's balance sheet.
And so leaving it doesn't economically benefit me in any way.
If I leave it, it doesn't ensure someone else doesn't kill it.
And if I do kill it, it's depending upon it's $500,000 worth of sellable, well-meat.
That perverse incentive structure, because nature has no balance sheet and sovereign
beings are seen as resources and whatever is, is genocidal, it just can't be called
anything else.
Like we have to be clear what the fuck it is.
But if we wanted to say what is the real value of a tree or a whale, I don't know if you
can still hear me, Patrick.
I lost your video.
And hopefully you can.
I'm sorry.
I'm turning off my video sometimes because my connection is still bad.
Sorry.
Understood.
So if you think about the real value of a tree, the first big question becomes value
to whom, to which beneficiary?
Because as soon as we realize that it's not only the value to whoever gets to put the
lumber on their economic balance sheet, but everybody that it is sequestering CO2 and
producing oxygen for, but also all the animals that get to live in it and all the migratory
animals that are maintaining vast inter-ecosystem interactions that use that as a critical part
of the inter-ecosystem interaction, the value of it, you have to say, to whom first?
And you find that there are so many beneficiaries and so many value types that are all non-fungible.
And when you realize that the tree, if I cut down all the trees in an area, so now I get
way worse floods, right?
Because they're not stabilizing the topsoil.
That also washes all the topsoil away.
I also get way worse droughts.
I also get increased extreme weather events in the area, independent of climate change.
So now this means all the people in the area end up moving from extreme weather events.
Now I get resource conflicts.
Now I get wars.
Now I have to invest more in military-industrial complex.
Do trees prevent wars?
Totally.
Do trees prevent mass poverty and famine?
Totally.
Do trees house the bats that keep the mosquitoes down that prevent the malaria overgrowth?
And do they also stabilize the topsoil that keeps the water clean for the fish that keep
the mosquitoes down?
Totally.
Do the trees stabilize the topsoil in a way that not only keeps the river healthy, but
where the river dumps into the ocean, where you fuck all the trees in an area and the
coastal ecosystem dies as a result, downriver?
What would it cost?
Well, it's fine.
We cut down the trees, but we created a mechanical carbon sequestration, and we're sequestering
as many tons of CO2.
Shut the fuck up.
The tree doesn't just sequester CO2.
It does a million things, right?
So if I said, what would it cost for me to maintain the soil microbiota and the migratory
pathways and the coral with known technologies, the tree would cost a trillion dollars?
And I will destroy a trillion dollars of value to get $100 of lumber because the trillion
dollars of value is not on my balance sheet, and the $100 of lumber is.
When you realize it's not like we externalize a few costs.
It's like the only thing we internalize is the cost to us.
That's it.
And everything else is fucking, I have to be honest, it's all just stealing and raping.
Right?
The default is we externalize all the costs.
We just take the shit and don't account for what it costs nature to make it, or the waste
we put back, or anything, or the wars that get created over.
We just take the shit.
The only thing that we factor in is what it costs us to extract it.
That's it.
So we only internalize the marginal game theoretic utility to us.
So externality is a bad concept.
We should talk about that we internalize just game theory units and otherwise are just doing
raping and pillaging.
That would be honest.
That's technological scale, extinct everything.
You cannot measure all the things a tree does.
You cannot, because we don't even understand what the soil microbiota really does.
We're just starting to get a sense that we're discovering whole new phylums.
We thought the human genome project was going to solve all of the health issues in the world
because we didn't know what an epigenome is.
No, when we were doing it, the genetic modulation through an epigenome was a thing we didn't
know about the transcriptome or the proteome.
So our stupid ass hubris has us think we know more than we do.
We affect shit that is in the unknown set we can't measure.
So when we do measure and say I am paying attention to the thing that I can measure,
I'm affecting a huge amount of shit that I can't measure either because it's fundamentally
not quantifiable.
It's only qualified or because it's in the unknown set and I don't know about it.
So if I over optimize for what I can measure versus what I can't, then I'm going to destroy
most of the world for what's in my little measure, Bloomville.
That is irresponsible.
That idea, that mindset has to go.
Yes, measure some shit, but realize that you're measuring trillionth of a percent of what
you're affecting.
And if you apply management theory, where you can only manage what you can measure,
so we're going to manage against the measurement, you will be dangerous to the world.
Wisdom is the delta between what measurement-based management theory tells you to do and what
the right thing to do is.
That's how I would define wisdom.
And that's the thing.
If you want to optimize for anything on, the return on it's that, because it's the only
thing that and safely steward the amount of technological power we have.
So I don't want data driven anything.
I want data informed, but there's so much sensible stuff that we can sense at some level that
we cannot quantify that has to be factored.
When the Old Testament says in the top 10 things not to do up there with murder and
rape is not have false idols.
The measurement of reality and the modeling of reality is what it's talking about.
The false idol is our model of reality where we optimize for that rather than reality where
rather than the indirect sensory connection to reality, we look at reality through our
model.
Oh, my model is I'm decreasing CO2.
Look, there's no forest here.
There's a stupid type of genetically engineered grass that sequesters a bunch of CO2 and killed
everything that was here.
You shut the fuck up about the model that's being optimized.
If you looked, if you felt that you would know that thing was wrong.
And this is when Krishnamurti talks about we have to have immediate, non mediated relationship
to reality, not mediated through measures or symbols or models like actually sense it.
If you actually sense you'll notice that most of the people in the name of progress are
all existentially angstful and depressed.
And most indigenous people, if they haven't been totally genocided are not.
If someone in their wealthy life gets to have two weeks of vacation a year, they want to
go camping.
They want to basically be a shitty indigenous person.
They want to be in trees without all of the phones and shit around and with close amount
of family, but they destroyed that in the name of a progress that is insane.
So, if this is maybe the thing I want to share here the most is, no, I studied math, I studied
sciences, I like math and sciences, but in math, Gertl's theorem and then Tarski's theorem
and all the unknowability theorems, halting problems, et cetera, show us that if I have
a set of logical truths that are consistent, they will never be complete.
The whole set of measures I could ever have, the whole set of laws I could ever have will
be infinitely far away from the set that matters.
So I want to take it as useful, but also infinitely wrong.
So the thing that is sacred is unknowable, but I have to continue to sense into it and
not live inside the model.
Idol worship is that thing, right?
That's what it is.
When Lao Tzu could write anything, the first thing he wrote is everything else in this
book is not it, right?
The first line, the Tao that is knowable is not the eternal Tao.
Why is that the first thing to write?
Because everything else is don't fucking pay too much attention to the words because you
can't say the thing in words.
Try to get a sense from the words to a feeling that you have had right after someone you
love died about what actually matters before you die.
Try to get a sense of what is meaningful at all of how you felt when your baby was born
and you saw it that you forget on a day to day basis.
But in those moments, like try to feel that and live where every one of your choices is
optimizing for what you felt was important there, but for everybody.
There is no way to make a good enough model.
We can't replace capitalism with better capitalism or better socialism or whatever you can't
make an AI that runs it.
We have to have people that make choices independent of the measures and models, meaning that factor
them, but also factor the limits and make the right choice anyways.
This is not systematizable.
Systems are models.
They are fundamental to everything wrong is human designed systems that have the known
inside and optimized for and all of the unknown outside and externalized.
So who has the fucking like honesty and courage about the fact that they're going to die.
They're not going to make it through this life alive and on their deathbed.
Most of the hours of their life will not be what they wish they had done more of.
And very few of the things they did will be what was really meaningful and that they will
tell young people I wish you would do this and says, fuck, I'm going to be loyal to that
more than anything else.
I'm going to be loyal to that more than I won't sign a fiduciary responsibility that
makes me unloyal to that because I'm not going to have two masters I'm split between.
Now, if I'm going to steward capital, I have to steward it in a way where on my deathbed
I say all of that was the best use of my life energy and the service of the life that continues
after me I could have done.
And there is no way to systematize it.
It just takes earnest wrestling with it moment by moment.
Patrick, does that bring up something for you?
The honest wrestling moment by moment is what I feel what I do anyway.
I'm not the biggest measure a guy in the world so far, but I was just, yeah, I have to think
about it.
But because I still feel every minute I think about something and I wrestle with it with
energy or with trying to bear an open mind, it will always bring my human mind down to
a decision that moves one across the other.
And then you can name that what comes out in the end.
You can name that measurement or you can name that I found it in another way.
I'm not quite sure.
I'm not quite sure.
This is really important.
Draw the line.
Yeah.
Yeah.
Hippocrates oath for the doctor, first do no harm.
Then if you can help do, but don't in the name of helping possibly do harm, which is
also a hymsa in the Vedic system.
Most ethical systems have a first don't fuck stuff up and then figure out how to help.
Because almost everything open AI was made to prevent AI risk because deep mind had so
much supremacy.
Now it's driving it faster than anybody.
So the guys that in at open AI that were scared of it made anthropic to really focus
on AI risk.
Then they took 300 million from Google and now they're racing ahead and they were a major
part of what made open AI release faster in the name of will make something better and
then get captured by Molok.
Most of the problems of the world are actually the results of us trying to solve other problems.
If the best thing you do is don't make shit worse, awesome, like everybody's in the name
of making shit better.
They're making shit worse and then lying to themselves because their motivated reasoning
requires them to.
If you don't know how to actually make stuff better, do less stuff.
This is what the whole doubt aging basically says is chill the fuck out, let the mud settle
till the water is clear and when something is really clear and there is something like
and there's a feeling of clarity, but humility at the same time, not hubris, then move forward
with it while maintaining heightened observation to change it if you need to change it.
So you don't make a once in final decision.
You can continue to change it is you won't be able to predict everything in advance.
So if I could just say your if you just do less stuff as opposed to stuff that ends up
being that negative in the name of progress, that would be way better.
And if you got other people to do that would be better, then work on.
Yes, you are not the UN, right?
You are not trying to say, how do we handle resource flows for the planet?
You're saying, how do I handle a little bit?
I have a little bit of time.
And so I am going to finally decide to work on this thing or this thing.
But you are not saying in that this other thing is less important.
You're saying of the things I'm aware of, here's where I feel I can be a best service.
That's fine because you do have not just the input of capital, you have the input of your
knowledge, your contacts, all those things.
And so you're factoring those multiple inputs into where you feel you can do the best thing.
But if you just really check for the motivated reasoning of all the various types,
the one that will make the most profit, the one that will keep everybody else happy,
it's the one that I can prove.
I'll give you a great example.
The Gates Foundation, for each dollar I can put into mosquito nets.
I know that I'm going to save this many kids.
So any philanthropist who's going to put a dollar in somewhere else has to say,
is it worth this many kids dying that I don't put the mosquito nets in?
Fuck, I hate that line of thinking.
In one way, it seems very reasonable because that seems like I could put that money there
immediately.
But on the other hand, why are there so many mosquitoes in the area?
Why are there so many malaria filled mosquitoes?
Because there's no fish and bats that eat them.
Because all the trees were cut down that the bats lived in and the fish were overfished in the area.
And so the problem will just keep getting worse.
The people, why are the people in that shitty area to begin with and not in the better areas?
Because there are landmines covering Angola and covering Mozambique from the wars that were there
that were left.
And then civilian gets blown up every 19 minutes from one of the 100 million landmines left.
And we got to remove those fucking things and move the people back to the non-shit areas.
They had to move to the shit areas because of the landmines we left.
Remove landmines, get trees back, get fish back, get people out of shit areas,
get sustainable agriculture.
We'll fix malaria.
Now the deep nets, someone can't live their life inside of a deep net.
And since they're already malnourished people, they're more susceptible to the fact that
deed is a neurotoxin.
Yes, if I'm only measuring that one measure in the narrowest way, that seems to make sense.
But it's literally the stupidest strategy I can think of if I zoom out from that one metric.
Now, if I say how many bats we save, it's bats, but it's also other predatory insects
like mosquito eaters.
And it's also, but the trees that get that don't just give me those bats.
They also give me soil stabilization.
And how do I say this other strategy was better?
Because in the short term, it didn't maximize this one metric as much.
And the things that it benefits aren't even measurable.
They're not all measurable.
Tell a story about it that's honest.
Be honest about your sensing and then try to communicate your sensing and have people
who are willing to make real choices that include, but are not limited to metrics
and are really willing to look at the underlying theory and sensing.
Do that.
Something like a mixture between a comment and a question to build on that maybe.
Which we've, as a species, developed the sensing for Dunbar 150 scale living, scale life.
But that's the kind of the level of complexity, the radius of our complexity
that we can usually manage as a normal human.
And given the global predicament, given the potential also benefits of global coordination
towards positive outcomes, what could be a good strategy to manage those higher
radiuses of complexity that are necessary for the things you are describing?
Then what we're actually capable of, we're just going to lay out to end of the spectrum,
a few massive galaxy brains when we're trying to outsource that to a large language models
at the moment, that can hold that complexity or can we somehow fructally move it up from a
Dunbar 150 to a global coordination system or anything in between?
What are your thoughts?
It's a very technical question that goes well beyond the limits of what we can do in the next
few minutes because obviously at a 150 person scale where most things are not based on important
export but are local, you have a totally different set of dynamics where you don't have
you don't have invisible externalities, right? If your waste is where you are, you see it,
your resource extraction is where you are, you see it. If you're starting to cause unrenovability
issues, it's where you are, that's really different, right? So you have direct sensing
and the direct sensing is within an environment we co-evolved with so we actually have hardware for
feeling a certain way about those things, right? We have mirror neurons with each other and we
have mirror neuron like things about the integrity of an environment. Most anyone who looks at
the tar sands compared to the forest that was there before without any ideology feels a thing
just associated with that for evolutionary reasons but we all buy shit that depends on the
tar sands but we don't look at the tar sands, right? The thing we look at is the thing on Amazon we
want and then we don't look at the plastic in the ocean that comes from that or the landfill or
the whatever and so the ability to ship all the ugly shit away and stay in this area is a major
part of the problem. So when you have six continent supply chains, how do you possibly take responsibility
for the end-order effects and when you have people that seem so different than you and it
doesn't seem like your life depends on them, it actually seems like they are against you,
how do you care about them and so obviously we're not going to go back to a world where
everybody lives in 150 person tribes without a global supply chain and we either go that low tech
or we figure out how to do lithography at every 150 people we're just not going to do that, right?
So we do have to figure out is there 150-ish person like various levels of coordination
that give the high touchness possible where then that whole unit has a cell interact with another
one, right? And that's what the Iroquois Confederacy or certain things were and then you get the
governance of a bio region that is a natural boundary. It's not an arbitrary one to find
in war and politics but basically things within a watershed, things within a migratory system,
whatever it is and then those interact with each other and so you go all the way up to a
planetary system but cells, tissues, organs, organ systems, organism, environment, you have these
kind of layers of self-interaction and obviously the level at which an effect is occurring is
the level at which governance has to be occurring. So you want subsidiarity that pushes things out
to the edge as much as possible but that also can do governance at the level across them because
that happens. So then you say what is the total complexity of the system that we are managing
at any of those levels? Like how many bits of information under maximum compression are required
to understand that thing if you wanted to say it, if you want to use complexity as a formal term
and then does our information processing system have the complexity both in amount and type to
process that thing? If it doesn't then our decision system will be an entropy pump, right? It will
fundamentally be reducing the total information to less than the real amount under compression,
make a decision based on that which means externalities will be proportional to that.
So how do we do the collective decision-making? What parts can the machines do? Like where can we
use AI and computational intelligence to crunch really big numbers and calculus that doesn't
disintermediate human choice at the center? How do we train humans to have better epistemology both
in terms of cognitive sense-making? Specialists can't do externality thinking as well. There's
some level of generality that is required to be able to think through externality. So there's
something in the nature of the what is curriculum trained, right, in people. So how do we train the
epistemology of people? Then how do we get collective intelligence? One person, one vote is dumb,
market dynamics are dumb. We need things that are smarter than those things. So what is the future of
liquid democracy, qualified democracy, subsidiarity, blah, blah, blah, all those types of things. It
ends up being a collective intelligence system augmented by computational capacities but not
disintermediating it. That is adequate. That is the what is the future of social systems, right?
What is the future of governance economics writ large? That has to be answered. To replace this,
we don't just have one fungible input. We have lots of types of input at a resource
accounting level and then lots of types of choice-making at various levels that occur.
So that is critical to answer the long-term question. In short-term, now we're in this system,
we're engaging with whatever business we want to do, even if it's a local business, still
is supplied by six continent supply chains that are supported by military industrial complex and
intelligence communities and all that shit, driving the arms races it does, otherwise the
sort of contract of the central bank produced dollar wouldn't be there. It is backed by OPEC
and horizontal oil and climate change. All of that is a part of every dollar we generate.
Can't not be the dollar as a contract. It doesn't mean shit without a military industrial complex,
a global financial system, OPEC backing and all those things. Okay, so I can't factor all that.
I can't, right? Galaxy brain or not, but what I can do is try really hard to do a much better job
than I have. I'm not going to just be excited about the upside and then do a plausible deniability
box checking on risk assessment. I'm going to really try hard and I'm going to talk to smart
people in different disciplines and say, do you think this is a good idea? How could it be a bad
idea? Regenerative agriculture person. How do you think this might be a bad idea? Watershed person.
How do you think this might be problematic? Person who's aware of the cultural dynamics in
this area and how it will affect wealth inequality and social dynamics and stuff. Oh, I would have
never thought of those things. So part of it is try, part of it is engage people that know
shit you don't earnestly, then engage them in, okay, I just have to kill the project because
it's obviously bad for a bunch of reasons. I didn't know and wasn't in the pitch deck of the
investors when they were trying to pitch it to me, but I would really like this thing to happen.
Do you, can you help me innovate at all? And if so, you get some of the upside or whatever it is.
Can you help me innovate into how to make this problem that you're seeing in this domain better
in this thing, right? So we yellow team and then we bring that back into a blue teaming process.
And then no, we can't figure it out. Then go with the first do no harm, don't invest in it.
We can make it better. Okay, now let's realize that there might be problems with it. We didn't
anticipate. So let's not go straight to full scale deployment, right? Let's not go to 100
million people in three weeks. Let's do a smaller scale deployment and say, okay, it's good enough.
We figured out how to do it enough that it's worth going forward, but it's worth going forward and
watching for things we couldn't have anticipated and then doing that again.
Now, this is going to go slower. Will it win market races? First to market advantage. Nope.
Will it cost more? Yep. Do you need the types of capital that are okay with that to not be
directly the cause of extinction in the process of their investment portfolio? Yes,
you need a capital that is aligned with those things. Could not steward anyone's capital that is
not. Otherwise, you are fiduciarily bound to the extinction paradigm.
Thank you. Very helpful. I don't know how your time is today, but we're reaching
the 90 minutes of our slots and sometimes it's also getting late-ish. Do you have a hard stop
in my question? I'm happy to take another question. Okay.
I guess one thing I want to say is
that Peter, do you mind this message is so much more exciting?
Like everything's getting better and as going to solve all the problems and
there it'll create some problems, but there've always been problems and humanity are problem
solvers and we'll rise to the occasion. We'll innovate our way out of it. It's going to bring
an era of such abundance and it'll redistribute all of the wealth. So blah, blah, blah, and we'll
be a space fairing and we'll live forever. And I would tell that story if it was true,
because it's a more fun story. It's just not true.
What is how, as you, as a point of that, how are the Peter Diamandis and the Tony Siba stories
related to one another? Are they the same story or is there a difference?
I don't know the Tony Siba story. The Rethink X story.
You'd have to walk me through it. I've looked at Rethink X, but it's been a while.
The reason why I ask is, to me, they're the same, because ultimately they're
beginning at very small boundary conditions, let's say city level or something like that,
and then hope they scale their way up to the globe by innovation. But it's just hope and it
isn't thought through deeply from a first principles perspective. And it's a very powerful narrative.
When we say Rethink X, it is exactly the thing I'm saying. I would say think is not adequate
and you can't, but Rethink what the word resource means, right? Rethink the word mind, Rethink
thinking in models and Rethink the adequacy of thinking as a epistemic frame that doesn't
also include other types of intelligence. So we're saying the same thing, but I think you're
saying how deep down in the stack of assumptions do we go? It is my assessment that
if you take the cumulative effect of the reality of history being written by the winners,
the cumulative effect of that is the naive progress narrative
because everybody that lost wouldn't have called that win progress
and the technology and ideas that went along with it progress. So
I, I bought this shit. I didn't know I bought that like Western civilization and democracy
and modernity and getting out of the dark ages and the philosophy of science and whatever were
like generally pretty good things. And there's some problems with modernity. So we need some of
the postmodern corrections, but until I really studied it. And then I'm like, wait, my country
the founding fathers that we canonize as almost saints were to the British Empire
terrorists, we call other people terrorists. So a terrorist or a freedom fighter just depends
on which side of the story you're on and whether they win or not. So they were seditious terrorists
and it's very well documented that Thomas Jefferson who wrote the unbelievably beautiful
declaration of independence raped his underage slave continuously.
And it is documented that those same people gave smallpox blankets to the Indians as gifts
where we, when we talk about how dare you question capitalism, don't you know that
it has brought all the people out of poverty and done all these wonderful things, didn't you read
Pinker communism? Don't you know that Stalin killed 50 million people? We killed 110 million Indians
when we came here. We dwarfed Stalin. We dwarfed Mao fuck do the history. We killed 110 million
Indians of all these civilizations that had made it tens of thousands of years and relatively
better sustainability. Their languages are gone, their knowledge of it. So ask how the Western
civilization democracy progress narrative is to the Indians and to all the extinct species and
to all the animals and factory farms. It's not like I like Novocaine. I think Novocaine is cool.
I would not like dentistry without Novocaine. I'm down with the parts of the progress narrative
that are authentic. But also when Weston Price went to the indigenous cultures before they had
introduced hybridized grain, they didn't get cavities. Go back and look at Weston Price's
fucking work. We're not supposed to eat grains as hunter gatherer people and the mineral density
meant that they didn't get cavities. So even the you wouldn't want to go back to a world before
Novocaine, would you? If it was also without the grains that caused the Anthropocene,
we're painting a bullshit story. So basically I think the naive progress narrative is apologism
for Moloch. And I think we all have Stockholm syndrome with Moloch. I think almost everyone
who's successful is less fulfilled, like actually fulfilled, meaning waking up,
base happiness for no reason, sense of meaningfulness can die with peace. Almost everyone who's
successful is less fulfilled than almost every indigenous person that were the savages we had
to civilize and net way more harmful for the world. When Krishnamurti said it is not a good
measure of mental health to be well adjusted to an insane society, go to a fucking factory farm
and realize that our society is as insane as Nazi Germany was. But at way more scale,
we are driving it in the name of progress. I want anyone who gives a shit at all to extract
themselves from the insanity deeply enough to shake it off the momentum of that system. And
oh, but I have to do the bidding of that system. I'll do a slightly better job. No, you don't.
Just fucking stop. You have a choice. Stop. You don't have to do that. Then reorient yourself to
life, not Moloch life. Get rid of, look at all the concepts that are bullshit. Oh, we're going to
optimize based on measurement and natural resources and like progress. We civilize the savages
and start to understand life. How do 70 trillion cells in my body do a trillion metabolic functions
a second and work? That's more complexity than the government system we need to make. Nature
knows how to do it. We don't know how to do it. Spend time in nature and start to understand,
but you can't understand it in words, but you can understand it. I'm not saying a gibberish thing.
I'm saying a thing that can get reduced into technology, but a different way. And then say
there is this beautiful conversation I watched. I believe it was with Edward Teller talking about
the physicists who did modern physics and the journalists asked him who was the smartest.
Johnny von Neumann was the smartest in terms of clock speed. We all knew that no one had a question
about it. No one was even in competition about it. And he went on and on. And the interviewer
then said, does that mean that von Neumann had the deepest insights? And he teared up and he said,
no, that would be Schereinstein. And there's why did someone who had less clock speed have
deeper insights? And he was like, this was the question that boggled von Neumann. And
we came to recognize it had something to do with what happened when he played the violin.
And something to do with what happened when he puffed his pipe and looked at the clouds and went
blank. And this was reducible to real intelligence that solved real problems through a different
process that is not gibberish. It's just a different process. It was not purely semantically
mediated, which is what the Tao Te Ching starts with, which is what all of the wisdom traditions
say. The symbol that mediates ground, there's reality out there. We make up symbols to refer to
it. The symbol is not the thing being referred to. The symbol does not have all the information of
the thing being referred to. You have to have a direct relationship to the ground not mediated
by symbol, meaning not mediated through thought. If you don't know how to think not through word
thought, you will never think deeply. And that will be like thinking, feeling, sensing.
And then you can translate it towards and you'll always know they're inadequate.
And you'll write something that is somewhere between math, prose, and poetry,
right? Because they do different things. Some of it I can do denotatively, some I have to do
connotatively because the limits of denotation. So how do 70 trillion cells work in timed
harmony at a trillion metabolic functions a second? How does an embryo grow itself where
it's growing the placenta and umbilical cord that it's going to let drop off later while
simultaneously growing the lungs and GI tract that are doing nothing now but will replace it later
while growing the endocrine system and the skeletal system and all that stuff without even
having those systems to mediate how it does it. What the fuck, right? Try to understand how nature
does it better and then say this is what I'm a steward of. This is what I'm avowed to. And I have
there are not multiple gods that I'm avowed to. And the one that I am doesn't have a name.
If you name it you fucked it all up already. You start a holy war over it.
But that intelligence that governs everything, that is the basis of we do not have a good answer
to cosmogenesis or aviagenesis. The emergence of life, the emergence of cosmos, all of the
standard models have massive problems. The emergence of consciousness from brain, which is a wrong
presupposition. But reality does it all. My dad just passed a few weeks ago and I was reading
all the old letters that we've written each other. And he wrote me this fucking beautiful
letter when I was like 20-something. And he said, and he was a deep thinker from which I was initiated
into thinking on these things. And he said, the world will see challenges in the age of your
growing up that it has never seen for which there are no precedents for which no previous models
will be adequate and nation states will try to meet them and they will fail and the great
market and industrial forces will try to meet them and fail. The only thing I can tell you is
pay attention to what nature wants and try to redirect the resources there.
And that's what I would say to people who are thinking of resource directing is try to think
about what nature wants. And try to feel into it and don't think that you can in the same way that
like it's a very right thing for someone in the in a poor black neighborhood to say if you don't
live here, if you don't spend time here and you make the laws that govern here, fuck off.
Like you can't make the right laws if you don't fucking live here because you don't get it. You're
wrong. Live here and make the laws. If you don't spend enough time in nature and both nature and
the tar sands and destroyed coral and factory farms that we have turned nature into, if you
don't touch that, you cannot know what nature wants or needs. If you do, then can you let the mud
settle until clarity emerges and then act from there? That's what I would say.
That's beautiful. Thank you.
One last thing before we can let you go. We ask everybody to try and condense
what you want us to take away from the session in a single word.
What word would that be for you?
Remember the deepest insights you've ever had about what matters?
We will. I promise I will try to remember. I promise I will help us remember here in this group.
Thank you. You had mentioned that you would dialogue with people about this afterwards.
I'm really curious to hear what metabolizes. If there are deep projects that want to happen,
if people feel yes, I want to steward that and committed to it, if I can help, you know how to
find me. We will. Thank you for that offer. I will definitely be in touch about what's
thumbs up here afterwards. Thank you, Daniel. It's been amazing.
It's been great. Thanks, Daniel. Thank you.
