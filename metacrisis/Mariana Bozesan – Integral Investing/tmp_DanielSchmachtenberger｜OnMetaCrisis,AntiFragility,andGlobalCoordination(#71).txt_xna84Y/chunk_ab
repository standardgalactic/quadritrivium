We haven't stopped arms races on a single new type of technology.
We have an arms race on drones.
We have an arms race on AI.
We have arms race on cyber weapons, on bio weapons.
We haven't been able to deal with any of the major tragedy of the commons,
like climate change or overfishing.
So it's like, all right, our problem solving processes writ large are not
adequate to the problems we face.
So we shouldn't have 17 SDGs.
We should have one superordinate one that is develop the capacity to coordinate
effectively towards global level issues.
If we don't have that, we don't get any of the other ones.
If we do get that, we get all the other ones.
So how do we develop better coordination capacities towards global level issues,
like arms races and tragedy of the commons and things like that?
And yeah, so that's kind of been the through line, is seeing all of the problems,
seeing how they're interconnected, seeing what's underlying and driving them,
seeing where the solutions have some effectiveness but are inadequate
and thinking about and working towards what would new problem solving processes
adequate to the problems that we actually face look like and how do we bring those about?
Brilliant.
So how do we, you mentioned AGI, I just wanted to explain AGI is like what artificial intelligence,
artificial general intelligence as an explanation.
So how do we, what are the acupuncture points?
Obviously, there are enough smart people on this planet to be able to develop this whole system
thinking and come up with solutions.
Why, what makes it so difficult for such people to come together and come up with solutions
and implement them?
Because obviously, there are many, many people who come, you know, have these solutions,
but they don't have the political power, the influence, the money, whatever to make them happen.
So what are the fault lines of existing systems and what are the possibilities we have
to find these acupuncture points and influence them?
So that we, just to frame me, let me frame this a little bit better.
You are, went on record saying that we're currently facing World War Three
and it's not kinetic, so we don't really see it.
We don't really, we think it's peace and it's wonderful and we all can whatever, whatever,
be blessed to buy this and that and the other.
But in reality, we are deep at war with one another and we are on our best way toward extinction.
It's only a question of time.
So how do we save ourselves?
It's just a simple question for you, Daniel.
So everybody knows that the thing we call politics and the thing we call war are a gradient
of basically rivalrous interests.
Von Klauswitz famously said war is politics extended by other means.
And but it's more like the other way.
It's more like politics is how we sublimate war where we want different things.
And yet diplomatic warfare, economic warfare, cyber warfare, narrative and information warfare,
population-centric warfare, are those politics or those, well, they're outside of the domain
of what we consider the agreed upon political process.
They're not kinetic warfare.
World War II was kind of the end of kinetic warfare being a viable solution for the major powers
because any weapons that the major powers used against each other to really be able to deal
with it could escalate and we had weapons now big enough that you have a war that nobody wins.
So after that, we had to depend on proxy wars, which we've done a lot of.
We've noticed there have been no major superpower wars since World War II, heaps of proxy wars.
Well, in order to fight a proxy war, you again have to base it off propaganda.
Oh, they have weapons of mass destruction.
No, they don't.
But you have to tell that story to be able to go invade and do that thing.
And that is a kind of non-kinetic warfare.
So we fight proxy wars and we fight non-kinetic, unconventional wars.
So is it fair to say that the world is in peacetime right now?
No, I don't think that's fair to say.
I think we can see the total number of cyber attacks that are obviously not peacetime.
We can see the increase in total numbers of catastrophe weapons.
The first real catastrophe weapon we had was the bomb.
And before that, the major empires of the world always fought.
There were never times where they didn't fight.
That was how we dealt with our border issues.
World War II was the beginning of having weapons so big that we couldn't fight as the solution,
or at least the major powers couldn't fight.
And so the whole world before World War II and the world after fundamentally different,
because before that, we weren't powerful enough to ruin everything.
And so World War II was the beginning of technologically induced catastrophic risk.
So we had to be able to do something we'd never done, was have the superpowers not war.
So we had to make an entire new world system, a globalized world system for the first time ever.
And it bought us like 75 years of no superpower war.
There was a cold war, there were proxy wars, there were other things.
And that involved mutually assured destruction.
It involved a bunch of IGOs, the UN and the World Bank and IMF and all those types of structures,
because we realized that national governments only weren't enough to prevent world war.
And so we needed these other things.
And a whole globalization system where we became so economically interdependent on each other,
that we had more incentive to do trade with each other than we did to war.
And so we can see that the computer that we're talking on today, the microphone,
all of it, no country in the world can build.
From the mining of the materials to the refinement of them to the hardware,
to the software, to the satellite production that our internet is communicating over,
all take six continent supply chains to make.
Well, when you have that much interconnectedness,
you aren't oriented to blow each other up, which is nice.
But you get other problems, which is you get radical fragility.
So you get a problem in one area of Wuhan and the whole world shuts down.
And you get cascading catastrophic failures.
You have to stop a virus in a world that connected.
You shut down transportation in a way where now you realize the flow of fertilizer and pesticides
that now got shut down just drove the poverty of the 100 million
poorest people into much worse conditions.
And we had locusts throughout Northern Africa and parts of the Middle East because not having
the pesticides.
You can see all these second and third order effects.
Also, a major part of that world, that globalization world, was we will use industrialization to
extract resources from the earth way faster so that we can be so positive GDP that everybody
can get more without taking each other's stuff.
And the idea there is that if GDP is not high enough,
everyone's desire to have more makes them go zero, some may have to take each other's stuff.
And so the answer is there has to keep being more.
Well, more with a linear materials economy where you're taking stuff unrenowably and then turning
into trash unrenowably, you can't run an exponential linear materials economy on a finite
planet for all that long.
And so what we see is that that Bretton Woods world that kept us from warring for like 75
years till now has just come to an end because we reach planetary boundaries.
So we can't keep running the linear materials economy that way.
We have enough fragility in the overall system that the types of local collapses that are
inevitable now create global cascading collapses.
And we can't do mutually assured destruction anymore because we don't have
one catastrophe weapon and two superpowers that have it.
We have dozens of catastrophe weapons and many, many actors,
including non-state actors, including people we don't even know who have it.
Well, how do you do a forced Nash equilibrium?
How do you do a mutually assured destruction?
You don't.
All right.
So now we're in a new situation.
There was the whole world up till World War II.
There was World War II till now.
There's a new thing where you could say that the orienting question that I find,
one of them I find most interesting is around why humans have not been very good
stewards of power.
Why we have been shitty stewards of power, which both looks like war environmental destruction
and shitty social systems and subjugation and whatever.
And we can see that as we've gotten more technological power,
those same underlying issues of not being good stewards of power have just become bigger deals.
And with exponential power, it's really important to get the ability to engineer
new life forms, to crisper genetically engineer new life forms.
This is not the power of an apex predator.
This is not something that a gorilla or a polar bear or an orca can do.
This is the power of gods, the ability to extinct species at 13 a day,
the ability to destroy whole ecosystems, to build totally new environments,
the Anthropocene where we are the largest force affecting the surface of the earth,
more than geology, the ability to build artificial intelligence that has the ability
to paperclip maximize the world that this is the power of gods that requires something like
the love and wisdom of gods to guide it or it blows itself up.
So while this has always been an interesting topic of how do we become better stewards for
our power, it is now a critical topic because rather than just having local wars and local
environmental destruction, which we've had for the last 10,000 years, exponential warfare
blows everything up on a finite planet, exponential externalities ends a finite planet.
So exponential tech is a forcing function for us to become good stewards of the amount
of power we have or for the human experiment to complete.
So a way of thinking about it, if we take exponential tech and the emergence of it
as the center of our inquiry, which I think is the right way to look at it,
we take a real politic view and just look at what is happening and what is going to happen.
Just what we can say that World War II was there's a bunch of other ways of looking at it.
This isn't the only way, but it's a useful way. World War II was a few competing social ideologies,
competing over a chunk of new tech that was all made possible by a level of science.
So you've got communism, you've got fascism, and you've got capitalism, liberal democracies,
something like that. And basically physical chemistry, the atomic physics, physical chemistry
got to a place where the bomb, the V2 rocket, the computer and chemistry all basically came on
board at the same time. And Germany was way further ahead than the Soviets or the U.S. for
different reasons. And we realized that was existential and had to catch up. And so the U.S.
did the Manhattan Project and invested like crazy, which was not market investment. That
was state investment. The market did not build the nuclear bomb. It didn't figure out computation.
So the idea that markets innovate and states don't is utter gibberish, because both Germany and the
U.S. and the USSR that developed all those things, the Apollo projects, but Nick, et cetera, those
were all done by states, not by markets. And markets have never done anything of that scale
of development before or after. So we can see, we can think of that as a few competing social
ideologies for who would get the new tech, because whoever would get the new tech would
rule the world. And we can see that the U.S. kind of came out ahead. So we get a Bretton Woods world
rather than a Soviet contracted world or whatever. We'll detect jump where at right now.
The center of it this time is computation. Computation gives exponential returns rather
than multiplicative returns, because I can make a piece of software once and then sell it an
infinite number of times with no cost of goods sold and no cost to transport the bits. That's
very different. Anything in the domain of atoms or energy, I have cost of goods sold and cost to
transport the energy of the bits or whatever. So computations at the center and at the very
center of that is AI. And then coming out from there is the application of AI and computation to
upgrading the computational substrates, quantum computing, photo computing, DNA computing, et cetera,
other critical computational capacities, crypto type stuff. And then the application of that to
things in the domain of atoms and energy. So biotech by being able to apply AI to protein folding,
nanotech because of that material sciences, because of that robotics that are run by AI,
all those kinds of things. That chunk of tech that is emerging right now is orders of magnitude
more significant than the World War II chunk of tech, who only those who are directing it will
have any say in the future, because it is that much more powerful and power has been what determines
the future. And this is the real politic assessment. Right now, there are only two types
of groups as far as I see it that are trying to direct that type of tech. Authoritarian nation
states and corporations. So authoritarian nation states, China is not the only one and I'm not
saying even the China isn't doing things that are quite smart and reasonable. Of course they are.
But China is not leaving the development of its tech completely to a market that isn't aligned
with the long term plan of its country. It has a long term plan for the country. It makes sure
that what the market does is aligned with it. So if a corporation starts to do something that is too
far outside of what would benefit it, like the Ant Group started to do, they bring it back in line.
They have a huge amount of R&D themselves as a country, which so they're applying AI and attention
technology and IoT and robotics and whatever to making a better country, not just a military and
not just an economy, but a better nation state. And so this is why they have been able to not only
make high speed trains within their country, but export them all around the world and the US
hasn't built one within its own country. This is why they have something like 94% of the supply
chain on rare earth metals. This is why they have the majority of lithography and
like really foundational things. So we can see that an authoritarian style nation state that can,
because they don't have term limits, they don't have a perverse incentive to only do
shit that will create returns within four years so they get reelected. So they can do long term
planning because they don't have two parties fighting against each other. They have the ability to
