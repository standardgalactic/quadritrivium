like Exeter Academy? What Exeter Academy, the average person becomes like a senator, right?
And like the people that do the worst still become partners at a law firm. And
I think if I took that person who thinks Africa is a country who had a shitty school, parents,
no tutors, et cetera, and put them in the same position and put them in Exeter Academy with
the right tutors and teachers and everything around, they would be similar. So the masses
are the result of how we condition the people. And this is why Benjamin Franklin said if
that the ultimate depository of the power must be the people, there's no other thing that is actually
a trustworthy depository of the power. And if we believe the people too uneducated to be a safe
vessel, the only answer is educate them better. Everything else becomes evil.
So it's a big damn task. But look at the options, right? The other options are
starting with the idea that I'm meritocratically better, right? I know what is true and good
and right better. So I'm willing to like, let's say I'm going to do this thing about
nobody's allowed to eat meat on Friday, whatever it is, because otherwise climate
change in the whole world will end. And it seems like it's worth kind of forcing people.
What I'm saying is, wait, is that a law? Does that mean I'm going to take someone to jail
if they violate it? Does that mean we're going to use a monopoly of violence via a police force,
which an internal kind of military capacity to take away people's freedoms? Because I'm so certain
that we know it is right, that we're willing to implement it with a monopoly of violence. Where
does that go as you keep going with that process? What legitimate authority is legitimate enough to
be not being corrupted in the presence of that? So basically, when you come back to the early
narrative, I said that the problems that we face today are not being solved by our current
problem solving processes. So we don't just need more business solutions and nonprofit solutions
and etc. We need fundamentally new types of institutions that have the right characteristics
to solve these types of problems. Well, who's going to build those new institutions?
And it's important to get when we look at like, the world has built totally new types of government
and new types of institutions for 200,000 years, it was tribalism. And it wasn't until the emergence
of the plow and baskets and a few things that we started to get the different types of empires,
right? And then that kind of emerged into certain dominant types of empires and feudalism. And then
feudalism for so long that like the idea of something like
nation states and markets, that wasn't even an idea that it would go that direction and
that new thing. And then obviously post World War II, not just nation states, but like inter
governmental organizations at a global scale and multinational corporations. So the world does
evolve at social technology. And we can see that when the founding fathers of the US
were founding the constitution, they didn't have AI as an issue to worry about.
They didn't have a billion people. They didn't have planetary boundaries that were coming up.
They didn't have such interconnected supply chains that a break in one area could break everything.
They didn't have the capacity for a digital democratic system. They had to try to fit people
in who would ride horses to fit them into a town hall. So they were not trying to solve the problems
we need to solve today with their system. The people who created the idea of markets and the
Scottish Enlightenment, Von Mises and Hayek and Rand, were not trying to solve these problems.
And neither was Marx, neither was any of the social theory. So we need fundamentally new
social theory that starts with understanding our problem space. And so the problem space
requires new institutions and new problem solving capacities. Those have to emerge from people
popularly starting to want them, care about them, be willing to empower them and participate with them
so that the power of governance emerges from the consent of the governed.
Otherwise, it will be imposed, which is its own dystopia.
Wonderful. Would you like to dive into the Concelion's project as a contribution to achieving that goal
of creating and developing a new social theory and education system to implement that,
to inform the public space and avoid AI and what Google and Twitter and Facebook are doing?
Yeah, so everything we're talking about is the problem space that the Concelion's project is
focused on. And I'll take one more tangent first just because I think
some of what I'm referencing might not be grounded an example for people. It might be helpful.
I'm guessing that most of the people who are listening to this are aware of many of the types
of existential risk that exponential technology makes possible. If not, go watch Nick Bostrom give
a short overview of it on TED. But briefly, things like nukes are hard to make. Not that many places
have uranium. It's hard to enrich uranium. You can see who has it because it's radioactive from a
satellite. It's not hard to make drone weapons. Commercial drones are good. You can 3D print
drones. Being able to put the charges on them are easy. You can take out infrastructure targets
that way. Infrastructure targets can lead to pretty big cascading failures if you know which
targets to look at. We can see that that's happened a couple of times recently, and they weren't
even really good targets. They were small things, but the drone a couple of years ago hit a Ukrainian
munitions factory, and a little homemade drone did the level of damage that an incendiary bomb would
take. Run that out a few years. See that tech getting at earth, and think about it, and you're
like, all right, well, how does, and now think about how cheap CRISPR gene drives are and how
easy cyber attacks on infrastructure are. The thing that happened with the pipeline on the
Atlantic coast shutting down recently where nobody could get gas, we've known about that for a long
time. Nobody's done anything to protect. For 25 years, we've known that was a type of risk,
but now it's easy. It was kind of hard before. Now it's super easy. So if we have decentralized,
meaning not just state actors, but non-state actors, if we have decentralized exponentially
more powerful, which could mean exponentially more catastrophic technology, how does the world
remain antifragile in the presence of that? It's a big question, right? It's a big question.
For the most part, Western countries aren't even taking the question seriously.
China is taking it seriously. Their answer involves ubiquitous surveillance. It's not a
dumb answer. It's a problematic answer. It's a smarter answer than no answer. What's a better
answer? I would propose better answers than that. But just to say, if people have not thought about
how exponential tech causes catastrophic risks, go look into that. I have a podcast where I talk
about that a bunch. But the other example of how could any of these emerging areas of tech innovate
in social systems? I'll just give a couple examples just so you can start thinking about it.
You think about a new computer technology like blockchain or some other kind of decentralized,
uncorruptible ledger. What if all government spending was on a blockchain, which meant that
it could be perfectly audited transparently by anybody? And you could see where the money flowed
with a total provenance of data. And there couldn't be any missing money. And there couldn't be emails
that got lost or burned or whatever because you had uncorruptible ledger or transparent.
Well, there's a whole bunch of corruption that just can't happen now. You just made it impossible
through a kind of technologically enforced transparency. That's pretty great. That changed
a lot of stuff when you start to look at how much unaccounted for money there are in federal systems.
Look at AI technology. Look at the ability of AI to take a number of different faces and make a new
face that isn't actually a real human face, but looks like a real human face because they average
these different faces. They can do that with sound of the things. Someone actually just emailed me a
proposition they're working on about this the other day and such a well formed proposition. What if we
use the same underlying AI technology to look at a semantic field of proposals that people have and
come up with a new proposition that is the weighted center of all of those propositions?
Could we actually factor a humongous amount of human input and be able to come up with better
propositions where then humans can take those propositions and go through something like a
div merge process to be able to come up with better refinements on the proposition to move it
through? That's not voting, but it's achieving the goal of voting is better than it. What about the
kind of attention hijacking tech that Facebook or YouTube have, where you think you're just going
to check for a second and then an hour went by? Well, it's taking a lot of time to think about
unbelievable personalized data about your behavior, building behavioral models and then
being able to use that ability to control your behavior. What if instead of maximizing time
on site because they have an advertising model, they were maximizing your rate of learning and
development? They had a pedagogical orientation. Well, that would be different, right? What about if
why do we not have voting in person everywhere? We can see Taiwan made the shift, right? We can see
a few places are starting to work on it. Well, if you can do your banking online with
public key crypto, of course you can do that online. Then you don't have to have voting
be something that happens once every four years or every two years. It can be a continuous process
and where you don't just vote yes or no on a proposition, you get to help craft a proposition
where you can see the provenance of information that is leading up to it and who's influencing it.
Maybe you can even do things like a qualified democracy where before you get a vote on a
proposition, you simply take a simple test that shows that you understand the pros and cons
as generally stated, not leaning one way or the other so that you can't just get populist people
that are coming and voting without understanding it and that if you don't want to do what it takes
to learn that thing, you can use liquid democracy to give your vote to someone who does understand
it, right? So there's a lot of things we can prototype with that are like, wow, that's really
different. That makes a whole new set of possibilities. What if you start getting lots of those together?
Well, when you look at the rate of technological automation, both in AI and robotics,
we're about to lose most of the jobs. Oh, but there's going to be new jobs that are comp...
No, they're not. No, they aren't comparably in the same way. This is why so many in the
billionaire class are fans of UBI is because UBI is arguably the cheapest way to tend to the
unemployed underclass, to keep them from being a problem. And so you get a centibillionaire
class who are the ones that control the top of the power law distribution within a vertical,
right? One of the things that happens in the new areas of exponential tech is that Metcalf's
law leads to natural monopolies and power law distribution. So Amazon is bigger than all other
online markets combined and Facebook is bigger than all other social media and YouTube is bigger
than all other video players combined and Google bigger than all other search engines.
You get basically one owner of a whole vertical, right? That's not through government monopoly.
It's through the natural monopoly of network dynamics. When we've made antitrust laws anywhere
in the world, network dynamics didn't exist yet in that way. So we didn't build that in.
And yet the essence of antitrust should apply, right? Which means our legal system can't begin
to keep up with the rate of tech changing the fundamental premises. Okay. So you control one
of those verticals of exponential tech. So, you know, ecobillionaire, centibillionaire class,
they get to compete with each other, coordinate with each other for class interests and compete
with each other for who kind of runs the solar system. And then some increasingly smaller number
of middle class who tends to those people's systems and then a much larger underclass that
is just not useful anymore because robots and AI are better at most things. So we give them
Oculus and UBI. So they're not a problem. Like, that's a shit world. That's a shit world. And
that's one of the attractors right now. Now, the same tech can be implemented towards very
different purposes that make a much higher quality of life possible. But again, when you take the
tech, oh, so you take that tech's going to merge. So, all right, well, the jobs are going to get
automated. Well, that sucks if the people need the jobs. Well, UBI is one way to make the people
not need the jobs, but still with quite low autonomy and upward mobility and etc.
But beyond UBI is something like access to commonwealth resources that she gets beyond just
individual possession and ownership being the only way to have access.
And being able to separate the meritocratic stewardship of resources from access to quality
of life. Those are things that are both mediated by dollars right now, but can easily be separated
should be separated. Well, technological automation, automating the easiest things to automate are
the things that are most wrote. The things that are most wrote are the things that people like
to do the least anyways. So, could we direct this tech in a different way, a not Centabillionaire
class oriented, not a short term ROI, but a how do we make a beautiful civilization way where we
say, okay, great, so we can automate the shitty jobs. Awesome. We used to have to financially
incent people to do those shitty jobs because civilization needed the jobs to get done. So,
we made it to where the people needed the job. So, the market forced them rather than the state
forcing them because otherwise we called it totalitarianism and didn't like it. We'd rather
let the market force them. Well, we just changed one of the underlying bases of capitalist stereo,
communist everything, which is you need a labor force. You don't need a labor force. You have
to rethink all the economics from scratch now. Okay, well, now maybe we don't need a system
of extrinsic incentive to force people to do shitty labor jobs. And you can make a whole
education system and an economic system that is oriented towards intrinsic incentive. What is it
that what what meaningful things could humans do with a life that they would have intrinsic
incentive for? I don't have to extrinsically incent them to do. We simply have to support
their capacity to do it. So, the same technologies that are being implemented based on current easy
market opportunity that lead to either dystopic worlds or catastrophic worlds could lead to really
beautiful worlds, but it's not just based on the current easy market opportunity. It's based on
designing it differently, aligned with long term civilizational vision. And I guess this is one
of the key things is a system that is in the process of committing suicide, right? A self
terminating system is not a system you should try to win at. And dollars are kind of like the
scorecard of how well you're doing at this current world game. And so if I have
it, what the market currently incents?
If I follow that, I'm not going to build a new system of incentive. If I want to build a new
system of incentive where that $70 trillion a day of human activity is incented in a different
direction, how I build that new thing is not going to be what's incentivized by the current thing.
So it's going to be some people who make an evolution in their values first,
who are willing to build new technologies in new ways, social and physical technologies together
in new ways that create new systems of incentives that make it easier for other people to onboard
into those values. But the beginning of a new civilization is always not winning at the previous
one. It is always willing to fight a revolutionary war to take some real sacrifice to migrate to
something because something matters enough that it's worth not continuing to just try to
be secure or win at the existing one. And this shift in sense making is the goal of the
Consilience Project? I didn't even do Consilience Project. Sorry. Thank you for bringing me back.
The goal of the Consilience Project is to help this zeitgeist that the one thing that civilization
needs to be centrally focused on is the development of new social technologies that both employ and
direct exponential technology. The goal is to not only get that zeitgeist out there, but to get
enough understanding about what those new systems must be, that the design criteria for
decentralized innovation can happen. So we're writing a bunch of articles. We have a research
team of people that have been thinking about these things in novel ways for a long time from
different disciplines. We're growing that team if people have the right kinds of background and
insights. And so what we're writing is where people can understand, take any social system,
take the Fourth Estate, take education, take law, take economics governance. Fourth Estate,
media, if you're going to have something like a democracy or a republic anywhere where there's
participatory governance, the people have to know what's going on to be able to be
able to be civically engaged. So you need some uninvested way of getting everyone the sense
making. Well, obviously those systems were built with print as the mechanism. And we can see that
the world has evolved into a way where they've all been captured by vested interests, economic
and political interests, and then attention optimizing social media technologies that deliver
it to people micro-target the things that appeal to their biases the most, their in-group biases.
So without a good Fourth Estate, you cannot have participatory governance. You need to be
ruled. But the type of Fourth Estate that has ever been possible before is not possible in a
post-Facebook world. So what are the criteria for a Fourth Estate that is adequate where people,
for an information commons and an epistemic commons that is adequate that people can participate in
collective choice making because they have good enough collective sense making? How do we do that
