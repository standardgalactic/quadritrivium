Welcome to the Bayesian Conspiracy. I'm Inyash Brotsky. I am Stephen Zuber. I'm Jess Dickey.
I'm Jess J-E-S-S. Dickey-D-I-C-K-E-Y. Not just icky.
Someone wrote in too before you put you on the website, was Jess Sticky?
Not that one either.
I thought I pictured a stick like a stick.
I'm somewhat stick-like, but that is not my name.
I've noticed that when...
But you're not dick-like.
No comment.
All right. Well, she's the nicest dick in this room anyway.
Oh, right. They. Sorry.
Thank you.
I know Polish a little bit from my parents, and I can talk with them, but then I listen to fast things like a newscast.
My parents are pretty good with English. They cannot understand English songs.
And the same thing with Polish because the words and songs are kind of like drawn out or smushed together or stopped at weird points for the meter.
And it's just, yeah, you have no idea what anyone's saying if it's not in...
I struggle to understand speech at all.
Right. Yeah.
Jess Dickey.
Thank you. All right. Now that that's cleared up, what are we talking about today?
Today, we're talking about a post called Degrees of Freedom by Sarah Konstantin, which can be found over at the new less wrong, which is just less wrong.com.
It's called new because there was a whole restructuring at some point in the recent past.
Yeah, I don't know if it's that new anymore. I think it's just less wrong now.
Okay.
Call it less wrong 2.0.
I think they used to call less wrong 2.0 back when it was lesser wrong, but now that it's just full on less wrong.
I guess it's just less wrong again, less wrong we born.
It's like that thing where like the remake video games and they just like now they're like they're just calling those same things as the ones that came out 15 years ago.
Yeah.
Like God of War, the one that came out in 2018 wasn't God of War 5.
What was it?
Just God of War.
Wait, they're not even with a subtitle or something?
No.
Just God of War.
Right. Minus the just.
This is the new original God of War.
That's stupid.
It's going to be confusing in another 15 years when God of War 10 comes out and it's just God of War again.
Jesus.
Okay.
But I like this post.
I found it and I said, Hey, we should talk about it.
And the other two on the podcast said, Yeah, let's, let's do that because why not.
So here we go.
And it kind of fits into the stuff that we've been talking about a little bit with like constraining choices and I don't know, like a vaguely of a theme over the last few episodes of like kind of centering on autonomy and that sort of stuff.
So.
And free speech.
Yeah.
I think it totally fits the, the whole rationalist thing in general because as rationalists were often trying to optimize everything, I guess, the, what's the Harry Potter quote?
I don't want to rule the world.
I just think it could be optimized better or something.
That sounds right.
I should know this.
Or I think it could be organized better.
So I don't think we said the post was called degrees of freedom.
Yes.
And the one sentence synopsis of it is the more constrained you are by optimization, like you want to make the best choice possible, the less degrees of freedom you have.
Yeah, cool.
Yeah.
The, the two definitions that Sarah puts forward are optimization is of all possible actions available to me, which one is the best by some criterion.
Okay, I'll choose the best.
Multiple possible options are equally good or in commensurate by the criterion I'm using.
My decision algorithm equally allows me to take any of them.
She points out that if you're only free to do the optimal thing, that can mean you are free to only do one thing all the time as rigidly as a machine.
If, for instance, you are only free to act in your own best interests in quotes again, you don't have the option to act against your best interests.
People in real life can feel constrained by following a rigid algorithm, even when they agree it's best.
But what if I want to do something that's not best?
Or they can acknowledge they're free to do what they choose, but are dismayed to learn that their choices are dictated as rigidly by habit and conditioning as they might have been by some human dictator.
So just like the naive question from the top is like, I can imagine decisions that I make that I'm a not putting into like a decision hierarchy that I'm ranking.
But be like, I'm fully aware are sub optimal.
And it's not that I'm indifferent is that like I'm kind of just doing the easiest things, I guess.
That's kind of a different sort.
Yeah, but
That maybe depends on the way you're defining indifferent.
And by how you're defining optimal, because the fact that it's the easiest if that's like really high in the preference order, then yeah, it's optimal for that.
Do you feel bad about doing those things though?
Sometimes.
Okay, like I lately I have not been actually this entire year I haven't really been writing been kind of slacking on a bunch of things I used to do a lot of and instead just drowning in video games.
And I always feel like I am wasting my life.
I am going to die have nothing done and I'm doing this instead and man I suck but I do it anyway.
And so I'm clearly not indifferent about these things.
I feel bad that I'm not doing the most optimal thing for for my life.
Yeah, so I guess brushing past all of like the the depth of that the the surface thing is like we seem to making choices that don't fit in either of those two categories right?
Yeah, this um this article presupposes that there's a coherent you and the way brains work is more like crystal society where you've made up of these different parts that have different preferences and they're all putting in bids.
So you have parts of you that want to play video games and then parts of you that want to write and they're in conflict and the parts that want to play video games are winning currently.
It's true, but those parts suck. They are unoptimal.
You get into the same thing when you get a society to when you have people with different preferences.
So it's hard to steer towards one optimal decision when you've got people with different preferences or parts with different preferences.
I used to not to belabor on the point, but like I used to feel bad with playing video games a lot.
And I'm not sure if like just the rest of me stopped caring or like I started enjoying video games more.
But I don't I don't I don't spend a bunch of hours a week and sometimes go weeks without playing a game at all.
But I guess I've somehow at some point gave myself permission to like stop feeling bad about doing things that make me happy.
So I was like, sure, like this weekend I had basically entire weekend to myself and I could have been more productive and said I played a lot in my Nintendo switch and goofed around and like I could have read books to make me better at my job or you know done something like that.
And I didn't do any of that stuff.
So I don't know, like I had a fun time.
That's I don't know.
I guess I'm maybe I need to reassess but like I'm like, no, I need the time to relax.
But I've been doing that for like 10 years.
So I should probably stop relaxing and start doing stuff.
But anyway, I've either of you read a pair of Scots parable about the optimizing earring thing.
Optimizing what?
Your ring.
Tell me about it.
It's about a magical artifact that's an earring that will whoever is wearing it they will always whisper the optimal decision the optimal thing for them to do at that moment.
Using their own personal utility function like if you want your children to love you or it whispers to you what to do if you want to provide for them it whispers to you what to do if you want to make the world less getting global warming.
What the fuck am I saying?
Is it like a path to victory?
Basically it's whatever.
I'm thinking Contessa too.
Yeah.
Yeah, basically it's whatever is the most optimal action for you to do right then using your own utility function.
It always tells you what it is.
And that's a character from Worm whose superpower is the ability to see the path to victory.
Oh nice.
Okay.
And it's as overpowered as it sounds.
Yeah, that sounds ridiculous.
Yeah.
But in the parable the people who find this ring are always live very happy lives.
They end their lives just surrounded by friends and family that love them.
They are pillars of their community.
They have all the resources that they want and which usually isn't that much because
they're not like money seeking people.
They just want a happy life, right?
And then afterwards whenever an autopsy is done on them they find that their brain has
shriveled to be almost nothing because they just simply don't have to think anymore.
They simply do.
They offload all their cognition to listening to the earring.
Yeah, yeah.
Because there's only ever one best choice and when you always do the best choice you get
the best outcome.
And I mean in our cases we still got to think and decide what the best choices are.
But if you had something else like a super intelligent AI telling you what would be
the point of you thinking anymore.
It's hard to find one.
Yeah.
And I still am wanting to push back against the idea that there is one coherent best,
you know, one coherent preference or one like, you know, readily identifiable best option.
I think that humans don't work that way.
And it's probably good that we don't.
I think humans are definitely much better modeled as societies, like you said.
Should we go on with the rest of the post?
Let's go on.
Does someone else want to read the next one?
Sure.
Freedom as indifference, I think, is looking behind our intuitions about things like rights
or ownership.
When we say we have a right to free speech, even a right bounded with certain limits,
as it of course always is in practice, we mean that within those limits you may speak
however you want.
Your rights define a space within which you may behave arbitrarily, not optimally.
A right, if it's not to be vacuous, must mean the right to behave badly in some way or another.
To own a piece of property means that within whatever limits the concept of ownership sets,
you may make use of it in any way you like, even in suboptimal ways.
And then this is still on the subject of property.
To own something just is to be able to hang on to it, even when it's economically inefficient to do so.
As Weil says, is that Weil?
I don't know.
Property is monopoly.
The owner of a piece of land can sit on it, making no improvements, while holding out for a high price.
The owner of intellectual property can sit on it without using it.
For better or worse, rights and ownership define spaces in which you can destroy value.
You only truly own what you have a right to wreck.
I think that's a damn good point.
I think that's kind of fun, yeah.
If I shared my car with somebody, I'd have to be more responsible in taking good care of it.
And yet, since it's just mine and it's got scratches and whatever, I don't really care.
I always feel much more like I have to take care of other people's property when I'm borrowing something.
Yeah, but as it's mine and then I get to value it exactly as much as I want to.
I also like the point about the ability to destroy value, because we both live in subdivisions, HOA places, right?
Here, there's just a service that comes in most everyone's lawn.
Out in the suburbs, everyone owns their own lawnmower, which they use once every week, maybe?
Not everyone?
When I was living in New Jersey, there's some pretty poor areas.
And I remember there were some people that, we had this system at my local community library that I worked at
where we actually were coordinating people lending lawnmowers to people who couldn't afford a lawnmower
so they could upkeep their lawn so they weren't getting fined.
Oh, neat.
It's ridiculous.
Some people also have neighborhood kids mow theirs for money.
But most people have their own tools for whatever and just keep them to themselves and never share them
even though 99% of the time they aren't in use.
And it'd be much more economically efficient to have some sort of pool where they're shared,
but then you run the risk of them being broken, them not coming back,
and so everyone owns their own and just, it's a huge waste of money.
And most people don't like talking to the neighbors enough to try and coordinate.
Like, all right, everyone give me 20 bucks, I'll buy a lawnmower,
then we can find a way to store it or something.
Yeah, it used to be easier to coordinate community resources when communities were like tighter knit.
Yeah, when they existed.
Yeah, to talk up libraries again.
A lot of libraries are starting to have systems where they will have,
I'm not sure if lawnmowers, but they have like tools,
like tool kits that you could borrow with your library card.
I know that some had like suits that you could wear to job interviews.
I think that's a really cool idea.
Yeah, that's awesome.
It's kind of bringing back the idea of there being community resources
and libraries are generally paid with state money or local, locally funded, you know?
So I like that.
Yeah, maker spaces too.
There's like libraries tend to have these free maker spaces where you can use different resources.
I'm just like kind of being a spokesperson for libraries right now, so I'll stop.
Every time I hear somebody talk about libraries, whether it's online or in person,
I learned something that like some of libraries do that I didn't know.
Like when I was a kid, they just, as far as I know, they just rented books.
And then, oh, they do movies and video games too.
Oh, and audio books.
Oh, and digital books.
And oh, tools and suits and stuff.
Yeah, you can get free classes.
Their maker spaces are awesome.
All the community center stuff is there now.
Yeah, that's kind of true.
Yeah, I actually really like wish that libraries would kind of take over that space.
I mean, like they're kind of starting to, but like, yeah, anyway.
Real quick question to you guys.
Do you both think that owners of property, both physical and intellectual,
should be able to monopolize it and exclude other people from using their property?
You're asking whether I'm a communist?
Sort of.
I'm going to sneak in a gotcha here.
I think my answer to that is sort of, I don't know.
My answer to that is man, I don't know.
Okay.
That's hard.
What do you think, Steven?
I think, I mean, intellectual property, I think is, is harder to define than harder to like constrain.
Like, is it my idea?
Like, I remember there was a thing with like Apple trying to patent the tablet.
Oh, God.
Because they had the idea of a big touchscreen repeater.
Apparently they said it was theirs.
And I think you told me that they like, no, no, check it out on Space Odyssey 2001.
There's one on the table here.
This was already public property before you guys got your hands on it.
So, like, or, you know, another, like, I think Sony and Apple do the stuff, kind of stuff all the time.
They wanted to patent like the home button on the bottom center of the screen.
Like weird stuff like that.
The rounded corners were a patent.
Yes.
And so like, you know, that seems weird.
And, you know, a lot of that seems just to be kind of like to, to litigate other competitors out of the market.
But like, if it's a, if it's a thing I have, like that makes it a lot easier.
I think it's my stuff.
I can do whatever the fuck I want with it.
My intuition.
It's weird that our intuitions are so different for physical things versus IP.
I mean, like everybody, I know pirate stuff and nobody, like, some people feel kind of bad about it.
And like most people just don't.
But like it's, can you imagine if we lived in a world where everybody just stole stuff from the convenience store all the time?
I think it's the, the parting, I'm not very in on the community, but I'll occasionally see like the comment sections of, of Torrance.
People are like complaining to the uploader.
Like, why is the, like the audio on this so bad?
And it's like, because it came out in theaters two days ago, you entitled piece of shit.
You're trying to steal it.
Yes, I'm here too, but I'm not complaining about it and already paid to watch it.
So anyway, so what's the gotcha?
Oh, I was just going to ask when's the last time you saw a piece of media that you shouldn't have.
Oh, sure.
Yeah.
Never.
Cause I'm a good, you know, copyright hearing American.
Yeah.
I recently watched, um, um, what's the new Star Trek called?
Oh, you did try to, you did try to loan me a DVD and I had to turn that down because I knew that that was prohibited by the agreement that you made with the company when you purchased it.
No, no, that is my mind now and I can loan it to whoever I want.
But yeah, no, I watched an episode of the Orville just last night on someone's Plex server.
So yeah, because where is it like CBS or something?
Who has cable anymore?
Who owns a DVD player?
I have an Xbox.
I have an Xbox one.
I don't think it plays DVDs.
Yeah, it does.
Oh, it does.
Well, today I learned.
I don't play the Blu-rays.
So yeah, anything can play Blu-ray can play a DVD player.
I believe.
Okay.
Well, in any case, like I only know one adult with a, with an expansive physical collection of movies.
Yeah.
And like, I just, I mean, it is like, I know this is like totally an aside from the post and I totally get like the people who make those things should, should get paid to like make them.
Right.
If I could have paid to watch Game of Thrones and not paid for a two year locked in contract with HBO, I totally would have.
Right.
What I would like, I think what could work is like.
Except for season eight.
I would have paid to finish this.
Finish the show.
That's true.
I would have paid and been angry.
Completion money.
But let, but you'd be less angry if you paid two bucks an episode or five bucks an episode even, then you would be if you paid 60 or whatever, 40 bucks a month for HBO just to watch it.
Right.
Yeah.
Yeah.
Because you still have to watch ads, right?
I'm not sure.
No, not on HBO.
No.
Okay.
I mean, that's great.
Like, but I guess just to me, it's like, I don't want the whole thing.
Just I want the little part that I want.
If I could get that, I'd be way more inclined to pay for it.
So I think that's actually where things are going.
Yeah.
I think Apple.
I mean, that's kind of what Spotify did.
They, they took piracy and made it, you know, so easy and convenient that all you have to do is listen to ads every now and then that now everyone uses Spotify instead.
Yeah.
And the service is like super affordable and like way more convenient than pirating and making your own playlist.
Absolutely.
With, you know, the one downside being that artists generally can't afford to eat anymore.
Yeah.
Don't love that.
Yeah.
Shall we go on?
Shall.
Yeah.
This is kind of what we're talking about.
But an intuition behind the fact that society is shaped by people's desire for more discretion in decision making the above the previous stuff was.
So some discretion is necessary to ensure good outcomes.
A wise human decision maker can always make the right decisions in hard cases where a mechanical checklist fails.
And they use the examples of like job hiring or admissions to college, that sort of stuff.
So there's still humans involved there.
However, what we observe in the world is more discretion than would be necessary.
We have discretion that enables corruption and special privileges in cases that pretty much nobody would claim to be ideal.
Rich parents buying their not so competent children, Ivy League admissions, favorite corporations voting themselves, government subsidies.
Decision makers want the freedom to make illegible choices or to put it more favorably, they want to destroy value.
So it is weird that like, you know, a law that like, you know, showed that required like transparency in politician funding would be seen like as constraints on someone's freedom.
But that's kind of what they're getting at here.
And like transparency is like violating their right to make bad decisions or make super biased ones in ways that like we as the people that they're representing don't know about.
The more you're constrained by optimization processes, the less freedom you have.
And, you know, once things are very transparent and these processes are in place, then you've lost that freedom that used to have.
Yeah, this also comes back to now these are cases where people are making decisions that affect others.
So you're part of a community or society or country.
Obviously, it seems like we should be free to make decisions that affect only ourselves but when they're talking about decision makers.
I can think of cases where I do and don't want people to have that ability to destroy value.
So like there's an example of say like a military general making decisions that maybe destroy value and that like people would object to but like,
because this person has this level of expertise and knows what's going on in a world that might be the right choice.
Even though it's the unpopular choice.
Maybe making it a military general makes me like more inclined to be disfavorable towards it.
So maybe instead of that, let's do the example of the banned things store.
Like a lawmaker saying, yes, we should have these banned things stores.
And then like the rest of society might be thinking about the mother of four who died of the Dr. Snakey's arthritis oil.
I think like another way because like politicians everyone hates, you know, everyone like it's a very politicized topics like parents or other like decision makers.
Right. So you want your parents decisions to be based on like their best judgment.
Hopefully that's like well informed.
You don't want it to be based off of like somebody lying to them or like Nestle's weird practice of like giving people formula and getting them hooked on it.
Because they're not producing breast milk, right?
So or or parent making decisions like not vaccinate their kids because some celebrity told them not to.
In general, I think you want parents to have the freedom to raise their children how they want because they are most likely to have the local knowledge as to how a child can be successfully raised in this environment.
And given the temperament of the child, like usually you want that to be parents decisions and there's just a few rare cases like the vaccine thing when you're like,
no, do you really we can't let you have this decision at this point?
Yeah. And at that point, like maybe the line where I think because the difference there is like, hey, I don't think you should be allowed to kill your kids.
So I'm pro back. I'm pro mandatory vaccination.
But like maybe you're like, you know what, I don't want to educate them.
I feel like that's just going to, you know, hold them back from like finding a good life meaning of like some, you know, craftsmen labor or something.
Right.
So society has decided like, no, you have to educate your kids.
If you don't want to go into public school, fine, but you have to like do at least something.
I think it was the.
But I think I was going to say that the difference there is like it's it's different between like the shows that you let them watch at home or something on TV, right?
Because whether or not your child is educated actually has an impact on society at large.
Same thing with vaccinations.
Exactly. Yeah, vaccinations. Definitely.
They do go to school and get other kids sick.
So but if you're if you're going to say, no, I'm not going to educate them.
They don't need to learn how to read society is like, yeah, they kind of do because they it's going to the rest of us kind of have a have an accrued interest in everyone having a minimum minimum level of competence.
Yeah.
There was a, I thought a really interesting example right near the end of this post about Stalinism where there was a particular intellectual in, I don't know, Russia around the time when Stalin was coming into power, who.
All the arguments at the time were in favor for communism and particularly Stalinism to enforce communism and make it make it work.
So it was obviously the most logically morally correct thing to do to support Stalinism.
It was the only way to move the human race forward.
And the person said, you know what, even though it's obviously the correct and most optimal way to run a society, I just don't want to.
And so they had that that I think that would be a case where the freedom to not choose the most optimal path is sometimes important.
And, you know, it turns out nowadays we know that was not the most optimal path at all.
But at the time that was not nearly so clear at all.
And so the ability to to be free to destroy that value, I guess, was important to.
Sounds like this person was a dissenter.
Yeah, I think they were.
Yeah.
So like that's another case of people having different preferences that come into conflict.
Yeah, I think it's.
But he was also convinced that that was the optimal thing to do the way to reorganize society.
Why what was his motivation then for saying no, I don't want to.
Because he wanted there to be some mercy and kindness in the world, despite the fact that it was not optimal.
I think that's one of those things where like that's that's a like non explicit value, although it was more explicit in their preferences than it was other people's because like.
The reason that you don't like tyrants is because you want a decision like what if the tyrant is wrong.
And it turns out that like having the flexibility there is worth having some some shake about it's like a democratic system, right?
Because at least then there's in theory the chance that like we can at least get back on course rather than just trusting somebody to keep us on course all the time that we can help kind of steer.
And yes, that means that will occasionally hit stuff.
But at the very least it means that we have everyone has a hand on the wheel.
Yeah, this is sorry we finished.
Yeah, go ahead.
It's actually making me think more of kind of the sacred cows.
What is the thing that I'm thinking of?
Taboo trade offs.
Yeah, like unthinkable thoughts where people might.
Oh boy, there was an example I had.
I was thinking of somebody who can't accept that there's no such thing as heaven.
Like I refuse to accept even though like there's no evidence.
But I just because it makes me feel better and thinking about a world in which people just die forever makes me feel bad.
And that's going to prevent that person from being able to consider things like cryopreservation or having you know their brain uploaded.
So that yeah, I guess there are cases where people's emotions could also like supersede their ability to choose an optimal.
I don't know somebody else talk.
No, I mean, I think we all agree with you that not dying is the most optimal thing.
I'm just trying to think of what would make people what would motivate them to choose something not optimal.
That's one example I can think of just like you get like a flinch reaction when you're querying your emotions about something.
And then what was what was the thing you were saying, Stephen?
It sounded more like you were just saying that like basically this person's kind of weighing their values and in this case this person more strongly valued kindness in the world than whatever the optimal state was going to provide for people.
Yeah, or they just expected that having some autonomy could keep them like and I'm not sure who this person was or what was going on there.
But I could imagine like, you know, voting against, you know, who I thought like might be, you know, really well qualified or something.
But like, no, let's let's go ahead and keep, you know, a way where we can all keep weighing in at some point or something.
Right.
Just, and I'm not necessarily advocating that democracy is the best way to do stuff.
But I could see the argument just that not handing off all the responsibility and all the power to something like lets you, I don't know.
Maybe the government example, although I do like how this post jumped back and forth between like individuals and government and they even mentioned Plato a couple of times because that was, you know, when we brought up early on that like there's a good analogy between how humans run and how societies run.
The, like, you know, personally, it's just nice, you know, again, this weekend, I play a lot of video games and watch TV, like it's, it's up to if there was still somebody in my life calling the shots and saying you can't do that, I might be like pissed even if I knew that they were right.
Kind of like doing your homework or going to school.
It's like, I know I probably should, even though when you're a high schooler, it's hard to see the value in it or something.
But the, I don't know, at some point, I think lose like the, when you, when you gain the autonomy to like make your own decisions and decide how you're going to spend your time, giving that up, like takes away something that you really, really value, which is the decision or the ability to make decisions, make decisions that someone else and you would probably would agree is not like the best way to spend your time.
But it's like, you know, I feel like doing that right now.
I'm not sure how this ties into, I guess I can see it, but it, sorry, I'm hedging on this because like optimizing things, optimizing your decisions is great, right?
But I don't know, I guess I don't feel constrained to do the best thing that I want to do all the time anyway.
You know, like, if I want to take, well, because that's my preference to shift all the time, right?
And so maybe that's why you like autonomy, because you know what your preferences aren't someone else doesn't.
Like if you want to take, if you want to take the long way home from work once, because you just, you want to 10 more minutes to relax or, you know, there's a prettier parks drive by over here.
Well, you're spending more time on the road, you're putting more CO2 out there, you're not home faster, so you can get home, you can get started on the things you need to do at home right away.
Like if someone else is making the decisions for you, you, you're, you're much less free to do your thing.
That was kind of, I think what Sarah was saying about a kind of losing degrees of freedom by choose, by like being, you know, forced to choose an optimal outcome.
No, go ahead.
Sometimes it's not even other people choosing for you.
It's just an optimization process that you think this is the most optimal thing.
So you feel constrained to do the most optimal thing.
Yeah.
I'm thinking about a discussion that some of my friends were having recently about feeling like I need to save the world.
And, you know, have a high paying job so I can donate to effective altruist groups and then someone else saying, but like, is that better than living a hedonistic life where you're just making yourself happy?
Yes.
And then like, how do you define better?
There was this whole discussion that I'm still very confused about now.
That 4,000 year old conversation about what is the good life.
Yes.
You guys didn't settle that over lunch?
Oh man.
Not yet.
Actually, we touched on the next quote already or the next bullet point we had here, which was that this is true at an individual psychological level too.
Of course, we want to be free to waste time and resist pressure to account for literally everything we do.
And I'm glad that I articulated my thing before I read basically what she said much more succinctly because I was making kind of the same point.
Yeah, that made me well.
Allegibility partisans say that the weekly enforced rules are the only way to incorporate valuable information.
Precisely that information which enforcers do not feel they can make explicit, either because it's controversial or because it's too complex to verbalize.
If you make everything explicit, you'll dump everything in the world down to what the stupidest and most truculent members of the public will accept.
Say goodbye to any creative or challenging innovations.
Yeah, that kind of was the military general example or the band goods shop example.
There was a good back and forth about that in the Talking Heads debate with Massimo Buclucci and Elias Udkowski when they were talking about, I think, uploading.
And that yes, it would be like murder by textbook definitions that we have now, but like you would continue on in a way that you wouldn't be murdered.
Like yes, you'd be killed.
You might be offline for a minute or something or whatever, right?
And then Massimo was like, do you really think like that you could get like the courses on off on this and Elias are kind of splitters?
He's like, do you really want to constrain like the best choices about what can be explained to the average judge?
Yeah, I've had, I don't know.
I've had that argument with people too where it's the, I guess, Star Trek transporter, but that's not really you.
It destroys you.
And then the new, yeah, that's like information theory, differential distance.
I still don't understand that.
Yeah.
I mean, we'd have to have someone, I guess, who believes that way on the podcast because we'd all just fall into the chorus of jerking each other off again.
The jerking off there being that the transporters totally fine because you live on in the ship or on the planet.
Yeah, that's my intuition as well.
I don't see myself, I guess, yeah, you're right.
We need somebody else to articulate the other position because I don't see myself being destroyed as a bad thing, provided that I'm reconstituted shortly thereafter, right?
The argument is that that's not quote unquote you that's being reconstituted.
I wonder how they know that.
I guess they'd ask how I would know that I'm the one that's reconstituted or something.
But like, if it has my memories and personality and my vague physical shape, then that's kind of all I care about.
Yeah.
Shrug, that's a whole another conversation.
All right, yeah.
So being predictable is in Venkat's writing, usually a bad thing because it means you can be exploded by adversaries.
Free people are inscrutable.
In other contexts such as parenting, which we already talked about a bit, being predictable is a good thing because you want your kids to have an easier time learning how to work the house rules.
And then I'll just read the last one.
The basic argument for optimization over arbitrariness is that it creates growth and value while arbitrariness creates stagnation.
The argument for arbitrariness is I'm going to defend my right to be wrong because I don't trust the world to understand me when I have a counterintuitive or hard to express or controversial reason for my choice.
I think that makes sense as long as like you have one, right?
And like in theory, you should be able to explain it to somebody.
You know, again, it might take a while. There might be a huge inferential gap to cross there.
Like if we're arguing, uploading to muggles, then like we have to, you know, go through a lot to explain why that's probably a good thing.
And in real life, you usually don't have the time or like that person's not going to sit there and willingly listen to the whole explanation.
There's things that I think you just can't explain to people.
But I think that's basically just another argument of you should be free to make the most optimal choice.
It's just that you can't always explain the most optimal choice.
I think that's what this is saying.
But I think sometimes you can just be indifferent among a bunch of choices and you shouldn't have to go with the one that's most optimal.
So those are two different statements there though, right?
Yeah.
Yes, like on the first one, that's kind of the advocate for like why you don't want someone else to make your decisions for you.
Right.
Because they might not see why, no, look, this really is better for me.
Look, mom and dad, I know you had this track for me to go to college and do this and that, but I've decided that for my own best life,
I need to take a year off and then go to trade school or something.
And they're like, no, we had this Ivy League track for a year or something.
And it's like at the end of the day, maybe that's too specific of an example.
But it's easy to imagine circumstances where like you as the person who knows more facts about what's going on in your head than they do probably are in a better position to make that call.
Like as a child, you're probably not.
Like an 11 year old who says I'd rather have, you know, ice cream and pizza for dinner and not go to school.
They're probably not the best ones to make decisions for themselves.
Sometimes I do things that are self-destructive and I know in the moment that I'm doing them that they are self-destructive.
Every time I get drunk.
Should I not do that though?
Well, that's, you know, you've weighed your choices ahead of time and.
And I know it's the wrong one.
Well, wrong.
I don't know.
You're trading your short term pleasure now for the.
Then, then yeah, that brings into, you know, question the system one system to kind of ability to think short term, think long term.
And we have that reptile brain that is going to generally overpower the system to a lot of the time and like been there longer.
And like what kind of ability do you have to your future self?
Like you work out a few times a week.
I try to and like that's because I know that down the road future me will appreciate it.
And, you know, it's not just that currently also appreciates it, but not in the minute that I'm working out.
Like I'd rather be laying down and watching TV for the most part, right?
Working out can be fun, but most of the time it's not.
If it's super easy and relaxed, you're probably not working out hard enough.
Yeah.
But we're like somebody gives up smoking, for example, they're going to have an annoying few days where they're like, oh man, I could really use a cigarette.
But you know what?
A year from now, I'll really be happy that I made this decision.
So I'm going to make it for future me, not for present me who's dying for a cigarette.
There's that line.
So we're coming down on the on the side of people should generally make the most optimal decision?
Well, I think that it's, you know, in the post is long and it covers a lot of content, but I guess it's not clear to me.
Like because you're weighing in like your expressed goals of like, I want to make X amount of money.
I want to buy this thing, whatever your goal is and then how to get there.
But all of your like your implicit assumptions are like, excuse me, your implicit goals.
Like I actually want to be happy or, you know, like you don't want to get a, you don't want to like schedule your day.
So you have enough time to get a good night's sleep tonight for its own sake.
You want to do that because you'll feel better the next day.
And it's like, that's your real goal.
And so constraining it by like the decision tree that led you to like, nope, I'm going to go to bed at 10 o'clock.
And that, that is subject to revision when there's something else that you can do, you know, like drink coffee or something.
And better coffee 2.0 that, you know, actually makes up for lack of sleep.
So I think maybe, maybe there's something hard about like the question of like, what's your coherent extrapolated volition really, really, really aiming at here, right?
All the things that you, that you actually want that maybe you haven't articulated to yourself yet.
Yeah, we don't know our own preferences a lot of the time.
We have different parts that have different preferences that fight with each other.
There's people that will kind of prefer to satisfy other people's preferences over their own, like a parent with their child or you with a loved one.
It's a, it's a much more complicated topic than like, which is better in difference or optimization.
Maybe I want the freedom to choose which, which choice, which, which mode I'm going to be in when I'm making a decision, right?
So like, some days I want to do the, the indifferent because sometimes I, some days I just don't care, you know, and not to say that every possible outcome is equally distributed.
Like, what do you want for dinner tonight?
You know, when I say I don't care, that doesn't mean like I'm okay with skipping dinner or eating, you know, rocks.
So like, when I, there's, it's not that every possible outcome is the same value to me.
It's that like every possible outcome in the space of things that I know you're like, that we're vaguely talking about are the same.
Like, do you want, you know, Mexican Chinese or, or burgers or something, right?
Like the freedom of speech thing that she mentioned.
Yeah.
That within these bounds, you have the right to say whatever you want.
Or, you know, within certain bounds, you, you feel free to eat whatever.
I think the within certain bounds part is, is what I was getting at there.
Maybe optimization is more about like finding better bounds.
Yeah, I like that actually.
All right, I have a question for you too.
Okay.
So can somebody have freedom if they have inaccurate information?
Ooh, that's a really good question.
Huh.
Because that was something I was thinking about in regard to this.
How do you even make an optimum, like, I think humans never have perfect information about anything.
Yeah.
And that kind of relates to the topic of letting authorities make decisions for you,
whether that's parents over their children, governments over citizens of religion,
over the adherence to that religion.
Right.
There's a complicated topic.
Can you make an optimal decision without all the information is the question?
Well, no, no, you obviously can't make an optimal decision if your information is wrong,
but do you have freedom?
Right.
I know that's raising the question wrong because that one was easy to answer.
I guess you could say you could make a most optimal decision.
Yeah.
That's based on your current information and that's still probably worth aiming for.
That's probably what I would say, right?
And in fact, that's what anti-vax parents are doing, right?
So they're making what, I mean, they're not vaccinating their kids because they hate them
and they want them to get sick and die.
They're doing it because they really think it's the best choice for them.
So like they had the freedom to make a bad decision based off of bad information.
Sorry.
Can you repeat the question?
Because the way you phrased it was hard and I'm rephrasing easier questions by head on
accident.
Yeah.
Basically, I was just saying to what extent can we say people have freedom if they don't
have access to perfect information?
And I guess like, you know, we kind of answered that the, you know, nobody has access to perfect
information and you have to just make the best, the most optimal choice within the bounds.
And I guess then thinking about that, I agree with what Eneesh was saying about it.
It seems like a goal should be making better bounds.
And you can do that by learning more if you can about the question you're trying to answer
and the problem you're trying to solve.
See, it's different because I feel like you should have the right to make the wrong decision
if given that you have all the information.
But if you don't even have correct information, in what sense are you free?
Yeah.
And I'm still struggling with the idea that like, anyone ever makes the wrong decision
quote unquote.
I think everybody chooses kind of what Steven was saying, what they think is the most optimal
choice based on the information they have.
I think like very few people are going to be like, I know that this is good, but I'm going
to do this other thing that is bad.
Like that there's the, you know, the trade off of alcohol, but that's just a, I know
that like I'm going to be hungover tomorrow.
But right now my preferences are I choose to have fun tonight.
I'd rather borrow happiness from tomorrow and have more happiness tonight.
Yeah.
I don't know.
There's, there's times when I'm self destructive or it's not even that.
It's just like, I want my outsides to match how my insides are right now.
And that, that involves them destroying.
Even that's working on a preference to like feel your emotions more strongly though.
I guess.
Or to have them kind of like, like, uh, reach some kind of catharsis about them.
I just like, I really am having a hard time imagining a, and then maybe, maybe it's just
a, the definition of what a good or a bad like choice is.
Well, and it's easy to imagine like someone making a bad decision, you know, because
you can, you can look at it in hindsight and be like, look, that decision killed them.
Their decision to use that much drugs was a bad decision because now they're dead.
Um, or their decision to, you know, uh, put all their money on the roulette table was
a bad decision because they lost.
So I know we've all seen the dark night in the situation where the Joker tells Batman
that your love interest is over here.
Harvey Dent is over here.
And now Batman gets to choose who he wants to go save.
Given the fact that the Joker lied to him and actually swapped the, where he told him,
did he ever have any sort of choice?
I guess he, he sort of did.
He still chose who he wanted to save, but.
He couldn't save Rachel.
Yeah.
In the situation because he, did he have the freedom ever to save her then?
No, not really.
The Joker constrained his, his abilities by giving him the false information, right?
Yeah.
He had the freedom to decide who he'd rather save, but not the freedom to actually do
anything.
Right.
Which is what makes, like, that's what makes that decision, like by the Joker way more
evil.
He could have given him a random location of an empty warehouse, right?
But he actually sent him to Harvey Dent's place, which is hilarious.
You know, the Joker got a good laugh about it.
And that's, that's what makes the Joker such a good bad guy.
Um, yeah, that's interesting.
I don't know, like reading this article, I'm just like thinking of the opinion that
I just want us, I want there to be more freedom.
And like by freedom, I mean information, I guess.
Well, sure.
But do you also, by the definition of this article, therefore want there to be less
optimization?
Because if you always choose the most optimal thing, you're never free.
I was going to say freezing it in the sense of always choosing one or the other.
I think it was the trap that the essay is trying to make us fall into, but there's
no reason to go into.
Yeah.
It's like, you're free to make, you're only free to make the optimal decision if you
have all the right information.
Um, but that's assuming you want to make the optimal decision.
Sometimes you just want to fuck around and, and, you know, waste your time.
So you're free to choose the most optimal decision, but you're also free to not do
so.
Right.
Okay.
So like, it would sure be nice.
Like if my, if my decision was like, all right, in five years on making this amount
of money, working at this place and have a house this big or something, whatever your
arbitrary, measurable goals are, then there is some path to victory there, right?
Um, like it's not clear to me if Contessa's power from worm could say, I want to waste
tonight.
What's the best way to do that?
Right.
There probably is some answer to that.
If you're, but like, I guess it's not clear what waste means there, but like what she,
what Contessa can do is not use her power.
So she has the path to victory that gives her the optimal, uh, 117 step route to solving
whatever problem she's facing.
Or she can say, I'm not going to ask my power and I'm going to just do what I think I want
to do.
So that sounds like the best, that sounds like the best outcome.
Kind of like having that, that, that earring parable with Scott, Scott, Alexander's post,
but not having to wear it all the time.
The downside would be like that.
If you are wearing it, life would be so much easier and you would be offloading a lot of
your decision making onto this thing, but it would be, it'd be a cool thing to have,
but one to be like really careful about using, I guess.
I think I'm still struggling with is the, the idea that there is such a thing as a bad
or a good choice or an optimal or a non-optimal choice.
In the case that such a thing existed, that a person would ever be, would ever want to
or be able to choose the bad or the non-optimal choice.
I mean, people can be wrong about what the actual optimal choice is, but like, who is
deciding what is and isn't optimal here?
Like you can, um, look at your brother and like be like, okay, like I'm a rationalist
and my brother's, uh, not and I can see that he's doing this thing and I could tell him
like, hey, obviously the optimal thing to do would be this, but then your brother could
say, well, I'm a hedonist and I don't actually care about advancing my career or this or
that.
I just want to have a party with my friends every night and that actually is his preference.
Are we talking about what someone's preference is?
What is actually making them happy?
Or like, are we defining optimal by some other metrics?
That you're an effective altruist and a rationalist and all that stuff?
Yeah.
Um, I, I take it to mean that you're actually going for what you're aiming for.
So in that case, your brother's aiming to have a good time.
Yeah.
Um, you know, not necessarily looking at looking at a hypothetical person, um, you know, who
says like, I guess you could say it was a wrong decision if like what they thought was
going to be a good time actually sucked or, you know, like led them into, you know, a
long strain of decisions that they regretted.
Um, so like if you're, if your thing is like, I'm going to party four nights a week and
then you fail out of college and you can't party anymore.
Right.
Then you can't party anymore or you can still party.
Well, you can have much worse parties by yourself.
Um, but like, you know, if you wanted to do both, you wanted to go to school and, and
party a lot, but like it turns out that you miss measured the scales and you failed out
of classes or something.
Right.
I think there is some level of extreme extrinsic good and bad in all these questions too, because
right now we're just focusing on what does the person think will make them happier or
whatever, but, uh, all your actions affect other people too.
So if you, if you put stress on your family, if the emotional financial, whatever, if the
rest of society is being brought down by your actions in some way, those could be classified
as bad, even if it's what's making you happy.
Cause everyone else in society now has a reason to try to, uh, make you not pursue those particular
goals or at least moderate them in some way.
Yeah.
Actually, uh, thinking about that, I think you're right.
And in the example of the hypothetical brother, there's still the internal family systems.
Um, there's like the domineering part of your brother who wants to party and then there's
the part of your brother that doesn't want to like be broke and sitting outside the 7-11
out of a brown paper bag, party of one after failing out of college and not having any
way to make money.
So yeah, a person is like a society and.
And a person is in a society.
Like the point you're just saying, yeah.
So, and even then too, like this, this hypothetical person still wants like presumably healthy
relationships, cause that's part of being a happy person for almost everybody.
And if some of their decisions are ruining that, then they're going to be like, oh, that
is something to do.
I should have done that.
Yeah.
And yeah, there are certain measurable things like you were saying, uh, having human connections,
having enough food, having shelter, like there are certain basic needs that we can actually
measure and figure out whether these are being met for this person.
So it's not like just people.
There's not such a thing as a person who only has one, uh, utility function.
Yeah.
Or if they do, it's a lot of numbers and they get a lot of weird answers depending on how
you're running them.
Like if you spend five years chasing a gambling addiction and at the end of it, you have nothing
and everyone hates you because you borrowed a lot of money that you can't pay back, then
like you've made the wrong decision.
You should have stopped earlier.
Um, even, even if that was me, I would think that I'm assuming, right?
I look back and be like, well, that sucked.
Even if each individual bet was fun at the time.
Right.
Yeah.
Now I'm wondering if I'm going to look back and be like, there's a really annoying question.
So like each individual episode was fun to record, but man, this podcast was a shitty
or like rewatching or like wasting my time.
Um, so like Sam Harris does this at the end of his shows, which I feel like isn't, like
it doesn't fit with the rest of his, his podcast, uh, personality where he does like free fire
questions.
It's like the same five cast questions for every guest.
He doesn't do it every time, but he does it to a lot of people.
And one of them is like, um, what, what are you doing now that in 20 years you'll expect
you'll regret doing?
Right.
And Robin Hansen is the only one so far.
I think he's had the best answer to that, which is like nothing.
Cause if I was aware of that, I'd stop doing it.
But that's, that's Robin Hansen.
Robin Hansen was also brought up in this post as an example of an optimizer.
Right.
So for the rest of us humans, um, it's like, there's a good chance that I will think, oh,
you know what I should have done through 2018 and 19 is instead of, you know, binge watching
shows that I already seen and playing video games, I should have like read more books
on my job.
So I could advance my career raster or something.
And yet I'm not sure if that'll hold me back enough to like make me regret doing that.
Cause I'm having fun.
Yeah.
I found a way to feel less guilty about watching TV.
Like generally what I do when I'm working out is like watch a comedy show or something.
Right.
But I can't really watch them much cause most of the time I'm not facing the screen, which
is why they're comedy shows.
Uh, and I've needed some falling behind on things like Umbrella Academy and all this
other shit.
Uh, I picked up a guitar and now I'm just kind of like practicing my fingering while I watch
things.
And I'm like, Hey, I'm doing something at the same time that I'm wasting time enjoying
myself.
So, uh, you know, figure you spend 20 minutes a day practicing fingering.
It's not much, but over the course of 10 years, you might be able to play a song or
two.
And the other way to do that is by Nintendo switch.
So you can play video games and watch TV at the same time.
How do you enjoy either one when you're doing both?
Um, so at least fingering is pretty mindless.
I used to like play video games and listen to podcasts as long as it's not like a story
heavy video game or one that takes a lot of your like four brain to solve a puzzle.
Yeah.
So if I, if I'm playing a game like God of War, which is actually really story heavy
and there's like, there's too much going on to like do I do something else?
Um, those, but those ones are like more intrinsically fun than just like kind of like, eh, you know,
or like, like Sudoku or Tetris or something, right?
Where it's like, I'm engaging brain a little bit.
So I can play Sudoku and do anything else.
Um, but the game that I'm thinking of that I got on the switch, there's, it's like a turn me.
You got to press a every time you want to continue the game.
So like there's like dialogue that you can like most games, I guess, but, um, it's called hand of fate.
You can Google it if you're curious what I'm talking about.
But it's a card one.
Yeah.
Okay.
But the short version is that it's really easy to play this game in a way that I can constantly look away from the screen.
So that's how I can watch TV at the same time.
But, um, I should move on.
Yes.
And I think this makes a wonderful segue to something I've been meaning to bring up for a long time.
Let's do a little intermediary section between now and the less wrong posts.
Uh, World of Warcraft Classic is coming out August 27th and I am so fucking stoked guys.
Woo.
Oh my God.
Oh, cause I, I played this game a lot when I was fresh out of college.
Uh, and good Lord, it's just so, I was about to say so much fun, but it's hard to call it funness.
I recently saw a video which put it up, which summarized it well.
A lot of people are looking for meaningful work that meaningful work feels very rewarding.
And World of Warcraft, uh, the original classic is a very good game simulation of meaningful work.
Yes.
Uh, because it is work.
It's not necessarily fun what you're doing, but it feels meaningful because you are helping your community.
You are helping your guild to get better and to get stronger and you will all be doing something together.
So everything that you do always feels like it is good for your society.
And to contrast that with like a bad video game where like in Warcraft, correct me if I'm wrong.
I never played it because I knew I didn't have the discipline to play that and have a life.
Like, you know, eat and sleep and go to school.
Um, but where if you do the thing, if you go through the quest, beat the big boss at the end, you get the prize.
Not every time.
Not every time.
Okay. Well, at least it's still fun to do maybe.
Yeah.
Whereas like a game like Destiny is where it takes four hours trying to get through this long raid and there's like a 2% chance of getting the prize.
Right, right.
And like the work isn't even that much fun.
It's more like all these stupid puzzles and like you got to shoot and stuff or whatever, but like it's more just like jumping through all these hoops in a way that isn't at all rewarding.
Yeah.
Um, the current World of Warcraft, I've been playing it a little bit just to like get my fix in.
It's first of all, it's completely different game just in terms of game mechanics.
Like this is not the same game that they had 14 years ago at all.
But also now it's much more of that looter shooter thing where you you sign in, you play for 40 minutes, you get your shot at some loot if you accomplish your mission, which generally always do.
And then that's it.
There's no community, the people that you played with you probably won't see again unless you've like started your own group.
But, uh, yeah, just it doesn't feel the same at all.
There's no, no real continuity.
It's a one-time session game that you can play over and over in 40 minute increments rather than a persistent world where what you do feels like it matters from week to week.
Hmm.
So it still can be fun if you like that sort of, you know, kind of a actiony puzzle game sort of thing is how I think of it.
I guess you said the same thing about Destiny.
It's kind of like a puzzle game where you shoot things.
Yeah, because it wasn't fun.
Yeah.
And that game had so much hype behind it.
And they had Peter Dinklage back at like, you know, the Prime of Game of Thrones do the voice with a little robot.
And they're like, we're going to keep adding stuff to this game for 10 years and it's going to just, you know, it's going to be coming to you guys for free and we're going to just keep making this game bigger and better.
They're charging like 30 to 60 bucks for every expansion and then like dropped after two years.
And they even like ended up replacing Peter Dinklage as the voice actor because they just didn't want to keep paying him.
So they had someone else do it.
It was like that whole game was a great to me like lesson in how like to do something the wrong way.
Yeah, my coworkers were super addicted to that game, though.
I mean, regardless of all the dropped balls and missed opportunities and broken promises.
They do a good job of making addictive addictive games.
Yeah, I think it was just the we were working together in an office all day long and then these guys would go home like have dinner and then they'd all log into Destiny and like and play together.
So it was still the community aspect of the game that was getting them to come back to it.
Yeah, I did that when I was delivering pizzas.
The guys that I played with we played Call of Duty and that's like it's a lot of the same.
It's the exact same kind of game.
You know, first person shooter and the zombies missions are a lot more like playing Destiny raids where it's like,
except you don't win at zombies, you just get further.
But like all the fun of that is playing with a team that's good and wants to cooperate.
Do you feel like when you successfully meet your goals, you're making the entire team better?
Not in either of those games, except like because in Call of Duty, you're not progressing at all.
There's not like experience levels that you're gaining playing the zombies missions and in Destiny, you're typically only strong enough.
And I'm talking about the first one.
I never played the second because I decided I was never going to give them my money again or I never and I'd never reserve a game again like pre-order.
So although I did pre-order Breath of the Wild, but I knew that one was going to deliver and it did.
So good.
Yeah, the thing you're talking about, Edie, that was so rewarding.
I didn't play World of Warcraft.
I was addicted to Ragnarok online for six years.
It was great.
I had this group of friends from like, I was playing on the international server.
So I had a friend from China and a friend from Brazil and friend from Mexico.
I'm still in touch with some of these people.
Two of the people that like, like six years ago, like we're like dating online.
There was a girl from Florida and a guy from Mexico are now married.
Nice.
I went and visited them in Florida.
Like, yeah, like that was kind of my substitute for having real life social interactions because I used to be too socially anxious to talk to people.
And I think a lot of people are that way too.
So I don't know.
I have mixed feelings about MMOs that do community stuff really well like that.
I think they are really great for people that don't have that ability in real life who are socially anxious, who are maybe like live in the middle of farmland and don't have access to people.
And then there's also the dangerous addictive quality.
Yeah.
The addictive quality is something to be worried about.
But like, even if you have access to people, like if you live in a big city, it's like sometimes playing a game is more fun than doing real life.
And, you know, you can meet people that, you know, your friends in real life don't have interests in.
That's why a lot of the less wrong communities online, right?
There's definitely a benefit to doing it in person too.
But to the extent that you can't or it's inconvenient because you live all over the state or something or all over the country or world, that it's nice.
We'll just like, you know what, Friday and Saturday night, we're going to get online and chat or, you know, kill some monsters.
Yeah, it's a fake world, but it's real relationships.
Yeah.
That shouldn't be the tagline for a game.
That's second life.
Yeah.
I guess the thing that's dangerous about them is the substituting fake work for real work or vice versa, you know, where you're leveling up and you achieve quests and you have like these metrics for everything that you can see and measure and you get the little like slot machine dopamine release of reward when you level up and there's fanfare.
Well, real life doesn't have that and it's much duller and harder.
It takes longer.
And that's how games are rewarding is like you good games are.
And that's what I was trying to get out with.
I got some of the specifics wrong, but with World of Warcraft, you kind of get in, you kind of get out what you put in.
And maybe if you hit a level cap or whatever, then you're just in it to see if you can get the last little thing.
No, MMOs are pretty famous for, for rewarding time played.
Right.
More than anything else.
Yeah.
Grinding ability.
And, you know, every time you kill this thing, you're going to get X amount of experience.
And if you're trying to get experience, you're going to get that doing it.
So whereas in real life, it's always a crap shoot.
So speaking of all that, I am creating a guild on a PvE server alliance in North America.
So if anybody wants to join, I'll put a link to the discord that I have created.
I'm assuming there won't be too many people.
I certainly hope there aren't like a hundred people in the guild because that's 50 more people than we need.
Yeah.
But if you're interested in playing, come on in.
Obviously we'll start with more than the required 45 because I expect a decent amount of people will drop out during, you know, the leveling process before they hit Max.
Do I need PC to play this game?
I believe there's Mac versions.
Hmm.
I'm wondering if I want to do this.
I'm sucking you in.
Raid times are going to be Sunday and Monday nights once we get up to raid, which will be a few months.
Okay.
I'll give it some thought.
Okay.
Yeah, I'm considering it.
I don't actually regret the six years that I was addicted to MMOs, but that was because I used them to teach myself how to do real life social interactions and like stuff with economics and just like overcoming an adonia.
I don't know.
There's useful stuff about games.
I don't regret my time in World of Warcraft either, but I also like eventually just stopped playing.
I learned how to do all this stuff in real life and now like I can get a real job and make money with it or have friendships in the real world and it feels better than doing it in a game used to.
I've gone back and tried to play it again and it's not as rewarding after I've experienced the real thing quote unquote.
That's what I'm kind of worried about.
That World of Warcraft just won't be as much fun now that like you said, the real thing exists.
So maybe I won't even get up to 60 myself, but I'm always going to give it a shot.
It's worth experimenting.
And that's the thing too is like assuming you already have the hardware to play it like the game is 60 bucks, which is like nothing to shake a stick at.
But you know, if you play it for 20 hours, which is probably a gross underestimate, you know, that's three bucks an hour for fun.
That's like that's way less than what you'd be willing to pay for a good time.
So like that was the thing, you know, we talked about that game that I was playing.
It was 30 bucks.
I bought it on a whim because I'd liked the first one a few years ago.
I was like, even if I only play this for 10 hours, like that's still a lot less like dollar per hour of fun than, you know, going to the movies or something.
Absolutely.
Which I'm planning on doing here at some point probably today.
So I don't I think my usual threshold of like, you know, movie is like whatever six bucks an hour for fun.
That's probably too much.
Well, it depends.
I don't know.
Yeah.
Six bucks an hour for an hour and a half movie that'd be like, yeah.
Movies.
I guess movies are a bit more expensive than that here.
Well, I was also saying they're a bit longer too.
So that's true.
They have been creeping up.
Yeah.
Most of them are around two hours now.
Yeah.
Kind of wish they would make some shorter movies.
Yeah.
So I can like actually watch them sometimes.
Dude, watching Army of Darkness now is crazy.
It's like 74 minutes long.
You're like, whoa, is this is this a TV episode I just watched?
It's over already.
Yeah.
Especially with all like the Netflix originals that are like 50 minute, 55 minute episodes or something.
And it's like a mini movie or like Game of Thrones is an hour.
Like the last one, the last season was like an hour and 20 minutes in episode.
So where's it?
I didn't think any of them were that long.
So season seven, they have some that were that long.
Well, some of them anyway, we're over an hour, which is over the time.
I love it for a movie or TV show and is encroaching an old movie time territory.
So yeah.
And then there's Avengers Endgame that was only three hours or three three hours long and it wasn't long enough.
It didn't feel three hours at all.
No.
It's crazy.
Shall we move on to the last wrong posts?
All right, let's do it.
Let's do it.
The last wrong posts.
The first one that we are reading and talking about this week is Universal Fire.
This is actually one that I did a.
I read the essay out loud in one of the down periods when Eleazar was writing more chapters of Harry Potter and the Methods of Rationality.
So I will post a link if you want to hear me reading the entire thing that exists.
There just occurred to me.
There are also two other audiobook podcasts for the sequences.
Yes, there are.
That we haven't been linking to and kind of like just we mentioned them once or twice, but we never linked to them.
Yeah, we linked to them once or twice, but we don't do it regularly.
They're out there.
If you want to find them, they're both on iTunes, I think.
So yes, if you don't want to read these, you can you can listen to all of them.
Right.
Reading with your ears is so cool.
Yeah.
It's going to say listen to them while playing video games.
Exactly.
Optimization.
That's right.
While you're out there grinding bat dicks.
Wait.
What?
Is this a World of Warcraft?
It's a joke of one of my friends as a thing.
We're like, yeah, I'm just going to go out and collect bat dicks for the next two hours because you get random parts of the animal.
Not random, completely random, but like sometimes someone's like, I need to attend wolf pause.
And someone's like, I need 11 bears now.
And someone's like, I need 20 rat dicks.
50% of what I know about World of Warcraft or some of that South Park episode make love, not Warcraft.
Yes.
And I feel like they did a good job.
Yeah.
Even though I don't have anything to compare it to.
I did demo the game for like a week when I was, because there was like a trial that you could play.
And I was like, I'm way too into this.
I can't do it.
Because I think I mentioned this before offline, but I put, I think 450 hours into my first
playthrough of Elder Scrolls of Libyan.
Yes.
And I was like, that's offline.
That's a lot.
That's a lot of hours.
And like, if I was online, like not just like competing with myself and like trying to
make a great character, but also measuring dicks with everyone else out there, I would,
I would lose sleep.
I would just stay up all night taking caffeine pills and drinking soylents and just like running.
Yeah.
I don't know.
I would run myself ragged playing this game.
Yeah.
Not a good idea.
Not for me.
All right.
Universal fire in universal fire starts off telling, talking about a piece of fiction, a book where
Harold Shea is transported from our own universe into the universe of Norse mythology.
This world is based on magic rather than technology.
So naturally when he tries to light a fire with a match brought from earth, the match
fails to strike.
Boom, boom, boom.
Eliezer has a problem with this.
Eliezer says that Antoine Loren de la Vossier, I think.
Yeah, pretty good.
Okay.
Discovered fire.
His great innovation was to weigh all the pieces of the chemical puzzle both before
and after the chemical reaction.
So he discovered that all the parts including the weight of the air after a fire are equal
to all the weight of all the parts before.
He also knew how to separate gases and discovered that burning a candle diminished the amount
of one kind of gas, which they called vital air, and produced another gas called fixed
air.
Today we would call them oxygen and carbon dioxide.
When the vital air was exhausted, the fire went out.
He said that the thing that's really amazing about this is that way back in the day when
people didn't know how their bodies worked, not on a real deep level.
You could look at your hand and flex your fingers and really have no idea why that worked.
You know the muscles are doing work and moving them, but why are your muscles contracting?
How is any of this possible?
Must be the soul inside you, right?
Yeah, why does your hand move and not like a piece of clay that you're holding that shaped
thing?
All of this seems kind of obvious to us now because we all took elementary school science
and stuff, but just a quick side note there.
Anyone who hasn't read anything on a history of science, I think it's worth just grabbing
something like a brief history of nearly everything.
There's not a book version of that too, but just putting yourself in the mindset of somebody
who didn't know all this stuff already, because you look at it now and I'm like, oh, chemistry
is boring.
Do you have any idea how weird it was to live in a time when you didn't know what stuff
like now we now we know and it seems like something that humanity is always known, but
we've only known for like a few hundred years, like stuff made of atoms, right?
So that I think that that sort of thought experiment, which you can run by reading a
history book is like just vital to getting the wow of science and to make something like
this make more sense.
And that's yeah, that's where he points out, imagine not knowing all this stuff and then
discovering that humans in the course of breathing consume vital air and breathe out
fixed air, just like a fire will consume vital air and make fixed air, meaning that people
also run on combustion.
We're made of fire.
Which is like, what the fuck?
Which is I mean, that's pretty fucking amazing when you think about it, right?
Who, if you discovered that, would that not freak you out?
Especially if you discovered it in the context of knowing so little else about the nature
of the world, right?
Yeah.
And so it's, yeah, what you could infer would be through the roof.
Yeah, why is there fire?
What happens?
There's obviously no fire inside me, but what?
Yeah, like you put a candle in a jar and it eventually burns out.
You put a mouse in a jar and it eventually burns out.
Yeah.
Like why are these things the same?
Right.
Because you don't know what's in the air and you don't know, yeah, the parts of it.
Yeah.
Is the fire alive?
I don't know.
Elias explains matches catch fire due because of phosphorus.
He gives some breaks down a bit more.
I skipped ahead a little phosphorus is highly reactive.
Pure phosphorus glows in the dark and may spontaneously combust.
It's also well suited to its role in ATP, your body's chief method of storing chemical
energy.
If a match stops working, so do you.
For the match to not catch fire when phosphorus is rubbed against something would mean that
phosphorus isn't working, which means that our own internal chemical processes aren't
working either.
They both work off phosphorus.
So I didn't read this, this fantasy story, but couldn't humans also just run on magic?
I suppose that's I guess how it must have worked.
Yeah.
So that would have been a cool rationalist version of that story.
If like Harold Shea had been like, the match isn't working, but then how am I working?
And then done some experiments and been like, my body's made of magic.
Yeah.
That would have been cool.
He ends with phosphorus derives its behavior from even deeper laws, electrodynamic and
chromodynamics.
Phosphorus is merely our word for electrons and quarks arranged in a certain way.
You cannot change the chemical properties of phosphorus without changing the laws governing
electrons and quarks.
So if you stepped into a world where matches fail to strike, you would cease to exist as
organized matter.
This reminds me of a, I feel like there's been a couple of stories like this too.
But I remember as a kid, I had this book of a short like science fiction stories.
And there was this one where there were these two kids that discovered a time machine and
the one kid was cautious and looked like we shouldn't use the time machine.
And the other kid was like, I was born in the wrong era.
I need to live in Victorian times.
And then like finally they wrestle over the time machine.
The one kid uses the time machine and then she's just floating in space because she's
gone back in time to Victorian times.
But you know, everything has been moving this entire time.
Right.
That's also my objection with ghosts that unless like maybe they're affected by gravity
though.
So ghosts must be affected by gravity, I guess, which would make, which is weird because
they're supposed to be substance list, substance list lists.
And like if you're killed like on the fourth floor of a high rise and they demolish it,
make room for like a parking lot, are you just like floating up there?
Or do you like zip away from the earth when like, you know, the moment you die and like
every year the earth swings back.
But then of course the galaxy is rotating too.
So like you just never really get back to where you were when you died.
I did actually read this story about ghosts where a ghost like there's this girl who could
go back and forth between the spirit world and the real world.
And she kind of became a ghost when she was in the spirit world.
And at one point she's in her dad's apartment in New York and turns into a ghost and just
falls through the floor.
I love people actually think about stuff like that.
Yeah, I think Dan Dennett when he's talking about his, you know, mind stuff and all that
in some of it because the philosopher of mind.
Like how can Casper go through walls and catch a ball and play like catch with you?
Right.
So maybe he gets to choose which parts of him are corporeal.
That's that's how like a lot of the ghost movies handle it, right?
Movies like Ghost with Patrick Swayze.
Yes, yes.
Although he doesn't choose just not fall through the floor.
He just chooses to be able to push things over and stuff.
Maybe he's just subconsciously choosing that all the time.
Sure.
You'd think you could learn a lot.
Like that'd be like the fun way to fuck with somebody who's just recently a ghost, right?
They can't push things, but it's like you realize like you're doing it to the floor right now.
It's like either they gain the ability to push stuff really easily or they just start falling.
The character in that story actually was like, man, how do ghosts work?
How could I could fall through the floors here?
Why don't all the ghosts in the world just sink all the way like through the Earth's crust
and just stuck in a big ball in the core of the Earth?
I think we just figured out what hell is.
We did it.
Theology solved.
I guess if you like take a completely relativistic view of the universe, I mean, sure, maybe we're moving,
but there's no difference between that and everything else moving around us in relativity terms, right?
So maybe the ghosts are just like really, really into relativity.
I believe I am standing still and everything else is moving relative to me.
Things are moving in some sense, though.
I mean, the universe is expanding.
It's not like it's all real.
I mean, it is relative.
Never mind.
Your decision whether or not it's relative doesn't impact whether or not it is, right?
No, it's still relative.
Right, but that's something your understanding or your decision to accept that doesn't change whether or not the universe is relative.
It's not like an observer phenomenon in the sense that you're controlling.
Right.
We're moving relative to the sun and the sun is moving relative to us and how we choose to think about it is just how we choose to think about it, right?
Right, but not what we choose to...
There is no...
Our ability to interact with it isn't determined by our understanding of that, right?
Yeah, but there's no universal 0-0-0 coordinate.
But I'm saying that if you're a ghost...
Oh, they shouldn't be able to choose that either?
They shouldn't be able to choose that either.
Yeah, well, maybe that's the one magic power as a ghost.
That's fair.
Alright, universal law.
Someone else do this one.
I got it.
Cool.
It was one of the most startling unifications in the history of science for it brought together the mundane realm of matter and the sacred realm of life,
which humans had divided into separate magisteria.
So this is referencing the...
The prior post.
Yeah, the fire.
The first great simplification was that of Isaac Newton.
He unified the course of the planets with the trajectory of a falling apple.
Which, by the way, I didn't realize was as big a deal as it was,
but apparently people had a really big thing between the world of the mundane down here and the world of the heavens above,
which was like God's domain.
It was supposed to be a completely separate thing.
Yeah.
I mean, they actually literally thought heaven was above the clouds in the sky somewhere.
Right.
And that the stars were implanted on a dome around us, right?
Or separate domes that you get.
They're rotating in weird ways.
Well, depends on how far back you go.
At one point, yes.
I'm not sure what they were thinking in Isaac Newton's time at that point.
They may have still been doing the dome thing.
It depends who you mean by they.
Right.
There's a lot of people alive in Newton's time.
The most important thing is that like they're they're literally two different planes of existence, right?
It would be, I don't know, like the spiritual world and the real world.
Like this is the real world.
It's like the matrix, right?
As opposed to the world outside the matrix.
They're completely divorced and and trying trying to prove that the two were the same thing was just crazy.
Mm hmm.
Newton's discovery gave rise to the notion of universal law.
One that's the same everywhere and every when with literally zero exceptions.
Human beings live in a world of surface phenomena and surface phenomena are divided into these leaky categories with plenty of exceptions.
The only time when it seems like we would want a law to hold everywhere is when we're talking about moral laws.
But even here there's exceptions.
The idea of a rule with literally no exceptions seems insanely rigid.
The product of closed-minded thinking by fanatics.
So in the grip of their one big idea that they can't see the richness and complexity of the real universe.
Which did you guys get that a lot in high school too with people?
A lot.
Yes.
You still see it now with, you know, the White House saying that, you know, the established scientific criterion or scientific consensus on climate change has nothing to do with the truth.
Yeah, so.
But I meant not just in terms of science, but in terms of like, well, you're just such a rigid nerd.
You can't even understand that other people could be different.
I've got that in a lot with people talking about like spiritual phenomena or like astrology or whatever.
It's like, well, you know, we can't know everything.
Yeah.
Science, like that people, you know, scientists think they know everything.
They're just so closed-minded.
Yeah.
How can we ever really know what's true?
And yet you're going to tell me a book that tells me exactly where outside the box is.
Great, thanks.
Right.
But this is your chakra positions.
These are the correct ones too.
Yes.
So this is the customary accusation made against scientists, the professional students of the richness and complexity of the real universe.
Because when you actually look at the universe, it turns out to be by human standards, insanely rigid in applying its rules.
As far as we know, there's been not one single violation of conservation of momentum from the uttermost dawn of time up till now.
I think this is brought up in the post too, and I didn't copy it.
But sometimes when I get into arguments with religious people about what God actually cares about and people say like, God wants us to be happy.
God doesn't want us to be suffering or dying.
Have they seen the world?
Right.
Yeah.
God dislikes gay people.
I'm like, look, God made suffering.
God made gay people exist.
You know what God really fucking cares about?
Beatles.
No, well, what God really cares about is that no one be able to move faster than the speed of light because you can't.
If God was all powerful and really cared about something, you just couldn't do it much like the speed of light.
I like that.
And the Beatles joke is because there's what 140,000 different species of Beatles.
I think like 70% of all biomass is Beatles or something like that.
I'm not sure if that's the exact number, but like there's a lot of Beatles.
Hundreds of thousands of species.
Yeah.
I think it's more than 140,000.
I don't think we're the chosen species.
God's a beetle.
The Egyptians were right.
Well, I'm thinking about the beetle rolling the sun across the sky.
They have multiple gods though.
Anyway, sometimes very rarely we observe an apparent violation of our models of these fundamental laws, which yeah, my dad's like, I'm just wrong all the time.
If you'd learned to think like reality, then here's the towel.
Since the beginning, not one unusual thing has ever happened.
Yeah.
Fantastic.
Yeah, I love it.
And then rolling with the theme of thinking like reality, that's the name of the next post, think like reality.
Reality has been around since long before you showed up.
Don't go calling it nasty names like bizarre or incredible.
The universe is propagating complex amplitudes through configuration space for 10 billion years before life ever emerged on Earth.
Quantum physics is not weird.
You are weird.
Human intuitions are produced by evolution, and evolution is a hack.
When you go down the fundamental level, the level on which the laws are stable, global, and exception free, there aren't any tigers.
The fact that there aren't, in fact, there aren't any persistent objects bouncing around at three-dimensional space.
Deal with it.
Probability theory tells us that surprise is the measure of a poor hypothesis.
The model is consistently stupid, consistently hits on events that assigns tiny probabilities, and it's time to discard that model.
A good model makes reality look normal, not weird.
A good model assigns high probability to that which actually is the case.
You want to reshape your intuitions so that the universe looks normal.
You want to think like reality.
I still have trouble with that, but I do find I'm less surprised than I used to be since I've adopted this rationality thing.
Can you give any examples?
The example that most jumps to my mind is a time when I actually was very surprised, which was when Trump was elected.
I was shocked by that, which means that my model of American society was just way fucking off.
A lot of people said that in response to that.
People in this community, well, it happened, so clearly my model was wrong.
All of our models were pretty wrong.
We have to update our models.
I can't imagine what it would be like to say, no, my model was right, the reality was wrong.
That's not a very scientific or rationality-oriented way of thinking about things.
It seems like, at least in regards to the politics thing, a lot of people are like, I think I was right all along.
There was just this one special exception, this one time, and they come up with excuses.
It's like, no, man, if you were that surprised by things, your model was off.
You were failing to account for a significant thing that turned out to be rather important.
I know one thing that Julia Galev either does or did was keep a surprise journal.
That's a damn good idea.
Yeah, even if it's little tiny things.
Oh, I didn't expect that to work.
That's a really good idea.
I've been trying to do the calibration, assigning probabilities,
random kind of vast numbers to things, and then using that as my anchor to update on things when you're right or wrong.
But it's often really hard to do that in real life because real life doesn't come with numbers.
And there's a lot of things happening that you wouldn't have thought or took the time to predict in advance.
So one thing you can try and do is just train yourself to notice that feeling of surprise.
And then be like, oh, okay, what just happened? What made me feel that way?
Then you can assess those after the fact when there's downtime to think about it.
Yeah, you can count how many times you were surprised and see if it decreases over time.
Because, yeah, the other thing with the calibration exercise is that often the thing you're surprised about doesn't come up again.
So if you're like, oh, okay, I was giving that 40%.
I guess I better up it to 60.
Trump's not going to get elected again.
Do you actually think that he's not going to get elected again?
Oh, I don't know.
I was trying to think of an example of something that was really surprising that is very unlikely to come up again.
That was a bad example.
I should bet each of you 200 bucks that he does.
So that you get 400 bucks if he does?
Right.
But then I'm screwed because he's president and I'm not 200 bucks.
That's the win-win for you, Stephen. I see what you're doing.
Right.
So I think Stephen Hawking's thing, he wanted to bet somebody that black holes weren't real.
At least in that way he would have won the bet if he was wrong.
So this principle extends beyond physics.
Have you ever caught yourself saying something like,
I don't understand how a PhD physicist can believe in astrology?
Well, if you literally don't understand, this indicates a problem with your model of human psychology.
Perhaps you are indignant.
You wish to express a strong moral disapproval.
But if you literally don't understand, then your indignation is stopping you from coming to terms with reality.
It shouldn't be hard to imagine how a PhD physicist ends up believing in astrology.
I actually just said, I literally don't understand how people cannot accept the transporter argument.
Yeah.
And we need to update our vocabulary in this community to be like,
I am strongly morally disapprove of the fact that people think that the transporter argument.
I actually literally don't understand why people don't get the transporter argument,
which means I have a serious hole in my models of other people's psychology.
Right.
Yeah.
That's good to know, right?
So now you can actually like, wait, this is actually like a problem with me not understanding them.
Not a problem with them for being inscrutable.
Right.
This sounds like a thing, something that you can figure out.
I should hope so.
Yeah.
So I now try to avoid using the English idiom.
I just don't understand how to express indignation.
If I genuinely don't understand how my model is being surprised by the facts,
and I should discard it and find a better model.
There are no surprising facts, only models that are surprised by the facts.
Nice.
Yeah, to frame things, right?
Always working to get better models.
Always working for your models to be a little bit less wrong.
Totally.
Wait a minute, that's the name of the show.
Yeah, I don't know if it's like the number of times that I've read these particular ones,
or these are particularly good sequences,
but I feel like there wasn't much to say about any of these three,
like kind of just like a fist pump, like, yep.
Yeah, these ones are poignant.
I think that's probably why you selected them for episodes in the Methods of Rationality podcast,
because these ones don't require a lot of extra backlog or discussion or anything like that.
It's like, no, you read this and you basically get what it's saying.
Yeah.
Yeah.
Also why I had three of them in this episode, because I knew we'd get through them pretty fast.
And they're all coherent.
They all had one theme that they were hitting.
Exactly.
For next time, we will be talking about the posts,
where the unsurprised, the third alternative, and third alternatives for afterlife-ism.
Dope.
All right, shall we get to one or two listener feedbacks before we wrap it up?
Sure.
Alrighty.
Mr. Oliva says on the subreddit,
oh, this is in regard to our last episode about the is-ought distinction,
the is-ought distinction is not that statements including ought cannot solely follow from statements including is.
That your moral result must be the product of one or more moral premises.
Simply from describing the world, meaning cannot be derived without the arguer providing it.
Death is bad is Emyash's moral input to his argument.
Badness is not a measurable quantity of the universe.
I, so I understand what he's saying.
And I, I agree that badness is not a measurable quantity of the universe.
However, I disagree that you need moral inputs to make moral assertions.
So, in the example of death in the simplest case, we already, we already, at least I believe, we established,
I at the very least said that there is no intrinsic value to anything in the universe.
The only value that exists is what agents value, right?
We give value to things?
Yeah.
Okay.
I don't know if you said that last time or not, but yeah.
I meant to say that even if I didn't.
So, given that only agents can value things, what agents value is the thing that matters.
And since the overwhelming majority of humans do value their lives a lot,
they have a lot of reason to, first of all, pursue their own continued living and to make it so that people who stop others from living,
are punished.
And even better would be to make those people have an intrinsic aversion to taking others lives.
There's like, this is what badness basically boils down to, right?
It's things that I will be punished for.
It's things that I don't want to do because I have been inculcated by the rest of society that doing this will make me feel bad.
It will make me be shunned.
It will just everything about that's that's what badness is.
It's everyone coming together and saying, these are our preferences.
Please do not harm them.
And if you do, there will be consequences.
Like, does that, does that make sense at all?
Yeah.
I think this is the same intuition I was coming to when we were talking about the free will argument where to the extent that we can say that something.
I don't know.
Badness does have no meaning on the scale of the universe, but that's because like Iraq is not sentient.
We're humans.
We're, we're sentient.
We're able to come up with concepts like bad and good because we have sentience to be able to think about it.
And I think that you can actually, there is something measurable in the brain of all the brain or the nervous system of all living organisms that like, you know, the very core of every living sentient thing is that it wants to continue existing and being sentient.
So maybe it's not like a law of the universe the way gravity is, but it's a constant.
Or at least we haven't discovered any exception to this really.
It's a more or less universal law of human psychology.
And I mean, I think, like, I get around a lot of the like philosophizing on like good and bad and whatever by just saying like make the world a better place.
I know that like better than is doing the lifting.
But people I think have have have are less caught up in their intuitions about like trying to extrapolate what that means.
Like, all right, cool.
You mean like, you know, less suffering and pain and like more happiness and flourishing, right?
And it's like, yeah, exactly.
Whereas if I just say it's bad and like, well, what do you mean by bad?
What if I thought it was good and you thought it was bad?
Then our opinions equal.
And so you kind of you can occasionally dodge that whole argument just by by reframing the the the the position that way, right?
So if your thing was like death leads to a worse world or something, maybe it would be a little like that's not exactly the way to put it.
But yeah, I think it's more because people want to keep producing this to is statements.
And I think that people have a desire to live is an is statement.
You can measure, you know, if people have a desire to live or not.
And in some respects, how strong it is.
But me saying, I don't care about your desire to live and I'm going to do whatever I want.
You're saying I shouldn't do that is an odd statement.
Yes, and no, I mean, I'm saying that everyone who has a desire to live has therefore strong reasons to prevent you from wanting to kill other people,
both in terms of punishment and in terms of just creating in you a desire to not be a killer.
Yeah, but but like my in that circumstance, my desire to like not be a killer being shaped by society isn't because like I agree that death is bad.
It's that I agree me and being in prison is bad.
Well, or just that you acknowledge the fact that society has successfully instilled these emotions in you that you would feel awful if you kill someone.
Like would you feel awful if you kill someone is a yes or no question and has society instilled that that emotion in you is something that's probably measurable.
I know there's a lot of societies that do not make a distinction about some people that you're allowed to kill.
Yeah, but I think that those are societies where they dehumanize.
Yes.
Like you shouldn't kill people and your enemy does not count as people.
Yeah, but luckily gay people aren't people so we can throw them off of buildings or something, right?
Exactly.
Yeah.
So there's whether that emotion has been instilled in you or not is also a is question.
And why was it instilled in you is because the people who did the instilling had motivations of wanting to you to not kill them.
So I mean, I think it's all comes back to his questions.
Yeah.
I'm not sure if this is what Mr. Allieval was getting at here, but I remember being very tired and we recorded that episode and kind of after the fact being like it really would have behoved us to taboo a lot of words.
And that discussion because this is like a lot of the is on question relies on there being agreed upon meaning of words like good and bad.
So like probably would have been good for us to have good to have defined what we meant by that or what like maybe other people making that argument mean by that because I think that we're actually like people on other sides of this argument are actually usually talking about different things.
Yeah, you're right.
I guess I guess bad is my shorthand way of saying undesirable.
No, no, no.
In general, people have many reasons that actually exist for making you want to hate that have an aversion to doing this.
So like death is bad means that in general, everyone around you has many true existing reasons to make you feel bad if you kill anyone to make you have emotional pain when you kill people.
So it's a perfectly normative claim rather than a moral claim.
Yes.
Okay, cool.
And those reasons are that they want to live.
Yeah, the last paragraph of Mr. Oliwala's comment was even if we stated it empirically as death makes people sad and death causes people not to actualize their goals.
You'd still need to provide the moral statement people being sad and not actualizing their goals is bad before you could derive the moralized conclusion death is bad, which is yeah just defining what we mean by bad there.
Right, but you're not you're not making a moralized claim you're making a normative claim.
Yeah, I'm saying that people being sad and not actualizing their goals is a reason for them to instill in me the emotion of emotional pain when I do those things that would make them be sad or or not actualize their goals.
Yeah, I think this is a sense where the word bad has no meaning in the context of Iraq, like the word bad only has a meaning in the context of a sentient being.
Yeah, and again it comes back to sentient beings don't want to die sentient beings don't want to feel sad sentient beings want to actualize their goals.
Do either of you or did either of you read Sam Harris's book on the moral landscape.
No, I didn't anyway.
I don't think I have.
So it's, I think lyric, our friend of the show lyrically put like they point out that there's some like problems with the book that they're not a huge fan of.
But what I like about it is that it sort of like it deals with that same sort of philosophical bedrock question kind of like we just did and then like just kind of just past it.
Like, I think he bites the bullet in a different way rather than saying like look no this is like not just purely a fact about human psychology and I'm making normative claims about what people want and what they're trying to make you do.
It's more just like, yeah, I'm going to say that, like, that's one reason I like reading Harris's stuff is that he does.
He's one of the same tools that I like where basically he like reduces something to like an absurd level, just to see if there's like an actually an intuition there that's like that actually pans out.
So, like, I'll take something run run with it all the way and see if it's if there's anything that it makes sense.
And so his his analogy is like the best or the worst possible world for everyone.
And so like whatever that kind of means to you you imagine something that's like hurts all the time.
Whatever it is right now basically hell writ large.
If you don't think that that's bad, then we need to stop using the word bad or I have no idea how to talk to you.
Yeah, there's universalize will universalizable aspects to badness pain.
Yeah, one loneliness being one.
I mean, things that are the opposite of goals that we as a sentient being are trying to actualize.
And you could even just say it's like something that we want to avoid.
Like, and so that's where he kind of just comes down and says, like, look, if you say that there's no difference between like the best possible world and the worst possible world.
And you're like, Nope, I have no preference about one or the other.
And it's like, all right, cool, then I'm not talking to you.
I'm talking to people who can see why living in the worst possible world for everybody is is wrong or is bad.
And why we should strive for the best possible world for everyone.
And I just want to say that I did not come up with the vast majority of what I've said by myself.
This is almost everything taken from the works of Alonso five we had on the podcast once and his theory of desire utilitarianism, which basically says that all value boils down to what sentient beings desire and, you know, and our verse to have an anti desire for cool.
Yeah.
And as sentient beings, that's really all that we can do.
Yeah.
And, you know, I don't know, it's probably not the end all of all morality, but it's what I have latched on to what I think is the most correct description of how the moral process works.
Sounds good to me.
All right.
Sunday, Jay says, imagine a society in which every time someone had a health problem that could be fixed with a bodily transplant, such as blood transplant, bone marrow transplant, kidney transplant, a donor would be picked at random from the male population in a way.
If you didn't want to be a donor, then tough luck.
It's being a donor or going to jail.
There's of course always the chance of the operation going wrong and the donor would end up dead crippled, otherwise radically changed in ways that stop them from following their dreams.
If you value human life over the bodily autonomy this much and find such a society more appealing than the current one, I can respect your decision of being pro life.
So that was obviously in response to her abortion, a lovely, popular, wonderful abortion discussion.
Yes.
I, I'm, I'm mixed on this one.
Are you?
Would that be a good.
I think that's not a good trade off.
To, you know, I still, I still think bodily autonomy is kind of a value that I will defend.
I'm going to put the shelling fence there for good reasons and I don't think it's quite the same here.
Okay, say that, you know, you're chosen to give someone the kidney transplant.
You go to the hospital and they, they do the kidney transplant and it's against your will.
And now you have, but like you're actually fine.
You still have one functioning kidney.
Your brain's still the same.
The operation is like, maybe, I don't know.
I think the longest, maybe it could go on as a week.
They did point out like, oh, maybe you could like be injured or crippled, but otherwise you're fine.
That's not what pregnancy is.
No.
The last nine months, you can die.
Your brain gets rewired.
Your body gets changed permanently.
And now you've got a kid to take care of for like 20 years.
The effects of having a kidney removed are worse than what you were saying, but yeah, it's not as bad as nine months.
And like when you're done, having, when you're done recovering, you're done.
Whereas like you're not, when you, when you go through childbirth, like you can physically recover most of the way in most cases, maybe even all the way in almost all the cases, but as someone who doesn't go through childbirth.
You're often changed permanently.
Yeah, physically for sure, but you can recover.
And psychologically.
That's the part that doesn't recover, right?
But they'd be like, oh, that's not an injury or something, but it's like it is if you didn't want it.
It's like, I don't know, it's like getting hit in the head.
And like, sure you can retrain yourself to like, whatever, do all the functions you lost.
But like, if you could ever do them like you could before, or like your values changed, you'd be like, I didn't want to be a different person.
And now I am, you've wronged me.
So you're picking a random male from the population and then just scrambling their brain a little.
And sometimes you'll come out pretty much the same and sometimes you will be complete, like your values will be completely changed.
Yeah, I'd be fucked up.
Would you choose to do that?
It's so weird because this particular example of choosing a person at random to be a donor.
It's not, for me on the face of it, a terrible thing.
Well, it would be, it'd be super weird and counterintuitive.
I don't mean to interrupt, but like if you had a long line of people volunteering, you're like, nope, we're going for random.
That's weird too, right?
We don't have a long line of people volunteering though.
I'm looking forward to the universe where, and like we're getting there where you can just like grow an organ and not have to take one from a donor.
I mean, I'm also looking forward to the universe where we have like, you know, birth control is implanted in everyone at birth and you have to choose to turn it off.
Yeah.
And we can have babies in artificial wombs.
I mean, of course, now I'm just talking about like in my perfect universe, here's how things would be.
But you know, I don't like the fact that we're really like thinking about the way things are.
Like right now being the way things have to be.
I would also find myself wanting for the state to be much more of a police state if this was the case.
Because like, sure, I understand some people can't help it and they get bone cancer and they need a bone marrow transplant.
Like if someone had an injury where they were playing football and they ruptured their spleen and now they need a spleen at random, I'd be like, hey, wait a minute.
I don't play football.
I never put my spleen at risk.
Why do I got to give my spleen to this person who was, you know, recklessly playing football with people?
Especially if they're burning through three spleens a year because they realize that there are no risk of losing it forever, right?
Right.
Or like maybe lung transplants for the same thing.
It's like, oh, I can smoke like a chimney because there's all the lungs I need out there in society.
And now all of a sudden I would want society to be much more policing of everybody's bodies, which probably not a good thing.
Yeah.
That's what I was thinking too.
Like you imagine that people getting picked at random are probably going to try to run or like, you know, skirt around the system somehow.
I mean, kind of the way that, you know, wealthy people who live in.
I got bone spurs.
I can't give you my lung.
Right.
Yeah.
No, there's, you know, there's wealthy people who are very, very pro life and then like their kid gets pregnant and then it's like, oh, but not us.
Yeah.
And I'll go say, I really have an abortion.
Like, yeah, there's going to be all kinds of negative externalities to this kind of world.
The same way there are lots of negative externalities to a world where fetuses are considered people.
The health analogy or the health example in that comment reminded me of another thing from Sam Harris's book where like health is a vaguely defined word like healthy.
Like it's not clear exactly what that means.
Like it's clear what it doesn't mean.
And like, you know, not always being in pain, not always vomiting.
His use of the word always.
I mean, we just think of something that was constantly vomiting.
It's kind of funny.
And like, even though it's transient, like, you know, right now, if you, if you can run a mile at 80, you're like amazingly healthy.
But there could be a time where like, you know, if you can't run, you know, a five minute mile at the age 200, you're like seriously unhealthy.
Right.
But that doesn't mean that like healthy is completely void of all meaning.
Right.
Even if the definition is transient over time.
So it doesn't really tie into anything.
It's just not the mental model of always avoiding this sort of sort of ever present in my head.
I just wanted to bring it up for that reason.
One more thing about this.
Here's another thing I just thought of.
So what if the person who's randomly chosen to be the donor doesn't like they have to pay for their own medical care forever?
Yeah.
And what if they're doing something that they find really important right at the moment, like my mother is dying of cancer and I want to be with her.
Or I'm working on this thing that will solve poverty and I.
Nope.
You've been chosen to go give your kidney and you got to pay for it.
Yeah.
Yeah.
The paying for it and like the fact that this is like a life ruining expense for almost half of America is kind of like a big deal.
Right.
See, I almost feel like there like there would be certain changes we could make that would make a pro life position more palatable to me.
I still don't like it for the bodily autonomy reasons.
But like, hey, what if like society compensated you for having a kid?
I mean, it does a little bit.
Get back breaks.
Not positively though on the aggregate.
No, no, it still costs you more than you get back.
Yeah.
But yeah, if this if this was if this is a money making scheme, then people could be pumping them out as fast as possible and cashing their $200 a month per kid or something.
Right.
But since things aren't quite so simple and there's there's more to the equation than that.
Then yeah, selecting people at random saying, look, this is now your problem.
Deal with it.
I think that puts a really fine point on it.
Jess saying that like, look, it's one thing to say, all right, you're elected at random.
We're going to give you a procedure.
You're out for a week.
Presumably in this thought experiment, like society would understand, you're not going to get fired.
You're not going to, you know, lose your house because you missed a couple of payments or something.
But you're also not going to be out $25,000.
Right.
Whereas if you have a kid, it's like, oh, yeah, you're going to, you can have all those things.
No paternity leave.
So you need to, you know, wipe your wipe yourself off and get back into the work on Monday morning.
There was a TV show I was watching completely aside from the point, but she works at like a supermarket.
And they she's like, oh, I'm going to leave, you know, like my shirt at home so the baby can learn my smell.
And it's like the saddest thing, but like, it's completely normal because she doesn't have any time off.
Right.
Right.
So there's a lot more to this in the real world examples of forcing people to have children than there is in this nicely hypothetical world of like selecting people at random for procedures.
But it's a fun thought experiment.
Yeah.
Yeah.
I'm not trying to devalue like it's usefulness and fun to talk about, but it was, I don't think there's too many disanalogies here.
Yeah.
We should probably wrap it up because it's 3.30.
Yep.
Cool.
We have one more important thing to do before we wrap this up though.
Yeah, we do.
I think it's been a while since you've thanked the patron in the ash.
Very well.
I will do it then.
Even though I always had picked it because they've got the coolest first name ever.
And you got a good one.
Do you guys want to take this?
It's okay.
I'll grab the next one.
No, you can have it.
So Alistair Park, everyone loves your name.
You are awesome.
And you are extra awesome for helping us with this podcast.
Everyone has great names.
It's not going to be wrong.
Well, Alistair has been one of my favorite names since when I was 14 and read The Goblet
of Fire.
That's Moody's first name.
Oh, right.
Yes.
Okay.
Anyway, cool.
Thanks Alistair.
That's awesome.
Yeah, thank you.
Give a cool name.
Yes.
Thank you.
It's almost as cool as any ash.
No, it is a great name.
And thank you so much for this.
You helped keep this thing going and you make all our days brighter.
That's right.
At least all our podcast recording days.
Yes.
And everyone else too.
Thanks for listening.
And you know where to find us for email, subreddit, all that stuff.
Just search the Bayesian conspiracy.
And feel free to share this with friends, iTunes, all that stuff.
I'm really bad at it.
Like we should just do a candidature that we all read.
But leaving a rating on iTunes can also help.
Yeah.
That sort of thing.
Yeah.
All right, everybody.
That's all we got for you this episode, I think.
Yes, it is.
Cool.
So we'll see you all in two weeks.
Great.
Bye, everybody.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
Bye-bye.
