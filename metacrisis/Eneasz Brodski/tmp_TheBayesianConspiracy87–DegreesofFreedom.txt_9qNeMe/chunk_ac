What is the thing that I'm thinking of?
Taboo trade offs.
Yeah, like unthinkable thoughts where people might.
Oh boy, there was an example I had.
I was thinking of somebody who can't accept that there's no such thing as heaven.
Like I refuse to accept even though like there's no evidence.
But I just because it makes me feel better and thinking about a world in which people just die forever makes me feel bad.
And that's going to prevent that person from being able to consider things like cryopreservation or having you know their brain uploaded.
So that yeah, I guess there are cases where people's emotions could also like supersede their ability to choose an optimal.
I don't know somebody else talk.
No, I mean, I think we all agree with you that not dying is the most optimal thing.
I'm just trying to think of what would make people what would motivate them to choose something not optimal.
That's one example I can think of just like you get like a flinch reaction when you're querying your emotions about something.
And then what was what was the thing you were saying, Stephen?
It sounded more like you were just saying that like basically this person's kind of weighing their values and in this case this person more strongly valued kindness in the world than whatever the optimal state was going to provide for people.
Yeah, or they just expected that having some autonomy could keep them like and I'm not sure who this person was or what was going on there.
But I could imagine like, you know, voting against, you know, who I thought like might be, you know, really well qualified or something.
But like, no, let's let's go ahead and keep, you know, a way where we can all keep weighing in at some point or something.
Right.
Just, and I'm not necessarily advocating that democracy is the best way to do stuff.
But I could see the argument just that not handing off all the responsibility and all the power to something like lets you, I don't know.
Maybe the government example, although I do like how this post jumped back and forth between like individuals and government and they even mentioned Plato a couple of times because that was, you know, when we brought up early on that like there's a good analogy between how humans run and how societies run.
The, like, you know, personally, it's just nice, you know, again, this weekend, I play a lot of video games and watch TV, like it's, it's up to if there was still somebody in my life calling the shots and saying you can't do that, I might be like pissed even if I knew that they were right.
Kind of like doing your homework or going to school.
It's like, I know I probably should, even though when you're a high schooler, it's hard to see the value in it or something.
But the, I don't know, at some point, I think lose like the, when you, when you gain the autonomy to like make your own decisions and decide how you're going to spend your time, giving that up, like takes away something that you really, really value, which is the decision or the ability to make decisions, make decisions that someone else and you would probably would agree is not like the best way to spend your time.
But it's like, you know, I feel like doing that right now.
I'm not sure how this ties into, I guess I can see it, but it, sorry, I'm hedging on this because like optimizing things, optimizing your decisions is great, right?
But I don't know, I guess I don't feel constrained to do the best thing that I want to do all the time anyway.
You know, like, if I want to take, well, because that's my preference to shift all the time, right?
And so maybe that's why you like autonomy, because you know what your preferences aren't someone else doesn't.
Like if you want to take, if you want to take the long way home from work once, because you just, you want to 10 more minutes to relax or, you know, there's a prettier parks drive by over here.
Well, you're spending more time on the road, you're putting more CO2 out there, you're not home faster, so you can get home, you can get started on the things you need to do at home right away.
Like if someone else is making the decisions for you, you, you're, you're much less free to do your thing.
That was kind of, I think what Sarah was saying about a kind of losing degrees of freedom by choose, by like being, you know, forced to choose an optimal outcome.
No, go ahead.
Sometimes it's not even other people choosing for you.
It's just an optimization process that you think this is the most optimal thing.
So you feel constrained to do the most optimal thing.
Yeah.
I'm thinking about a discussion that some of my friends were having recently about feeling like I need to save the world.
And, you know, have a high paying job so I can donate to effective altruist groups and then someone else saying, but like, is that better than living a hedonistic life where you're just making yourself happy?
Yes.
And then like, how do you define better?
There was this whole discussion that I'm still very confused about now.
That 4,000 year old conversation about what is the good life.
Yes.
You guys didn't settle that over lunch?
Oh man.
Not yet.
Actually, we touched on the next quote already or the next bullet point we had here, which was that this is true at an individual psychological level too.
Of course, we want to be free to waste time and resist pressure to account for literally everything we do.
And I'm glad that I articulated my thing before I read basically what she said much more succinctly because I was making kind of the same point.
Yeah, that made me well.
Allegibility partisans say that the weekly enforced rules are the only way to incorporate valuable information.
Precisely that information which enforcers do not feel they can make explicit, either because it's controversial or because it's too complex to verbalize.
If you make everything explicit, you'll dump everything in the world down to what the stupidest and most truculent members of the public will accept.
Say goodbye to any creative or challenging innovations.
Yeah, that kind of was the military general example or the band goods shop example.
There was a good back and forth about that in the Talking Heads debate with Massimo Buclucci and Elias Udkowski when they were talking about, I think, uploading.
And that yes, it would be like murder by textbook definitions that we have now, but like you would continue on in a way that you wouldn't be murdered.
Like yes, you'd be killed.
You might be offline for a minute or something or whatever, right?
And then Massimo was like, do you really think like that you could get like the courses on off on this and Elias are kind of splitters?
He's like, do you really want to constrain like the best choices about what can be explained to the average judge?
Yeah, I've had, I don't know.
I've had that argument with people too where it's the, I guess, Star Trek transporter, but that's not really you.
It destroys you.
And then the new, yeah, that's like information theory, differential distance.
I still don't understand that.
Yeah.
I mean, we'd have to have someone, I guess, who believes that way on the podcast because we'd all just fall into the chorus of jerking each other off again.
The jerking off there being that the transporters totally fine because you live on in the ship or on the planet.
Yeah, that's my intuition as well.
I don't see myself, I guess, yeah, you're right.
We need somebody else to articulate the other position because I don't see myself being destroyed as a bad thing, provided that I'm reconstituted shortly thereafter, right?
The argument is that that's not quote unquote you that's being reconstituted.
I wonder how they know that.
I guess they'd ask how I would know that I'm the one that's reconstituted or something.
But like, if it has my memories and personality and my vague physical shape, then that's kind of all I care about.
Yeah.
Shrug, that's a whole another conversation.
All right, yeah.
So being predictable is in Venkat's writing, usually a bad thing because it means you can be exploded by adversaries.
Free people are inscrutable.
In other contexts such as parenting, which we already talked about a bit, being predictable is a good thing because you want your kids to have an easier time learning how to work the house rules.
And then I'll just read the last one.
The basic argument for optimization over arbitrariness is that it creates growth and value while arbitrariness creates stagnation.
The argument for arbitrariness is I'm going to defend my right to be wrong because I don't trust the world to understand me when I have a counterintuitive or hard to express or controversial reason for my choice.
I think that makes sense as long as like you have one, right?
And like in theory, you should be able to explain it to somebody.
You know, again, it might take a while. There might be a huge inferential gap to cross there.
Like if we're arguing, uploading to muggles, then like we have to, you know, go through a lot to explain why that's probably a good thing.
And in real life, you usually don't have the time or like that person's not going to sit there and willingly listen to the whole explanation.
There's things that I think you just can't explain to people.
But I think that's basically just another argument of you should be free to make the most optimal choice.
It's just that you can't always explain the most optimal choice.
I think that's what this is saying.
But I think sometimes you can just be indifferent among a bunch of choices and you shouldn't have to go with the one that's most optimal.
So those are two different statements there though, right?
Yeah.
Yes, like on the first one, that's kind of the advocate for like why you don't want someone else to make your decisions for you.
Right.
Because they might not see why, no, look, this really is better for me.
Look, mom and dad, I know you had this track for me to go to college and do this and that, but I've decided that for my own best life,
I need to take a year off and then go to trade school or something.
And they're like, no, we had this Ivy League track for a year or something.
And it's like at the end of the day, maybe that's too specific of an example.
But it's easy to imagine circumstances where like you as the person who knows more facts about what's going on in your head than they do probably are in a better position to make that call.
Like as a child, you're probably not.
Like an 11 year old who says I'd rather have, you know, ice cream and pizza for dinner and not go to school.
They're probably not the best ones to make decisions for themselves.
Sometimes I do things that are self-destructive and I know in the moment that I'm doing them that they are self-destructive.
Every time I get drunk.
Should I not do that though?
Well, that's, you know, you've weighed your choices ahead of time and.
And I know it's the wrong one.
Well, wrong.
I don't know.
You're trading your short term pleasure now for the.
Then, then yeah, that brings into, you know, question the system one system to kind of ability to think short term, think long term.
And we have that reptile brain that is going to generally overpower the system to a lot of the time and like been there longer.
And like what kind of ability do you have to your future self?
Like you work out a few times a week.
I try to and like that's because I know that down the road future me will appreciate it.
And, you know, it's not just that currently also appreciates it, but not in the minute that I'm working out.
Like I'd rather be laying down and watching TV for the most part, right?
Working out can be fun, but most of the time it's not.
If it's super easy and relaxed, you're probably not working out hard enough.
Yeah.
But we're like somebody gives up smoking, for example, they're going to have an annoying few days where they're like, oh man, I could really use a cigarette.
But you know what?
A year from now, I'll really be happy that I made this decision.
So I'm going to make it for future me, not for present me who's dying for a cigarette.
There's that line.
So we're coming down on the on the side of people should generally make the most optimal decision?
Well, I think that it's, you know, in the post is long and it covers a lot of content, but I guess it's not clear to me.
Like because you're weighing in like your expressed goals of like, I want to make X amount of money.
I want to buy this thing, whatever your goal is and then how to get there.
But all of your like your implicit assumptions are like, excuse me, your implicit goals.
Like I actually want to be happy or, you know, like you don't want to get a, you don't want to like schedule your day.
So you have enough time to get a good night's sleep tonight for its own sake.
You want to do that because you'll feel better the next day.
And it's like, that's your real goal.
And so constraining it by like the decision tree that led you to like, nope, I'm going to go to bed at 10 o'clock.
And that, that is subject to revision when there's something else that you can do, you know, like drink coffee or something.
And better coffee 2.0 that, you know, actually makes up for lack of sleep.
So I think maybe, maybe there's something hard about like the question of like, what's your coherent extrapolated volition really, really, really aiming at here, right?
All the things that you, that you actually want that maybe you haven't articulated to yourself yet.
Yeah, we don't know our own preferences a lot of the time.
We have different parts that have different preferences that fight with each other.
There's people that will kind of prefer to satisfy other people's preferences over their own, like a parent with their child or you with a loved one.
It's a, it's a much more complicated topic than like, which is better in difference or optimization.
Maybe I want the freedom to choose which, which choice, which, which mode I'm going to be in when I'm making a decision, right?
So like, some days I want to do the, the indifferent because sometimes I, some days I just don't care, you know, and not to say that every possible outcome is equally distributed.
Like, what do you want for dinner tonight?
You know, when I say I don't care, that doesn't mean like I'm okay with skipping dinner or eating, you know, rocks.
So like, when I, there's, it's not that every possible outcome is the same value to me.
It's that like every possible outcome in the space of things that I know you're like, that we're vaguely talking about are the same.
Like, do you want, you know, Mexican Chinese or, or burgers or something, right?
Like the freedom of speech thing that she mentioned.
Yeah.
That within these bounds, you have the right to say whatever you want.
Or, you know, within certain bounds, you, you feel free to eat whatever.
I think the within certain bounds part is, is what I was getting at there.
Maybe optimization is more about like finding better bounds.
Yeah, I like that actually.
All right, I have a question for you too.
Okay.
So can somebody have freedom if they have inaccurate information?
Ooh, that's a really good question.
Huh.
Because that was something I was thinking about in regard to this.
How do you even make an optimum, like, I think humans never have perfect information about anything.
Yeah.
And that kind of relates to the topic of letting authorities make decisions for you,
whether that's parents over their children, governments over citizens of religion,
over the adherence to that religion.
Right.
There's a complicated topic.
Can you make an optimal decision without all the information is the question?
Well, no, no, you obviously can't make an optimal decision if your information is wrong,
but do you have freedom?
Right.
I know that's raising the question wrong because that one was easy to answer.
I guess you could say you could make a most optimal decision.
Yeah.
That's based on your current information and that's still probably worth aiming for.
That's probably what I would say, right?
And in fact, that's what anti-vax parents are doing, right?
So they're making what, I mean, they're not vaccinating their kids because they hate them
and they want them to get sick and die.
They're doing it because they really think it's the best choice for them.
So like they had the freedom to make a bad decision based off of bad information.
Sorry.
Can you repeat the question?
Because the way you phrased it was hard and I'm rephrasing easier questions by head on
accident.
Yeah.
Basically, I was just saying to what extent can we say people have freedom if they don't
