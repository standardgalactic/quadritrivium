The judges should be as critical, especially if it's a, you know, contest as they, as they constructively can be.
But then you, if you, if you're at home and you want the people who worked so hard all day on this to feel good about it, you want the people there being like, oh my God, that it looks so good or whatever.
Right.
Yeah.
I just wish they didn't always cast the person who's actually like, like Simon Cowell is cast in the position of the bad guy.
Like he's kind of the villain, like a lovable villain.
But like, or, um, Gordon Ramsay, like same deal.
Except he doesn't have an opposing person saying the food is great, does he?
Does, does Paul Hollywood, you said?
Gordon Ramsay.
Oh, have a reputation about what? Sorry.
Does he have a counterpart that says, oh, this is actually what you did pretty good?
No.
This food is great.
His stuff is basically by himself.
Yeah.
Like.
That's why I have a lot of respect for him.
Maybe they should put him and Guy Fero together.
Oh my God.
Guy Fero just like deep-frying love everything.
I've never seen either of these shows, but that is the impression I get.
I don't watch a lot of, uh, I'm just drop, draw a blank on that chef's name.
Gordon Ramsay.
I don't watch a lot of his stuff, but I've watched, uh, all of like Cutthroat Kitchen,
which is hosted by Alton Brown, who didn't, he didn't judge the food.
He, there was like a blind judge that would come in and judge the food.
Um, but they'd always say something complimentary about it, even if it sucked.
And then they would rip it apart and be like, here's why it sucked.
That's, yeah.
When, when I'm in my writing group, it's the compliment sandwich.
Yeah.
And then you're like, and here's where you took a giant turn.
Here's a healthy helping of this sucked.
And, uh, but your punctuation was spot on.
Yeah.
You need something good at the end as well.
Yeah.
Um, I'd like, so I like this line that if your tongue speaks truly your rational beliefs,
which are themselves, evidence can act as evidence for someone else.
But it's also like really hard because like I sometimes repeat things that I've heard
that I didn't investigate myself or maybe didn't investigate it.
But you tend to like, I don't know.
So I trust people in the rationalist community.
Cause they're like, if I feel like if people like see something and they,
they haven't necessarily verified it, they'll be like,
I don't know what my epistemic status is here, but like I saw this thing.
Like they won't just say it as though it was true.
Yeah.
Like I feel like a bunch of people that I know in the rationalist community or like
somebody whose opinion I would absolutely trust because they would like tell me as
much as they knew about the thing.
Yeah.
And with the global warming fires thing, I just, I hadn't heard of that before.
So when I did hear it, I updated way too hard on it.
Well, David's also like, I think it's a fair reason to update on what he said, right?
Yeah.
And, and he did say it rather, he did make, I think I, I'm behind,
but I listened to the episode where he walked back on that.
Cause he's like, I think I make, I made too strong a case for it.
I think he did.
And so, but how strong his case was made, you're like, oh, he's done his,
he's done his due diligence and he's otherwise reliable.
Like I think it was perfectly reasonable, but that's,
that's why this process isn't without a misstep.
It's, it just gets you more reliably in the right direction.
I think if they're talking about the idea of what was it of ideas being contagious.
And I think that it's not necessarily though,
the thought that it's like a one to one, like I have this belief,
I tell it to Steven, now Steven has this belief.
It's like, I, I tell you a thing, Steven like updates 80% that things probably true
because Jay stills third research, huh?
Or like, and then the next person down.
That sounds about right.
Yeah.
You know, you tell Rachel and Rachel is like 60% and et cetera.
So like you're, you're propagating the beliefs, but like smaller amounts of them.
I think it's also really helpful if you have like a back and forth network with these people
so you can update as they update.
Yeah.
Like that, that was what I was thinking too.
Cause like you were saying, David said this, he was too,
then he came back and said, oh, here's an update.
And then you updated based on his update,
which is how it should be, that's how science works.
Well, I think you went and tried to go verify this and then found that you couldn't,
and you're like, oh, I was wrong.
Right.
I looked at it and I was like, okay, it is an influence,
but I greatly overstated how much of an influence it was
and how I understated just that, the global warming part.
Right.
And it's one of those things that makes a community valuable.
You know, like if I go to the discord and post something that's not true,
someone will call me out on it.
And I'm sure there's a relevant XKCD where it's like the fastest way to get information
is just to go out and say the wrong thing and someone on a forum will correct you.
So you can save yourself the time of doing the primary research.
That's really funny.
I wonder if anyone's tried that.
I'm pretty sure I've seen someone do it at least one.
I don't remember where it was now.
Someone I met who's active in the community, Alex Chen was,
for a while, like the number one person asking questions on Cora,
or I think asking and answering, which like, it was this ridiculous amount,
like at the peak of their productivity, I think they were like asking 50 questions a day.
Wow.
Asking or answering, but like, that's like in, you know, in search of positive answers.
I wonder if anyone's tried to just like do the opposite thing where they just like,
I have this belief that X and see if like a bunch of people come and screaming at them.
This doesn't come out to Wednesday, right?
Yes.
I'll try and think of something to put on discord and I'll just,
we'll test this before it comes out.
Okay.
And then now the best part is that I get to say, I knew that, you know,
I won't actually sound it stupid even though I said this because I said it in advance,
but they won't hear it until the future.
Right.
Yeah.
All right.
My perfect excuse to make something up.
I'll give it some thought.
Are you worried that after this they'll never be able to trust a thing that you say on discord?
No.
No, it's just a one-time thing.
You're coming on seeing it right now.
They're welcome to distrust me as much as they want.
I hope no one trusts anything I say anyways.
I try to be honest and reliable, but like no one should take anything I say as facts.
I trust your like media recommendations.
Not good.
Oh, maybe that's it.
I'll recommend something terrible.
That sounds nice and harmless.
I don't know if you can because there are people who really love terrible things.
I'll think of something.
Okay.
If I'd be like, oh my God, Batman vs Superman knocked the Avengers out of the water.
Right.
Of course they'll never believe that coming from me.
All right.
I'll think of something.
All right.
The rational beliefs being contagious.
Yeah, it says they're contagious among honest folk who believe each other to be honest.
And that's why I claim that your beliefs are not contagious,
that you believe for private reasons which are not transmissible is so suspicious.
If your beliefs aren't tangled with reality,
they should be contagious among honest folk.
And that is why I personally don't trust religious people
because they have access to special revelation
and the rest of us just have to believe them.
No, that sounds like bullshit to me.
I mean, I'll trust their recommendation on how to improve a recipe.
It depends on what they're saying and who the person is
because religious people range from this is one special domain where magic applies
and then everything else just like works logically,
like doctors who are religious,
but still I would trust their opinion about neurotransmitters.
But yeah, then there's some people who just colors everything.
But he does say that if your beliefs aren't tangled with reality,
they should be contagious among honest folks, which, okay,
that sounds right to me, but then like...
How do they know that you're...
I don't expect people in a different culture than me
to necessarily be contagious by my ideas.
Contaged?
Yeah, infected, sorry.
There's a word for contagious and it's not contagious.
What on earth would culture have to do with that sort of transmission?
I mean, there are...
I trust other rationalists, but like...
But there can be beliefs that...
But like somebody in my cosplay group, not necessarily,
unless I knew them well enough to know that they basically would...
Then I would introduce them to the rationalist community.
I guess I was thinking it depends on the particular belief slash claim.
Like if I don't care who says,
don't mix ammonia and bleach when cleaning your bathtub,
like they're right, right?
Then I think things like having a minimum wage is harmful.
That is something that I would not expect to, for example,
cross over into the socialist or even democratic
tribes at all, even though, you know,
someone who says it may be a rationalist and may believe it to be true,
but I don't think they should consider that to be contagious to others because...
This guy's a rationalist.
Doesn't mean anything outside of our community,
except for like maybe some estrategist thinks it means something bad.
Yeah, but if a more conservative rationalist and more liberal or more...
I don't even want to say conservative and liberal.
If a more red rationalist and a more blue rationalist met,
I don't think they would expect some things to transfer over.
I disagree.
Disagree?
I mean, like you and Wes and David aren't...
I don't know if it's a red-blue divide, but there's different colors there,
but I think you guys, you know, when you're not jokingly disagreeing,
I think you aim to find some sort of ground in the middle, right?
