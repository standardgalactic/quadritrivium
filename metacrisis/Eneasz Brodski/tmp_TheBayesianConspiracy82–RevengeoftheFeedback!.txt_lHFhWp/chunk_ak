with like something this complicated
for that Chrome extension versus one that just like,
has like a list of keywords, like, I don't know.
Right.
They're probably.
A bunch of profanity and just cuts those out too.
Yeah.
I bet that one just gets like 80% of the same ones
that this one gets.
I would assume.
But that's really cool.
And this one's actually done the hard way,
which is really cool.
I'd be curious to see, and this is a link
that I haven't read yet.
So if you have any discussion,
a discussion about toxic, about toxicity in general
or about like the content that's there or something,
if that would also get flagged, like probably.
I would imagine not.
I mean, I imagine using the word.
I imagine you keep using the word content,
fag, you're going to get flagged no matter what, right?
Yeah.
Well, I mean, that's where a traditional flacker
would totally get it.
Yeah.
This thing is supposed to like judge tone, though.
All right.
I'm going to click this.
I'm going to see if I can play around with it
and see what we get out of it later.
So that's it for listener feedback.
We did have a comment here or something that you put in here
from Julia Gale of Facebook.
Do you want to do that really quick too?
No.
All right.
We'll save that one because that one's not time sensitive
and as far as I know, she doesn't listen to the podcast.
Yeah.
Or at least she hasn't listened to my request
to have her on the podcast.
So.
All righty.
Shall we move on to the less wrong posts?
Yeah.
Let's.
It feels really weird doing the less wrong posts
without Jess here.
We can skip them and talk about other stuff
or we can knock them out really quick.
It's up to you.
Yeah.
Let's, we should do them.
All right.
We'll, we'll trudge on and we'll just, we'll,
we'll acknowledge up front that these won't be
as much fun without her.
Yeah.
So we had three posts this week or this episode rather
because they were kind of short
and I felt like they kind of tied into each other.
Let's see.
So the first one was knowing about biases
can hurt people.
And my one sentence read on this is like,
basically, if all you have is the knowledge
that biases exist and how to identify them,
it doesn't, it, it can be a double-edged sword
where you, and he, I think he uses the word
sophisticated arguer here.
This is like somebody who knows.
Let's not do the sophisticated arguer yet.
All right.
That's fine.
Okay.
But this is kind of like akin to like knowing
logical fallacies, but not practicing not using them.
Yeah.
So you can point out slippery slopes
and false dichotomies with your opponents,
but like you're not paying attention to your own words.
Right.
That, that, that can happen with biases too.
Yeah.
You always apply them to other people and be like,
oh, this is where you're doing wrong
and you don't look at your own arguments
the same way.
Yeah.
Which just makes you get more and more entrenched
in the viewpoint you already hold.
Especially if like it's never,
if you'd never really accept the fact
that like you're doing that
and then you find yourself winning all these arguments
and you're like, I must be right.
It can be definitely a vicious feedback cycle.
Yeah.
It starts off with a fun little story of once upon a time
I tried to tell my mother about the problem
of expert calibration saying, quote,
so when an expert says they're 99% confident,
it only happens about 70% of the time, unquote.
Then there was a pause as suddenly I realized
I was speaking to my mother and I hastily added,
of course, you've got to make sure to apply
that skepticism even handily,
including to yourself rather than just using it
to argue against anything you disagree with.
And as my mother said,
are you kidding?
I use this all the time.
It's great.
So it's a lesson in knowing that these are tools
that if used properly will work both ways.
You can't just use them to rub other people's things apart,
but to dive into actual content of the post.
And he had a really interesting thing that he said too.
Do you think you are helping these people
who are sophisticated in this way?
Do you think you're making them more effective rationalists
if you just gave them these lists of biases?
I was like, wow, that's, I hate ever being in a position
of saying that more knowledge makes people worse off, right?
So I don't want to say that,
but it sounds almost like, you know.
In this case, it's, it's, it's not, yeah.
And it does run against that, that grain of like,
you know, why should knowledge hurt?
But this, this is knowledge that's.
If you just gave them that,
you're not making them a more effective rationalist.
You're making them more effective at fooling themselves,
which is the opposite of what we want.
Right.
Because for some reason, I'm not a car person,
but all my analogies involve cars.
If I taught you how the go pedal works and not the brake,
are you a better driver than you were before?
Right.
Or probably not, right?
I mean, I guess a little, you can,
you can do one thing with the car.
Are you a safer driver?
Absolutely not.
You're a safer driver knowing nothing about how the car works
than you are just knowing how to, how to hit the gas pedal.
Yeah.
So this, that's actually not the worst analogy in the world.
And they even tied it to cars.
What is it with you and cars, man?
I don't know.
Are you sure you're not a car nerd?
Pretty sure.
Do you have like a broken down car
you're working on every weekend?
I've had lots of broken cars.
I think it's more just like, they're really simple
and they do lots of little things.
And it's, I can usually find a way
to pitch and hold an analogy into them.
But yeah.
So he, he gives off, I don't know,
well, we'll burn through them really quick.
Tabor and Lodge.
Let's not go through all of them.
All right, cool.
There are whatever, six, whatever.
I thought there were.
Unless you want to burn through them.
Go ahead then.
We'll just jump through.
Cut out me being a dick.
No, you're totally fine.
There's, we'll run through really quick.
There's Tabor and Lodge's motivated skepticism
in the evolution evaluation rather of political beliefs.
The confirmation of six predictions.
There's the prior attitude effect
where subjects who feel strongly about an issue,
even when encouraged to be objective,
will evaluate supportive arguments
more favorably than contrary arguments.
Number two, disconfirmation bias.
Subjects will spend more time in cognitive resources
denigrating contrary arguments than supporting ones.
Number three, confirmation bias.
Subjects free to choose their information sources
will seek out supportive rather than contrary sources.
Four, attitude polarization.
Exposing subjects to an apparently balanced
set of pro and con arguments will exaggerate
their initial position or their initial polarization.
Number five, attitude strength effect.
Subjects voicing stronger attitudes
will be more prone to the above biases.
And number six, the sophistication effect.
Politically knowledgeable subjects,
