Welcome to the Bayesian Conspiracy. I'm Inyash Brotsky. I'm Stephen Zuber and today we're
joined by nobody. We're all alone in the Brotsky International Studios. Jess is taking a pilgrimage
to Rationalist Mecca. She's in the Bay Area with a friend who used to live out there.
Seeing all the cool sights, meeting all the cool people, and leaving us here to keep
things running while she's out. I asked her to take a bunch of pictures of Reach for
me because I really wanted to know what they do there, how they do it. I think it'd be
cool to have something like that in Denver. I didn't know what Reach was. What is Reach?
What does it stand for? Rationalist and Effective Altruism Community Hub?
That's what it was. It's like a community center for all the rational people out there.
Yeah. It looks cool. One note, nothing against them, but it looks bizarrely cluttered. You
guys should fix that. It freaked me out. It didn't freak me out, but I'm like, why is
there like a code on the floor? Come on, people. It looks cool. Is this just like a space
that someone rents that anyone who wants to come in could come in and hang out?
I have no idea. In fact, if there's anyone listening who knows about Reach and would
like to talk to us about it, I would love to hear about that and maybe do an episode
on how you can start a little community center thing.
We can ask Jess to ping people while she's out there.
We should do that.
We should do that.
Okay.
All right.
But since Jess isn't here, we didn't want to do anything huge without her, so we said,
oh, let's just finish up that listener feedback we got because we did still have a bunch of
stuff. And it was like good. And I am a little bit worried though that we're doing two listener
feedbacks in a row. Like, you don't think...
Still content.
It is still content, but...
Let us know in the comments if you hate us doing comments for two episodes in a row.
Yeah, yeah, seriously, because I wanted to like, you know, where people are like, oh,
God, another feedback episode. It's like back in the 80s and 90s every now and then they
had a filler episode where they would just show clips of...
Oh, God, clip episodes. You did a two in a row in your week by week. That would suck.
I know.
But this isn't a clip show. We're not showing our greatest highlights. We're visiting
and we're continuing conversations.
Yes, we are.
The other benefit of doing it now is that a lot of these were, you know, some of the
comments from these were from older episodes before Jess was on full time. So I don't know
if we actually have any that old, but whatever.
Yeah.
Yeah, we're going to dive right in.
Yeah, let's do that. And also we should try to keep on it better next time. Always have
a little bit of feedback at the end of an episode so that we don't get up in this backlog
again.
Yeah, part of our thing is we start recording a little late, which now at least it's daylight
savings and all that. So maybe it'll be, you know, less depressing to start recording
before dark.
Right.
And the, we're mindful of how long it takes to edit, but this one's actually a good quick
one. We had a comment from one of our patrons, Tim Sharp. I'm pretty sure the full names
are on Patreon.
Yeah.
Anyway, so Tim wanted to say thanks for the bonus content. I guess that's a reminder that
we do put out some stuff. We try to put some out every episode. Anyway, so Tim says thanks
for the bonus content.
By the way, are you planning on updating the website? As much as I love, parentheses loved
Katrina, she hasn't hosted in ages. And on a related subject, I'd love for you to bring
her back as an occasional guest. P.S. Welcome Jess. So we do have news on that. Jess is
on the website now.
Oh, is she on the website now?
Oh, I thought you said you were doing it. Jess, we'll be on the website by the time
this airs.
Yes, exactly.
And yes, she's our new full-time host and she's awesome. I'd love to have Katrina on
at some point. I know that she's been busy. She's got, or she's had a career. She's had
a kid.
So yeah, she has a brand new infant right now, which is taking up like all of her energy.
We can have the kid on the podcast. I mean,
we can do it. It'd be cool if we got his first words ever on the podcast.
Bayes.
Easy to say. That's right.
Actually, I think the S sound is probably is pretty hard for kids.
Yeah, probably.
But if she says, Bay, we know what she really means.
That's right. Yeah.
So that's the first one that'll be updated.
I've got a picture from Jess and the little blurb and that'll be done.
Deal. Cool.
All right. David wrote into the podcast email and said,
since Enyosh seems to be in a very similar place to me a few years ago,
vis-a-vis news, fake news and social media.
That is to say, we don't believe anything we read, et cetera.
Since I managed to get out of this hole, I thought I'd share my winning strategy.
Quite simply, I have a one strike you're out policy when it comes to unfollowing
slash unfriending people.
If anyone shares anything which seems like they shouldn't have shared,
I'm unfollow them.
This includes fake news, news which is factually correct, but so partisan that
annoys me and well, anything that makes me wonder, why the hell am I seeing this?
I actually know somebody else who does this, or more or less,
I think Matt Freeman and I were talking about our social media strategies.
And I don't think he has necessarily one strike policy,
but he's working on curtailing his input.
Or maybe that was me who said something like that and I'm projecting.
So I don't want to put words in Matt's mouth unless he wants to back it up.
I do something similar.
Like for me, it's not one strike.
Like I'll give someone a few swings.
But yeah, I have got at least three fourths of my list is unfollowed.
And sure, it does make things better, but I don't think it necessarily solves
all of the problem about about what news you can believe.
Yeah, that's true.
And it's tough.
Like in the other hands, too.
I mean, I think maybe one strike might be too severe given the source.
Like if one time Neil deGrasse Tyson shares a quote, you know,
he complains about how Thor's hammer is too heavy or something.
I'm like, you know, that doesn't necessarily mean I'm not going to see
what he posts anymore.
This is why I never followed him in the first place.
Oh, he's, uh, I might have mentioned this before, but he's
finding that like some people find it annoying that he rips apart movies
for how bad their science is.
Yeah, but I mean, that's his thing.
That is his thing.
And when he had Andy Weir on his podcast, he, um, he told Andy
that I was really impressed with like how little criticism I had to draw
with the science in your book.
And he's like, you know what, when I revised it and I, or maybe when I was
writing it, I wrote it with you ripping it apart in mind and I'm glad it passed.
Cool.
Um, so I mean, he made sure to double check all his stuff, which I think
it's pretty good, quick side note.
Uh, when I left Facebook, I still have an account, but I haven't posted
in a couple of years.
I think many people had done what you did to me, which is on follow me
cause I've rarely, rarely shared anything worth seeing.
And the whole time Rachel was in New York, we would, instead of like sending
each other pictures of cute animals and stuff, it post them to each other's
walls, which shows up as activity that other people have to see.
And they're like, I'm sick of seeing three fucking dogs a day from Stephen.
So bye.
Um, so I don't think I'd miss.
Ever get sick of seeing three fucking dogs a day.
That's a good point.
Yeah.
A monster.
Yeah.
That's fair.
Yeah.
You don't want to be their friend anyway.
Forget those people.
I don't know if you want to do the second half of this or not.
Yeah, sure.
Uh, he says it is amazing.
My social media experience has become so much better since I started
adopting this policy.
Uh, give some examples, but the key to this was adopting a mindset of the
follow button isn't an expression of love or appreciation for this person.
It's a statement that I'm willing to give this person instant access to my
life to say whatever they want.
This is a privilege that I'm very judicious about giving out and it is no
shame to have it taken away.
Uh, after I adopt this mindset, I unfollowed all the high school friends
and distant relatives who were filling my Facebook feed with crap and the level
of stress in my life instantly dropped by half.
Yeah.
The, the, the internet seems like a way to get annoyed.
Yeah.
And it could be in a different number of varieties, right?
It could be your one friend to keep sharing MAGA memes or something.
But I mean, my mom's not even that old.
She's not grandma age, but she's basically, you know, grandma on Facebook meme
style that, you know, she'll share like whatever inspirational quote she
came across or like completed this survey, check, you know, what, what,
whatever bullshit flower or something or you or whatever.
So it's like, ah, it's boring, you know, I love my mom, but I'll, you know, like
you said, it's not like, it's not like I don't like you.
It was just, you know, I'm not going to let you bug me with this crap all the
time.
So they wrap up by saying that since then my list of people I follow has
dropped to a 10th of what it was, but my average details per minute of Facebook
time has increased enormously, which I think is doing Facebook right.
Yeah.
They also posted something, but since Jess isn't here, we can't address it yet,
but there was a, he wants to see our reaction to it.
Cause it was the best, um, repudiation of universal basic income that they've
ever come across.
Ooh.
So that sounds like fun.
So I've got it still saved.
We'll hit it next time.
We'll hit it at some point.
We'll do a UBI episode at some point for sure.
Yeah, totally.
All right.
Cause I'm not an economist, but I should totally do that.
I mean, the biggest problem that I know of, uh, with it right now is the
fact that it's just not feasible considering how much it would cost.
We don't have the way to pay for it.
Is there, uh, is it a ripping apart that is addressed as something other than
I didn't read it.
It was a link.
Oh, yeah.
So we haven't checked it out yet, but, um, I mean, yeah, that's my thing
cause I'm not an economist, but I'm, I am a socialist libtard.
So if someone says, Hey, give everyone free money, then I'm all for it.
Yeah, but you can still do math, right?
Yeah, but like it's, I don't know.
It's one of those things that there's arguments about, you know, this, this
does seem like the kind of thing that would actually boon the economy.
Um, you know, I'm again, not an economist, but my understanding is that if
you're working at McDonald's, making about $1,000 a month right now, and then
Andrew Yang wants to come on and give everyone $1,000 a month, well, then
McDonald's gonna have to up their, up their, their wages to keep you on board.
Cause you could make as exactly as much money sitting in your ass at home.
Right.
But we just come, the extra wages come from somewhere.
Yeah.
Probably from McDonald's.
So they'll cut their profits down from 7 billion to 6 billion next year or
something, right?
Uh, more likely they're going to increase the prices.
The profits might go down, but people could afford it too.
So, you know, if you, if you're, I mean, can people afford it?
If they're only making a thousand a month, but if they're, if
they're suddenly making twice what they're making, if they're making, if
they're making a thousand before UBI, then, then suddenly they're making
$2,000 a month, then yeah, they can afford another $0.99 or whatever per
bread piece of McDonald's.
Yeah.
That said, I had a griddle on the way over and it was amazing.
So I don't eat that much fast food, but I was craving it.
Just quick warning to all our listeners, don't eat any McDonald's.
Don't listen to any ash.
We have, we have fairly decent health and safety food standards here in the United
States.
Oh, it's not the health and safety.
It's not the safety part that I'm worried about.
It's, it's the, the, just the health part.
Yes.
I think this is my general, I guess, like once a month or something.
That's, that's basically the rate at which I eat it, if that.
I mean, so like the whole thing with fast food phobia, this is my
Skeptoid adjacent rant that like, I mean, there have been people who have
done, um, McDonald's only diets and lost weight.
The idea is just to eat in proportions that don't make you sick.
Like that Chocumentary with, um, Morgan Spurlock supersized me.
Yeah.
He wasn't, first of all, he had a preexisting condition that made him get
sick and have to quit partway through it.
That was his liver issue that he disclosed up front.
Um, and so if you're eating a diet that's rich and whatever, um, I'm
guessing fats and salts or whatever, um, it would make it be rough on his
already damaged liver.
But the other thing is that the average person doesn't, so part of the gimmick
of the show is that if some, if they offer, do you want to supersize that,
which I don't think McDonald's even does anymore.
Um, I haven't heard of a supersize.
No, you're right.
I haven't heard them, well, I haven't been to McDonald's in a long time,
but I've been to some other restaurants and they don't ask that anymore.
I don't think it's a thing.
I think maybe the documentary did that, which cool, whatever, but the thing
was when, if they said, do you want to supersize that, he would have to say
yes, and you'd have to try and eat it all, which is not the experience
of your average eater, right?
You usually stop eating when or shortly after you feel full.
So you're not sitting there gorging yourself, throwing up and then eating more.
Well, I, I mean, the main problem I have problem, the main concern I have, I guess
with the fast foods and those sorts of foods is that they seem to be optimized
to not make you feel full until you've had too many calories.
Like you don't, you get a 700 calorie burger or something, and it doesn't
feel like you've had that much food.
And it just always seems to be that if you eat until you're full, you will
overeat at those places.
That's probably fair.
I mean, I, I typically don't like, I'll get one thing and drive off.
So I'm not hanging out and then, you know, going back for more or something.
Yeah.
But if you drive off and you're hungry next time, you'll get two of the thing,
right?
And two of the things more calories than they should have.
That's, that's a reasonable concern.
But from my own experience, I, I never do that.
I'm, I always know that like, if I don't feel full 10 minutes after eating it,
I will 30 minutes later.
The other main thing about fast food or restaurants in general is, um, the, uh,
portion sizes of beverages, I never get sodas.
Um, I drink soda very rarely and I'll never get a large soda McDonald's.
That's like what a leader.
Uh, so I'm not going to suck down a leader of Mountain Dew or whatever
they have, uh, to, you know, cause that, that's going to be more calories
than your Big Mac and your fries, right?
Sugar water is really cheap and they make a decent profit off it.
Yeah.
Oh yeah.
It's like 17 cents a cup or something on their end.
So anyway, that's, that's, oh, all right.
Last thing on UBI, that just to prime us for our conversation on it later, that
one thing that I like about, um, raising minimum wage and laws that do that is
that since UBI is more of a pie in the sky goal, raising minimum wage is a
step towards that.
You know, so like, yes, there's other economic issues with just that, that
aspects to make poor people less, uh, poor, but it, it, it's a, it's a step
in the right direction and I don't know if it's a step straight towards
the right direction, but it seems to be a positive step.
But again, not an economist.
So maybe we'll have one of those on when we do this.
We might as well.
Yeah.
We know some people that know some econ stuff.
We do.
All right.
Alrighty.
Uh, let's go on to Pearl Geek.
This is from the subreddit.
This is from the subreddit.
Yes.
Pearl Geek says there was some talk about how you should enjoy life at a young
age rather than optimizing for a good life when you're older, since you're not
that healthy, et cetera anymore.
I'm not sure I necessarily said don't optimize for when you're older because
you're always going to get older.
So it's not a bad idea to optimize for it, but I might have said something like
that we were kind of like, we were kind of saying like, man, it seems so weird to
just work constantly and be tired all the time when you're young, just so that
when you're old, you can be tired from being old, but not having to work.
Yeah.
And like the thing is like you, you know, traveling is harder because, you know,
it's just, it's harder to carry a big backpack or go hiking or whatever it is
you like can do while younger.
And isn't it just me or our emotions muted a bit, the older you get?
I think it depends on the person.
Okay.
It's definitely been true with me, but I'm hoping that turns around a bit at some
point.
Well, I mean, on the one hand, it was good when I was, you know, in the middle
part of the late part of being young, because early young, the emotions were
fucking out of control.
I did, that was not a fun ride, but now it's starting to almost get to the point
where sometimes I'm like, I think I kind of miss, you know, some of the more
intensity of like 10 years ago.
Yeah, I try to tune into that and make those happen when I can.
Oh my God.
So like, maybe we won't enjoy the traveling as much when we're old because
we're like, yeah, yeah, seeing this.
That could be another part too.
Maybe they feel it the same, but maybe it's just kind of like exercise, you
know, like, if you've been through enough shit, then like, oh, this is
sucks, but it's, you know, back when, you know, my great, when my grandma, you
know, was, was living through the Great Depression and literally sharing bath
water in a house without electricity and that sort of stuff.
It's like, oh yeah, you know, I, I don't know, insert, insert minor tragedy here.
It's like, yeah, I went through that shit when I was 10.
Like, you know,
It's not as bad as going uphill both ways to the worst school in the snow.
That's right.
And it's not as good as that one weekend with that one girl.
Speaking of salient emotions, can we sidebar really quick?
Sure.
I mean, try and stop me.
Um, I finished a Red Dead Redemption two.
Oh my God.
Then I'm sidebaring for a video game.
This is an important video game because it ties into emotions.
All right.
I've complained a little bit about the gameplay.
It's still kind of clunky, but they did a great job.
And I'm not, it's going to spoil anything.
I mean, not really.
Uh, they did a great job making you care about all the characters.
And so if you played the first one, you know that you don't start with the full
gang from the first game.
So you know that they're not all going to make it probably.
Okay.
Or at least they're not all around.
And, uh, man, at the end, there's, you know, you get this kind of classic, uh,
well, classic from the genre of like the redemption arc for the character.
You know, like I used to be this kind of rough and tough, fuck you attitude
outlawed, like they get perspective and actually have things to care about or
like want to do better.
So that, that really came through really well.
And speaking of salient emotions, man, any game that can make me cry at the death
of a virtual horse did something right.
Nice.
It was so touching when I was telling Rachel about it, because I, you know, I
went off, finished it for like three hours and then I was telling her about it.
I couldn't even tell her the part about the horse.
Like, cause I was right after it was still really fresh.
But like, since I suspected the end was coming, the end of the game, and since
this character is not in the first game, which takes place later, um, I assumed
he wasn't going to make it.
And that's not a spoiler because that's just history.
If you've seen the series and he might, you don't know, but anyway, in any case,
I'm feeding my horse, like you've got like all kinds of foods and stuff for if
you want to, like somewhere like good, you know, for whatever, but I'm giving it
like sugar cubes and stuff.
And I'm like, you know, I hope, you know, be happy.
And you really develop a relationship with the horses.
That does a good job at that.
And hit me right in the feels, man.
So where were we?
Oh, yes.
Old people have fun and emotions was the point that pure geek was making.
Oh yeah.
Um, or Pearl geek, excuse me.
It turns out, continuing the, the, um, post or the comment, it turns out that
young people have a tendency to underestimate how much they will both
enjoy life and cling to life when they are older.
I currently have trouble finding sources for that, but this at least touches on
the subject and there's a link.
Also being old can be a surprisingly long time span for me.
The limit of old was our German historic retirement age of 65, but many people
live to be 80 or even longer.
So 25 plus years of being old.
So I'm officially accusing Eneosh and Steven of unscientifically unsound
ageism with a smiley face.
Yes.
Um, so I did reply to that one.
Hey, I found that super, um, comforting, um, if it turns out that, that research
supports that old people are happier than I suspected, that's great news.
Cause I might be an old person someday.
I've heard that old people are fairly happy.
Most of them.
Yeah, that's good.
Um, you don't have all the stress of life crushing down on you anymore.
Yeah.
Certainly went to retired.
And if you're doing okay, um, yeah, there's, there's the other benefit too.
That just like, you can do what you want with your life.
Yeah.
And I had something for this.
Um, I do, I do have to say that I am in general terrified of the whole aging
process and being as I'm like kind of the oldest amongst my friends with one
exception, uh, well, either the oldest or everyone else is on par with me.
Right.
Again, with, with one exception, it, it feels, it feels weird and I'm feeling
my age a lot and I do not like it at all.
And, uh, maybe you'll hate it less when you're older.
It's hard to say.
Maybe it's like, from my limited perspective, I've, I've had like body
mechanic related issues for like 15 years and at a point you kind of just get used
to it and like, in that sense, it stops sucking.
Like it's just like, well, I mean, I, you know, it's like, I couldn't jump three
feet in the air before and like, you know, or so like, if you couldn't, if you
could never jump three feet, then like not being able to, it doesn't really matter.
So like, if you can't do something that you could have done 15 years ago after a while,
it's just like, yeah, that's just not something that my body does anymore.
I just, I hate the whole getting in firm and not being able to do stuff.
And like everyone gets, I hate to say this, but uglier, you know, and it
just, everything about it sucks.
There's, I guess there's some good parts of it, but God.
Well, I think the good parts are, are like, other than, I mean, I imagine
that when you stop being attracted, whenever you get old enough to like, you
know, not be super sexually attractive, you're also probably not super sexually
like active, you know, actually old people's sex happens, but it's, it's not.
I mean that in the sense that my, my fiance works, she's worked in
geriatric social work for like the last, what, five years.
She's always walking in and old people boning.
Luckily, no, but it does happen.
Like STDs can be rampant in nursing homes because these crazy old people are
banging.
Yeah.
Um, they're like, I don't care.
I'm going to die soon anyway.
Basically.
Um, or maybe they just need free condoms.
I don't know how it works, but any, in any case, uh, I think that I don't know.
I imagine like the lack of like sexual appeal will probably bug you less than you
think, but I'm also still holding out for the fact that we probably won't get old.
So I'm hoping fingers crossed.
Yeah.
I guess I'm less the, I was much more hopeful of that when I was younger and
the older I get, the more I'm like, Oh God, it's not going to happen in time.
Is it?
I think that's, uh, I want to break her as well.
I'll keep that keeps up at night.
Cause he keeps moving back when the singularity is going to happen.
Cause he keeps missing the deadline.
I think, I don't know.
I mean, we've got decades before this becomes a real thing, right?
I mean, my main concern is dying.
And yes, it can be old for a very long time.
I think I saw it today on Reddit that the oldest person alive right now that
they know of is 116 years old, but granted, the last 50 years of that must have,
well, last 35 years of that must have sucked.
Well, maybe the last 20.
After being 96, I don't know, in any case, some, some amount of it is just
increasing pretty spry 90 year olds.
It's true.
Yeah.
I mean, my great grandpa, he lived until his mid and late nineties.
And I mean, we'd go visit their place in the summers and he'd be like on his
roof, cleaning gutters and shit in his late eighties, but I wish he wouldn't
cause we were there and we could do it.
Okay.
So, um, yeah, I mean, people, people do stuff.
I think it's just like, you know, you, you know that your life's going to be
constrained in some ways, right?
So, but at the very least, apparently people are happier than we suspect.
So we'll, we'll take some solace on that.
Kind of like it would suck to become paralyzed, but like, I know, because I've
seen this touted over and over that people who become paralyzed return to their
base level of happiness after a few months.
So it's weird too.
Cause I was like, I, when I was young, I was kind of, I was never rebellious, but
I always like wanted to be rebellious, rebellious, I guess.
You're very well as you left the village.
Oh, not, not when you're really young.
Yeah.
Yeah.
I don't know.
I, I bought into the whole, you know, don't trust anyone over 30 thing.
And now I am over 30 and you're like, listen to me.
And it just, it's, I see, I don't know.
I never thought I would be this old.
I used to really hate old white men cause they ruined everything.
And I'm like, I'm basically an old white man now.
I guess I've ruined everything.
That sounds racist.
No.
Okay.
Well, yeah.
I mean, you can say that this group of people was historically responsible for a
lot of problems, but just cause you haven't fit those demographics, that's
just straight up profiling.
It is.
And I will, I will say that I was at that age, the race slash agist and, uh,
didn't think it was a problem.
So now you got to get over it.
No, I guess so.
Yeah.
I mean, you can do some transracialism and trans age or whatever, trans ageism
stuff, which I think is more ridiculous than trans age, trans, trans, uh, racism.
Yeah.
Like I think it could be trans racial.
I'm not sure how you'd be trans age old though.
There was somebody because, uh, yeah, the, the, uh, what's her name, uh,
blanking on it, the, the very, very bad wizard person step mom.
Okay.
She's one of the intellectual dark web people.
Yeah.
And she keeps bringing up this example of the person just, I think this person's
trolling cause they want to just, you know, make a fuss, but they want to like
change their age.
I think they're like in their fifties, they want to change it to like, I'm 35 now,
which me, I'm like, cool, no harm done.
You're going to retire when you're 80.
Like fuck you.
Sorry.
We only let people retire when they're 67, you know, um, but I think that one's
just, that one's harder though, because there was a day you were born and we can
measure how many days it's been since then.
You know?
Yeah.
Yeah.
That's fair.
But what if you feel a certain age?
I, you know, I, I, and some people do mature much later than others.
I've been an old man for 10 years.
See, right?
You, you are trans agist in the other direction.
Yeah.
But I'll, I'm not going to change that on paper because there's, there's perks to
being certain ages and you know, whatever, there's also perks to being older.
Yeah.
If I had a money to retire on, I could change my age to whatever age I could
collect my non-existent pension at.
So in any case, it's, it's, it's good to hear that old people are, are, you know,
I never thought that they were miserable, but there's, there's the concern that
like, oh man, I'm not going to be able to do all the stuff I like, but apparently
like the, you know, like the paralysis thing that turns out to be less of a
concern than I thought it was.
And that's super reassuring to me.
So all right.
We've got J.
Michael two, four, nine, seven on here on one of the subreddit comments.
I think this was on, yeah, it was one, a couple of episodes ago.
They had a long post with a bunch of sections.
So we pulled one out here on a freemium profits.
And he says, uh, again, if they say again, if you, if you weren't the customer,
you're the product, PGO is tracking your location habits and
Oh, Pokemon go.
Thank you.
Pokemon goes tracking your location habits and monetizing that data.
And they're in that.
And they, they are Niantic slash Google powered after all, um, with association.
No one, no really bro.
We're really not tracking you when you tell us not to, et cetera for the, for
reels this time, that whole thing of like, Oh, we're not tracking.
You don't worry about it.
And the micro transactions are just a nice, easy bonus.
Yeah, I know it's a, it's a freemium game.
I know exactly what I'm in for.
I haven't considered that.
Does Google really need more ways to track us though?
I already tell them everywhere I'm going because I need to know how to get there.
I think there's that.
And the other thing with Pokemon go that monetizes it without you paying for
anything is that Pokemon Poke stops are, um, not, not necessarily, not necessarily
even most of them, but a lot of them are in businesses.
Like every Starbucks actually a few months after launch is now Poke stop.
So it was every sprint store.
Yeah.
And they pay for that.
Yeah.
Exactly.
So, you know, that, that's the thing that happens.
It'll draw you to that location.
And Hey, while you walked all the way over here for a Poke stop, aren't you thirsty?
Why don't you swing in for a Starbucks?
Um, yeah, I mean, these things happen.
I, I can't remember what context this was brought up in, but I think this is just
an understood cause of an understood effect of the game.
Like there are other games, the only other mobile game that I play that has
anything like a monetizing aspect is, um, what's it called a clash of clans.
And that one, there's, there's no tracking because your location doesn't matter,
but it, it, it heavily intensifies as you just spend real money to get in-game
currency to speed up building and stuff.
Yeah.
Which if you play it right, you never have to do.
So I just, I've been playing.
But you'll always lose against people that do do that.
This one doesn't, doesn't actually do that.
Luckily it's not quite as bad as some of those cool new AAA games where you can
pay for an instant win card.
Like looking at you, Star Wars Battlefront two.
No, I mean, so other people can, can basically get their bases
leveled up faster than you, but you're competing against people at your same
level all the time and that also increases their level.
So it's not like they don't get an unfair advantage other than being able to
skip spending five years to build their base and they can do it in two.
Yeah.
Or right away if they're fucking millionaires.
Right.
So this was a comment that came in a, maybe a month or two ago on episode 56,
which is the one that we had, um, our guest Vivian on to try and explain to
me what like privilege was and offense and all that stuff.
And, uh, Bob wrote in saying that in a sense, I'm glad Vivian expressed her
views because I always thought that quote privilege on quote narrative is
cloaks and racism and per se perpetuates everything wrong with it.
Oh, excuse me.
Is cloaks and racism and perpetuates the very thing of reports to seek out to solve.
I feel more secure in my view than ever.
The term punching up betrays a mentality here.
I'm a white guy.
You're a black guy.
Well, of course I'm above you.
Yuck.
Um, this view is despicable and minimizes people into little more than
members of a tribe.
This wasn't rational.
It was nonsense.
Um, I agree with most of that.
I will say that the, the, the phrase punching up, I think it doesn't necessarily
mean I'm above you.
You're below me.
It's that society has me above you and, uh, therefore you below me.
And so it's, it's, it's not necessarily like I'm racist and I'm above you.
It's that like, because I'm in this class and that classism is real.
Like, I don't, I don't think, I hope I didn't, none of us came off denying
anything like that and it sucks.
And it's like, I mean, obviously that's a stupid thing for me to say.
So it's the, the problem isn't that like this isn't real or this is a bad attitude
to have this is that's, that's socioeconomics, right?
And they're, they're too often, uh, in today's day and age, hopefully this
will get better in the future, derived along racial lines, which is insane.
And so people can, uh, I think the slippery slope to fall into is, is to
say that like this is every person's fault or this is, this makes every person
a victim, right?
I was listening to NPR about a month ago or so and they were talking about
Taylor Swift and it was something along the lines of kind of not attacking her,
not like ripping into her in the whole John Stuart eviscerates way, but they
were like really going at her for, you know, being this white lady and not using
her privilege correctly to help out the minorities and benefiting from the system
and all that.
And I was like, wow, man, they are hating on Taylor Swift.
And then someone mentioned, yeah, but she's done good things for the causes
of women and it was like, oh yeah, yeah, no, no, she's, you know, as a woman,
very empowering for women and everything.
I was like, damn, that was some fast backtracking.
And it was, it was just interesting to see, you know, the, the quick switch as,
as to whether she was the oppressor or the oppressed class.
And just changed on which lens they were using.
And it was, it sure shows the fragility of that whole stupid game.
Yeah.
And also, you know, she's fucking Taylor Swift.
Maybe just judge her as a human, as opposed to a member of, you know, the
whites or a member of the women's or the riches or whatever.
Yeah, yeah, I, you know, I don't know what her early life was like.
Maybe consider that.
I know that right now her life is pretty good because she's super rich and pretty famous.
Not to say rich people are no problems, but they have problems that poor people
would love to have.
Yes, yeah, they have ways to deal with their problems.
Yeah, they can afford therapy and they can afford time off to take it.
I think it's interesting.
Like this might have been an example I brought up during that episode where like,
you know, if somebody I knew who got like beat up or something while somebody
called him racial slurs, I'm not going to pause to ask like, Oh, well, hold on.
What can I hold a brown bag to you?
See if you're passing white or not.
Like that's, that's disgusting.
That's madness, right?
But it's fun to see people change lenses depending on whether or not they're
playing identity politics or tribalism or tribalism or whatever.
Right.
I have a friend of a friend in the Quaintance, I guess, who often
cosplays like Jasmine and other people from Arabic areas.
And she is, I believe, oh crap, Syrian.
I want to say Syrian, maybe Lebanese.
No, I think she's Lebanese.
But yeah, they like ripened her for it because she's fairly light-skinned
into how dare you, this cultural appropriation.
Oh yeah, you mentioned those costumes on.
Oh, did I?
And then she's like, bitch, I was born in the Middle East.
Yeah.
Yeah.
My and and isn't that weird?
Like, I mean, I didn't learn about the term brown bagging
until what, a few years or a few months ago.
What is brown bagging?
That's where you take a brown bag and see and hold it up to them
and see if they are, if they're darker or lighter than the brown bag.
Yeah.
Which I guess, depending on the bag tells whether or not they're passing
white or not.
And that's like a lot of what like the same card you see pulled out,
which is bizarre because this is the same, the same brown bag
that the that that racists will use to determine whether or not
you deserve inclusion in our special group, which it's, it's weird.
I mean, like kind of like distant third person perspective on this is like
history is always just reactions from the extreme of how it was a couple of
decades ago, right?
So like we're wearing a pendulum swing.
And I'm pretty sure we're at like near the top of the swing where like it's not
going to get much, it might get a little weirder, but it's not going to get.
This isn't the stasis that it can stay.
Ultra prudish right now.
It's really weird.
And in some ways not, you know, it's weird, but yeah, I think, I think
it's going to, it'll swing back and do what it, you know, and obviously
it's not a clean metaphor because there's lots of pendulums.
I'm sure if we're going to totally torture it, but I don't know if you
want to mention this or not, but you had somebody do Padman, Parvati Patil
for the Methods of Rationality podcast.
Do you want to talk about this?
Oh, have I mentioned it before?
No, I was going to mention it, but I didn't know if you wanted it.
Oh yeah, go for it.
I think it was, you know, because the show was done in segments as it got
caught up with the book and then you do like side stories or other short fiction.
Somebody wrote in and it was like complaining that the person who did
Padman, Parvati Patil, when they did their attribution, didn't have a
brown person sounding name and did it with an American accent.
And they were like, that's super offensive or something.
And well, what it was, so to set up, when I did the podcast, originally
I was doing basically all the voices, certainly all these small parts
because there's over a hundred small parts and I don't know that many people
at a level where I can just ask them to do the parts, right?
And eventually I got enough fans of people just start setting in line.
So now every part I think is done by different people with a few exceptions.
But to keep all these characters separate for me, I started doing them
like in different funny accents and voices and stuff.
I had like the Debonair English guy.
I had, um, I had one like old Western cowboy drawl guy.
Was that Ron?
No, no, no, that was Ron was the surfer, dude.
That's right.
And for Seamus, I had a terrible Irish accent, which was kind of like a mashup
of the Lucky Charms guy and groundmaster Willie from Pesimpsons, which is literally
what I based the accent on because those were the only two people I knew who turns
out those are two different countries anyway.
But at the time I was like Scottish Irish, same accent, right?
I was just kind of the mash up the two of them.
Anyways, that there was a lot of like funny accents and just goofing around
playing with the thing.
So I could, uh, so I could keep them separate in my head and eventually
like I started getting a few other parts, specifically the female parts.
I just could not do female voices.
You couldn't do 20 of them at that too.
Exactly.
That was the thing is during the speowark, there's what eight main women or something.
So good luck doing eight convincingly separate voices.
Yeah.
So I got, uh, I tapped like a whole bunch of friends.
And since I was doing like silly voices and shit, then, uh, they were playing
along with that too.
And this, uh, this one girl was like, Oh yeah, Pavarti Patel.
I would love to do with them.
And she like went on YouTube and tried to do more or less the best
accent she could, but it's still sort of a humor piece, right?
So she was just having fun with it.
And, uh, and it wasn't until, I don't know, the series was almost over.
When I got this, uh, feedback that someone said, you know, I was listening
to Harry Potter methods of rationality.
I was having such a great time.
I was loving all of this, identifying with Harry.
And then I hear this accent come on and my heart just drops because it's
the same accent that people in high school would always torment me with.
And, and yeah, I was like, Oh, fuck.
And I just felt awful.
So, okay.
That's, that's, I went and yeah, I got that changed as quickly as I could after that.
I didn't have the whole story.
I thought that it was just some, you know, stereotypically white social justice
where you're complaining that you're doing this on behalf of other people.
Oh no.
If this was somebody and they were, they were saying like, man, this was the
shit that people blocked me with like that.
Or even if it was like somebody, you know, what I'm getting at is it came
from a place of like genuine, like personal, uh, notice rather than like,
if it was just like someone saying, Oh, that's culturally insensitive.
I'd been like, whatever, bite me.
See, that's what I thought you're capitulating to.
No, no.
Okay.
So that's different.
All right.
So that, that makes it better.
I forget how we got on that.
Uh, because we were talking about cultural appropriation.
That's right.
Yeah.
Oh, and the brown bagging, whatever.
So I brought that up because I told somebody that story and I gave them my
wrong version of it, that it was just somebody who wrote in, but that it didn't
actually matter.
What they said was like, well, yeah, why didn't he bring an Indian person on to
do it?
And I was like, cause he didn't know any Indian women.
And what is he going to do?
Like if somebody writes in and gives them a voice, I don't know if he knew this
person, IRL or not.
But if they did, like what are you going to do?
Like ask them for their 23 and me.
Right.
Like, or, you know, what, what are they falsified?
Those documents or just, or if they lie to you, like, you know, how much, how much
of this background check is really due on you for doing a free podcast?
I mean, it's also made doing, made making the podcast harder.
Cause now I always either try to get someone of the nationality described or,
or ethnicity described, or, uh, just change the accent.
Like, uh, Kokomo in the crystal society is described as having a Kenyan accent.
And it's like, I like reading it cause I can hear it in my head.
It sounds kind of like, I know Trevor Noah ish.
I don't think he's from Kenya because I, I, I don't actually can't tell the
difference between all the accents, but I, I, I kind of hear it, you know, like
the, the kind of know the Eastern African accent.
And, uh, I don't know anyone like that.
So I was like, you know what, just, just do straight American accent because I,
I don't want, I don't want to ask someone to do a Kenyan accident and get it wrong
and, and have that sort of thing happen again.
So yeah, I've, I've had to look a lot harder for people.
And if I can't find someone, then I just like, you know, don't, don't do an
accent and it's kind of a bummer, but
which sucks.
Cause it's also kind of like erasure too, right?
Yeah.
And so it makes, it makes characters that were ethnic white on, on, I mean, or
sounding white anyway.
Yeah.
I mean, on the other side of that, sounding mid American.
Sorry.
When it was lots of flavors of white, when you're doing it on a budget of
zero dollars, like you can't really afford to do casting calls.
So it just kind of turns into what it is.
I had something on accents and stuff.
Damn it.
It slipped my mind.
And miss accents because accents were always fun.
And I don't even think for the most part, they're like making fun of people that
much, but comedians almost always do accents of some kind, you know, and it
just makes a set better.
And you can do it with, in a way that's not like me and spirited, you know, if
you're talking about some guy from Wally Brock in Scotland, you can do it with
an accent.
Exactly.
But it doesn't, you know, that, that I wasn't saying something disparaging or
making a racist joke or whatever.
Right.
Yeah.
Yeah.
It's, but we'll see where things shake out.
Um, but having heard that it came from an actual person's place of like, man,
this kind of actually hit me, then that, that, that actually changes my whole
perspective on it.
So I didn't want anyone to have their methods of rationality
experience ruined by something like that.
Totally.
That's awesome.
Let's see.
Oh yeah.
Because we were talking about the whole episode with Vivian.
Yeah.
Which yeah, it was learning experience.
I mean, it was conversation that I had enjoyed.
I mean, I thought it was a good episode.
We had a lot of feedback, people like what the hell was this?
And there were a few people like, you know what?
I, I don't want to be involved with this.
Right.
Someone thought that like, if they're replacing our third host and I'm leaving
and I'm taking my Patreon money with me, which I think it was, wasn't it one of
the people that did some of our music?
Yes.
Yeah.
Yeah.
That's right.
Yeah.
Like we'd rather not have our music associated with us.
I explained, you know, this is, we cover a lot of topics on this and we like to
hear from the people that actually hold these positions.
It's not that we endorse them, but you know, everyone gets to say what they
want to say and not be censored.
Yeah.
If they're going to be cool about it, most people can.
Yeah.
And it's, it's important to get all the perspectives and they're like, oh, okay.
Yeah, that's cool.
No, I'm totally with you.
I was like, cool, rock on.
I'm glad we're seeing the same thing.
But yeah, I wouldn't want that to be a constant feature.
You know, it was an interesting episode to have.
Yeah, I couldn't do that every two weeks.
Moving on.
So yeah, this was on the one that we talked about.
This is another one from David via email.
We did that one on everything fitting into four categories.
If you squint hard enough and he brought in that Helen Fisher, the, I know
we're from her episode on Neil deGrasse Tyson's podcast and she does
like a lot, like love science, like what's actually going on there, the
different, you know, phases of love and neurochemically, what's going on there.
Oh, love science.
I thought you were saying she loves science.
Oh, who doesn't?
Yeah.
Yes.
No, the science of love.
Okay.
So he has, he says, he thinks he has an answer to why everyone seems to fit
into four broad categories because the most, most of personality, human
personality is governed by four neurotransmitters.
Stope means serotonin, testosterone and estrogen.
This research mostly comes from Dr.
Helen Fisher and he links to a talk that she gave, which we can put in the
comments, um, the reason foundations, annual donor weekend.
To make a long story very short, her work is the best I found to explain
the four bucket thing, even though she assists that conceptualizing them as
buckets is a mistake.
The Hogwarts houses and inch turtles, the colonial groups from Albion Seed,
reproductive strategies, even the four conspiracies from Brennan's story,
competitive, cooperative, Bardic and Bayesian.
Those are the short stories and the sequences.
It also pays a lot of rent and anticipated experience.
She's used survey data to predict brain scan results from the prevalence
for the prevalence of these neurotransmitters and vice versa.
Unlike, say, the Myers-Briggs where those predict basically what's your
Myers-Briggs, whatever personality trait.
She's also making money for it with match.com, which I think she helped
found, or at least they were, she was heavily consulted.
I remember that from Tyson's podcast a few years ago, if the market
test holds any weight with you.
So anyway, hope you found this interesting.
I do find that interesting.
Yeah.
I don't, I mean, I would want to read more about it because again, the, I,
I am kind of suspicious of anything falling into four easy categories like that.
One of the parables from that, uh, thought, from that thought experiment
slash exploration was that it's not always neat for buckets.
Yeah.
There was a PS here that that is, that is interesting.
And I'm interested in hearing more about that.
And I'll totally listen to her, her talk at least.
Yeah, me too.
PS, I would guess that rationalists are high on testosterone.
Do you happen to know the sex ratios of children produced by two rationalists?
I'd like to register an advanced prediction that it pursues
prevalent, pretty strongly male 60 to 75% he's guessing.
So that's sex ratios of the children produced by two rationalists.
Not how many people are rationalists.
Do high testosterone people have boys more often?
I didn't think so, but maybe they do.
I assumed that it was always just a 50-50 shot.
I'm not a doctor.
Maybe it is close to 50-50.
You know, yeah, certainly nothing like 60 to 75% well, unless, unless
testosterone plays a big part and if rationalists tend to have higher testosterone,
I mean, those are two assumptions that we both have no data on you and me personally.
I mean, maybe someone does.
Yeah.
And we also don't know the, the ratios there.
60 to 75 though.
That's intense.
That'd be interesting.
No, but that, that is cool.
And I, I hope to read some more about it at some point when I have time.
Yeah.
I want to check that out.
I will put that in the notes and, and ping you again when I find the link and to post it.
So, um, anyway, thanks, David, for that one.
Yeah.
Oh, this was a really quick one just from a listener who recently started listening to
the show and then binged it all, which is great from Graham.
And, uh, they listened to, uh, you know, she's a reading of, uh, method metropolitan
man and methods of rationality.
When we did the signaling episode way back with, it would have been signaling
without Robin Hansen.
It was one of the ones before that where we just talked about signaling.
Okay.
When Katrina mentioned, uh, mimicry where harmless species might imitate
venomous ones that predators will avoid it.
Like, uh, like some flies and snakes do.
Enesh pointed out that it seemed like cheating and nobody mentioned that
Professor Quirrell had taught us one, about one thing.
Cheating is what losers call technique and be worthy of many
Quirrell points was successfully executed.
So yes, good catch.
Thanks for noticing that one, Graham.
All right.
Next one's on you.
Uh, Desmond on a comment on the cyber Christianity episode, this one actually
came from our website, the basing conspiracy.com rather than, uh, the Reddit
says, this episode had me scared for a good while.
Not at the content of the discussion, but at who I could have been.
I was raised Mormon and didn't break into atheism until six months
into a two year Mormon mission trip.
Even then it was a slow process, two steps forward, one step back.
That said, if my slightly younger self had heard about cyber Christianity, I
think there's a very good chance I would have bought into it as an excuse
to hold onto my beliefs.
I like to imagine that I would have eventually shrugged it off, but this
could have delayed my deconversion by months or even years.
Worse, I'm cringing because I know I would have shared this idea with all my
friends as something I believed in and something they should believe in too.
I wonder what it says that a person can be exposed to the same ideas, but the
order in which they were exposed to the ideas can send them down different
paths, which is, yeah, I'm curious to hear about whether young
Enios might have fallen into this trap too.
Um, no,
I was going to, I dammit, I was just finishing a drink of water.
I was going to run your prediction that the answer would be no, but can I guess
why?
Sure.
Because it would have been a drastic enough departure from the religion
that you were taught that it wouldn't have been an excusable substitute.
Like you, this wouldn't be something that you can kind of slide in and not go
to hell for.
You still would have gone to hell if you were still a Jehovah's Witness when
you were exposed to this, right?
Uh, well, I'm probably according to official dogma, but if I bought it, then
I would be like substituting this in for the belief anyway, right?
I always sort of saw this as, I think, what, um, what Desmond was concerned
about as like a kind of like, um, the, the, the reason to stay in the, in the,
the faith, yeah, stay in the society, the, the, the faith's society.
Like if I bought into it, I don't think I'd be worried about being sent to
hell for being bought into it.
I, you know, I'd be like, Oh, so everyone is secretly actually going to get, you
know, taken out of the matrix and I will be among them because then they don't
believe it right now, but they're still going to get, they're still going to get
taken out of the matrix.
So that's awesome.
I sort of always just saw the cyber Christianity thing once I learned about
it as just like kind of more of that slippery apologetics bullshit where it's
like, say this when you're talking to somebody's arguing with you, but then
go off and do whatever you want and, you know, pretend and just kind of pretend.
Okay.
If someone really bought into this as their actual religion, that, that would,
well, I mean, most of religion is, you know, just say this stuff and then go
off and be a community together.
I don't know.
Yeah, but, but the, the important part is that you're saying the same stuff
as the rest of your community.
Yeah.
And then when you're on the debate stage with Richard Dawkins or Christopher
Hitchens, you'll make other noises and then go back off to your congregation and
make those appropriate noises.
So like you'll go to the stage and be like, well, of course God's not like
real.
He's not standing on a cloud.
He's, he's in our hearts.
He's, he's a manifestation of all the good that's in the world.
Then you go right back to your pew on Sunday or to the, whatever the stand where
you talk to people and say, of course God's real.
He really cares about you, which is not what you'll say when being challenged.
I sort of thought this was just sort of another bait and switch position.
Gotcha.
Which it might be by some people, but maybe that's not the point.
I think that'd be a really weird bait and switch.
I don't think it would be very effective.
It seems to me more as the sort of thing you would tell yourself if you wanted
to stay in, despite all the evidence you saw.
I doubt someone would try to use it as a bait and switch sort of thing.
The much more common bait and switch would be something like, yeah, God is
just the feeling of love that we feel for all humanity.
Gotcha.
That's fair.
So why wouldn't, what wouldn't, why wouldn't you have about this as a teenager?
Oh, because, uh, my main gripe with God was that he was evil.
Uh, that he, you know, for some reason hated the gays and wanted them all to die
and had this abhorrent moral system.
And this wouldn't have changed any of that.
This doesn't make, I mean, just to be clear, that, that doesn't make God not real.
That just makes him an asshole.
Right.
But that is, that is where I started.
And that is what started me down the path.
And there was, there was, this would have not arrested that path.
That's fair.
Yeah.
Plus, I mean, that, that rebuke doesn't really land when you're also told
that God loves you and loves everything infinitely.
Right.
Yeah.
And it's like, he loves me a lot, but he's still like, keeps hurting me and keeps
torturing people and killing kids and, you know, wants gays to be tortured forever.
Who loves somebody enough to torture them for fucking ever.
I know.
That's some intense love, man.
I guess I just don't really understand the true meaning of love.
Yeah.
So yeah, that's interesting.
I think as a kid, I wouldn't have found this convincing either.
I was never as religious as Enya's, but to my vague sense of religion, I don't know.
I guess I saw the matrix when it was new and because I'm super young, that would
have been like when I was early teen, maybe 11 or 10, 12 ish.
And it came out 99.
If someone had tried to sell me on the idea that like, no, look, and like I, you
know, if, if say, Bostrom's paper had come out about, you know, simulation theory or
something, I don't know, it's hard to say what I can't really put together a mental
model of my younger self that well.
Um, I still don't know if I did the least bit compelling now.
And I haven't actually, I, the most I've looked into Bostrom's, um, simulation
argument is like the really short version.
Um, he's actually, I think the most recent guest in Sam Harris's podcast, which
I haven't heard yet.
So I will see if they go into simulation argument there.
They don't think he again gives the really short version.
Okay.
Well, at the end of the day, it's not convincing to me.
And I think my thing is, well, I mean, yeah, let me, let me explain.
Cause the, the argument that they're variable may be more simulations than
there are real worlds or because there's one real world at the top, right?
And then it's just turtles the rest of the way down.
If that's the case, I guess it's not that I don't necessarily buy into it.
It's that I don't think that changes anything.
I feel like I'm still in relation to other people and other minds and like,
whether or not, um, like if you're in the matrix, which is a really easy way to
distill this thought experiment and you're being a dick to somebody, you're
still being a dick to somebody.
Right.
The other person's a mind in a bat too.
It doesn't matter where their body is.
It just matters that you're being mean to them and you're impacting their
mental states in a way that makes them less happy.
But that's not a refutation of the simulation argument.
Even if it was true, I wouldn't change anything.
That's, that's what I meant to clarify.
Yeah.
So it's not that I, I don't, I don't have a solid refutation to, to his argument.
What I do think is that it doesn't change anything for how I'll live my life.
Okay.
So you just don't really care.
Yeah.
So like, and it's also not something that I could ever transform into like a
religion that like, oh, when we all get out or when all this changes or when
they, you know, patch the, the really shitty, uh, death bug that's in the
here or something, right?
I've got nothing like that.
And it, uh, my current conviction in that theory isn't going to change any of
those perspectives yet.
So, okay.
Yeah.
All right.
Let's grab the next.
I want to do more than a male because apparently I didn't compete into a
document, which is weird, but I have it up right now.
I did at the bottom actually.
Cause I grabbed the one above it too.
Oh, okay.
Um, oh wait.
No, I didn't.
I grabbed another more than a male on, that was on the atheism.
So you do that one because that wasn't a cyber Christianity.
Yeah.
Yes, it was.
Okay.
So on the same episode, um, we're doing a male on the subreddit says, I share
Anyosh's ability to easily be, to be easily sniped by these ideas.
There's a part of me that's grasping for explanations and this part seems to
find there's somebody watching or something that created your world for
purpose and they're watching you and judging your behavior to be really
compelling, probably because I'm a social primate, timeless physics helped solve
my issues with meaninglessness in a pointless quote unquote cosmos.
Yeah.
In the far future, the universe will be a flat smear of cold hydrogen.
But if you think of the universe as a timeless object, then past and future and
now cease to have objective meaning.
The moment when you lost some sleep to help talk a friend through a rough time.
That moment is permanently embedded in the universe.
It will always be there right where you left it.
It will always have happened.
Nothing can take it from you.
So what if the moment passes out of living memory?
You did a good thing.
You had a moment of connection.
You mattered in that, in that moment.
It's preserved in the causal history of the universal wave function, which is a
more indelible substrate than diamond, which holy shit.
That's great.
Yeah.
I think for me, that was basically just what I said, but more poetically put.
I'm kidding.
I'm giving myself too much credit.
No, but I thought that was beautiful of that life.
I think so too, that that was very moving.
When there's a beautiful moment, it is forever now part of reality.
I did say something much to the same effect, but minus the actual, like, I
guess the convincing part of like, this is actually part of the timeless physics
universe.
My thing was more just like, it still matters because it was nice, which is a
lot less, a lot more hoity-toity and a lot less solid than this.
Yeah, I'm like, I'm like the solidity of.
No, I totally agree.
And apparently other people did too.
Um, because I think these are the only ever, uh, gilded comments I've ever
seen on our subreddit.
So, or rather this, the only comment that I've seen gilded and it was gilded
twice.
So yeah, that's awesome.
I think it's, yeah, it's just the idea that correct me if I'm wrong, if my
reading is the same as yours, but I might have used this example or maybe I
didn't, but like, if you're in, if you're in Auschwitz, you're going to be
killed next week and you do a kindness for one of your, your, your fellow
prisoners, that doesn't go away when you're both killed next week.
It, well, to the point with timeless physics, it really doesn't go away.
It literally doesn't a forever moment of beauty that's in the universe.
Okay.
I'm glad that's solidity, solidity landed.
Um, like to me, when you first gave that, gave that analogy, I was like, I guess,
but they're both still dead.
So whatever, no one knows or remembers or anything, but the fact that I don't
know, there's something about it actually being there that makes a difference.
That's awesome.
Yeah.
And that is actually, I even visualized it.
As a bright color that's just almost trapped in sort of an, a clear amber
thing, just the act of being a color in there.
I know it's stupid visualization.
It's not, it's great.
Everyone has their own, but that's how I saw it.
No, that's beautiful.
I picture it more like time on a, this is embedded in me from as a teenager
watching Richard Dawkins' Christmas day lectures where he had that cool, like
that big several meter long meter stick and a little beam of light moving
across it.
I see it's kind of like little bright points where the beam was, right?
Yeah.
And no, to be clear, Matt, this was a much more beautiful and articulate
way of putting it and it landed harder.
And I think that's great.
Um, I really liked that one too.
So I'm glad it's on there.
Yeah.
I don't have anything else to, you know, this isn't, I don't have much of a
conversation for that one other than saying, I think it's fantastic.
Thank you for sharing that.
Yeah, man.
Relating similarly to that and another, uh, backed into their
more dynamical comment, but this was a child comment of another one on our
atheism episode.
We had user, uh, Calvin three, two, one say that I consider myself a
rationalist theist.
Is this necessarily a contradiction?
I would think a Bayesian would consider, excuse me, I'd consider a Bayesian
would only consider unlikely.
I think it needs to be careful to not prescribe too many
mandatory positions to the rationalist label because that is one definition of
fundamentalism.
Uh, I have found many contrary opinions have merit like the anti-vax
person, Jerry Hammond, for instance, I don't know who that is or what they
said that has merit, but whatever, maybe it's some gentle
admonishment of like being sure that science is safe or something.
I have no idea.
It could be something that nice.
Um, I kind of made hand gestures reading the first two sentences because it
feels like wishy-washy apologetics and then they go on to link to apologetics
later on in the comment chain, um, which I, so apologetics is, I like how
it sounds sorry in the name.
It's the, the branch of like theistic defense where I don't know why they
call it, I'm sure there's some great reason that's historical, but in any,
in any case, it sounds like sorry.
Um, but that's apologizing for the fact that our God can't actually provide
evidence and it's the same to me.
It's that what I was talking about earlier with that, that, that wishy-washy
bullshit where, and don't be wrong.
I'm not, I'm not criticizing Calvin or anything.
I think, you know, people do whatever they want.
You know, it sounds like you've got something that works for you and that's
great, but my experience watching apologetic debates was they would say one
thing and do another and they would engage in a lot of, of really dishonest
debate tactics, you know, straw manning, um, oh, here we go.
Apologetics from the Greek, meaning speaking in one's defense.
Yeah.
All right.
That's fair enough.
Um, so yeah, this is, this is in defense of, of theism, but there's this guy.
What was his name?
Oh, actually it's the one that, that you mentioned or that you, you put in a
link to a video by, uh, um, or excuse me, Calvin puts, puts in a link to a video.
Dr. William Lane Craig.
Oh my God.
Yeah.
Who I had seen debates from and this was the guy, I remember there was like,
he was on a, he did a debate with Sam Harris, where Harris points it out like
that a lot of the characteristics of, of religiosity, you take away like the
religion aspect, if it's one person, it's straight psychosis.
And in his opening statement where Harris made that remark, he, he went on, you
know, he elaborated that length that like, I'm not saying religious people are
psychotic, I'm not saying that there's, there's even a parallel, uh, other than
the fact that, you know, basically, I think he used the example of like, if,
if you're, if you're praying to, to God and you're talking to him every night
and you hear him talk back to you, you're religious.
If you're, if you're talking to Michael Jackson or, or Elvis or somebody,
you're, you're crazy.
And then, you know, Craig comes back and he's like, well, I certainly wouldn't
think my esteemed colleagues here at the university hosting us are psychotic.
Um, which is exactly not what Harris said.
So it's that weird, it's, it's super dishonest debate tactics.
Maybe he's got some things worth hearing, but I only saw him in the
context of a debate.
I, when I was big into atheism, I saw a bunch of things with him and he's,
these are typical, typical apologist.
I was trying to be generous, um, but yeah, it only cause I actually didn't know.
But yeah, I, I, I got the impression that he, he didn't have, I mean, he,
he definitely didn't argue with integrity.
Like I said, I mean, this wasn't even as disingenuous as like misquoting
somebody like from a book and then publishing an article about how, you know,
your, your wrong quote or something.
This was like, he was right there.
He just said it.
In fact, I think Harris's rebuttal was like, I didn't say that my, that
our colleagues here were psychotic.
I guess I'll let the YouTube video sort that out.
Like this was recorded 30 seconds ago.
So in any case, um, um, we're going to reply to, to that comment about, um,
would a Bayesian consider, you know, a Bayesian should only consider
unlikely, not impossible and that don't prescribe too many, uh, mandatory
positions to rationalize label.
Cause that's how you get, that's one definition of fundamentalism.
I think we've talked a bit about, maybe we'll talk about how that's not fundamentalism.
I think, uh, in, in one sentence that I can think of right away, it's the
differences that like these aren't unchallengeable tenants of the faith.
This isn't things you have to believe on insufficient evidence to get into the club.
Um, this, this is, these are things that are more or less settled, but they're
always open for discussion.
Like rationalists tends to be anti-death, but if you find a deathist
rationalist and they're arguing in good faith and they're not straw manning,
well, no, probably be a good conversationalist.
You know what I mean?
I hate to go down this track because we're just going back to the same old
atheist, uh, debates that we've are also bored of now, but it's just basic
special pleading.
No one ever says, I would only consider it highly unlikely that apples
will start falling up into the sky tomorrow.
It's, there's some things that you're just like, yeah, that's not going to
happen for all effect and purposes.
It is zero probability.
That, that was more than emails reply that I liked here.
He says, I suppose we're all rational theists and that we all assign some non-zero
probability to the possibility that the world or the universe or something was
created by an agent rather than purely consequence of physical laws.
We've just talked about simulation hypothesis, right?
But I wouldn't say I'm a theist because the apportion is because I apportion so
little probability to mask to that hypothesis.
I feel like that's the thing is like, maybe this time when I drop my phone,
it'll go up and is it logically impossible?
No.
Therefore, should I sign real probability to it?
I don't want to break my phone.
I, right?
So I'm not going to drop it.
Eliezer has this post in the sequences about the lottery where, uh, he, some
people talk about like how the lottery at least like gives people some hope for a
while, you know, which is one of the good things about it.
And he said, okay, sure.
But if you're being rational about things, you should appropriate, you should
portion out an amount of hope equal to your chances of winning, which is physically
impossible because a human cannot devote less than one neuron to hoping something.
Right.
And, uh, I feel the same way.
The chances of God are so close to zero that I cannot subdivide a single neuron
into giving it that amount of probability.
So, uh, no.
No, yeah, I think, I think I used the, the example that I gave my old co-workers
when somehow God came up like the first time we hung out and I thought about how
I was going to answer because I didn't know what their stance was.
And I had said, I put God in the same mental category that put unicorns in.
I haven't seen one.
I don't expect to see one.
I'd be extremely surprised to see one.
Um, God is probably actually less cause unicorn wouldn't, wouldn't blow my model
of the universe out of the water.
Right.
But it's also, this is kind of like a reverse apologetics point.
And then an apologist can make a counter-argument, but like, it's not clear
what would even convince me.
Um, I've, I've thought about this a bit and then stopped 10 years ago
cause I got bored of atheism, but like, Oh, well, what if somebody came down
and they could fly and, you know, like, like Harris uses the example.
It's like, what if, you know, Jesus landed on the White House lawn tomorrow.
And it's like, look, there he is.
There's his magic powers.
That's all it would take.
I don't know if Harris has considered that, like, what would be more likely
that that's the returned son of the creator of the universe who has DNA.
And, you know, whatever he's a son and not just like this, this thing, but it,
or, and that the universe was created, you know, whatever 10,000 years ago
and it's all a trick, you know, heredity, DNA is a, is a myth, but, or whatever,
all that stuff that we thought we understood is all false.
Or that this is aliens playing a trick on us or that we're in a simulation
and they're like, Hey, someone hacked God mode.
Um, so someone found really clever magician.
Right.
Well, I did hear this isn't original to me.
So I wish I could give credit to who said it, but I did.
He, I have someone point out that if God were to actually come down
and make me omniscient so that I knew everything that would be, you know,
then I would also know that he exists.
And so that'd be a, that's one way I could be convinced.
Yeah.
I mean, I wonder then, I mean, if, if you were to take a little DMT,
you might think you had that state of mind, right?
It's true, but it goes away after the DMT wears off.
Yeah, I suppose.
But I mean, you could literally, if, you know, people report the experience
of like going somewhere and talking to intelligent agents when they're on
DMT for like 15 minutes, right?
And if you, if, if he's like, Hey, you're here, here's omniscience.
And you're like, God.
And then you come back and it's like, guys, I saw it.
I had it all.
Like that, that's not a real experience or excuse me.
That's, that's a quote, real experience, but that's not a real epiphany.
No, well, that's also not real omniscience.
Yeah.
But yeah, I suppose, but I don't know.
I would, I would put real omniscience maybe in this.
Like I don't, I guess if it was real omniscience, I would know it wasn't a
trick omniscience.
So I guess that's the rub there.
Okay.
So solved.
So, uh, more than a male says, I wouldn't say I'm a theist because I
apportion so little probability mass to that hypothesis.
If you're claiming that the words rational and Bayesian and implying that as a
Bayesian rationalist, you were also a theist, then you need to have some
really extraordinary evidence in favor of theism.
If the rationalist label means anything at all, it means that you can't just
believe things that you find convenient or aesthetically appealing to believe
and continue to use the label.
I think that's fair.
And, you know, I, I'm not gatekeeping rationalism, you know, I'm, I'm,
there's probably somewhere out there a handful of like sincerely devout
cyber rationalists as the elder conspirator here.
I will gladly take on the burden of gatekeeping rationalism for us.
Fair enough.
You know, and I'm tempted to, too.
I'm, I'm torn between being politically expedient and not being a dick.
I mean, I appreciate your comment, Calvin.
I think it's, I think it's thoughtful.
I don't think like people should necessarily be excluded because being
around rationalists help people, helps people to become more rational, you know?
Yeah.
So I, yeah, we've had people before who are into things that I consider
woo, basically, like, you know, magic.
And, uh, I think we've had a, a theist before.
And, you know, sure, I'll still hang out with them.
I'm not going to shun anyone.
I don't think the label is, I don't think you can really be a rationalist,
the theist, but on the other hand, I'm not going to like kick you out of
the community just for that.
I'm like, yeah, if you aren't abusing anyone and you're trying to use your
rationality, stay and eventually you probably come around.
Yeah.
And I think, and if not, whatever, you do you.
Yeah.
And, and then not so many words.
I think it's not that it's like, because we don't allow that nonsense over here,
but mainly because it's a contradiction and like, you're just not getting it.
It's like saying, like, I'm a martial artist and I'm, I'm a black belt, but I,
uh, I can't move or refuse to move or something.
Right.
And it's like, then you're not going to be able to beat any of it up.
It's like, oh, that's not the point though.
I'm really a black belt.
And it's like, or yeah, like, you know, you came into an accident and you
couldn't move anymore or something.
It's like, sorry, you're not a black belt anymore.
Like, cause if, if part of the test of being a black belt is that you can
beat up a blue belt and you can't do that, well, then it just happens to be that you
can't.
So it's like, it's just kind of a contradiction.
Yeah.
Absolutely.
Sure.
But, and it's about, and it's about analogy and I made up on the fly.
I think it's, I don't know.
Like, I think the way that this works in, in some circumstances when you're talking
with people is like, what's something that you don't believe in.
And you know, usually it's like aliens or bigfoot or Loch Ness monster or
something, and maybe an apologist would be willing to say, well, I assigned it on
zero non-negligible probability to all of those.
I would ask someone who's Christian, uh, what's a Hindu God that you do believe in?
Right.
That's actually a good point.
And I, I don't know.
And I, maybe I, my impression from, and if they can't name one Hindu God that
they do actually believe in, I'll be like, that's the same level of belief that I
ascribe to your God.
I like it.
And it, it could be that a, a truly introspective apologist would say, I believe
in all of them or something, but that almost sounds like a cop out too.
Maybe.
At that point, you don't really have any religion.
Yeah.
If you believe in all of them, you're just a spiritual hippie.
And hey, you can be spiritual hippie-ish, but it's, it's one of those things.
People are spiritual hippies.
You know, they tend to be really nice.
So my best friends are spiritually hippies.
Oh my God.
I just said that didn't I?
Oh, I didn't say my best friends.
That's right.
You said, you said, you said people.
Yeah.
Um, yeah.
No, it's, I think it's just like, you wouldn't consider somebody a scientist if
they didn't believe in DNA, like not, not just, not just that they challenged,
you know, and, uh, Mendelian inheritance or, or evolution or something.
Although I think that that would be a good disqualifier.
I mean, you could be like, I don't know, geologist or some kind of high
energy physics or something and not necessarily know anything about DNA.
And do like, yeah, I don't believe in that.
Sounds weird to me.
Let's say you can't be a biologist if you don't believe in DNA.
Okay.
Yeah.
Yeah.
So that, that's like this, right?
Except this isn't like a dogma.
This is DNA isn't, isn't a prescribed belief that you're told you have to
accept to become a biologist.
It's just like, if you look at biology, that's the conclusion that you
can't help but find, right?
And if you find something else and you've, you've got really good evidence
for it, publish a paper, get your Nobel Prize.
Like if you, if you overthrow DNA, if, if, if it turns out that DNA isn't
real and we've just been tricked for the last 60 years, um, that'd be super
weird, right?
And somebody'd be really interested to hear that, but it wouldn't be enough to
say, well, I, I assign a non-zero probability to the fact that DNA
doesn't do anything or isn't real.
That's, that's, that's not a, that's not a belief that even pays rent, you
know, um, cause if you're going to behave in the rest of your life, like
DNA is real, doesn't analogies now becoming tortured?
Cause most of us don't care that DNA is real.
But if you were a biologist going through your career,
yeah, you would have to keep making the, it's a whole thing.
So anyway, I thought it was fun and I really liked more than emails, uh,
contribution there.
So let's wrap this up with some GPT two comments.
Yeah, sure.
I'm very ill equipped to handle all the good ones, but, um, I'll do my best.
So, okay.
Uh, so we have some, uh, skepticism on the GPT two.
Chebatron, Chebatron, uh, says that in responding to, oh, I think it was
responding more than a male saying GPT two knows that the semantic tokens
that uses are related to each other by rules, each token having its own rules.
And at this point, people were starting to discuss like, what does GPT two know?
You know, and, uh, Chebatron says, I highly doubt GPT two has any representation
of semantics in its model.
You're correct about relation rules, but what are those rules?
You construct English texts using grammar rules.
You're also using vocabulary as a mapping between concepts and specific words.
You have a personal style for GPT two.
Those rules are after this word, the most likely one to go to is this other word.
I'm sorry to disappoint you, but GPT two is just a buffed up Markov chain generator.
It has a decent look behind buffer and takes into account lots of values,
not just the last one, but in its essence, it's just that don't take this as
me being dismissive.
GPT two is very impressive for what it is, but it doesn't bring us
closer to AGI in any meaningful way.
It demonstrates that neural nets can scale.
It's good for all sorts of expert systems dealing with highly specific tasks,
but it's not a missing piece for each AGI.
That's, uh, I think that's a good comment.
I think, yeah, I guess it doesn't bring us closer to artificial
general intelligence in a meaningful way.
I think I agree with that.
Um, what it does bring us closer to is, you know, you can have a conversation
with a robot about a book, not yet, but we're getting close.
Right.
Um, maybe not actually conversation.
That would be intelligence.
You know what?
And I take that back.
Actually GPT two doesn't seem to get us closer to being able to have, I don't
understand it well enough to say whether or not if GPT two, or if GPT five, if we
could have a conversation about the Lord of the Rings with it, where it could
teach me something I didn't know, other than like a parrot, a passage I missed
or something.
Cause it, I don't think it quite, it doesn't work on a holistic understanding
of the, the, of the, if I was talking about the rings of the trilogy, right?
Right.
It works on like word distributions and how fun I see these things with this
things.
Yeah.
So it, I don't even think yeah.
GPT five in my, I'm sure dad, that's two is even like the second version of this.
I'm sure I'm just torturing the hell out of this.
I don't think that version 5.0 will be able to like challenge Steven Colbert
on like thoughtful and sighfulness on Lord of the Rings.
Now use him cause he's a big nerd with this.
Yeah.
So I mean, it could probably, I would say certainly challenge him on trivia about
like who, who's related to who and how.
I think there's a difference between trivia and like thoughtful analysis though.
I agree that there, I agree with the second part that there's a difference between
those two things, but does it even have a real running memory of like, you know,
our, our, what's the daughter's name?
The daughter elf that Erwin Erwin or Eowyn Eowyn Eowyn was the Rohan guy.
My bad.
No, that's Aomer.
Who cares too many names?
The elf daughter.
If, if, if, uh, if Liv Tyler is, is, uh, Oh my God, you know an actress's name.
Yeah.
I know, right?
That's crazy.
She is related to the guy from Aerosmith.
Yeah.
Um, is his daughter.
Yeah.
Actually, I think that it wasn't, they weren't even raised together.
It was like, he had, he had her with a groupie.
Um, really?
Don't correct.
Don't, don't, I thought it was like a model.
Well, I mean, she, she is related to him.
I think, but I don't think that they grew up together.
I don't think that he was like her father.
I think that he was, I think that, I think that he was her biological father, but
not like her in Yandu's words.
She was, he was their father, but not her daddy in the timeless words of Yandu
from Guardians of the galaxy too.
It was Arwen, the name of the, that's right.
In any case, if you find out if my trivia is right, but then, uh, if
Agent Smith's daughter was Arwen that, or Elrond, I don't know who that
guy's name is, then she was the daughter of a, of a model and singer, which
makes me think it wasn't just some random groupie.
Cause generally, Oh, huh.
Yeah.
She named her after their last name was after, uh, Todd Rudgeran, who was
she claiming that Todd Rudgeran was the biological father at age.
You tend to relive and live met Steven Tyler and figured out he was her father.
Okay.
Yeah.
And now we all know more about Liv Tyler than we ever thought we would
before we started this podcast.
Well, you already knew this apparently.
I just didn't know it.
I don't know if it counts.
Yeah, funny.
I don't know if this counts as knowledge because that wasn't really sure.
But, um, yeah.
So what I, but this is my long way of getting to, I don't know if GPT two
knows that Arwen is Elrond's daughter.
I mean, it's certainly knows it knows that those go together sometimes.
But like, I think it, it would be easy enough to be like, it, there's some
concept of a daughter is a relationship.
It doesn't have concepts.
It just has, it has word mappings.
Yeah, but what I'm getting at is, I don't know if this would be enough.
I don't think that this kind of neural net is the thing that would engage
you in a good conversation about this until what a daughter is in the real
world, but it knows that how the words daughter, father, and all those are
related in terms of words, I guess.
I was just curious if it would be a daughter is a thing that comes from a
father and a mother.
I guess maybe I wasn't sure if like GPT two ever had like probabilistic
estimates where it could be like, no, no, I like, if I, if I challenged it,
it's like, no, no, it was actually someone else's like, no, no, I'm pretty sure.
I don't know if GPT two has that kind of, of like insight into its own
probability distributions, or if that's even how it works.
No, you're right.
I mean, we're using, we shouldn't use the word no, because there's a lot of
implicit assumptions with the word no right now.
Right.
But we have maps of concepts in our brains that cover a lot of things.
But I think our two maps of concepts are just a lot thinner and I think only
work on words.
And I guess what I was getting at is that my impression was that they did,
that it didn't quite work in a way that like, if I challenged it, if it could
say, I'm pretty sure that this is the case.
I mean, I've been able to give me text examples or something, but it couldn't
say really, I read this and I gave it like a 99% confidence level that this was
the case.
Right, right, right.
I think it's just like, I saw the word Arwin, Elrond and daughter together a
lot.
Yeah.
Yeah.
I don't know much else.
I think I kind of lost myself other than, oh no, I was agreeing with, with
what, uh, Chebotron was saying that this isn't AGI stuff.
Um, and then I was briefly thinking for a while that this might be, Hey, I can
have a cool conversation with a robot about a book, but then I walked it back
on that and said, wait, no, I don't think that this is, this is that either.
This is something that it can give me very often accurate trivia about the book.
Right.
It certainly couldn't have a conversation with you about it.
Cool.
Uh, Mordinnum male responds or not responds, but Mordinnum male has a
counterpoint for me, Alpha star and GPT two were a one two punch that made me
much more concerned than I had been and moved my AI time tables up slightly.
Before now, it wasn't obvious that Starcraft two is a game that can be played
super humanly well without anything that looks like longterm planning or
counterfactual reasoning.
The way humans play relies on a combination of past experience, narrow
skills, and what if mental simulations of the opponent building a superhuman
Starcraft two agent out of nothing more than LSTM, which law short for long
short-term memory, uh, nothing more than long short-term memory units indicates
that you can completely do away with planning, even when the action space is
very large, even when the state space is very large, even when the possibilities
are combinator, combinatorially enormous.
Yes, humans can get good at Starcraft two with much less than 200 years of time
played, although those humans are usually studying the replace of older masters
to bootstrap, but I think it's worthwhile to focus on the inverse of this
opt for surfacing that a sophisticated problem domain, which looks like it
ought to require planning and model based counterfactual reasoning actually
requires no such thing.
What other problem domains seem like they ought to require planning and
counterfactual reasoning, but can probably be conquered with nothing more
advanced than a deep long short-term memory network.
That's a provocative thought-provoking question, right?
Cause like this looks fucking impossible.
Doesn't it?
Oh wait, we did it.
Yeah.
What else looks like that?
Lots of things, right?
Yeah.
Yeah.
It also reminds me, brings me back to various science fiction stories,
including most recently, I think Peter Watts has been doing this that kind of
assert that consciousness is on the net, a drain, and any sufficiently advanced
species will either evolve out of consciousness or remove it on purpose
in order to be more competitive.
This brings to mind like the most ridiculous, but to me, one of the like most
not ridiculous sounding, but also kind of one of the most like it seems startlingly
plausible hypotheses of like why people sleep or why everything sleeps basically.
Cause like in the evolutionary long-term view of organisms and individual bodies,
we're just vehicles for our genes to ride around and reproduce, right?
Well, we only need to be like awake long enough to do that.
And the rest of the time, we should just be doing nothing and staying safe.
To conserve energy.
To conserve energy and to stay safe while we then like go out, reproduce and then,
you know, return to that state.
So like sleeping is more than a natural state there.
And so in that sense, consciousness is like, other than the fact that I guess
sleeping is also beneficial or whatever.
But I thought that was kind of like hauntingly compelling.
Yeah.
And Dan, now he's saying basically the same thing.
It looks like long-term planning and consciousness isn't that important for
solving a lot of things that we used to think it was important for.
And people were making that argument about driving 10 years ago, you know,
and like now we know driving, robot driving is a solved problem.
Or if it's not 100% solved, it's a, no one denies now that, well, I don't
think decides that it's a solvable problem, right?
Yeah, driving is complicated.
There's lots to do, but it turns out it's not that hard.
So, or it is that hard, but we can, we can solve it.
Right.
It's brute force.
Doesn't mean, yeah, it's not intractively hard for a robot to do.
Yeah.
More did a male continues.
And now we have GPT2.
People keep calling it a language model.
It is obviously more than a language model.
It is a concept model.
It clearly has a complex web of understanding of conceptual relationships.
It knows that water is wet, that wet things are slippery, that slippery things
make people fall, et cetera.
It knows, quote unquote, and again, we're using that word, this abstractly and
without the kind of concrete reference that you and I have access to, but I
would argue that it still counts as knowledge and conceptual understanding.
Much like I was saying that I think knowing that a daughter is the way daughter
is related to father is something that is encoded in that web of concepts, even
if it doesn't know what a daughter or a father is in the real world.
Yeah.
See, I guess I'm, my understanding of GPT2 isn't sufficient because I'm, I
didn't spend a lot of time researching it and I get the impression that there's a
lot of groundwork I have to cover to get my head around it, but I was thinking
that it was more like a, a well-calibrated, a very strongly calibrated, like
text prediction or in my understanding, which I think very well, maybe wrong, but
if it's right, it doesn't have like a confidence node that it's like, I'm
pretty sure of this, that just has like, it just has the next word and maybe some
of the previous ones, but anyway, go on.
Yeah.
I'm going to skip just a little bit and continue for me, all of this adds up to
the following humans are actually pretty dumb.
The things we think are hard are not hard, certainly not as hard as we think
they are. The clutch that is the human brain is a clutch or Cluj, I never
was sure how to pronounce that word.
The only word that I saw was one that you skipped and that was copacetic, which
I liked the Taylor shout out because she used that word 15 times in worms.
Okay.
Maybe exaggerating, but she used it a lot.
So that's the most times I've ever seen the word copacetic.
In any case, I want to shout out that I noticed that Matt.
So well done.
The Cluj that is the human brain is good at doing a wide variety of things, but
any individual thing we do ultimately requires less CPU power than you find on
your cell phone. Yes, the training phase for these systems tends to involve huge
amounts of compute, but we're only getting more efficient at that part.
And the train system ends up being something that, as Alexander Wales noted,
can fit inside a virtual machine on a net book.
Yeah, it was four gigs and I'm not sure how many gigs though human brain is,
but to me, I mean, four gigs is well, it's funny because like now it's nothing.
And yet I remember 15 years ago when like the new large 256 megabyte flash drive
was $60.
So I remember the first time I heard the term gigabyte and I thought someone was
like pulling my leg because it sounded stupid.
Like gig, sure.
Whatever, man.
Right.
Okay.
The only reason GPT two isn't obviously scarier than it already is, is that it wasn't
really asked to do anything other than predict, than predict text, give and text.
So imagine this, another AI system trained purely to identify logical incoherence
or contradiction in written text, not that hard to do.
I wouldn't think there are easy versions of this that can be made without even
needing deep learning, but a full deep learning system with lots of training
data would do an even better job.
Now imagine connecting this system with GPT two, such that GPT two generates a
large number of possible essays rather than just one and the logical
coherence spot judges which essay is the most logically coherent.
Usually such systems are trained in tandem, such that they get even better at
doing their joint job.
Now you have a new system, which does what GPT two does, except doesn't make nearly
as many of the kinds of obvious mistakes that GPT two does.
Now just think about other types of simple things that could be plugged into
Alpha Star or GPT two, and you start to see the road to AGI.
Yeah, I like that.
I think that that sort of hybrid thing is what we're both kind of converging on here.
This tool on its own is cool, but it's not on its own sufficient to do the job.
And yet training up a logical consistency bot, and I mean that's the thing too,
is the training times with these is not like training a person where you can give
them a few years in school and read a bunch of books and write a bunch of essays.
It's like hours.
Subjectively it's hundreds of years, but whatever.
For us, at our scale, that's all we care about.
It's pretty wild.
I'm excited about it.
We'll see what shakes out.
One final comment from Googleplex Bank?
Actually, I had one here on.
So we kind of took these out of order.
We read Trebotron's first, then we did more dint of males,
which was the parent comment of his.
Oh, was that what it was?
Yeah.
Oh, okay.
Oh, wait, no, I'm sorry.
They kind of had a bit back and forth here.
So there was Trebotron on his own comment, and then there was another one
underneath Matt's comment here.
So I'll read that one really quick, too.
Mm-hmm.
In the child to Matt's comment was another Trebotron one where he quotes,
it clearly has the complex of understanding of conceptual relationships.
It knows water is wet, that wet things are slippery, that slippery things
make people fall, et cetera.
And then Trebotron says, no, it doesn't.
It knows none of that.
The only thing it knows that wet, the sequence of character is not a concept,
often is seen around, quote, water.
Another sequence of character is not a concept.
It's just a statistical model.
It's not any deeper than that.
No conceptual knowledge at all.
Quote, is that it wasn't really asked to do anything other than predict text given text.
Unquote.
It literally cannot do anything else.
Arguably, you can take that size neural net and train it on cat pictures,
and it would be able to probably generate a decent cat pic,
like this person does not exist thing that we talked about.
It wouldn't be able to do anything, text prediction or anything else.
This is why GPT2 is not scary.
Its main innovation is parameter big spacing enough to encode a decent statistical model
of English and nothing more.
So then Matt kind of grabs out that, no, it doesn't, no conceptual knowledge, quote,
and then says, you're just a machine that models statistical relationships.
We have more context for our statistical relationships.
At this point, we're just reading their thread.
We are.
And it was really good thread.
So this isn't worth reading thing.
This is just a time constraint thing.
And it's just we don't want to be reading other threads.
Yeah, this thread exists.
It's on under episode 80 on the subreddit, the reward and parallel GPT2.
Check it out.
It was a great, great discussion.
One of our most highly commented posts in the last few months.
So, and I got to plug really quick too.
If you like that level of like thoughtful analysis and good use of words,
Matt can talk like that in real time too.
That's true.
So I once again want to plug the We've Got Warm and We've Got Ward podcasts,
as well as the Doofcast episodes of, well, all of them,
but they're good with or without Matt too.
But Matt and Scott discuss Warm and Ward, a great web serial fiction,
if you haven't read it, as strongly recommended,
in just that poignant and deep and thoughtful analysis.
And what's great too is that Wild Bo was playing at the same level as the author.
Like everything that he's doing is clearly on purpose.
And that's the sort of stuff that I could write a short story
with a beginning, middle, and end.
And it would be like, yep, things happened.
And it told the little thing I wanted it to.
I could never put in without some serious time,
and it would suck for me to do it.
Symbolism and implied meanings in this and that.
Like I just, I don't have that.
And so Wild Bo's a brilliant author,
and the editors work brilliantly.
So everyone check that out if you haven't yet.
Excellent.
To wrap up the GPT-2, and I think also this episode,
Google Plex Byte says,
I am saying that given enough data and computing power,
GPT-2 could understand abstract mathematics
as well as a mathematician does.
Abstract mathematics doesn't require any reference to the physical universe.
So GPT-2 would have every tool it needs to understand it
as well as a mathematician can.
I think we'll leave that to computer scientists to dissect there.
Without trying to taboo the confusing words,
like understand and that sort of stuff and knowledge maybe.
I mean, I guess, yeah, you can write something
that'll give you the resultant equation of throwing a baseball.
It doesn't have to know what a baseball is.
That's not abstract mathematics though.
That's fair, yeah.
So, but I mean, GPT-2's language analysis isn't abstract either.
It's giving the actual words, give an actual input, right?
I'm sure I'm missing stuff.
I have a job, well, I work in the field of computers,
but my computer science is drastically lacking.
And if that's not obvious, well,
if that wasn't obvious before, it is now.
You were not an AI programmer is what you're saying?
Or a computer scientist, okay.
I went to a boot camp.
They don't train us computer science.
They train us on how to code,
which is, that's the main difference to get out by, for example,
actually I've had a couple people ask about that in email
and in Patreon comments and stuff.
It's worth pointing out, I guess, if anyone's curious,
the analysis of like, post computer science graduates
and post boot camp graduates for software development,
it tends to be that boot campers can code faster and better
than the average computer science graduate.
What they can't do is like, describe data structures
or different data models for,
or like different models for building applications on,
or really any computer algorithmic, any stuff.
That's all skipped over in the like, how to do this course.
So if you want a good, long understanding,
do the long, hard way.
If you want to be able to hit the keyboard
and get a job in six months, maybe do a boot camp.
Oh, we do have one comment from me.
Yeah.
I said, this happened pretty fast
and linked to Alphabet Google and anything that Alphabet made.
Alphabet made a Chrome extension
that is designed to tune out toxic comments.
It just will scan the comments, rate them on toxicity
based on its understanding of the language
and not show you, you know,
past a certain level that you choose.
I prefer the plugin that just changes
all the YouTube comments to like Meow and like Woof
and all that stuff.
Right.
But that was, that was pretty fucking impressive
that like, it could in some way have a rating of toxicity
based on reading a comment and, you know,
I want to show them or not.
I wonder what like the success overlap is
with like something this complicated
for that Chrome extension versus one that just like,
has like a list of keywords, like, I don't know.
Right.
They're probably.
A bunch of profanity and just cuts those out too.
Yeah.
I bet that one just gets like 80% of the same ones
that this one gets.
I would assume.
But that's really cool.
And this one's actually done the hard way,
which is really cool.
I'd be curious to see, and this is a link
that I haven't read yet.
So if you have any discussion,
a discussion about toxic, about toxicity in general
or about like the content that's there or something,
if that would also get flagged, like probably.
I would imagine not.
I mean, I imagine using the word.
I imagine you keep using the word content,
fag, you're going to get flagged no matter what, right?
Yeah.
Well, I mean, that's where a traditional flacker
would totally get it.
Yeah.
This thing is supposed to like judge tone, though.
All right.
I'm going to click this.
I'm going to see if I can play around with it
and see what we get out of it later.
So that's it for listener feedback.
We did have a comment here or something that you put in here
from Julia Gale of Facebook.
Do you want to do that really quick too?
No.
All right.
We'll save that one because that one's not time sensitive
and as far as I know, she doesn't listen to the podcast.
Yeah.
Or at least she hasn't listened to my request
to have her on the podcast.
So.
All righty.
Shall we move on to the less wrong posts?
Yeah.
Let's.
It feels really weird doing the less wrong posts
without Jess here.
We can skip them and talk about other stuff
or we can knock them out really quick.
It's up to you.
Yeah.
Let's, we should do them.
All right.
We'll, we'll trudge on and we'll just, we'll,
we'll acknowledge up front that these won't be
as much fun without her.
Yeah.
So we had three posts this week or this episode rather
because they were kind of short
and I felt like they kind of tied into each other.
Let's see.
So the first one was knowing about biases
can hurt people.
And my one sentence read on this is like,
basically, if all you have is the knowledge
that biases exist and how to identify them,
it doesn't, it, it can be a double-edged sword
where you, and he, I think he uses the word
sophisticated arguer here.
This is like somebody who knows.
Let's not do the sophisticated arguer yet.
All right.
That's fine.
Okay.
But this is kind of like akin to like knowing
logical fallacies, but not practicing not using them.
Yeah.
So you can point out slippery slopes
and false dichotomies with your opponents,
but like you're not paying attention to your own words.
Right.
That, that, that can happen with biases too.
Yeah.
You always apply them to other people and be like,
oh, this is where you're doing wrong
and you don't look at your own arguments
the same way.
Yeah.
Which just makes you get more and more entrenched
in the viewpoint you already hold.
Especially if like it's never,
if you'd never really accept the fact
that like you're doing that
and then you find yourself winning all these arguments
and you're like, I must be right.
It can be definitely a vicious feedback cycle.
Yeah.
It starts off with a fun little story of once upon a time
I tried to tell my mother about the problem
of expert calibration saying, quote,
so when an expert says they're 99% confident,
it only happens about 70% of the time, unquote.
Then there was a pause as suddenly I realized
I was speaking to my mother and I hastily added,
of course, you've got to make sure to apply
that skepticism even handily,
including to yourself rather than just using it
to argue against anything you disagree with.
And as my mother said,
are you kidding?
I use this all the time.
It's great.
So it's a lesson in knowing that these are tools
that if used properly will work both ways.
You can't just use them to rub other people's things apart,
but to dive into actual content of the post.
And he had a really interesting thing that he said too.
Do you think you are helping these people
who are sophisticated in this way?
Do you think you're making them more effective rationalists
if you just gave them these lists of biases?
I was like, wow, that's, I hate ever being in a position
of saying that more knowledge makes people worse off, right?
So I don't want to say that,
but it sounds almost like, you know.
In this case, it's, it's, it's not, yeah.
And it does run against that, that grain of like,
you know, why should knowledge hurt?
But this, this is knowledge that's.
If you just gave them that,
you're not making them a more effective rationalist.
You're making them more effective at fooling themselves,
which is the opposite of what we want.
Right.
Because for some reason, I'm not a car person,
but all my analogies involve cars.
If I taught you how the go pedal works and not the brake,
are you a better driver than you were before?
Right.
Or probably not, right?
I mean, I guess a little, you can,
you can do one thing with the car.
Are you a safer driver?
Absolutely not.
You're a safer driver knowing nothing about how the car works
than you are just knowing how to, how to hit the gas pedal.
Yeah.
So this, that's actually not the worst analogy in the world.
And they even tied it to cars.
What is it with you and cars, man?
I don't know.
Are you sure you're not a car nerd?
Pretty sure.
Do you have like a broken down car
you're working on every weekend?
I've had lots of broken cars.
I think it's more just like, they're really simple
and they do lots of little things.
And it's, I can usually find a way
to pitch and hold an analogy into them.
But yeah.
So he, he gives off, I don't know,
well, we'll burn through them really quick.
Tabor and Lodge.
Let's not go through all of them.
All right, cool.
There are whatever, six, whatever.
I thought there were.
Unless you want to burn through them.
Go ahead then.
We'll just jump through.
Cut out me being a dick.
No, you're totally fine.
There's, we'll run through really quick.
There's Tabor and Lodge's motivated skepticism
in the evolution evaluation rather of political beliefs.
The confirmation of six predictions.
There's the prior attitude effect
where subjects who feel strongly about an issue,
even when encouraged to be objective,
will evaluate supportive arguments
more favorably than contrary arguments.
Number two, disconfirmation bias.
Subjects will spend more time in cognitive resources
denigrating contrary arguments than supporting ones.
Number three, confirmation bias.
Subjects free to choose their information sources
will seek out supportive rather than contrary sources.
Four, attitude polarization.
Exposing subjects to an apparently balanced
set of pro and con arguments will exaggerate
their initial position or their initial polarization.
Number five, attitude strength effect.
Subjects voicing stronger attitudes
will be more prone to the above biases.
And number six, the sophistication effect.
Politically knowledgeable subjects,
because they possess a greater ammunition
in which to counter-argue
incongruent facts and arguments
will be more prone to the above biases.
I felt like it was worth going into
because everyone's heard of many of these,
like confirmation bias, probably attitude polarization.
But the main thing is that there's the effect
that if you're just aware of the first five,
those are great tools to use to rip other people apart.
But this is where it introduces the sophisticated arguer.
But yeah, also I thought that it was interesting
because I was chipped up briefly on prior attitude effect
versus confirmation bias, which are different.
And he pointed out that even telling people
about this isn't necessarily enough.
He says that he told someone about the sophisticated argument
a sophisticated arguer effect,
where if you know all these biases,
they will tend to use them just to promote their own position.
And next time that Eliezer said something
that the person didn't like,
he accused Eliezer of being a sophisticated arguer.
Didn't try to point out any particular
sophisticated argument or any particular flaw,
just shook his head and said that
I was apparently using my own intelligence
to defeat itself.
So he basically had just gotten
yet another fully general counterargument.
Which I don't think we've discussed the topic before,
and yet it was a hyperlink in the post.
So somehow we missed it.
It wasn't a hyperlink.
It was, I think.
Oh, it wasn't.
Yeah.
Why am I tripping up here?
I think it's something that was already being discussed
like in comments and such.
So I guess plus the other bloggers,
fully general counterargument.
So they added all in caps as the thing
that's actually already known in the community.
But there was never a post about it.
I somehow read it this afternoon
and thought there was.
So I'm crazy.
So I guess we didn't discuss fully general
counterarguments because we haven't gotten there yet.
But the gist is that it's this one thing you can wave
that's like, nope, conversation stopper.
I'm done.
I generally run into,
there's children dying in Africa or in China or whatever.
That thing you're doing right now doesn't matter.
It's like, okay.
Or running with our anti-theism run from a little earlier.
Like the God works in a serious way
to answer any and all,
like why is God killing poor babies?
It's like, well, he works in a serious way.
How could you possibly know the mind of God?
He has his reasons that you puny humans cannot comprehend.
And to say that, like, again,
not necessarily picking on theism,
but to run with that example,
not necessarily not picking on theism,
but to run with that example,
like the comeback God works in a serious way
isn't an argument.
It's not even really a position.
It's like, it's just a,
this is my stop to your argument.
And nothing you can say will change
the fact that God works in a serious way, right?
So basically it's a tool you can use to like quote,
win any argument,
but not in a way that like makes either of you better off
for having had the argument, right?
Right.
Yeah.
All right.
Yeah.
So he says,
even the notion of a sophisticated arguer can be deadly
if it leaps all too readily to the mind
when you encounter a seemingly intelligent person
who says something you don't like.
I thought that was,
that was almost depressing in a way that even,
even that is misused.
You know, I remember reading when I first read this
that like this might come up in real like rationalist life.
If I had a conversation with the rationalist and stuff,
I don't think I've ever been accused of being a sophisticated arguer,
which might mean,
which may be a good sign that I'm not a sophisticated arguer
in the, in the pejorative sense.
Right, right.
Or it could mean that my friends aren't sufficiently rational
to point out when I am being one.
Okay.
But it's,
it's the kind of thing that in a,
in a conversation between two people
with the right training,
if we were discussing,
I don't know, somebody's position on something and I'd be like,
are you sure that's not, you know, sophisticated argumentation?
You would be, you would idealistically pause and say,
oh, maybe it is.
Right.
And so it's another thing to be aware of when you're introspecting.
But the thing is like,
no one has the motivation to investigate all claims as rigorously
as they would investigate something like,
your mother is a pedophile, right?
That would be something where I would be like,
no, she's not allowed me to prove it to you.
And there's, you know,
people feel that way about the things they really care about,
but no one like's going to go and investigate the opposite position
because they just don't have the passion and the energy for it.
I think,
I think this is one of these places where it's better to have
a variety of views on things and get your,
get people who believe differently,
both investigating something.
You mean,
you mean,
you mean like you couldn't be an impartial investigator
if someone raised this charge seriously?
No, I just mean,
you cannot be this impartial.
We're not perfect Bayesian machines, right?
We already have our passions and our things we care about
and limits to our time and our energy and our motivation.
So I think the best thing to do if like you want to,
and now that I say this,
sorry, my head's running out of my mouth.
I was going to say,
the best thing you want to do when you want to investigate something
is to get two people who are both really interested in the subject,
but in opposite directions
and both look into it at the same time
and present their viewpoints to each other
or to an interested third party.
And then that reminded me that,
yeah,
that's the thing that Scott Alexander is doing
with his adversarial collaboration.
Yeah.
And it's just,
it's catching on a little bit more.
But yeah,
I mean,
that's the reason why you want to have debates and such, right?
Because you,
you're all into looking up the stuff that supports your position
and you need someone else who has the same sort of passion
to look into stuff that is against your position
so that you at least have the,
all the available data in front of you
instead of just the stuff that you had the time
and the inclination to find.
Does that tie in to the sophisticated arguer?
That just sounds like a good lesson
in like being aware that you might be too invested in something.
Yeah.
I don't know that.
I might be missing something.
I think the sophisticated arguer would be someone
who would dismiss the other side quickly.
Or yeah,
they would use all of their sophisticated arguments
to point out why they're so stupid,
but not really defeat,
not really defeat it.
Right.
Okay.
Or even say to the other side,
you are blinding yourself with your own sophisticated arguments
instead of actually accepting my position.
Yeah.
I think maybe choosing an emotionally charged example is,
I don't know.
Now I'm kind of wondering if I don't sufficiently care about things
because like if someone told me that,
I'd be like, wait, really, what do you,
why do you think that?
I might insert my response depending on who they were
and where this came from.
But like if you told me that my mom was a pedophile,
I'd be like, why the hell would you say that?
Like, what do you know that I don't know?
Right.
And if she's not, I'm pretty sure.
But if you had really compelling evidence,
I kind of want to know.
So like, that reminds, this is,
all right, this is a sidebar,
but we're in the end game now.
So remember, we had the conversation way back in the day
with Katrina about like whether or not
you can harm somebody who's dead.
And you and I are both kind of running with the Aristotelian
like virtue of like, sure,
you can destroy the reputation or something.
But I wish I had asked her was like,
if say you died and I put a bunch of meat in your fridge
and a bunch of child porn on your computer,
would I not have harmed you?
So like in the technical sense, no, because she's dead.
But in like the other sense, it's like,
all the good that you've done in the world
is now destroyed by the fact that like,
I've created this convincing fraud
that or this convincing framework
that like you're this fraud who ate meat this whole time
and never believed your virtues.
Oh, and you had kiddie porn on your computer.
Yeah.
So like-
So that book I raved about a couple episodes ago,
Monster Baru, The Monster Baru Cormorant.
Hold on, can you say that also?
Because when you, when I plugged that in the last episode,
I had to ask you what it was
because I couldn't understand what you said.
Okay, the book was The Monster Baru Cormorant.
Her name is Baru, first name is Baru,
last name is Cormorant.
Okay, so that's why I couldn't like Google it
because they weren't words.
Yes.
Okay, gotcha.
Well, Cormorant is actually a word.
It's a type of bird.
Okay.
Yeah.
All right.
Last name is NAFTA bird.
Anyways, but yeah, in the book,
there's a character that makes the point
that it can't be that things don't matter anymore
after someone is dead because we all die.
And so that means that nothing matters.
So arguing from the bottom, but I like it.
Yeah, yeah.
Things have to matter even after you're dead.
What I thought you were going to say,
and this is the other side of that coin,
is that like things have to matter
after they're dead because we care about dead people.
And we care about the impact that they had.
Like Martin Luther King didn't stop being important
the day he was shot, right?
So your posthumous impact matters.
And don't get me wrong, this was not a dig on Katrina.
The reason I was thinking about this recently was,
I can't remember what brought it up,
something about that like,
can you harm dead people?
It came back to mind just a few weeks ago.
And it's not like I thought I had this great gotcha.
It's like, I wish I'd asked her that
because I wonder if that would have illustrated my point better.
Anyway, so wrapping this one up, this post.
The literature on bias is mostly cognitive psychology
for cognitive psychology's sake.
I had to give my audience their dire warnings
during that one lecture,
or they would probably not hear them at all.
And I don't think we talked about it.
That lecture he's talking about is that when he became of this,
became of the sophisticated arguer bias,
that now he teaches that in the initial talk,
he never, that's always part of the first exposure.
And I guess he could leave the room before he gets there,
but you're not gonna get any good weapons.
You're gonna get vague things like population insensitivity
or something as an example of a bad heuristic.
But yeah, so being aware of the sophisticated arguer trap
is important for a good rationalist.
I don't know, kind of like the analogy to rationality
and martial arts has hit so many times.
And so acute that like it's worth,
it comes to mind easily, right?
This might be like using a headbutt to strike somebody.
Like if you hit them right, it hurts them a lot,
but it hurts you too, but you might not notice it maybe.
Is that too torture to an analogy?
I would say like, you probably want to teach someone
how to fall early on in martial arts.
And if you don't, they're gonna hurt themselves a lot,
practicing it.
That's good, that's good to think of it too, yeah.
And I guess just to be aware that like,
some moves can damage you too,
if you're not careful about them, maybe.
Yeah, all right, maybe it's on a smooth analogy
with that particular one.
Post two, de-biasing as non-self-destruction.
So this starts with a quote from Nick Bostrom, quote.
A question from Nick Bostrom.
Quote slash question, it's in quotes.
Okay, it's a question from Nick Bostrom.
What practical things does de-biasing enable us to do
other than refraining from buying lottery tickets?
You know, that's the fair question from the outside, right?
I mean, we've asked basically that same question
using becoming rationalists as instead of de-biasing
a number of times on this podcast.
Yeah, that's a good point.
And de-biasing isn't sufficient
to become a rationalist as necessary.
Yeah.
Yeah.
So, it seems to me that how to be smart
varies wildly between professions.
Yet such concepts as willing to admit you lost
or policy debates should not appear one-sided
or plan to overcome your flaws
instead of just confessing them,
seem like they could all apply to many professions.
All of this is a device, not so much about
how to be extraordinarily clever as rather,
how not to be stupid.
Which I think is something that we hit on
before we're trying to answer the question of somebody like,
what's something you do rationally daily life?
Like, it's not so much like,
I do these five things every day.
It's more like, I just try not to suck
and I try to use these tools.
And it's so familiar.
I almost think that we must...
Did we quote this post before?
Was this just something we had on our minds?
Because we've dreaded?
I think I quote...
I think I informally quoted it not verbatim
during that conversation.
Yeah, because I use the example of like,
and maybe that's in this poster now,
but it's not in the quotes that we pulled out.
Like, not sucking up being a janitor
and not sucking up being a lawyer
probably have a lot in common.
But being great at both of those professions
have like very little in common.
So there's the basic,
base level art of just like,
not sucking at what you're doing.
That tends to be pretty consistent
across lots of things.
And I mean, it's just like, I don't know,
if you've had lots of jobs,
if you've had lots of coworkers,
and you've had good and bad ones,
a lot of the bad ones will have a lot of the same habits
as a lot of the other bad ones, right?
But the good ones can be good in different ways.
I mean, the bad ones will be the ones that,
you know, whatever don't show up to work
or are mean or something like that, right?
So.
Not showing up is a pretty big deal.
It's a pretty big one.
And it's a good sign that you suck at your job.
Debiasing is mostly not about
how to be extraordinarily clever,
but about how to not be stupid.
It's great successes are disasters
that do not materialize,
defeats that never happen,
mistakes that no one sees
because they are not made.
Often you can't even be sure
that something would have gone wrong
if you had not tried to de-bias yourself.
You don't always see the bullet that doesn't hit you.
That's the quote that always stuck with me.
Because it also sucks because,
and he goes on to point out
because that makes shitty anecdotes,
that makes shitty evidence, right?
Yeah.
It's like, remember all those times
I didn't get killed?
I don't know, man, running back to driving.
It's like, you know, if you're a good driver,
you might not even notice all the time
is that you don't kill yourself
when you're driving, right?
You'll notice some of the close calls
if you do screw up.
And if you're like, I was texting and then,
oh shit, that car came out fast
and I thought I was going to.
And yet it's your reaction
and your skill as a good driver
that lets you notice and then not have that happen.
But that's not like,
that's a victory because it's not a loss, right?
But it's not like a I won at not crashing,
unless you're getting those,
the game you're playing is not crashing.
You see what I mean?
It's like an inversion of winning
in the sense of not losing,
which I'm just hitting home
because that really struck ball with me as,
that's a very basic thing, right?
I remember the writer who wrote in,
or the commenter who wrote into us once,
he lived, I forget which country it was,
but it was one of the developing nations.
And he said how much,
how often he saw people doing
simple, somewhat self-destructive things
that if they had just known some rationalism,
it would have made a difference.
And if the entire community had known that,
it would have been a huge level up to the whole community
to not make those errors.
And it's just things like that that you don't see.
Yeah.
Especially when your entire community
is already practicing it.
We're going to have to have Jess talk
about her time in the Bay Area and like visiting,
I'm not sure exactly where she's staying
or she's like, in a hub where people are all doing this.
But I'm curious like what a small microcosm of society
would look like if they're all doing all the things right
and they're all not losing all the,
if they're all missing all the easy bullets
or the easily dodgeable bullets.
I mean, I imagine for example,
like electricity bill never not gets paid, right?
But I'm kind of curious if there are like victories,
if everyone's together and doing this,
what are the awesome things that are happening?
So that'd be curious to see.
And if Jess can't do it,
we'll get somebody from Ritu cans or we'll try.
So yeah, I mean the great victories,
and this is more on the point I was making,
the great victories of de-biasing
are exactly the lottery tickets we didn't buy,
the hopes and dreams we kept in the real world
instead of diverting them into infinitesimal probabilities.
The triumphs of de-biasing are cults not joined,
optimistic assumptions rejected during planning,
time not wasted on blind alleys,
is the art of non-self-destruction.
And I mean, this is actually kind of funny
because he mentions the, you know,
cults not rejected and stuff.
Or cults not joined.
That's right, excuse me, not joined.
Only don't reject one cult.
This one.
When I was a kid, probably up until my early teenage years,
I was convinced that like,
here's what I'm going to do and how I'm going to win at life.
I'm going to find a magical artifact.
There's all these stories have to come from somewhere.
As a kid, I didn't think that it was all wishful thinking.
I assumed that it was all rooted somewhere.
I was like, I'm going to find that a magic amulet
or the magic ring or something,
and I'm going to get these powers.
And I mean, how dumb in my life have turned out
if I didn't shake that off after a couple of years, right?
Like if all of my like working to like get enough money
was so I could go, you know,
whatever dig in Egyptian pyramids or something
to go try and find a magic trinket.
Maybe you'd be a faith healer right now, man,
raking in the money.
Or maybe I'd be a real magic person,
not just a faith healer, right?
Oh, well, okay.
Oh yeah.
There's the shister art of like pretend faith healing
where I'll pull out your cancerous tumor with a sleight of hand.
But yeah, if I could, if I could do something.
But yeah, the thing is, I don't think that's the case.
So it was just funny because I wonder if I'd read this
as a kid, what I would have thought.
As a kid, to give my younger self exactly as little credit
as he deserves, I think I would have thought,
sure, but this one's different, right?
This pyramid scheme is real.
It's got an actual pyramid, man.
Exactly.
Fact is most people, this is back to the post.
The fact is most people who take a half-hearted pot shot
at debiasing themselves, excuse me,
at debiasing themselves,
don't get a huge amount of mileage out of it.
This is one of those things you have to work at
for quite a while before you get good at it,
especially since there's currently no source
of systematic training or even a decent manual.
The sequences end up being a decent manual to get started,
but he's writing it right now, so in this time.
If for, and this is a quote, or this is a link
to the 10 virtues of rationality post
that we should actually just do for one of our sequence posts.
Yeah.
So this was all hyperlink in this next sentence.
If for many years you practice the techniques
and submit yourself to strict constraints,
it may not be, or it may be that you will glimpse the center.
But until then, mistakes avoided are just replaced
by their mistakes.
It takes time for your minds to become significantly quieter.
Indeed, a little knowledge of cognitive biases often hurts
that quote got cut off.
It's often harmful, I'm assuming is what that was going to say.
I think it was the link back to the prior post.
Yeah.
Yeah.
Do you want to stop there?
I don't, I kind of don't want to do the third one
because I'm not sure it's as related and I'm sort of burnt.
That's totally fine.
Okay.
We've got one bullet point and then I'll hit it.
Sure, sure.
Yeah, sorry.
No, you're totally fine.
I appreciate the, yeah, it's been a long time.
So the last thing on here is that as a public proof of like,
that this does anything, that rationality is useful,
he says, I can see at least three ways that it could come about.
First, there might be founded an order of base craft
for people who are serious about, serious about it.
And graduates of these dojos might prove systematically
more successful even after controlling for measures
of fluid intelligence.
Second, you could just, you could wait for some individual
or group working on important specific,
or domain specific problem, but also known for their commitment
to debiasing to produce a spectacularly huge success,
public success.
Third, there might be found techniques that can be taught easily
and have readily measurable results.
And then a simple controlled experiment could serve as public proof,
at least for those who attend to science.
As far as these go, I think CIFAR is kind of doing the third.
And the first two, I've heard people in our local community
who are trying to do something kind of like that,
where they, they want to, and it's not necessarily committing
to like a, it's more, I guess, the first one of saying,
look, I'm successful here and here and here
because of my rationality training.
And these are all the stupid mistakes I didn't make.
I think they're, they're in the progress now of,
or in the process now of trying to refine something like that,
that's presentable to people.
Oh, cool.
So this things are still happening.
I'm sure there's way more happening outside of the Denver area that,
you know, I wonder what people, like I said,
in the Bay Area or at CIFAR and all that more up to.
That's where all the big names are?
Yes, where all the big names are.
And yet, like, I'm pretty sure if we had, you know,
this, this great breakthrough at some point,
we might have come, we might have heard a word about it here yet.
Right, right.
So I think they're still working on it,
but granted, this was what, in 10 years ago,
some things take a while.
Yeah.
Well, in 10 years ago, there was really no one yet.
I mean, there was a few posters on overcomingbias.com.
Right.
Which later turned into less wrong,
but not yet at this point even.
Yeah.
That's fair.
And I mean, I guess the other thing too is like,
I guess I'm just kind of heading off like the rejoinder of like,
well, why hasn't this produced anything like this yet?
Because this is like untreaded water in social science.
And I mean,
And if you had told me, hey, it's been two years,
I've made a breathtaking discovery in a new area of social science,
I'd be like, okay, well, I'm kind of suspicious.
Right.
And there have been steps.
There have been very positive motions and like I said,
movements working on these things, but.
And it's not like there hasn't been success.
There has been a huge amount of public interest
in finally addressing friendly AI due, you know,
in large part due to the work of Eliezer
and the early rationalists, Nick Bostrom, of course,
the AI movement was kicked off by these people.
And there is a, you know,
large supportive community in the Bay Area
that a lot of these people can live meaningful lives in now.
I mean, I would consider all three of those
to be pretty big successes too.
Yeah.
And I mean, we've heard from other like non Bay Area
based rationality groups that have to report similar,
you know, meaning and friends and communities.
So yeah, these things are happening.
I think just as far as like,
why isn't there a manual yet?
Like that, you know, eight quick steps
to not sucking at life.
Because there's no such thing.
Yeah. First of all, there might not be eight quick steps,
but B, I'm sure there's a hundred books with that title.
And C, we've only, the community's only been at this
for, you know, a little over a decade.
I strongly suspect I'm very confident
that things like this will be coming out.
But, you know, so far as I know,
nothing has been published today
that is a guaranteed manual.
So cognitive science or cognitive science
and like social sciences are hard.
And that's the downside.
It's like, you know, anyone who knows anything
about like treating depression or, you know,
dealing with a mental disorder
or mental illness or whatever,
like what works for one patient
doesn't necessarily work for another.
And so part of like working with the person
is figuring out what approach they need
because of what specifically we need to work on.
So like it's not, what I'm also strongly confident in it
is that this isn't going to be a set of steps
that works for 90% of people, right?
This is going to be the kinds of things that
all right, cool. Well, we found that 90% of people
who do all hundred of these things
tend to do really well.
Maybe only need a dozen, you know?
So anyway, it has run on quite a bit.
And we did have a third one we were going to do,
but frankly, it's kind of Matthew and boring.
He dives into more math that I think is strictly necessary,
but it's not like, maybe I'm just math averse.
But it's just, it's on inductive bias,
which we will actually, I think, save for next time
because it's been a while.
So for next time, our less wrong posts
will be inductive bias and futuristic predictions
as consumable goods.
Cool. So all that's left for this episode
is to thank our patron, Oren Milman.
Thank you so much for your support as you've heard before,
but it stays true. This means a lot.
We're sorry you only get two-thirds of the normal thanks
since there's no Jess here today.
Nonetheless, your support is appreciated
just as much as if she actually was here.
Yeah. So she is also thankful in spirit.
That's right. So yeah, other than that,
um, you know, rating review on iTunes,
star with your friends, et cetera, all the stuff.
People plug all the stuff at podcasts,
but you guys know what to do.
Yeah. We trust you. I don't have anything else to say.
Seriously though, thanks you guys. It's awesome.
Yeah. This has been a fun thing that we've been doing
for just over three years.
Oh man, it's been three years now.
Wait, no, two. Yeah.
No, I think it's been three.
Actually, we do one over two.
Oh wait, yeah, you're right.
It has been three. Man.
Suddenly, I feel older.
And we've had a patron to thank every week
since we started. Man, that's true.
Yeah. There was a time where we were like getting
near the bottom end of the list and I was like,
well, I guess when we get to the end of the list,
we just stop the podcast because we're at patrons.
Not seriously, but jokingly.
And then yeah, it's just been increasing again lately.
And wow, we've got, we've got the list still.
So yeah, thanks guys.
And so yeah, if you want to add your name to the list,
jump on Patreon, find us, throw us a buck or two
if you feel like it.
Once again, if you don't, iTunes, friends, all that stuff.
But we're happy to listen. This is fun.
I don't know. I, someone wrote in,
and I don't think we touched their comment.
It was just, it was on the subreddit or maybe via email.
I don't know. Once in a while, people write in
and say that they like listening to it.
And that means a lot. That's all I was going to say.
So that means a lot to me and it's fun to do.
So thanks.
All right. We will see all of you in two weeks.
Sounds good.
Oh wait, just kidding.
We have a couple more things we wanted to hit
before the end of the episode.
So we're going to do those now.
Yes.
So the first thing I wanted to do was,
one of the feedbacks is,
I wanted to ask you a question.
Oh boy.
Yeah. Feedback from the co-host and co-host.
Non-listener feedback is sometimes,
sometimes permitted, I guess.
Right. I warned you about this one though.
In our last episode, you said that you went into the pot shop
when they were having a woman's ladies night,
like 50% off pot or something?
Some percent. Something like,
something not negligible, like 25 or something.
Yeah.
Yeah. And you said, well, I, I'm a woman,
or identify as a woman or something.
And the guy gave you this look.
And you said, just kidding,
because I didn't want to be that asshole.
And I was like, I was curious, what,
what do you mean by I didn't want to be that asshole?
You bet.
So this would have been two episodes ago,
because this is the second feedback episode.
Yeah.
So.
Right.
Um, was that, was that a non-feedback episode
when we said that?
Oh, maybe it wasn't.
So maybe it was, oh, you know what,
it probably was the one that came out today.
Yeah.
Okay. Yeah.
So the one that came out today,
this one's coming out two weeks from recording.
So yeah, I can't remember the specifics.
I don't know.
He might have said no or something first.
It wasn't just a look.
I definitely waited for a response,
but the, my main reason for like not pushing the point at all
was because it wasn't true.
Like, I mean, I didn't,
there are people who are actually in that position
that maybe feel like if there's some promotion going on
that like they, they qualify more than I do,
because I'm, I was just trying to save 25% or whatever.
Right.
That was basically it.
Okay.
I didn't want to claim a status that you don't actually feel.
Yeah.
It would have been just ingenious for me to push it
beyond the like, oh, as long as all you have to say
those magic words to get the percent off or something.
Yeah.
And I never go, I had been to this place,
I went with a couple of coworkers,
they were driving, so it was on the way home.
And this isn't like a, one of my saying,
a deal I'm missing out on because I buy so much stuff.
I almost never go to the pot store.
So it's not a huge deal.
But because I had prep time to think of this,
I was thinking of this on the drive over.
One could make a utilitarian argument
that I ought to have pushed the point
because they clearly didn't have a policy in place
for somebody who was in the position
that I was claiming to be in.
Right.
Yeah.
So if I had, if I had made a stink and it was like,
no, look, you guys are discriminating against me.
They might have actually been forced to like,
refine a policy that was more inclusive
or if their dicks more exclusive.
Right.
Yeah.
They probably wouldn't.
What they'd probably say is like,
what it was is I'm sure this is the promotion
that didn't come from the cashier.
Right.
So if you've ever worked a register,
you know, you get people who are like,
well, man, why can't you guys, why is this so expensive?
And it's like, oh, you're right.
Me, the 750-hour employee determines how much those cost.
Right.
So I knew that this wasn't his decision.
It was something that they might have to escalate up.
So.
OK.
Yeah, I was just curious because I thought,
I thought the dick part was that challenging the narrative
that anyone can identify or choose their gender
without any sort of excuses or reasons given
or something like that.
And I was like, I wonder, I wonder what he was worried about.
Yeah, that's a good point.
Certainly, I don't think I should have been like,
demanded to justify why I felt that way.
So the dick part wasn't that exactly.
It was more just that because it wasn't genuine coming from me.
Yeah.
It was since it was insincere.
So we had at least one other thing you wanted to hit,
which was something else.
I was just wondering, oh, yeah, that, yeah.
So I guess the thing is then they would have had to explicitly
say, you know, we're gendering you as opposed to anyone
can choose their gender.
And then that would be the asshole move
of forcing that on them.
But it was just the asshole move of not wanting to claim
an identity you don't actually have.
Yeah, exactly.
It wasn't me defending their assumption
or their need for justification.
If I was in that, if I was in a class that I was claiming
to be in, it would not have been as such of me
whatsoever to push it.
And if anyone is feeling discriminated against
and they're actually being discriminated against and not
like me just pretending, then, yeah, by all means push it,
make a stink, make change.
But yeah, my main thing was that since I'm not actually
in a situation where I feel like I identify as a woman,
then it was definitely insincere.
So it was an asshole to my honesty,
not to them for being, you know, gendering whatever jerks.
Yeah.
So.
OK.
Yeah.
The other thing was that, so like I said,
I was in pain on Monday.
And so that was on my mind when we got to the aging question
and just like, man, this really sucks.
Getting old is going to suck.
Is this going to be my life now?
Yeah, exactly.
But the reason that I originally copied and pasted that in
was because I wanted to say that actually,
I think there's a lot of really good things about aging too.
But they weren't salient on Monday
when you're thinking of all the bad things.
Exactly, yeah.
Like not necessarily the aging.
Well, no, some parts of the aging process itself.
OK, so first things that are not integral to the aging process,
but merely the process of having more years of life,
is just you pick up a lot of stuff over time.
Like I got all sorts of crazy miscellaneous trivia in my head
and other things that I know.
I have a lot of skills that I've learned over time,
which are just really useful.
And like I didn't know those 10 years ago.
And sometimes people like compare people of different ages
and like how you look at how more advanced.
And it's like, yeah, OK, but he's also had 15 more years of life,
you know, he's just had a lot more time to absorb things
or she or they or whatever.
So you just having those extra years of life
comes in really handy with most everything.
And it's also helped me like I have the experience
of fighting crippling depression now.
So I'm generally pretty decent at it when it's not at its worst.
I will say that sex has gotten better constantly throughout my life.
Like five years ago, I was having the best sex I'd ever had.
Now I'm having the better sex.
And then I'm just like, you learn six.
Hell, yeah, high five, bro.
I mean, it's not like a high frequency activity,
like throwing a ball is that you can do it 20 times in an hour
to practice at it, right?
So just learning more about your body and interacting
with other people and figuring things out really makes a difference.
Am I hearing whispers of a like sex tips episode
for the patrons or something?
Heck, no, the I think that would be weird.
I think so, too.
But it's there are instructional videos for that.
Exactly. Yeah.
And they're not found at x2, although maybe they are.
They are found on Pornhub for all sorts of neat things.
They have like strictly educational material, which is funny,
because it I mean, now we're this is definitely tangential.
But like one of the one of the downsides of porn,
which is actually on my mind because Sam Harris did an interview
for Playboy a couple weeks ago.
That's cool.
Yeah, they did like a photo shoot and stuff,
which like so they like showed that at the top of the web page,
I guess, so you got like these fancy pictures
and then like just quick Q&A on like intellectual dark web stuff,
thoughts on a religion, afterlife, drugs and then porn.
And I don't remember what his full answer was
and it doesn't really relate because my answer is basically
as long as it's not psychologically damaging than go nuts to you
or obviously to the participants.
You know, if you're watching stuff with non-consensual people
who aren't really porn.
Exactly. That's a film crime.
That's a crime. Yeah.
But one of the downsides is like, I remember I was at the cusp
of manhood when the internet was first like getting a different one's house.
And so I remember, you know, being at a friend's house or, you know,
occasionally at my place, waiting for a picture to load line by line.
Right. Yes.
And so that was like, fortunately for me,
that was the that was the the level of technology available
for the 13 year old porn seeker, right?
Or however old I was.
Now you can get 1080 pixels on your phone in the bathroom.
So like it's I I'm curious, not to sound like a
cumbersome old man, but like I do worry that that would be
malforming for good attitudes for a 13 year old.
Yeah, I really think that sexual sex ed should actually be about sex
and not just procreation and sexual diseases because that's a long
that's a long leap because large parts of the country right now are anti sex ed
in the first place. I know.
And it's not even about sex.
But no, sex ed really should teach you about sex and how to
at least the basics of how to do it because porn is the only education
a lot of people get and it is a shit education.
It's like trying to teach someone to be a law enforcement officer
by making them watch John Woo movies.
No one actually runs downstairs,
leaning on a banister, shooting two pistols and killing 20 guys.
Right. You're not going to get to be a good cop by watching Die Hard.
No, that's not how any of this works.
That's actually a really good analogy.
It's fun to watch, but it's not how real life works.
Yeah. And I mean, you know, we don't have any
I doubt children listening to this show, but I mean, I'm just, you know,
some of the convoluted sex positions that these athletes can do,
like they might feel good, but they're not the kind of thing
you want to try at home without practice and probably like a trainer there
to make sure you don't, you know, concuss your partner or something, right?
So yeah. So other than that, why don't we get on porn?
Oh, because the internet is terrible.
I really think the internet should go think this could never happen.
I wish that the internet could go back to the days of being funded by porn
because everyone just has like porn ads on their site
because that at least wasn't terrible.
I mean, I guess it made it technically unsafe for minors or whatever.
But now the internet is run by making people as outraged
at their most hated outgroup as possible and stoking that.
And it's basically ruining society.
And I think that's a much worse way to fund the internet
than having porn banners everywhere.
It'd be interesting to see like if Facebook had poor banners,
if you'd get half as mad, right?
Because like you would be like, oh, man, my idiot uncle is pro.
Oh, wow, look at that ad over here.
And like that's got to distract from some of the rage, right?
You can't be both like, you know, super angry in your head
and while diverting blood elsewhere in the body.
So I just I think that the the the culture of generating clicks
and money from outrage has harmed society far more than porn ever did
or porn ever could. Yeah, it's interesting.
I mean, one cool thing about porn and tech is that porn tends to be
at like the forefront of all like new internet development.
So like I they were among the first to do anything with like 3D videos.
Mm hmm. So I mean, if that's your thing, you know, they pushed the secure
web payments and the technology behind that.
Yeah. Yeah. I mean, the tech scene, if you get a chance to work
for a porn company, sounds awesome. Yeah.
So there's that. I feel like it was less tangential.
Oh, we were talking about sex and stuff.
Yeah, that was all better places to learn about sex stuff.
Other cool things about getting old.
Oh, yeah. So yeah.
But that but I guess the to bring back the the porn digression
is that porn hub has educational videos in addition to pornography.
Yeah.
So if you live in a place that doesn't do sex,
they actually have sexual education videos and things that are even related to sex.
Pornhub has a few things that are just generally not porn at all.
And it's weird and interesting.
I think Kumail Nanjiani's movie, The Big Sick,
the whole thing was available on Pornhub.
Somebody tweeted him a link.
This was no, I was just not ready to make the internet porn hub from now on.
I was thinking about that recently.
I don't know how it came to mind.
It might have been because I'm never on Snapchat, but my brother has
ferrets and he sends me videos once a while.
So they're great. So I'm on Snapchat again.
And if you go to like the stories section, there's like ads for other things.
And one of them was like an oddly satisfying channel.
And there's a great you or there's a great subreddit called oddly satisfying
where it's like, you know, somebody like fitting a piece of formed wood
that they'd cut just to fit exactly right and it's like seamless.
And so like, you know, those like, oh, that feels so good to watch.
There was a recommended thing for that.
But that's the only place I've ever seen like an oddly satisfying tag.
And I didn't know that Reddit sold my stuff to Snapchat.
So I was thinking just recently why, like, it would be nice
to have like, I don't know, an alternative hub where there where there was another
because like this internet is never going away.
This is this model.
But if there was if there was a competing web.
We need actual internets in real life.
That'd be cool. Yeah.
Hey, hey, I could hear music. It was dope.
You said it wasn't too well.
No, no, it's fine. I was I was enjoying it.
Yeah. See, that's that's another good thing about getting older.
You learn, you have time to learn skills.
Like if you just practice guitar one hour a week,
it's not a lot of time, even like two 30 hour sessions a week.
It's not a lot of time to spend.
But every spend a half hour on it, your fingers are a little sore.
But you keep that up for five years.
You're goddamn good guitar player after that time.
Yeah. Five years passes way sooner than you'd notice.
I think all of a sudden you're a guy who's got five years experience playing guitar.
And there's like more free time with a lot of case in a lot of cases.
Like my mom's learning paint.
Oh, I mean, she probably took painting in school or something.
But like she's doing painting stuff for fun now.
I mentioned Rachel's mom does cello.
And that's something that she's picked up in the last few years.
So like it's just the freedom of doing stuff.
And the emotional dulling we were talking about actually can be a good thing, too, in a way.
You don't you don't get as crazy by everything.
You're like, yeah, this is no big deal.
I've gone through this sort of thing before.
Yeah. Like you other people can even tell other people,
hey, I've had this sort of thing happen before.
Don't panic. Here's what you do.
Like I can I can only imagine how awesome it must have been to live
in a village or a tribe with elders that would just know things
as opposed to having to figure out everything yourself, getting occasional
advice from one or two older people and finding everything else on YouTube.
Yeah, it's I mean, I learn better talking to people, too.
But on the plus side, like our generation, the people who are, you know,
savvy with the internet now have access to elders all the time.
Right. And whatever niche thing it is you want to know,
there's YouTube tutorial for it, which, you know,
probably has its pros and cons.
I was thinking about that speaking of aging.
There's this thing I remember in school where, you know,
like especially older teachers and maybe even people's parents,
because like you'd be annoyed that, you know, you're everyone
probably has worked with a coworker or something where they're just completely
tech illiterate and, you know, I've heard from multiple people.
They're like, don't know people who will
they'll receive an email attachment in the form of a PDF and then print it
and then scan it and save it at the desktop because that's the only way that
they know to do it. And it's just like random pointless shit like that.
And then we try and correct them on it and be like, why don't you just do it
this way? Oh, I'm retiring in five years. It's no big deal.
And it's like, it's kind of annoying though.
It takes you 30 minutes to do something that should take five seconds.
And so anyway, the, the response from a lot of the start of a response from
older people is like, oh, well, you know, since I don't need to let know
it because it's new stuff and I'm retiring soon, it's not a big deal.
And you'll be in the situation too someday.
I challenge that assumption.
I can see why it's a natural assumption because that's what happened previously.
And that's probably happened previously for as long as tech has been booming,
right? And yet our generation has grown up with advancing tech and has
kept up with it this whole time.
Every single year we got to learn new things.
Yeah. And I mean, I, I don't think my dad could play, you know,
anything on an N64, you know, like it, which isn't to say that's a life
skill, but that kind of stuff is transferable.
Being able to, I mean, I remember they got a, my parents got a TV a couple of
years ago that has like, it's like a smart TV with like, you can download
Netflix onto the TV rather than have a third party hardware that you plug into
it. And they couldn't figure out like, how do I select an open Netflix?
And so it was kind of an intuitive, it took a, like a mental switch for me to
like, Hey, look, you see that highlighted square on the screen, touch
the direction on the remote that you want that square to go in.
And that's the highlighted one.
But like, that's super intuitive to me because I've been doing that since I
was, I guess, basically shortly after I learned to walk.
And it's, it's not even just technical skills.
It's a lot of things you learn throughout life that I see younger people
making these mistakes now.
And I'm like, well, only one way to learn that way thing is to actually learn
it. I mean, for, okay, as a, as a non-specific example,
a few years ago, I was playing rock band and we were playing the song,
won't get fooled again by the who, right?
Which is a really fun song to play.
It's got a cool message, but it's basically about after Vietnam, they
wrote the song about we were fooled into a war under false pretenses.
It's not going to happen to us again.
And now I know what that song is about.
Okay, cool.
And what happens?
Iraq war comes around.
We get told there's WDMDs in there and we go into war again.
Like the exact same fucking scenario.
I was like, it, it, it happened again.
And I don't know, maybe.
So to be clear, I'm not pro-Iraq war, but that war made a lot more
sense than the Vietnam war.
I mean, because there were, there were actual pretenses of actual danger.
Well, there was actual pretenses of actual communist danger.
Well, that's the thing is there were going to be communists over there.
That was the scary danger.
Not that they have problems that could kill us.
In, in the modern day, yes, that's funny, but back in the sixties, the,
the rise of communism was actually a scary thing.
It was a scary thing.
I, and I, I guess I remember being flabbergasted when I learned that was
the reason for the, for the Vietnam war, whatever, in school.
And I was like, wait, it's the concerns that they were going to have bad
government, like over there, this small country.
Oh, well, there was a concern about it dominoing and taking over everything.
Yeah, I know.
Yeah.
Yeah.
All right.
So I guess that, that, at least my teacher didn't even make that point.
They were just like, yep, people didn't like communism.
I'm like, okay, but that seems like a weird reason to go in and, you know,
they palm the country, but okay, sixties, whatever, they were weird seventies,
whatever, but I mean, this shit just keeps happening.
And I can't help but feeling, this is one of the reasons death is bullshit.
You spent your entire fucking life learning all sorts of things about
yourself and how to work life and just how to live and be a good person.
And just all these skills you pick up to during life and you get to the end of it.
And then you die.
And the next generation has to start all the fuck over from nothing.
I'm like, just how much more advanced could we be if it wasn't for this death
bullshit, painting the reset button constantly?
We, we need to get rid of this.
Cause I'm sick and tired of seeing the same mistakes being made over and over.
And got every generation, people got to relearn how to read and do numbers and talk.
And yeah, it'd be kind of cool if that useless 15 year period in your life only
happened like once per, I mean, doesn't have an once per person, but only once per
whatever era, like, um,
and that you would have to keep learning the same political mistakes and everything.
Yeah, it's, I'm looking forward to seeing that experiment carry out.
Hopefully I get to see it happen.
Yeah, death, death is bad.
Oh, that's not familiar.
Oh yeah, death is bad.com.
That is bad blog.com.
Okay.
That is bad blog itself is taken.
Is that a good site?
It's a squatter site.
Ah, dicks.
Yeah.
Uh, there is one other nice thing about aging, at least for men.
Um, I'm assuming this doesn't apply for women, but, uh, the turns out that a lot
of women find men more attractive as they get older.
So like if you have trouble getting, getting laid in your teens and early 20s,
it's not necessarily that bad a thing because like looking distinguished is a
thing that a lot of people, a lot of female people are attracted to.
And probably, and probably some male people, but it depends if you age like
Ted Danson or if you age like Donald Trump, right?
Right.
So I mean, you got to take care of yourself and have probably baseline level
of attractiveness, but I mean Ted Danson's 70 and he's, I'm, I would bet $1,000
right now he's still polls.
Like there's, there's no way I got that exact quote in his fifties when he was
voted sexiest man alive.
Uh, but what you got the quote from?
It was a comedian that the work, the reason I use the word polls there,
because that's kind of, uh, you know, a, that's not a very nice way to say that.
He's still sexually active, but, um, I got that.
It was some comedians that's something like that.
But yeah, I mean, Ted Danson's dashing is all hell.
And I did, I blew my mind when I learned he was 70 years old.
So yeah.
But even for people who aren't like just naturally, huge good looks, the fact
that growing out of the boyishness and starting to look like you have some
resources and some maturity at your disposal can be attractive.
We'll see if I ever get there.
I still, I still look boyish.
Um, what was I going to say about, Oh aging.
Yeah.
So that's a perk for men.
Um, I, you know, some older women are attractive too.
I think, but unfortunately I think it does tend to skew one way, but that's
just society, whatever.
Um, I think it's at least in part evolution too.
Yeah, that's fair.
I, I, my understanding, having not gone through menopause myself is that the
process of, of being like currently going through menopause is kind of annoying.
But then you're done with having periods.
And I think you still get like all the bad effects from having the periods though.
Including the bleeding.
Well, except for the bleeding probably, but like everything else that you get
from periods that makes it awful is still comes back every month.
I thought all the, like half the awful stuff is related to the bleeding, like
the cramps and all that stuff.
And I think all that stuff keeps happening.
I thought the cramps are from shattering your uterine lining, which
causes, which is why you had, which why you bleed.
We need a woman here.
We do.
Well, we also need a woman who's gone through menopause or at least one
who knows about periods about this and ever talk to someone who's older.
Uh, man, this is how you, this is why you shouldn't have two dudes on a podcast.
At least not talking about menopause.
Right.
Yeah.
So yeah.
All right.
Let's move on to something we know something about like, uh,
actually was that everything that was the only two things that we had.
Oh yeah.
That was the only two things we had, uh, like the rest of this podcast.
Oh wait, is this being put in the end or the near the front?
This will be at the end.
This will be at the end.
Yeah.
Okay.
Uh, I think that was everything I had.
I think that's everything I had.
Um, I mean, there's a lot of topics I want to get around to discussing here at
some point, at some point we need to have a criminal justice episode because I
was just ranting about that before we started recording.
Yeah.
Um, and I can think of a couple of people who might be good, good resources for that.
So we've got UBI, criminal justice, uh, gender.
Uh, I really want to talk to Jess about the whole reach and thing that she's
seeing right now and she gets back.
So yeah, we got, we got a bunch of things on there.
There's those.
I also, we haven't had like a like futurism episode or like, I don't know if we
need a whole episode for anti-death, but that could be part of our transhumanism
episode, which we've never done exclusively.
Uh, we have, we did a transhumanist transhumanism episode.
I linked it in the show notes that just went up today.
Oh yeah.
Okay.
So we have done one 38 or 39.
And that was, that was ages ago.
It was time to do that one again.
Okay.
We need to have an EA person on to talk about EA, um, effective altruism.
And there's at least a couple others, but oh, I guess as part of futurism, maybe
separate something about, we've talked a little bit this episode, last episode about
like saving for retirement and how to do that in a way that, uh, is there a, in a
couple, and very quickly, is there like a, a position that's common in the
rationalist community on that?
Cause I don't think the rationalist community per se, but there's, I mean,
just very basic, easy advice.
Oh no.
I mean, I know what the general advice is, but I wasn't sure if rationalists
said like, no, no, it makes more sense to spend now because when we're 50, we'll
all be post DBI post singularity, all that stuff.
Oh, I was curious if there's any, any sort of belief leaning that way or something.
Uh, certainly nothing explicit that I know of.
Yeah, me either.
I think that sounds, I mean, individually, people can make that decision
for themselves if they think that things are that coming that quickly.
But, uh, that sounds a lot to me, like sell all your possessions and follow me
sort of thing that Jesus did.
And then it turned out the world didn't end in his lifetime, which is like,
though,
but at least the perk with this is that it's not give me all your possessions
or sell them.
It's like, go have fun.
Right.
Right.
Yeah.
And then you'll be destitute when you're 60.
Yeah.
Yeah.
Alrighty.
Well, uh, thank you for coming over and helping me get that off my chest.
Hey, absolutely.
And this is the real ending to the episode.
So thanks for, uh, your bonus little few minutes here and we'll see you guys
all again in a couple of weeks.
Okay.
Peace out.
Feels weird with that just here.
It feels like I'm waiting for just to show up, you know,
like, oh, that's right.
She's not coming.
