disillusion people from their beliefs if it makes them happy? And I was like, but like,
but like, what if, what if you need to know the truth so you can like fix something, you know,
like the delusion about like, it's a better example, I think, Steven, the thing you've talked
about before about suspecting you have cancer and then being like, that sucks to think about,
I'm just going to be like, nah, I don't, I don't think that there's a good example of this.
My wife and I got, or we went and donated blood last week. And she was sick, like a month ago,
more, I have no idea time is fuzzy now sometime, I think in October, for like a couple of days.
And because she works around people in the medical industry that have COVID all the time,
there was a very reasonable guess that that's what it was, even though presented, like,
non typically. So she thought, Hey, maybe I had it. And I was like, well, that, you know,
that'd be awesome if you had it, then you've got the antibodies and you don't have to worry about
anymore. How fucking awesome would that be? And so like, we could have just operated under that
nice, happy thought, right? Instead, what you can do when you donate blood in today's day and age
is you can ask them, or you can go to the whatever web portal when they upload your results,
give you your blood type, which she also didn't know we have the same blood type, which is cool.
But she also doesn't have COVID antibodies. And so like, that sucks. And yet, that we're already
living in a world where she didn't have them. Now we just know that and we're actually better off,
right? So it's, it is, it's a bummer to be disenfranchised. If there's something you can do
about it, you know, if you're going to go for the hyper constrained deathbed thing, where they've
got 30 minutes left, are you going to try and talk about it every religion? I probably wouldn't
know. I would have also agreed with that. But at the time that was when I was like,
in the new atheism, I went through the exact same phase. Yeah, I moved away from that when
realizing that, yeah, okay, we're going to paint it that constrained. Sure. They've got five years
left. And getting them, you know, persuading them to sign it for chronic is a real option.
I would actually think of worthwhile. If they're like, no, I'm going to go to heaven, it'll be
fine. It's like, yeah, but what if you're not like, if there's time to have that conversation and
have it go anywhere, I think that'd be valuable. But if there's literally not, then forget it,
right? Well, can you just come out to her without trying to, you know, can
de-convert her? Like the thought experiment or what I don't know if it was a thought experiment,
but like, it was just about the teacher, like telling her grandmother, actually, I'm, I've
like, de-converted I'm an atheist. I don't think I'd bum my dying relative out in the last 30
minutes. I would just steer the conversation. But like, the thing that I said, the last half
hour of your life, yeah, I still don't know. I feel about this where like, because that gets
into the subject we had about lying, which is sort of getting off topic of the thing. But like,
it's like, I sort of feel like I would prefer if this person is close to you, that they like,
know like, true facts about who you are and what's going on with you.
Right. I was going to say, if this is a grandma that you see, you know, for 30 minutes once a year
at a holiday, then whatever. But like, if this is something you track with a lot, you've got to be
in the closet constantly around them. And that's a huge stress. And it's basically lying to them.
I just, I don't like being in the closet in general about things, especially if it's something
that might, you know, come up and be important in some way.
Yeah. Another thing I sort of realized is that like, I guess, I was like, I'm carrying around
distress about not being out as trans to my parents. And I didn't really think about it that way,
though. But like, when I did, I realized I felt this like, massive amount of relief. And then
they felt distressed. And it's kind of like, so you transfer the distress from you to them.
And now it's their thing to deal with. And that's kind of how it should be, I think.
And that's the only way you can kind of get rid of that stress or tension. Because like,
each person has to work their way through it. And that's one of those like, Hey,
it is how it is deal with it. I guess, I don't know. I mean, like, this is going on,
kind of out into left field. I just wanted to find out that there was two footnotes
in this. And I'm trying to scroll back up. Okay, the one that was after he's talking about,
yeah, imagine a billion worlds, Everett branches, tag mark duplicates, this thought process won't
systematically correlate optimists to branches in which no nuclear war occurs. There's a footnote
if you scroll down to the bottom, some clever fellows bound to say, Ah, but since I have hope,
I'll work a little harder at my job, pump up the global economy and thus help to prevent
countries from sliding into the angry and hopeless state where nuclear war is a possibility.
So the two events are related after all. At this point, we have to drag in Bayes theorem and measure
the relationship quantitatively. Your optimistic nature cannot have that large of an effect on
the world. It cannot of itself decrease the probability of nuclear war by 20%. Or however
much your optimistic nature shifted your beliefs, shifting your beliefs by a large amount due to
an event that only slightly increases your chances of being right will still mess up your mapping.
Which I think takes us nicely into the next post. Yeah. Yeah. What's fun about it, and this
kind of leads us into the next post is I remember a few months ago, I was talking with somebody who
kind of denied that it was possible to have like a Bayesian prior that wasn't given to you as like
a six-sided die. You're odds of getting one or one in six, like it was anything more complicated
than that. They're like, you're just making it up. And it doesn't mean anything. And yet, like,
yes, you're making it up. And yet it would just take the example of nuclear war. I don't know what
the odds of nuclear war on the next 20 years. I don't even have a guess. And yet there are things
that could make my estimate of it go up. Right. And we've got a month left of Trump. If he starts
talking about how big his red button is again, like he did when he first got into office, and
I don't know, metaphorically waving his dick around. I don't know what my odds are, but my
odds would go up, right? Do you think your odds are gone up or down now that the Israelis, allegedly
the Israelis, assassinated that Iranian nuclear scientist guy? Because like on the one hand,
it's going to be harder for Iran to get nukes. But on the other hand, this could lead to war,
which could possibly spiral into more things, you know, more powers getting drawn into conflict,
which could lead to nukes being exchanged. I would ask the wisdom of crowds. Has anybody
betting on this on one of the big prediction market? Who's betting on there being a nuclear war
in the next 20 years? Like, what do you expect to make money on that? I think that's one of those,
like, you win. You get to say, I was right. And then you get incinerated. Yeah. I don't even know
if I would trust the wisdom of crowds on that. I would be more interested in people who know a
lot about the political situation. Yeah, no, there's there's a whole thing where people
can outperform experts after certain critical masses reached.
Did we talk about that in this show? Because I feel like we did. Probably. That's
or maybe we talked about it in discord or something. Yeah, I believe we may have done it
during our episode on metaculous. Is that the name of the website? Yeah, I thought this was
recently because there was just a few months ago an episode of Skeptoid about wisdom of crowds.
Okay, sorry for anyone who's curious to that, which is a lot of fun. And it's 12 minutes.
I mean, I like I like the betting markets because the people who think they have more information
will bet more money. So they will be given more weight. And also the people who are really wrong
with their estimates eventually go broke and leave the markets. But if it was just like everybody
betting, I kind of feel the noise. I know the the idea is that the noise is random in all direction
so cancels itself out. But I'm not sure how how likely that actually is in practice. I think
there is systematic bias to some things. Totally. As far as this goes, I have no idea. I don't know
anything about the politics over there to the to the granular level to know whether or not this
will likely increase the increase the chance of war. My naive guess is that the less people who
know how to make nukes, the less likely nuclear war is. But that's probably too simplistic, because
you know, they could be pissed off enough to steal or buy a nuke. Right. That said, I don't know,
I'm not losing sleep over it. So also I didn't hear about it. Maybe that's why I'm losing sleep
over it. Oh, okay. Yeah, just happened yesterday. Oh, I think it was yesterday. Could have been the
day before. Something else happened yesterday that I heard about again today. Oh, Governor
Polis has COVID. Sorry. It's a bummer. And it's it's one of those things like
the mayor of Denver, flying out to celebrate Thanksgiving. That really, really irritates me.
You're supposed to as as a leader, like set an example and show that you're willing to make
sacrifices as a leader as well. He was the one telling everybody stay over Thanksgiving. Yeah.
Yeah. And then he flies out later. Fuck you, dude. It doesn't apply to me. Really hope he gets COVID.
So there's like, I was talking to this with the people last week about like not getting your
haircut as like kind of a signal of I'm very pro science and liberal and care about COVID and stuff.
And it definitely is a signal of that, assuming you were getting haircuts before, right? Right.
Right. Like, but it's not to say it's merely a signal. Like everything that's the thing is,
you know, if you say, oh, that's signaling, people assume that you just mean like that's just a
signal. But like, I was thinking and I didn't put it this way to the people I was talking with
because I was time constrained and I didn't think of it this way. But like, there's no way that like,
what's his name, Seth Meyer or Stephen Colbert can't safely get a haircut right now. Right.
Yeah. I mean, it's where we're most of a year into this. And I'm pretty sure if they wanted to,
they could carefully get a haircut. Oh, have they been growing their hair? Yeah. Oh, okay.
And so because it's a nice, it's a nice signal of like, I'm very careful. And like that said,
that's good. We need those people. It's just like, this, I don't know why that came to my mind
because we're, oh, we were talking about Governor Polis and stuff. Anyway, updating on priors is
kind of the next information or the next post here. And so how much evidence does it take? And it
runs through a, the chief example it uses is a lottery example, where the odds of winning are,
watch me fuck this up. One in 131 million, 115,985. I did it. So I'm not going to say that every
time because I think that number is used maybe 15 times in this post. Why? Because you said in
the podcast, they read it out the entire, in this entirety every time. Yeah. Just to say the big
number when it comes out. I mean, I would probably read it out the first time. But after that,
you could just shorten it to one in 131 million. But that's not the math gets much more granular
than that. In any case, the gist is like, so if I buy a ticket, what are the odds of me winning?
It's one in one hundred something million, right? But so how much information would I need to know
that I've got a winning ticket here? And so it gives, I don't know, this is one of the ones where
I wouldn't praise it for like word count to information delivery. It makes an important
point though, it just does it in a way that I think because you've got to use a mathematician
that he really appreciates that I showing his work in this one, which I think there's a like
nice ratio, I guess, in the sequences of, well, yeah, most of them, I think do tend towards the
like layperson friendly, brief, intuitive format. There's a few where he does start
throwing math at you. I think those are good to have in there too, because it's, you know,
the whole I'd like out here, like here's the thing I'm trying to say. And then here's the proof,
I guess. Right. And that's valuable to have. So it's not just all, you know, air, right?
But I like it kind of sums up at the end here. It says, in general, the rules for weighing how
much evidence it takes, follow a similar pattern, the larger the space of possibilities in which
the hypothesis lies, or the more unlikely the hypothesis seems a priori compared to its neighbors,
the more confident you wish to be, or the more confident you wish to be, the more evidence you
need. And like, simplistically, big claims require lots of evidence.
Or to win the lottery, you'd need evidence selective enough to visibly favor one combination
over the big number alternatives. Right. And so, like, of course, you can still
believe in it on inadequate evidence, if that's your whim, but you'll not be able to believe
accurately. As I try to drive your car without fuel, because you don't believe in the funny,
dirty concept that it ought to take fuel to go places. Wouldn't it be so much more fun and so
much less expensive if we just decided to repeal the law that cars need to fuel? Well,
you can try. You can even shut your eyes and pretend the car is moving,
but to really arrive at accurate beliefs requires evidence to fuel. And the further you want to
go, the more fuel you need. Yeah. That's my kind of analogy. Yeah. I was always more a fan of the
one where it's like, I don't know, people that talk about sort of having, what is that word,
like post postmodern people that are just like, well, you know, we can't really know anything.
Oh, my God. I like, okay. Um, I mean, like,
are you thinking, um, postmodernism in general or solipsism specifically?
Um, I'm not exactly sure what the distinction. But solipsism is the, uh, belief that actually
you cannot prove anything except for the fact that you are conscious. Like literally everything
else could be a dream or you could be a matrix. There might not be other people. Everyone else
may be zombies that say that they, you know, have thoughts, but they don't really, it's
like solipsism is just the complete denial of reality. And I just refuse to have conversations
with people like that because there's, there's literally nothing you can say to someone like
that. Yeah. Well, I was going to say you could go jump off a cliff and I guarantee that gravity
will do its thing every time. I mean, they will certainly think that they have fallen and broken
their legs and or died, but the point being the people who like, you know, you're still,
you're still walking around like making choices based on evidence. Yeah. Because like,
that's, yeah, that's the thing that really annoys me about them. That's how life works. It's like,
you don't, you don't go to the store just by closing your eyes and wishing you take the route
that you took, you know, similar to the one you took last time or whatever you have to make a
detour. But the point is, you know where the store is, you know where your house is, you take
turns in such a way that will reliably get you there. You don't just like, you know, roll a
diet or, you know, flip coin at every every intersection because it doesn't matter which
way you go. Like their entire lives operate on logic and consistency of reality. And then for
certain things, usually religious exceptions, they pretend like, oh, no, I don't actually run that
way. It's like, you definitely, definitely do. Yeah. But like, you only get to be like, woo,
woo about the things that you can't prove with evidence. Right. Like that I kind of like that,
uh, uh, they're getting off topic again. But I was just going to like talk about how the world
that like religion gets to encompasses shrinking, like more and more, the more that we learn via
science. Yeah. Um, anyway, so what's there more about more in here? I think that was basically
it. You definitely need very long fuel to arrive at accurate beliefs. Yeah. Uh, I guess it's not
this one too, but I was scrolling to the bottom to see I remember there was when I was like first,
I had, um, gotten into methods of rationality and then I started reading the sequences, just
like the ones that sort of linked to it or correlated. But I remember one, it apparently wasn't
this post, but like they were talking about, uh, Bayesian probability and making predictions based
on it and somebody in the comments or like someone that was like, well, where are you getting your
priors? And he's like, well, they sold them at Kmart or something like that. Just remember that,
like for some reason that cracked me up and stuck in my head, like for a while. And I don't know
where I read that. All right. Are we done with the, the sequences then? Yes. I was just trying to
find, uh, you mentioned something about the shrinking skill of what like people get from their
religion slash Bible. There was a thread yesterday on Ask Reddit. What is your favorite sex scene in
the Bible? And, uh, someone, I just liked how like they get into describing what this was and
someone just put like in that kind of, uh, I think they call it, um, sponge casing where it goes up
and down. Okay. And it's like Judeo Christian values. And it's, uh, and it sounds like it's
being mean, but it was talking about, uh, well, it's, it's a, it was the top response on that thread
and you're welcome to Google it. But, uh, well, all right. What was your favorite sex scene in the
Bible? That one where the two sisters get their dad drunk, their mother is still salty about it.
Oh, I just got the, because it's Lot's wife. Yeah. God damn it.
I like, I like those things that they, that like the bad movie summaries are the same kind of thing
where, yeah, it subverts the way you remember the story, but, uh, it's accurate. Yeah. There was
that one, what was Lord of the Rings, like two short people go through a piece of jewelry into,
like, into a volcano or something. I liked, uh, my favorite one was the, the, I think this may have
been the first one that kicked it off, the Wizard of Oz one. Um, uh, girl arrives in a strange land,
