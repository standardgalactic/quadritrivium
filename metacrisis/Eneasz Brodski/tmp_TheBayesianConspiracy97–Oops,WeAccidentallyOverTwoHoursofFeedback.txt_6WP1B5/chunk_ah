especially where they required the Belnaut report and the Helsinki Declaration.
They're basically requiring that you need to give informed consent before you are allowed to
enroll somebody in medical experiments. But apparently back in the day, it was just like,
oh, your kid eyes leukemia, I'm a doctor, I'll take it from here, and then you could just do
whatever the hell you wanted because you're the doctor, and nobody, the kid, the parent,
had to sign off on any of it. So yeah, they were doing some pretty horrifying things to try to treat
cancer. On the other hand, your kid was probably going to die if had a leukemia anyway. Like before
the 60s, if your kid got leukemia, it was a death sentence. Yeah, yeah. But yeah, you're right,
the informed consent thing is really important. It certainly is. Was there anything particularly
horrifying you remember that they did? Well, I mean, a lot of it was just experimenting with
early chemotherapy. And it took them a while to find the ones that were, because like cancer is
not like a virus where it's something, we can identify this as being not the host and create
drugs that are targeted to destroy it. Cancer is the host, it's still your own cells, they're just
mutated. So you have to find something that will selectively kill cancer cells. We're just getting
to that point. That's actually what like one of the things I'm working on is CAR-T. But chemotherapy
is indiscriminate, it just wreaks havoc. And so like you'll get like these five chemotherapy
drug regimens that you'll try. So like we've still got this, we got like a R chop, which is like
rituximab and a bunch of other drugs with long names that are really, really poisonous. And like
back in the day, they were just kind of like, Hey, let's throw these six drugs together and
put them in this kid and see if they survive. I knew I recognized Siddhartha Mukherjee's name.
They were on episode 98 of Sam Harris's podcast, Into the Darkland was the name of the episode.
What were they talking about? Was this the one where antibiotics might fail?
No, that was another one. That was more recent. I just knew I'd heard this name before and it
was driving me crazy. That's why I did my victory thing, because I couldn't get the search thing
on my podcast app to work, so I had to Google it twice. Cool. Yeah, I want to check out more of
their books because this one's, I'm enjoying it a lot. Cool. And then like the last recommendation,
I forgot if I've brought this up before either, but I know other people in the nationalist community
have been doing this. I got a PlayStation VR and I've been using Beat Saber as my solo exercise
routine. And it's very good for people who like video games or have a competitive streak. I was
having the hardest time trying to establish any kind of regular exercise routine after I moved and
all kinds of things shifted around. So I think that there's other benefits to playing Beat Saber
too aside from it being good exercise in that you can watch yourself get better at something
really quickly. I think it's structured in such a way that especially if you play through the
campaigns and they like go through the various difficulty levels that you can actually like
see yourself in real time learning and getting better at something. And it's really good like
motivational boost if you're struggling with other things in your life. Fine, I'll come play
this. This sounds awesome. Please come play it. It's fun. I'd like to be happy about introducing
people to watch me sitting there with a headset on ignoring you playing a game, but it's actually
pretty fun to watch too. Cool. Um, yeah, that's all I got. We should probably move on to sequences.
Alrighty. Does anybody else had anything to
this? If anyone else has anything else, wrangle them.
Focus your uncertainties. Our first one. I was gonna, you're already beat me to my joke. I'm
like, Oh, I got something to recommend. Focus your uncertainty from lesser on.
So yeah, how do we want to do this? Should I jump in or what? Yeah, you're already there. Okay.
Focus your uncertainty is the first lesson post we're reading this time. It starts out with
Eliezer proposing a hypothetical scenario where someone is asking you will bond yields go up
or down or remain the same. If you're a TV pundit and your job is to explain the outcome after
the fact, then there's no reason to worry, which is first of all, great dig on TV pundits. Like
they just make up whatever after the fact, right? But he goes on to say, suppose you're a novice
TV pundit and you aren't experienced enough to just make up explanations on the spot,
you need to prayer prepare remarks in advance for tomorrow's broadcast and you have limited time
to prepare. You only got 100 minutes to come up with excuses. You can spend the entire 100 minutes
on up and also spend the entire 100 minutes on down and also spend the 100 minutes on stay the
same. You got to prioritize somehow. You don't want to spend 33 precious minutes on excuse.
You don't anticipate needing in your uncertain state of mind. It seems that you anticipate the
three events differently that you expect to need some excuses more than others. And this is the
fascinating part. When you think of something that makes it seem more likely that bond prices will go
up, you feel less likely to need an excuse for bond prices going down or remaining the same.
It even seems like there's a relation between how much you anticipate each of the three outcomes
and how much time you want to spend preparing each excuse. Of course, the relation can't actually
be quantified. You have 100 minutes to prepare your speech, but there isn't 100 of anything to
divide up in this anticipation business. And so, I just thought that was a absolutely wonderful way
of illustrating the idea of what a probability distribution feels like inside your brain.
Yeah. Basically, this post is, Ellie, as you're making the case for why you should apply math
and other thinking skills that you should have learned in school to real life.
And I like how it's, for some reason, making me think of, I've been digging back into the
Getting Things Done GTD method again. And David Allen proposes natural planning. And it really
it's a systematized way that you can create steps for a project that is based on the way
your brain naturally thinks about stuff. And I like how this is kind of the natural planning
version of how you come to have probability distributions in your head. Because I guess
maybe the thing that's the similarity between the two of them is maybe people might come at
planning a project or trying to develop a probability distribution with some trepidation.
Oh, that sounds hard. That sounds like that's something that requires a lot of study or
knowing higher level math. But actually, it's just like, no, this is the thing you're doing all
the time. You're doing this naturally like behind the scenes. And you just don't realize it.
And I like that framing of the minutes that you have to spend because a lot of times people are
like, well, I don't know how the hell to put like a 10% probability on something versus 90%
of something else. I just think like, this is really unlikely. And this is very likely. But
once you put it in terms like, okay, you have 100 minutes to
prepare for these scenarios, how much time are you going to spend on each one? That really helps
someone get the feeling for what their probability feels like.
Yeah. And the novice pundit like having to justify the expenditure of their time and resources
and deciding to go with the one that's more likely. It's explaining how you can think of
intuition as this conserved resource like money. There's a limited supply and you have to decide
where to allocate it. And that makes total sense if you think about it in the metaphor.
Totally. And I liked the ending remark as well, which was, if only there was an art of focusing
your uncertainty, squeezing as much anticipation as possible into whichever outcome will actually
happen. But what would you call an art like that? And what would the rules be?
Yeah, that's perfect. Yeah. That would have been, I get why that wasn't the first post on the blog,
but it's, it almost feels like it should be. Yeah. I wonder, I haven't read AI to zombies.
I wonder if it's one of the earliest ones in that. I don't think it is. I have no idea.
This might be a good introductory post for someone that wants to get into,
well, at least learning about like Bayesian rationality, but if they want to, you know,
learn about the sequences and read kind of all that I have to say about that one.
Good way of visualizing what uncertainty feels like.
Mm-hmm.
The next one is the proper use of doubt.
Yeah, I can take this one if you want. Excellent.
Eliezer says that organized belief systems seem like they flee from doubt. So, doubting or skepticism
seems like it's scary or not allowed or unvertuous to people.
A friend replied after he says this that Jesuits are supposed to doubt.
And at the time, Eliezer wasn't able to confirm or deny whether this was true. And I'm actually
not sure if that's true either. I intended to look it up and forgot. But yeah, this friend was
basically like, oh no, like, organized belief systems love doubt. We're encouraged to doubt
ourselves all the time. And so Eliezer thought Jesuits wouldn't be properly described as fleeing
from doubt or they'd be rationalists. They claim that they're, or the claim that they're really
doubting it all seems suspicious to him. What his friend described sounded more like
a desensitization program for phobia, like exposure therapy. If you're afraid of spiders,
like slowly introducing you to a photo of a spider, or like here's a tarantula in a box,
and you can just like gently touch it and it's tame.
Like first doubt for a little while that God exists, and then at the end of the class,
it's okay kids, God does exist.
Yeah, so he was thinking rationalists should be comfortable with doubt.
Whereas this, like they're making doubt sound like a phobia here. So he likens
doubt to the idea that by unweaving the rainbow, you ruin the grand mystery, like the,
the, um,
Keats poem.
Yeah. But like the unweaving the rainbow was also one of Richard Dawkins books about atheism,
or generally like, not even about atheism about this whole idea.
World view of science, the whole, the thesis of that book in my one sentence summary would be
that Newton didn't destroy the rainbow by explaining how it worked. He made the universe
that much cooler, and that was more beautiful, and that all of science does that. It doesn't
take anything away other than your, your fantasy of how things, you thought they were.
Yeah, or you're like, ooh, what a cool mystery tingles.
Yeah. But then you get the, oh my God, what a cool phenomenon, which get you off way more.
Yeah. And I like, I don't know, I always thought that.
And either one phenomenon tends to be even more, uh, cool than like the whole mystery vibe that
you had before.
Yeah, everything's so much more complicated.
In, in the right framing, way more fun than just imagining Thor up there throwing a temperature.
Now that would be cool, but, um, you know, it's
earthquakes, how that actually happens on something the size of the, of a planet
is really interesting. If you just thought, oh, it's because gay people are having sex. It's like,
like, I, I don't see how that's nearly as satisfying as an explanation.
Or even if you just don't know the, that feeling of mystery is still like,
it's not as good as like actually learning it and seeing how complicated it is and how
all these different forces go into what you end up seeing in the world.
Yeah. I feel like learning something just gives you more questions. Like, well, how does,
how does the rainbow work? Light is a spectrum of these seven colors. Well, how does that work?
And like, you start talking about wavelengths and then what is light and it's a wave and a
particle and you're just like, the mysteries just keep going all the way down. And so like,
you're actually just stopping yourselves from having more cool mystery tingles.
Anyway, yeah, if you want understanding tingles and mis-routingles, science is the way to go.
Meanwhile, uh, the act of solving that mystery,
Eliezer thinks that's the virtue of rationality. And I pulled a quote out,
I doubt that neither destroys itself nor destroys its target might as well have never existed at
all. Oh, can I read the few sentences just before that? Oh, sure. So I pulled that little longer
quote, all curiosity seeks to annihilate itself. There's no curiosity that does not want an answer.
But if you obtain an answer, if you satisfy your curiosity, then the glorious mystery will no
longer be mysterious. In the same way, every doubt exists in order to annihilate some particular
belief. If a doubt fails to destroy its target, the doubt has died unfulfilled. But that is still
a resolution and ending, albeit a sadder one, which I think is also an interesting commentary on
his personality that he thinks it's sadder for a doubt to, um, annihilate itself rather than the
belief. Like either one is interesting information and some people would be like more relieved that
the doubt was, you know, false. Yeah, I mean, if you think about the book methods of rationality,
like, it's kind of like the character gets really excited when they find a new mystery,
something they don't know or something that challenges them. So I do kind of see that as a
virtue. But yeah, then he says a doubt that neither destroys itself or destroys its target might as
well never existed. I think it's maybe he says it's sadder because you didn't learn anything
new if the doubt destroys itself. But yeah, you're just confirming things. Yeah. Yeah. He says it's
the resolution of doubts, not the mere act of doubting that drives the ratchet of rationality
forward. Yeah, and then he goes on to say that not all doubts are rational. Wearing it, this is
another quote, wearing doubts doesn't make you a rationalist anymore than wearing a white medical
lab coat makes you a doctor. And I agree with that. It reminds me of people who
doubt stuff with scientific evidence like anti-vaxxers, trying to argue that their opponents
aren't open minded, or science is a dogma, where yeah. And that's that sounds like anticipating
that sort of weaponized doubt where it's like, oh, I'm just being a good virtuous doubter,
skeptic by not by not buying into all this vaccine business. The doubt should either
annihilate itself or annihilate the the belief that it was aimed at. And it could be applied
both ways. All right, so let's look at let's doubt the the anti-vaxx position and see what you get
there. And if you're, oh, I don't want to look into that. Or, you know, if you're if you have a
reflex to shy away from that, then that's not the proper use of that. That is the exact opposite
of what you should be doing. He says a doubt should point to the way to destroy the doubt.
So pointing out kind of the idea that untestable hypotheses are pretty worthless. That's why I
like bust on string theory. But if you are going to put forth a hypothesis,
it should be something that's testable. There's not really much point to sitting there and being
like, well, what if there's an invisible fairy that causes milk to turn into cheese? And I don't
know, like just start coming up with this whole history behind like other than like maybe making
some entertaining fiction. This isn't really a useful productive use of your time or brain power.
He says, here's a quote, that you need a particular reason to doubt. An unresolved doubt is a null
op. Yeah. And then this ends with, if you don't really doubt something, why would you pretend that
you do? Because Jesuits want to pretend there's virtuous as scientists, or they're doing this
modesty signaling thing by going, but I doubt my religion. So I'm as good as you. But this is not
real doubting. It's, I think he said, maintaining the tribal status hierarchy, instead of actually
having a real doubt seeking to annihilate a belief. I did have an interesting conflict while reading
this. Do you guys think this, this all doubt seek to annihilate themselves conflicts with the previous
post at all? Because like isn't, isn't holding a probability distribution in your head kind of
the same thing as, as being kind of doubtful? I think that it's kind of using probabilities.
Because like you can't always test every hypothesis. Or you can gather more evidence
in support of it. But most things don't come in a black and white, like, okay, we're gonna
do this experiment. And then like, this is definitely going to prove it. So that's just like
a tool that you can use to kind of bring your doubt into higher resolution. I don't think that this is.
I think I get what you're saying that you can use doubts to alter what your probabilities of
things are. Yeah, or like, I think it's a more sophisticated, like, first you have to be able to
know what is worthwhile of doubting and why and then like what the purpose of a doubt is. And then
once you start developing the skills to think about these things in terms that are,
this is really hard to explain. If I might just jumpstart my thought on it.
Yeah, go ahead. No, I was just like, struggling. I think I think that the key stepping stone is
to think of things in probability distributions rather than in, I believe this is true or false.
So if you like, if you're 80% confident that bond yields would go up, you'd spend 80% of your
