Yeah. That's probably all we need to say about that.
Yep. Moving on to...
Error of crowds.
The error of crowds. So this one is a direct response to The Wisdom of Crowds,
which is a really fascinating book. Have you guys read it before?
Or do you know about it, I guess?
I know about it.
I haven't read it either.
Yeah.
Basically, it gives a whole bunch of examples about places where everyone was trying to figure
out something or guess something, and every single person was individually wrong,
some more than others. But when you averaged all of their guesses, I guess,
for lack of a better word together, the average was startlingly close.
Like, in a surprising way, in one case, they asked a whole bunch of people who were...
Not experts in the subject, but who had some knowledge in the subject about where a...
I believe it was a Russian sub went down, because no one really knows where it went,
but they know where there was last contact with it and what the secrets were,
and there have been some efforts to find it before, and everyone was off by quite a bit.
But the surprising thing is, if you averaged what everybody said, the actual location was
really close to that average guess, whereas everyone individually was off quite a bit.
And the idea, the explanation was that, most likely, everyone had some little piece of data
and a whole bunch of noise that they thought but were wrong about.
And when you took everybody's guesses, everything that they were right about,
all kind of pointed in the side direction, everything that they were wrong about,
kind of pointed randomly, and all canceled each other out in the wash,
so you just sort of get the useful information left in the end.
This sounds like a very humbling and inspiring message that we should be more modest and just
taking everyone's opinions and then amalgamate on the truth. Is that the way I should take this,
That is exactly how you should take it, Steven.
At the very top of the post, he links back to an old, overcoming bias post where the author says,
I've kind of decided that I'm just going to take the average human population position on
everything because I'm pretty sure I cannot do better than the average of everyone.
Therefore, God is real.
You know, right? And if he was around a few hundred years ago, therefore, slavery is okay,
et cetera, et cetera. Yeah, which, on the one hand, kind of strikes you as dumb,
but on the other hand, if you take this logic far enough, it's like hard to argue with him.
We've got a sign on the, it's kind of a long little thing. It's on this cool scroll thing that
my fiance got, and we put by the front door of our home. It's a long quote, but the end thing is,
and it uses the word crazy in a way that today wouldn't be acceptable, but it's an old quote.
And it's like the crazy ones are the ones who are willing to go out on a limb, and they're the
only ones that make change and make progress. And this modesty argument here sounds like a great
argument against that. Coprenacrisis crazy sort of thing, right?
It looks like you were trying to say something too.
Actually, like I just lost my train of thought because I was thinking about that.
I got sidetracked thinking about the sign being like crazy people are the ones who make
change. And you were saying that that was not a accepted use of that word. But like,
I feel like the people who are the people that make change tend to be like non-neurotypical.
So like, in a way, it's still kind of correct.
There was a guy who wrote a book, and he was on Julia Gillis podcast. It wasn't about this
controversy. It was about the actual content of the book, which I can't remember the actual name
of, which tells something about it. The original name was how to think like a crazy philosopher.
And there was enough pushback against that's ableist language and that's that's putting down
people with mental illness and stuff. And I think it's very clear from like the message of like,
you know, how to think a crazy philosopher, like, I get exactly what you're trying to say.
And I feel like no one can say in good faith that they didn't get what he was saying. It was just
whatever Twitter mob, not to say that there's not a mean way to use the word crazy, but that's
not what I'm doing. Yeah, that's not using it as a pejorative. I don't think so either. If anything,
it was like, you want to think like crazy philosopher, not like you want to have manic
depression, right? So anyway, yeah, that's what I was getting at with the crazy on there being
not necessarily something everyone would be on board with. It's interesting the words that
become taboo over time. Yeah. Yeah. And in 10 years, somebody will be Twitter mod for using the
word crazy in a tweet in 2019, right? So I don't think it'll take 10 years. I'm pretty sure it'll
be next year. Anyway, in the area of crowds, Yuckowski talks about prediction diversity,
which is the squared error of the collective predicting, equaling the average squared error
minus the predictive diversity, meaning the more diversity in a group, the smaller the error of
the crowd. Then he asks, why should the bias variance decomposition be relevant to modesty?
Because it seems to show the error of averaging all the estimates together is lower than the
typical error of the individual estimate. But then he goes to say that you shouldn't be more
modest and compromise a little based on this, because predictive bias assumes that actors
aren't predicting like Bayseans. A quote, as Einstein put it, insofar as the expressions of
mathematics refer to reality, they're not certain. And insofar as they are certain, they don't refer
to reality. You've got to do it in a really offensive German accent. Oh, no, that's fine.
Do you want to do that? I don't want to do it. No. Whenever I hear, whenever I do, I say, I hear it
kind of in his voice or like the way that I've heard his voice portrayed. Anyway, the real
modesty argument, Oman's agreement theorem, or Alman has preconditions. AET depends on agents
computing their beliefs in a particular way. AET's conclusions can be false in any particular case,
if the agents don't reason as Bayseans. And then he goes to this example about the students
and the math problem. Somebody else want to go? Sure. So he uses a lot of math here. And I kind
of stopped following it. And I found that the for the last this week and last week, it's really been
useful for me to read the post, then put it aside and just do something else for an hour or two,
and then come back and read it again. And it seems to have like filtered in or something,
or maybe I got the past the initial intimidation of the math. But when I came back and read it a
second time, it worked better for me. Yeah, that's how like you solve hard math problems. A lot of
it is actually done in a what was there's there's a terminology for this, and I'm not having a good
brain day subconscious. Yeah, basically, the subconscious. There was I called it shower thoughts.
I guess. Oh, it's a diffuse mode. Okay, there's like focused mode and diffuse mode. And apparently,
you kind of like process stuff with the front of your brain. I'm not even sure if it's actually
like the front of the prefrontal cortex or whatever. But like, there's a part of your brain
that's like focused on like, concentrating on something and working on it. And it gets tired
quickly. But then there's like this background part of your brain that is able to work on things
and chew on them for much longer. I had been banging my head on a programming problem this
afternoon for like an hour. And finally, like, all right, finally, I'm gonna get up and get it
get some water and take a break. Less than five minutes. I'm like, wait, I should try this and
I got it fixed. Nice. Is that kind of thing? Yeah, that kind of thing happens all the time. It's like
how your brain works. Just give it a chance to get away from that stuff. That's why you have ideas
and inspiration through dreams sometimes to kind of dreams are weird, actually. But I see what
certainly moves to good night's sleep. And then you come back to it on a fresh brain,
but one that you didn't know was exercising all night in weird ways. And then boom, thoughts.
So what I got out of this after I got past all the math was that Eliezer really dislikes this whole
wisdom of the crowds thing and thinks that, well, he said in the previous post that he suspects
these might be cherry picked examples. And this isn't as useful as they were claiming in the book.
But he uses math to reduce this to an abductio ad absurdum, which I think wasn't really needed.
Because in the very top of the post, he linked to that guy who said, I'm going to take the average
of all human opinions on everything in all seriousness. And Steven and me were both like,
aha, well, that shows how ridiculous this is. That was our reductio right there. We didn't
need all the math. But he goes and he posits this. I think he's proving his case with numbers.
Exactly. He went and posits this case where it's a very specific case with a math problem and a
classroom. And the math problem has like a gotcha in it. So all the students will get the wrong
answer, but they'll all get it in one direction. But they don't know which direction it's in.
And the score that the teacher will give them is based on the square root of their error,
which means that what all this piled on top of each other means that if the students have the
option to either talk with each other about the problem and try to figure things out,
and get a better answer, or to plug their ears while everyone else is talking so that they
can't hear anything and just go with a random answer such as their own, that they're better off
plugging their ears. Because in all the other examples given, once everyone pooled everything,
pooled their data, pooled their guesses, they came up with something better. In this case,
if they all did that, they would come up with something worse since the score was based on
square root of the difference. Anyway, it's a bunch of complicated math stuff. But Eliezer's
reductio here is that here is a specific situation where increasing your knowledge of something
will also make you worse off. So the best thing you can do is not get more knowledge and go with
the dumber answer that you had. And I see how he did that with math. And I can see how if you've
proven that in one case, this is absolutely absurd, you have just proven that this is not a rule
that always holds, but I didn't really need that. And it was such a fringe edge case that it also
really didn't do much for me. I think it's much more compelling to people who are high into math
and would understand this on a more intuitive level, why it's so breaky. Whereas for me,
just that top blog post was more impactful than obviously it was for Eliezer.
Yeah, I'm not super mathy, but I actually wasn't really convinced until I got to the math problem
part. Oh, really? I think then that's why he put it in there. I think you're more mathy than you
give yourself credit for. If it landed for you, that's the way it was intended. Maybe he wasn't
just flexing his math. I actually summarized this article as Yuckowski's annoyed by some commonly
held notions of prediction diversity and decides to destroy it with math. At the end, he does point
out that he thinks the students should actually talk to each other, but then goes on to say that
that says something more positive about the value of conversation and not about averaging answers.
I think it just annoys him that this idea of, oh, well, we should always average answers.
That's not how you would solve a math problem. That's not how you should solve problems
of reality either, because you might come across one of these kinds of cases where there is some
kind of gotcha in reality. The evidence does all lean in a weird direction for some reason.
You want to actually be calibrating as best as you can and not just going off of your
realistic, like, well, if we just average everybody's answers, then it seems to do good.
He's spent a number of posts now kind of laying the groundwork for
sometimes the massive people are wrong and you have to be revolutionary and think in weird ways.
Yeah, and that's going to be kind of a recurring theme over all those sequences.
So next one. Yeah. All right. Next one's short. And it's just sort of another example
or another framing of the previous post, as I wanted to lump it into this one.
Yeah. Okay. Can I summarize this one? And then we can do our experiment.
Let's see if I can do a short version. In this article, Ykowsky...
This one was called, the majority is always wrong.
The majority is always wrong, which is about kind of pondering the anti-majoritarian effects,
by which he means instances where the most popular idea or tool is not actually the best idea or tool.
So, like, of course, he noticed it. He was talking to a co-worker about probability
and thought that it was really odd that frequentism, which is the predominant view
in mainstream statistics, is the worst of the three major alternatives.
He brings up another example where the Dvorak, I don't know if I'm saying that correctly,
but it's a keyboard structure, which is seemingly easier on the fingers than the ones that we all,
like the standard one we use, the QWERTY.
Dvorak was specifically designed so that the keys that are used most in the English language
are directly under your fingers. And the less often a key is used, the further away it is,
as opposed to the QWERTY keyboard, where only one of the vowels is directly under your fingers,
which is ridiculous. You have to reach like a madman for some of these letters that are used
a ton, whereas you barely have to reach at all to use Q, which whoever uses Q, right?
Yeah, he then asserts, in any case where you've got, one, a popularity effect,
it's easier to use something other people are using, and two, a more dominant alternative,
plus a few small initial alternatives, then the most dominant alternative will probably be the
worst of a lot, or at least strictly superior to none of the others. And then he asks the
commenters to think of counter examples. He gave the example of Max and PCs, which this was back
in the day, younger listeners will have to remember that PCs were really popular and were used by a
ton of people. Max were kind of a niche that not too many people used. And there was an old saying
that Mac users had that saying if Max really were worse than Windows PCs, no one would use them.
The point being that there is a big popular thing that everyone uses, and there's a small
thing which only some people use. There's a lot of pressure to use the thing that everyone uses
due to network effects. Everyone is using Windows, everyone is using Word and Excel,
so you can transfer files between those easily. So the popular thing has a lot of staying power.
If there is a smaller group that is worse, no one is going to use that because in addition to not
having the popularity drive behind it, it's actually worse. It would have to be better than
the popular thing for anyone to use it at all. And just like now, Macs are always more expensive.
So if you're going to shell out three times the cost for a computer that's also worse,
then they'd all be idiots. And so they're just observing that if it was worse and more expensive
and didn't have all these benefits, nobody would be doing it. That proves that there's
something there. What else could explain it? Some weird hipsterism? I guess people listening
to records. Kind of. Robin Hansen had a pretty good answer to that in the comments. He said that
less popular choices must have advantages to compensate for their unpopularity,
but it doesn't mean that they're better. Many small religious sects are bound together stronger
for being persecuted minorities, and that bond may well be the advantage that they seek.
And you can probably think of more examples in that vein where something being small and niche,
you like that kind of hipsterism? Yeah, that was actually a good intuition pump. I didn't read
the comments. That would have been giving me something to think about because yeah, I mean,
I think the records thing might be something to run with a little bit there. Because then at
the end he challenges people to think of their own examples, and I threw out some jokey ones,
and one serious one, but. What was the serious one? I think Ford versus like Honda and Subaru.
Is Ford more popular? I don't know which is more popular. I guess I should have looked that up,
or at least had some idea before I think about it. I just know that people buy Ford,
people buy Hondas. Since the cost is roughly about equal to me, it's a no-brainer. I don't know a
ton about cars, but I've worked on some of several kinds, and I've just seen how long they last.
And my understanding, I haven't lived long enough to drive a lot of cars to the grave,
but if your Ford isn't going 150,000 miles, that's like really good. If your Honda makes it
300,000, that's really good. It's like you're getting twice as long of life out of this car.
But yeah, I think, I don't know, people still buy records, but they're not buying it. Well,
I guess they're buying it A for the signaling value of yes, I listened to records. Cannonball,
Jenkins was on and made a joke about that once. He said he has listened to his record. Yes,
I listened to records, I'm better than you. But he did it. Yes, I am better than you.
