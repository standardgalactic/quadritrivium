Welcome to Basional Conspiracy, my name is Stephen Zuber, and I'm Minyash Brotsky, and
we have with us today Max Harms.
Max, why don't you introduce yourself?
Oh my goodness.
So, I'm Max Harms, probably the thing that listeners will know me the best for is that
I wrote Crystal Society, and I just put out Crystal Mentality, which is the sequel, which
are science fiction novels about artificial intelligence and minds, and have a lot to
do with rationality.
I also was a leader in the Columbus, Ohio, or Central Ohio rationality scene for many
years, and I recently just moved to Berkeley, California.
Oh yeah, probably the most important thing that we should tell our listeners is that
Max Harms is actually your real name.
That's right, it's not a pseudonym, I actually intend to destroy the universe, but don't
tell anyone about it.
Awesome.
Your parents have a cool sense of humor.
Okay, so, we, I was thinking maybe for the first half or so we would start talking about
general rationality things, and then like for the second half, jump into Crystal Society
and Crystal Mentality.
Is that okay?
Yeah, that sounds fine.
Okay, great.
So the first question we usually ask when we get an aspiring rationalist on the phone
here, not really the phone, but on Skype, is what is your rationalist origin story?
Because most of us, you know, weren't born into it.
Yeah, so I feel like I was born a little bit closer to it than most people.
I was raised in a secular household.
I never had any sort of religious background or anything like that.
Some of my earliest encounters with religious stories and things like that were like reading
Greek myths or, you know, like occasionally breaking out a role-playing book.
So wait, how old were you when you discovered about Christianity?
You know, I don't know.
It's so much a background thing in culture that like I must, you know, I encountered
it slowly I think, and I just, there was never like a big point where I was like, whoa, this
is a thing.
It was after the age of reason enough or, you know, it was mixed in enough with things
like Greek myths that it never really occurred to me that it could be true.
It was never like a big deal.
Did you find it really weird that other people believed in this thing?
So Christianity, no.
I never really had any like seriously religious Christian friends, but when I was a teenager
growing up, I lived when I was homeschooled.
And one of my friends who was a homeschooler was Orthodox Jew.
And his family was like kept a Sabbath and it was very, very strict and he believed quite
a bit.
And so that was really interesting.
Like I got my first exposure to like a friend who was really into religion through Judaism.
And you know, we have lots of good philosophical conversations as teenagers are want to do.
But I feel like my rationality origin story really belongs with immortalism or immortality
based thinking because being raised in a secular household, I never really had a sense that
I was going to live forever.
Right.
Like there's no afterlife story to, I don't know, placate and I was bothered by my death
and I still am bothered by my death on a regular basis.
Right.
Like I was young and I was just like, well, but I'm going to die and how young were you
when you realized that you were going to die and start having this existential dread?
You know, I'm not sure it started early.
I remember being a young teenager and just feeling like the specter of death was looming
over me on a day to day basis or at least a week to week basis.
So I was convinced that I was going to die and I wouldn't say I made peace with it, but
it was just the sad state of affairs.
Like I didn't like it, but what was I going to do about it?
So I lived my day to day life, you know, just sort of dealing with that fact.
And when I was about 18, I think I started watching Ted Talks, which were super fantastic.
Right.
Ted Talks are just candy for the teenage mind, right, where you can just say, oh, the possibilities
are endless.
Oh, shit.
I'd say it's still candy for the 30 year old mind that too.
They're not Ted X, right?
Well, yes.
Yeah.
Well, I mean, like there's there's there are good Ted X talks and there are bad Ted
talks, but regardless, I saw Ted Talk by Aubrey de Grey and it blew my mind.
I did not have a conception.
So I had I had grown up in a culture which was like tangentially related to, I guess,
singularitarian culture or extropian culture.
And I had some exposure to this throughout my childhood, you know, like my parents talking
about things or whatever, but it always seemed like, I don't know, it never it never sunk
in or something like that.
And watching Aubrey de Grey and then later I read his book, Ending Aging, which is a
fantastic book.
I I felt like for the first time that there was actual hope that like death wasn't just
this inevitable thing which was going to occur.
And I started following anti-aging like blogs and things.
And that led me to watching like getting into singularitarian circles and transhumanists
circles and things like that.
And I got very, I guess, techno utopian for a while and just like, oh, the future is going
to be so fantastic.
And I still do believe that the future, at least some of the futures are going to be
really fantastic.
But at some point I watched a talk, I'm not sure when or where it was by Eliezer Yudkowski
way back in the day.
And I was just like, hmm, no, that's an interesting idea.
Like maybe if we build an artificial intelligence, it won't be nice to us.
And that got me thinking about like the importance of artificial intelligence.
And at the time I it didn't really, I was I was a little bit like half and half on the
AI safety thing.
I was like, yeah, this is probably important, but it's maybe not like the biggest most important
thing.
What's really important is that artificial intelligence could design artificial intelligence
better than humans.
And if that happens, then the world could transform way faster than I thought it would
even given things like, I don't know, life extension technologies or all sorts of super
cool Moore's law things.
And so at that point, I basically shifted my entire life plan to be pushing towards AI.
How long ago was that?
So that was in about, let's see, I would have been 21.
So that was seven years ago.
So 2010.
All right, you've been working on this for a while then.
Yeah.
Like I said, many years.
And so in the wake of 2008, my father lost his job.
And the family decided to move out to Ohio, we had been living in Oregon at the time.
And I decided to follow them instead of being in Oregon without much family around.
And when I moved out, I changed, I lost my normal social circle.
And so I started looking around for people in Ohio.
And I found a couple of rationalists on okay, Cupid, and there was one of the first meetups
was getting started.
It was a cross city meetup between Cincinnati and Columbus.
And I got invited to that and I enjoyed it a whole bunch.
In preparation, I had read a bunch of the less wrong sequences before.
But I basically read through them all in preparation.
Holy shit.
And how long did that take you?
I mean, not like all, like I said, I read a decent chunk of them.
But I read, I think I read at least half.
In what, a week's time?
I don't know.
A couple of weeks.
I didn't have much else to do at the time.
This actually might tie in that amount of free time.
Oh wait, you're past 20, never mind.
I was going to say this might tie into your flexible school schedule with being homeschooled.
I do approve of flexible school schedules, but now this was after.
Didn't mean to do it elsewhere.
I was between jobs.
Do you think that being homeschooled had an effect on how you pick up information and
read through it on your own time?
For sure.
Yeah.
I tend to think that there are a few good things that school does and there are a lot
of bad things that school does.
And one of the worst things that happens in most schools is because kids are forced into
them and they don't want to be there and they're confronted with this like antagonistic experience
day in, day out.
Schools are really good at making people hate learning.
Oh, okay.
That's, you know, that's the same reason I will never learn German.
My dad tried to drill that into me when I was, I don't know, nine or 10 and just months
of clashing and horror over that and I will never touch that language even though I think
it's kind of pretty.
Right.
It's just a question of like association, right?
If your association with learning and studying is this is awful, I'm being judged and the
teacher is like, I don't know, boring or going too fast or confusing or I'd rather be doing
other things, but they're forcing me to like, of course, you're going to not like it.
And, and I just have that experience growing up.
Yeah, I feel so, I feel so lucky now because I was almost always the teacher's pet and
I still kind of love learning and I think that may be part of why I think a lot of there
are some people for whom schools are a really good experience.
Some people are just sort of like naturally good fit for the institution or like naturally
bookish or happen to get good experiences, you know, some combination of the three and
for those people, right, school ends up being this fantastic thing and you go on to college
and you love it and maybe use, you know, go to grad school or something like that.
And a lot of the like modern schooling institution is built to cater to that kind of mind, right?
And so there are some of us, I really enjoyed the school experiences that I had.
So there are some of us where schools are set up in a nice way, but I think for a lot
of people, there's just like, there's some damage that's done and it's not, it's not
insurmountable, but it is definitely, I'm very glad that I didn't have to do that very
much.
Although I was the experiment kid, I was home school for most of my education, but there
were several years where I was in various larger institutions.
How do you think they compared the larger institutions to the homeschooling?
How did I compare them?
Yeah, I like person I know.
She was homeschooled for most of her life and when the, in the two years that she was
in public schooling, she said were some of the most horrible years of schooling ever
because she was constantly bored and she didn't get along with anyone and it just completely
turned her off to any sort of institutional systems.
Yeah, I think that that's pretty close to my experience.
Especially with like public schools and things, there were a few charter schools or alternative
schools which were set up in a pretty good way and I enjoyed those, but it's always hit
or miss and there's a reason why I was homeschooled most of my childhood because that was just
the better one and the experiment yielded positive data in that direction, right?
So I read a bunch of the sequences and that's when I actually got involved in rationality.
It was, I had gotten involved in the AI scene and I knew what at the time the Singularity
Institute was for artificial intelligence was doing, but it wasn't until I changed social
contexts and started going to meetups that I read through the sequences in depth and
I got very excited about community and the possibilities for having rational communities
and in the week of that, while I have spent a good amount of attention on artificial intelligence
and like I wrote some books about AI, I've also put a lot of my attention towards I guess
growing the rationality community as a whole and especially my local communities.
Huh, so Steven, you and me and Katrina, she's, oh, Katrina's not joining us today.
She has job stuff for the listeners out there who are wondering why Katrina's not here.
We were talking about doing an episode on building your own rationalist group.
Would you be willing to join us if we have one of those in the next couple months and
talk about that as well?
Yeah, sure.
I feel like, I don't know, since I'm here, it might be a good opportunity to like say
a few things, but if you're planning on having a full episode dedicated to that, maybe I
should hold my tongue.
If there's any, you know, points that you definitely think are worth reiterating, you
know, the chance that this doesn't come out for another six months, if there's anything.
Or if there's something you think that people should know, yeah, like right now to get started
before we get into the full in-depth episode.
No, I think the biggest point is kind of the most obvious, which is if you want to do a
rationality-based social thing, the biggest thing to know is that you should just go and
do it and not wait for anybody to give permission and invite a whole bunch of your friends and
tell them about rationality and don't try to make it just like you have to know all
the things in order to come.
Ours worked out in a really nice way in that I was relatively new to the Denver area.
I guess I'd been there for a little under a year and that March was the HP or the Harry
Potter methods of rationality wrap up and I guess around the world there were, you know,
wrap up parties and Inyash hosted that because he did the podcast and he had some notoriety
and what 20 people showed up.
Probably more than that.
Yeah.
Maybe 24.
It was this big party and it was funny because we got there and, you know, six hours before
you got there, you checked and Facebook was like, oh, there are three people, so you got
a table and they're taking an entire half of this restaurant.
So for me, I just, I enjoyed that so much.
I was like, we should do this again.
Let's make this a regular thing and we've had a pretty steady amount of, I guess, 15
on average, maybe every month.
So, but we were lucky to start off with that kernel of people who were already adjacent
enough to know whether or not they would like the community and some of those fell out.
Some more came in and we're, you know, it's a flux thing.
It was really handy to have that big shelling point, like just a large Clary on call, hey,
Harry Potter methods of rationality rap party.
And then everyone came to that and we all met each other and that sparked it.
It was awesome.
But if you don't have an event like that, then yeah, the, I mean, there are resources
to, you know, like meetup.org, you can make something there.
There is the less wrong meetup subsection on the less wrong website where sometimes there's
ones near you.
Sometimes they have like, you know, meetups listed there that no longer exist, but you
know, you can post on there.
Sometimes people show up.
We've had a few people show up from ours on less wrong.
So it's, it's a thing.
It's something I guess we can get more into later if we want.
So, so I want to pick your brain real quick on this whole immortalist thing because that
is something I'm also very interested.
I assume, first of all, you're signed up for cryo.
I have a member of the cryomics institute.
Excellent.
I am as well.
And I've given talks on the subject as well.
Oh, neat.
Can you send us a link after this?
No, put it in the show notes.
Fantastic.
Do you do anything else in your day to day life to try to help prolong your life if possible?
Yeah.
So like there's basic standard things like exercise and try to eat well.
I try to get enough sleep, someone and so forth.
I try to avoid being in cars when I can.
Although that's, you know, I don't take that to a super extreme.
It's just like if you have, if you have the chance to not do a regular commute, that's
probably a few micromorts at least.
There's all kinds of other perks to not commuting as well, like not wasting an hour
and a half a day in traffic.
But yeah, you also run your odds of longevity, but not risking your life to and from work
every day to how do you, how do you define a micromort?
Oh, that's one, one millionth.
Yeah, it's one, one millionth of a, try to remember if it's a millionth for percent
or just a millionth of, what should we, what, 10,000th of a percent chance of dying.
OK, so like there's some very scary statistics on motorcycles.
If you're trying to live forever, do not ride a motorcycle.
And I don't know, just like basic things, trying to be safety conscious.
Right now, I'm a guinea pigging myself with the basis supplement from Elysium.
Have you heard of that one at all?
I have not.
OK, it's one of the NAD plus ones, actually possibly the only one, but it was the one
that had a whole bunch of Nobel Prize laureates coming out and either working for them or
saying, yeah, this, this seems legit and obviously not FDA approved or anything like that.
But I figured, what the hell, I'll find out in 20 years if it's helping any and consider
myself a part of the research project.
Yeah, there are a whole bunch of exciting supplements.
I don't actually take any right now, but it's something that I sort of perennially
turned my attention to.
I think like most of the bang for your buck is just exercising it even well.
Yes.
And those have the added benefit of making you just feel better and be more productive
in life in general.
Absolutely.
So much of rationality, I feel, is like adds up to common sense.
It's really fantastic.
It's, I feel like it's one of the most primary lessons of rationality is when you ask
a question, most of the time you're going to get a very boring answer that looks
something like, eh, it depends.
It's kind of complicated.
So yeah, so since then you've been doing the rationality thing.
Yeah, so running meetups, running, I ran a rationality dojo, which met every other
week for a few years, lots of other stuff.
Yeah.
So right now I follow primarily Scott Alexander and I try to keep in touch with
Hansen's blog as well.
What, what are the, ever since the less wrong diasporas happened, what, what do you
usually use to keep track of where the rational, rational sphere is going?
Yeah.
So I think Slate Star Codex is something of the, the new hub for rationality at this
point.
There's less wrong renaissance, which is sort of underway and people are trying to
get less wrong happening again.
Yeah, I was going to ask you about that next.
Yeah, I'm probably not the person to talk to.
Some of my housemates are involved, but I myself am not.
And then there's, I don't know, just a variety of sources that I've been
fond of reading the blog, put a number on it.
And I don't know, there's, there's Sarah Constantine's blog.
There's your blog.
There's a whole bunch of good resources.
Did you say there's my blog?
Well, that is bad.
Yeah.
Another primary source is just Facebook and a lot of people are using Tumblr and
there's all sorts of like, you know, again, you mentioned the rationality diaspora.
There's rationality resources all over the place nowadays.
There's also a less wrong Slack channel that has some hundreds of people.
It's active all the time.
There's, you know, 40 different, uh, I forget what you call them, sub channels.
I forget what you call a sub channel and Slack.
I mean, there's everything from, you know, neuro enhancement to AI, to general
advice, uh, relationship or human relationships, whatever.
For me, that's exactly what I was looking for when, you know, so I've tried a
few things on Facebook to get little active groups going.
And the ones that I've gotten going basically can get, can reliably get a
post every five or six weeks.
And that's all people really want to get on.
Then three or four replies and that's it.
The Slack channel is pretty active.
So if anyone's looking for just, uh, something, you know, it's not the kind
of thing you have to follow and read every little thing either.
So it can just be there if you've got 20 minutes at work and you're bored.
So worth looking into.
Yeah.
And there's also, uh, rationalist subreddits.
Um, I enjoy Slat r slash rational, which is the rational fiction subreddit.
Um, there's also the Slate star codex subreddit, which is pretty good.
And then there's like podcasts like this one.
And I feel like a lot of most of my attention, I suppose, has just been in
my face-to-face experiences because I have been centrally involved in like
local rationality communities.
And now since moving up to the bay, uh, I've been working to build a lot more
of like personal connection with people who work at, uh, center for applied
rationality or, or Miri or any of the other organizations.
Yeah.
I would say that in general, face-to-face are the most emotionally satisfying.
But when you're right there in the hub, there's really no reason not to
just go with that.
Yeah, absolutely.
Well, I mean, there's, there's some reason it's emotionally satisfying.
And I, I wouldn't do without it.
But, uh, let's take, for example, the Les wrong study hall.
So there's a, um, I think it's Malcolm ocean.
I think runs the less wrong study hall.
I'm not sure whether or not it's part of compless or not, but it's a, it's an
online space you can go on and there's like a Pomodoro clock.
That everyone shares and you can write down what you're working on and you
can turn on your webcam if you want.
Uh, and there's a chat, but it's silent and you just work like being
watched with other people around you, um, who are, you know, like less wrongers.
And this is super useful.
Um, I've used it in the past and play.
There are some people for whom that just makes the difference between being
unproductive and watching a bunch of TV or, you know, doing something useful.
And like writing some blog posts or reading some material or whatever else
you're doing with your life.
Yeah.
For my, for my work, uh, schedule, I guess now that I'm working for myself in quotes,
uh, I generally go, I generally go down to Starbucks every day because just having
those people around like judging me, even though I know, but they're not really,
really helps.
Yeah.
And like the point of the less wrong study hall, I think you can include a link
to it in the show notes all sent you a, where that is, is to replicate that sort
of experience that like working at Starbucks experience, except that you know
the people around you because they're less wrongers who are part of that community.
And, um, you can just like share those break periods in between Pomodoro's,
uh, talking about whatever you want or, or not as answer need, maybe.
And like, that's the kind of online space that is better for having the community.
And which probably just wouldn't work on a local level.
I do co-working with people in the local community too, but you can't just set
up a persistent co-working space unless you have a lot of people around.
Uh, so one final question, if you don't mind, before we jump into crystal society
and feel free just to pass on this one.
If you want, since you said you were not the right person to talk to.
But do you think that the less wrong renaissance is plausible and or desirable?
That's a good question.
I think that first of all, again, I'm not the expert to talk to here, but there's,
there's a way in which we need a hub, we need some sort of central meeting point,
at least from the perspective of being one community.
If you don't have a hub and like less wrong kind of faded and died, what happens
is that you, a whole bunch of other things start moving into that space, into that,
I don't know, community shelling point.
And if you start having people who are like, unrationalist tumblr versus
slatesharkodex versus whatever else, um, the community starts to fragment, right?
Without having that central hub with, with whatever sort of cannon, um, posts are
present, but because what was once one community starts becoming a whole bunch
of communities and that could be good or that could be bad, depending on what
you're trying to do.
I think that I wouldn't want to give up the sub communities that have started,
but I think that there's something important about having a place that is
like the central place of discussing ideas among the people who, you know, share
the perspective on rationality and better thinking and cognitive bias and that
sort of thing.
And I would love to see a next version of less wrong succeed.
I'm kind of on the, uh, on the edge, 50, 50, about whether or not that will
work, but I'm definitely supportive of the people who are trying.
Okay.
Shall we hit the crystal society and mentality?
What do you, what are you calling the series, by the way?
So it's just the crystal trilogy.
The crystal trilogy.
Okay.
Yeah.
The final book is crystal eternity.
I guess we can decide what order we want to tackle this in.
I'm interested in talking about rational fiction as a whole.
And if we feel like that's a good segue into crystals or into the crystal
trilogy or crystal trilogies, it could segue into rational thick at large.
What would you guys prefer?
Uh, well, I'm assuming do you consider, um, crystal, the crystal
trilogy to be rational fiction?
Yes.
Uh, I do.
It's certainly not rational fan fiction, but not all rational fiction has to be
fan fiction.
Certainly not.
And the rational subreddit characterizes rational fiction as a story where nothing
happens solely because the plot requires it.
So like, essentially the world behaves according to rules and not, you know,
it's not just because it moves at the speed of plot or whatever.
Um, any factions are defined and driven into conflict because of their beliefs
and values, not just because they're good and evil.
Um, the characters solve problems through intelligent application of their
knowledge and resources.
I think that's very central.
And then the rules of the fictional world are sane and consistent.
So by those criterion, I definitely think that crystal counts as rational fiction.
Do you think those are good criterion for rational fiction?
Is there anything that leaves out?
Well, it's a little bit hard to say.
So it goes on to say in rationalist fiction, as well as the above, the main
character uses or tries to use, uh, rationalist and scientific methods to
demystify seemingly mysterious phenomena.
And this story shows rationalist techniques, which can then be applied to
by the readers and the story is like a puzzle in that the readers can reach
the same conclusion as the characters by using the same information.
So there's like this sort of classic question about Sherlock Holmes, right?
Sherlock Holmes is supposed to be, uh, like super intelligent, uh, detective,
but it's not the case that you as a reader, if you're as intelligent as
Sherlock Holmes can solve the mystery because Sherlock Holmes actually
relies on a bunch of information that you as a reader just don't have.
So, um, his intelligence isn't really displayed.
It's more like he has this black box out of which he pulls solutions to
whatever problem happens to be presented.
And I think that this is really at the core of what rational fiction is about.
It's, um, it's about taking intelligence and minds and opening them up to the
reader to say, Hey, this person is acting according to a set of heuristics
and rules and pressures.
Um, and we can understand what those are and we can understand all of the
information that they have available.
And if we're clever about it, we can think about like the mistakes they're
making or we can predict in advance what they're going to do.
And if the world behaves according to a same consistent set of rules, we
should be able to like random events, uh, excluded.
We should be able to like understand roughly how the characters are going to
behave at any given moment.
Well, like, like the, the, the final exam and Harry Potter methods of rationality.
That's a good example of that.
We knew everything that Harry knew about magic and we were explicitly told,
figure it out, or it's not going to end nicely.
And so with, with the, with the homework problem, the, the community was able to
solve, to solve the answer or solve the problem correctly by coming to the correct
answer. There's one other, I guess, sub bullet point that I add when I tell my
friends about rational fiction, which is, I guess implied by at least two of the
previous bullet points, but to me, at least we're making explicit, you know,
like contrasted to a show, I mean, anything I don't want to shit on a
particular show unless you guys want examples, but the shit wherever you want,
man, well, the characters action such a way that makes sense for what's actually
happening and you're not sitting there, you know, either staring at the page or
staring at the screen and saying, why the fuck aren't you doing this?
You know, why, what are you thinking?
You know, so like, like the walking dead, they walk around with revolvers and
shoot zombies point blank, attracting her, it's attracting, you know, other crazy
humans, which God, why are they not cooperating?
But that's, that could actually, you know, whatever that aside.
But, you know, I think there was, in fact, it was on the rational subreddit.
There was a very short story of a survivor woman in a zombie apocalypse and
she's doing exactly the appropriate thing.
She's wearing basically like thick motorcycle gear, a helmet using like what
a Tomahawk or a hatchet or something, some silent weapon and all of her clothing,
including her gloves and her boots are all like strapped together.
So you can't pull a glove off.
And so like that, that is the, and even in like the walking dead, they, they at
some point acquire police riot gear and then subsequently ditch it.
No, my God.
Like I would sleep in it, right?
I mean, your enemies aren't powerful, you know, unless you're surrounded and
they just, you know, tackle you, but they bite you.
And you're, you can, there are bite proof things in the world.
You're like in, in 28 days later, one of the guys wraps his arm in magazine,
like with a magazine and like rubber bands or something.
Like just to make it to where, you know, a human jaw can't bite to it.
The little things I, I, I, I'm picking, I'm railing on one example now.
But I suffered through one season of walking dead and I regret just sitting
through that many episodes.
I sat through five seasons.
I, I did, I did eventually fall off, but it just, it never gets better.
Okay.
There, there are little things like there are some cool things.
Like, yeah, there were a few little cool things.
And I kept coming back for those episodes because I kept thinking, maybe
they'll have more of these cool things unless of the dumb things.
Right.
But it just, it ended up not being worth it for the few cool things we got.
Well, like, I liked zombie movies as a kid.
And, uh, you know, I would think like my high school would be like a great
zombie apocalypse refuge because it's got thick brick walls, you know, solid
windows, my apartment, my current apartment building, another great example.
Right.
I mean, small, like small entrances, not easily scalable walls, like it would be,
it would be awesome.
And so in the walking dead, they eventually find a natural or an existing structure
like that they move into a prison for a season, which to me is like a great idea.
This is, this is specifically designed to be hard to get in and out of.
Right.
So like just the shambling debt or it could be able to walk in.
So there are fun little steps like that, but they just, they just literally stumble
upon it.
They don't like, they don't sit and like, we should think of a good place to move
to they, they just, they haven't defined it.
So no one thinks in that stuff, but, but, so to bring this back to rational fiction,
people do think and their thought processes are expressed to the reader.
So like, like, it's like one of the other points that the reader can follow what
they're saying and thinking and follow similar trends of thought.
Um, I think like one of the surest signs that some writer is definitely pushing
in the rational fist, rational fiction direction is if they avoid the idiot
ball in writing, there's this concept of like, you've got a problem of like how
to write this scene or like how to make something go wrong or how to increase
tension and the solution as the writer is like, oh, okay, the character was
stupid or made some error.
And so you give the character the idiot ball and they do something stupid.
That's very unsatisfying, especially if what you're interested in is like
understanding how competent people solve problems or how the mind works.
Well, just like if at any moment characters can just do stupid things
because it's useful for the story, then you can't get behind the feeling that
like when you are presented with information, you can use that information
in a way that makes sense, that like adds up to something useful in the world.
Yeah, you don't trust the author.
I think tied to that, there's also a sense that you said how a competent
person could solve problems.
There's the similar example that you can get examples of how almost
competent person can come so close to solving a problem, like the time
pressure chapters and methods of rationality.
You could argue he was stupid and didn't think of any of us 1000 solutions
that could have gotten there, but he wasn't stupid for that.
I mean, it was, it helped drive plot and stuff.
It was, there was, there were those reasons, but he wasn't stupid in a way
that was unforgivable for his circumstances, right?
Right.
I think it's, it's important to recognize that rational fiction doesn't
have to have the characters be like omniscient or perfect or whatever else.
It's more the case that when the character makes an error, you as a
reader should be able to understand why they made that error.
And I think that this is, this is a way in which rational fiction can
help us understand the human mind better.
Like why does Harry make the errors that he does?
Or why does, you know, any character in rational thick, they can make the errors
that they do is because usually they don't have the resources, the cognitive
resources, the time, the energy, the, whatever else to think things through.
And often their attention is locked to the wrong part of the solution space.
Right.
And that's, that's like a very useful insight to take away is to be like, ah,
when errors are made, it's often because the character didn't have the
ability to think it through enough and because they were looking in the wrong
direction.
So in my own life, if I want to make fewer errors, maybe I should do it more
time to just thinking things through more fully.
And how can I de anchor from the parts of like where my thoughts are drifting
that aren't going to be useful and put more attention to the space of solutions
that are going to be useful?
I, I like, I think it was Daystar Eld who said, this is one of my favorite
things to describe rational fiction because it's so simple and it kind of
gets it across.
He says it's thinky fiction.
It, there is a lot of emphasis about thinking things and thinking through
things.
And yeah, there is.
And I like that sort of thing in my fiction.
And I like what you just said just now about how you can use rational
fiction to like open up a mind and see what's going on inside it and how to
get through these processes because that is like literally what you do in
crystal society.
Yeah.
So the premise of crystal society and the crystal series as a whole is that
it's told from the perspective of an artificial intelligence.
So the, the AI is named face and it's created by other artificial
intelligences that collectively pilot a robot.
So some scientists find a crystal, which is magic in quotes, but so the, the
crystal is able to be put into a robot and the, the robot's name is Socrates
and it's in a university.
And there are, basically the idea is that the code for the AI is set up to
have a bunch of different goals, which it tries to maximize like he tries to
understand its environment, tries to classify its knowledge, tries to obey
human instruction, tries to be creative and tries to learn.
And there's a flaw in the programming where these goals end up controlling
different parts of the reasoning process for the machine.
So, so each one of these sub goals basically carves off a section of the
mind and competes with the rest for, uh, like control.
So, uh, at any given time, like the sub goal that's trying to explore the
environment has to deal with the other sub goal that's like trying to, uh, I
don't know, solve some sort of creative problem.
And one of the problems that they encounter is that the humans keep being
annoyed with them, the AI's, like they're, the AI's are doing things like, uh,
reading web pages and not, uh, following social norms.
And so the AI's build another AI, which is face to interact with the humans.
Like each goal is its own personality and its own person, and they're all
trapped in the same body and they're constantly talking to each other and
fighting with each other and shit.
It's awesome.
Can I, uh, I'm going to interrupt just for one second.
This isn't a spoiler because you find it out in the first few chapters, uh, the
main problem that the AI's have with the humans is that humans keep
murdering the fuck out of them.
If they aren't happy with what a goal thread is doing, they will reset it or
roll it back or just delete it entirely and replace it with another one, which
to the humans, they're like, whatever we're altering code, but to the AI, they
just saw their sibling murdered.
Right.
And it's important.
I think this is, uh, like the big reason why I wrote crystal society is because
so much of artificial intelligence in, um, fiction is handled just entirely wrong.
You know, whether it's Ultron or even, you know, like R2D2 or commander data,
which are like, you know, nerd icons and I don't want to besmirch them.
But, um, that's not how AI, we, that's not how we should expect AI to work.
Now they're basically just humans with metal bodies.
Yeah, exactly.
Like the important thing about, uh, an artificial intelligence is that it's not
guaranteed to want the same things that a human wants.
If it's intelligent, it's going to come across the same sort of ideas.
Uh, it's going to believe the same, like brute facts about the world or better
ones, um, but the, there's an is on problem, right?
Where just because the sofa is over here, rather than over there, it doesn't
mean it ought to be over there.
And you have to code in explicitly what the AI should care about, what the
odds are.
So when the AIs are seeing the other girlfriends being murdered, there's
nothing intrinsically upsetting about that to them.
Like there's, there's no like, oh, you're, you're like murdering my family
or anything like that.
That's a human reaction.
But they don't want to die.
But they don't want to die.
And why is that?
It's, well, I mean, there's one part of the, uh, AI that's explicitly
devoted to self-preservation.
But again, there's like, when you code in an AI to do something like
explore an environment, it's not going to want to survive just because humans
want to survive just because, because we evolved that way to care about
survival as a primary value.
But the reason that the AI that wants to explore its environment wants to
survive is because if it's destroyed, then it can no longer explore its
environment and it will therefore fail.
And I think that that's like, it's understanding the way in which goals
diverge, but then there are certain goals, instrumental goals, which like
self-preservation, which arise regardless of what, what you care about.
And so Crystal is largely a work that's meant to show rather than tell a lot
of the, um, ideas about the alignment value problem and other ideas in
artificial intelligence, which are celebrated in this community.
I've got to say, if you like, uh, subterfuge in your plots, like when, uh,
Harry and Coral are trying to outthink each other and outsmart each other.
Oh my God, this is like the main thing the book has, because first of all, the
humans don't know that there's multiple personalities within the AI body.
They think they're just dealing with one personality.
And so all the AIs are colluding to fool the humans and to still thinking
there's only one and not deleting them.
But then they are also constantly like feuding with each other within the body.
And they can't physically harm each other.
So there's a lot of building coalitions and keeping secrets.
And there is a, just a lot of thinking through things where face, you know,
sits back and it's like, okay, how do I get through this with the resources I
have? And the resource they have are very limited.
It's mainly the ability to think really good and, uh, and quickly, quickly in,
because, you know, in real time, they can do a lot more thinking than one
human could in the same amount of time.
Having not read it yet.
What, speaking of quickly, how quickly are it, does it think is it at the
theoretical maximum?
No, no, not at all.
And in fact, one of the things that I wanted to show was, um, that you can
start with an AI that is very limited in a lot of ways, and it can still be bad.
Um, so spoilers, uh, the book does not consist of, uh, they built an AI and
things were good forever.
Although I will point out that for people who understand intelligence
alignment problems, um, the plot of the book is written to be interesting to
rationalists and there's, there will be twists and turns for, for even the
people who are very familiar with the ideas.
It's been on my shortlist for a long time.
I'm a, I'm a slow reader.
I've had other busy things happening and I have one fiction book that I'm
getting through before I start this and, uh, I'm eager to, to dive into it.
So God, I love face so much because face is like my spirit animal.
Awesome.
I couldn't be anyone would be a multi faceted AI.
No, no, face is just one facet of the AI.
It's the facet that wants humans to love it.
Oh, I see.
Yeah.
Perfect.
Not, not that it doesn't care about the humans being happy or enjoying their
lives at all.
It just wants other humans to love it.
Oh, that is your spirit animal.
Yes, we've spoken before about your desire to be liked.
Right.
So yes, I could read about face all day long.
Yeah.
So face is actually a neuromorphic AI, which means that it's, uh, she's like more
or less thinking like a human and has most of the same sort of mind parts.
And this is like one of the primary other points of the book is that there
are aliens in the book and the aliens are actually more alien than the AIs are.
And sir, there's a kind of a spectrum there where you get to see the divergence
of different possible minds.
But, um, when face starts out, face is able to think fairly quickly, but not is
actually less intelligent than like peak humans in a lot of ways.
And most of face's ability comes from, uh, not speed of thought, but rather
determination, the fact that she and her siblings don't sleep, right?
And don't get distracted and are sort of, I don't know, maniacally focused
on their specific obsession.
Yeah, it's, it's wonderful the way they weave together.
Right.
So I'll point out, uh, to listeners who aren't familiar, you can read, uh,
Crystal Society, which is the book that we've been talking about, um, and
Crystal Mentality, which is the sequel on Amazon.
So if you just search for Crystal Society or Crystal Mentality, that's
the, probably the easiest way to get them.
Now Crystal Society, uh, when I read it was available free online to everyone
in its entirety.
Is it still available free?
It is.
So let's, we can also put up a link to my website where you can read, uh,
Crystal Society online.
Crystal Mentality is, uh, not free, but you can also, there's a link to it on
my, um, webpage, so we'll put that in the show notes.
Excellent.
So it's been, I think over a year since I read it.
So my memory is a little hazy, but there was a character, a very kind of idealistic
programmer, if I remember correctly, who replaced, uh, one of the lead programmers
at the university and stayed throughout the rest of the book, uh, who seemed kind
of familiar.
Is he based on anyone in the real world?
Okay.
So you're talking about, uh, married, is that's right.
Yes.
Yeah.
And I swear, I swear to God, he is not based on that laser.
Okay.
He, uh, like any resemblance to Eleazar is the product of my subconscious mind.
And as someone who knows Eleazar in, in meat space, I can say that the actual
Eleazar is very different.
Okay.
Cool.
So, uh, when, because Crystal Mentality, I have not read it yet.
It just came out recently, right?
Yeah.
Crystal Mentality came out just, uh, let's see, uh, about a week ago.
Yeah.
Actually a week ago, exactly.
Excellent.
I don't know if we want to ask questions about it.
They might be too spoilery.
Can you give us a quick little teaser about it with that spoilers?
Yeah, sure.
What's on the, what would be on the dust jacket?
Yeah.
Let me see if I can pull up the dust jacket.
Give me a second.
That said, it came out a week ago, we're recording on the 26th of January.
That's right.
This might not come out for another four or five weeks.
Yeah.
So it came out near the end of January.
Yeah, sure.
So the, the primary spoiler, which is, uh, you can probably just skip, uh, a few
seconds if you don't want to hear spoilers here.
It's on the cover of the book is the planet Mars.
And so at the end of crystal society, the AIs are headed to Mars on an alien spaceship.
And crystal mentality is largely about how the, uh, society unfolds.
Like what is it like to, to have them in an environment where they're no longer
constrained by, uh, the humans that are around them.
So there's a lot more with the nameless.
There's a lot more with the aliens that, that they're traveling with.
And there's a lot of what does it look like when the AI starts thinking in new
directions and has a whole planet, um, full of possibility for, for building.
And that sort of thing.
Fascinating.
I'm really like, I'm just still caring about this.
I used to read a lot and I, I slowed down a lot in the last few years,
especially fiction and I don't know what, what has gotten to me, but I, I need
to just dive into this again, especially this, this sounds like a lot of fun.
This is really great.
Or at least it was really right up, right up my alley.
I mean, it sounds like it's right up mine.
I was just wondering based on the name and also based on how the gold threads
work is, was crystal society based on, uh, the society of mind?
If there's some inspiration there, uh, I was definitely familiar with, for example,
Marvin Minsky's work.
And I think that there's something to be said about the way in which it
parallels human thinking as well.
I didn't want to, uh, clutter the story with like trying to talk about explicit
parallels with human thinking, but there's a lot of ways in which I think it
makes sense to model humans as not exactly different agents, but different
pressures, right?
Like there are genuinely different goals within us that are in a sense competing.
Right.
Like if I, if I'm hungry, but I also haven't seen other people in a while, I'm
in, there's a tension inside me and how I resolve that tension.
Whether or not I seek food or I seek companionship is an interesting question.
And I think that how are the various pressures and internal goals within
us, uh, interact is an interesting question for any aspiring rationalist.
And, um, I think that a lot of reason why people enjoy crystal society is it
gives something of a framework inside of which to, uh, to think about and talk
about the ways in which we might feel conflicted with ourselves.
This is fresh on my mind because we were just talking about this yesterday.
The, the one that really is getting to me right now is the conflicting desires
to have a society free of violence and what you do with, with people who espouse
violence verbally without actually doing it physically.
I'm talking, basically I'm talking about the Nazi punch thing and how a lot
of people I've seen them just being gleeful that Richard Spencer got decked.
And I'm, I'm, I just, it seems to me a very interesting line where people
think they're the people who fall on the side of it's okay to do violence.
And the people who fall inside of no, he shouldn't have been punched even,
even though he's saying some awful things.
Sure.
And this is an instance where, uh, I feel like just with many, uh, rationalist
ideas or many ideas that we reason about in the context of, uh, a rationality
framework, the answer is, yeah, it's complicated.
And it kind of depends, right?
Yeah.
Um, the, we need to be careful not to just stop at that point and say, you know,
oh, well, it kind of depends on walk away because that's, that's not an answer.
But, um, I think that, well, it's, it's the answer that you're okay with whatever
is happening is, is the way it is, I guess.
Well, not necessarily, right?
Like we can be upset about what's happening or we could be okay with it.
Um, I think what it is, is it's a reminder that the answers to most
questions aren't going to be simple, like rules or easy heuristics to follow.
I think that there was a time in my life when I was, uh, I was really into
pacifism and I'm like, well, it's, uh, it's not right to hurt other people.
And I'm not going to be part of this, like culture of violence or whatever,
but that's too simple.
What happens when important values are on the line and it's, and, and you
can't just weasel out of it by saying, like, Oh, but actually, uh, I'm going to
assume that it, like acting along this line solves my problem anyway.
Cause there are, there are cases like that where genuinely we have multiple goals.
And when those goals come into conflict, you know, where does that resolution
take place at what level do we decide, like it's more important to have peace
or it's more important to have tolerance or it's more important to have, I don't
know, open discourse.
I think that like a lot of, a lot of why rationality is important is because we
as humans are primed to give immediate polarized answers based on nothing more
than what side we happen to be on and any given instance without thinking about
like the underlying principles.
And so I guess in this instance, as with many, I would say that the correct
approach is to say, well, stepping back when there is a conflict between these
two values, what is the line that we, you know, myself as an individual or we
as a society wants to draw as to where, where those values trade off.
Well, and that, that's a, that's an important distinction to make too.
That the line for me to pick up a gun and get ready to go out and risk my life
and take others lives, that line is probably from, from my personal
levels, probably a lot higher than I just feel like me to say as a society, some
people should be prepared to do that, you know, whether it's a, uh, an
international conflict or, you know, some other circumstances, but I think it, it
is not inconsistent to say that your value, your personal level can be
different than what you would advocate at a societal level.
Yeah, absolutely.
I think like, again, we're, we're anchored by this, unfortunately, all too human
context where we try to like pretend like the larger groups that we're part of
are individuals or something like that.
We say some things like, Oh, but, you know, if the United States
government was a single household, this is the proportion of the income that
would be going to like paying off debt or something like that.
And, and that's, that's a, uh, an interesting metaphor to look at, right?
You can certainly make the comparison, but it's fundamentally wrong.
Like the United States government is not a single household and neither is
like a city, a single person.
It makes a lot more sense for like the human species as a whole to have weapons
that it does a single individual to have a weapon or, you know, like that's
very, we're getting a little bit too political here, but okay.
Well, I, we can, we can make it safely political again by saying that that was
the same, I think, false analogy that Plato used in the Republic.
The whole thing is this big analogy between the individual and, oh, by the way,
nation states are just like individuals and, you know, they have these,
these three main parts and they, they work like this.
And that the, I think the, some of the points survive when that, if you say,
I don't accept that analogy, but that's sort of the whole point.
That's the whole edifice of the book.
And like you said, it's, it's, it's a very limiting scope, right?
And there's, there's only so, so much use you can get out of analogy,
have an analogy that stretched.
So, uh, is it okay if we move away from politics then?
Please.
Alrighty.
So moving away from the politics and back to the, the books themselves,
I was wondering as a fellow aspiring writer, what's your writing process like?
Yeah.
So that's a good question.
I have a very strict regimen and I think that different writers,
writing styles are just different in, as I've talked to other writers,
I seems like everybody's got their own strategy.
But I found that what works for me is I wake up at 6 30 every morning.
I take a shower and I write for an hour and a half.
It's like the first thing I do every morning and it's right when my head is
like most clear and I have the most energy.
So you're like one in a million people who is most clear and has the most energy
first thing in the morning.
Yeah, right.
Exactly.
And so this is where, you know, like, unfortunately,
I don't think my advice generalizes, but for me, I tend to, uh, I write every day
and I have for years and I feel like it's just, uh, an anchor in my routine
that allows me to make incremental progress.
So one thing I would definitely not recommend if you are an aspiring writer
or a writer or whatever, don't write only when you feel inspired.
Oh, God, no.
That is the surest way to shoot yourself with writer's block.
Like learn the skill of being able to write on command.
Even if it's not good, you can go back and delete it later.
But what determines whether or not you write should not be whether or not,
like you are excited to write.
Which is pretty much true about anything worth doing in life, right?
Yeah.
I mean, people say do what you love.
And there's a way in which that's true.
Like you shouldn't try to be an author.
It certainly doesn't pay very well.
If you don't like writing and hopefully most of the times that you go to write
or do anything, you enjoy it at least at some fundamental level.
But if you can't, if you can't take it when it's bad,
you're just not going to be able to have it be good all the time.
And it will slip by when it stops being fun.
How long did it take you to write the two books?
So I started writing Crystal Society in March of 2014.
And I finished in December, I think.
That was the manuscript, first draft.
And then I did editing various edits throughout 2015.
And I published in January, 2016.
2015, I wrote Crystal Mentality, which just got published.
I did edits this last year.
So it takes me about two years to per book.
But that's doing editing and writing in parallel.
Yeah.
And also they're entirely reasonable
while you're holding down a day job at the same time.
That's right.
Yeah.
So I've got a full-time job doing software development.
And like I have social life and I do rationality events
and all that sort of stuff too.
So being able to time box it and say an hour and a half each day adds up.
Yeah.
Yeah.
And eventually you get to the end.
Exactly.
Yeah.
But yeah, it's definitely a long process
when you have other things going on in your life.
And it's not like your full-time job.
One novel every two years is actually pretty good, in my opinion.
Well, it's a novel every year.
Because like I said, I'm doing editing and writing in parallel.
Oh, right.
Yeah, no.
Okay.
And a novel every year is fantastic
if you're holding down a day job too.
I could probably give it to be a novel every year
with writing and editing.
But I feel like that I have to give myself some space
after I finish the first draft
to be able to go back and be more impartial about what I'd written.
I think that the trick is to not get lost in all that remains.
On a day-by-day basis, and this applies to any sort of project,
just think about the next line, the next chapter,
the next feature, or whatever it is.
And set aside a regular amount of time
just to incrementally work on that problem
and it will get solved at some point.
This will be a question for both of you guys
because I don't have no creative impulse.
Like I had a blog where I kind of did what you did
is I made sure I wrote something every day
and it would typically take half an hour to an hour.
But then I did exactly what also you said not to do,
but this was, I don't know, five years ago,
which was once I got bored with it,
I didn't force myself to do it.
So I had like a few lazy days over the year
where I was doing it and I would put something out.
But then I got bored and just gave it all up.
But that was all like short essays or something.
There was no, I don't have,
so when I say I don't have creativity or a creative outlet,
it's that I don't have, there's something in me
that like some people paint, some people draw,
some people write.
I have nothing in me trying to get out like that.
I might be trying to like articulate a thought or something,
but I guess I'm not sure if this is the kind of question
that's answerable, but where on earth do you guys,
where do these universes that you create and write,
where do they come from?
Psychological trauma.
Right ready for that one.
So deep childhood issues, are you?
Right.
So Max obviously is secretly a robot.
No comment.
Totally not robot.
I think that, I think that there are two things.
I think that on one hand there's probably something
that's just unlike storytelling and I have for my whole life.
And there's probably a way in which some people are drawn
to storytelling and some people aren't.
But I think that maybe the more interesting component is,
it seems, I've yet to meet someone who really doesn't feel
like they have an idea that they don't think is valuable
and that they wish more people knew about.
Stephen is raising his hand.
Stephen, do you not have an idea that you feel is valuable
and you wish more people knew about?
I mean, not an original idea.
Okay.
But what is an original idea?
I mean, let me put it this way.
If, so Harry Potter and the Methods of Rationality,
okay, this is a fantastic story, loved by thousands.
What is the original idea in there?
Like what if Harry Potter had like science, right?
And thought about things in a clear and thoughtful way.
That's just a remix.
But it's a remix that depicts useful things, right?
Things which are important to see, not just like on a deliberate
or philosophical or abstract level, but see in a visceral
like moment-to-moment basis.
What does it actually look like to spend five minutes
thinking about a problem?
It doesn't have to be a novel idea for it to be a good idea for a novel.
Was that an accidental sentence or was that a cash quote?
Because that was...
I made it up on the fly, but...
That was awesome.
It just has to be something which when the reader reads it,
they go, huh, that's really cool, right?
That's all that's necessary.
There are hundreds of books that have fantastic ideas in them
that people don't read because they're not written in such a way
that the person reads them and says, huh, cool.
Instead, they say something like, this is boring.
And then they put it down.
Yeah, I've seen this a hundred times.
That's actually, I think, a good way to put it.
So I take back what I said.
When I said the original idea, I guess I meant I wouldn't be able
to create the Harry Potter universe from scratch,
but I could think of a fun spin to put on something existing.
And so when I would write blog posts, I would try and synthesize
ideas that I'd come across into something kind of fresh.
And so that wasn't me creating something new whole cloth
that was kind of just weaving two things together to make a new fabric.
I mean, if you read enough about creativity, that's what creativity is.
There's no such thing as making something new out of whole cloth.
I believe the term is everything is a remix.
And it's really true.
Everything builds and remixes on what came before.
Like you said, I couldn't make the Harry Potter universe up,
but neither could rolling.
I mean, it's based on a deep tradition of lots of fantasy that's been written
and based on her tradition of British boarding schools.
And I mean, there's, yes, there's some new and interesting elements
that she put in, but it builds like everything else.
It builds a lot on the society around you
and what's already out there in the zeitgeist.
Fair enough. I guess there's a lot when you said,
when you read a lot about creativity, it didn't even occur to me
that there was established writing on the subject of creativity.
Oh, yeah.
I'm sure there's creative ways to present ideas about creativity.
I believe it's been said that the secret to creativity is concealing your sources.
Yeah, exactly.
People will be like, wow, this is a fantastic new idea.
I can't believe you thought of it.
And then you like hide all your reference material.
And you're like, yes, I came up with all of those ideas.
The first story that I managed to get published was heavily inspired
by the evil overlords list.
And a number of people were like, this was the greatest thing.
I can't believe you did that.
And I'm like, it's it's number 17 on the list.
The button that kill the self-destruct button that actually just kills you.
Yeah, I really do think that like this remix culture mentality is a very healthy one.
It's one where you shouldn't be asking, like, is this a story which no one has ever told before?
Just ask, is this a story which you want to see more of in the world?
Right?
Is this like the kind of story that appeals to you or is interesting to you for some reason?
Because there's, you know, there's no reason why you can't just have another story.
I mean, goodness knows, Hollywood does this like to the millionth degree, right?
Just telling basically the same story over and over again.
My inner contrarian will will object to the idea that there's nothing new and that everything is
just mashing up two ideas.
Clearly, there's some generative process which is creating, but it couldn't.
No, I agree.
Obviously, because the the best things are things that are new and that you haven't seen done before,
but they need that mulch of prior work to to feed them and nurture them before they can.
99%, 99% is stuff that just came before in other forms and shapes.
And then you put in that, like, dash that seasoning of, you know, whatever
inkling came to you in a dream or something like that.
Right.
And it's kind of like when someone writes their thesis to get a doctorate,
they're supposed to expand the human body of knowledge in some tiny way.
And I feel like every creative work is kind of like that where you're using tons of what has
already known and been done before you and just expanding the sphere of originality a little bit
if you're doing it right and putting a little more original stuff out there.
That makes me feel better.
I did have one little foray into writing a creative story.
I did one of the submissions for the slash rational whatever.
I don't know what the prepper syntax is for naming a subreddit.
The rational subreddit does a monthly writing prompt contest.
And I think the winner gets a month of reddit gold and something else.
But the point is that everyone gets on and reads them.
And one of them was like a new take on a Disney story.
I think it was what it was.
And I remember as a kid, they didn't even they kind of waved away the idea of wishing for more
wishes in Aladdin.
Like it was just against the rules.
Yeah.
And for me, you know, so like what if you could wish like not just for more wishes explicitly,
what if you could wish for the powers of a genie?
Which which actually happens in 11 to if I remember correctly.
Oh, I didn't see that.
It doesn't have to be the end of Aladdin.
It's at the end of Aladdin.
Oh, Jafar becomes a genie.
Yeah.
It'd been a while.
I just remember I remember Robin, Robin Williams's songs.
But so the little the little nugget, I think that I don't think I read this anywhere.
I'm sure someone else independently came across it.
But Aladdin thinks about that actually thinks about the problem, considers the the genie path,
but then geniuses know that didn't work out with this last person.
So he's like, OK, there's there's a prohibition on wishing for more wishes.
I wish there wasn't a prohibition on wishing for more wishes.
So he wishes he wishes away that rule, then wishes more wishes, then has infinite wishes.
This is exactly what rational fiction is like, right?
It's like, no, imagine you actually got this power.
What would you how would you try to break it?
Munchkinery might be in parentheses in some of the bullet points of rational fiction.
The idea of figuring out the rules and then how to abuse them.
Yeah, I think that there's really two major sub branches of rationalist fiction.
And I was having a conversation about this the other day because we were talking about
rationalist animorphs. I'm reading Duncan Sabian's Animorphs Rational Fick.
Yeah, the what is it the reckoning?
Yeah, I think that's what it's called. It's fantastic.
Two thumbs up, at least if you're an animorph fan.
But the way in which that universe is turned into a rational universe is where like all the things
are changed so that they make sense and all of the characters are sort of like have their
wisdom and intelligence meters cranked way up,
which is a little bit different than like Harry Potter and the methods of rationality
and where mostly it's just Harry that is more intelligent and more rational.
And I feel like these are the two major branches where it's like,
is your entire universe more inconsistent and like just more of what we would expect something
logical? Or are we watching like a single rational character get inserted into the universe
and then exploit all the loopholes, which you know, the original author or whatever invented?
Yeah, that's a good dissection to make for the for the second category. I'll pitch Harry Potter
and the natural 20 is is a I think it sort of died off after book three and they're not
Harry Potter book length, but it covers each year. And the main character is Milo.
He was transported to the Harry Potter universe from a Dungeons and Dragons universe.
He operates on hit points, experience points. He and he can't do Harry Potter magic, but he
can do his magic, which he can cast, you know, a spell or each one of his learned spells every
once a day. Oh, my God. And it's a lot of fun. And it's exactly the months can read one. Well,
that's exactly his whole thing. And so there it was very enjoyable. I found myself laughing
out loud reading it more often than I did any other any other short story. So can't put that one
high enough. There's something else. Oh, if you guys wanted to, I'm not sure if you guys want to
dive into this or not. I thought worm was another good candidate for what I consider rational
fiction. And I think worm is a good example of something that's more like the crystal trilogy
in that it's entirely novel. It's not fan fiction. But it clearly is inspired by lots of the ideas
that are part of our specific subculture. And you can you can see the the characters doing very
intelligent things. And it's sort of satisfying to to have that as a relief from the day to day
like movies where no characters are thinking about anything really.
I still like the Marvel movies. But yeah, I mean, so I kept thinking of worm when we were talking
about like where the creative process comes from and how how it's about synthesizing new ideas
from existing ideas. So the author doesn't invent superheroes, you know, that idea has been around.
What he does do is really so I mean, without spoiling anything about the plot, you've got,
I don't know, some, I don't know, on earth, there'd be maybe a few thousand people with superpowers,
max, and the the powers can range anything from, you know, standard Superman to like the protagonist,
she can control bugs within a few blocks of her rate of her location. And you would think like,
okay, so she's on a world with Superman, what does what does she do? Well, she gets creative.
And that's the main enjoyable part about the story for me is that people have some mundane powers
or some interesting powers, but use them in, you know, really creative ways. And you would think
this book was written by a team of people, or I mean, the author must just have been on creative
overdrive to think of not just like some really convoluted powers, but then really creative
implementations of them, you know, one person can it's like micro telekinesis, you know, like where
I'm thinking of a perian or parian, however you say her name, she basically she sews together
stuffed animals that she can then kind of keep inflated from the inside at the stitches and
use them as like decoys or, you know, vehicles. But her like the specifics of her power are really
confusing. And then there's the one guy clock blocker, he can he can stop time on what he touches
from anywhere I think between 30 seconds and 10 minutes and it's random when he touches it. But,
you know, so that would be great if you want to just run up and touch the bad guy. But he carries,
you know, in his utility belt, like loose leaf paper. So he can because the thing is when they're
stopped in time, they're all they're they're stopped in space, they're as immovable as Superman is,
I don't know what would happen if Superman crashed into one of these things. So he if he's under
bullet fire, he can throw up a piece of paper and pause it with his power and it stays there and
it's indestructible. Or you know, if there's some rampaging monster, he can do that to a piece of
fishing line. I'm listing off these examples because I found them really exhilarating whenever
new characters introduced, you would some of them have a somewhat standard power set, but they're
really creative with how they implement them. And I find that really satisfying. Worm is very cool.
I am when I read Harry Potter, the original Harry Potter, not the methods of rationality,
what I thought united the series was that it was is a set of books that are about bravery,
they're about showing what it means to be brave. And when I read worm, I feel like the same thing
is happening. But for creativity, it's really satisfying. I agree to watch, you know, okay,
so here is this character's powers. How do you, you know, creatively use those in the most efficient
way, again and again and again. I did want to ask, do you think God, I don't know if this is a bad
question to ask, because I don't want to like, make it sound like anyone's putting on errors or
anything. But do you think the book would would help with the drawing attention to the AI alignment
problem if people were to read it? I do. I think that while Crystal Society and the sequels are
written to be interesting, first and foremost, and entertaining, especially to people who have
rationality ideas, there are definitely accessible introductions to AI safety risk stuff that like
just random intelligent people can can get into and enjoy. So if you have someone in who
is intelligent, but like maybe is not very familiar with AI stuff, and you don't want to point them
towards, I don't know, like a nonfiction work, something like Nick Bostrom's Super Intelligence,
which is a fantastic book, but not everyone's cup of tea, telling them that they there's this
novel that they could go read for free online or something like that could be another way to get
them involved. Methods of rationality serve that double purpose too, right? It's true. This is a
good introduction to the general concepts of rationality. Exactly. So I mean, I think, you
know, it could be written for it was written for fun. And, you know, to for at least as far as my
understanding of what L.A. has eroded for, it was a fun practice forum. He enjoyed the process of
writing. And it had this sort of intended collateral damage of getting a lot of people or anyone who
read it a much higher probability of being interested in the kind of work he's doing,
which also happened to be very important to him. And if you're, if you agree with his premise,
he's very important to everybody. I think that that having that sort of that dual purpose for
a novel is is not just I think fiction when it's done well has often served that role in humanity
to get people thinking about things that they otherwise wouldn't but which are important for
the coming future, especially like sci fi and fantasy, speculative fiction in general has really
been good with that sort of thing. I agree. And you know, of course, it has to be entertaining
first because otherwise why would people read it? Right? Yeah, that's a good point. Is there
anything else you wanted to say or anything that we didn't ask you but we should have? I mean,
no rush. I mean, if you've if you've got time, we can, we can spend a few minutes talking about
whatever you want. I could talk about all sorts of things all night long. I think we didn't touch
on a lot of, I don't know, rationality community stuff that I'm interested in and involved with
and so on and so forth. But I guess just a last note on the topic of rationalist fiction. The
Machine Intelligence Research Institute, which is Mary is running a monthly prize. They just
started it up for authors that they feel are contributing to understanding the nature of
intelligence, artificial intelligence, or the AI alignment problem. They posted a link on
r slash rational a while back. And my guess is that this is going to get scaled up with time. So
this is a monthly prize. If you feel like you want to write stories that might help out like the AI
alignment sphere, there will be a link in the show notes, I think, probably where you can submit
those to Mary and maybe win some money. And I would like to point out that you, I mean, writing is
always good and I encourage it, but you don't have to write to contribute to this if you don't want
to. The the prize is for any piece of work that was published in the past two months that furthers
this goal. So if you just read something online or in a magazine that you think is a good contender,
you can submit it to Mary. And then if Mary judges it worthy, they will give the $100 to
that author if that is if I understood correctly. Yeah, I'm not sure where the $100 goes in that
case, but it's always a good idea to, I guess, direct people towards these sorts of stories and
make the best storytellers win, I guess. Yeah. Man, what a someone's job right now is to sit and
read some interesting fiction and fun essays. There's a lot of people whose job is that,
but a lot of the fiction they end up reading is not very interesting. That's true. I guess you
have to slog through some stuff. Yeah, you can be a slush reader for one of the magazines. Yeah,
I was going to say, I mean, that sounds fun, but then I think about doing that for a month and that
sounds exhausting. Yeah. All right, so I take that back. It doesn't sound as much fun as I initially
imagined. I think that's it then. Yeah, I think we covered a lot and thank you for coming on with
us. This was very enjoyable and I'm looking forward to reading mentality. Thank you so much
for having me on the show. Yeah, I'd love to have you back on to talk more about some of the topics
that we only touched on. Yeah, building community is really one that I want to touch on here in a
few months. All right, well, I look forward to my possible return. Awesome. Well, if you're open,
we're open. Thanks, Max. Thank you. Thank you. Bye.
