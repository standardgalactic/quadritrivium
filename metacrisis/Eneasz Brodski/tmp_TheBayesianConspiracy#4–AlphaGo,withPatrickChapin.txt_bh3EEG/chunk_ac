was, it was, I mean, it's obviously somewhat hyperbolic, but it was actually from AlphaGo's
estimate, less than one in 10,000 chance that a human would make that move as well. It was actually
it was the most surprising thing that Lisa Dahl did in the match. And it was a move that was,
it was off its scale. It was the, you know, where it could not imagine that a human would do this.
And as soon as he did it, the people watching were just like, that's brilliant. They didn't
know how it was going to end or where it was going to go. But they could tell you would not do this
unless you were setting up this, this, this big plan. And it, it looked like it might not,
it might, it looked, it's actually the next 10 moves after it looked like AlphaGo is making
blunders. What's going on? Why is AlphaGo making these slack moves? And they realized AlphaGo thinks
it's winning by a lot. It's playing so conservative. It thinks it's winning. And then 10 moves later,
suddenly AlphaGo's percentage chance of winning the game, according to itself, plummeted rapidly.
What happened? Why, how could it possibly have dropped that much that fast? Like,
it went from like 70 something percent to like 28 percent or whatever. What happened?
And AlphaGo said 10 moves ago that it blundered. It just didn't realize it. It didn't understand
the position 10 moves ago. And it was too late now. And then it started playing desperate where
it started doing crazy things to try to like the type of move that if it works out, it would be a
huge win, but it's never really going to work out. It's just too easy to see partly because it,
it thought it was losing by so much that it started getting very, very desperate for
what moves to make. But it also didn't take into consideration, Lee Sedol has no time on this clock.
If the computer would have just been playing quickly, it would have, it very likely would have
beat him actually very easily because it was a very complicated game that went on for over two
hours with Lee Sedol having no clock where he just was just having to just play. And it was like
an incredible test of his constitution, but also the computer just not understanding that it shouldn't
take the full amount of time every turn to think about its moves. Okay. So can the developers
fix that and what caused the blunder in the first place? Yeah, absolutely. I mean, they,
they definitely could never even occurred to them to have Alpha Go change how much time that it takes
based on the other person's clock. You know, Alpha Go, one of its flaws is that it always
thinks that humans are making decisions at peak human level. Like it doesn't evaluate, oh, you've
been making some mistakes recently, or you're in an emotional state where you might be compromised,
or you don't have any time on your clock. It actually just assumes that humans behave
sort of like a machine. So on the chain of bad moves and the kind of traps that it laid,
that that Lee Sedol made laid for Alpha Go, is that the kind of trick that a human Go player
of Lee Sedol's level would have felt fallen for? Well, what Lee Sedol did was a play that was brilliant
at any level. I mean, it would be very, very difficult for a world, like world class player
if once they're in that position to, to defend against. But the problem was that Alpha Go
actually started making crazy, risky moves against Lee Sedol, and no world class player
would fall for the things that Alpha Go was trying. Alpha Go just thought it's so desperate.
Let's get some humans sometimes fall for this. And so it's like, even though this is a small
percentage chance, it has seen that some humans would fall for this, but not Lee Sedol. Gotcha.
Wow. Part of that was just that it thought at first, it thought that it's winning by so much
that it can be just giving away edge, because it's just playing conservatively, where it just wants to
if you willing to give up 10 points, because it's like, oh, this gives me a 2% chance better
of winning, but it just didn't understand the board position. And then later it thought,
I'm losing by so much. I need to do crazy things to try to win.
So Alpha Go is very much less good when it thinks it's winning by a lot or by a little and is wrong.
That's real. I just want to quickly say, listening to you tell this story, it's hard not to,
to throw my hopes behind Lee Sedol. And you know, this is such a John Henry driving railroad
ties story. Are they called railroad ties? Yeah. Yeah. Yeah. Where you just really want him to
win against that steam powered tie driver. But so Lee won that fourth game. Can I go back to your
question? When she asked that, you know, the human programmers could program around that.
They're not going to change it in the middle of the match either. No, no, no. Just not in the middle
of the match. But wouldn't, isn't that kind of, doesn't that feel like cheating? Like,
isn't it something that you would want to make an AI that can recognize that and fix it on its own
rather than humans having to come in and patch it? Long term. Okay. But, you know, this is,
this is just one more step along the way towards the, like my real question isn't,
can we patch the problem? The real question is, can we make an AI that can self modify so that
it sees this problem and fixes it? Yeah, it's not so much that we would patch the problem,
because that's not how it operates. It's more of a, we would give it another access that,
another access that it can explore for determining how to fix itself. Because right now it doesn't
even have the ability to change that part of itself. But absolutely, it needs to be able to do it.
It's so unlikely that a human could just predict the right amount, the right patch. So to speak,
it's just much better to let the neural network build its own patch. The fourth game, though,
was crazy because for like an hour, an hour and a half, it's like, okay, Lee Sedol is definitely
winning. He has this game locked up and the computer is doing crazy, ridiculous, awful things.
Lee Sedol has to have the game won. And the other guy's like, you saw what happened before. We
thought it was crazy. This has to just be some genius master show. He's like, there's no way.
There's no way. There's no way. He would never, this is just horrible. And then at the very end,
eventually, AlphaGo resigns. If AlphaGo's probability of winning drops to a low level,
it resigns because it just starts playing more and more embarrassingly. And they're just like,
let's just get it over with. It's below 20% I think? Yes. But it's also kind of a weird 20%
because it's 20% among humans. And it starts to spiral out of control. Because as we've seen,
when AlphaGo thinks it's losing, it starts becoming more and more desperate because its only goal
was to maximize winning, not avoiding looking foolish. And so after game four, the fact that he
actually won, he's already a national hero in South Korea anyway, but this is like this great
redeeming moment. And actually he had in game five, he could have had the privilege of the slightly
better position, but he actually requested the to play black because he had already won. The one
he won, he won with white. And he wanted to, he actually asked Google if it would be all right,
if he played from the black side, because basically just as a sort of pride, like I want to try a
chance, partly AlphaGo is better from the white side. They realized is that a start side? Which
side is the start side? So black goes first. Got it. So it's at a slight disadvantage. Yeah,
it has to make up a seven and a half point handicap. And it is at a slight disadvantage,
but also AlphaGo exacerbates this. Like AlphaGo is very good at defending. And so they play the
fifth game. And the most remarkable thing about the fifth game, because there was a question
watching it is, is Least at all just going to demonstrate the loop? Like is he just unbeatable
now? Is he just going to beat the computer? Or was he lucky? And Least at all immediately adopted
a very, very aggressive attacking position and took lots of territory all over. Because after
analyzing the fourth game, he realized AlphaGo has a weakness in understanding when, like when you
take lots and lots of territory all over the board, it loses track of, like it doesn't have a
great understanding. It doesn't have as good of an understanding in, and this, this is not the
kind of game that Least at all would want to play normally, but he can play any style. And
in the early game, it seemed as though he was just routing AlphaGo. They were actually wondering
if AlphaGo is going to resign because he looked like Least at all was winning by so much. Now,
AlphaGo actually did not believe that it was losing by as much as the humans watching believed
that it was, but it thought that it was losing pretty clearly. And it would, but it's one of
those Least at all's plan worked marvelously. He gave himself a 60-40 edge. And in the end, AlphaGo
got its 40% and got there. Because even if you pull off a 60-40 edge, it doesn't mean you've won.
It means you are 60% to win. So in the end, 4-1 in favor of AlphaGo. And that one may be the only
one ever that AlphaGo will loses because I got a feeling that when it plays against Guli in the,
the best Chinese player in the future, which I assume will be the next match they set up,
I do not think AlphaGo is taking any losses.
So do, there's a lot to process. I'm trying to get to the, I guess, the next
way to look at this. So I think, is Google going to go and do any revamping whatsoever?
Or any, any, any, so when is the, anytime scheduled or announced yet?
Okay. So they've got some time to, to make sure that's not vulnerable to the same maneuvers that
Least at all was utilizing. It's not so much that they're making sure that it's not vulnerable.
It's more of a, they've warned lots of new places to let the neural network be able to explore and
try new things. And additionally, it's going to be thinking about the game more. AlphaGo gets better
all of the time. Like it, it thinks about the game a lot. And part of that involves playing
millions and millions. I mean, it's only played about one human lifetime worth of games against
opponents, but it plays against itself in its head a lot. It has literally nothing else to do.
Very, very little else. Once in a while to do an exhibition against the world champ, but
it mostly just thinks about go.
Why are we having AI systems play games? Why is that really important to be happening now?
So AlphaGo is a general learning algorithm. It wasn't designed to play go. It was just designed
to learn and think. And that's part of what's so fascinating about it is that like, for instance,
when some of the previous games that AlphaGo learned, AlphaGo learned how to play, the deep
mind learned how to play Pong. And it's just the best Pong player in the world, which is kind of
bizarre to watch it play because it doesn't play like a human would. They had it look at every
YouTube video on the internet and identify which ones have cats, which ones have humans, and what
are all the cats and what are all the humans. And it's kind of crazy the amount that this same
system is learning how to think about things, like it's figuring out how to make relationships
between things. It's a very intuitive program. I mean, it's properly described as intuitive,
and some have described it as empathetic. It's continually trying to understand the world view
of the other actor, like what are their values? What are they going to do? What are they? And
the hope is that this can be used in any number, and basically every other area, everything from
optimizing street lights to where to investigate for medical advances to where to drill for oil to
how to efficiently move resources around to where to build a new power plant. Basically,
just things that people think about. The hope is that systems like this will be able to think
about them better than a human would be able to and accomplish these tasks better. It would be
great if AlphaGo is better at Go than any human in the world. That's great for winning a Go,
but imagine if we had something that was that much better than any human in the world at
figuring out what combinations of chemicals to put together in order to cure some disease,
or how to lay out a city so that there would be less traffic or anything like that.
Or how to do accounting really well. Absolutely. So why is it playing?
That's going to be my next question. How much longer till we're all unemployed?
Unemployed is kind of an interesting thing. I mean, sometimes when you don't have to carry
the heavy load yourself, you're a little bit more free. Is it that you're unemployed if they don't
need you to drag the plow across the field, that the robot does it for you, and then you get to
spend your time recording podcasts? Why are we so concerned about this computer playing Go
when we could be more concerned about it taking Inuyash's job and doing accounting,
which might be, which would be significantly more useful. Sorry, Inuyash.
That's true. I don't know, it depends. I think different people are concerned about
different things. I would guess he's more concerned about his job being taken. But
I think that the big thing is this AI is a big step forward for, I think super AI is the real
thing on the horizon. But there's also just some of the AI systems like recently,
it was revealed that there's an AI system called Skynet that evaluates people and determines things
like who the drones should go after. So it's really important to know the state of affairs of
where AI is and what we can do to improve it, because one way or the other,
AIs are continuing to get built and will be stronger and stronger in the future.
Would it be fair to say that we're not at a place quite yet, we're at a place where
human go players can be beaten by AI, but human accountants cannot be replaced by AI yet?
That we don't have that technology, that Go is kind of at a different level?
We did, I wouldn't have a job right now.
Not necessarily.
A big important thing here is the difference between
perfect information games and hidden information games. Accounting, funny enough,
is sort of a hidden information game. And Go is sort of the final frontier of perfect information
where it's just like, okay, this is clearly computers are just better than humans at games
where all the information is known, where there are concrete sets of moves you can tell when the
game is over. When things involve hidden information and undefined victory conditions
and endpoints, that's, there's a lot of rich area to explore in that area. And well,
AIs will continue to replace humans in different areas. It's hard to predict which ones are going
to get replaced first. And I don't think that there's any reason to believe that accounting
is next on the chopping block. So the trillion dollar question is how long until deep mind or
a similar AI program is better than any human at designing AIs?
Well, in some ways, there already is.
Well, so it deep mind, I mean, the neural network is already
incomprehensible to humans. Like, why is AlphaGo making the decisions? Like, how is AlphaGo
doing the things that it's doing? It's not clear. It's tried lots and lots of combinations. And
there's like this sort of, it's almost like a tower function that maybe maybe humans are higher
up on the chain where the humans are still the ones who can unplug it and the humans are still
the ones directing it. And maybe it's not too far in the future for when AIs will be better at directing
it than humans. Because already we have AIs are much better at than humans at making a specific
type of AI. Like if the AI, you need to come up with some artificial intelligence for a
particular thing. And AI is much better at figuring out how to do that thing in general,
for at least for perfect information systems. Now when it comes to just making AIs in general,
I think that when a computer is better and has the direction, at that point, there isn't really,
there isn't that much game after that. Like, all of the games before that, because at that point,
the die has kind of been cast. You mentioned when we spoke about this a couple weeks ago,
that your estimate for the timeline of this draped radically in the last couple of weeks.
This is the first time that my, my, I guess if you could call it a, I think that the most likely
scenario is that the AI will be in charge. The AI will be, there will be a super AI and it will
functionally be God and sovereign. Yes. Do a little callback. We did a, some homework to look up some
of the technical definitions that LAIs are brought up in our last, or I guess in episode three.
And before you thought this wouldn't ever be a thing that could happen? No, no, no, I thought it
would be, but it's more of a, instead of, instead of, you know, by the end of 2040, the 2040s,
maybe a little closer to the beginning or possibly even the late 2030s. I don't know. This is such a
unexpected jump forward and the system that they've described is so widely applicable. Like, so
the, the, the, the two different styles of combining the neural network, you know, the,
combining deep learning with the, the look ahead ability that it has. I think that this is
really decreases my confidence that I can even meaningfully be able to predict when
certain things are going to be unfolding because it's going to happen very, very radically and
likely by surprise. I have a question for all of you. Okay. Are you frightened?
I've always been frightened. This moves my frightness up a little bit, but I guess that
means I'm a little more frightened since then we have less time to, to figure out the friendly AI
problem. You, I remember you were very pessimistic when we talked a few weeks ago. You were kind of
pessimistic. I don't know if pessimistic is what I would say. I would say you thought that we did
not have enough time left now to do it. No, no, no, that's not what I'm saying at all. No, no, no,
I'm saying that there isn't a, I would say if you're describing pessimistic as a funny word,
because I wouldn't even describe myself as frightened. I don't think there's a ton of utility
