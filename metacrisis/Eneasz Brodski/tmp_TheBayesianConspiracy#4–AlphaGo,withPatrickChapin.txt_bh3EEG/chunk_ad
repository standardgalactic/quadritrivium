in the fear. I would say perhaps motivated. I think that it is unlikely that one could
stop there from being AI, like from being a super AI eventually. I think that most likely the best
way, if that's your only goal, the best way would be annihilation. But I think realistically there's
going to be, that there's going to be super AI. I, I don't know, I got to take the position
though, just play to your outs. Like, we have an opportunity right now to help shape things as
best as possible. I also think that some of the factors that go into whatever that world is
are so incomprehensible to us right now. I don't overly worry about it, because it's very easy to
imagine how scary the world one might be. But I can't possibly evaluate the decisions that are
being made in that world. It's, it's like looking in, you know, like an ant can't evaluate the,
the position, like the decisions being made by humans in a meaningful way. And instead, I think
that you kind of just, when you're the ant, you evaluate, are you going to take this little
kernel of corn back to the, you know, to the colony? As people though, we have the opportunity to
affect policy. We have the opportunity to sway the decisions that corporations make. And if more
people maybe have their nervousness meter up a little bit more, that could pave the way for
more research into friendly AI, pre super AI. I wanted to say from your initial question that my,
my anxiety level and my eagerness level both go up. Because, well, because there's a lot of ways
that could go wrong. You know, even, even if exactly they're, they're way more ways that go
bad than it can go right. So my, my thinking is that I guess I personally don't like being left
out of the loop, even though that's that kind of has to happen of, of even a good future, like
it's not going to consult me first. And see, actually, that's one of the areas that I think that it is,
we don't know enough to be so sure. I mean, how do you know that you're not going to be able to
have an increased level of awareness and understanding, like for instance, being augmented
by AI or having all of the, like think about how much knowledge you have access to now that you
could not possibly have had access to 15, 20 years ago, not only, you know, growing up and having
all the experiences you've had, but also the technology, the fact that you have a smartphone
and can just get 99% of the world's knowledge at will. It's, it is fun to reflect on that
anywhere that I have cell phone reception, I have access to more information than the
president of the United States did 20 years ago. Absolutely, more than existed. Yeah. I mean, like,
so I think that if you just look at just how much power, how much knowledge, how much
awareness and understanding you have at your disposal now, there is no reason to think that
that there can't be futures in which you continue to increase your awareness and understanding.
And even if you don't, at a certain point, there's also the
your children carry on like this, this is the philosophical thing that I wanted to ask you
about because I saw Hugh Howley, who wrote the world series was recently posting about
how right now we are watching our baby AI grow. Yes. And every time she does something like beat
her chest, chest, grandmaster or go grandmaster, it's like, look, she took another first step.
This is so amazing. Why is it a baby girl? I saw the headline. I saw the headline.
The buzz, buzzwords headline and assuming because he thinks baby girls are cute. Sorry, women,
it's a baby boy from now on just to be clear. How about just a baby? Why does AI have to be
gendered? Because ships are ships are girls. Whoa, we can talk about that another time.
Isn't that the thing our vessels named after traditionally girls? Oh, good. Having, having
never or female, I guess, right? Having, having never been on a proper example of something sexist.
See, I actually think that part of the reason why they default that way is the wanting to help
bias a way for like, there's been a historical bias where a lot of males will design systems or
tech and just talk about it in very masculine language that is not as inclusive as with the
use or like ships. A lot of times they talk about it with with female pronouns and as female entities.
Ah, yes. Like the race, like, for instance, describing their baby. They're, you know,
this is the thing I made and speaking almost diminutively, right? I mean.
Right. I think he was trying to make it really cute. And so, you know, you, you call it a baby,
humans are used to babies being gendered. So he was going to have to pick a pronoun.
I don't want to derail this. I really don't, I don't want to derail this conversation to be about,
about gendering things and things being biased in favor of gendering versus not. So
let's move on. That aside. So I, yeah, I wanted to ask about the whole children thing because
there's a lot of, a lot of thought along the lines of, well, this is the next thing we make.
This is the next step in life on earth. And so these are like our children. But I personally
do not really want to die ever. And so I don't want to become irrelevant either.
So are you okay with changing?
Yeah, I'm totally okay with changing. But isn't there a theoretical limit to how much a human can
change before they're not human anymore? I mean, are humans today humans the same way that cave
people were? No, not, not even a little bit. Is it okay? Like even though the cave people might
be really attached to the way that they were, it's pretty easy to imagine that it's better,
humans now are better than the way that cave people were 100,000 years ago.
It is. It's really weird to just recently read an article about this tribe that doesn't have
counting, like one of the few in the world that still doesn't have counting. And you read about
their way of life. And it's so bizarre. I literally felt like I was reading about a different species.
I was like, I, I cannot empathize with these people as humans anymore. I empathize more with
my pet dog because it was, it was the most bizarre thing. And yeah, no, we, we are significantly
different. And are we losing something? Can we even become a different thing and keep ourselves?
Yes. Well, I just wanted to, to give a quick two cents answer on that, that I'm thinking
if I were a cave man from 140,000 years ago, and I could have it sufficiently explained,
I probably couldn't have it sufficiently explained to me what it would be like to be
a person in the 21st century. But now if I could, if I, as that person I could grow up and to be
that person for the 21st century, I would look back and say, I'm so glad. And now it's easy
having taken that perspective, I can imagine in some, some future looking back and saying,
I'm sure glad I changed. Yeah, but I think that may just be accident of birth. Like the cave man
would be like, these people never go chase after game and throw spear. Instead, they sit in front
of glow box and manipulate pixels on a screen. Where is the glory in manipulating pixels on a
screen when you can murder a mammoth? You know, but now I can shoot fireballs from my hands in
Skyrim. So, you know, in the future, the future, it's like, you were so content to throw pixels on
a screen. In the future, you can literally just rearrange atoms in a solar system to build things
and do things like work on problems that actually matter, like heat death of the universe.
Yeah, but can we? Or is that something so beyond humans that only a something so alien that you
don't even recognize it as human anymore can do? That's, I guess it ends up just being, what is the
important thing? Who cares? Who cares? I don't, we're all different one day to the next. I don't
think it's very important that that humans continues. And I think that, well, that's,
that might be overstating it. I mean, in the very long term, I think that's natural. If you want,
if your argument is, oh, we're going to be losing something, we always, we always lose something
through the history of the universe. There's always been change, right? I agree with you
entirely. If I could change, if I could change into that, I'm totally okay with changing into
that. I'm just worried there may be some level where my neurology cannot change anymore.
So who do you think is in a better position to evaluate this?
Well, assuming future AI's than me, yeah, but there is, it's theoretically possible that I
cannot be modified that much, right? Yeah, it's theoretically possible that you spontaneously
combust. Who cares? Fine. Okay. Right? Like, I mean, I mean, we care because we know you and like
you. Yeah. But no, I'm not like, who cares is in who cares about that tiny probability? Oh, yeah.
Like I'm talking like, do you really think it's a tiny probability though? I'm saying that it's
not like if you spontaneously combust, it's not like if you spontaneously combust, it's not like
you're like, well, I shouldn't have let some of these atoms move in this place. No, you could have
done about it. There's no way a human could think up move 37. That's not true in game four. He thought
of move 78. move 78 was as inhuman and as improbable as move 37. Way to bring it back. So brilliant.
That's what makes us so brilliant. So I for one, as a human, I'm very proud and excited about AI
babies. And I and I'm happy to hopefully they're going to grow up to be good and kind and wonderful.
And I'm happy that they'll be taking over the world. But as long as we program them to be good
and kind and wonderful, I don't come around in this whole don't be evil thing. That's a great
like when you first you got to define evil for the machine, though. I define itself. I'm worried
about that. And as you should be, I totally agree with you. So to bring things kind of back,
back, back, back to rationality. So we are all members of Denver area less wrong. And we are
broadcasting from Denver, Colorado, just some back information. And we're very concerned with
rationality. What is the connection between rationality and what Eneash and Steven, you
and I have been talking about on this podcast for the past few episodes and AI. AI's are,
if I can give a quick sound bite, the ultimate, the ultimate rational agents. So we're where
humans can be aspiring rational agents, we are still built with all of this weird ape programming
that worked great for hunter gatherers on the savannah, but doesn't work great for
optimizing decision making. And AI is, you can build from the ground up and not include all that
baggage. I think the the main connection is that if we're going to eventually make some sort of
superhuman thinking device, which will more or less become a God, we want to design it so that
it thinks well, and so that it values the same things we do. And that rationality were the first
tools to try to explore, well, not the first tools, but they were a major step forward in trying to
explore what makes thinking, how to codify thinking in a way that it can be programmed into a machine.
Not just, you know, intuitive thinking, but actually breaking thinking down into math,
and probability distributions, and how to make a machine learn it. That's a good explanation.
Yeah, I mean, that's that's actually part of the brilliance of AlphaGo's system of thinking. It
isn't just that it has a neural network that that can evaluate these positions. It thinks about like
it has an idea, you could say, based on, you know, just let's let's roll some dice based on what we
think humans would do, play it all the way to the end and see how that idea turned out and continue
to change its values. As it thinks about the problem, change its values and steer what sort of
ideas it has, based on what sort of positions is it getting to, and are we getting warmer or cooler?
And in many ways, it's like when a human thinks about a problem, and can feel like they're making
progress, like moving closer to the answer, even when they don't have, it's not like a partial
credit thing. It's like, this is the right place to be thinking about this is the right access to
be thinking about, you know, what surprised me is all of this neural network and kind of
natural not natural, but it's artificial selection way of developing the artificial intelligence
AlphaGo. I was kind of surprised that we used things that are already in place, evolution,
brains, human brains. One of my favorite, I guess, adventures with computing involving evolution
is a microchip that is self like, like a genetic algorithm, like it improves itself over time
for solving particular types of problems. And the people who were working on the chip as an
experiment, they were trying a variety of ways to effectively stress test the microchip and they
gave it a problem that the human quote unquote solution involves thousands of logic gates.
And they only gave it 100 just to see what would happen if it were under these extreme
conditions. And it was effectively when a sound is played, if the computer powers up,
that's a success. And if a different sound of a different frequencies played and the computer
powers down, that's a success. And then they just seeded it with 50 random combinations to see,
and then let it evolve over time where it would take different, some of the combination, some of
the seeds and reproduce depending on the success and, and continue to evolve and the microchip
would just evolve itself. And over time, and it took a while before the microchip was even like
responding to stimulus, like, real reliably, there was a lot of noise for a while. But eventually
they get to a spot where the microchip is actually producing the correct answer more than
50% of the time up and more than 50% down. And they let it play more, you know, hundreds of
generations, hundreds and hundreds of generations go by. And eventually, it's actually pretty consistently
getting the right answer. And eventually, after some number of thousands, it stopped
meaningfully evolving at all. And they were just like, Okay, let's take a look. It's done cooking.
I can't believe it actually solved the problem. And they look under the hood. And, and then to that
point, the guy leading the experiment was about ready to punch the other person or
experiment for for trolling him for like, why would you pull a prank like this on me? This is
just this is not funny. And he assured him there was no prank. And the security cameras in fact
affirmed there was nobody tampered with it. He he's like, this is this doesn't make sense. He
looked down. First of all, I was only using 37 of the 100 logic gates. This doesn't even make sense.
Second of all, 32 of them are are in one corner, where the power is, the other five are just in
a circle in the opposite corner, not even plugged in. What in the world is going on in the 32 over
here involves two little loops in opposite directions of current and a few logic systems.
But it's like, this is baffling. Nobody would ever make a microchip like this. This doesn't even
this is, this is nonsensical. And they looked and sure enough, it continued to work. And he tries
this as an experiment. He's like, Okay, first of all, let's take these five out, because he must
have just grown some vestige that wasn't necessary as an instantly it didn't work. And they're like,
how in the world is not even plugged in. So he puts it back and he tries sliding it over a little
doesn't work. So huh, what in the world? And so they're like, Okay, well, clearly, we're going to
have to like, we're gonna have to revise what it is we're looking for here. It can't be anything
that's possible. So we're gonna need to start coming up with ideas that are impossible to try to
describe this because and apparently the theory they eventually came up, the came to is that
when like, so that when you have the power on, there is a magnetic current, there's an
the electricity going opposite ways creates a magnetic field. And when the sound plays,
it vibrates the circle in the opposite corner, almost like a tuning fork, or I don't know,
a human ear. And it, it actually distorts the magnetic field in a way that causes what few
logic gates are actually plugged in and doing anything logic gated to power up or power down
the computer in response to that change in the magnetic field. And this is a radical departure
from how microchips are made by humans. I remember reading that same thing. And that was the reason
extremely effective. Yeah, you couldn't move it. All right. Yeah, it was like literally optimized
to that exact position relative to the computer on planet Earth. It was fantastic. That's awesome.
The one of the things I wanted to ask, which I think you sufficiently answered,
we can expound on it for much, much longer to anybody who who listened to the whole episode,
I'm glad I didn't ask this at the beginning. So I think an uninformed outsider could be like,
so what deep blue beat Bobby Fisher at chess 20 years ago, who cares? So why is this a bigger deal?
But I think that's been sufficiently covered. But if you if someone asked you that question,
and you weren't an elevator, what would you say in 30 seconds? Yeah, you have 30 seconds to tell
them why go is different than chess. 20 years ago, the best chess player of all time, or at least
one of the best Gary Kasparov was defeated by deep blue, but it was a system in which humans
taught the computer the strategy. The humans came up with the AI, they gave it the formula,
and it just relied on brute force and an enormous series of tools given to it by humans.
AlphaGo made its own strategy. AlphaGo, while it has an enormous amount of processing power,
is playing a game that cannot be solved by brute force. And there's not enough big enough universe.
And it is it made its own strategy and taught itself. And that's part of what makes it so
revolutionary. Awesome. I wanted to actually before we go any further, is there anything you
want to plug or promote at this point? Oh, God, that you can already promote at the beginning.
If not, we'll put it on the if you can't think of anything we'll put on the website.
I mean, down for whatever it depends. I guess you said a lot of people play magic,
author of next level magic, and a series of books on magic, write articles for spare city games.
And I got a music album coming out later this year, kind of excited about that other another
music album. But what's it called? I can't I hasn't come out yet. But the Gathering is on
YouTube, some of the stuff I did with Bill Bowden. But anyway, so it's a pleasure to remind Patrick
remind everybody of your full name so that they can look you up. And of course, we'll have this
