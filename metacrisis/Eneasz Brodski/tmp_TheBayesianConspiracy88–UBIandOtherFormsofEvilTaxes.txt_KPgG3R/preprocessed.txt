Welcome to the Bayesian Conspiracy. I'm Minyash Brodsky. I'm Stephen Zuber. I'm Jess Dickey.
And today we have a guest with us. Calling in is David Spearmanis. Is that how you'd
like to be known? Yep, that's fine. I am... I'm David. I've been bothering these guys by email for a while
and they finally decided to just let me say my piece on the show. I am definitely going to be sending them a
three-page email after this airs with other stuff I didn't get a chance to say, but hopefully I'll get to say
what I want to know. Excellent. Don't let this be an encouraging parable for anyone else who wants to try the same gimmick.
This only works once per podcast. Alrighty, so we have David Spearman on today to talk about UBI,
Universal Basic Income, which was last mentioned on the Yang-a-Ring episode and when this is, I think, near when this conversation started,
have you contacted us before? I think so.
Yeah, I think it was on the feedback episode. Yeah, but the first time was just like Jess, I think, mentioned offhand
something about UBI and you didn't really talk about it, but the Yang-a-Ring was when, like, it's the most substantive time
I can think of that you've talked about it on the show. Okay.
That's right. I remember that thing that you sent us was a link to, I think one of the ones that you sent us for the prep
episode that has been sitting in our, like, wait to get around this section for all too long. So here we are.
Alright. And why are we talking to you as opposed to, I don't know, someone else?
So you're talking to me because I am a graduate student, which means I have enough expertise, if I may say so myself,
to have interesting things to say, but I don't actually have, like, real grown-up commitments yet.
So I'm also willing to do things like come on to podcasts. Although, I guess you had Robin Hansen on and...
We did, but I think we managed to leverage Robin's kind of, like, grandfather of the rationalist movement
thing, emotions to get him to come on. So we snuck that one in.
Yeah, I feel like he's got commitments.
Yeah. Well, I don't. I'm also a UBI skeptic, so it's not just a matter of you guys bringing on a fourth person
who's totally on board to talk about how great it is. Hopefully we'll actually be able to have an interesting discussion
and learn from each other and stuff.
Good. I think we've had a lot of that in the past.
Yeah, anytime we all agree on something, it's sort of, like, not the most interesting thing.
Yeah, it's more fruitful. Plus, it's nice to have a consulting expert.
Yeah, and you were the one who wrote in about the abortion episode that caused us to have the little abortion non-episode
with the email response, and that was really good because finally we had someone with a little bit of pushback
to contrast against our opinions. So we're hoping you'll do the same thing here.
I generally don't like talking about abortion, so if anyone brings that up on, like, the subreddit or anything,
I'm probably just going to ignore it. No offense, I just...
It's a uniquely bad policy debate, epistemically speaking.
So, yeah, I'm not really interested in talking about that much beyond what I've already said.
Yeah, all that's in the past anyway. We're moving on.
We've already talked about it too much.
Yeah, on the bigger and better things.
Exactly. So, UBI, quickly, if anyone is just coming to this podcast out of nowhere, is Universal Basic Income.
It's basically the idea that everybody should get a certain amount of money from the government every month
with absolutely no qualifications or restrictions, no preconditions you need to qualify.
You just get the money for being a citizen.
I think just to caveat that definition that the most persuasive version of that that I've heard has some minor caveats,
which is if you're already receiving government aid, you don't get the UBI.
Right, or it's reduced by the amount of aid you're getting or something.
Sure. Or, like, I mean, to say if you're getting $850 in Social Security every month and that's all you're getting,
and UBI is $1,000, then you drop the Social Security and you can take the UBI.
Okay.
Yeah.
Yeah, I don't know if there's one model that UBI necessarily represents.
I mean, there's UBI could replace all of the federal programs.
There's, you said, paid monthly, there's different payment schedules.
It's still kind of in the works.
Have we said anything drastically wrong?
Not as far as I can tell.
Like you said, there are a lot of specific proposals floating around.
I think some of them are worse than others, but most of them have cheaper and more effective alternatives around.
So if you want to get into the details of specific proposals, I'm happy to do so,
but probably our time would be better spent just sticking with the basic everyone gets a certain check for a certain amount.
And most of the arguments I have to say about that would generalize to more nuanced proposals.
So.
Okay.
The first question I have about UBI is when I look at it, it seems basically to be a less frills and less restrictive form of negative income tax.
Is, am I wrong here?
Is this just another term for a negative income tax?
So that's, so the thing is in homework land, and this is actually one of the, one of the main reasons why I oppose UBI in homework land.
They're the same.
So if you just look at the income post taxes and transfers for any given level of earned income, then they're the same.
But the thing is when the government moves money, it does it in a leaky bucket.
So however much you take from the rich people, you will have to give less than that to poor people if you're transferring from rich to poor.
So while they come out the same, if you assume away the administrative costs, tax evasion, all that, they do come out the same.
But in the real world where we have to actually make this policy work, UBI comes out looking a lot worse.
And that's my big reservation about it.
Basically anything a UBI does, a negative income tax does better.
So what is a negative income tax?
A negative income tax is if you make underneath a certain amount of money, the government gives you money.
The simplest form is just your tax rate is your income times a certain percent, which is the tax rate minus a lump sum.
So to take a simple example, if the tax rate is 10% and the lump sum is $1,000, then if you make $1,000, then 10% of $1,000 is $100, minus $1,000 is $900.
So your taxes are negative $900, meaning the government gives you $900 at $10,000 you break even, 10,000 times 10% is $1,000 minus $1,000 is zero, and so on.
So how would a negative income tax decrease the leaky bucket effect as opposed to a UBI?
Because you mentioned that.
And also can you define what you mean by homework land?
Yeah, so homework land is just the parallel universe where undergraduate homework problems exist.
It's where you can safely ignore things like administrative costs, fraud, all those complicating features that make the world more interesting than just a supply and a demand curve.
All of those don't exist in homework land.
And the reason why a negative income tax is in a less leaky bucket is because there are fewer transactions that take place.
So think about that sticking with the 10% tax and the $1,000 dividend in the $10,000 case under a UBI and a flat tax, then I send the government a check for $1,000 and then the government sends me a check for $1,000.
Whereas under a negative income tax, I just send in a receipt to the government or whatever showing that no taxes are owed in either direction.
Okay.
It's, I mean, that that seems like a valid criticism and yet seems dumb to like send the government a thousand so they can send you back a thousand.
But doesn't every government program in the world have administrative costs and possible leaky bucket issues?
It seems like a relatively minor complaint.
So it's a hypothetical.
So take what I'm about to say with a grain of salt, but the Nisganian center, which is a very well regarded think tank did a cost estimate and it would and their estimate is not trivial.
They are somewhat libertarian slash right wing leaning.
So if you think they might be biased, take that for what it's worth.
But they found that the administrative cost would not be nothing.
Plus another benefit of the negative income tax is the sticker price is a lot lower.
It's in fact about an order of magnitude lower.
And so that makes it a lot more politically palatable.
It's an order of magnitude lower than UBI?
Yes.
With the Nisganian center's estimate, they come to a total cost for a negative income tax of 182 billion.
Whereas a negative income tax or a UBI of $5,000 would come out to 1.6 trillion.
How how is that remotely possible?
I mean, because as far as I can tell, they're just different words for the exact same program.
Am I misunderstanding something?
So basically the negative income tax would send out a lot fewer checks with any pretty much any sensible funding mechanism.
The UBI would claw a lot of it back.
But depending on how you feel about the American electorate and their ability to tolerate nuance,
they historically don't respond well to arguments along the lines of,
no, no, this program won't actually cost us this much money because we'll just tax a lot of it right back.
I think that's that's one of the points to me that I think catches for like the the counter or guess what I'm trying to say.
I can see many you mentioned the American electorate.
So I can imagine many of them being resistant to the idea of a negative income tax because quote like why the fuck am I helping pay them when you know they're whatever too stupid or whatever to not be poor.
Whereas if everybody gets a thousand dollars, then like, hey, I get a thousand dollars too.
I think that's a much easier sell to the American people.
Yeah, I guess the psychology behind it is vastly different.
I mean, on the one hand, like if you're of the mind where like why am I paying my lazy neighbors bills for him versus like, hey, three thousand bucks.
Yeah, yeah.
So this argument has become a lot weaker since 2016.
I admit that there used to be a party of fiscal responsibility in the United States.
There used to be a party where when there was a policy proposal, they'd actually look at how much it cost and make sure that the electorate knew what that number was.
That party no longer exists.
So that is a much better criticism than I would have credited four years ago.
I would argue it's been a lot longer than four years, but that is not what we are on topic here today.
Maybe it's maybe it's only been the last few years where they've been able to stop pretending that they're the party of fiscal responsibility.
Okay.
Yeah, that's a better way of putting it.
There was a party that pretended to be the party of fiscal responsibility.
So I don't know.
I think in the end, I mean, if it's an order of magnitude, it's obviously not worth it.
But if it's just like twice as expensive to do UBI as opposed to negative income tax, I kind of think it might be worth swallowing that cost because I think it'd be much easier to get people to sign on to a UBI than to a negative income tax.
Just it sounds better, right?
To many people, I should think that I should think so.
Right.
Like I'm getting the check no matter what.
It depends if you're asking, I guess, the American people versus policymakers who actually know what they're doing.
Or me, who for some reason has an opinion on this and doesn't know what he's talking about, or David, who doesn't know what he's talking about.
So I think there's also let's not be hasty.
I think there's also the aspect that I would feel that if it was a negative income tax, it is up to the vagaries of the IRS.
It could be taken away from me if a law has changed or if policy is slightly altered.
Whereas like a UBI, I'd feel more secure that it's now the law of the land that I get $1,000 a month no matter what.
The other major thing that occurs to me is that we don't have a negative income tax, but you do get food stamps and other benefits if you're under a certain income bracket,
which to many people on these services incentivizes them to stay on those services,
which means don't pursue a better paying career if you can because that bridge between...
I've seen graphs, I couldn't quote the numbers, but you're getting so much in aid that if you were to go just above this line of income,
then all the aid goes away, but you're still way below the purchasing power of things like food and electricity that you had before.
So you're incentivized to not try to earn enough to climb out of that hole.
So I guess between that and I can see how a negative income tax would help with this a bit too, but I liked...
I mean, being a non-economist and I guess swayable to persuasive sounding politicians like Andrew Yang,
I really liked one of the things that he mentioned a lot was like if I got $1,000 a month, I being the general person,
I probably won't save that because I'm an American, I'm bad at saving money.
If I do, I'll give it to a bank and they'll spend it and that'll help the economy a smidge.
But the other thing is I'm going to go buy $1,000 worth of stuff every month or $500 worth of stuff, which is a lot.
And that sales tax goes back into the whatever ecosystem of money and I'm buying more goods, employing more people.
So even if McDonald's has to raise their wages because while I can earn $800 a month working for McDonald's,
if I can earn $1,000 a month sitting on my ass at home, then I'm going to stay at home and earn the thousands.
So McDonald's will be like, well, all right, we'll pay a bit more.
Well, you can do both though.
Exactly, that's my point.
They'll pass that cost on to the product, but now I can afford a $3, what do you call it, Big Mac,
because I'm making $1,000 a month that I didn't have last month.
I think it also feels different because if you get $1,000 a month for doing nothing,
or you go to McDonald's and work for $800 a month, you're getting $1,800 a month.
Right, absolutely.
Because like the negative income tax, you might still end up getting that, but it still feels more like you're paying taxes
and the government is just like daining to let you have some of that money back.
Right.
I know that's not how it'll actually be, but the feeling really is different and I think that matters.
It's hard not to feel that way, yeah.
Yeah, I think the negative income tax might, I mean, to the extent that you would say one or both of these programs disincentivizes work,
the negative income tax might disincentivize work on like the lower end,
like people working for McDonald's or driving Lyft part-time, more than a UBI,
since they would count that as like part of your income and then that would be taken out of the income tax,
versus you'd still get your $1,000 and then yeah, you'd get however much you're getting from Lyft.
Does any of this seem remotely reasonable to you?
Yeah, so a couple things.
There are two different discussions when you're talking about both UBI and negative income tax.
There's the, we had this neat idea and we want to layer it on top of the current system
and we had this radical earth-shattering idea and we want to nuke the current system and replace it with this.
So depending on which of those conversations we want to have and I'm happy having either or both of them,
I'll have different responses to those.
Also, so the reason why a lot of economists like UBI is because it preserves what's called the marginal incentive to work,
which is basically the way economists think about this is for the next dollar I earn,
how much of that dollar do I get to keep?
And the thing about UBI is the UBI itself does preserve that better than the negative income tax,
but the UBI has this big looming question hanging over it of where does the money come from?
And my belief is that a flat tax on income is really the only plausible way to do that,
but if you want to talk about something other than tax policy, then I'm happy to do that.
I'm curious why you think that's the only way to do that.
So there are basically five ways that you can fund a government program.
There's a progressive tax, a flat tax, a regressive tax, debt and inflation.
Debt and inflation would be a bad idea, but explaining why would be a podcast in and of itself.
So it's probably best if you just take my word for it on those two.
Pretty sure that we're not fans of either debt or inflation anyway, right?
Despite debt being so popular, nobody loves it.
Sorry, go ahead.
I was just going to ask how does value added tax factor in?
So value added tax is a regressive tax.
It's regressive because if you're poor, then you will spend a higher percentage of your income on consumption
than you will if you're rich.
You're very, very likely to consume the hundredth dollar you make a month,
but the ten thousandth dollar you make a month you're very likely to save.
And so the nice thing about regressive taxes is you could actually use them to fund UBI.
The not so nice thing about regressive taxes is then you would be taxing poor people
in order to send welfare checks to rich people.
And that seems like not a very good idea.
So the three kinds of taxes that you mentioned, what are the three names and definitions really quick?
I'm not a tax person.
Yeah, sure.
So there are progressive taxes, which is when your income goes up, you pay a higher percentage of your income as taxes.
There's regressive taxes, which is as your income goes up, the percentage you pay goes down.
And then there's flat taxes, which are the percentage of your income you pay as taxes are constant.
So for example, a 3% income tax or 10% or whatever.
Yes, however much you make, it's always 3% or whatever that you send to the government.
In general, I'm not a huge fan of income taxes on humans, but I've tried to spin a few times a VAT tax as like an income tax on robots.
Wouldn't it be less regressive if it was mainly income tax on returns to capital, such as an income tax on robots?
And then it would be mainly the owners of factories and other large labor replacement devices that would be paying these rather than the working poor.
So that sounds more like a capital gains tax than a value added tax?
I see what you're saying, and it does sound very much like a capital gains tax, but it would be the way I'm picturing it, more of a tax on the returns to capital from using non-human labor devices.
Yeah, for replacing people.
Basically, yeah.
So instead of paying whatever an hour to have people stock your warehouses and move your goods, instead of paying the wages for that, you're paying at least a percentage of that back in taxes to have robots do it for next to nothing.
Right.
Yeah.
Okay.
I mean, that would be hard to administrate, but I feel like that would get around a lot of the taxing the poor problem with VAT taxes.
Also, why isn't progressive taxes more like, to me, it sounds like a great idea.
Like, what was it?
Alexandria Ocasio-Cortez, my new favorite congas person.
Don't get me wrong, there's 100 things, but the main thing is that, well, I won't get into the main thing.
A very small aside is that one of the things that she's pushing or that she's proponent of is, I forget what it is, like charging or whatever, 50% tax after everything over $10 million a year.
And so, if you make $20 million a year, you pay whatever the flat rate is for up to $10 million, and then you pay $5 million of that other $10 million in taxes.
Well, I mean, we do have progressive income taxes in the US.
But nothing like that.
No, no, not nearly to that extent.
But I mean, currently, the income tax at least does work that way.
Right.
But I mean, I love, I mean, this isn't me like, you know, some poor proletariat person, like, you know, just scrounging in the dirt complaining about this.
I think it's like, if you're making $10 million a year, if you're making $20 million a year, the other $5 million is like, if you're going to claim you need that, then like, kind of fuck you.
Like, we need like the society that like built your infrastructure to make your millions needs it more than you do.
Yeah.
Yeah.
David probably has a better answer for this.
The one that immediately comes to mind for me is that the more you progressively tax the rich, the more they're going to shelter their income.
That's actually exactly what I was going to say.
I haven't, like, read any papers on this because it's the first time I've heard the idea.
But Iñas, I feel like your idea would probably just mean we get both.
What's the word?
Outsourcing to a different country.
I think that is the word outsourcing.
Yeah.
Yeah.
Yeah.
You just get both outsourcing and mechanization.
Yeah.
Damn it.
Well, as we all know, trade wars are good and easy to win.
So if you want to put the tax on both robots and outsourcing, then maybe.
What we really need is an omnipresent omnipotent one-world government.
Maybe.
I thought you were going to say AI, but.
You know, how else would you get that, right?
I mean, I'll give it a shot.
As long as you can never go back once you try it.
Okay.
Response to the argument against progressive income.
And this was, you had, like, posted an article in the comments.
Like, we can post it again.
The, what was the author, the Samuel Hammond article.
Someone in the comments had put that they suggested maybe there could be a progressive
land value tax used to fund the other, you know, negative income tax or the UBI.
And what do you think about that?
Because you can't shelter land that well.
Yeah.
So land value taxes, wealth taxes in general, all of those are really tricky because they
depend very heavily on the valuation of a good that's not on the market.
So you can, if you're willing to just get rid of the concept of property rights, Glenn
while has a really interesting idea to deal with that, which is basically you list a price
for your property.
And that's what you, that's the price used for like taxes and whatever.
But if I come to you with that much money, you have to give me the property.
I think the concept of property rights has served humanity pretty well.
So I'm not eager to implement that, but it is an interesting idea.
And as far as I can tell, it would get around the problem.
But yeah, just in general, those sorts of wealth taxes are really, really hard and expensive
to administrate.
And you can tell that by just looking at the list of countries that used to have wealth
taxes and no longer do.
I have the list right here if you'd like me to read it off.
No, but you could probably email it to us and we'll put it on the website.
Okay.
It's just like seven of them.
Oh, okay.
Well, sure.
Yeah, it's Austria, Denmark, Germany, Sweden, Spain, Finland, Iceland and Luxembourg.
Huh.
And for all of those which I Googled, which was like three of them, the reason that the
list repealed was just that it was so expensive to do the audits and the administration that
the tax didn't actually end up raising that much revenue.
Good answer.
Also in that article you mentioned, there's a link in that article to another article,
which is a biography of the guy who came up with the leaky bucket quote.
And there's a quote from him in that and it says, high tax rates are followed by attempts
of ingenious men to beat them as surely as snow is followed by little boys on sleds.
So if you want to like cover more on this, I will go ahead and let you have that opportunity,
but I want to transition sort of into like the idea of UBI is to help future proof us
against, well, I guess the future, like as more and more gets, labor gets given to machines that are better
and better at doing what used to be human tasks, more and more of us will become unable to participate
in a meaningful way in the economy.
How do we future proof ourselves if we don't do something like UBI?
Is there some other better way?
So if there's a benefit to UBI over the negative income tax in that case, I don't see it.
If you have one in mind, then I'd like to hear it.
I don't, but I just felt that UBI is a better way to implement it and to sell it to the public.
I also want the administrative costs to be cut by replacing multiple federal programs.
I mean, assuming you're in the Nuke the current system camp without one UBI program.
Yeah, that's a good point.
Like we have currently, I don't know.
I'm assuming many dozens, if not hundreds of different kinds of like social security type situations.
If that would just all went away.
And even if we couldn't maybe wipe it out overnight, because you know, people who wanted to stay on it
for the next 40 years could or something until like everyone on it stopped needing it because they died.
Then everyone's just getting the same basic blanket.
Hold on, before I get too far ahead of myself, some people might make more than whatever UBI is in benefits.
If you're like taking care of like a special needs loved one and have whatever need food stamps or something, right?
But it does seem like this would curtail a lot of those programs, the one that manage, you know, small amounts or something.
I hear that means testing is pretty expensive both for the government and a lot for the people that need the assistance.
Like a lot of the most badly off just can't do it because they don't have the mental ability or emotional ability to go through the process.
You said means testing?
Yeah, yeah.
That's what to like find out if you earn enough to need this?
Yes.
Gotcha.
You're gonna have to slow down for me.
Sorry, sorry.
No, no, you're totally fine.
I am not playing dumb or I don't know any of these things.
But also I'm asking for the benefit of listeners who might not know these things either.
Right.
So I did kind of blow through some things too fast earlier.
No, no, it's totally fine.
Yeah.
We were basically just saying the current programs are expensive too.
So wouldn't the UBI, like one of the things I hear about UBI is that if you do the nuke and replace strategy, it would probably not cost any more than the current things.
Or at least that would knock down a substantial chunk of it.
Yeah.
Okay.
Yeah, sorry.
If you're talking about UBI versus the status quo, I do prefer the UBI for that exact reason.
But the negative income tax, which I think is probably what we should have, doesn't have that much in the way of means testing.
Like my understanding is that current systems or current programs, you need to show that like you're old, you have some disabilities or you're taking care of someone who has disabilities.
There are all these hoops you have to jump through.
But the negative income tax is just what's your income, multiply, then subtract.
And that's the benefits or taxes you owe.
So are you a proponent of negative income tax or are you not a fan of either of these?
Yes, I am.
So that's kind of hard to answer without getting pretty far afield.
Just the very, very short version is I think there are a lot of ways that the government kicks poor people in the teeth.
And I would like them to stop kicking poor people in the teeth.
And if they stop that and we still have people who aren't able to afford as much health care and food and housing and whatever as we want them to,
then a negative income tax is the way to get them to where we want them.
But I think it's not unreasonable that if we got rid of occupational licensing and zoning and all the other government policies that hurt poor people,
then being poor would be easy enough that what's left could be covered by private charity.
But if I'm wrong about that, I'm okay having a negative income tax.
So I guess you might have mentioned this earlier and it went over my head, but does negative income tax get you out of that,
whatever that trap where you're kind of incentivized to keep earning as little as possible,
or not as little as possible to keep earning under that threshold so that you keep making your negative income,
or rather you keep benefiting from the negative income tax?
Yes, it does.
Okay.
So if the tax part of the negative income tax is say 20%,
then for every dollar you make, you get to keep 80 cents as opposed to the current system where there are some discontinuities,
so that if you make an extra dollar in earned income, you can end up losing on total points.
That the negative income tax does not have that, which is why, again, economists really like it.
Okay.
And like not to keep beating up a negative income tax, I actually think that UBI is kind of the idealistic version of what I would like
and negative income tax is like the much more realistic version.
I'm very pro both of them, especially compared to the status quo.
You're kind of the pro negative income tax person.
Another argument I had was wouldn't negative income tax not encourage like middle bracket people to spend,
to spend more than they would normally like UBI might.
So might it not be as good for the economy as UBI could possibly be.
So the issue with the middle income people is the UBI payment isn't a free lunch.
You can't just make money up.
Well, you can just make money up here.
It's called inflation.
And like I said, it's bad for complicated reasons.
So then the issue is how do you get the money and the money to send to the middle income people?
And is that is that worse than the benefit you get from them having more spending money?
And that depends on how the funding mechanism is structured.
But generally speaking, I at least have a very strong prior that whatever the government taxes is probably going to end up being worse
than what the money would have been spent on anyway from a welfare perspective.
Cool, got it.
Okay, that was all of my arguments that I struggled to find for why UBI was...
Oh, you had more?
I actually have a question for you.
So what benefit do we get from sending basically sending welfare checks to Bill Gates and Jeff Bezos?
I think part of it was the loss aversion argument, which I think was brought up in the Samuel Hammond article
but then he kind of just dismissed it.
I think that human psychology is actually pretty powerful.
And it was kind of what we brought up earlier, the idea that if everybody's receiving a thousand, nobody's really going to fight against it
versus the negative income feels a bit more unfair, even if it's not.
The other thing was, oh, what was it?
I've got one.
So what would you say about a low overhead UBI which is rhetorically identical to a UBI but administratively identical to a negative income tax?
What I was saying before, honestly, I'm actually pro of the negative income tax as a...
I think that they are really analogous that the UBI and then the low overhead are all things that I would vote for.
What did you have to say, Stephen?
I was just going to say that there are a handful of Bill Gates and Jeff Bezos people in the country where there are, I don't know,
150 million Americans who could strongly benefit from a thousand dollars a month.
So yeah, we'll be giving a few rich people extra money to pad their wallets,
but if that's the cost of helping the rest of the people who actually could benefit from it,
that seems like a really small cost to pay and one that I think everyone would be kind of okay with.
I could totally see some Mitch McConnell-style politician saying,
look, they want to give your money to Jeff Bezos and Bill Gates to live,
but I feel like that would be a lot less salient than the argument of like,
look, we want to put $1,000 in your pocket, no strings attached.
I guess it feels more fair.
Yeah, that's basically the loss aversion argument.
Yeah, it's loss aversion, but it was also just like the numbers.
Yes, we'll be helping rich people, but there are very few rich people and there are a lot more people to whom $1,000
is like the difference between living in financial insecurity,
worrying that if you strain your ankle going up the stairs, then you're going to lose your apartment.
And I guess this is an argument from emotion, which isn't how I usually do things,
but I don't know, man, I know a number of people and I've been in this situation most of my life
for like $1,000 a month would have just been this enormous relief of a security blanket.
And granted, a negative income tax could totally provide that too.
And so I think that would be, you know, a good bridge on the way there.
I think the ideal solution would be just like find some way, like, all right, cool.
Everyone who's not earning above X, you get $1,000, but then like the weird part is then,
okay, while I'm earning exactly $900 a year over what it takes to get $1,000,
I'm inclined to like skip a few days of work or something, right?
So this all gets convoluted somewhere near the middle for me anyway, but yeah, that's where I'm at.
Did you have anything on that or should we move on?
Yeah, so I just say that the inefficiencies that come into play when you're talking about UBI
don't really exist when you're talking about people who have income levels similar to ours.
They come into play when you talk about people with income more like, say, my parents
and like comfortably upper middle class people would under a UBI end up getting a check from the government
which gets immediately taxed back and I just don't see why,
I don't see any benefit from like behavioral economics or anything like that
which overcomes just the basic silliness of having a bunch of people get a check from the government
and then having to send it right back plus extra.
Yeah, plus paying the people in the middle to process the checks.
Yeah, so there is that loss of overhead of the, you know, paying the processing in the middle part,
but I think that is a price that it would probably be a price we'd have to pay
in order to get all those people to vote and sign on.
Could be. I mean, so that I think might bring us a bit like a side from like the economic argument, right?
But that is not, was it, did Robin Henson coin the phrase homo economicus?
No, no, it's been long.
No, that's super old.
Yeah, well, I think I heard about it probably somewhere on one of his posts, but like,
yeah, given that that's not, those aren't the players involved, that it really is just the people hearing
speeches, watching TV and, you know, being told we're going to give you a thousand dollars
or we're going to give your money to people who, you know, either need it or don't deserve it,
depending on your political slant.
One of them is just an easier sell.
But yeah, I don't have a lot to offer.
So that's a factual claim about what the voters would or would not support.
And I don't know which of us is right.
If you are right, then sure, UBI might be a better idea than I'm giving it credit for.
But I don't know that there's any anywhere productive we can take that disagreement without calling a halt to the
podcast for a couple of hours to look at poll data.
Yeah, that's totally fair.
David, are you basically then in agreement with the Samuel Hammond article, which was the leaky bucket?
Let UBI is negative income tax with leaky bucket.
Yeah, so like I said, he takes this given that the welfare state is a good idea.
And if we're talking about this sort of radical social change, I'd like to at least check to see whether or not it's necessary.
But given that we do have a welfare state, I'd like it.
I am in agreement with the Hammond article.
Yes.
I have a question about one of the things that you one of the bullet points that you have in the document you sent us.
You said one basic assumption is that people are income maximizers, not income satisfacers.
And this claim is moderately controversial.
A few segments of society like kindergarten like kindergarten teachers seem to suffice, but a model with a substantial
number of satisfacers would mean that a UBI has serious implications for productivity, which hurts the case for UBI.
Do you think that this would be a big problem if a lot of people who are just working to get enough money to live would drop out of the workforce?
I don't, but I felt obligated to include that because there are very smart economists who disagree with me.
Why do they disagree? Because I kind of feel like people who don't want to work shouldn't necessarily have to be forced to if they could live on $1,000 a month.
That is a big can of worms.
I'm going to try to go through it with taking as little time as I can.
Basically, so I disagree with you about what wages and profits are.
I think those are not perfect, but they're pretty good measures of the value you contribute to society.
And if you're going to be taking things from society, such as apartments and food, you should also have to put something back in.
And that is wage labor.
So if you believe what you believe about the nature of work, then you're correct, but I disagree with that.
And that's just a values disagreement, and I'm not sure there's anywhere productive we can take that.
I think it's a values disagreement, but I think it's one that bears out in the history of just being, I'm trying to think of a way that doesn't sound politically slanted, but progressive.
I know people who are, like I mentioned, the mentally handicapped, many people can't work.
And so the idea is, well, I guess since you can't work, you're useless to society because people have to take care of you, so you're just a drain and you don't deserve to be taken care of.
And I see your point and on some instinctive level, I agree with it, but on the other hand, you know, right now the people who are, quote, too unproductive to live are usually taken care of by people who love them.
And there could be a point not too terribly long from now when 90% of the human population is too unproductive to live.
And I just don't think saying, okay, so 90% of the human population gets to not live anymore is a reasonable answer.
So for one thing, it wouldn't be 90%.
With the most pessimistic estimates, it would be something like 66%, which are the number of Americans anyway who have money and savings.
Basically, if you have a friendly AI takeoff that for whatever reason doesn't think that putting money towards, like, letting people not starve to death is a good idea, then basically the benefits would accumulate to anyone who has any money and savings.
And 34% is probably enough to be covered with charity because the returns to AI would be so huge.
And if not, then again, we can talk about a negative income tax.
And there's also the issue to consider that if you do have most of the workforce replaced by robots in some capacity, the cost of living would absolutely plummet.
So it would be reasonable for someone to be able to live on a bare fraction of what you need to live today.
And again, that's assuming that we somehow get a friendly AI who doesn't turn us all into paper clips and yet doesn't think that helping the people who don't have money and savings would be a good idea.
And I don't really see how that could happen, though people at Miri might disagree with me.
I don't think anyone at Miri would say that a friendly AI takeoff that resulted in, like, the negligent deaths of two-thirds of America would be a friendly AI takeoff.
Well, there would be survivors, so I don't know.
It might be an AI takeoff. Like, I don't want to, this isn't an argument about the definition of capital F friendliness, but like, so I guess that whole thing aside, what were we going to say, Inyush?
Oh, I was just going to say, I don't even think you need full God mode AI, just, you know, several decades of major corporations having very strong AI powers that they aim at places would basically result in the same thing.
Yeah, so this, I mean, it could just be dumb automation.
I mean, so what was at MIT, and I think the White House, back in like 2015 or 16, put out studies around the same time that had estimates of something like 30% of the labor market being automated by 2030, which is coming up right around the corner.
So things like cashiers, shelf stockers, drivers.
Even if cost of living does plummet, it's still not zero, and people who can't get a job because they just don't have anything productive to offer still have an income of zero.
And there's, there's, I guess, some estimates that that could be one in five people in the next 10 years.
Yeah, but the thing you need to remember is that labor isn't labor's only asset.
So if you own a home, you will see the return to AI because your property values will go up, and because you have a house there instead of an automated factory.
If you have any money in savings, then you'll see the return to AI because stock prices will go up.
And the much maligned creature known as the stockholder is actually nowhere near as rare as most people think they are.
But those aren't the people that are, you know, don't have a savings account because they're earning $9 an hour bagging groceries at Safeway, right?
Yeah, but yeah, but that's, again, that's not 99% of the population you're talking about. That's around 34%.
Right. Those are the ones that I'm talking about.
I don't want a third of the population to die, but 34% is a pretty manageable problem when you're talking about charity in a world where the cost of living has gone down as much as it would if all those menial jobs were replaced.
So how do self-driving cars and self-bagging groceries make my cost of living go down?
You buy things that are sometimes transported from one place to another, and if the only cost of that transport is maintenance and fuel, then the cost of those things that are transported, which is basically everything you spend money on, will be much lower than if you have to pay a trucker.
No, that makes sense. I just figured someone might ask. And then same thing at the grocery store. I'm paying not just for the stuff on the shelves, but to keep people there, keeping stuff on the shelves.
Jess, I saw you writing something down.
I think we kind of went past the point where I had some notes. And in the interest of time, I had some kind of random questions for you since you have the expertise in this field. David, if you wouldn't mind.
Yeah, I have a couple more things to say about this.
Yeah, please.
Then we can get back to it. So one of the big concerns I have, if you guys are right, is that UBI or an NIT, which again, all of that, what I didn't say was all of those concerns could also be covered by a negative income tax and it would have lower overhead, et cetera, et cetera.
But basically, none of that would really solve the problem. That's basically just sort of bread and circuses, just throwing money at social unrest to get it to go away.
And it wouldn't actually solve the problem of people lacking economic opportunity in political agency, which I'd rather have a stable world than not, but I'd rather have a genuinely stable world than one where there's hollow stability because we're throwing money at people.
I don't know how we could do that.
And you're talking about if we can figure it out, then that would be a better thing to do than just having a very generous welfare state.
As far as the bread and circuses analogy, you were saying that that would be both the NIT and the UBI, correct?
Yes.
And again, I don't have a solution to that in mind, but we shouldn't think, oh, we just need to implement these policies and then we won't have any problems.
Yeah.
That's to a certain extent, it's better than nothing, but to a certain extent, it's putting band-aids on bullet wounds.
Yeah, and that's the whole other discussion and probably be on the scope of this podcast. I mean, this episode anyway.
Yeah, you're probably right.
But okay.
You had a thing about, also in the document sent us, there isn't much reason to believe that AI will cause unemployment because comparative advantage implies that humans will still be employable even after the takeoff, as long as AI aren't perfect substitutes for labor.
Could you expand on that a little?
Yeah, so there's this principle in economics called comparative advantage, which basically even if, so the easiest way to understand it is with an analogy.
Even if America is better at producing both computers and corn, and you can tell I'm getting this example from a textbook that was written in the 80s back when we still made computers in America.
And corn.
I think we still make corn.
Even if America is better at making both computers and corn, as long as we are even better at making computers than we are at making corn relative to Mexico, then we're still, we maximize welfare by America making all the computers and Mexico making all the corn and then trading.
And the implication of this for AI is, as long as AI isn't literally identical to human labor, then there will still be a labor market.
Because even if the AI is better than humans at everything, then they're very unlikely to be exact mirrors of humans. And as long as they aren't exact mirrors, then there's room for specialization and gains from trade.
I think, tell me if this is a good analogy. I read The Golden Age, a science fiction book by John Wright, where he explained it as, even if there's a task that an AI can do in one minute, and it will take a human one month to do it.
The human, if they can spend their one month doing that task, it frees up the AI to spend that one minute on something else that's even more valuable.
And in that case, it would be still useful to have that human around. Is that a good comparison story?
Yep, that's a pretty good summary. And if you want me to send you a homework problem that I can put in the show notes, that's actually something you can prove mathematically.
And then you can prove it in homework land. So there should be asterisks in all the appropriate places. But yeah, that's a pretty well-established principle in economics.
We'll totally put that problem up on the website.
Yeah, totally. I want to dive more into that, but I want just to get some chance to go over some of your stuff.
Yeah, so let me find my random questions. Okay.
Sorry, one other thing I do want to say about that, and I don't want to talk about this too much, because again, it's a podcast in its own right.
But if you think that argument is wrong, that belief is very hard to square with support for a minimum wage, because basically what a minimum wage would do would just throw gas on the fire of workers being replaced by robots.
So I think that's all I want to say about that, because if I say any more, then we'll be talking about it the rest of the night.
But it's pretty hard to both worry about technological unemployment and think that minimum wages are completely benign.
We have wanted to do a minimum wage episode for a long time, so we may take you up on that in a month or two.
Honestly, though, that would find that very persuasive. So yeah, if McDonald's, we tell them we're going to have to pay $15 an hour to your employees, they're fine, then fuck this.
The standard counterargument to raising minimum wage is we'll find someone who's willing to do it less, and if we're not allowed to make anyone do it for less, we'll make something do it for less.
Right.
And so they're going to find a way not to pay it.
Yeah. There's a really cool study coming out of Seattle, so I am happy to come back on and talk about that,
because it's really good just like as an economics nerd who likes really well done econometrics.
So yeah, let me know if you want me back on.
Awesome.
Dope.
Cool.
All right, Jess, you have the floor.
Okay. Yeah, I'm going to just use UBI to mean UBI or negative NIT.
So here's some random questions.
At what age would you start distributing a UBI?
Late.
I'm not sure exactly when, but probably I would not start it any earlier than 18.
I would ideally like to start it at as late as like 21, because if you have parents with dependents who are collecting the benefits, then the funding problem just becomes
even harder, because the parents need to pay so much in taxes that they cover benefits for the parents and the children and not just the parents.
So, yeah, I would put it very late.
And that also does address the potential perverse incentives problem where if you give it fairly young, then there's incentives for poor people to have as many children as possible so they can get as much money from the negative income tax or UBI.
And that it has historically not worked out very well for actually making poor people better off.
Especially since they'd have to neglect the children so the cost of the kids is less than what they're getting.
Yes.
Oh, there's also the component that if I had $1,000 a month as a 15 year old, I feel like a lot of people would have been seriously hurt by all the dumb shit I bought.
Like fireworks.
Oh, you'd be helping the economy.
I'd be helping the medical industry for sure.
Okay, so almost like the opposite question.
Would you prefer a UBI to replace social security?
Would I want a UBI to replace social security?
Not necessarily.
Would I want a UBI with a flat tax or a negative income tax to replace social security and a payroll tax?
Absolute freaking lootly.
Payroll taxes are such a bad idea.
Again, if you want to have a really wonky podcast, I can go off about tax policy.
But I'm going to leave it there for your listeners sanity's sake.
Too bad that sounds kind of fun.
I always just kind of assumed that it would replace social security.
Like it would be the one-stop income shop.
As long as we can get rid of payroll taxes.
And that's the one that we all pay where I get paid every month.
If I make $15 an hour, I take home 12 of that.
That's also the surprisingly the one regressive, as far as I know, the one major regressive income tax in the US.
Where it charges poor people more.
Yeah, because it caps. You don't pay it once you make over like $81,000 or so.
Which is super weird, right?
Yeah, I mean you pay it on everything make up to $81,000, but then it stops after that.
And it might have gone up since I last looked at this.
So the big problem with which this is getting into the weeds, so feel free to tell me to shut up if you want.
But the big problem with payroll taxes is it's literally a tax on jobs.
Yeah.
And as every first year economics undergraduate knows, if you want more of something, subsidize it.
If you want less of something, tax it.
And if you tax jobs, then you have fewer jobs and jobs are generally seen as a good thing.
At least in the world we live in, if not in all possible worlds.
So, yeah.
Isn't it payroll taxes suck?
Isn't an income tax basically the same thing?
No, because I mean, so again, there's a similar problem where you have income hiding and people spending their income on non-taxable things.
But basically income taxes are easier to avoid.
And yeah, I think evading payroll taxes is a moral thing to do.
But it's very, very hard.
I actually think evading all taxes is a moral thing to do.
Do you propose a society without any public funding of anything?
I do on Mondays, Wednesdays and Fridays.
I'm going back and forth on the anarchy question.
Basically my opinion on anarchy is the same as Scott Alexander's.
At least on Tuesdays, Thursdays and weekends.
I want to see it tried somewhere very, very far away from me so I don't get caught in the blast radius if it goes wrong.
But there's at least good theoretical arguments for why an anarchist society would be a pretty good place to live.
I believe it was tried in Somalia for about 15 years.
No, no, no.
Somalia is what happens when you have a radical Islamist regime that is also socialist.
And yeah, that goes pretty dang bad.
In Somalia you actually did have a lot of the things that David Friedman talks about, like private judges who competed and competition drove down corruption.
So Somalia is both not an example of anarchy and also kind of an example of why anarchy is pretty good.
I'm not sure you can have both, but wasn't Somalia also the country that was without any form of government at all for about 10 or 15 years where war bands roamed the countryside?
Yeah, it was without any government at all for 10 or 15 years after you had the aforementioned Islamist, socialist government that burned everything down.
Right, I'm talking about the post-burned down period.
And if you have a really, really uniquely bad government set everything on fire and then they go away, that's pretty bad.
But that's not what I'm talking about when I'm talking about anarchy.
I hope it would be a much smoother transition.
Okay, I see what you're saying.
Yeah, you always start at a shitty position if someone's burned everything before you start.
Yeah, Somalia is a straw man at best and an example in anarchy's favor at worst.
Alright.
Okay, let's see, two more random.
If you guys can link in the show notes Scott Alexander's review of the machinery of freedom, it's very good.
I vaguely remember reading that.
I'll have to reread it.
Sounds fun.
It does.
Okay.
Yeah, two more random, kind of socio-political questions about UBI.
So how would you propose getting this UBI money to people who aren't connected to the tax system, like the homeless, the unemployed, non-citizens?
So wouldn't non-citizens just not get it?
I'm trying to think of the politically correct word for illegal aliens and I can't think of it.
Yeah, I'm kind of okay with them not getting it, especially if that's the price to be paid for open borders.
As for the homeless, again, homelessness is to at least a larger extent than people appreciate a problem caused by government.
If you look at places that have relatively relaxed zoning laws, they don't tend to have much of a homelessness problem.
And there was actually, I can't remember the details, but there was a case where a private charity built a bunch of tiny homes that were basically just 10 by 10 boxes with mailing addresses for the homeless.
And I think it was in San Francisco, it might have been LA, I'm not sure.
But yeah, the government, because they didn't comply with zoning laws, the government just bulldozed the houses and set fire to them.
We've got something like that in Denver too where it hasn't been bulldozed and set fire to yet, but there's a lot of regulatory issues with whether people are allowed to make these tiny homes for the homeless or not.
Yeah, so as for how to help them without getting rid of the stupid laws that are currently hurting them, I don't know.
But that's a pretty intractable problem for any system you have.
So the main takeaway is just get rid of zoning laws as soon as possible.
I like that.
I think just one quick anecdote, I know that when I worked at the bank, at least a couple people that come in relatively frequently were, if not homeless, they were homeless adjacent.
And I think as long as you can get your paperwork together enough to prove to somebody, if you're fortunate, you know, maybe a case worker, social worker who can work at that population, they can help you prove your identity, give you a piece of government issued paperwork that says you are who you say you are, and then you can collect social security and that sort of stuff.
So people would come in whatever first Monday of the month or whatever and grab their social security check all in cash. And those people, I'm pretty sure it didn't go home afterwards.
Yeah, I was just curious whether a UBI or an IT system would have some kind of advantage over the current one or disadvantage.
I don't want to sound like a heartless asshole, but I'm kind of in favor of people who aren't citizens not being included in the UBI.
Yeah, I mean, like, maybe you should just start that one from the list. That's, again, a whole other conversation.
Milton Friedman did famously say a welfare state is incompatible with open society, meaning society with open borders.
And he's actually wrong. You can have it as long as you're comfortable saying you can live here and you can work here, but you're not a citizen.
And we're not going to give you these nice things we give to citizens, which I'm perfectly comfortable with, but a lot of American voters aren't for some bizarre reason.
It might just be bottom lining, but...
And historically, that's how most of the human race worked.
Like, there were a bunch of city-states, and if you were a member of the city, you got the benefits of being a citizen.
And if you weren't, you could live there and you could work there, but you weren't a Roman, so you didn't get all the protections and, you know, benefits that the Romans or the Venetians or whoever it was got.
I'm sorry, go ahead.
Oh, I was going to say, I like it as long as there is some path to attaining citizenship.
Right.
All I was going to say is that while that might be historically true, and this isn't me taking a stance, historically, living as a human is often sucked.
Right.
So, like, that argument from history doesn't persuasive as, like, the way things should be.
Yeah, no, I'm just saying that it's entirely possible and people have done it before.
Totally.
Alrighty.
And the last one, maybe it's a little bit connected.
David, how do you think geographical locations might be affected by a UPI or an NIT system?
I'm talking about, you know, agrarian locals versus the cities and where people choose to live.
So, the biggest issue there is just that cost of living is so wildly different in different places.
And, like, I hail from rural South Carolina where $1,000 check you can live per month you can live comfortably on.
I am given to understand that in San Francisco that would just about cover about a quarter of your monthly rent.
So, that's one of the bigger arguments for something like the status quo over either UBI or negative income tax is just it's more flexible with respect to differences in cost of living from place to place.
Do you think we'd see a bunch of people moving out?
I don't know how we could address that other than just, like, having some sort of cost of living index.
I mean, that might not be necessary.
It's entirely possible that we just see a bunch of people moving out to the country where it's cheaper to live, right?
I mean, I don't know if I would necessarily because there's a lot of stuff in the city that I like.
If I could convince a large chunk of my friends like, hey, let's just go live out in the country where it's cheap as hell.
We'll still have each other for company and the internet for internet stuff.
Why not?
And it would free up city room for people who want to live in the city for some reason.
Yeah, so people aren't that mobile.
That's something that and the argument very similar to that.
Economists have been talking about it and debating it for a while.
But just if you look at places like West Virginia where there aren't any jobs and yet people don't leave and go to where there are jobs.
It just seems like locations are stickier than that argument assumes.
I think it's much easier if you don't have any friends or family you care about.
And you have the means to take whatever shit you have and move a thousand miles, right?
Right, right.
But the less shit you have, the easier that is.
Yeah, I mean, if it involves a lot of walking, though, still people don't want to do it.
But hitchhiking exists.
I mean, many people can get money together for a bus ticket.
So I guess then you get there and then what?
Then you just can't afford to live less because you've got no one's couch to crash on and stuff.
I think then you get to spend a year deciding whether or not you want to live a life where you don't do much of anything
or maybe you want to decide this isn't for you after all and move back to the city
where you can strive for things and be stressed but also in the game.
I don't know.
It'd be at least kind of interesting to have the option.
I mean, there's kind of the option now.
But you're saying if there was already had some net income already.
Yeah, yeah.
So certainly, yeah, I mean, if you go from making $0 a year to making $12,000 a year,
then you have the means to leave wherever you're at and do stuff, right?
Yeah.
Go somewhere your money goes further.
Yeah.
It's weird because I have a friend who lived in Mexico for about a year and like Southern
part less developed part of Mexico didn't have a greater connection but had a good enough internet
connection to still get his job done.
He could do a lot of it offline.
And yeah, he said the cost of living was so ridiculously cheap.
He was basically living like a king on the US salary he made.
But in the end, he ended up moving back to Denver.
Hmm.
Yeah, you see a lot of these digital nomad types and I think don't see very many of them
that aren't like in their 20s and 30s.
So it's kind of interesting.
So all that is to say, yeah, that's a problem.
And but it's again, not really a problem that we can get around very easily.
So.
All right.
Yeah.
That's all I can think of.
Steven or do you actually have any questions?
I think I covered most of them.
I'm sure something will come to me right after we hang up.
But we do still need to get to the less wrong posts and then, you know, get some sleep in
tonight.
So we're probably going to have to wrap it up.
Do you have other things you wanted to mention or something that came to mind during this
conversation that you'd like to talk about?
Yeah, so you should probably use computer wizardry to put this way way earlier in the
conversation like right at the beginning.
Okay.
But just so you know where I'm coming from, even though I've made it pretty clear.
I'm a libertarian.
I have deep anarchist sympathies so much so that on some days you can catch me calling
myself an anarchist.
But I, depending on where you put this, I either hope to or think I have done a pretty
good job of just sticking to the economics and not bring it or at least very clearly
pointing out where I'm bringing my personal values into it rather than just letting the
numbers and the efficiency arguments speak for themselves.
Yeah, I think, I mean, we'll put it wherever you want, but I thought it was fun to learn
that about you as it came out throughout the episode.
So we'll move it to the back or to the front, whatever, to the beginning if you want.
It was fun to hear about and you've put your cards on the table.
I think anyone, and like the part, the points where you were clearly expressing those, those
intuitions and priors, I think you did so in a way that wasn't like pretending to be
couched in, in whatever carefully cited studies or something.
I feel like you were very transparent and fair about it.
So if you want to put it in the front, we totally will, but I kind of like it here because
I feel like, like seeing the, the, the Darth Vader Luke, I'm your father reveal at the
very beginning of Star Wars, you know, leading up to it as part of the fun.
I have mixed feelings about the analogy, but I get what you were trying to say.
Okay.
I think it's a compliment.
Yes.
I'm not sure if you're Luke or your Vader, but either way you're entertaining and, and
not just entertaining, but informative to talk to.
Yeah, absolutely.
This was great.
And to anyone, well, I guess everyone who can't see your face, you have this awesome
beard that I'm very jealous of.
So that's, that's, that's a big point.
But I had one random question, not about your, your professional contribution to, or what
am I trying to say?
Whatever, to why we asked you on, but everyone that we talked to listened to the show, I'm
kind of curious how you heard about it and what got you into rationality and all that.
So what got me into rationality?
I have maybe the, not the weirdest origin story, but probably the least expected origin
story I know of for any rationalist.
I was actually,
Oh guys, I hate you with this car and
Harry Potter and the methods of rationality by my church youth group leader.
Huh.
Right on.
Yeah.
That is not, yeah, not someone I would have expected to recommend it.
Yeah.
Uh, and then from there it was the usual downhill tumble of, of methods of rationality into
the sequences and then into all the other rationality things.
Did you ever, did you ever find out why the youth group leader recommended this?
Yeah, cause he really liked it.
I, even when I was still calling myself a Christian, I did a pretty good job of like
keeping the fundamentalists away, which was very, very hard living in the back end of
nowhere, South Carolina, but I somehow managed it.
Uh, so like the people I hung around with were the people who like actually thought about
things like evolution and creation and that sort of thing intelligently.
And even if they come down on what I now believe to be the wrong side of those questions,
they didn't just shrug it off.
Um, so.
That's awesome.
Yeah.
I don't think we've ever specifically talked about it.
And like we haven't talked to each other for, uh, quite a distressing number of years.
Um, not cause I like miss him or anything, but just cause I don't like feeling that old.
But, um, yeah.
And, uh, as for how I found the podcast, it was via the audio book, uh, which by the
way, if no one's told you the rationalist audio book is a very noble public endeavor
and, uh, you win many, many virtue points for doing it.
Oh, well, thank you.
Hey, I'm very happy that people have found so much use and joy out of it.
Seconded, but I told you that before.
So I like to imagine that your youth group leader just like was never a believer and like
just showed this as many people as possible and like just took the role just to subvert
the church.
Right.
But maybe that's me being the, the Facebook posts he's put up for which I have since
I followed him, uh, are pretty strong arguments against that, but it's a nice thing to think,
I suppose.
Uh, I mean, I guess it could be playing, you know, really heavily undercover, but, you
know, yeah, you're, you know, better than I do.
Something might be worth it just to send him a thank you note being like your recommendation
changed my life.
Thanks.
And he converted me and I'm going to hell.
Thanks.
Maybe keep it big.
I might have, I might have come to it anyway because I've been a fan of Brian Kaplan for
a really long time and you can only be a fan of Kaplan for so long before you encounter
Hanson.
Um,
The slippery slope.
Yeah, that's, that's the, that's the path I walked.
That's awesome.
Even if it sometimes feels kind of inevitable.
Yeah.
Well, thank you for coming on.
This has been a delight.
Yes, I can do this.
This was great.
Yes, it has.
All right.
And, uh, we'll get back in touch with you about maybe doing a minimum wage thing.
Sounds great.
I'm looking forward to it.
All right.
Uh, thank you and have a great evening.
Yeah.
Thanks, David.
Okay.
Have fun with the other sections.
Yeah.
Thanks.
Awesome.
Thanks again, man.
Yeah.
Have a good night.
Night.
Good night.
Okay.
On to our less wrong post section of the episode.
Yay.
Boop.
Boop.
Boop.
Our first post this week is beware the unsurprised.
I guess I'll start it.
Yeah.
Sure.
I'll pick an order.
We really should have thought of that beforehand.
Um, so basically the, the point of the post is that, um, people often try to not look surprised.
Some people may actually be genuinely unsurprised when their models are wrong, uh, because
as Eleazar says that a breeder pointed out, uh, if their models are so vague that they
don't understand the implications one way or the other, uh, they may not be surprised.
Or if they appear unsurprised, if they, or they may appear unsurprised if they fail
to emotionally connect to the implications.
Uh, for example, an asteroid is going to collide with the earth in 10 years and they're
just like, okay, let's get, let's get a little sursy to the doctor.
Oh, I will put in a relevant Saturday morning breakfast cereal, um, to this.
It's not, they, they were emotionally registered, but it's hilarious and it's relevant.
So going for it.
Oh, right.
I guess we'll have to actually put it on the website.
Yeah.
Yeah.
I could try and paraphrase the cartoon, but I would ruin it.
You got to enjoy SMBC as it is on the page.
Heck yeah.
It's the audio versions of cartoons.
Yeah.
Um, and also they mentioned that some people don't want to appear to be surprised by surprising
seeming data.
You mean unsurprised?
Oh yeah.
My, yeah, appear to be unsurprised because, um, that makes them look more, uh, confident
and in control and competent.
Like, well, I wasn't surprised by this.
My model was already perfectly fine the way it was.
I totally expected this.
So, um, yeah, those are, these are all situations in which people may be unsurprised by what
should be, what is a surprising event in their model.
And then there's like the, the classic example of bystander effect where there's a number
of things going on, but one of them is like, you can look calm and unperturbed and like
gives you like this air of, this isn't really, this is tangential to bystander effects.
But like, if everyone's freaking out and you're keeping your cool, you kind of look
like a cool person.
Um, and since everyone's kind of trying to do that a little bit, then like somebody
collapses in front of you on the street and like, you look cool because I'm a cool, composed
person.
And like, you're casually looking around to see if this is an emergency, but everyone's
doing the same thing you're doing.
So everyone assesses that it's not emergency because no one's overreacting.
Yeah.
That was going to be the second point.
Okay.
Yeah.
My bad.
I jumped ahead.
No, it's okay.
Uh, well, did we have anything to say on the first point aside from what we already
had?
The whole, no.
Not really.
Okay.
I do think it's kind of scary that, uh, some people might just have such vague models
that they don't even realize they're surprised because the model really didn't predict anything
either way.
Yeah.
That's just, I think that's kind of what he talked about in the last post too is like
then you just, you don't really have a model of reality.
You just have like this thing that you say you believe, but like it doesn't mean anything.
It's not connected to any other beliefs.
Yeah.
That model is not paying rent.
Right.
So going to your second post, the point that you jumped on is that, yeah, if you're looking
around and everyone else is acting cool and you're acting cool, then nobody, nobody
is, uh, actually treating an emergency like an emergency.
Right.
And, uh, he's saying that, right, since everyone else is also basing their actions on, uh, what
everyone else is doing, then, uh, everyone may believe that something isn't really as
big a deal as it is.
Like someone collapsing on the street or something, uh, therefore everyone looks unruffled fails
to act.
And so appearing unsurprised, even when you are, or pretending to yourself that you weren't
surprised is both personally detrimental and socially detrimental.
It is, it has negative effects on the rest of society when you act unsurprised on purpose
because, uh, that is information that you are denying to other people and things that
may need to be acted on are not.
Yeah.
I think this is kind of related to one of your strengths as a rationalist is the ability
to notice when you're confused, confused and surprised to have like slightly different
meanings here, but it kind of lends a lot more weight to something if you're surprised
by it and, uh, gives you a stronger motivation to update.
And yeah, when you're signaling that to everyone around you, then everybody is updating their
models the appropriate amount.
Yeah.
I don't know.
It feels like the kind of thing I've talked about with you, with the, with the two of
you, but I don't remember doing it.
Um, did I mention at least a few years ago, Julia Gale, I've mentioned on one of her podcasts
that she kept a surprise journal.
Yes.
Yeah.
Which is just a nice way to like even just like low brow calibrate, like, and I'm not
writing these down, I guess, cause I'm lazy and don't write stuff down, but I've been
like trying to document just like minor things about my life a little bit more, um, not as
a regimented thing, but like mainly just to improve my like, uh, well, in this case,
my commute, my commute is a little shorter than I thought, which kind of surprised me,
which means like I could sleep in for like 15 minutes if I felt like it and get to work
still on time.
Like somehow the train goes about the same distance as the train that I used to take
to my last job, but it's like 10 minutes shorter.
So that's cool.
Yeah.
Yeah.
Cause I mean it's not, again, it's a very, very minor surprise, but it's one that I noticed
literally in the last two days.
So I should absolutely keep surprise journal.
I feel like that would make me a better rationalist and I think it's just kind of a fun practice
and mindfulness too.
And it'll help you like notice when you're surprised and help you track like your changes
over the years.
Yeah.
Yeah.
Help you pay more attention to the things that you're not surprised by, but that you
are still noticing in the background.
Yeah.
There's a lot of stuff that you ignore just because you're so used to seeing it that it's
like blended into it's camouflaged.
Um, what do you think about there's this kind of other thing that the media does about being
over surprised or exaggerating their surprise about everything new that we learn?
Oh, right.
I feel like that might have the same kind of negative bystander effect, but like to
the opposite extent, like you mean like the outrageous science headlines or yeah, like
every, every, you know, science headline ever is like scientists are baffled.
Yeah, I, my general rule, and I didn't invent these, but there's a handful of them that I
don't know if I could talk about in the name of the list, but it's like, how to like notice,
clickbait and just answer to it.
So like if the, if the headline is in the form of a question, the answers always know.
Um, so, or like scientists can't believe it's like, yes, they can, or you're wrong.
So yeah, I can, I'm not a social scientist, but I would bet a thousand dollars that there's
no way that's not damaging society.
I mean, you hear again, big capital words headline, this new revolutionary treatment
for whatever, um, I can't remember how many times back before I left Facebook, I saw that,
you know, we've got a treatment or a early detection for Alzheimer's or something.
And it's still not around because, you know, turns out like whatever, the ability to smell
peanut butter was like loosely correlated to like 30 people or something, right?
Yeah, someone's proposed like a phase one's clinical study or even something pre-clinical,
like, okay, now we have some evidence that this might do this and we're going to test it.
And some, you know, journalist jumps on it as, aha, we have found a new drug for Alzheimer's.
And that's super common with like, you know, the idea that like the plastic and water bottles
causes cancer that was, uh, from like one study by a grad student at M or some Ivy League college,
whatever. And their lab equipment was tainted with BPA. They're like testing tubes and they
discovered that published, you know, the result got redacted or they published the update,
but like nobody notices that they catch the headline cancer in your water and it never
goes away. And that's still a thing that people worry about today, right? The, the, the vaccine
concerns people have from Andrew Wakefield's bullshit stuff, which was actual fraud. Yeah,
which someone fucked up, but straight up intentional fraud. But, but all the average
anti-vaxxer knows is that some doctor found this was a thing and then whatever, maybe he got
suppressed or something. What they don't know is that he got his license revoked for malpractice
and, uh, fraud. Yeah. So do you see the recent thing about the incredibly strong correlations
between, uh, air particulate air pollution, air particulate pollution and, uh, Alzheimer's
onset? Yeah. Apparently it's a really lot of, um, I mean, still only correlation and they,
they would have to look more into it somehow. Though I don't know how you double blind that
sort of test, but, uh, it, it made me really think twice about living in a dense urban environment.
This is not that dense. No, no, no. This is not that dense at all. Uh, I'm out in the suburbs
and it's pretty nice, but like I'm, I'm less likely to want to live near a major street or in,
you know, downtown Denver itself. Denver in general is just not that dense. You should
cozy New York or New Jersey sometime. Everything is so far apart from everything else here.
It's ridiculous. I think it's just the idea like the less the merrier, but yeah, that's,
that's nerve-wracking. Um, this is totally an aside, well too far of an aside to get into,
other than I'll skip straight to the punchline, which seems like a non sequitur that it's a
travesty that you can't sign up for cryonics or that rather you're not, whatever, you can't
cash in your cryonics benefits if you commit suicide and or use the, whatever they call it,
if you elect to die from a terminal illness. Um, so like if you have Alzheimer's and you're like,
oh great, I can, you know, preserve my brain while it's still in, still in good shape,
you can't do that yet. Uh, you have to wait until Alzheimer's kills you, which means that your brain
is just a mess and there's very little worth saving at the end anyway. So you might be able
to stop eating and drinking. I'm not sure if that would trigger the suicide autopsy or not.
I'll keep that in mind. It would. I, I saw it, never mind. All right, yeah,
tangent. We'll have to save it, sorry. That's a dark topic. Anyway, unhappier note, uh, sign
it for cryonics. It's cheaper than you think and it's cool. Yes. Uh, both me and Stephen were
signed up. Are you signed up at Jess? Um, no, but I do plan to. What if you had died camping this weekend?
Yeah. Also, it's cool is also a pun because cryonics, sorry. Yeah. Everyone loves puns except me.
Just have this mental image of somebody in like a cryo tube with like dark sunglasses and yeah,
double thumbs up. If I get to choose the time going in. Hell yeah. All right. How about the
third alternative? Third alternative is a good one. Who wants to read this? I'll jump in on this
one. Okay. So, um, classically, the third alternative is also known as like the false
dilemma or the false dichotomy or the excluded middle or the package deal fallacy. Basically,
it's the either or option. You know, um, we need, give me, give me a stupid example.
He used Santa as an example. That was a good one. What was Santa? Right. Yeah. So Santa, you know,
well, we need Santa, we need the Santa myth for children to give them, you know, hope and, uh,
a sense of Matt mystery or whatever. I actually forget the argument. Yeah. And I read it like
four hours ago. Act better as humans if they, yeah. So then you say, well, if we take that away,
then they won't have anything to give it to them. Yeah. And they'll have no hope.
Everything will be joyless and dry and empty in their lives. Plus they'll be naughty all the time.
Right. So it's a great example because it's obviously bullshit. So there's, there's a million
other things that you can do to actually treat the goal of like, let's give kids a sense of wonder,
mystery and, uh, responsibility for their actions or something. I feel like just giving them
presences enough too. Yeah. Like, has anyone tried that? Just like, Hey, you know, on this day,
you get presents. Like, are the kids more excited if it's like, we don't know how these presents
got here? Maybe. Maybe. I think so. Like getting presents is still awesome, but like the mystery
behind it is cool. But like you said, there's much better ways to give them that sense of mystery.
Yeah. Like, did you know that we're actually traveling around that sun up there and it's a
ball of flaming nuclear gas? Yeah. I mean, throw some science at them and then throw a present at
them and get that association going early and then make some of the young scientists. Dude,
that'd be awesome. There you go. Whenever I put up my Christmas tree, I always put like a book
under it and I call it my tree of knowledge rather than my Christmas tree. Oh, I love it. That's
awesome. I'm so nerdy. I love it. I've got a niece that I can start bombarding with, with books for
trying to, well, I don't know if I'll be rounder enough to try and like get that immediate pigeon
feedback to make her and to meld her into a scientist, but I'll see what I can do. All right.
So the noble lie is the, like the generally all-package deal of fallacies where like,
it's, yes, we all acknowledge the people who in the know, yes, we know it's a lie, but we tell it
because society couldn't function without it. Right. You know, Plato had his for like, people
have like a core of different elements in them and like the gold people, that's why there's like
caste systems and like just, you're, you happen to have a lower thing and if you're born, you're
born believing that, I think that's in the Republic. Okay. So he believed in that. He didn't believe in
that noble lie. It seems like, but he, he was like, that's something that we could push to keep
society together. Okay. Or like the very popular one of like afterlifeism, where, you know, of
course we, the sophisticated people, we know that you're just going to die when you die, but
you guys couldn't handle that. So very condescendingly we'll lie to you to keep you sheltered from the
horrible truth. It's not clear to me in that argument, like how the noble liars think that
they're doing okay, but no one else could. It is condescending. Yeah. Yeah. All right. Fair enough.
Or like, yeah, the reason that they're calling this the third alternative is the idea that there's
only this lie or something terrible as an alternative and there's not other stuff you
could do. Like the example of it's either Santo or your kid is miserable and there's all kinds of
other things that you might be able to do to make your kid not miserable. Yeah. I think the core
argument is that generally the, the noble liars and the, the excluded middleers are saying like,
your only real options are either this thing that I have already proposed or else nothing at all.
And Elias is saying that we can and should think of third alternatives, other ways of handling
problems. It's not that your only alternative to believing in Santa or in believing the afterlife
is to not believe in Santa or not believe in anything. There's other alternatives that one
can think of. One just has to do that. Yeah. And that's actually like harder than
it sounds. Elias did bring up the just set a timer and think of stuff for five minutes.
There's, I like looking up, there's a narrow framing exercise you can do. And that's kind
of a similar idea where when you're trying to make a decision, you kind of like think of,
okay, I've got two alternatives and narrow framing is the idea that you're only thinking in terms of
these two, these two options. And you're actually like psychologically blocking yourself from
thinking about anything else outside of that. Is this the first post? I don't remember if he
brought up the five minutes by the clock thing before. I noticed it in this post though. I think
this is the first post where he actually starts the meme of think about it by five minutes by
the clock. Don't just like, say you're going to think about it and then give up after a bit,
look at a clock and really think in brainstorm for five minutes. Yes, this must be coming up
shortly before hold off on proposing solutions. Because that's an important part. Like Jess
mentioned, like the narrow framing effect, if you grab two, one or two guesses or whatever
solutions that in your five minutes of thinking, then you spend the next four minutes and 30 seconds
just analyzing those two, you've prematurely cut yourself off from like the search space, right?
And more than likely you've, you didn't think of those two from like nowhere. You just grab two
quick ideas that were already available. You haven't really considered alternatives.
And like the reason for that, which he gets into in this post is the number of alternatives can be
huge. So you need some kind of stopping criterion. And he says whether you're looking to buy a house
or when you're looking to buy a house, you can't compare every house. At some point,
you have to stop looking and decide. So that's why you would want to make some kind of exercise
where there's a set in stopping point, like setting a clock. But I was gonna say, there's a
there's a nice quote in here that I think just still is kind of the difficulty of this. Like
the, oh, there's a bunch. Actually, this is a good one. Everyone read it. It's fun.
But like, how can we obtain third, how can we obtain third alternatives? Well, the first step
in obtaining a third alternative is deciding to look for one. And the last step is the decision
to accept it. It sounds obvious. And yet most people fail on these two steps rather than within
the search process. Like it's just basically, yeah, the first thing is like realizing that someone's
come to you with a bullshit dilemma, and you're picking between two crappy choices. And just
saying, you know what, I need to go find something else. And that there's usually a ton of stuff to
look for in there, right? Yeah, there is. Some of it can be really hard to think about for various
reasons. And that's where the psychology comes into play. And I don't think this article really
gets into it. I could think, for example, a benign one could be if you're looking for a new house,
you might just be artificially restricting yourself to neighborhoods that you've already
visited and that you kind of have an idea of what they look like in your head. But you don't
think about that consciously while you're looking for a house. Or you could also, if you're trying
to figure out, oh, man, what should I do? Like my relationship's not going so well. And you're
kind of thinking about, well, couples counseling, or I could, well, you could leave that person.
And then like, that's another thing that your brain just might be preventing you from even
thinking about you just flinch away from it subconsciously. All these techniques work so
well together. It sounds like nerdy reverence, but I mean, the ability to hold off on proposing
solutions, not be afraid to flinch into scary looking ideas, and just stare into the uncomfortable
possibility like, oh, wait, the scary thing that I'm trying to avoid thinking about, I should actually
think about that and decide as objectively as I can if it's a good option, right?
He also touches on what I think later will turn into the privileging the hypothesis post.
It's a quick note about motivated cognition here. He says, but what about when our conscious
motives for the search, the criteria we can admit to ourselves, don't square with subconscious
influences? Like you were just saying, when we are carrying out an alleged allegedly altruistic
search, a search for an altruistic policy, and we find a strategy that benefits others,
but disadvantages ourselves, well, we don't stop looking there, we go on looking,
telling ourselves we're looking for a strategy that brings greater altruistic benefit, of course.
But suppose we find a policy that has some defensible benefit, and also just happens to
be personally convenient, then we stop the search at once. In fact, we'll probably resist any
suggestion that we start looking again, pleading lack of time perhaps. And I just, I mean,
that's wonderful and true, right? Like the best way to get, I think they say on the internet,
the best way to get the right answer to something is to post the wrong answer.
Yes.
Because then everyone else is like, that's not right, and they spend all the time doing
the looking for you and disproving you. And yeah, that's the same thing. Like if you really want
to test a claim, then you can put forth some crappy argument and find the people who are
willing to prove you wrong, I guess.
Yeah, you could, there's a bunch of exercises you could do yourself to. That's actually a good one
is just coming up with the opposite of whatever you're trying to figure out, making yourself
brainstorm like, how could I write the crappiest novel possible? That was actually an exercise I
did one time and it was really funny because then I just went through the list and kind of reversed
everything. And I was like, now here's how I should write my novel. And I generated a list I
wouldn't have thought of if I was just thinking about like, how could I write something cool?
That's awesome. And see, like that's the kind of like third alternative strategy that you probably
wouldn't get from your average, like learn how to write textbook, right?
Yeah, I love doing stuff like that. Just if I could go like one more that I really love is
if I was like, this is especially when you're trying to come up with a solution to some hard
problem. It's like, okay, if I had like all the money in the world, how would I solve this? Or
like if there was some like clever way I could cheat to get to the finish line, how would I do
that? And that can actually help you come up with stuff that you just were blocking yourself from
thinking about either because you're scrupulous or poor or whatever. I like that a lot.
Yeah, I don't have much else to add to this one. I feel like I actually kind of spoiled the next
one because I forgot that it was a, that forgot that was the third post. I thought it was the
end of this one. I read them all again really quickly this afternoon and I guess forgot that I
clicked three tabs rather than two. Right. So the next post then is third alternatives for
afterlifeism. Which I feel like ism-ing everything is kind of condescending, but I'll let it slide.
I think it's supposed to be sort of a needling at something. It is. Jokingly roasting it.
Like I had a conversation with my life insurance agent who's also signed up for Cryonix and
is a big proponent of it. And in fact, he wrote a book, Rudy Hoffman. Everyone look him up.
If you want. He's also got a book on Amazon. That's Rudy, R-U-D-I, Hoffman, I think with two Fs.
Anyway, if you do contact him and get signed up for Cryonix, tell him I sent you. I don't get
anything out of it. I just would be happy to hear it. So I think we were talking about, you know,
like with anti-Cryonistsists and like the mean word for them is like deathists. Like no one's
a deathist. Like no one's a self-described deathist and they are there being a troll. And if they're
not being a troll, then they're an idiot. So I realized I just like to find somebody out of
existence, but whatever. Like, but we use it to encompass people who, you know, are okay with
death and you attach an ish to it to make it sound like it's an intentional thing on their part,
which makes it seem ridiculous, which I get how that's a move, but now I'm tired enough.
It's a good move. Yeah. If you're, if you're being sneaky, you know what? I'm willing to use a
tiny little bit of gray arts to get people to sign up for Cryonix, especially because it's a very
obvious gray art. I know you're gonna call someone a deathist. I know it's not like there.
I know you're gonna say that. So I'm on board and I, and it's sneaky, but it's sneaky in a good
way. Yeah. It's kind of a reframing exercise. Thank you. That's a much better way. Yes. High five.
So third alternative to afterlife ism. Afterlife ism is exactly what it sounds like.
People can't go on living knowing they're going to die. So we have to give them this fantasy of
an afterlife, right? And the, the question areas are proposes is that if the problem is that people
are terrified of ceasing to exist, uh, is there some other way to combat that aside from this
crazy afterlife belief thing? And he asks, did you close your eyes and think creatively about
the problem for five minutes? Like as an actual straight up yes or no factual question to anyone
at all, like either people who are pro this or against it, have you just stopped for five minutes
and really thought of other ways of, of ending this existential terror besides the religion
thing? Which is first of all, a thing that I would like to say to a number of people I know who are
like, I want to say pragmatically religious. They seem like they don't necessarily believe in any of
the Jesus and mystical spiritual stuff, but just think it's a good thing for society in general.
I'm like, that's great. Have you actually thought for five minutes if there's other ways to solve
these problems that you say exist? Because I think there might be. And I think almost all of them
would say no, I have not sat down for five minutes with that goal of thinking of other solutions.
To be fair, it's rare that I actually set aside five minutes. I mean, even since reading this post
what seven or eight years ago, like I've actually set a timer maybe twice. But what I have done is
actually set a deliberate like focus period, whether like I'm watching a clock or not. But
you know, I think I did do that for cryonics, but I probably spent, then I thought about it for
five minutes and then I spent months deliberating and talking to other cryonists I knew. But the,
I don't know, don't take my lack of actually engaging the exercise as a way to do it. I think
whether or not you're using a clock, the idea is like that you don't say, all right, I'm going to
think about this and then like not specify a time and then decide that you've done enough thinking
after 30 seconds. That's what you're trying to avoid by setting a clock.
So Eliezer says that at the very least in alternatives for afterlifeism, I would cite
medical nanotechnology, the argument from actuarial escape velocity cryonics or meddling with the
forbidden ultimate technology, which when you click, these are all links to different things.
Actuarial escape velocity is the idea that as life extension gets better and better,
we might get to the point where life extension starts going faster than your aging.
But I think Aubrey de Grey calls longevity escape velocity.
Yes. And the meddling with the forbidden ultimate technology, if you click the link is
over to intelligence.org, an AI research place. And I just wanted to point out that the reason
this is called meddling with the forbidden ultimate technology is in part because at the
time he was writing it, there was a moratorium about talking about AI stuff on less wrong.
When he first left overcoming bias, a lot of conversation kept like going back to that
and distracting from anything else anyone was trying to say, specifically about
rationality and biases and those sorts of things. So he's like, all right, I'm starting this website
less wrong. But for the first, I don't remember how many months it was like six months or nine
months or something. But for the first X months, no one is allowed to talk about AI at all. We're
talking about other subjects, and then we'll get back to AI. And I believe that is part of the
reason it was called that and also, you know, for fun, which is a really smart like strategy.
The whole endeavor of creating less wrong, I think it's just an awesome example of
taking a long goal, thinking of a way to do it. That's actually hard. He wrote a blog post every
day for like two and a half years, and all the steps that he did in the middle, and including
like the idea of this whole endeavor, correct me if I'm wrong, a other than raising their sanity
waterline, basically it was raised to raise it high enough to people to send money to fund AI
research. And so like, if you're daisy chaining people along the way to give them all the cognitive
tools they need to see that this is a good idea, and to try to bridge that huge inferential distance
by keep dropping AI all along the way, they're going to keep trying to jump to the end of the
daisy chain road rather than walking it, right? And if they don't walk it, they're not going to
learn everything they need to learn on the way there. So if you just think, again, just high
five, I think that was awesome. Yeah, also, there's a lot of other cool things that have come out of
the rationalist community than AI. Totally. AI is cool and groovy, but there's a lot of really
nice instrumental stuff that I've gotten personally. Epistemic stuff, you know, there's all kinds of
good stuff. Effective altruism was one of the major spawning grounds for that was also less wrong.
Yeah, I didn't mean to say that was the only thing or maybe even the only intended goal,
but like, if the collateral damage for getting more funding and more social support for AI research
is making better, smarter, happier people than like, so be it. I don't think it was that cold and
calculating, but maybe it would have been if Robin Hansen did it. Cold and calculating in the best
loving way. Yeah, Hansen's great. And also, you know, it is a common theme that this AI is the
ultimate technology and probably should be forbidden until we figure out how to do it without
destroying the world. So fingers crossed. Yeah, God, that's that sounds like sort of grim.
He does say that any one of those third alternatives that he mentioned stretches
credulity less than a soul, which I mean, yeah, because depending on your priors, but magic has
been proven true zero times. We've proven all kinds of medical technology. You have not yet
heard the good news of our Lord and Savior. That's exactly what I was going to say. There is miracles,
there is magic. Yeah. Yeah, anyway, if you're coming from there, there's a lot more distance to
cross there. Yeah, but yeah, at least each of those things is physically possible, as opposed to
a soul which isn't totally not even a defined thing. Right. Yeah, I had Chronix in the mind
because I was talking to my life insurance agent yesterday evening and what's today, Tuesday. So
yeah, new co workers started my job yesterday and me and a other guy in the office when I was leaving
work early to go talk to my life insurance guy. I get in the five minute picture on Chronix and
I forget where I was going with that, but it was fun and rewarding and I'm well past the point where
I'm like socially anxious about talking about it. So that was cool. I mean, like souls are on the
face completely ridiculous. And like if you get a lot of inculcation of it in your early childhood,
it can eventually be like accepted. But then on deep examination, it's also completely ridiculous.
So on both ends of the spectrum, it's just completely dumb. Like what
it's hard to even compare the two, you know? Yeah, I think that's the important thing. And I get
where like, Oh, you know, medical technology or telling me that's more likely than souls
say it says somebody and then the answer is like, Yes, like one, yes, it stretches credulity because
it's mystery, future tech, but it stays within everything that we currently understand about
physics. There's no reason this shouldn't work. And like for me to believe what you believe about
magic or souls or whatever, like that requires a huge that requires me to throw out their established
model of physics. And that's, you're not, that's not you're not providing enough extraordinary
evidence for why that's true for me to throw away the standard model. Yes. There's last bullet
point here that I wanted to ask you about because I think you put in the comments on it. I did. So
afterlife ism stands immediately convicted because it cannot be the best strategy,
even as a noble lie. Yeah. And Inyash asks, really?
Yeah, because he he stressed even as a noble lie. And I think that all those tech things are
definitely well, I mean, they're true. They're not mystical fake magic stuff, which is a huge
point in their favor. But they're all things that can work in the future, right? And so they're very
convincing, not very convincing. They're much more appealing to people who still have a lot of
future in front of them. Like Elia has wrote this in the 20s, in his 20s, the majority of the reader
based then was late teens to late 20s. Even nowadays, rationality is more of a 20s to 30s
kind of thing. There's not that many people over the age of like their mid 40s in the movement.
So all those things are still great for people who are youngish, but like
someone who's 80 and on their deathbed, they're obviously not going to get the benefit of medical
nanotechnology or the longevity escape velocity or meddling with AI's because they got like a year.
At best, maybe they got cryonics. And that's what they can afford it?
That well, yeah, that's if they can afford it. Well, yeah, that's if they can afford it, which is a
big if to a lot of people who are in their 80s that don't really have life insurance policy for
this. And it just seems like for someone like that, the only thing you have left is either accept
that I'm going to be extinguished or believe in the noble lie, like all those other things don't
work once you're ready at the end of the life. Whereas the soul is something you're at least
like, ooh, there's there's a chance, you know, because the other things are now impossible.
Yeah, I think you're absolutely right. I think like if you're on your deathbed and there's no
time to do anything else, like it would be nice to believe a consoling lie, like just just to
stave off the horror of the next few, whatever, however long you have left. Maybe it depends on
the person. I think Christopher Hitchens was just fine. Yeah, that's true. But to him, death wasn't
a horror. He was I think what we might call a deathist. Like it wasn't he wasn't pro death,
but he wasn't like, he I don't think death was the enemy to him. Right. And like, Richard Dawkins,
I can I'll find a great YouTube video of it. He has in the opening, I think the beginning of
the second chapter of Unweaving the Rainbow is this beautiful couple paragraphs about the the
in the scientific sense of the word miracle of being alive. Yeah, the implausibility that you
managed to be here and have any experiences at all. Yeah, you get time in the sun in the universe
and on the earth. It's it's that that just saying that fills with this like sense of gratitude and
wonder. And there was a time like between when I like got out of religion and when I got into,
I don't know, being totally horrified of death that I found that very consoling for a few years.
And in a way it is like, even if I end up being annihilated, like being alive was cool. I'm glad
I had the chance to be nice if it, you know, didn't go away. But the like, I think, oh, I was going
to say as far as like a for another global lie, a better noble lie, I think by anyone else is
like by the rationalist metric would be like Chronix works. Yeah, no, that's I absolutely agree
with you. Yeah. Oh, no, this works great. It's just, you know, be ready in 20 years.
I think it's a lie. I think it's something that you hope for. Yeah, right. But if we were going
to pitch it in a form of a noble lie, it would be a better lie than the soul thing, because it's
more plausible. Yeah. And it actually has the collateral damage benefit of saving people. Right.
Or at least potentially saving them. Yeah. The yeah, I think the the afterlife is also has
all this inertia from all of society, like being on this train, not all of society, but a lot of
society being on this train and pushing this and it being taught to you as a child. All those things
are advantages that are absolutely unfair and stupid. But I think do make it easier to swallow
and to find comfort in it, especially when you really need it at the end of your life for a bunch
of people. Yeah. If that's where you're at, like I remember when I was like losing like during that
fun phase in high school, where I argued religion with a lot of people, that'd be kind of like
their like line of retreat where they'd like, you know, take their last stand and like, you're
going to tell somebody in their death bed that like religion's bullshit and it's not true. And
I think for the first few times I was asked that was like, yeah, they should know better.
But that wasn't like really thinking when you get a moment to really think about it, like, no,
I'm not going to ruin someone's happy delirium, like when they're literally dying. I think there's
a difference between going and like, if it's someone who already believes in a soul and is
comforted by that, like bursting into their death bed and being like, hey, guess what? But like,
if it were, you know, I wouldn't tell somebody who didn't believe in souls that like, oh, don't
worry, you're going to live forever in a child land, playing a harp with little angel wings and
doing, I don't know what all day. Watching after people. Yeah, they spend a lot of time doing.
Yeah. That's why I think it's just, it's a slight overstatement to say that after life,
life after life isn't as immediately convicted, because it cannot be the best strategy,
even as a noble lie. I think in some rare cases it can.
I don't think LA areas would disagree with you on that. But that's me totally
but a typical minding. Yeah. Well, I'm just thinking like, I don't think he had that edge
case in mind. I think he thought of like the general like, live after life ism that we give
is better, better supplanted by any of these examples in the general case.
I think it's even better supplanted by just thinking about death better.
Yeah. The Richard Dawkins version is beautiful and enchanting and comforting in a way.
Yeah. I have this book by Greta Christina. I think the title was Better Ways to Think
About Death That Don't Involve God. I'd have to find the title exactly.
But it's a great title if that's not it. I'm kind of just, it was very similar to that.
But like, if I were that 80 year old, I would rather be hopeful about cryonics or medical
advances working for my children or my friend's children or just like, you know, other humans
that aren't me. Like it's not all about me. Also, the whole gratitude about like, man,
it sure was cool that I was able to be here. And instead of thinking about fake magic stuff
and being all consoled by it, I'd rather spend my last few minutes kind of having experience.
I don't know that like maybe the experiences are just like being an incredible pain, but
you're not going to, I don't know if souls are really going to make that that much better.
Yeah. I think to be fair, like when you're being consoled by the noble lie of afterlife ism,
you know, you're not like consciously aware that you're being consoled by the noble
lie of afterlife ism, right? You just feel safe and secure. And so, like, while it would be
great to know that like medical science will keep my grandchildren from dying or something,
if I actually just thought like, I don't want that because they're going to join me in heaven
in 60 years, like, if I really believe that in my heart of hearts, like, I feel like that would be
probably a great way to feel. Maybe I will. How could it not be? Yeah. If you thought it was a
great place and you thought you'd see everybody you cared about and they'd all see you later.
Like, I remember when I was a teenager, I knew somebody whose parents were younger
with creationists and they were like super fundamentalist religious people. And one of
their, one of their sisters died and they were like distraught seeking therapy for months.
And they were like a wreck about it. And like, I totally understood because I wasn't at the stage
at that time where I was like 14 where like, I would be okay with somebody that I cared about
in my family dying or something. But I was, I wasn't quite so tactless to ask like, why does
this bother you? Like, aren't you going to see her again in 30 years? Like, isn't she like
way better off now than she was a month ago when she was alive here on earth because this place
sucks compared to heaven? So at least in one use case, and I'm given to understand more,
people say they're comforted by this, but they really aren't. Like, it's still
terribly distressing and stuff. Yeah. I remember being a Christian kid and believing in heaven and
then still being very scared of death and not wanting my friends and family and pets to die.
It's like part of you knew that's interesting. Well, yeah, I mean, that's, I think most people
are probably compartmentalizing that because like, we still cry at funerals, we don't like
laugh and go, Oh, it's great that this person died or we don't all commit suicide because heaven's so
great. Right. Well, like, I think the epist, the epist, what do you call it, the memetic
advantage of that is like, you can't, your, your meme can't say, if you die, you get here
no matter what, because everyone, and if everyone believes that going there is great,
they'll all kill themselves immediately, right? You have to throw in the package.
Everyone gets in unless you kill yourself. Yeah. Right. That's why that's why suicide is a mortal
sin. Yeah. I guess moral of the story is, unless you plan to have $100,000 when you die in cash
or, you know, the inflation adjusted equivalent, get insurance now and sign up for cryonics.
Yeah. And honestly, you'd have to sign up for cryonics anyway, but also get the insurance
to fund it. Yeah. The five second pitch is that Chronix Institute charges 120 bucks a year, which
is substantially less than your Netflix subscription. Or one-time payment of $1,000.
Exactly. Yeah. So if you're planning on being a member for more than 10 years, you save money
that way, or nine years, mind your own math. I have now reached the point where I'm saving money.
Nice. Yeah. I need to do that this year, I think. Mine re-ups in May. And a life insurance policy
for a healthy-ish 20-something-year-old is like 30 bucks a month, which is nothing to take a stick
at for a lot of people. It was hard on me for the first few years, but like, if you can swing it,
man, look at the rates for signing up for life insurance in your 50s. It's hundreds of dollars
a month. It's insane. And just the fact that if I were to get cancer tomorrow, I wouldn't be like,
well, shit, I'm probably fucked. I mean, I'm still probably fucked, but at least now I have
that glimmer of hope, whereas if I were to get it tomorrow, I'm like, damn it, it's too late for me
to get life insurance now. What am I going to do? This is the kind of thing that you should have set
up before you need it. Yes, exactly. As they say in Poland, it's too late to dig the well
once your house is already on fire. I thought it was going to be, never mind. Awesome. Well,
that sounds good. All right. We're getting close to the end, so we got to finish this up.
Sounds good. Go ahead. Oh, well, I'll save this for the non-existent side topic section that we'll
get to after we plug the next time posts. Okay. We have scope and sensitivity, one of my favorites.
I think everyone's familiar with it at some point, and One Life Against the World,
which sounds super dramatic and exciting, so stay tuned. Excellent. Or read ahead and join us
in two weeks. Yeah, and links will be, as always, at the basinconspiracy.com. That's right. But before
we sign off, I sent you guys a message earlier this week, might have been the weekend. Okay.
Speaking of all this solism and afterlifeism, God's real guys. Is what? E3, they launched a
trailer for Breath of the Wild 2. Oh, right. Nothing's been more compelling evidence to me.
We've had people write in, send us some cool arguments, and no, man, they don't make sequels
to Delta games. They certainly, I don't think they're going to make a sequel to Breath of the
Wild. It looks like it picks up right after the first one. This is proof positive. Finally.
It's a miracle. A miracle in every sense of the word. Oh, that said, I should find,
give me just one second here. Oh, yes, great Reddit name. Operation Question sent in a link
to a podcast that I actually enjoy called, Philosophize This. And the, I've only listened to
four or five episodes. The authors or the host clearly has like a slant. Basically, it takes
philosophers or specific ideas and just talks about it for like 30 minutes in a cool way.
And it's approachable if you, you know, miss having a good philosophy podcast in your life,
because you listened to all of the Philosophy of Whites episodes when they were out in 2011.
Maybe they're still making them. I don't know, whatever. I haven't had a philosophy podcast
in my feed for a long time, so it's a good, it's a good fun thing. So thank you, Operation Question.
And that's, Philosophize This? Yep, Philosophize This with an exclamation point,
but I just put in FIL and it found it anyway, but maybe it's smart search or something.
FIL? F-I-L? Or pfft. Geez. All right, time to sign off.
P-H, I was looking at it, looking at the letters, I still phonetically said it. Yeah, it's spelled
Philosophize This like you actually spelled both of those words, not like I just tried to spell it.
Cool. And I think that's all I should say for the night, so.
Before we sign off, I have one last thing.
Patron? What's that?
We gotta thank a patron too. And yes, so we got two more things.
Yes, sorry. The thing before the thanking the patron is that this episode will release on July
3rd, and which means that when this episode releases, my novel will now be officially out to buy.
It'll be in its first week of release, just have released a few hours before this episode.
It'll be available both in ebook and in paper versions.
If anyone has any interest in reading this, buying it someday in the future, I would like to ask,
if you know you're going to buy it anyway at some point, please buy it in the first week.
That makes a huge difference for Amazon's various algorithms as to whether they will
show this to other people or, you know, recommended anything.
The really the first week sales are unreasonably highly weighted in my opinion, but that's what
they are. So please, if you are going to now would be a good time. I would also say in promotion of
my own book, when I was writing this, I workshopped it at the Northern Colorado Writers Workshop,
which is Writers Workshop, which was run by Ed Bryant, not anymore, because he died a couple
years ago. But Ed Bryant, a big name in older sci-fi, he won two Nebula awards, presented,
you know, at the Nebulas. He worked with Stan Lee on some comics. He worked with George R.R.
Martin frequently on their wild cards. You guys can hear my expression changing. This keeps
getting higher and higher and awesomeness. Yeah, yeah. So, I mean, Ed Bryant was a name back in the
day and, you know, he helped me out in a few places. He had some nice things to say, but
probably what I will never forget is that in one of the, he was old fashioned because, you know,
he was old at this point. He died basically of old age. He always wanted all his stuff in
paper copy. Like everyone else, I'd send emails and stuff, but he would get printouts. And in one
of the printouts that I got back across the top, he wrote bravara writing with an exclamation point.
And I was like, fucking awesome. Oh, I love that. Yeah. That was the coolest thing I've ever had.
Like, I don't know. Not only was it like enthusiasm for my writing, it was enthusiasm for my writing
from someone who's this big in the field, you know? So, anyways, if you would like to read
some bravara writing, as said by Ed Bryant, please check out What Lies Dreaming, available at
all sorts of places, but also at Amazon. The paper copy is quite a bit more expensive than
the ebook copy because, you know, I don't have a traditional publisher, so print on demand is
quite a bit more expensive than running 2000 books at once and warehousing them. But yeah,
if you really want a paper copy, you can get it. Cool. Are you comfortable dropping the price
dropping? Oh, oh, oh, yeah. The ebook is $9.59. And then the paper book is like $16.99, I think.
I don't remember just now. I thought you were going to say $16.99 or something. No, no,
not that. Say print another seven bucks for a paper copy. Yeah. I think that's way more than
a display on your shelf. Yeah. I don't buy a lot of books on Amazon, but like,
I think paper copies typically cost about twice as much at least, so. I don't think they cost
twice as much, but they always cost more. Well, I'm glad I asked because you scared me away by
saying like, oh, it's way more expensive. It's another few bucks. You're still getting a paperback
book of a given a claim by a renowned author for 17 bucks. Yeah. Sounds dope. Okay. All right.
Also, the book title is What Lies Dreaming. Yes. We should keep saying that.
I feel like you keep forgetting to say what the title is. The title is What Lies Dreaming.
I did make sure that he said it like a minute ago, but you almost got a boy without saying it.
All right. Cool. Okay. We can touch on everything else and more feedback later,
because it's late. Yes, the name. Whose turn is it? Jesses. All right. Our patron this time is
Marcine Jaco. I don't know if that's how you pronounce it. They always give me the hard ones.
Marcine, thank you for your support. We appreciate you. And you're the reason that
we were able to keep doing what we do. Hell yeah. Thank you, Marcine. Yeah, thank you.
Once again, we really appreciate it. And we do have some very vague rewards on our Patreon page.
I think a lot of other shows that are maybe put a little more time in production actually like
have tiered awesome rewards. But basically, if you support the show and you want literally
anything within reason, shoot us a message and we'll see if we can make it happen or we can
negotiate something. So seriously, Patreon message, go straight to our inbox. We'll respond as soon as
we can. Yeah. You can comment on our website, TheBaseInConspiracy.com. You can comment on the
in the subreddit, which is where a lot of the feedback happens at r slash basin conspiracy.
I think it's TheBaseInConspiracy. Okay. And yeah, thanks for listening. You guys are awesome.
Awesome. Have a great night. Bye.
