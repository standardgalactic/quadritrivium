a deathist. Like no one's a self-described deathist and they are there being a troll. And if they're
not being a troll, then they're an idiot. So I realized I just like to find somebody out of
existence, but whatever. Like, but we use it to encompass people who, you know, are okay with
death and you attach an ish to it to make it sound like it's an intentional thing on their part,
which makes it seem ridiculous, which I get how that's a move, but now I'm tired enough.
It's a good move. Yeah. If you're, if you're being sneaky, you know what? I'm willing to use a
tiny little bit of gray arts to get people to sign up for Cryonix, especially because it's a very
obvious gray art. I know you're gonna call someone a deathist. I know it's not like there.
I know you're gonna say that. So I'm on board and I, and it's sneaky, but it's sneaky in a good
way. Yeah. It's kind of a reframing exercise. Thank you. That's a much better way. Yes. High five.
So third alternative to afterlife ism. Afterlife ism is exactly what it sounds like.
People can't go on living knowing they're going to die. So we have to give them this fantasy of
an afterlife, right? And the, the question areas are proposes is that if the problem is that people
are terrified of ceasing to exist, uh, is there some other way to combat that aside from this
crazy afterlife belief thing? And he asks, did you close your eyes and think creatively about
the problem for five minutes? Like as an actual straight up yes or no factual question to anyone
at all, like either people who are pro this or against it, have you just stopped for five minutes
and really thought of other ways of, of ending this existential terror besides the religion
thing? Which is first of all, a thing that I would like to say to a number of people I know who are
like, I want to say pragmatically religious. They seem like they don't necessarily believe in any of
the Jesus and mystical spiritual stuff, but just think it's a good thing for society in general.
I'm like, that's great. Have you actually thought for five minutes if there's other ways to solve
these problems that you say exist? Because I think there might be. And I think almost all of them
would say no, I have not sat down for five minutes with that goal of thinking of other solutions.
To be fair, it's rare that I actually set aside five minutes. I mean, even since reading this post
what seven or eight years ago, like I've actually set a timer maybe twice. But what I have done is
actually set a deliberate like focus period, whether like I'm watching a clock or not. But
you know, I think I did do that for cryonics, but I probably spent, then I thought about it for
five minutes and then I spent months deliberating and talking to other cryonists I knew. But the,
I don't know, don't take my lack of actually engaging the exercise as a way to do it. I think
whether or not you're using a clock, the idea is like that you don't say, all right, I'm going to
think about this and then like not specify a time and then decide that you've done enough thinking
after 30 seconds. That's what you're trying to avoid by setting a clock.
So Eliezer says that at the very least in alternatives for afterlifeism, I would cite
medical nanotechnology, the argument from actuarial escape velocity cryonics or meddling with the
forbidden ultimate technology, which when you click, these are all links to different things.
Actuarial escape velocity is the idea that as life extension gets better and better,
we might get to the point where life extension starts going faster than your aging.
But I think Aubrey de Grey calls longevity escape velocity.
Yes. And the meddling with the forbidden ultimate technology, if you click the link is
over to intelligence.org, an AI research place. And I just wanted to point out that the reason
this is called meddling with the forbidden ultimate technology is in part because at the
time he was writing it, there was a moratorium about talking about AI stuff on less wrong.
When he first left overcoming bias, a lot of conversation kept like going back to that
and distracting from anything else anyone was trying to say, specifically about
rationality and biases and those sorts of things. So he's like, all right, I'm starting this website
less wrong. But for the first, I don't remember how many months it was like six months or nine
months or something. But for the first X months, no one is allowed to talk about AI at all. We're
talking about other subjects, and then we'll get back to AI. And I believe that is part of the
reason it was called that and also, you know, for fun, which is a really smart like strategy.
The whole endeavor of creating less wrong, I think it's just an awesome example of
taking a long goal, thinking of a way to do it. That's actually hard. He wrote a blog post every
day for like two and a half years, and all the steps that he did in the middle, and including
like the idea of this whole endeavor, correct me if I'm wrong, a other than raising their sanity
waterline, basically it was raised to raise it high enough to people to send money to fund AI
research. And so like, if you're daisy chaining people along the way to give them all the cognitive
tools they need to see that this is a good idea, and to try to bridge that huge inferential distance
by keep dropping AI all along the way, they're going to keep trying to jump to the end of the
daisy chain road rather than walking it, right? And if they don't walk it, they're not going to
learn everything they need to learn on the way there. So if you just think, again, just high
five, I think that was awesome. Yeah, also, there's a lot of other cool things that have come out of
the rationalist community than AI. Totally. AI is cool and groovy, but there's a lot of really
nice instrumental stuff that I've gotten personally. Epistemic stuff, you know, there's all kinds of
good stuff. Effective altruism was one of the major spawning grounds for that was also less wrong.
Yeah, I didn't mean to say that was the only thing or maybe even the only intended goal,
but like, if the collateral damage for getting more funding and more social support for AI research
is making better, smarter, happier people than like, so be it. I don't think it was that cold and
calculating, but maybe it would have been if Robin Hansen did it. Cold and calculating in the best
loving way. Yeah, Hansen's great. And also, you know, it is a common theme that this AI is the
ultimate technology and probably should be forbidden until we figure out how to do it without
destroying the world. So fingers crossed. Yeah, God, that's that sounds like sort of grim.
He does say that any one of those third alternatives that he mentioned stretches
credulity less than a soul, which I mean, yeah, because depending on your priors, but magic has
been proven true zero times. We've proven all kinds of medical technology. You have not yet
heard the good news of our Lord and Savior. That's exactly what I was going to say. There is miracles,
there is magic. Yeah. Yeah, anyway, if you're coming from there, there's a lot more distance to
cross there. Yeah, but yeah, at least each of those things is physically possible, as opposed to
a soul which isn't totally not even a defined thing. Right. Yeah, I had Chronix in the mind
because I was talking to my life insurance agent yesterday evening and what's today, Tuesday. So
yeah, new co workers started my job yesterday and me and a other guy in the office when I was leaving
work early to go talk to my life insurance guy. I get in the five minute picture on Chronix and
I forget where I was going with that, but it was fun and rewarding and I'm well past the point where
I'm like socially anxious about talking about it. So that was cool. I mean, like souls are on the
face completely ridiculous. And like if you get a lot of inculcation of it in your early childhood,
it can eventually be like accepted. But then on deep examination, it's also completely ridiculous.
So on both ends of the spectrum, it's just completely dumb. Like what
it's hard to even compare the two, you know? Yeah, I think that's the important thing. And I get
where like, Oh, you know, medical technology or telling me that's more likely than souls
say it says somebody and then the answer is like, Yes, like one, yes, it stretches credulity because
it's mystery, future tech, but it stays within everything that we currently understand about
physics. There's no reason this shouldn't work. And like for me to believe what you believe about
magic or souls or whatever, like that requires a huge that requires me to throw out their established
model of physics. And that's, you're not, that's not you're not providing enough extraordinary
evidence for why that's true for me to throw away the standard model. Yes. There's last bullet
point here that I wanted to ask you about because I think you put in the comments on it. I did. So
afterlife ism stands immediately convicted because it cannot be the best strategy,
even as a noble lie. Yeah. And Inyash asks, really?
Yeah, because he he stressed even as a noble lie. And I think that all those tech things are
definitely well, I mean, they're true. They're not mystical fake magic stuff, which is a huge
point in their favor. But they're all things that can work in the future, right? And so they're very
convincing, not very convincing. They're much more appealing to people who still have a lot of
future in front of them. Like Elia has wrote this in the 20s, in his 20s, the majority of the reader
based then was late teens to late 20s. Even nowadays, rationality is more of a 20s to 30s
kind of thing. There's not that many people over the age of like their mid 40s in the movement.
So all those things are still great for people who are youngish, but like
someone who's 80 and on their deathbed, they're obviously not going to get the benefit of medical
nanotechnology or the longevity escape velocity or meddling with AI's because they got like a year.
At best, maybe they got cryonics. And that's what they can afford it?
That well, yeah, that's if they can afford it. Well, yeah, that's if they can afford it, which is a
big if to a lot of people who are in their 80s that don't really have life insurance policy for
this. And it just seems like for someone like that, the only thing you have left is either accept
that I'm going to be extinguished or believe in the noble lie, like all those other things don't
work once you're ready at the end of the life. Whereas the soul is something you're at least
like, ooh, there's there's a chance, you know, because the other things are now impossible.
Yeah, I think you're absolutely right. I think like if you're on your deathbed and there's no
time to do anything else, like it would be nice to believe a consoling lie, like just just to
stave off the horror of the next few, whatever, however long you have left. Maybe it depends on
the person. I think Christopher Hitchens was just fine. Yeah, that's true. But to him, death wasn't
a horror. He was I think what we might call a deathist. Like it wasn't he wasn't pro death,
but he wasn't like, he I don't think death was the enemy to him. Right. And like, Richard Dawkins,
I can I'll find a great YouTube video of it. He has in the opening, I think the beginning of
the second chapter of Unweaving the Rainbow is this beautiful couple paragraphs about the the
in the scientific sense of the word miracle of being alive. Yeah, the implausibility that you
managed to be here and have any experiences at all. Yeah, you get time in the sun in the universe
and on the earth. It's it's that that just saying that fills with this like sense of gratitude and
wonder. And there was a time like between when I like got out of religion and when I got into,
I don't know, being totally horrified of death that I found that very consoling for a few years.
And in a way it is like, even if I end up being annihilated, like being alive was cool. I'm glad
I had the chance to be nice if it, you know, didn't go away. But the like, I think, oh, I was going
to say as far as like a for another global lie, a better noble lie, I think by anyone else is
like by the rationalist metric would be like Chronix works. Yeah, no, that's I absolutely agree
with you. Yeah. Oh, no, this works great. It's just, you know, be ready in 20 years.
I think it's a lie. I think it's something that you hope for. Yeah, right. But if we were going
to pitch it in a form of a noble lie, it would be a better lie than the soul thing, because it's
more plausible. Yeah. And it actually has the collateral damage benefit of saving people. Right.
Or at least potentially saving them. Yeah. The yeah, I think the the afterlife is also has
all this inertia from all of society, like being on this train, not all of society, but a lot of
society being on this train and pushing this and it being taught to you as a child. All those things
are advantages that are absolutely unfair and stupid. But I think do make it easier to swallow
and to find comfort in it, especially when you really need it at the end of your life for a bunch
of people. Yeah. If that's where you're at, like I remember when I was like losing like during that
fun phase in high school, where I argued religion with a lot of people, that'd be kind of like
their like line of retreat where they'd like, you know, take their last stand and like, you're
going to tell somebody in their death bed that like religion's bullshit and it's not true. And
I think for the first few times I was asked that was like, yeah, they should know better.
But that wasn't like really thinking when you get a moment to really think about it, like, no,
I'm not going to ruin someone's happy delirium, like when they're literally dying. I think there's
a difference between going and like, if it's someone who already believes in a soul and is
comforted by that, like bursting into their death bed and being like, hey, guess what? But like,
if it were, you know, I wouldn't tell somebody who didn't believe in souls that like, oh, don't
worry, you're going to live forever in a child land, playing a harp with little angel wings and
doing, I don't know what all day. Watching after people. Yeah, they spend a lot of time doing.
Yeah. That's why I think it's just, it's a slight overstatement to say that after life,
life after life isn't as immediately convicted, because it cannot be the best strategy,
even as a noble lie. I think in some rare cases it can.
I don't think LA areas would disagree with you on that. But that's me totally
but a typical minding. Yeah. Well, I'm just thinking like, I don't think he had that edge
case in mind. I think he thought of like the general like, live after life ism that we give
is better, better supplanted by any of these examples in the general case.
I think it's even better supplanted by just thinking about death better.
Yeah. The Richard Dawkins version is beautiful and enchanting and comforting in a way.
Yeah. I have this book by Greta Christina. I think the title was Better Ways to Think
About Death That Don't Involve God. I'd have to find the title exactly.
But it's a great title if that's not it. I'm kind of just, it was very similar to that.
But like, if I were that 80 year old, I would rather be hopeful about cryonics or medical
advances working for my children or my friend's children or just like, you know, other humans
that aren't me. Like it's not all about me. Also, the whole gratitude about like, man,
it sure was cool that I was able to be here. And instead of thinking about fake magic stuff
and being all consoled by it, I'd rather spend my last few minutes kind of having experience.
I don't know that like maybe the experiences are just like being an incredible pain, but
you're not going to, I don't know if souls are really going to make that that much better.
Yeah. I think to be fair, like when you're being consoled by the noble lie of afterlife ism,
you know, you're not like consciously aware that you're being consoled by the noble
lie of afterlife ism, right? You just feel safe and secure. And so, like, while it would be
great to know that like medical science will keep my grandchildren from dying or something,
if I actually just thought like, I don't want that because they're going to join me in heaven
in 60 years, like, if I really believe that in my heart of hearts, like, I feel like that would be
probably a great way to feel. Maybe I will. How could it not be? Yeah. If you thought it was a
great place and you thought you'd see everybody you cared about and they'd all see you later.
Like, I remember when I was a teenager, I knew somebody whose parents were younger
with creationists and they were like super fundamentalist religious people. And one of
their, one of their sisters died and they were like distraught seeking therapy for months.
And they were like a wreck about it. And like, I totally understood because I wasn't at the stage
at that time where I was like 14 where like, I would be okay with somebody that I cared about
in my family dying or something. But I was, I wasn't quite so tactless to ask like, why does
this bother you? Like, aren't you going to see her again in 30 years? Like, isn't she like
way better off now than she was a month ago when she was alive here on earth because this place
sucks compared to heaven? So at least in one use case, and I'm given to understand more,
people say they're comforted by this, but they really aren't. Like, it's still
terribly distressing and stuff. Yeah. I remember being a Christian kid and believing in heaven and
then still being very scared of death and not wanting my friends and family and pets to die.
It's like part of you knew that's interesting. Well, yeah, I mean, that's, I think most people
are probably compartmentalizing that because like, we still cry at funerals, we don't like
laugh and go, Oh, it's great that this person died or we don't all commit suicide because heaven's so
great. Right. Well, like, I think the epist, the epist, what do you call it, the memetic
advantage of that is like, you can't, your, your meme can't say, if you die, you get here
no matter what, because everyone, and if everyone believes that going there is great,
they'll all kill themselves immediately, right? You have to throw in the package.
Everyone gets in unless you kill yourself. Yeah. Right. That's why that's why suicide is a mortal
sin. Yeah. I guess moral of the story is, unless you plan to have $100,000 when you die in cash
