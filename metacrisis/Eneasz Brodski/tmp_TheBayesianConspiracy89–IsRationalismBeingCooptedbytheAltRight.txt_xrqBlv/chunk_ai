yeah yeah i think that that is completely within someone's rights to
choose and i respect their decision absolutely i also think that
i'm gonna reduce my judgment from cowardly to overly cautious in my
opinion but i do get where he's coming from well i think if you're one of the
like 50 people in the world working on what you think is the most
important problem for the human species you might want to take a little extra
care with your brain which i totally understand
um i what do you guys think like i think i don't know what the high of making a
new scientific discovery is like it's probably not the same as a drug
high like i'm not sure they're even comparable
but i also think the new scientific uh i know what this feeling is like
okay or at least i have had a mini taste of
it um so i don't know if i mentioned this to
you guys a while ago but i found this little buddhist
palm manual of non-newtonian calculus oh yes
and did but i think this may be an entire episode
yeah but the main point was i have been going through the process of deciphering
this weird abstract form of math and finding new applications for it
and at least one of them was completely novel like i've checked
every academic source i could in multiple languages
i think i have a completely unique math paper
and i have done a lot of drugs in my life and i can tell you
it is a comparable high and the math one is better because it's not just a
fleeting high it's like a warm feeling of satisfaction
that's growing more and more as i polish my work and work on my paper
i was going to say that i think that even if the drug one might be better
for like a few minutes like the drug thing goes away whereas
an accomplishment like that you have for the rest of your life
and maybe i haven't tried the right drugs but yeah i've tried like
you it's it's apples and oranges like i mean i guess because i'm always aware
that i've taken a drug and that's why i feel this way
um if i've done something nice for somebody and it's made you know made
them if if it's changed somebody's life and or you know if i figured something
out i've had small versions of both of those things not like an
innovative scientific discovery but for me that's why like programming when i
figure shit out i get that rush so it's a very small version of it because other
people can do it but when i do it originally it feels nice
um but the uh like with drug stuff it's like oh man i feel
crazy right now this is fun um like it's i mean you might as
well be comparing you know two other completely unrelated
things this is just like you know listening to a good song how does that
compare to like the joy of a scientific discovery it's like it doesn't
they're different they're completely different sensations for me yeah yeah i
don't even like i don't know i'm not gonna say i don't like
recreational drugs some of them are all right but i'm much more
interested in midafinil uh or cognitive enhancing drugs
nitropics and even psychedelics are interesting for me because it helps me
understand my own brain i think i mean i like mdma is the
drug i was comparing it to and that's just like a flood of happy chemicals
yeah based on the end based on the context of the post i was assuming that
he meant like recreational make you feel good and or happy
and i was thinking i think mdma too but like i still like i'm on it and it
felt great but like i knew like that you know it it
it wasn't like i like if you're it wasn't like i thought this feeling was
fake because the feeling is real it's as real as any feeling you can have because
it's your actual brain um but it's like i knew it wasn't
tethered to i we're kind of aside but yeah yeah
all right so back to the post then uh he says that it probably seems obvious to
almost everyone that yes the entire world is worth more than one life
but uh it might not be entirely that obvious to everyone
for example people who follow the greek greek conception of personal virtue
which uh rather than consequentialism which i feel slightly called out on not
because i'm a greek but because i am the virtue ethicist
he says uh someone who saves the world is virtuous uh because they are
fulfilling their duty to save life which is a virtue
but they're not six billion times more virtuous than someone who only saved one
life because they were also fulfilling that duty
they're certainly more virtuous if they save the whole world but not
six billion times more um and perhaps another way of of not
grasping this would be that uh the value of one human life is too great to
comprehend anyway so like a human just couldn't
comprehend it and it's like a scope in sense
insensitivity thing if one life is so immensely valuable
already how can you even think about you know saving the entire world
um and he points out that uh yes he agrees one life is of unimaginably high
value but that two human lives are twice as unimaginably unimaginably
valuable so um please save the entire world
if you have to uh you know if you manage to dedicate all of its resources
towards you know curing um whatever puppy disease or ALS
like he's he's saying yes that's like that's good
you can't say it's not good but like it is if we're gonna
if we need to we need to fix the most important thing and to him
you know it's obviously uh friendly AI research right
and he's probably right um certainly like
you know even like curing prostate or like whatever curing prostate cancer
breast cancer like great both good things but curing death
is a bigger is a bigger win and so like this is just
I think a of like the point of the post I guess
is almost to it's like if it was as simple as like what's
like written there it'd be like one sentence right I think the point is the
subtext of like no there's actually big problems that we need to actually solve
the really really really big problems that's that's how I read it
and he does say that if two deaf children are sleeping on railroad tracks
and uh someone screams at you to go save them if you run up
save one and uh then just kind of leave the other one there hang out have a
cigarette and I'm screaming quick go save the
second one too and uh Eleazar says eh I I already
saved one so I'm unimaginably ahead on points
because one life is unimaginably valuable I don't need to do another
unimaginably good deed and uh that that just does not seem
right at all plus you'd lose points for not saving the
second that's so weird what what's so weird
like
that doesn't even make sense by the definition of that worldview I don't
know if like isn't the goal isn't the goal to save an
unimaginably huge amount of good things you already did that when you saved one
because it's unimaginably valuable
so yeah it's also a fun like intuition pump for
like taboo trade-offs yeah right like I'm not going to bake up my hospital
buy one liver to save this little girl um because like we need to keep the
hospital running so I hate this can before we
continue by the way I was gonna say that one thing
I dislike about these posts is Julia Galef once said that
rationalists
try and work hard to get rid of the word should
from our vocabulary because it distracts from the reality that is there
and the reality that is there humans are sensitive to faces and
individuals so if we know that humans are scope
insensitive instead of saying humans should be changed into
beings who don't have this scope insensitivity
let's accept it as a fact of human nature until we can genetically modify
ourselves and work on creating tools that work
around it like people pictures and stuff like what
effective altruism and using those very mental biases to encourage us
in more intelligent donations this this post
does have a last paragraph here which I have issues with and
originally I wanted to not talk about it at all because I considered a memetic
hazard but then I figured one that would be cowardly
and two people who read this post are going to see it anyway so
I'm going to say right now that this next section of our podcast is a memetic
hazard you should probably avoid it if you
already have problems with guilt and super high scrupulosity
is that how you pronounce it okay uh because this will be
bad for you so um scrupulosity yeah feeling very responsible for everything
oh I call that heroic responsibility well this is more of a the bad version of
that thing yes this is also in my in in my head it's
always been a bad version too but I totally get it yeah okay I just thought
of her responsibility as a good thing method of rationality kind of give it a
great spin yeah but the way that I've had a complex
like that I've gotten over it I guess partly mainly it's by stopping caring
I guess about stuff I guess so I'll call it scrupulous scrupulosity
scrupulosity from now on so all right yeah so this next part um again
probably uh bad for people's emotional well-beings
and I would skip forward by about five minutes
uh if if you are in that but going forward
um he points out that combining scope insensitive
insensitivity the last post with uh this one uh if you were the guy who had the
two children on the train tracks and you only saved one and didn't save the
other one as if you could have uh not not only did you not save that
it's not you're not the person who saved one life you are the person who killed
one life when you could have because you could have saved the other one
so uh you have damned yourself he says you have damned yourself as thoroughly
as any murderer uh which he puts at the end of a sentence
at the end of a paragraph saying that
basically talking about donating money to curing fatal diseases right
um he says when human lives are at stake we have a duty
to maximize not satisfies and this duty has the same strength as the original
duty to save lives
so basically if you have any money left over after you're done providing for
your own uh continued existence all of it
should go to save other people is how I have interpreted these sorts of things
before and that really leads to a horrible life very quickly
yeah he also mentions that you should be disdained for uh
spending your life saving money inefficiently it's yeah so it'd be well
well wait wait I have a question does Elias or Yudkowski know anything about
mental health and like maybe people needing things like little luxuries to
keep themselves sane instead of just becoming
robots to give money to other people I think this is a common criticism
yes and it's like I think the I mean I imagine well maybe he
doesn't drink coffee but I imagine Elias here spends some of his time
like I mean he does in fact this was actually something I remember him being
called out for in the comments when he mentioned they had a girlfriend and
it's like what do you mean you hang out with your girlfriend aren't you like
busy saving the world how can you justify spending three hours
watching a movie when the you know those three hours could bring you know the
end of you know human death forward by five seconds right
hundred people to just kill aliizer yeah so like I think I don't remember
actually I remember his response to that it was
like grossly inadequate it was like you know those like quotes where like you're
not like typing it's like quote like shows girlfriends comments yeah they're
being super mean aren't they I wonder if he I'm sure there's more
rebuttal to that somewhere else in deeper comments somewhere in later posts but
like yeah people need to live and be happy
some people like will mcaskill does this he lives on I think like 37 000 pounds a
year and the rest he gets yeah and the rest he
gives to charity this is where the same Peter singers argument
with the drowning child is basically the same thing right
if you see a child drowning you should sacrifice your two thousand dollar suit
to wade into that river and save it uh which is true but
he uses that again to lead people to why are you not donating all your money you
don't need a two thousand dollar suit buy a hundred dollar suit and spend that
extra money saving dying people yeah and I mean
but that that ignores time I mean like if I have to dive in to a hundred lakes
and save a hundred kids I'm gonna drown I'm gonna be too tired
like the goal is not to just burn yourself out
and anyone who is encouraging you to give to the point of burning out or any
mentality that says that is shallow and selfish
it's short-sighted we should be like smarter than that
we should say give as much as you can so that it is sustainable and that you can
live your life the longest and healthiest way possible
