First, I want to maybe, can you clarify your question more,
because I want to make sure that I'm responding to what you're actually, what you're, yeah.
Okay.
So when people like, the most recent examples I have is Enya's example where he's like,
oh yeah, but if everybody's just like, do you remember the Scott Alexander post where he's like,
oh God created this universe where everybody sits on a lotus?
He said something like that.
Everybody's like perfectly happy, almost identical.
And to me, that's like perfect, but you seem to disagree with that.
And I don't understand why, what missing piece is missing?
This reminds me of like arguments I've had with Wes about wire heading where, so if you,
you know, okay, it's really hard to talk about this because I feel like there's not good
words for some of these concepts.
But so a version of me that was just eternally blissed out sounds kind of horrifying because
I actually like get meaning out of work or out of, well, okay.
I think my core like main value is curiosity.
So I get like the most enjoyment out of learning new things, exploring.
And if I was just like, you know, having liquid value, I'm like pumped into me at all times that
would stop that aspect of me.
And learning can be frustrating and annoying, but it's so rewarding because you overcome that.
Exactly.
The struggle to learn something or to achieve something or build something I think is really
inherent in what makes a good life.
And yeah, so my point of confusion here is it seems like you're explaining it in terms of
ultimate happens, right?
Would you agree with that?
I think that happiness is not, I don't know, it's not my like top priority.
And that is the main point of the main crux between me and people who agree with wireheading where
and that's also my argument against negative utilitarianism where it's like,
I think happiness is great, but I don't think it's like the best thing about existence.
I yeah, I basically agree.
And I know Matt, I don't know if Matt is still here has this thing about how all humans
are basically a bunch of competing nodules in the brain that are that want you to
do various things in our sort of in competition for your internal resources.
And what you do depends on how strongly one is weighted over another.
And I think that is a very good way of modeling humans.
And really the desire just to be happy is always like something that's pulling on me,
but it's not the only thing.
There are many other desires I have that are much more important than just that.
And if I was put in a state where that is the only part of me that was being constantly
fulfilled to the maximum value it could be, I don't think that would be me anymore.
That would be a tiny fraction of what was me.
That is that took over the rest of me like a cancer.
I think there's a lot of things that are important to me.
I have one of the classic examples is you ask a parent,
would you rather that your child is in pain, but you believe that it's happy?
Or would you rather that your child be happy, but you believe it's in pain?
And generally parents answer, I would rather that my child be happy,
and I have the wrong belief that they're in pain.
Because even though the parent would be made miserable thinking their child is in pain,
in actuality that child is happy.
And that's the important part.
Like I mean, one of my most best parts of my life was when I was creating methods of rationality,
and I couldn't do that if I was just sitting around being happy all the time.
Did we want to have Johnny on?
Hi.
Yeah.
Hey, Johnny.
Yeah, you had a fairly strong opinion vis-a-vis wireheading.
I'll jump in.
Yeah.
So.
Oh, wait, hold on.
Sorry.
Go ahead, Steve.
You're good.
I was going to raise hands now.
I was just going to say really quick, I basically concur with what they said,
but I'll take it one level further that I have this stupidly sentimental attachment to physical
reality to where like if I could move, if I could, I liked Phoenix mentioning what was that,
that my little pony.
Yeah, friendship is optimal.
Yeah, if I had the option to migrate to equestria, I would choose not to.
I have a sentimental attachment to physical reality.
A super doll.
Like things as they are, rather than things that, I mean, I would visit for sure, that sounds fun,
but I don't know, there's something exciting knowing that, or at least believing,
you know, if we're not in a matrix, you know, I could visit Hawaii and pick up a piece of lava
and be like, this is a piece of, what's the kind of rock?
That sounds right.
And like this was inside the earth, like not that long ago.
And, you know, there's something cool about that rather than just picking up a whatever,
if I was in a super immersive Elder Scrolls game and be like, look, this is an Elder Scroll,
like how cool is that?
Like that sounds fun, but not the same kind of fun.
All right, sorry, go ahead, Johnny.
By all means, quite all right.
So Wes, as we mentioned, he like, you know, he is the big wireheading fan around here.
And I must thank him for my opinion, because it is by arguing with him constantly that I have
formed such a strong opinion on this topic.
I have to expect that's why he does that.
Yeah, I do too.
And that's why I appreciate it.
So when we talk about how wireheading, we expect it would change it.
What is that horrid noise?
I don't know.
Okay, whatever.
It was a coil, I think.
It was possible.
So you have a, there is a meaningful sense in which you can say that anything that humans do
is for selfish, hedonic reasons.
You know, to some extent, that is an accurate model, because we expect that the things we do
will be good for us in some way, or it at least makes us happy to do them.
And to that extent, if you expect that if you get wireheaded, you're not going to want to do any
of the other stuff that you want to do.
You're just going to want to get wireheaded, because it is good enough that it supplants
all the other stuff you might want to do.
However, as an agent who has desires, not just about those, so you have desires about reality,
you might want your kid to be happy, for example.
You want that because you expect that will make you happy to a certain extent.
However, if you were wireheaded, you would not, because you would just be maximally satisfied,
regardless.
The reason that you, or I shouldn't say you, the reason that some people don't want to get wireheaded
is because they have explicit, meta-level desires about their desires.
They don't just desire things.
They desire to desire the things they desire.
And they do not like the idea of at least certain desires being changed.
There are some people who, I imagine many people, would enjoy thinking healthier foods
tasted better, for example.
It would be really great if broccoli tasted better than cookies.
It would be extremely convenient.
However, a lot of people would not like to change their beliefs such that, say, hurting
people in ways that were beneficial to them, felt as good as being kind to people.
Because while that might be a useful change to their values, they have a meta-level value
that they should not change that value.
And I think that is a good way to conceptualize why people don't want to get wireheaded.
Can I ask you a question there, Johnny?
I just have a quick question there.
Sure.
So my confusion here comes from, like, okay, so I imagine somebody thinking that they want
something.
What in reality is happening is they have a hypothesis of what mental states will come
from certain actions, right?
Is it possible that they have a hypothesis of how their brain would react to certain stuff
and they just are wrong?
Do you know what I mean?
Like, do they imagine something happening that doesn't actually happen?
Yeah.
I mean, I expect that a lot of the desires that people follow make them less happy.
In fact, it is almost definitionally true that if I were wireheaded, I would be more happy.
But I would still choose not to do it because the agent who is wireheaded and the agent who
is me right now have different sets of goals.
And while mine include my own happiness as one of those goals, they also include my values
staying the same and certain external things about the universe that I want to be able to
affect and would not be able to meaningfully affect if I were wireheaded.
Yeah, it's like saying murder Gandhi would be okay with being murder Gandhi, but actual
Gandhi would not.
Yeah, in theory, I totally get that.
That's the thing that confuses me here because it's like, okay, if that is true,
because I know the theory behind that, like an AI, for example, that has a utility function,
doesn't want to change, like I understand that.
But since I am okay with being wireheaded, it sort of seems to me like one of us possibly,
like we could be very different, but like one of us is probably wrong, right?
One of us is probably imagining a mental state and a reaction to it that is an actually the
reaction you would have, right?
It's not necessarily have to be true because this is a case where it's in cases where it's
a values thing, you don't have to agree, you know, if you genuinely have different values,
you can come to a different conclusion, even if you agree about the same things about reality,
you may not have to go higher than happiness.
I totally agree.
That's why I'm asking like, how do you know what you think you know, right?
But that's sort of the question I'm trying to ask you.
How do you know this is actually what you want?
It's okay.
Well, did you have something you wanted to jump in on?
Oh, we've kind of moved past that moment.
Yeah.
Oh, I'm sorry.
You can bring it back though.
I mean, we're still, did you have a comment about wireheading?
I have a more meta level observation on wireheading debate here.
It wasn't so much about wireheading as what I'm hearing is like this undercurrent of
is pleasure good and can we trust it?
And like, what do we value suffering or not?
And Alex and I were having a discussion last night, which was along those lines,
where I found myself having a very strong desire that when people are discussing these things,
that they make a distinction between suffering and discomfort.
They're very different states.
One is productive and the other is destructive.
I think with wireheading, that's probably a very strong factor that I'm not really hearing
considered.
It's just kind of being left out because all pleasure is not equal.
All suffering is not suffering.
I think people use these terms way too broadly.
So last night, when Enesh and I were talking about my previous discussion with Alex,
I said that for one thing is like the difference between anxiety, fear, and terror for me.
Where I'm like, anxiety, I can control to a degree.
It is something that builds to overwhelming, whereas when I feel fear, I have an immediate
uncontrollable reaction and terror would be that beyond uncontrollable.
I don't even have the ability to be embarrassed because I'm still screaming.
So when you're talking about wireheading, it sounds like the discussion isn't nuanced enough.
Yeah, the language barrier is so frustrating.
I don't know if this is an illustrative example, but have either of you guys ever been
blissed out on psychedelics or MDMA?
No, for probably the same reasons I don't support wireheading for myself.
If wireheading were a thing I could try for an afternoon, I might do it.
In fact, I definitely would if it was safe, just to see what it was like.
Again, assuming that people didn't come out of it saying my life will never be meaningful again,
that was the best ever, whatever, if it was a safe thing to come in and out of.
But I once took well over the recommended dose of MDMA and your thoughts feel awesome,
