than it is to have...
Okay, go ahead.
Oh, yeah, than it is to have a filter that's not strict enough and opens you to liability.
You don't have a bunch of false positives than one false negative.
Right.
If you're AI filtering for child pornography.
Like, I remember when Tumblr got acquired,
they shut down a bunch of stuff and they flagged a bunch of stuff as inappropriate content.
And a lot of them didn't even have...
It would be like a statue or something.
And it's like, yep, that elbow looks kind of like a nipple and the AI caught it as a nipple.
And so it's funny, but that's just the overzealous problem there, right?
Right.
So best case scenario, that's what it looks like.
Best case.
And there are a lot of other less good ways this can affect ordinary people in ordinary lives.
And let's go into the Earned Act itself for a bit,
because it's not just saying this law makes child pornography illegal,
because child pornography has always been illegal and that never stopped.
What it actually did was make it so that if anyone posted something on any service
that counts as a child sexual material or whatever they used, then...
I wish they used that.
It's actually just anything illegal, not at all.
Really?
I thought it had to be specifically with a child abuse.
I don't think so.
And maybe that's in the amendment.
The actual act is called the Eliminating Abusive and Rampant Neglect
of Interactive Technologies Act.
These names don't mean shit anymore.
Rampant, rampant neglect of interactive technologies.
They just needed it to be words.
They're really one of the acronyms.
They earn it.
As far as I know, it doesn't specifically call out, let's see, any...
No, I think it's almost a blanket revocation of Section 230 protections,
which includes just about everything you can be sued for.
It was originally called Earn It because there was going to be a government committee
which made a list of best practices, and as long as you followed that list of best practices,
you could still be protected by Section 230.
This is the original bill, and it had basically nothing in details as to what the committee
would say, and they could revise what they wanted every five years.
This was viewed as a way to get rid of encryption on the internet basically entirely,
because it was assumed that one of the things that would be in the requirements was that
any law enforcement can see anything on the website or that went through the website without
exception.
The naive thing is... I remember this was nice and fun to watch Sam Harris just kind of
spout this as somebody who doesn't know tech stuff, but then immediately update when he got
backlash was like, it makes sense that Apple should have... This is me quoting him.
It makes sense that Apple should have a way to get into your iPhone because they literally
catch a terrorist or you're murdered and they're pretty sure you got a video of the person murdering
you, but if your phone is locked and there's no way to get it, then that person... Murderer walks
free or whatever. Wouldn't it be nice if we could just... There's some secret way that you have to
get a warrant and you take it to Apple and they can get into it. The problem with that is once a
door exists, somebody can break in. If there's no door, then there's no key that someone can
forge to get in, so that someone can leak or lose 10 years from now.
Right, exactly.
I think it's just a matter of understanding technologically that you can't have a backdoor
without also having it be exploitable. Yes, there's literally no way to make
encryption that is completely secure in every way except to this one agency. If there is a hole in
it, that hole is exploitable by anybody. My main contribution to this was when I was googling
around this, I saw that it was introduced by Lindsey Graham, who everybody is a big fan of.
This was the guy who... I said that my main contribution to this would be ad homonyms
against Lindsey Graham. His SuperPack got a quarter million donation from Oracle a few days
before the country through a fit at TikTok. Everyone knows who this guy is, but I think
he was the guy who just this week said something about the good old days of... How did he put it?
Segregation. Yeah, the good old days of segregation. I mean,
again, it doesn't have anything to do with his argument. I just hate the guy.
But what I like about the slithering meanness of it is couching it in terms of fighting the
worst crimes imaginable makes it impossible to argue against, right? Right. Oh, you're pro-child
porn. Is that where you're fighting this? Yeah. This is basically the same thing that
Faust Assista was, where they're like, oh, you're for the trafficking of sex trafficking of women
and children. I'm like, no, that's not what this bill fights at all. That's not what it does. It
makes their situation even worse. And earn it is a very similar thing where it doesn't address
child pornography because, like I said, child pornography already illegal. What it does is
make content providers basically become censors for anything that goes onto their system or
through their system. The Human Rights Watch says in the first paragraph of their article about it,
the United States Judiciary Committee should reject a proposed law that would jeopardize
privacy and free expression rights without effectively protecting children from online
sexual exploitation. Everyone who's actually... Dude does work in this realm says, first of all,
this is not effective. This is not going to protect children. And all it is going to do is
just wreck the internet for people. They've also pointed out that this runs into Fourth Amendment
problems. The Fourth Amendment is the one against unreasonable search and seizure,
where you have to have a warrant in order to search people's private shit. There have been
rulings in the past that when a company was compelled to search things and turn it over to
the government, they were acting as a government agent. And so the stuff they found was not admissible
because they hadn't gotten a warrant for it first. This would have to go through the courts to
really make a final decision, but based on prior rulings, this would effectively turn
every single content company into a state agent that is required to monitor all people's contributions
to it. And so basically, then it would all be covered under the Fourth Amendment,
since the companies haven't gotten a warrant to search every single thing everyone is posting
beforehand and might make anything that was posted illegal not admissible as evidence,
which would make pursuing these cases even harder if the actual stuff that was posted that is
child porn is not admissible as evidence anymore. Is this just for public platforms like YouTube
or Facebook? Or is this for any sort of encrypted over-the-net communication?
Funny you should ask. Go ahead.
No, please.
Okay. So there has been an amendment made to the Earn It Act where they actually carved out
encryption where they said, okay, end-to-end encryption will not be covered by this. So
if you have end-to-end encryption, that's okay. This won't be covered anymore.
So I could still text you links to child pornography via signal?
Yes, but I mean that would be illegal.
Right. Yeah, but it would go into the radar. But what are we going to say, Chase?
Yes. However, their best practices list still includes recommendations such as scan it before
it goes into the end-to-end system.
Yeah. That's like saying we won't read your letter while it's on the truck,
but we can read it when it arrives at the post office.
We'll open it in the period between when it's in your mailbox and when the guy picks it up.
Right. Yeah. So they kind of carved that out, not sure exactly how that'll work,
but they also took away the thing where you can earn, quote-unquote, your Section 230 protection
by following their practices because that was the thing that kind of made it look like every
company would now be an agent of the state. So now just simply everyone has lost all Section
230 protections if this passes. And whether you follow their best practices guidelines or not
basically would be more of a how hard the court is going to hit you afterwards for anything that
was posted on your system. And it's just looking for any illegal stuff, right?
So if I wanted to hurt Facebook after this passes, I could go to your page and post a link to
how to make a bomb or something. And I would get in trouble, presumably. And so would Facebook?
Yes. It is called the harassers veto. You could do that in theory. Yeah.
But that would make Facebook liable for what you did.
So I guess I just don't see how any of these platforms can possibly survive.
That's kind of the point, I think. I think they want complete censorship control.
The human rights to avoid criminal prosecution companies would have a strong incentive to adopt
practices for restricting content that would sweep more broadly than the illegal content.
So it wouldn't put them out of business. It would just make them ban encryption
or have such a strong filter that it's going to make it very unusable.
A filter against talking about anything that might conceivably be illegal now or in the future,
which end up to the individual company's interpretation of that, which would probably
be quite wide, right? Post a picture of the recipe I use to grow weed in my basement.
Oh, that's illegal in 30-some-odd states. That's illegal content.
It also does this purdish thing of cracking down on any sexual content. And Eric quotes
sexual content like a woman breastfeeding is going to go. All trans stuff is going to go
because that's sex. It includes all sexual education. Funnily enough, it also includes
any sexual education that says abstinence is the only way to go because that's still sex ed.
So that would probably also be swept up, although I doubt they would enforce that particular one.
Yeah, one of the interesting parts about the amendment is that it
says state laws also can revoke Section 230 protection. And there are two states,
specifically, I believe Illinois and Florida was the other one, have laws that say if you don't
monitor what your users are posting, that is illegal. And previously, those didn't particularly
matter because the federal law with Section 230 in it preempted that and said, no, carriers can't
be held liable for this. But with that being specifically removed by this amendment, now any
company that had any users that lived in Illinois or the other state, which I think is Florida,
would be required to scan everything that anyone said, a post that are transmitted through their
service, or they could be held liable for, quote, reckless or negligent allowing people to do shit.
Rampant.
Yes, rampant. Just rampant communication.
So, Chase, what do you see the dystopian outcome of this looking like? This past is, say, in December,
once they confirm that new Supreme Court judge. And five years from now, what does the Internet
look like? Well, it's basically an amplification of, it starts with an amplification of a huge
pile of problems we already have. Companies don't want to host anything or show anything that might
not be, right now, that might not be profitable. They only want to show what's going to get the
clicks and keep users on. They're not going to show, hey, my car died. Can anyone help me out?
They're going to show cute puppies or whatever. And now we're just going to expand that into
anything that might be criminal, maybe, sort of, depending on what we feel like and depending on
how accurate our filters are. And as a wide blanket, that is going to interfere with reasonable
conversations about a whole lot of things that aren't explicitly legal, but are a lot easier
to put in the illegal bucket, right? And a lot of, there are a lot of important things that
ride that line. A lot of journalists, a lot of other communication that rides that, yeah,
it's not illegal, but it might be, and it's not profitable, so let's just not.
And specifically, there's a lot of things that, since the guidelines are so vague,
they're just like whatever this committee thinks isn't great, what it comes down to is
stuff that the government doesn't like. Specifically, speech the government might not
like will become censored because these guys don't want to risk being taken to the government and
either locked up in jails or fined millions of dollars. And so if the government has a bug
up its butt about protesters in the streets, maybe that stuff will just get wiped out. If the
government instead gets taken over by the communists and Pro First Amendment rights stuff is not
liked by the government, then that can all be taken off the internet. Like whatever the government
feels is disadvantageous to them will start being taken off the internet.
And whistleblowers.
Imagine how deaf me whistleblowers.
Imagine if it was literally illegal to share like all those videos of police brutality over
the last six months. Like Twitter feeds were full of them and all that.
Or if you're on the other side, what if it was illegal to talk about the satanic conspiracy
that the Democrats have to rape children? What is it that QAnon says? It's something along those
lines, right? There's lots of other things. What if it was illegal to talk about your religion?
Because the government is now officially a atheist government.
Yeah. It's one of those weird annoying things that I don't know. I don't even have the energy to
be upset about it. So I guess the other thing is that this would be for...
It's not going to start out with that.
It's going to start out with...
That's why I said five years, not next month, right?
So this sounds like the kind of thing where if my internet didn't think I was operating in the
United States, it would be fine. I just VPN to England.
England and France are also bad choices, but for different reasons.
Also any company that has a significant user base in the US is just going to
have this in a blanket thing because it's hard to have a policy that doesn't include...
It's the same reason like textbooks that cover biology often just skip over some things that
Texas doesn't like because Texas buys so many fucking textbooks. It's easier just to make
textbooks that is okay with Texas than to make a separate textbook for Texas students.
The flip side of that is think about how many of those...
Are you sure you accept cookies? That's a result of the EU's GPDR, which technically
doesn't affect you here, but I bet you've clicked on a few of those pop-ups.
Oh my god. Privacy policy cookies. Every website you go on now, it's just like,
okay, we've updated our privacy policy. We've updated it again. Hey, you enable cookies.
Do you want to know what cookie? I'm like, oh my god.
Yeah, that's GDPR. That's not even American law.
Exactly. And then there was a separate one. I forget what the shorthand for it was,
but in California, I'd had a similar thing. If you do business in California,
you might remember the title of it, but basically, if your company does business in
California, your internet company, the user has a right to actually have their data deleted.
I think after 30 or 60 or 90 days of inactivity or something,
