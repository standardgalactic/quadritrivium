Yeah, I wish I could schedule some doggy tags at work.
Do they allow dogs?
Like comfort dogs when they're cancer patients or anything?
Or are they not in there for very long?
No, they're there for a while.
You get to see them, right?
Yeah, you can't have animals around cancer patients generally.
It depends what regimen they're on.
Compromising new system?
There are therapy dogs at the hospital.
I work in an office.
I go to the hospital every so often.
So what do you think about the Jews Day argument?
You were sitting here listening while Stephen and me were moving around.
Honestly, I don't have a lot of opinions about it.
I don't know.
I wish I had something interesting to say about the end of the week.
It's a little bit of a Jews Day argument, but I got nothing.
So I wasn't just been listening.
Yeah, I don't have anything interesting either.
My main thing is like sort of a naive realism where I'm just like,
we're in the world, we'll figure out how later.
And I'm not, I don't burn a lot of fuel.
We're worrying about other universes or whether or not ours is going to end soon.
I worry about us wiping ourselves out.
A good deal.
But I have no, like, I'm not burning any concern on, I don't know,
some mathematical reason for why.
Yeah, exactly.
Nothing like that keeps me up at night.
I think that's the reason to be concerned about things that we ontologically
are incapable of controlling.
I don't think that stops most of us though.
Yeah, I'm very good at it.
One of my special skills in my CV.
I think, I don't know, I think it's kind of good that it's motivating.
I think a lot of the stuff rationalist, the key rationalist community does is
based at least partly on this worry about the possible coming human extinction
doing some good, right?
I mean, I'm not saying ex-risk in general is worth ignoring, but
like it has to be of the kind of thing that you can at least in principle
take action to avoid.
Like you can't avoid the ex-risk of what if you're a Boltzmann brain?
Is that what's pronounced?
Yeah, Boltzmann brain.
You can't do anything about that.
Yeah, the real weird thing about Boltzmann brain is, by the way,
if that's true, then no experiment you have ever done has actually been done.
So there's no reason to think that physics is actual physics, right?
If there are Boltzmann brains, then the probability that the universe
that we know has quantum physics and so on is the actual universe is very low.
So then the mathematics you have for Boltzmann brain is probably wrong.
Very unlikely that you are.
I don't know if that is Boltzmann brain or I think I've heard that before.
So in the quantum fluctuations, particles can come in and out of existence.
There is nothing saying that in theory it is impossible for particles to come
into existence spontaneously that form an entire brain that is in the middle
of thinking a thought or something.
I mean, it's stupid.
It's as stupid as saying like I can walk through a wall because there's nothing
saying that my particles couldn't spontaneously move through the walls particles.
But the argument being that in an infinite universe of infinite space
and infinite time, eventually somewhere that's going to happen
just because literally every possibility will be explored
across all of infinite space and time.
It's very absurd and I can't afford it.
Right, yeah.
Okay, I see Kyle.
Congrats on the episode, folks.
The worst thing is that in an expanding universe, okay,
our lives and galaxies will happen sort of once
and then after a while, galaxies will become too far away to continue happening for real
and you would only really have Boltzmann brain happening every, let's say,
10 to the 10,000 years, whatever.
But that will happen in infinite amount of time and you will only be alive once.
So it's a lot more likely that you are that single Boltzmann brain
that happened throughout time and space and infinite amount of time
than you are really that really living human being.
Which is, of course, why we don't like how the eternal inflation,
which is the theory where the universe sort of goes on forever.
Because then it's really weird.
Yeah.
That's a lot of weakness.
It's kind of funny to think about that.
It's really, I find it always very depressing to think about.
I don't.
Well, I mean.
But again, then people ask me, but why?
I'm like, ah, it's a whole thing.
Yeah.
Steve, just stole your account.
Steve, just stole your account.
I'm just on.
It's called Steve.
Steve.
So it says Steve on there.
It says Stephen on there.
How did I, this is the second time I've done this this month, isn't it?
Well, you get one more.
I'm really sorry.
I don't know what's going on with my brain.
It's a bad brain.
So I'm going to take it back and spank it.
Okay.
All right.
Do we have the next topic?
Sure.
Oh, God.
Thank you.
Watching, watching us to be like glad to meet you.
So.
Okay.
So we're going to have someone else come on now or what?
Um, well.
And so these are in email.
I should see if anybody else wants to come on.
If not, you guys can stay on.
But I want to make sure we have enough time to talk to everyone's as well.
Would anybody else like to come on and say hello or anything?
I will just say real quick.
While we decide who's coming on next that, um, at baby.
I better pronouncing it has emailed a couple of times asking us to do an episode on modern
money theory.
And I try researching that and it is some economic stuff that is well above my skillset.
So unless you guys know about it, then we'll have to have an economist on to help us talk
about to navigate that one.
Probably a good idea anyway.
Yeah.
So it sounds like a cool topic.
We did read some of the PDF age and almost all of it went over my head.
So, um, we are interested in, I'm interested in learning more, but I'm not capable of talking
about it at this point.
So.
Oh, per choise request.
Uh, April wants to talk about the sequences.
And I'm not sure wants to use the correct phrase here, but we're going to use that.
So it sounds more voluntary.
Okay.
Um, so the sequences, they are long and that makes it hard to recommend them to people.
Yeah.
Here does the thing that several times the size of the Bible.
Several being 1.75, I think.
Oh, I thought it was like somewhere between two and three.
But 1.75 is still a lot.
I listened to episode 98 like earlier today while I walk.
So.
Okay.
Yeah.
So I feel like not all of it is essential.
Like a lot of, I think we can edit it down.
Yeah.
I mean, I know they did in rationality.
Yeah.
I mean, they cut out some stuff in that, but it's still like the bulk of the content.
And I think like, I don't know, for a while, I've just sort of had the idea of trying to
write a version with like the vast majority of the content cut out and like distilled
to the base insights, I guess.
I'm not, I'm not sure exactly how effective that would be or whether like you need to
spend a lot of time really engaging the content to absorb any of it.
But I was about to say, I'm really curious how that, if that would work as effective
as it is to try with just maybe one sequel and seeing if I can summarize it without losing
enough information that it's not worthwhile.
Right.
Like I think, and there's no value in reading the whole thing, but you can still get most
of like most important stuff in a shorter work.
It might be worth doing anyway, even if you know, if somebody really doesn't have time
to read it.
Yes.
We managed to give them a few insights from it, then still a knowledge that exists where
knowledge wasn't before.
Yeah, like we rationally abridged exists, but it's like one sentence summaries of everything,
which I think is too short.
It's too abridged.
It's too abridged.
Yeah.
In up-gill or five terms.
It's weird because I've heard a successful story defined as something which is as short
as possible, but cannot be shortened more to give the same experience.
And I mean, that's just a way to explain fiction.
But in my opinion, the point of that is that you need a certain amount of experience to
give emotional valence, which is what you want out of a work of fiction.
And the sequences, like a lot of it, you can get a lot of the information without reading
all the sequences.
A lot of it has been written about before.
There's self-help books, there's textbooks on various topics, but the way it was written
gave it a sort of emotional valence to me that made it stand out where all those other things
just kind of faded into the background of my life.
So I would also like an abridged thing that can give the same sort of emotional thrust.
Yeah, without telling someone here, read this massive holy tomb that we have.
But I wouldn't have the skill to do that.
And I don't know how well it could be done and still retain that stuff.
Because you don't want to tell everybody what you really got to do is be alive in 2009
through 2012 and reading along on the internet.
Because that just doesn't work as actionable advice.
All right.
So in addition to just shortening it, I also think it can be explained in ways that reduce
inferential distance.
Okay.
I saw someone say Up Door 5, which is the book by the ex-KCD Randall Monroe, which like
explained a bunch of stuff using the most thousand, or the thousand most common words
