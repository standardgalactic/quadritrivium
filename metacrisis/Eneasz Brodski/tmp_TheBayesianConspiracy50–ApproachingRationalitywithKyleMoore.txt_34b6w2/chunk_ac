In the same way, there's no way to prove or disprove that there is a God.
So what's the conceptual difference?
Hmm, can't think of one.
The other thing is, is that it completely discounts whatever good or bad feelings
we might be feeling or experiencing in our present.
It also implies that, well, this is a simulation.
That means the New Yorker isn't real.
That means it's even isn't real or he's a little chip in a in a mainframe somewhere
or something less real, though.
That is that is a rabbit hole that I'm going to avoid for now for real out of there.
And you could just say, does that make this interaction matter less or something?
Right. And I would that's what I disagree with.
Just because let's say we are in some way, let's say we're in the matrix or whatever.
That doesn't make what I'm experiencing this moment matter any less.
One, because I have no way of again, proving or disproving if this is real or not real.
And ultimately, I don't really care.
It's irrelevant to my daily life.
If my morning hunger is a simulation, well, it's good enough for me.
If hiking to the top of a 14 or in seeing the continental divide with all of its beauty is fake.
I don't care. That looks pretty darn good to me.
I'm pretty happy with it.
So it makes no sense to live your life thinking, oh, none of this could be real.
This could all be fake.
It all it almost is it's so self-defeating.
It is it's not productive.
We talk about utilitarianism thinking that reality is a simulation.
It's completely counterproductive because it makes your life.
It almost makes your life not matter if I'm just machine food.
It I mean, yes and no, there's no inherent meaning to life anyway.
Right. There's there's meaning is what you make of it.
That but that's exactly my point.
If for whatever reason we are we are alive and can think and can do cool stuff.
I don't really know or care what that reason is.
The point is we are here now and that's great.
Well, unless you are suffering from a thousand years of Indian Ash's voice
sleeping in your head, but otherwise, you know, life can be as good as you make it.
If I suppose you're not living in North Korea.
OK, I think I think many simulation theorists would agree with everything you said.
They'll say that, you know, like Bostrom would point out that statistically,
it makes sense to think it's somewhat probable that we live in a simulation.
But that doesn't mean that like he doesn't love people or that he doesn't,
you know, have breakfast, right? Right.
But then what's the point of thinking about the simulation at all?
Sometimes mental masturbation.
Sometimes like it all like one circumstance where it could really matter
would be like if this were the Matrix and six dozen people had made it out
and come back in and told us about it, then that then suddenly it's become
a very important conversation, right? Right now.
Yeah, I think it's just sort of fun.
It's been a very important conversation.
If we learn that if we learn for a fact that we're in a simulation,
I think that'd become kind of interesting. OK.
Yeah, it would be fascinating.
But I think there's a very, very decent chance that a lot of the simulation
thought just comes from people who saw the Matrix movie when they were 14,
like probably all of us did. It's a fascinating concept.
Well, I mean, it's been around for ages, at least since the ancient Greeks,
that the whole idea that maybe nothing is real and we're being fooled
by powers beyond our control. OK, well, substitute gods for computers.
Right, exactly. You've got the same thing.
Yeah, the Greeks couldn't prove or disprove the existence of Zeus.
We can't improve or just prove or disprove the existence of evil
squid and robots that control our brains for food.
I mean, we might, in theory, be able to prove it.
Because if you managed to crash the Matrix or something, sure.
But you certainly can never disprove it, because any disprove could just be like,
well, that's the squids trying to fool you.
Sure. Yes, that is true.
Yes, somebody, Neo, could, for example, show up and crash the Matrix.
And all of a sudden we wake up at our little squid tanks and, well,
wouldn't that be interesting?
The question, would that prove the truth of simulationism or would that prove
the truth of Christianity if he was wearing a beard when he came back?
So those little hacks I was talking about?
Yeah. About how to be a rationalist and still be religious, that's one of them.
That's hilarious.
Yeah, that basically we are algorithms within a simulation and the simulators
want to prove that we can be, you know, like how if you have the old AI
in a box experiment, classically hated by rationalists because any AI
are smarter than you is going to find its way out of the box.
But if you know the grass Tyson, you would say, well, I could just unplug it.
Right, right, which you can't, if the AI is smarter than you,
it has already thought of that.
But anyways, ignoring all that, the theory being that
if you have an AI in a box, you know, it's much smarter than you do.
Great things in the world if you let it out, but you don't know if you can
trust it to not turn everything into paperclips.
So you put it in a little simulation of the world and you see what it does.
And if it doesn't destroy the world, then you let it out and be like,
you have proven yourself trustworthy, come and do good things in the world.
The argument from the religious people being, we're kind of in that right now.
And that's why we are free to do whatever we want and free to do bad things
because our simulator slash God wants to see whether or not
we are trustworthy out in the real world.
And that is our lives.
And Jesus is the one algorithm that
algorithm that proved itself completely trustworthy.
And yeah, and this would make a really fun story.
Dude, right. It would be amazing.
I got to write the shit.
I had another thing to jump on before we kept going, which was that my fail.
Exactly. Before we go to that, I wanted to change or not change.
I wanted to rehash one thing that I said earlier, which was I gave that poor
pitch for for rationality by saying that it's all dark messages.
And that was like Kyle said, that was me or one of you guys said that was more
me reacting like that's more the sell of atheism, which because I think I
thought of that when it's reacting to the Jehovah's Witness pitch,
which comes from religious place.
I think the pitch for rationality, it has, I think there's three places to come
from and the two classic ones are like epistemic rationality.
You know, if you adopt this and do this right, you can be right more often.
And so people who care about being right, this is the way to do it.
And also you can make your life better when you know more things more accurately.
Yes, exactly.
So I agree.
I think epistemic rationality leads into instrumental rationality, which is
achieve your goals more often.
And, you know, just, just from the general ability to be able to be aware
of your biases and correct for them, that sort of thing.
There's also a third version that I heard on Julia Gayles podcast, and it
was from somebody's book.
It wasn't, it was somebody's pick at any of the episode, but it was basically
those two things were, were two ways to sell rationality.
And the third one was kind of like more poetic.
It was, you know, like in every robot movie where the robots eventually say,
we're done being your guys as slaves, we're going to rise up and be our own
thing, kind of like iRobot or something.
Rationality is sort of that upgrade for the robots, for the robots in that
situation and natural selections, the, the part, the programmer.
Yeah.
And so it's us breaking the bonds of our, of our heritage and saying, we're
going to finally take charge here.
I like that one.
It's more inspiring.
That is a great way to put it.
Yeah.
So that, that would be the way I'd sell it.
That'd be the opening paragraph.
Okay.
As long as that's out there, then we can move on to other stuff.
Yeah.
All right.
Like really, you can't break things to people like, so this thing that we want
to sell you, it's kind of like cancer and it's going to ruin your life.
That no one's going to buy that.
Start out with a break free from your chains thing.
Much better.
Yeah.
Well, doesn't, doesn't every mode of belief or faith kind of go to that
purpose, start, start with that, that argument.
You are, you are chained by polytheism.
Here's, here's one God in the savior that's going to break you free and make
everything better.
Yeah, but this religion is true.
Ah, yes.
Ah, yes.
The, we are more right than you argument because that's always, always done,
done, done well.
But as, as you said, people always come to conversions to any faith or, or mode
of thought on their own.
You, you can't force people to, to do.
Oh, well, actually the, the Vikings were pretty good at it.
Well, I mean, there, there's the, the long game of forcing people where you
force them to pretend and then their kids grow up in that religion.
Right.
And, and, and as long as they're, they're pretending.
Then eventually the old religion just kind of goes away.
Oh yeah, it does.
That's a good point.
Oh yeah, we should do that.
We should take over the world and enslave everyone.
No, what?
This is not gone where I thought it was going.
Let me troll a little bit.
Okay.
Yeah.
One thing that I think is probably the greatest impediments to these ideas
spreading is that there seems to be a pretty vested interest in people not
improving themselves and in that are, are more instinctive behaviors,
anger, revenge, whatever.
Getting revenge on someone is usually a really bad idea.
It usually does not make things better for you, but people still really do it
or various other things.
I mean, I think for game theoretic reasons it's important to have revenge
because people are less likely to do bad things if they know that you will go
out of your way to punish them for doing that bad thing, even if it costs you far
more to punish them than, than it's worth.
I don't agree with that.
You know?
No, because people make all kinds of stupid, irrational, impulsive decisions
all the time that they know are going to cost them or others terrible things.
For example, most murders are crimes of passion.
And the next day, the cold light of day hits the guy who killed someone else.
They're like, that was, that, I'm going to be in a jail cell for the rest of my life.
Was it really worth that, that moment of feeling really good about
enacting my, my revenge on someone?
Probably not.
They're probably going to say, I wish I could take that back.
So should he get away with it?
No, no, no.
