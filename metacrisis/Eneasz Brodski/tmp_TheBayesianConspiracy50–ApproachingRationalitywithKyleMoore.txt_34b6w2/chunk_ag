And I'm like, that you're advocating for killing everyone.
Well, then you're getting to Logan's Run territory, I guess,
which is also an interesting way of having a society.
I'm not familiar with Logan's Run.
Logan's Run is a 70s science fiction movie that takes place in a utopia that is made possible
by virtue of all humans are killed ritually on their 30th, basically the 30th birthday.
And the movie was the 30th birthday, yeah.
Yeah. And basically up until your 30th birthday, you have a utopian perfect existence.
And the way that this being killed at age 30 is kind of made a palatable thing,
as people are told that if they might, if they're so perfect and pure,
they might survive the ritual and then they become, then they're gods basically.
But of course, nobody does because they get inserted by laser beams.
Yeah, yeah. But I mean, they don't find out that they're killed.
It's like an ascension, I believe. I remember the movie.
So nobody knows that they're actually going to die.
Right. But it's sort of like you're going to get, I think they chant rebirth,
rebirth or something when they're in the ritual.
But basically the way that the system works is that it, everyone is killed.
Yeah. That's a story, that's a lie.
And that's basically what we have right now, except instead of 30, it's around 80.
And it's not an exact date, it's 80, give or take a decade.
Well, the difference is we don't choose that.
Well, but we could in theory, and there's people who don't want us to have the ability to choose that.
Yeah, I think the difference is that, yeah, we're not choosing that right now, but the
future that we, people advocate against the future where it is a choice.
Yeah. And that's what we call a deathest.
Where we shouldn't have the choice to live forever.
That the only way to correctly continue to be human and to keep our problems small,
and is to make sure people only have that hard limit, like the Logan's Run limit.
30 years seems, and I haven't seen the movie, but that seems super low.
Do they still have to take like 20 years to become real people?
Oh yeah. Dude, in the book, I don't remember if it was a book or short story.
I didn't actually read it myself, but in the book, it was like 21.
Oh, it was 21.
Yeah. Yeah.
You basically got through adolescence and then like, you're done.
Which also made this really immature because you were teenagers were the oldest people, right?
Yeah. See, that sucks. I don't feel like I started like self-actualizing until I was post 21.
Oh, I know. I didn't until, I don't think I did until I was early 30, maybe 29.
I have the same here, 28, 29, I think is when I actually became an adult.
Yeah. Oh, cool. I've got something to look forward to.
I just turned 28 a few months ago.
Well, I mean, I had to go through three years of alcoholism first, so you got to get on that train.
All right. I'll assume by the store on the way home.
And, you know, all of us have been through divorces and, well, that sort of wakes you up a little bit.
Yeah. I'd like to skip that part. Is there a shortcut?
Nope. No.
Got to get married and divorced. Sorry.
No. Got to have all the pain and then you get smart stuff.
This is why my parents are still children.
Ooh, sick burn. The thing you said about deathists and how they say that by virtue of
trying to, why am I tired and have words? No words.
You just said a thing about deathists say that if we try to be immortal and have utopia,
we will not be human. And I think that's correct.
I think that's absolutely, we would be more than human at that point.
Transhuman.
We would be transhuman at this point. You could also say that all religions are effectively
transhumanist because they say that, well, you're going to die and go to heaven or hell.
And then that will be either utopia or misery. So if you go to heaven.
But I think transhumanism has a specific focus on the physical reality aspect of things.
Oh, sure. But if we achieve this, you know, immortality, we achieve utopia,
we've effectively stopped being humans. If we would have effectively perfected ourselves.
I don't think we've stopped being humans. We've like humans plus, you know, like is a dog is
like still a wolf sort of, but not entirely. It would be the same kind of thing where humans,
we still have the human roots, we wouldn't stop, we wouldn't turn into some other alien species,
right? I could, I could recognize my transhuman descendants as coming from me and sharing some
human values. Are we less human that because we were insulating clothing and we have air
conditioning and we can get far distances in short times with cars and we can augment our
bodies with the glasses? I don't think we're any less human for having those things. We miss out
on some of the primal experiences that our ancestors had, like being cold and being unable
to see and having to walk everywhere. But that sounds like a small price to pay, right?
Are we less human because we don't fear and hate the outside tribe that comes by and,
you know, steals our game every now and then. I always still do that all the time, just in
a modern way. Damn. I'd like to think that humanity could shed that aspect of ourselves too,
right? That'd be really nice. Tribalism sucks. It's not necessary anymore. But I think that,
yeah, while that might be the kind of thing that's been characteristic of our species for
millions of years, that's seemed like the kind of thing that we could live without
and be better off for it. So I think, I mean, that's sort of how it like, are we less human
because we now live to 80 rather than 50? I mean, I don't think so, right? So if we lived to be,
I mean, granted, it's a bigger jump to say 80 million years old as opposed to 80,
but I don't see where the argument falls apart. At what year do you pass this barrier? Like,
okay, yeah, hold on, that's too far. 217. My 217. Arbitrary? Yeah. Well,
I mean, we're so far away from transcending that biology that's kind of, we don't even,
we're so far away from it. I don't know. I feel like I'm surprised every once in a while about
how close we seem to be. Now, whether it's going to be this week or this century, I think that
that's, you know, kind of like the upper and lower bounds. But I think, I think it's possible that
some people born today might not ever have to die of old age. I think so. I think that, and that,
that wasn't true 100 years ago, right? Well, yeah. So obviously now we know that it wasn't
true 100 years ago, but it might have been stupidly optimistic to say, you know, I was born
like my, my grandma was born in a house without electricity. And I don't think they got electricity
in their house till she was in their teens. I don't think that her parents were saying my
kids are going to live forever, right? But I don't think that it's unreasonable to think that I,
rather I would say it is unreasonable to think that in 500 years, we won't have some of these
breakthroughs. And I'm, I think 500 years is like my super high upper bound, I think is probably way
closer. Aubrey de Grey talks about longevity, escape velocity, where if you can hit life extension,
life extension technology and live to be, have another 30 healthy quality years, by the time
those 30 years are up, we'll probably have more life extension technology, and then allow the
rinse repeat until you kind of hit this fume takeoff and you can just live as long as you want.
But he talks about the, the first able to hit that extension might be the first immortals,
right? They won't just live to be 150 and be healthy. They can, because by the time they're
aging again at 140, they found new better ways to make you revive your aging cells.
Exactly. And I mean, maybe there are upper limits on how much a human brain can handle
before it starts falling apart and going crazy, no matter what we do to it. And we'll find that out
if that is the case. And then we have to modify our biology and then we're a new thing, whether
that's a good or bad thing is up to you. Yeah. What other topics do we have? We had utilitarianism
overpopulation and net neutrality still. Overpopulation, I think was touched on. I think we
kind of, yeah. Utilitarianism I touched, but not really discussed. Was there more you wanted to
go into about my introducing myself to rationalism or anything like that? Or do you feel like that
got? I had a couple. I was curious, was there anything that you heard so far since you started
editing that was like, these guys are fucking nuts. I'm on board with half this stuff. Man,
that that thing I'm never going to be sold on. In terms of overall concepts, I'm sure one will
come to mind. I think overall, and there's a lot of pie in the sky that goes on says the guy who
just had a two hour conversation about pie in the sky immortality. So that's me. I guess I would
really be interested in seeing more ways in which this way of thinking could be a little more
practically based. I mean, it is obviously practical just by thinking about, hey, be less
wrong. I would, I think I would like to explore, you know, we talked about, oh, hey, a practical
thing is getting people to think rationally. That's pretty darn practical. I guess I would
like to say there are lots of problems that we can touch today versus immortality, which is going
to be a tomorrow thing. So what can we touch today more? And I know you guys have done that with
cryptocurrencies, you've done that with drugs, some other things. So I think that's more of my
overall, we keep trying to do spirituality, but it always gets derailed, in my opinion. Like,
one time I got derailed into rituals, last time I got derailed into drugs. I was like,
I'd like to do actual spirituality at some point. Well, not not to say that spirituality with drugs
isn't actual spirituality. But you know, careful Jenkins, we all put all up in your business.
Right, exactly. But I meant just the spiritual part without any any drugs involved. Yeah,
I wonder, but there that is, I mean, and that that is a very good point, especially when you
asked us off the top, like, how do you get people into rationality? And how do you, how do you
present this to someone and spread it in the world? Because the world really does need more
rationality in it. Yeah. And we could, we could stand to raise the sanity waterline. And talking
about, you know, future utopias and simulation arguments can be fun and all. But you're right,
I think we should hit that a little more often. That would personally appeal to me more. But
again, that's just my maybe my personal thingy, Bob. No, I think that's a good point. I like that.
I mean, it's one thing to have, you know, fun conversations that, you know, are engaging,
but ultimately kind of like, well, that was fun. And another thing to have a conversation where
you could walk away with like an actionable like, okay, cool, I should start doing this.
And I think you shouldn't divorce them entirely because like the whole future utopia thing is one
of the things that can get people excited. Gives him a goal. Yeah, I would also say that it's
also a really good brain workout. And that that is inherently beneficial, just by virtue of thinking,
oh, yeah, these utopian problems and, you know, immortality problems. That makes me think and
thinking about that kind of stuff is, I think, and just it's good. It makes you thinking about that
stuff increases your overall, I don't know, brain fitness. It's you gain XP and level up. That's
what it does. Nice. Yeah, it's been my brain fitness is quite down at the moment. Right.
So that that that is that is certainly advantageous. I guess I would like to,
I think it'd be cool to explore people who are, it would be great to have a non rash list on the
show. Someone who it was a very emotive, who someone who's a very emotive person, someone who
really lived in their gut and try to sell them on this thing, not even so much trying to sell it,
but just trying to understand. So it's sort of when you, you know, if you ever have a conversation
with someone who passionately feels and believes something and it kind of seems to come from a
totally different part of the human experience and it just goes way past you because you just,
you cannot, cannot get to where they are. And I feel like if you were able to interact with someone
like that and try to get them into a rationalist mindset just for a moment, they might be able
to make themselves clear to you and thus increase mutual understanding and that's always a good
thing. Oh yeah. This episode is sort of a dry run for me for that kind of experiment. But I'm already
in the headspace that you guys are in. Yeah, but A, I didn't really know that. And B, I think it's
easier to start with a slightly easier run because like I said, you didn't seek this stuff out. It
was kind of like, this is what I'm going to have to look at at the show. But that's interesting. I
don't know how we had put out a listing for that. Oh, come on. We both know people who are on the
other side of the how brains work spectrum. The second part is going to say people who'd be
interested in doing a show about that. I think you could be charming. You can finagle someone
into coming over to my place. Maybe you're charming.
I think that would be quite easy if you have a willing happy friend person and you have a list
of things that you find interesting to talk about that they also you could probably you could just
make a list of topics and let's we can talk about spirituality. If you've got a religious friend,
boom, there you go. Really? You want to talk about, you know, maybe cultural or stuff, which I know
you guys probably avoid because that gets very gut gut feelingy. That would be an easy way to bring
that out. It's not a good introductory topic, I think, but it is a fun one. And it's also kind
of important. I mean, that's one of the places you most need rationality, right? Is when culture
more stuff. Yeah, absolutely. That is the grabbing you by the gut and making your emotions do the
work instead of the thinking. Sure. Isn't that like explicitly super hard to do for entry level
critical thinking? Yes. You don't grab somebody and say, Hey, so the things that you care about
are really stupid. Let's let's have you defend them, right? Yeah, that's true. Well, that's why
you are nicer about it. That's really interesting. Tell me more about your feelings instead of you
sucking your wrong. Like that street epistemology person. Yeah. That's the hood about what? Street
epistemology was an earlier episode we had before we brought you on board where someone said that
basically outlined ways to talk to people that is non confrontational and do that sort of thing,
like try to draw them out and ask them questions and, you know, tell me more about your thing.
It was essentially Socratic method, which is like, ask them to clarify and be like,
that's really interesting. Do you mean this? And then they'll be like, Oh, no, wait, I guess I
mean this and kind of just, you know, I guess Socrates them into hating you. So I'm kidding.
Ask leading questions that both draw out their views, but make them think about their own views
in a slightly critical way. I don't know. And I was being funny, but maybe they will hate you,
because they made Socrates kill himself, right? Fuck you, get out of here. Didn't work great for
him. But you stop right before they try and poison you. So. Oh, the idea being that if you
did this with someone who was maybe more of an emotive thinker, it would make them not like
the things that they actually thought. And that would make them unhappy. And then they would not
like you. Or at least think more about the things that they have accepted very uncritically.
There was Oh, dear, I can't remember where I saw. Oh, yes. There I listened to something once about
what it meant to actually know something and how hard that really is. And part of
the theme of this was look into a claim of whatever it is, whether it be something as
simple as two plus two, or is voter fraud real, and really look into that. And somebody actually
started doing a few of these things and really looking into common accepted arguments of whatever
this. And of course, it's always much more complicated than anyone ever thinks. And the
reason why I thought, well, it was great that somebody did that, but it's so hard to really
know something, just because there's so much to know. And I have to trust my friend, and Yash,
who knows lots about accounting, because lots in quotes, he he has taken the time to do this,
and I just have to trust him because I don't possibly have the time to know everything myself.
Yeah, like I haven't personally verified the age of the universe, right?
But I'm not going to say it's right around 13.4 billion years old or whatever it is.
Right, because we all rationally trust other people who we think are smart to
know things for us. Yeah, I trust the enterprise of science to where like, if the scientific
