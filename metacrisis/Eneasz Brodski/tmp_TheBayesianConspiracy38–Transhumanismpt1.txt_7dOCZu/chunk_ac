I completely agree.
And I'm looking forward to a time when I can do everything I want to do.
I'm like, yes, in three centuries from now, I'll get around to the cello.
That's, that's, I mean, part of my way of looking at it too.
I think, and Shelley did this earlier that like you'll get bored with eternity.
And I did love and method rationality was the most concise version of challenging
that that I'd ever heard, which was, I don't think it was Harry arguing with
Dumbledore and he would, he was explaining to Coral later.
He's like, I don't think Dumbledore had in his mind a mental model of himself,
you know, continuing in the afterlife when he was telling me how bored I'd get
being alive forever.
Right.
And that seems to be, you know, the people who most, I mean, a lot of people are
religious, a lot of people make the argument that you'll get bored.
And it's like, so you're not going to get bored sitting on a, you know,
cloud learning the heart for a trillion years or whatever it is you do.
I guess the idea though is like regular life will get boring, but transcendent
afterlife is a fundamentally different thing.
And then we make, then we make earth transcendent and awesome.
Yeah.
But I also maintain that there's a lot more to get, like a lot more to do, even
in regular boring earth right now, then you can fill in the lifetime.
So once that gets boring, then we'll have plenty of other cool stuff to do.
The Chinese afterlife is really interesting.
Oh, okay.
Actually there's a little wide bunch of diversity of cultures in China.
So I don't want to say the Chinese afterlife, but, uh, at least one of the,
one of the major ones that I've read about, it's basically just real life,
except with ghosts, like they have bureaucracies and, and, uh, people that
they have to file paperwork up to and they have cash problems.
And it is, it is like, you just get life again, except now you have a ghost
body instead and it goes on for a lot longer.
And I, I, it, it almost seems like, oh my God, I thought I was done with this shit.
And now here I go again.
When will this unending hell ever ever?
You just move next door, basically.
Shift one dimension over.
What are you looking forward to in the immortality?
A lot, like the whole, the whole fun theory sequence is perhaps my favorite of
the whole of all the sequences.
Should we, should we get into this now?
Or should we talk a little bit more about the different elements of transhumanism?
Uh, that's a good question.
Did we want to do that?
Cause I remember the second one was IQ, which we didn't even get to in the,
in the simple, simplified humanism.
Oh yeah.
We don't have to go over everything in order.
I'm totally fine to do whatever we want, but I am curious, I kind of
want you to steer this.
So if you want to do more, more exploration, like ground level stuff,
before we get deep into one thing, if you want to get deep on one thing,
then drag ourselves back out and go down to other avenues.
Okay.
I guess I would want to at least briefly mention some of the different paths we
can go down before going down, what any one of them, which is, um, IQ,
intelligence, um, enhancement is really important.
The, well, because first of all, as far as I can tell, intelligence
really impacts your enjoyment of life.
I don't know if this is a controversial opinion, but I, I, I go back to the old
better to be a sad soccer tease than a happy pig quote, just because there
seems to be so much more to enjoy and more ability to enjoy it in different
ways when you have more mental capacity.
And the, the example that Elias are used in the simplified humanism one was
if someone has an IQ of 130 and a lead heavy environment is slowly degrading
that down to 120, most people would say it is a good idea to prevent that
from happening to let him stay at 130.
Uh, but if his sister has an IQ of 120, a lot of people wouldn't say,
let's embark on a program to gradually increase her IQ to 130.
They would be like, now let's just leave her where it is, where she is.
And, and transhumanism doesn't make that claim.
Transhuman says if a higher IQ is better than it would be just as good to
raise her to 130 as it would be to prevent him from dropping down to 120.
And, and I think that is true too.
Why not just keep.
I think there are two elements to consider that are not quite as straightforward
as just like smart as good.
Okay.
Um, one is that it should be their choice.
Like if he wants to let the, his IQ degrade, yeah, there's not going to force
any treatment on him.
I, I don't think we ever mentioned this explicitly, but I do think bodily autonomy
is a core component of transhumanism as well.
Yeah, I agree.
Yeah.
Which is a thing like no one can tell you that you have to do things or that you
can't do things to yourself.
Like if you want to kill yourself, you can.
So we have morphological freedom is one of the key components of my transhumanism.
But the second thing also is that there is an argument for not changing in so
far as it's part, you may be changing things that are part of your identity.
And there are, I can imagine enhancements, the things that could be
considered enhancements that I wouldn't want to, to go through myself in the
interest of still being me and not being like me being dead and replaced by
someone who has all my memories.
Yeah.
Like I'm sure a 200 IQ me would be a drastically different person than the
me I am now at only 198.
From my perspective on changing a lot of these things is that if you change gradually,
then you can still maintain some coherence of identity so that you can get there
eventually in a lot of ways.
Still, there are some enhancements where I wouldn't be able to get there even
gradually, I don't think, but as far as IQ, I feel like you could continue being
yourself as long as you had the ability to do maintenance to continue being coherent.
Can I, I want to touch on those in reverse order.
I like the point of gradual increase because, I mean, in some important way,
I continued from childhood to adulthood in a way that wasn't radically disrupting
overnight, right?
So if I winked out for a second and all of a sudden I have the mind of an adult,
that would have been very disrupting and I might not have appreciated the change,
but going slowly, I liked it, I think more than I would have otherwise.
Although, to be fair, I didn't try the otherwise.
But the other thing was, as far as autonomy, I agree that if someone's in capacity to make
a decision that it's good, but then I'm wondering if that holds true for the reverse case.
So in the example of the sister with the 120 going to 130,
say it was 60 and she could go to 130.
And now at 60, she might not have the capacity to make a choice.
But so do you give her the shot that fixes her brain?
I am tickled pink that you are holding that copy of analog right now because that is what
my story in there is about.
Oh, perfect.
It's about, is it moral to force a change on someone when they are not competent to make
that decision for themselves?
Well, if your answer is no, then I disagree with you.
I mean, at least I softly disagree with you.
I am currently persuaded that lacking the capacity to make a choice,
it's okay to let people who can make good choices make that choice for you.
Just like my go-to example of this is if you offer a three-year-old the chance to get a vaccine,
they're going to say, no, it hurts.
And that you can't explain to them, no, no, seriously,
you don't want to die of mumps, right?
But so you deferred the person with the capacity to make the choice for them
and override that kid's wishes.
Yeah.
I don't see a problem with that.
But I view that three-year-old as actually not having full autonomy
by virtue of the fact that they don't understand.
But.
So you're not actually violating their autonomy.
It is their childlike mind that is violating their autonomy.
Yeah.
But what if the trans are transhuman descendants with IQs and the unmeasurable thousands
look at us and say, we are like children.
We do not have enough autonomy to make that decision.
And so we will make it for you.
It's possible.
And I'm not going to rule it out.
But I feel like the ability to make decisions to the degree where you can have some kind of
sensible autonomy happens pretty low in the IQ scale.
Yeah.
No.
I mean, in the current world, it's pretty...
Okay.
It can be a little bit iffy around the edges when we're talking about people with developmental
disabilities.
But we have just the right now, the straight outline at 18 years of old.
Unless you get emancipated early.
It's where you can actually make your own decisions.
But I think that's because everyone becomes an adult eventually
and everyone wants to have that bodily autonomy.
And in a future world where there is an entire race of humans like us who will never
reach transhuman godhood, the superior race would just have to make that decision
for us by themselves or respect our autonomy if we want not to, right?
I mean, where there is no sharp line to draw anymore.
We will never reach that without their intervention.
I think...
I see where you're going and I like that.
I really like that point because the analogy I think is pretty solid.
But I would like to think that I have more capacity to understand arguments and be persuaded
than a toddler.
Yes, but probably you to a toddler is less of a jump than you to the transhuman gods.
Yeah, but hopefully they could, you know...
So should they respect your autonomy or should they make the right choice and give you the vaccine?
I was going to go with the third option and say that they could probably talk me into it
for reasons that I would agree with.
Now granted, if they have super persuasion powers, that's almost like taking away my autonomy.
But at least, I mean, I don't know if it's...
I think I'm kind of on board with Steven, which is that ability to reason
doesn't require you to be even as smart as Enias.
Like you could be dumber and still have enough...
And still have ability to reason such that the most intelligent creature could still come and
reason with you and respect your autonomy.
This relates to my major beef that whenever...
If you make the wrong choice.
Well, that may...
Reverb to a previous save?
No.
Then that's not respecting your autonomy if they just keep trying until you make the right choice.
No, I personally really strongly believe in the right to harm yourself.
And I agree and that is why I did finally come down on the side of
you should let people make the wrong decision.
Even if it's something to the effect of I refuse the mum's vaccine.
I think we all sort of agree because like Shelley points it out, kids aren't really making the
decision. They're just... They hear it's going to hurt and they say no.
And that's not not a decision or that's not an expression of preference,
but they're not really thinking about it because they can't.
And so their lack of rational capacity does, I think, mean that they don't really have autonomy.
But the way those people would... Those human people would look at us would be
as if we right now went downstairs and saw a group of three toddlers around microphones
discussing whether or not they should be forced to get vaccines.
