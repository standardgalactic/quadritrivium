The actual argument though, the actual definition of a P-Zombie
is that it is molecularly or on an atomic level, identical to me.
But the counter argument is that is literally impossible
unless you believe in souls.
That anything molecularly identical to you will have self-awareness.
That is in fact impossible.
But creating an NPC doesn't have to be on the atomic level identical to me.
And maybe that is possible, even though the P-Zombies are impossible.
A non-sentient, believable zombie, perhaps, maybe.
I don't know.
If it was really non-sentient that at some level it would fail
and you would be able to tell that this isn't really an interesting person.
That anything interesting enough to be indistinguishable to a human
would have a level of consciousness and qualia that approximates a human.
And they would be a person.
I think even if that was true, we could just say,
all right, cool, so the NPCs are conscious.
But then it would still be a drag to have the quote fake people,
the generated ones, you're not fellow quote humans or post humans or whatever,
to have one of these generated people be more engaging than your loved ones, right?
Not when you can modify yourself to gradually over time to be also very engaging.
I already have a lot of history with my loved ones.
Even if you're more boring than this person, I still love you a lot.
Let's get more interesting together.
I haven't had this conversation before, so I'm just thinking of this on the fly.
So this is what it's like.
Well, I mean, me too.
I haven't rehearsed my position.
But it's fun, right?
Yeah, but I guess if it seems like I'm scrambling because that's sort of what I'm doing.
No, I appreciate all the things you're coming up with.
Well, I don't know if it was really that more compelling to hang out with these NPCs
than it was with your friends, then I feel like something might be lost there in the sense that like...
But they're still conscious persons.
It's not that much different from genetically engineering a baby that's going to be super
charismatic.
It seems like you have a problem with someone who wasn't born into a meat suit.
Like if they were born in silicon fully formed, then they're not real people.
Not necessarily.
I guess I'm thinking of ones that were developed specifically by the AI to be super compelling
to you personally or something.
Oh, like it makes you your own perfect mate kind of thing?
Right.
Now, I am also on the fence about this one, but leaning negative towards like tailoring
new mines for the sake of existing mines.
Yeah, it seems kind of wireheadish as well.
Like a large part of the fun of knowing other people is that there are things that are different
and you can explore new things and be challenged.
I guess I just don't really like people's purpose in life to be so focused on a particular
other person.
I think this can happen actually in reality already, but I don't like it.
Agreed.
I think that it would just be easier to do in a simulation, which isn't a general argument
against simulations.
It's just like one of the things that I'm wary about.
My main thing though, and I still don't know if I feel better about is like losing touch
with like physical reality.
And granted, I'm not experiencing physical reality directly right now.
I'm experiencing it as directly basically, well, so far as possible.
There might be cooler ways to get in touch with it.
Speaking of cooler ways to get in touch with it, brief digression.
Our last episode is about recreational drug use and I was so compelled by some of the
points made that I took LSD the next day and it was a different way of interacting with reality.
I don't know if it was actually interacting with reality per se because the ground doesn't
usually move like that, but that was interesting.
Your mileage may vary, use caution, etc.
But would you recommend the experience?
If they had the experience that I had.
I can't guarantee that you'd have that experience.
I actually still haven't even tried the medafinal that I got because I'm like,
I don't know, I'm feeling okay today.
And maybe someday I'll get around to it.
I mean, it'll make you feel better than okay.
I would try it sometime just on a, you know, whatever day.
I should try it at some point, I guess.
Especially if you have anything like due to do that day.
If you're like, okay, I got to crack this out today.
Like, all right, fuck it.
Give it a shot.
I mean, it is not a reality altering drug.
The thing is, I don't have a lot of hard, I don't have difficulty concentrating on
things I want to do anyway.
On Monday, I spent, I think, 13 hours just working on this little project that I'm really into right now.
Got to envy you.
I can't even do things I like doing for that long.
And I was like, oh God, I got to go get food.
All right, fine.
And no, if I get really into something, I don't, it just, it takes my attention.
Me as, like my goals as a, as like a transhuman, like alteration is closer to you as a person.
I can't even find the motivation to do stuff I like, I like doing.
Well, the motivation to start it is hard.
I didn't even get started until like noon because I was just like,
I could be doing other things.
I could be on Facebook.
I don't want to do this.
But like once I dove in, it was 1 a.m.
And I was like, man, I should get to bed.
I need a stick or a carrot, but usually the carrot is like, you know, lack of a stick.
So I need some motivation to do stuff, but like some external motivation.
I can't just like drive myself to do things.
But maybe I haven't found something that I like doing that much.
I don't know.
I mean, I'm sure there's some things you like doing.
I'm sure.
No one's ever had to force you to drink alcohol or have sex, right?
Fair point.
I consider responding with a joke, but none of those would have been tasteful.
So yeah, I mean, but I guess what I'm getting at is like,
I wanted to sort of just dial this back from like, you know, wild discussions
of like the like idiosyncrasies of like simulated worlds back to like
the basic transhuman thesis is that like, it's less about like, you know,
how you'll interact with simulated people and simulated worlds and more about like,
how can your life be a little better in ways that you can even currently imagine,
right?
Like my eyesight could be better, even though our glasses, my sense of touch could
be more acute and I could be, you know, have finer motor control and be
better at whatever mechanical stuff.
Like all these things and, you know, not to even extent that is superhuman,
although there's no reason to stop at regular human.
But I mean, you can look at other people who can do things that you're like,
you know what, that'd be kind of cool if I was, you know, as physically fit as
that person or something or whatever it is.
So I think that that's really the takeaway, like that it's more just about
just being okay with like a general growth mindset of like, you can be a better person
and there's no reason to stop where you're at.
And then of course, like the next step, I think that might, that might just be humanism.
And then the transhumanism part is like, there's no reason to stop it.
Like, well, let's not stop at peak current human, right?
You can do better than that.
But I, getting back to your culture example, well, I'm not super familiar.
Haven't read that many of the books.
But the, your argument about how you don't want the AI to take over a lot of the like
survival tasks for humans or the advancement in power over the world.
It's not just the survival part.
It's the fact that anything of importance is done by the AI now,
aside from friendship with other humans, I guess.
I mean, to me, that's the number one thing that makes anything important.
I'm sort of curious what the other important things are.
Like figuring things out.
Like to me, like scientific progress is important.
And I hate to have that all taken away because it's fun for us.
Like that, I mean, so as long as it's not taking away fun and like interpersonal friendships.
It includes scientific progress, but it includes anything humans can do.
AIs can do it better.
You want to write a song?
I can write a better song.
I mean, sure, humor yourself as a human do writing your human songs.
But there's, there's, there are other races in the galaxy or galactic cluster.
Maybe I don't know that, that are interacted with and generally the AIs handle that every now and
then humans like get special assignments and stuff, but it's always like the AI say,
okay, here's an assignment that a human can handle.
We will humor them and let them do their thing.
But when the shit is really serious, AI step in and like, nope, we're fixing this now.
Go about your way, human, because this is not playtime anymore.
Part of me, all right, having not read this either caveat.
I've actually not read very many in it, but the few that I've read, that is the distinct
impression.
So I think as long as, all right, so your first thing about, you know, the AIs will,
they can do science better than we can.
And they'll just, there's like letting us do it because it's fun for us.
That's sort of like completely fine with me.
Like that's exactly what you're doing with a kid, you know, who wants to see, you know,
they haven't heard of Galileo, but they want to see which one falls faster.
I mean, you could just grab their arm and stop them from doing the experiment and just tell
them the result and show them the math and say, whatever, or you can let them do it and have
fun, even if they're not like doing it in a refined way, they're still having fun.
They're still learning things.
I find that completely fine to, you know, just because, like, so I guess I'm going to
guess that's our current state now with adults and children and like me and real scientists.
But I wouldn't want to be trapped into childhoodness forever.
No, me either.
But I mean, well, if the cost of, or I guess the benefit of that was, like you said,
when things got serious, the AI was like, no, I'm doing this, I'm kind of super fine with the AI
having like a safety net over the universe or our universe than, you know, me doing it or,
you know, my peers doing it, because we don't know what we're doing.
Right.
Well, I mean, but that's, that's literally the infantilization of the human race.
We can have fun and do our things, but when anything important happens, the parents step in.
We're sort of infantile, though.
Well, I think that you may be able to make a choice in the scenario to say, well, I really
want to be part of the super intelligent jobs that are out there to do.
And then you basically have to become part of the AI, right?
Right.
You have to modify yourself to such a degree, right?
And, and there's, that's inherent in the task.
Like if you want to do it the best, you have to be the best so you can't be what you are.
Yeah.
That that's not something you can get away from.
That is one of my kind of minor hangups about creating AI that we might make ourselves irrelevant.
Well, but I mean, it's inherent in any, any power to be that great, right?
Right.
I mean, it's, it's, it's kind of the reason behind if there was a God, we would have to kill him,
right?
Because you don't want that sort of adult making all your decisions for you.
I was actually just going to bring up that point, but take the other side with it.
A, I wouldn't say all the decisions.
That's a false dichotomy.
It could just be the really important ones that we, that it believes we would make the wrong
decisions on, right?
Right.
