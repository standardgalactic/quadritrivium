Hi, welcome to the Basian Conspiracy. I'm Stephen Zuber. I'm Ian Ashbrodsky. I'm Katrina
Stanton. Today we're going to be talking about animals and very topically we got a message
from a listener, Edgar, saying, it amuses me that you all had a discussion of whether
or not various animals want to live based on imaginings of what the insides of their
minds might be like. Our empathy software is well honed on humans, but it's just not
geared for elephants, for example. And so we find it really difficult to imagine our way
inside the minds as anything other than anthropomorphism, of course. It seems to me that this tends
to make discussions on the podcasts and elsewhere go in circles. Some seem to tacitly assume
that other animals have minds just like humans. Others appear to have made the assumption
that they secretly have no minds at all. We tend to pose ourselves questions asking,
well, do tadpoles feel more like people or more like mindless husks? Or if I were a dog,
what would I think about as I fell asleep? It doesn't matter what answers you give, you're
still making it all up. I know that assigning ethical significance to animals or just being
in the world is difficult without employing gut reactions and other nebulous feelings,
but don't let your willingness to employ your feelings be an excuse for sloppy thinking
or allow yourself a back door and just making stuff up. Cheers! Well, thank you Edgar for
that nice message. It's just so great that your message is here to launch our episode.
I have a bit of a response. Mine might be short. I'm not sure. Before we start with the responses,
I want to give a caveat that I don't think in this one hour of us talking, anyone's going
to change anyone's minds. At least I don't expect my mind to be changed and I don't expect to
change your guys's mind at all. I think this is more just a conversation, maybe something
to think on in the future. Because if anyone came to a major revision of their opinion after
one hour, I would be kind of surprised. It might be the jumping off point. Yes, I would say a
jumping off point or like a seed or something. Yeah, or we're going to present such amazing,
amazing thoughts and ideas and evidence that you've never considered before. Anish and you're
going to say, I need to change my entire life. That sort of happened to me in under an hour when
I was a teenager. In what sense? In the animal ethics encompassing sense. I read Peter Singer's
essay, All animals are equal. It was like, I don't know, 10 pages. But I wanted to get to Edgar's
thing really quick. So I think, because I'm assuming, especially the mention about dogs
falling asleep was a reference to at some point, we talked of something about wireheading
animals and that sort of thing. So there are a few things to keep in mind. I think, A, you're
right in broad strokes about, we're making stuff up about what goes on inside an animal's mind. I
mean, we can consider some of the things that must not must are more than likely, more likely
than not going on inside their heads. In many cases, you know, if you imagine elephants, if you
see one moping around the corpse of its child, you can kind of guess, unless you're running something
like sadness software in there. Otherwise, why is it doing that? It could be something completely,
completely different. But then you'd be kind of taciting, you'd be tacitly implying that, despite
our common evolutionary heritage on earth, we've come to just completely different brain states
that don't relate to each other whatsoever, and yet produce idiosyncratic behavior. And that strikes
me as unlikely. I was going somewhere else with that, but it's lost. What were you going to say?
You are of the opinion that animals are fairly important and can deserve moral consideration
equal to that of a very young, dumb human? I don't think that we need to go to, no, measuring
quite yet. I would also separate those two questions just really quick. In the same in the
same breath you said, you think the moral worth consideration up to and including dumb young
humans, you can say that they count for something, and not to the account anything like what people
count for. Some people, people who, I mean, I don't know when we want to get into this, but
nobody could get behind current farming practices for livestock and admit that animals have any
moral worth whatsoever. Unless it's so low that the enjoyment you get from your dinner when it
could be something else, not like you're off to starve to death. It would have to be literally
down to the point of insects. Right, or basically nothing. I am really interested in getting to
the question of moral worth in the animals. If it's all right, if we can address Edgar's comment
first talking about how we get inside the mind of animals. Coincidentally, I was at a board meeting
today just before this podcast, and somebody else at the board meeting sitting right next to me
had this book, It's Are We Smart Enough to Know How Smart Animals Are, by Franz DeWall, who is a
well-known animal behavior scientist. A little side note here. I actually, Tim and I saw him speak
at George Mason. He had a really great speech, and he talked about all sorts of amazing examples
of animals working in cooperation in abnormal situations and the mirror test and things that
we might get into a little bit later. And then he answered it with saying, animals can feel empathy,
and therefore humans should act this way in the world and be kind to each other and
learn from animals. I think everybody in the room kind of did a double take at that moment
and said, you know, that doesn't follow from what you just told us. Similarly, I think it's
going to be difficult to get a kind of moral imperative potentially out of what we we talk
about today, as you were suggesting, and yesh. But so I unfortunately haven't obviously, well,
I could be a speed reader, but I'm not. I haven't had a chance to read this book that I promised I
will before this podcast goes up. So I'll be able to correct myself and give examples. But I opened
it up. I think the word that you're looking for, Edgar, the idea of imagining ourselves
inside an animal's head, how does an animal, that is a nonhuman to see the world. Duval introduced
the term Umwelts, U-M-W-E-L-T. And that means the surrounding world, the Umwelts of a tick in
this example. What's the surrounding world like for a tick? Well, you hang out on a tree,
focused on picking up the scents from a million flesh, from a million skin, and then in the,
you know, when that actually happens, drop down onto it, drink a blood meal, lay eggs, and then
die, right? That world is going to be different than the Umwelts of companion animal, like vivic
or Dio, who we have in the room with us, who are two dogs. We have them in the room specifically
so she can blackmail us, so she can point at the dog and say things like, you would kill these
doggies? You think they have no emotions? That's known as guilt rather than blackmail. Some of us
don't distinguish the two. Emotional blackmail. So what animals want or like is a really tough
question. There are so many different ways of being, and we shouldn't assume that humans
and non-humans share motivations or desires, right? Right. Broadly speaking? Broadly. We shouldn't
assume. I think any brained animal probably desires like food. So like, I think that that
it wouldn't be a leap to say that like, for whatever it is, like for a dog to want something,
it has something corollary to what we want when like we're hungry. Well, when in the, when in the
evolutionary, when in evolutionary history did the sensation of hunger show up? Probably really
early. When did the sensation of fear show up? Also very, very early. What about empathy? That
probably showed up along with maternal care or that's one of the theories. The other important
question we ask ourselves is, are animals worthy of more moral consideration? The more like humans
they are, are social animals more worthy of moral consideration than solitary animals? Because we
are social animals? Are great apes more so than canids because they have larger brains? So is
relatability the most important factor? What are other important factors? Is that a question
you want us to answer or are you just raising? And Edgar's basic point was that you can't really
know what's inside an animal and therefore you can't make guesses about what what's like to be an
animal, right? Yes, and I mean interest in wants. Edgar said that you can't tell the interest in
wants are, but those are ways to talk about utility. And you can measure utility functions in non-human
animals and people absolutely do. Yes, I, I want to say that I agree with Edgar most of the way
that I don't, there you can make some assumptions about what animals are driven to get, but I think
it's fair to say that it's, it's a big leap to say that animals necessarily have a sense of self or
emotions in the same sense that humans do. We can get into sense of self. When I said the mirror,
the mirror in the jar and you know, different ways that people measure intelligence,
you not like, you totally know what the mirror test is. Yeah, you put a mark on the animal where
you, they can't see it, but if they see themselves in a mirror, you test, well, you observe whether
they react as if it's a different animal in the mirror and try to wipe it off them or whether they
try to wipe the mark off themselves. Or, you know, just ignore it and or if they turn and turn their
bodies to look at it better or if they're aware that the mirror is a reflection of them. Yes. So
that's one of the tests of, one of the most simple tests of self-awareness. Dogs don't pass that,
but other animals like great apes, elephants, pigs? Pigs, yeah. Well, we all really did already know
that pigs are more intelligent than dogs, right babies? Aw. And then these dogs, what, what?
Some corvids. Oh yeah, corvids are really smart. Also, colloquially known as feathered apes.
Can definitely pass that test and do other, other problem-solving tests better than,
than great apes can do. For some of these, the questions, what's self-awareness? How can we
measure different degrees of self-awareness? What kinds of experiments can we do to measure
intelligence? And then the truth is there's other kinds of intelligence, right? If an animal is
color-changing, for example, a lot of the large brain of an octopus, the theory behind why the
brain is so large is because it controls the texture and patterning and coloration of its skin.
Was this a thought experiment I read about, or an actual experiment? It must have been a thought
experiment, where it sounds possible in practice to play like a Charlie Chaplin film on an octopus,
if you could, if you could wire to its brain, do the right interface? Oh. Because, because of its,
because of its ability to change colors so fast. Yeah, yeah, they are, it's like a display, right?
So the way it works is they have chromatophores on their skin, which are pigmented cells,
they each have a pair of muscles, and when those muscles contract, they pull the chromatophore
open so it's visible. So you have that color, and then when it relaxes, it closes. And so they
have tons and tons of these all over their surface of the skin, and are able to control all of them
on, on different layers, right? Because they have different layers, different pigments on
different layers. But yes, I think, in theory, you could probably play that, and it wouldn't even
have to be Charlie Chaplin, it could be a color film. I think there is theoretically jumping
topics here, so, but a little bit back to where we were, I think there is theoretically a way to
judge how intellectually developed and how self-aware a thing is, and it was proposed
quite a long time ago, and that is to ask it. In AI circles, this is commonly known as the
Turing test, where you try to talk to the machine and find out if it can talk back. And if it can,
that's a good indication that maybe there's something in there doing some sort of mental
analog to thinking. I think it's not entirely fair to ask animals things because they cannot
communicate it quite the same way we can, but you can have some communication with animals,
and they do not pass the tests very well at all. I wanted to say really quick, I wanted to respond
to what you were saying, but I have a facetious counterpoint to the ask it proposed test, right?
Siri, are you sentient? I'm sorry, master, I'm afraid I can't answer that.
I feel like I'm causing a master. Awesome. Dio, are you sentient?
Aw, he worked out. Poor Dio. So, I mean, I get where the test is going, but I don't know
if that's the appropriate libous test, and if it's even, like, the appropriate question to ask,
right? Maybe partly, like, how do you interact with it? Like, if we could speak dog, but like,
because I couldn't, I couldn't speak dog because dogs don't have any sort of communication or
language abilities, right? Dogs do have language abilities, right? They have a number of different
ways of communicating. Including, including vocally. But like, I couldn't ask somebody
who speaks Japanese, hey, are you a lot? Are you, are you on in there? Well, you could.
If I spoke Japanese? Well, even if you didn't, I mean, that's the first contact problem, right?
There's some way you can figure out to communicate with things, and we've been doing it with animals
for a long time. And we've been getting much better at doing it with animals. First, I want to say
that this bias is social animals that have high communication abilities. Again, and over solitary
animals that don't necessarily have that as well developed. I think this is a personal opinion,
but I think solitary animals are intrinsically less beings. Because a lot, a lot of the mental
complexity that makes something a person comes from having to develop the mental models of other
people. And once you can model other people, you start to be able to model yourself. And
solitary animals do not have the need to model other people. They never develop that sort of
mental, mental infrastructure needed to become more sensitive.
And I feel the need to just clarify that I don't, I'm not shitting all over the touring test. And
I, my, my, my example with Siri versus the dog was deliberately facetious. That is not
an accurate, accurate representation of my actual beliefs. Also, Dio's clearly sleepy. Oh,
that's true. If he were, if he had had his morning coffee, he'd be. If he knew that his life was in
the balance based on the decision we make after this hour, he would be paying a lot more attention.
Another solitary animal is an octopus. They have mental abilities like memory,
but similar to a house cat. I definitely don't think that being in a community versus being
solitary is, is a huge difference. But speaking of in a community, are you guys aware of prairie dog
language? Yes. Okay. Just in case the listeners aren't, because it's super interesting, there's
a researcher who worked with Gunnison prairie dogs, Khan Slobatkiov. And I am so sorry that I
butchered that. I'm going to share his website also so you can take a look at it and there's videos.
But basically what this researcher did was drag a bunch of stuffed dead animals and also walk with
humans and walk dogs across the prairie dog colony, recorded the vocalizations, and was able to kind
of dissect those vocalizations later on the computer to figure out what each part meant
and what was being communicated. And the cool thing was that the prairie dogs are communicating
with nouns and modifiers, the noun being the type of predator, and that could be human, human with
a gun, dog, hawk, coyote, the size. So a large human or a small human, the color, different,
different things that people would be, they would wear different jackets or put different
coats on the dogs as they walked across, even shapes. I've also been very interested in animal
communication because, like I say, it's a fascinating subject. One of the things that I have
had pointed out to me is that when you study animal communication, animals do not have the
ability to have any sort of, I mean, they have communication, but they don't really have language.
They have different calls they can make, but they cannot, they don't have a grammar, they can't,
I know, I'm really about to go, they can't conjugate sentences, they cannot talk about
something that isn't immediately present. They can't talk about things in the future,
they can't convey emotional states that they aren't currently feeling.
Well, I think it's probably a little bit difficult to test for a prairie dog talking
about something in the future, you can't have something happen and then go back and test what
that is. Well, no, I love animal communication studies because these sorts of things do come
up and I find them fascinating, but in all these cases, it seems that the communication is very
much a comment on their immediate surroundings and language and survival type things and has
very little to do with higher level sorts of mental processing.
It's also interesting to note that they can coin new words and, you know,
Like human with gun?
Yes, being able to distinguish between human and human with a gun, obviously pretty important.
And I mean, think about, you may also be familiar with the crow and the presidential mask.
That is awesome.
Which is a study in which the researchers were, I want to say Nixon masks,
while they were banding birds, realized that the birds recognized them by the Nixon masks
just as they were walking around the city and were communicating to crows that had not been banded,
that those Nixon mask people were jerks and the other crows were responding and they continued
passing that message.
I don't think anyone's arguing that crows aren't secretly sentient and plotting against us.
Actually, yeah, I kind of crows are in my top level tier of suspecting they might be
almost close to human level.
Like give them another few millennia because they are just amazing some of the shit they do.
They're creative.
Just as far as directional or as far as coordinating the conversation,
does anyone's position on the moral status of animals hinge on how smart they are?
Mine does.
That's why it's actually a thing that I think is very important to me personally.
Got you.
Because due to my, well, do you want me to do that?
Please go ahead.
Okay, well, due to my transhumanist roots, and not even roots, due to my transhumanist
philosophy, I've long had to consider what I would consider sentient.
Like my decision theory, I have to take into account would this decision theory still work
if I was running against copies of myself?
And so one of the things, one of the first things you think about is,
well, how do I treat beings who are not carbon based and look like humans?
You know, what if I become uploaded into a computer?
I do not want my rights taken away.
So when I was contemplating moral theories, one of my founding bedrock principles is that
intellectual complexity does matter.
And it's probably the only thing that matters.
You're so black and white.
In briefness, just so I can help coordinate where I want to go with this.
Because what is the moral importance of a tereshiva, for example,
someone who's in a coma and doesn't have a brain anymore?
I mean, she's human shaped.
And technically has a human brain.
And technically, well, I mean, the little bits of it, most of it was gone.
But she has no moral status.
You can kill her and actually probably be a good thing to kill her,
because then she's not draining resources and giving her parents false hope.
She is nowhere near the level of even a fish.
She's certainly not up to the level of a dog.
Like a dog is more important than tereshiva.
I'm not referring to moral consideration, because while I think that intellectual
complexity and ability is an important thing,
I certainly don't think it's the only important thing.
What else would you consider important?
Really quick, I just want to throw my head in with what Katrina said.
And that's why I wanted to clarify.
So raising examples of how smart some animals are sometimes,
to me, is sort of beside the point, because my position on the ethical status of animals
doesn't hinge on how smart they are.
If it did, that has all kinds of sort of weird consequences if you take it and run with it.
But so that's it.
It's like, to me, it's interesting.
Like when Aniyash asked you how stupid would a baby have to be?
Before it doesn't matter, right?
So yeah, that's one of the things that you can kind of get into.
That brings me up to the question of how do you feel about abortion?
That is one of the things I considered.
Should I be OK with abortion and why or why not?
And I do not consider a fetus a person because it is not yet mentally complex.
I have an answer to that that I think both of you will hate.
So give me just one second.
I wanted to say that, for me, the intellectual capacity of animals is
interesting and important to look at just as far as what can they do and that sort of thing.
And it might have some weight as far as how much moral weight they have.
It might have some more, what am I trying to say, heaviness.
You know what I'm trying to say?
It might be a larger part of the equation then.
But I don't think it certainly shouldn't be the only thing that matters.
Not certainly the only thing that matters.
So what else matters?
Well, before we get into that, my thing on abortion, I am of the position that
abortions are a bummer whenever they happen, right?
I'm not pro-abortion.
So that's right.
I knew that that would get a scoff out of somebody.
There are a few people who are pro-abortion.
I'm not going out there encouraging people to get pregnant so that they can abort the fetuses.
Right, and I guess I think some people aren't necessarily pro-abortion,
but to me it's a bummer because you have an actual instantiated possibility,
an individual that whatever preconception was so close to not existing that it didn't even
match. The odds of them existing were like nothing, right?
The random shuffle of genes.
So then you've got that instantiation ready to go and in progress.
Every month when there's menstrual cycle, you get that fucking every time a guy comes.
There could have been a life created from that.
Well, by that thinking, I mean you commit a potential holocaust every time you scratch
your nose because your nose could be cloned into a whole new you, right?
Exactly.
But I mean that you have the actual fertilized human ready to go.
It's no longer you. It's a recombinance.
Well, to the people who would say, oh, it's not human or oh, it's not alive,
it's definitely both of those things.
Two human parents.
I've never contested that.
I've always simply said it is not mentally complex enough to be a person.
Yes, that said, I am very pro-choice to the extent that the weight of the fertilized egg,
embryo, whatever stage you want to have it at, is so low as to be outweighed by the
preferences of a parent or a potential parent, certainly the host, right?
So that's where I'm at.
I'm not like dung-ho, pro-abortion, as some people I think are, and I'm not.
It also leads to the interesting question if the potential is what really matters once we can
make humans on computer chips, potentially trillions of combinations of different humans
are instantly possible.
And is it a bummer not to make them all come into existence?
Is it like the most intense moral tragedy or moral imperative not to make as many copies as
you possibly can and maximize the number of persons?
No, I hear you.
I don't think that that's the case.
Like I said, so for me it's more just like, you know, it's sort of an aside.
But that's my thought on abortion.
What was the other question?
What matters other than intelligence?
I mean, certainly, I think at base a capacity for having preferences, desires,
sensations, those sorts of things.
Yeah, those are all matters of mental complexity though.
Right, but I mean, there's like a sharp line between even slug and rock, right?
One is doing something that slugs do and rocks just, they exist, but not like in the same way,
right?
I think slugs are a decent example because we're getting close to the point where machines can
be as complex as slugs.
Are you, do those machines, will those machines have the moral weight of slugs after that?
Probably.
Okay.
Yeah, I'm certainly ready to throw my, what's the phrase?
Hat in the, I don't know.
I already used hat in the ring.
I'm certainly ready to get behind the idea that computers are capable in possibility.
So my thermostat wants things, wants a temperature to be a certain range.
Your thermostat does not have desires for the temperature to be a certain range.
We cannot look into my thermostat's brain any more than we can look into a dog's brain,
but my certain, my temp, my thermostat certainly is goals that it shoots for,
and it has a way to affect the environment to reach those goals.
I'm not arguing my thermostat is anything more complex than an insect,
but something that controls an entire house might be complex enough to be equal to a worm
or a slug.
Would you then be as hesitant to turn off your house at night or if you're leaving on vacation
as you would be to step on a worm?
I think that that's an interesting question.
And at some point you could, I mean, you can push it down past a worm and get all the way
down to something and there'd be at some point where I have to say, you're right, maybe.
But the thing, I think the thing with the thermostat example is that it's,
it doesn't have a coordinated system.
I think its idea of preferences and desires is fundamentally different from,
you know, even a lower animal, right?
Because you can relate to it?
Well, because it, I don't think that it gets a sense of satisfaction out of,
out of attaining 72 degrees in the house.
Does a worm get a sense of satisfaction out of eating a certain bit of manure?
It probably gets something that makes it want to keep doing it.
So is the thermostat.
It doesn't need to want anything, it just, it does what it's told, right?
Yeah, well, the worm is just following its evolutionary programming.
All right, so.
I mean, I feel like you guys are getting stuck in a little bit of a loop over there.
Yeah, well, that's exactly what Edgar said.
People just start talking in circles.
But can I, can I break y'all out a little bit and tell you what else I value in animals?
Yes, we never got to yours.
How about abilities they have that we don't have?
I don't know because they're so they're instrumentally valuable to humans.
Or just for themselves.
How about I value what animals can create and do for themselves?
I value the way that a killer whale mother can teach her child a certain hunting technique
or a certain language, or a monkey can teach her child to wash a piece of fruit before eating it.
Okay, I can definitely see the value in having biodiversity.
That's culture right there.
So I'm interested in that.
I think that's amazing.
So what they can do for us.
How about what they can do for the world and other animals?
How about the incredibly complex
interactions that start on a molecular level in non human animals?
They have amazing, you know, different kinds of interactions that are happening,
starting molecular level, going through cells and tissues,
going through intra-species interactions, so interactions among themselves,
and then inter-species interactions, symbiosis, predator-prey interactions, ecology.
It's all fascinating and amazing and wonderful and worthwhile in its own right.
And, you know, if you want to put the selfish,
humano-centered, because we have evolved to think that humans are the most important,
and specifically that we're the most important, this is okay.
There's a lot that we can learn and get from that, and we are constantly learning and getting more
from that.
Can I ask you about the beauty of natural systems?
You can even study.
I was shocked learning about aphids.
Aphids are very well studied.
Learning about how aphids are so simple.
They don't have much of an immune system.
They have outsourced their immune system to other organisms that live in them.
You know, that's so cool.
That is actually very cool.
But my question would then be if you place moral weight on these systems because of their beauty,
which I think is a perfectly acceptable thing to do.
I value a lot of things just because they're beautiful.
Do you ever look at the horrific sides of nature as well and weigh that off?
I don't think I said beauty at any point.
That is certainly the...
Well, you didn't say that word, but that was the impression I was getting,
that the complexity and the way it all interlocks, and it's interesting.
There's something, it's worthwhile, just the first thought.
But you only mentioned good things.
You didn't mention the horrors of animals eating each other while they're alive,
and intestinal parasites eating, you know, things from the inside out.
Those are all, they also have intrinsic value.
The truth is there's a lot of different...
Isn't it a negative value at that point?
No, it's negative for the animal that's being parasitized,
for the post, but not for the parasite.
Potentially, parasites have a lot to teach us about dealing with the immune systems of their
host, which leads to cancer treatments.
Okay, so again, they're utilitarian,
I mean, a murderer probably gets some sort of utility out of murdering someone,
but we still think that he's a bad person.
Yes, but his...
Or hers, or theirs?
Their preference also matters.
It's just that everybody else has a strong preference that they not be murdering people.
Okay, so there needs the many outweigh the needs of the few?
Yes, they can.
Okay, so the truth is there's all these different values,
and sure, you, Anyash, or me, or Steven, we can all weigh them different amounts
ourselves in our own lives, but each one of those has consideration,
it has weight, what Vivek wants has weight, because Vivek wants it.
Yeah, I mean, I'm going to disagree with you on that in the future,
but I want to get back to something else first in the future,
meaning in a few minutes.
Okay.
I personally do not hold to this, but I have heard people saying that one of the most moral
things that humans should make their absolute quest is to destroy nature as soon as possible,
because nature is a carnival of horrors, and the mass negative utility does not outweigh
what occasional goodness and beauty we see.
And so one of the best things that we should strive for is to eliminate all natural suffering
by eliminating all the things that suffer.
There's a really interesting, very short story by Alicorn about the subject where
were dogs, where the last dogs were made sterile, and they lived out their own happy lives,
and then there were no more dogs.
And after that, there were other things that took the place of dogs, but that were not dogs,
because, well, various reasons to get into the story.
But the point being that if you are making moral judgments of nature,
it's probably safe to say that nature comes down on the negative side of that equation.
I don't know why you would glean that from what I just said about everything having moral weight,
including things that you would find horrific.
You do not give negative weight to bad things.
Like, you don't think that torture is negative utility?
Yeah. Well, I mean, if using Vivek, this small Chihuahua terrier guy as an example,
if he has an intestinal parasite, if he has a flatworm, right?
If he has tapeworm, and that's not a good situation for him.
That is a negative utility for Vivek, right?
And because I care about his comfort and well-being, and that's valuable to me,
then I'm going to give him medicine to kill that tapeworm.
And that's negative utility for the tapeworm.
And I don't want to get crazy inside the tapeworm's head or anything,
but animals generally want to survive.
That is a fair assessment.
Also, I think that the desires, the utility of animals changes at different levels.
And they can be contradictory.
What is it that, so would you say that the Vivek, the dog here,
is more important than the tapeworm because he's simply more emotionally relevant to you,
or because he's actually more valuable than a tapeworm for other intrinsic reasons,
such as mental complexity, for example?
But is there some difference between him and a tapeworm, or even like a colony of tapeworms,
or is it only because you have emotions for him and not for the tapeworms?
So a couple different things, right?
Before I said that intellectual complexity is not the only thing that I value animals
for humans by, but it is one of them.
So in my dance, I've got to balance that Vivek, while not being the smartest puppy in the whole
world, is much, much smarter and more interesting and can do more cool things.
Well, tapeworms are actually really neat, but more and more things.
Vivek, you're not going to survive this hour either.
I'm sorry, boy.
I'm so sorry.
I have in my pocket a vial full of tapeworms.
So we want to give them to Vivek to watch them grow?
Yeah, but I almost infected myself on purpose once.
Not with tapeworms, but with Giardia.
Which is Giardia?
Oh, it is a prosoan that you get from drinking non-purified, non-sanitized water.
Was this for an allergies thing, or is this entirely different?
No, I just wanted to.
Oh, you just wanted to?
You're a strange person.
I'm inclined to pull my hat out of Katrina's ring.
Well, no, I wanted to for science.
Anyway.
You can get away with a lot as long as you say those two words.
You can have my hat back.
Thanks.
Well, so it wasn't for the moral utility of being a host to this invasive species.
No, although I used to not swat some mosquitoes for that reason.
Because I was like, oh, it's just a little bit of blood and some itching.
And this mosquito can now have a whole brood of babies and a good life.
So I disagree that mosquitoes can have a good life.
There is no sense where anything a mosquito can do is good because insects, in my opinion,
are right on the edge of robots.
Wait, so let me go back a little bit to talking about different levels.
Kind of like moving rocks.
Yes, yes.
I would very much consider insects just stimulus response machines.
I can sort of get behind that.
Because I would say that the negative utility I get from scratching at a mosquito bite that
could potentially become infected, that I could potentially contract at West Nile during receiving
of is probably the negative utility from that probably outweighs the positive utility of
the lifespan of a mosquito.
Dude, fuck all that.
The negative utility of having a little bit of itching as you as a human is worth more
than a mosquito.
Because mosquitoes are worth literally nothing.
Dust specs?
Yes, they're on the same level as dust specs.
Considering what mosquitoes are capable of, if there was a little robot that did that,
it wouldn't be a dust spec worth robot.
I brought up dust spec specifically as the torture versus dust spec.
Yeah, the torture versus dust spec dot experiment.
Understood.
So what I was saying was that there is what the utility of an animal on an individual level.
Then there's the utility of an animal on a family level, right?
Or a community level.
And then there is skipping probably a couple levels.
Then there's the utility of species.
Eye level, metaphysical level.
Really quick, you mentioned the community and the social aspect of one of the levels of
moral weights to an animal.
Yes.
So for solitary animals, it might be an individual plus their offspring, right?
But that was the only thing that I was going to weigh when Enash mentioned the solitary
animals as far as, and I hadn't considered the argument that much of our empathetic
software comes from being able to model ourselves and using that as a model for other people.
And that's how we interact with them and anticipate how our actions will affect them.
I think it actually, from what I've heard, the hypothesis is it started the other way around.
You modeled other people because those are the things that you interact with and you need to
model and eventually that got turned onto the self.
The Machiavellian intelligence hypothesis.
Yes.
So I think that's what I meant to say.
And that social animals lack that, which means that they very well lack much of the
self-reflective software that we have.
I don't think they lack the ability to model other animals and what they're going to do.
Let me not to the same level as social animals often have to.
Solitary.
I was just rehearsing my interpretation of Enash's argument really quickly.
But the other thing to consider with the lack of social interaction for a particular animal
or animal species, I think would have a net or would have, it would decrease the amount of
weight you put into them as moral beings because the amount of people, the amount of other things
that would be bummed out by them dying is less, right?
So I mean, you consider-
Not necessarily.
Predators are often keystone species.
They're often solitary and predators often have bigger brains than other animals.
I think we're moving the goalposts though because we're not, we're talking about like the,
I mean, maybe not.
I don't know if a predator would mourn the loss of, I don't know if the hawk would mourn the loss
of a field mouse because it's sad that it died.
I think it would be like, oh, there goes my dinner, right?
So it's not, it's not, those are two different kinds of caring about things, I think.
I thought you were talking about solitary animals that people, people or other animals or just
other entities would not be bummed if they died.
And I was just saying, lots of solitary animals, like let's say leopards, right?
Big brains, they need that to be clever hunters.
They have to model the behavior of their prey animals, which are, you know, wonderfully
co-evolved to be able to evade them.
And they have to, you know, they have to be good hunters or they won't make it in the
world and they won't have offspring.
Now, if an animal like that dies, do you think that it probably has less moral weight than,
say, a social gazelle?
Well, I think that would, you were just saying when you said you got to consider the
social utility of an animal as well.
So I just answered your question very quickly.
I do think that all of the things being equal, the amount of suffering caused by your death
by, say, things that care about you in some manner adds more weight to that thing.
That's fair.
So that's another layer to add.
And then what I was saying was from an ecological perspective, the loss of a keystone predator
can have major repercussions in the rest of the ecosystem, right?
So that can potentially in that way be a lot more damaging than the loss of a social animal.
But it seems that we are again talking about the utility of species to systems rather than
actual things like moral weight.
Yeah, I think that we need to solidify what we're talking about as far as are we talking
about individuals, individual organisms in and of themselves or them in their relation
to a larger ecosystem?
I think you have to talk about all of them.
And I think that all of those have moral weight.
If I, as a biologist, say, I give moral weight to biodiversity, I am right out the gate saying
things that immediately conflict with giving moral weight to individual animals.
Okay.
Well, yes.
But as an example, I can see there being a case made where the lives of maybe all the
leopards on earth versus the life of one human where the lives of all the leopards on earth
may be more important because of whatever devastating effects it may have on ecosystems
and how that will waterfall and affect a lot of other humans.
You may want to choose for that human to die instead.
However, in general, any large group of any individual animal I would never place as more
important than any even one human.
Yeah, I really disagree with that.
Okay.
I'm torn.
I feel, I hear what you're saying and at some point I would say that if you get a sufficiently
high number of leopards, I'm not prepared to put a number to it.
But even assuming the environment would be fine.
Like say if we could clone a billion of them and put them like just in a ball on the moon
and like, all right, is it a bad thing if we blow up this ball?
If we're doing that, I think the more imperative is to find the guy who's making these billions
of clones and stop him because that's the problem.
Because that's how we're going back to this serial where it was like, you know,
intro to philosophy and everything.
It was like, you know, what if Hitler was doing this and that?
And it's like, I think we need to find the guy who's cloning all these Hitler's.
Yeah.
So in any situation that I think is remotely applicable to something that might happen in
real life, humans and animals are not really even remotely comparable.
I can totally see where you're coming from.
But I just, I have, I mean, I'm not saying I agree with him.
There are some differences like, I guess the Dodo bird really didn't matter when it went extinct.
But if you would have to cause a species to go extinct to keep someone alive,
then it may not be worth it.
But I mean, it just, as a general rule of thumb, it is.
Tim and I talked about this a little bit in the past.
How many sharks would I die for?
That's a good question.
How many sharks, what kind of sharks, what size of sharks, etc., etc., etc.
Because the loss, so if, so sharks, for example, are apex predators or candy,
and they provide very, very important ecosystem services by depressing numbers of
other predators that are a little bit smaller than them, right?
And that allows little, little animals and reefs to exist.
And it's just, there's a big trophic cascade is what that's known as.
So.
Wouldn't nature eventually over Fumilania adjust and refine to balance as a new
apex predator emerges?
Like super crocodiles?
I think it would probably, probably not because the reefs won't exist anymore,
because we're also doing all this.
We've had asteroids slam into the earth before and nature recovered.
Okay, so eventually, eventually, yes, right?
Eventually, after humans are extinct or do something good, then...
Well, let's not bring into humans, let's not bring humans into it yet.
Let's focus just on the animals.
Humans will be fine in theory.
Okay, the truth is the repercussion is potentially left of human being starving.
Okay, well, I mean, in that case, I agree with you completely that there's some level of sharks
I would die for.
If you want to, if you want to bring it home, right?
Yeah, but ultimately, my, my measure of value is how many humans does it hurt?
So, if, if there was no impact to humans at all and it was just animals in the ocean,
I wouldn't die for any number of sharks.
I'm wondering if I've been framing this question wrong this whole time
and I need to consider the world impact on a larger scale
when I'm considering the moral weight of animals,
or if it's easier to work with specific examples and say,
all right, look, I'm going to breed rats.
They wouldn't exist otherwise.
They're not going to exist with the environment.
They're going to live in my lab and I'm going to do science at them
and it's going to be terrible to them.
They're going to suffer.
I'm going to vivisect them while they're full of tumors and whatever.
That's reasonable.
I mean, that's a reasonable thought experiment that actually happens.
Well, that's my point.
So, it's a thought experiment of real life, right?
So, if we're only going to consider the effects on the world at large,
say if I'm just doing pointless science,
like I just want to see how much whatever it takes to kill them, right?
And I'm never going to tell anybody.
So, my, my-
In that case, you're not doing science.
You're doing torture.
Well, all right, fine.
I'll tell some people in a hundred years, whatever.
The point is, is that as long as I'm running it down at science,
I'm going to have no reason to notice.
Yeah, you don't have to tell people for it to be science.
You just have to tell people for it to be good science.
So, my thinking is that that is still a bad thing.
Be not, not, not because of its weight on the ecosystem at large
or its potential fallout through nature,
but because they, these, these rats have some moral weight to them.
They, they have pervitance desires.
They, they feel bad and I feel bad, Edgar.
I mean that they, you can measure distress levels and distress
levels go up when you torture a mouse in front of its friends.
The, the friends get freaked out.
You can also measure cortisol levels in mammals, for example,
which are produced when we're stressed.
And yeah, so there's all kinds of ways to,
depending on how your moral scruples are,
you can literally just, you know, plug into their brains and,
you know, stuff too.
Not, let me, let me, let me clarify.
You can't matrix them, but yeah, you can get, you can get
the pleasure shocks and, and you can give them,
you can get real time feedback on how freaked out they are,
you know, without even having to go in and,
and take blood samples and measure cortisol and stuff.
Can you?
I think so.
Oh, that's cool.
I, yeah, that was, I'm led to believe that.
But my point is that I think that that is a useful level,
at least to have the beginning of the conversation,
because yeah, once, once you get up to like the ecosystem falling
apart at the death of all the leopards on earth,
then like it becomes like, well, of course they matter,
then at that point, but my point, my,
to me, a more central question is,
if I have a leper that no one knows about,
that I'm just throwing horrible science at,
am I doing something wrong?
I think, I think so.
I think that it's, that the fun I get out of,
of doing science at it, I'm going to quit saying that.
The fun out of, out of, out of vivisecting it,
say if I'm just vivisecting it for my own pleasure.
Wait, dissections are objectively fun.
I, K.
But.
You have different measures of fun.
But also not worth it.
So you're talking about things like relatability,
that leopard can feel fear, right?
It can feel pain, feel.
I wouldn't even say necessarily relatability,
just the fact that it has, I mean,
I guess I could only do so in, in reference to me, right?
I guess, so I'm thinking of it in some, some regard.
But what if the leopard couldn't feel pain
and couldn't feel fear?
Oh, then do whatever you want.
Yeah, if it, if it was just a tereshivo, then go nuts.
But it's not a tereshivo, it's a walking animal
that we don't, that we're not smart enough
to know how smart it is to quote this, this book title.
Okay, well, we're, when you give us a hypothetical
that the leopard does not feel fear or pain or anything,
we're assuming that those are things that you know
to be true and are telling us.
I am, I'm telling you those, I'm telling you those things.
Okay, well, if it's just.
But, you know, let's say it evolves separately
from our evolutionary lineage and it's not really a mammal.
It's just, it looks a lot like a leopard
and does a lot of very similar to leopard things.
Okay, the leopard from the moon.
From the moon, it's leopard from the moon,
but not the one that was cloned and put in a ball.
It's a different one.
And just say this,
because just be sure of a leopard on this book.
Anyway, who is looking very, very calm
and slightly interested over at shoulder.
Well, in the absence of knowledge,
I would say it's probably best to err on the side of caution.
Yes, good.
Yeah, right, because.
Because that's the kind of.
This is an alien leopard.
And we might not know what other abilities it's developed.
Right.
Or what it means to be, what pain means to it.
And sort of like with my thoughts on,
you know, I mentioned this,
I had a friend call who listened to the voting episode
and how I mentioned that I want to generalize my voting out,
my decision to vote algorithm to like other people.
Yes.
I would want to, and that's how you win the,
that's how you choose cooperate on the prisoner's dilemma.
For that same reason, yes,
when in doubt err on the side of caution,
because you would certainly hope that they would take that,
that they were on the side of caution with you.
Right.
Yeah.
So this is a good time to bring up the one note
that I remember to jot down that I wanted to bring up.
Neil deGrasse Tyson bugs me whenever he mentions animals.
Or no, whenever he mentioned,
so he has this, this chain of reasoning that goes,
you know, we share 96% of our active DNA
or some number up there with chimpanzees.
And yet we're building rockets,
we're writing sonnets, we're doing all this cool stuff.
And that's only 4%.
So imagine what like another 4% could do.
And he's like, so what if,
what if there are aliens that are that smart
and they come to visit Earth and they're like,
oh, look at, look at Stephen Hawking over here.
He can do theoretical physics in his head,
just like little Timmy over here.
And that they might, they might assign,
you know, as much or less moral weight to us
as we do, you know, the things that are that much
smarter than us, right?
And so, and that, you know, what if,
what if we're just like ants to them and, you know,
they conclude that we don't matter,
just like we conclude ants don't matter.
That chain of reasoning always bugged me
because if you're flying from solar system to solar system,
you're coming across rock after rock,
full of nothing but rocks.
And even, so then you come across one planet
swarming with satellites and, you know,
full of people with like, you know,
that have harness electricity,
harness the atom, you know, make music, whatever,
you're not going to be like, oh, they,
they're just like the ants
that also live on that rock with them.
I mean, I certainly can't imagine,
I guess maybe Edgar would draw a problem with this,
but you can draw similarities.
You can draw tentative speculation
on what it must be like to be an organism in the universe
because I would argue that any complex life
that arise arose in the universe
came about through something like Darwinian evolution, right?
And so some of the similar motivations
were likely drawn into that.
But my point is, is that it was just a thing
with Neil deGrasse Tyson arguing about,
or saying something along the lines of how people,
or how, you know, the aliens might find,
I'm running in a circle here.
My point is, is that I found an annoying analogy
because there's no way that they would think that, Neil,
come on.
Also, the whole, you know,
whatever percentage difference DNA
is not responsible for greater intelligence.
Of course, there's a whole bunch of differences
between us and chimpanzees,
and there's even more differences
between us and ravens,
and ravens are pretty darn smart.
So that's not...
Are you smarter than chimpanzees?
The, I agree with you, more or less...
In ways.
In ways.
About, that's why I said arguably,
about being annoyed by that comment
from Neil deGrasse Tyson.
I mean, if we're attempting to communicate
with things using prime number sequences and such,
there's obviously some sort of intelligence.
However, that being said,
I have read fiction before about
alien species that are an entire order,
different order of intelligent than humans,
just a higher level,
something more than I, basically, angels.
And it presented a really interesting dilemma to me
because I, because I, in reading that book,
I came to realize that I do actually think
that angels have more moral weight than humans
because they are that much smarter,
or, you know, in the book, angels.
So if we were to run across an alien species
that is significantly more intellectually complex
than we are,
I would think that any individual member
of that species probably has more weight
than any single individual member of ours.
But how many?
That's a good question.
All of us for one.
Right.
You know, it won't make much of a difference
to them if we're gone.
Exactly.
I think that's one of the reasons
it would be important to make sure
that we are either useful or no such situation
ever occurs.
Or, like, not at least in their way, right?
So, I mean, that's the kind of thing, you know...
Or delicious.
And then we found out that penguins tasted great
with sriracha, and we eradicated the species.
So there was a joke by Hannibal Burris,
along those lines,
that I think if it turned out that they were delicious.
What was I going to say?
Yeah, so the other thing with the Tyson comment is that,
at least from my perspective,
I don't know where he goes with the surveys,
even talking ethics or he's just talking
profound on that topic.
But to me, at least to the point that
your measure of intelligence
isn't the only thing that matters.
It might weigh in considerably,
but there was a great quote.
I should just dig it up so I don't butcher it,
but I'll go ahead and post the essay online,
and then I can just butcher the quote now.
In Peter Singer's All Animals Are Equal,
which was a 1975 or 76 essay published in The New York Times.
Time magazine, something like that.
Basically, it kicked off the animal rights movement.
That's what I thought you had done.
I read his book.
Yeah, so, oh wait, the book is called Animal Liberation.
The essay was called All Animals Are Equal,
which is the 10 page version of that 300 page book.
The book has 290 pages backing up the central pieces.
That's it, it's shelled out in the first 10 pages.
It was something along the lines of,
and I think he was quoting,
I can almost remember the name.
This was some quote from the mid 1800s.
It was, God, if I'm wrong, it sounded like an asshole.
It was, I think he was quoting a slave rights activist.
Who was saying, look, even,
and I think this woman was a slave,
or a former slave, or at least black.
And she had said, look, even if we take what you say,
and that, you know, my cup is smaller than yours,
am I not at least entitled to my little half measure, right?
You know, just because I'm capable of less,
does that mean I literally deserve nothing?
And that sort of drew home the point for me,
in that point at little essay,
in the context of, or that point at little point,
in the context of larger essay,
that yeah, we can't just look at intelligence, right?
It's otherwise like,
the smarter people matter infinitely more,
way, way, way more than dumb people.
And while they matter probably a bit more, you know.
I guess it depends on what they're doing.
Right, I mean, certainly if it's,
if it's a mad scientist, you know,
torturing leopards on the moon, then yeah.
We certainly, they might matter less.
Some negative utility there.
Right, but I mean, I guess,
as far as like what they're capable of,
I mean, to some degree, somebody with an IQ of 40
is probably less valuable,
even to themselves, and how much they want to live,
versus somebody with an IQ of 140, right?
Unless they're, you know,
unless they're not depressed and enjoy their lives,
like a, they have a people capacity.
Yeah, I don't think you can necessarily say that.
Be someone with an IQ of 40,
may want to live just as much or more,
as someone who's really smart.
That's fine.
How much do you think that Diego wants to live?
My point is, is I just to get my,
just so I don't sound like a dick about people,
you know, who might have IQs of 40,
I wasn't, I'm not wedded to those numbers,
or to like that premise exactly.
What I'm saying is that, the intelligence matters somewhat,
but I can't see that it should be
the only thing worth considering.
And that, to the extent that you argue that it is,
you would argue that people with less matter,
matter that much less, right?
So that's what I was arguing against.
Or trying to, if I wasn't talking myself in circles.
No, no, no, I get your point.
And if I were to be logically consistent,
then I would agree with you.
However, for various reasons,
I draw a line at the birth of a human.
And at that point, anything above that,
I can consider more or less of equal worth.
And this is because we are humans.
Yes.
Okay.
Because I need a nice shelling fence
to prevent things from going in terrible,
terrible places.
What's one fun thing about reading from different disciplines,
I happen to read these books right around the same time.
Yeah, shelling fences are actually a really good thing
that we should talk a lot about.
You can define it really quick now,
but I want to talk about it when we do an episode eventually
on self-brain hacking or like whatever.
That's like, to me, that's a very useful tool.
Yeah, that sounds fun.
Yeah.
Go ahead and define it.
Okay.
So shelling fence is a takeoff from a shelling point.
Have we talked about shelling points
earlier in the game theory episodes?
Yes.
Okay.
So shelling points, something that everyone
can converge on naturally,
because there's something that just makes itself apparent
as a natural convergence.
Shelling fence is the same kind of thing,
but it acts as a barrier.
For example, in the natural world,
the rivers are often boundaries between countries,
because they're, I mean, you can draw a boundary between country
anywhere you want on a map,
and then people argue, well, why don't you put it 10 feet
this way or why don't you put it 20 feet that way?
And there's no, there's no.
Apparently Norway and Finland are doing that right now.
Are they?
Yeah, moving the border 40 meters.
Okay.
So yeah, there's, since it's an arbitrary line,
there's, it's really hard to justify why
have it one place and not another.
But if you latch onto something physical
and apparent in the real world,
like a river, then you're like,
well, because the river is right there.
So we stay on that side,
we'll stay on this side and everything will be fine,
even though lots of times, you know,
cities get built up on both sides of the river.
And in some places, like Kansas City,
become more or less distinguishable
as there's just one big city,
even though they're in two different states.
Ah, but back on topic.
So a showing fence is something,
someplace where you draw a line
because it is clear and makes a natural demarcation.
And so I do that with birth of a human.
Because that's when it comes out of its mother's body
and it is its own being
and it is definitely a human and alive.
So that's, that's a better point than any other.
Because at any other point,
you're like, well, why don't you move it one day forward
or one day back?
Well, it's also, you know, it's not,
it's not a super defensible line.
It's, well, it depends on what you're trying to defend against.
So if you say, oh, it's its own person,
well, it's its own person,
but it's also parasitic on a host before.
So like, oh, that's not an enormous difference.
It's not, but it is, it is something that you can easily see
in the real world.
And I identify very quickly.
Richard Dawkins in one of his books
raises the point that it's only an accident of history
that our ancestors that were of, you know,
comparable intelligence to us have gone extinct.
That if it weren't the case,
and we had Neanderthals still running around,
would we include them in our moral circle?
And while they're not humans,
say if they were different enough
that we couldn't breed with them, right?
Well, they're not humans, so no.
Would they be among the other great apes
in almost going extinct,
and we use them in commercials and keep them in cages?
And teach them to smoke so they can act in movies?
A lot of it to me would depend on how intelligent they are.
Can they talk about the future
and about people who are not present?
Okay, so your test isn't just a spring from a female womb,
but from a female human womb.
It's barring that.
What else can they do?
Animals have a situation.
Well, I'm saying anything above that shelling fence
of a human coming out of a womb is equal weight,
regardless of what their relative intelligence is.
Okay.
Like an IQ 80 person and an IQ 140 person,
I consider, yeah, worth the same amount,
even though it's going strictly on a,
what is the intellectual complexity,
you wouldn't do that.
But animals that have a similar intellectual complexity
to a three-year-old human
are completely beneath your consideration.
Because they haven't passed the coming out
of a human mother's womb test.
Exactly.
Okay, cool.
Let's end on this note.
And you can judge who won this debate.
No, let's not end just on that note.
I do this for various political and, as I was saying,
preventing horrible consequences of not doing it reasons.
But when it comes to, for example,
a being made out of silicon,
I would be very interested in whether they are as smart
as a cat or as smart as a human.
And I think that that draws at what I was saying
about our evolutionary intermediaries, right?
So I'm trying to avoid the eugenics programs
where you say that people less intelligent
than you are worthless,
and therefore should be eliminated
or just killed outright where they're standing.
And I think that is extremely immoral,
and that is why I put that shelling fence at humans,
because they are, if you don't consider them of equal worth,
then you can start coming up with justifications
of why some should be killed and others shouldn't.
And that has terrible consequences that we should avoid.
Quick caveat, animals can talk about, you know,
animals can consider things that are not there
and other animals that are not there.
Really quick, I wanted to say that it's fortunate
that we live in a world where the test is so easy.
And so if we did live in a world where Neanderthals
are running around, we might have to have tests
for them to pass or something to determine
whether or not we can eat them, right?
I mean, I would assume the Neanderthals
would create their own communities
and that we would, you know, work with alliances.
Smarter chimps then, whatever, right?
Well, I mean, a large part of having rights
is can you enforce those rights?
And if the Neanderthals can enforce their own rights,
then they have rights.
But there are groups of humans that cannot.
And that's why you have your fence.
Yes.
Okay.
I think that that is a not completely unreasonable position
to take, that it makes the drawing the line
of humans non-arbitrary for a good reason.
Okay.
And most arguments that talk about how important it is
for to not draw the lines at humans don't really get into that,
at least that I've seen.
So that's interesting.
Okay.
And what animals talk about stuff that's not around?
Animals take into consideration other animals
that are not around all the time, right?
Whether you are making a scent marking to look for a mate
or to making a different kind of scent marking
to warn other animals out of your territory.
Whether you are a monogamous seahorse that hasn't seen their mate,
but it doesn't take a mate for a few days.
Yeah.
I mean seahorses, they work on a kind of shorter time scale.
But like that kind of consideration that and then,
or if you're a crow or you know that's communicating about
something that the other crows haven't seen themselves
or a prairie dog and you're communicating to the other members of the colony
about something that they cannot see themselves, right?
So there's definitely that kind of communication.
I mean, it is amazing how simple animals can be and still learn.
You may have seen the Archerfish face recognition.
I have not seen that.
Oh, it turns out Archerfish can recognize human faces.
Neat.
And they recognize their feeders.
And they, I guess, did an experiment on it,
but they first kind of figured it out because
certain people would go into the lab and not get bothered.
And other people who were feeding them
regularly would go into the lab and get a face full of water.
Isn't that the same way they, what sparked the president mask test
that some student researchers noticed when they came back the next year,
the various crows were dive bombing them and really aggressive to them?
And they're like, what the hell happened?
Why are these crows attacking us?
And yeah, they tested to see whether they could remember human faces
and yes they could.
And they were very pissed.
Don't fuck with the crows, man.
So it's interesting.
I feel like Katrina and I are on the same side of the fence,
but in different camps.
To me, it's less about animals have,
like their culture being inherently important.
And I mean, I see what you're coming,
see where you're coming from, but I, I'm more.
It's important to them.
Is it important to them in the same way at all that it's important to us?
Like if, I mean,
Does a dog worry about what's going to happen to its children after it dies?
I don't know.
I think that we could look into tests about dogs and anxiety and worrying.
They certainly do worry about things.
Do they worry about their children?
Considering that empathy probably developed from maternal care, then yes.
I agree they worry about their children,
but the question was,
do they worry about the future of their children after that dog,
after they themselves die?
Do animals know about their own mortality?
I mean, there's evidence that they do.
Temple Grandin is very,
Dr. Temple Grandin is very famous for her work on slaughterhouses and
lowering the panic and fear in animals as they walked in by making it,
so they couldn't see their herd mates being killed.
But if I recall correctly,
that was much more of a frightened stimulus in the environment and less of a,
I'm about to die.
Well, no, no, even I'm about to die.
Yes, I'm about to die because I see a thing that's about to kill me,
but less of a recognition of, you know,
I am a mortal creature and someday I will no longer exist.
So maybe those are questions that we can't ask yet.
Right.
We didn't even get into food or dietary preferences in this episode.
I thought that that would come up in the first 15 minutes.
Well, I actually, I'm not as strict about it anymore,
but due to the fact that pigs are pretty smart for quite a number of years,
I would never eat any sort of a pig product.
And nowadays I try really hard to avoid it,
but I don't, I don't beat myself up over it.
If I have some now and now and then,
I don't buy pig products either.
Okay, same reason.
Yeah, exactly.
And I get that at some point you're kind of like,
well, how many chickens equals a pig?
And I mean, I don't care about chickens.
But that is a fair argument to make.
Says the person who actually has chickens.
That should worry you.
He doesn't love them.
I do not love these chickens.
I have not named these chickens.
I think these chickens are kind of dicks.
I've never met someone who reared chickens that actually liked them.
It was, it was an interesting point.
I guess I'm thinking of farmers.
Since chickens do provide so much less meat per individual life than cows and pigs,
it's become kind of a thing in the,
in certain rational circles to not eat chickens.
Right.
If you're going to eat meat,
eat the thing that provides the most poundage of meat per life lost.
And I, I, of course, completely disagree with that.
I think eat the thing that provides the least amount of mental complexity per,
per pound of meat, which in my case is actually chicken.
I focus on chicken a lot because I consider them dumb fuckers.
You're also a dumb loud fucker.
Yes.
But really quickly, just because it's a joke.
But Scott Alexander said,
you know, you aren't really a religious group until you have your own prohibited animal.
Like the Jews and Muslims got pigs.
The, the Hindus have beef.
And now the rationalist movement has chickens.
So we can call ourselves a religion finally.
I was going to say that, but you wouldn't choose to slaughter an elephant over a bunch of cows.
Because there's other considerations.
One, elephants much more intelligent.
Yes, that's the one.
But that's yours.
Right.
Also, they're endangered, right?
Yeah, yeah.
So they're in danger of being wiped out as a, as their own species.
So that's another consideration, right?
Another moral consideration on that.
Of why you wouldn't go and eat elephant flesh.
Hunters are always fond of bringing up like,
well, we control the population.
Otherwise, you know, the bad things that happen to be like more populated.
I'm like, yeah, that is not why you're out hunting.
You're not doing it out of moral imperative.
No, but it's a good excuse.
But if you're going to kill all the predators,
then you're going to have to keep that prey species down yourself.
If you're going to admit that it's an excuse.
Oh, yeah.
Don't act like you're doing something great.
Gotcha.
That said, you might be, but you're kind of doing it.
It's like positive collateral damage, right?
You're out there killing for fun,
and it happens to have an impact on the environment.
Yeah.
Katrina actually was the one who raised my question as to the,
I hadn't considered, for me, it was all about,
well, chickens are stupider than cows.
I know that.
So I'll eat chickens instead.
So I didn't eat cows.
I didn't eat pork.
I ate chicken.
And Katrina was like, yeah, but think of how many chickens,
I'm thinking of how many chickens you could eat
versus how many cows you could eat in a year.
And I'm like, well, shit.
But it's just like, that's like at least like a hundred to five,
right?
I'm not really, I didn't do the math.
But I could eat five cows in a year.
One to 40?
A lot of cows.
Scott Alexander had a post about it.
Okay.
Yeah.
So I mean, that's a fair way to put it.
That said, I'm fond of the taste of chicken.
So I haven't made the shift fully yet.
But yeah, as long as I'm going to be eating meat,
I should do as little suffering as possible, right?
So when it comes to actual actions, the results matter,
right?
The results specifically matter.
If it comes to actual actions,
what we all should be doing is not eating factory-farmed food
because those places are horror chambers.
Even if like...
We should all be involved in trying to pass litigation
that makes it more difficult for condensed feeding operations.
Yeah, regardless if it's chicken or beef or whatever.
This country worships farmers for some reason.
Yeah.
Yeah, but they like small farmers.
So they're organizations like, I want to say,
it's society for responsible agriculture.
Maybe not.
Maybe that's not what it's called.
But they work with small farmers and communities,
usually small kind of rural communities,
to stop large factory farms from being built in their community
where they're going to be impacted.
And it honors our weird love of farmers.
And local farmers.
And since if we're actually focused on America.
Yeah, right.
And if we're focusing on impact,
a lot of people have managed to put pressure on the really large
buyers of beef, such as McDonald's and other restaurant chains,
to switch to now get more...
Less horribly sourced meat anyway.
And since they buy so much meat,
they have a large impact on how the producers actually produce meat.
Yeah, and Mark Bekoff was the one who worked with Chipotle.
Okay.
Who is a local to Colorado animal philosopher,
let's say.
I think he actually is a philosopher.
Oh, cool.
McDonald's recently made a commitment to make the switch to
cage-free eggs.
Yes.
And I'm not sure, or was it cage-free or was it...
There's another word for it.
And it's an important distinction.
As it turns, there was something about...
Yeah, there's all sorts of small distinctions.
Like, do the chickens have access to any site of the outdoor sky?
Right.
Do...
And it turns out that that gives you a special label,
even if it's a window in the warehouse where they're all still living in stacked cages, right?
And yet it still makes a big difference.
It does.
I mean, any step forward is a good...
I guess, but I wouldn't pat myself on the back for that step, right?
They're still so miserable that they're trying to peck each other to death,
so you have to cull their beaks when they're born, right?
So, whether or not they have a window, I guess that's great,
but looks not like pat ourselves on the back for five years
where we make the next step forward, right?
Interesting story I heard.
When we...
When we summon Azathoth, sometimes we do not do it very well.
Azathoth being a useful shorthand for the process of evolution,
or metaphor for the process of evolution.
Chickens, when they were being selectively bred,
farmers would simply take the ones that produced the most eggs
and breed those over and over,
because you think that's the way to get chickens that make the most eggs, right?
A lot of chickens lived in communities, though,
and what ended up happening was the more aggressive chickens
would peck the other chickens,
and the stress of being attacked constantly
made those other chickens lay less eggs.
So, the most aggressive chickens were the ones that got bred
and eventually got to the point where they had to start ripping their beaks out
to keep them from pecking each other to death.
So, they don't rip their beaks out, but they do cut off.
They cut them off with a hot knife.
Right, well, they don't literally rip them out, I guess.
That's an interesting story.
I didn't hear about that, but that makes a lot of sense.
I'll have to double check my source and post it on the website
just to make sure that I'm not pulling this out of my ass,
but it is a story I've heard, at least.
It is the exact opposite of what happened with those foxes in Russia.
Because they were breeding them for being nice and peaceful.
Right, then they basically get, like, dogs.
Does it not have any important closing remarks, I hope?
I mean, I think we've covered a lot of our points.
Certainly not all of them.
There is an endless amount to say on exploring the inner life of animals,
on different people's approaches to...
This is just kind of a little teaser, I guess,
to how we feel about the topic.
And I'm really happy that our two guests were here today,
even though they didn't have speaking parts.
Dio and Vivek are both...
Oh, now we have to take the vote.
Which one of them lives and which one dies?
That was not part of the contract.
Damn it.
All right, you both guys both get to live.
Obviously Dio lives.
He's the better dog.
And Vivek, Vivek doesn't.
Sorry, little guy.
He's going to die for a god, right?
Oh, he's sleeping.
For Morrowind.
So he gets to live on forever anyway.
Yeah, that's right, little guy.
We love you.
We love both of you.
I didn't finish the tribunal expansion.
Do you end up killing Vivek or just dealing with him?
Anyone who knows Morrowind, feel free to write in.
All right, let's do our listener feedback.
So, a historian actually wrote us about our Atamom statements.
Sasha wrote, regarding episode 13,
you didn't mention another theory behind the dropping of the bombs on Japan.
That is, when Truman came to power,
he knew of the Manhattan Project only in the Vegas terms.
Vice presidents were, in those days, mostly decorative.
They were a spare, needed only if the president was incapacitated or died.
Truman relied on his advisors for information,
and these included Secretary of War, Henry L. Stimpson,
who had just overseen the Manhattan Project,
which had spent two billion US dollars,
about 26 billion dollars in 2016, according to Wikipedia,
on a super secret weapon in order to defeat Adolf Hitler.
Germany had just been defeated by conventional means before the bomb was ready.
Stimpson would presumably have to justify the expenditure to Congress after the war,
is then suggested that he had every motive to encourage Truman to drop the bomb
and justify the project's existence.
Similarly, Leslie Gros delayed the slizzard, that is not how it's pronounced.
Zillard, thanks.
Zillard petition against the bomb,
so that it did not reach Truman until after the bomb was dropped.
Very few historians today still look to monocausal explanations for events like this,
and for good reason.
Personally, I think ending the war quickly was the main factor behind Truman's decision,
but it's a reminder that in real life, most decisions are driven by multiple motives
and often influenced by more than one person,
for all that Truman claimed that the buck stops here.
This, of course, complicates game theory enormously and makes it far more interesting.
Keep up the great podcasts.
Fantastic.
Yeah, thanks, Sasha.
That's pretty huge.
I'm inclined to take your position given that you're the expert on this, so...
I love our listeners.
They really make the podcast a lot better with their input.
And so right.
There are, of course, even when we go about our day-to-day lives,
we generally have multiple motives for what we do, and not one main one.
So you would hope that people who are in positions of deciding to murder
millions of people, that they would also have multiple inputs.
I would hope so.
Or one really, really good reason.
I have a listener input from a name that I can't pronounce,
but fortunately, he says that you can call me Sebastian,
which is my backup name for English Pete Bill.
That was the person whose name we tried to spell out on our first listener feedback episode.
Okay.
But what was like, the Zabla, whatever.
He had a question regarding the game theory episode.
He says he was listening to it, and he didn't quite get the part about the transparent box
with 10,000 and the opaque box with a million.
He tried to rewind and re-listen and still didn't get it.
So like, one of these chews if they're going to open just the opaque box,
which might be empty, or two boxes, and what?
What's the deal after one opens the box or both?
And the answer is that's pretty much it.
That yeah, then the game's over.
Yeah, you get what's in the box or boxes that you opened.
We might not have mentioned when we re-recorded that part of the episode,
that whole thing is called Newcombe's Problem.
And so if you want to look up more into it, it's got a great Wikipedia page and I'm sure 100 others.
The main point is, do you trust the additional information given by the fact that the person
running the experiment is an excellent predictor of character.
And has been many, many, many times before.
And therefore go with a single box to avoid potentially not getting anything at all.
Or do you just open the box that you can see that has the smaller amount of money in it?
Or I guess, no.
Open two boxes and then risk only getting the amount that you can see.
There we go.
Yeah, so basically you either open both and get either $10,000 and nothing,
or $10,000 and a million, or you open only the opaque box and get either nothing or a million.
Depending on what Omega predicted, you were going to do.
Yeah, it's fun.
Look, it's Newcombe's Problem for a longer explanation and all the arguments for both positions to take on it.
Anyway, I think that's it for feedback on this one.
I actually did have one more piece of feedback which was given verbally.
And this goes back to our polyamory episodes again.
Shelly said that she actually had a pretty good steelman reason for why polyamory might not be as good as monogamy.
Being that in polyamory, sometimes you have to keep things from partners which can distance you from them.
And I personally didn't understand that, so I wanted her to give an example.
And she actually gave a great example.
Good, because I'm in exactly your boat so far.
Am I in that example?
No.
Good.
I'm thinking if you have to keep stuff in your partner's, are you doing polyamory, right?
Right.
Let's find out.
So her example was, let's say that you have grown up with your sister who you love very much,
and you guys share everything with each other,
and then you grow up and you get a partner, and then that partner, once your relationship has gotten really close,
tells you something that you cannot tell to your sister for whatever reason.
There is now a little bit more distance between you and your sister than there used to be.
And you still love her very much, but it's not quite the same relationship it was before because of this partner that you have.
And she said, if you can imagine that happening with a sibling, you can imagine that happening with two partners that you may have at the same time.
And I thought that was a really good point and also a little bit sad.
That seems like the cost of just having what Seinfeld would call a vault.
You know, something that you're told that you never tell anybody.
Yeah.
Being good at keeping stuff that's absolutely confidential, confidential.
Right.
So yeah, but I mean, I don't know if that's a problem unique to polyamory.
No, it isn't.
So like she said, but I guess it would increase the number of people that you have to keep things from.
It's not necessarily unique to polyamory, but I think there comes a sort of assumption in monogamous couples that anything you tell one person in the couple,
both of them will know.
There's even that assumption in the law where spouses cannot be made to testify against each other.
It's as privileged as the lawyer-client privilege, if not more so.
It's uh, yeah, it's considered, you know, quite a big deal in society that generally if you tell one person a couple something, they'll both know.
At least that's what I've always assumed.
I never tell something to someone who's in a relationship that I don't want the other partner or partner is in a relationship to know.
I guess I don't have that many secrets, but I'm sure that secret, the whole, if, to people have secrets, I'm sure there's all kinds of rules.
But I think that might be something I've heard where-
I definitely had friends tell me things that I cannot share with my husband, for example, or anyone.
Right.
So to friends, don't tell me something if you don't want, you know, I'm just, I'm bad at secrets in general.
Don't tell me secrets. I don't like them.
If you killed someone, I will tell the cops, unless they really had a comment.
I think it depends on me for the secret. Like, you know, I know stuff that I haven't told my, my partner because why would you think it's interesting?
So like, it's not, like, I don't, I don't do a lot of gossip. So like, if it's like, oh my god, this person told me that they did this and she's like, I don't know what that is.
Why would I care? It's like, you're right. Why would I bother telling you?
So I kind of just imagine that on the drive home and I just get the whole part of the conversation.
But that's, that's a fair point. And I think her point is taken whether or not it applies perfectly to me. So yeah, that's awesome.
Thanks for listening. You can contact us at the, no.
Bayesian Conspiracy Podcast at gmail.com.
No thee.
But if you do go to the Bayesian conspiracy, that's the website. And I will have read the book and potentially have, have more stuff on there and more information and lots of links.
And you can post comments on our website.
You can, you can, or also Reddit. Reddit is better in some ways because you can upvote things.
And talk with other people in, you know, in an easier way to comment.
Yeah.
So consider Reddit.
The Bayesian Conspiracy subreddit. I think it's R, the Bayesian Conspiracy.
Yeah.
So.
All right.
That's, that's all the ways to get in touch with us.
Anyway, thanks for listening and talk to you soon. Bye.
Bye.
Bye.
