charities. We don't need as much money as we make, and we can give, we can comfortably give
chunks of that away to organizations that strictly pump that, turn that money into less pain and
suffering. We should quickly define effective altruism because I'm sure not every listener is
familiar with it. Well, first of all, the, the effective part generally means that you compare
charities and you give money to the one that does the most of it per dollar. Yeah. If you have,
if you have two choices, this is the, the consequentialist, right? Yes. Say the, the, the ends.
Yeah. If you could spend $10,000 to save one life or $10,000 to save three lives, you give to
the charity that can save three lives with the $10,000. Yeah. Or as some of the best charities go,
if you get to give $10,000 to save 35,000 lives, right? I don't think it's that much. How much
does malaria net cost? Well, I believe that the three to five dollars. Yeah. I believe that the
standard currently the, the standard estimate is saving a life cost between one and $2,000.
Okay. I was thinking back to the 1976 essay by Peter Singer, 1975 or six or seven or eight.
We don't, we don't need to, we don't need to worry about lives though. We're worried about
pain and suffering. Oh sure. So, so if we're deworming children, that's like 35 cents a pop.
If we are talking about mosquito nets, that's three to five dollars per mosquito net and that can
reduce a huge amount of pain and suffering plus it then allows more stable households
when your parents aren't dying of malaria or your siblings aren't dying of malnutrition.
They can go to school. They can make more money. They can, they can then increase the overall
happiness of themselves and their loved ones and all the people in their area for 35 cents a pop.
Right. And the, yes, I was thinking it was called famine, affluence, and morality. I couldn't get
the title of his, one of his newer books called the life you can save out of my head and I knew
that wasn't it. So we can link to famine, affluence and our morality on the website if you want to.
It talked me into becoming a charitable person when I was 18. I read it the same week I read
Animal Liberia or all lives are equal. Or was that it? All animals are equal. And that week I
became a vegetarian for like five years. So it was, I found it very persuasive. Not everyone
responds to argument the same way when it comes to these sorts of things, but I think effect
vultureism is first of all a much happier topic for the second half of the episode. And second of
all, it's one of those things that is so, I think, obviously clear for anybody who agrees that charity
at all is an okay thing or is a desirable thing. But there's still a lot of kickback to it, which is
weird. People get, I think indignant. I remember seeing someone complaining that the effect of
vultureism was taking money away from arts like opera and sculpture in the cities.
And I would come right back to that person and say, yeah, it's giving it right into the lives
people who need life saving. I think the more interesting part of the family, all that is
interesting too, but I think perhaps the most interesting thing about effect of vultureism
is the earning to give mentality, where it is considered a very high value, a very ethically
good thing for a person to do to get the job that pays them the most that they can possibly
swing with their skills, and then donate a large portion of that directly as money to
effective charities. As long as your job does not make the world worse, make the world a lot worse,
which is can be difficult when pain and suffering pays, right? Like as a salesman, I want to find
products that don't cause more suffering than offsets, or offset by the income I'm going to
make by selling those things. Yeah, I don't remember which way the equation came down,
but I do remember someone looked into whether becoming the CEO of a tobacco company and donating
99% of your earnings was a net positive or not. That sounds like a fun, see that's what I like
jumping to hyperbole, but this is this is this is real life hyperbole. That's awesome. Oh man,
I want to I could like smoke like cigarettes from malaria wouldn't that be wouldn't that just be a
great campaign? Oh man, if every time you light up you're saving a child's life. The three dollars
from every pack you buy goes to save this kid and put a picture of some oh my gosh. Or Marlboro
wants to come up with a new advertising campaign. I think I think they just they just found it. Oh,
we could how about this we could cut we could cut the the tobacco we could cut syntaxes and we could
take uh we could we could keep the same tax in there but just have that go to oh isn't that what
syntax does anyway it's only what syntax does it's just not it's just not very not very effective
yes they do not target the money usually very well yeah that still sounds awesome but I think so
some of the kickback so I guess there is yes someone complains about arts and opera or something
which seems maybe about a little more defensible than some of the other kickback you get from people
so the effect of altruist if you're straw manning the person could be like oh so you're saying the
fact that I give money to my local animal shelter isn't enough and so the effect of altruist would
be like kind of so I think some people find it indignant to challenge them and say you sorry
your your impulse to charity just isn't good enough it's not well calibrated do charity better
and people find that insulting so I don't I think it's fine I would rather be pointed out like if
I was giving all my money to name a popular city charity I can actually look like you might lose
some sponsors here I can name a charity actually I cannot say the name of the charity because I
don't know the name but I there's a charity that every year comes to my work and takes volunteers
and my my you know my workplace will pay people just their regular wages to go and work at this
charity for one day a year if they want to what they do is they take two blankets and they cut
fringes along the edges and then they tie them together that's the charity yeah that that is
that is that feels like an anti-charity to me it is taking productive hours that those people
could have used at a charity that actually does some good to tie two blanks that what what do you
get out of two blanks tied together that you wouldn't have just from layering one blanket on top of
another blanket how about how about like the catholic church I mean it looks pretty weird can we go
to I mean tithing right right that's how I started that's how I started giving was I said okay well
let me let me see what's doable let me let me do 10% right and so that's because that's a tithe yeah
so if you're tithing to the catholic church where is that money what is it going to how much pain
and suffering is it reducing I mean that's probably that's probably one of the biggest one of the
one of the worst charities that you give to if you want if you want to come up with something a
little less agreeable you could say things that go to fight climate change right so dollar per
dollar money that goes to maybe research but try to stop climate change is being spent very poorly
partially because we don't have a partially because we don't have a we don't have a cost effective
way to fix it and that's the other thing right like do you pour all your money into into one big
thing that could possibly reduce pain and suffering on a large scale or put it into a guaranteed
nets and water and food and education I think the general idea of the effective altruism movement
is that we we pour our money into the things that we know we can fix that are guaranteed
some things that reduce suffering yeah there's it's an interesting taste because it feels like
it feels like you're at least being consistent that something like donating to the arts or opera
is something that would increase happiness but you're more concerned about reducing suffering so
at least you get props for being consistent well it's interesting so like the the stop climate
change dollar per dollar ineffectiveness is is one example but as far as long as we're I think the
for me there's something else to sort of undecided on so I tend to split my charity budget between
like the machine intelligence research institute which stands a non-zero chance of more or less
creating utopia in the next century right and something like give well or the against malaria
foundation where I'm saving literal lives and reducing suffering I guess not today but however
long takes that money to get out there so on one hand it's it's it's a payoff between a bet of
some probability that this is going to make everything awesome forever versus I'm at least
doing some some solid concrete work today I also want to maybe point out that I think Miri's
goal isn't necessarily to usher in utopia but to prevent unfriendly air from destroying everything
fair enough I think I think related to that is creating friendly AI right that could make things
better yes I've got a hypothetical for you Stephen let's say that there's a machine that can that
will create utopia right it's going to is this is this for people or is this for is this more of a
on a transhumanist kind of thing yes yes to both yes yes to both do you would not consider
transhumanist people I mean by definition when they not be well they wouldn't be human no they
wouldn't be human but I don't know the definition of people is I think I think of people is
depending on which moral philosophy you ask it's a being that's inside your moral sphere of concern
so to a lot of people so I think they have to break down special terms for like so for me
I feel well scratch that because that's actually definition but it is one that's out there a better
definition is a being that's able to think for itself and not want to die and has some level
of introspection so by that by that measure there are a lot of non-human human animals on earth that
fit that definition like chimps and dolphins dolphins thank you and elephants it's a fun
semantic term what is expanding the word people it's to find people well I mean so like yeah we
could be to hear oh my hypothetical my hypothetical um is this machine creates utopia maybe it's uh
maybe it's I mean just taking out the potential parts that make us unhappy early whatever however
you want to um it puts a chip in us that just feed this constant dope you know whatever whatever
your idea of utopia is sounds a little different but sounds like a horrible place to me but you
have to feed it everything on earth then who's it who's the utopia for it's for the things that
live after that but if you feed everything on earth how's the hard things like I guess I don't
understand the what if it's what if it's to force a what if you have a chip what if you have a
forced chip that you can put into people that will guarantee that they will no longer experience any
kind of pain or suffering I think that would be a terrible thing I think that some level of pain
and suffering is important that if all you were ever I mean are we are we seriously saying that at
the point of just being blissed out on heroin kind of happiness yeah so see I think I think that
would be that would be like hell I think that for there to be a meaning in my life there has to be
a possibility of of being disappointed and I'll put it this way if everything you do has the exact
same uh has the exact same outcome then there's no point in doing anything at all and I'll put
this way for an intuition pump uh at the risk of sounding like an evil apologist
like I don't want to be as happy if my loved one if if my loved one lives or dies right it's like
if I'm going to be the same whether or not they continue to exist in what sense do they even matter
to me it's like the fact that I would be sad at their loss makes that that is that's an integral
part of them having meaning in my life yeah I don't think there has to necessarily be suffering
but there has to be the potential for suffering at least yeah imagine them dying or so I guess I
don't know but like it would just be weird to think that you know a sibling or a spouse or
something dies and the definition of what I you know if someone's saying I would want to feel
just as happy three seconds later like their death I don't want it to impact me whatsoever
it's like what do you what does that even mean to like say that you care about them
what why why why why wouldn't that be like why wouldn't why wouldn't grieving be why wouldn't
getting rid of grieving be be awesome I think I'm not necessarily not getting rid of grieving but
like you know said having the potential I guess it would just be weird to be completely indifferent
to their life or death what's something different you you greatly enjoy their existence you you love
them you care for them but then when they die they just they're they're gone and you don't
feel pain and suffering I think this was tying more into like the the binary so you used the word
whacked out on heroin I think I think the word that we can we can link to with the definition
is orgasmium I think that's quite what you were getting at where some people would argue that
there's not a global obligation to move humanity into orgasmium into an orgasmium state which is
basically just this big basically I don't know if I haven't talked to a heroin user who's as
stoked about heroin as you seem to think some of them are well at the point you've actually
injected it yeah well sure wouldn't wouldn't it isn't this the opposite of so if we're going to if
we're going to value happiness over pain and suffering doesn't isn't this to where we get
don't we don't we is that why you is that why you abandoned happiness entirely and only focused
on suffering because you because of the orgasmium no I think you're there to avoid that the orgasmium
is win-win we know okay there's no pain and suffering and I went in that situation too okay so
but I'd rather do that because remember the the utils are split into two columns it's right happiness
and pain and suffering yeah so I've gotten rid of the suffering column and I've I've boosted the
happiness column to as high as I'll ever get so yeah the super happy world basically yeah now I'm
trying to decide if you know grasmium world would be better or worse than no world at all I guess
better but it's hard I mean because I think it would be indistinguishable from a world with no
value at all so so if I if I um there's two buttons I'm about to implant the orgasmium in every
everyone and everything I would again be ethically obligated to kill you what if you push it what if
the only option you had was to blow up everything at that point I'd be neutral the two worlds are
equally awful everyone experiencing constant bliss is worse than nothing at all uh it's no it's not
worse it's equal to because there is no there is no growth there is no change there is nothing of value
in a world where all you do is feel happy all the time I don't think that the feeling of happiness
is a good in its own right I think if I put the orgasmium into your brain you would you wouldn't
believe that anymore but I wouldn't want to self-modify somebody who would feel that way right
yeah I don't think that pain and suffering is good I mean obviously it's bad but I think that
having nothing but happiness is all so bad or nothing but ultimate happiness all the time right
so like if if everyone's scale was moved so like I don't know just arbitrarily let's say on a scale
from one to ten five and under is suffering and and six and up is is happy if we could move everyone
to have their base level be six and they can still move between six and ten that sounds like
there's some value still there right six and ten is good yeah so but I'm saying is that they could
they could be happy all the time but there's at least predation where some things make them happier
than others they're more happy doing something that they like than something that they hate
so I guess I was just I was coupling with saying making people happy all the time versus making
everyone blissed out all the time so what would the what would say if you're a six what's your goal
what do you what do you want as an individual you want to be made more happy so you want to get
up to a ten yeah and if you're at a ten what's your goal your goal is to stay out of ten okay
I but then if you just put people at ten all the time you take away their ability to achieve any
goals why do you need to achieve goals you've already achieved your goal I I disagree I think
working towards goals and achieving goals is actually an important part of being a human
and if you were just to give someone that happiness all the time that that diminishes
the meaning of what it is to do things and to matter in a universe would you be less happy
I think I well see now this comes down to how we're defining happiness if we're defining happiness
as the chemicals in my brain making me feel happy feelings then obviously no but uh me right now
would say yes I would feel I would find very little value in that I think okay so I'm gonna get
briefly onto what I have heard as the definition of happiness which I I find to be the best definition
at least in my personal opinion so basically we are all we are all executors of adaptations that we
have evolved over time that these adaptations help us to survive and help us have grandchildren
and well what uh what I've heard is that the when you do something which in your ancestral
environment consistently led to greater reproductive success in the terms of having grandchildren
those actions would bring about a feeling that nowadays we call happiness and nowadays this
doesn't necessarily map onto things that actually bring reproductive success like we can be happy
when we gain fame and status because that means more resources for us and our children
even though when we have sex we're you know sterilized or using birth control or something
so that we don't have them we still feel that happiness even though it doesn't increase our
reproductive success but things that in the ancestral environment led to reproductive success
are what triggers that feeling of happiness are all of those actions uh or their modern day
equivalent still good or worth pursuing because I imagine like winning a war yeah definitely oh
I've heard it's still a rush nowadays yeah but that's not something that necessarily is worth
keeping around just for that no not necessarily I'm just saying this is this is the only definition
of happiness I've found that actually made sense to me okay like when I was trying to figure out
what the hell happiness even is things that lead through reproductive success was the best
definition I could find or that lead to that lead to um ancestrally led reproductive success
yes the which and you anticipate leading to the reproductive success so there comes a point where
once you have accrued this is where the treadmill comes from once you have accrued a certain level
