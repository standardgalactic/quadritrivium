but I remember that quote third hand.
So that's why the rapids thing was also timely because this was in the era of new atheism
books and all that stuff.
So.
Yeah.
So yeah, he points out that X-Men comics, these terms like evolution, mutation and genetic
code purely to place themselves in what they conceive to be the literary genre of science,
which is something we mentioned last episode too.
And Eliezer says, the part that scares me is wondering how many people, especially in
the media, understand science only as a literary genre.
Yeah.
He says that probably an actual majority of the people who believe in evolution use the
phrase because of evolution, because they want to be a part of the scientific in-crowd
belief as a tire, like wearing a lab coat.
Exactly.
And this is whenever I see those like, I fucking love science Facebook groups or whatever
this is exactly what I think of.
Yeah.
And I remember conversations with people like in college and high school who would say things
like this and they would argue, you know, basically the same people that were like in
the era that I was in, like just coming out of like how much fun it is to argue with religious
people and they would, you know, throw evolution talking points out, but they, they didn't understand
what they were arguing in defense of.
And it doesn't make them, they happened to be right, but they were, they were really
just arguing for their side and they weren't arguing, they were, I mean, they were arguing
for the truth.
It's, it's hard to, like, what do you call it if somebody is, doesn't really know what
they're talking about, but is arguing for the right thing and using the right words.
It's false knowledge.
Yeah.
Yeah.
Lucky is another great word for it.
I saw the best troll in the world recently.
I think it was, I posted on our discord, someone says, whenever he talks, whenever he has
meetings with philosophers over zoom, he uses a fake background.
That's a picture of his current background so that the philosophers will have true justified
beliefs that happen to be false or that happen to be not real information or anything based
on information that isn't real.
Yeah.
Cause yeah, only, only a philosopher would care and that's just perfect trolling.
The epistemic status of that person's background is, is, is shakily founded.
Yeah.
Yeah.
So anyways, um, yes, the, the belief is a tire thing.
I, this is more of like a setup for other things, but it's, it's an important point
that a lot of people, I don't know, just care about looking like they're in the right group
rather than really knowing stuff.
Yeah.
And I mean, as a, from a purely consequentialist point of view, it's like, great, as long
as you're doing the right thing, you know, like, as long, as long as part of your, your
belief as a tire means voting for the right things or, uh, I don't know, advocating
the correct policies.
I disagree entirely.
Cause then they're like, like we just said, they're lucky, right?
Like I, I also fucking love science and I really hope that the people who fucking love
science really do fucking love science so that, um, they can incorporate actual evidence
and changing, you know, changing knowledge into their worldviews.
But I get the feeling the vast majority of them happen to fucking love science because
it supports their current view.
And if the science were to shift, they would be like, Oh, well fuck those scientists.
They're all making me angry and shit and, um, and just not followed those things anymore.
And I would much rather someone have an actual true belief desire for true beliefs and, um,
let them take that, then like, let them,
I said, you're saying I would rather have that too.
But if I don't get that, then at least have them rather, I'd rather have, uh, I'd rather
have soldiers on my side, even if they don't know why that's the right side to be on.
Right.
Now, now don't get me wrong.
That's, that's a bad way to look at the world that I wish the world wasn't that way.
But, uh, in this torture analogy, since our votes are soldiers, uh, or since our votes
are bullets, other than be shooting the right way, like I would love for them to, for my,
for my people to know what they're doing and why and, and have the right motivations and
the more the merrier.
But if it's not going to everybody and like some of them are going to just do it just
to impress their, their friends or something like, great, cool, I'll take what I can get.
No, I would rather have people voting against me, but who at least think that they're voting
for the right reasons and actually be concerned about the truth because those are people that
I am confident, uh, would switch over to the right side.
If you could show them the truth, like with evidence and with, um, argumentation.
And like that is something that reality doesn't, um, budge on.
If there is a correct side, it is there to be found.
And eventually either I'll go to their side or they'll come to my side, but the side will
be right.
Whereas the people who happen to be right and are recruiting signs for their side as,
as soldiers, that's great.
But if it turns out that they're wrong, you know, you, you aren't going to convince them.
They, they will not stick to the truth.
They just want you to vote their way.
Like, I think if you're not going with something empirical, like, um, you know, provable positions
to decide how you vote, what are you deciding by?
Are you deciding how to vote because of who your in group is or who has, you know, the
sexiest celebrity endorsements or who has the greatest force of guns on their side?
Because those are all things that I don't want to be the focal point of the battlefield.
I don't want to fight over who has the sexiest celebrities or who has the most guns or who
can most marshal, you know, hatred or passion on their side.
I want the fight to be over who can prove the truth of the matter.
I do too.
Don't get me wrong.
I'm just saying I'll take what I can get right now.
In an ideal world, that sounds perfect, but it's, it's kind of like, I mean,
It's short term thinking.
Uh, I'm, I am for term thinking right now.
Okay.
Yeah.
This, I, stretching again, the analogy more, we're at war now with who, uh, the, the,
the wrong, uh, the, the people advocating for wrong ideas.
Will we still be at war in 50 years?
I sure hope not.
But like right now we need, we need, we need feet on the battlefield.
See, I think we've been at war for at least a hundred years, maybe longer.
And so I'd much rather have, uh, the weapons on our side that will have the correct side
winning 50 years from now, as opposed to just winning right now in the short term and assuming
this will not come up again.
Well, we'll, we'll, we'll keep indoctrinating them while they, while they keep fighting.
All right.
That's not that that's where we're getting away from the post.
We are.
Sorry.
No, no, you're good.
It's a good.
It's a good.
It's a good.
It's a good.
Mind killed again.
No, no, it's fine.
Um, as your goes on to say, I encounter people who are quite often willing to entertain the
notion of dumber than human artificial intelligence or even mildly smarter than human artificial
intelligence.
Introduce the notion of strongly superhuman artificial intelligence and will suddenly
decide it's pseudoscience.
And it's not that they think that they have a theory of intelligence, which lets them
put a calculated theoretical upper bound on the power of optimization process of an optimization
process.
Rather, they strongly associate superhuman AI to the literary genre of apocalyptic literature,
where an AI running a small corporation associates the literary genre of wired magazine.
Um, which is now you see the flaw inherent in your system, right?
If you have people associating with, uh, what they believe to be, you know, science and
lab coats and the attire of science, then if someone makes the argument, Hey, uh, this
AI thing, I, we don't know what the upper limit of an optimization process is, but we think
it might be much smarter than humans.
And now suddenly they're not on your side because they're like, Oh, that's, that's just
apocalyptic fiction.
That's not real science.
So I don't fucking love apocalyptic fiction.
Yes.
And I, I, I, I fully own the flaw of my thinking.
Like I said, it's, this isn't like what I advocate.
This is where I think we are now.
Like if Bill Gates wanted to give a billion dollars towards safe AI research and he wanted
to do it to signal to all of his friends how smart he, like how smart he was, or because
like, Hey, look, I'm very forward thinking or something.
I don't, you know, I don't care why he's doing it.
I care that, Hey, good things are happening.
Like right now he's, he's on the track to cure, like to solve the malaria problem on
earth, right?
If, if he does that, I don't care if he's doing it just to, you know, for the social
esteem, you know, I don't, I don't care if he's doing it because he lost a bet.
Like if he does it, awesome.
But do you think that's why he's doing it?
I think he's doing it because he cares.
Right.
Yeah.
He actually is convinced by both compassion and the science.
Right.
Which is why it's fortunate that we have people who are actually convinced by science.
Whereas if all he wanted to do was look good to his followers, he would fund like more
pre K education or something.
Have you ever met like an aesthetic vegetarian?
What is an aesthetic?
Like someone who doesn't eat meat because it's icky.
Oh, like just the idea of like, oh, just ripping into an animal with my teeth just
feels gross.
I think so.
So like, I feel like a vegetarian is on the right side of, of the moral fence on
where, on what to eat.
And if they're, if they're, if they're not eating meat for what to me don't sound
like good reasons, like I don't really care.
I think you're doing the right thing.
Granted, I eat meat.
I'm a hypocrite.
Um, I was vegetarian for years and fell off the wagon and never found it again.
So if the aesthetic vegetarian at some point got over their grossness of meat
and was like, Oh, this is pretty good.
And started eating meat.
How would you feel about that?
I would, we lost a troop.
Really?
I mean, what else would I feel?
Well, because you eat meat.
Right.
I'm, I'm not, I'm a hypocrite that much.
Right.
I suck.
I'm not saying you suck.
I'm just saying you don't care that much.
I, I don't.
Um, but I kind of hear more about the extinction of the human species, I assume.
Yeah.
Okay.
So the, I'm also, I act, I act just as much in favor of that.
