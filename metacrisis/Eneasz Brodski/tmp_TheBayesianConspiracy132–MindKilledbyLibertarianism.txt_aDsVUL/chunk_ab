Does this sound like crazy bullshit?
Not using those exact words.
For things that mostly sound like crazy bullshit, they don't replicate.
Or even just people are like, Oh, yeah, that kind of makes sense.
Those often will even just ask yourself, you know, just this trick, my bullshit, oh, meter.
Now that said, like it's possible to be surprised by results, right?
If you had asked me two years ago, hey, if there's a flu like plague going around in
2020, you think vitamin D will have a surprising effect on the, the impact that it has on a
body?
I'd be like, no, fuck you, you snake oil salesman.
And then lo and behold, it appears to, right?
And the other thing about this too is like, I think it's worth keeping in mind that like,
like I don't blame Eliezer for getting this wrong because it was the established state
of science and his goal wasn't to like become an expert.
Yeah.
It wasn't his research.
Right.
He's citing other research that seemed to have been peer reviewed and yeah.
And I think that, you know, even if you're trying to be as right as possible, like a,
it is still a reliable heuristic to say, let's trust the expert consensus.
And like, I'm doing that with the vitamin D thing.
I didn't review anything personally and I'm not equipped to it would take me a long time
to get good enough.
And how am I going, even if I were to review some of the, the studies that were done, how
do I know that they weren't fraudulent?
Am I going to talk to my own before I believe anything?
Fuck that.
Who has the time?
I think we've been talking a lot because we're in the same room and we can see each other
to West, David.
Did you guys have things to jump in on at here?
So the vitamin D thing is pretty hotly contested.
Somebody's offering like a $100,000 bet that vitamin D cures COVID.
And Scott Alexander is definitely on the other side.
He said, and he was offering to take that bet with slightly lower terms.
100 K was a bit too rich for him.
Cures COVID isn't the claim I heard.
I heard that it impacted the severity of the case.
Yeah.
There's a lot of evidence that people who have bad cases of COVID are vitamin D deficient.
There's not a lot of evidence that it's that deficiency that's causing the severity, but
it does kind of hint at that.
And they, they haven't really had time to write, to run you really good studies on,
on what the causal mechanism is.
Yeah.
Wait, didn't they run a study that were like 100% of the people that they gave vitamin
D had no to mild cases?
I, I don't remember.
I distinctly remember, uh, uh, Sve Moskowitz blog post that said, either this is a real
effect, it's fraud or it's an incredibly good luck and no one has luck that incredible.
Or I guess incredibly bad luck if it's really is a false positive.
Yeah.
Just a bad study.
But then the takeaway to take from this post is that we should wait for that to replicate
once or twice.
But of course, like the other thing with this particular example is that a bottle of 300
vitamin D pills is $8.
Yeah.
And it's not going to hurt you.
Right.
I was already taking it every day for the last few years anyway.
And so when I heard this, this was, geez, sometime over the summer, maybe.
Yeah.
Probably like six months ago.
I bought $80 worth of vitamin D pills and gave them to everybody in my family to take
these please.
I, I gave them out as a stocking stuffers for Christmas.
Nice.
Yeah.
I mean, if they were, maybe it was over Christmas, whatever it was, it was sometime, you know,
the whole year blended together.
But you know, if vitamin D pills cost a buck each, I would have been more inclined to do
more homework or, you know, at least wait for better data or something.
But given how cheap it was, this didn't strike me as like a, you know, if I was being huckstered
by snake oil, well, there's probably some marginal benefits taking vitamin D anyway.
It didn't cost me that much money.
So I, so talking about the replication crisis, I get, I get really mad that that's what people
call it because it's, I call it the bullshit crisis because it is, the thing we're referencing
is we've discovered that a lot of the entire, like the psychology community and psychological
studies are bullshit.
They did them badly with bad information hygiene, poorly designed studies and didn't use methods
that we've known for decades or, or what you should be doing.
Yeah.
And so like, I feel like a couple of episodes, you talked about the, I think you talked about
the post where, where it's basically just to hell, you guys are bitching about how rationalization
is a really bad term because rationalization is the opposite of rational.
Yeah.
So I feel kind of the same way about the replication crisis.
The replications aren't the problem.
Yeah.
Yes.
But it's not, it's not that the failure to replicate isn't the problem.
The problem is the study was bad.
Yeah.
Well, I mean, it's much harder to cite the bullshit crisis in a serious scientific article.
I suppose so.
And I think most people who are talking about it know what it means.
Like, I don't think anybody thinks that replication is the problem.
Yeah.
I mean, that's also true of rationalization though.
Yeah.
I love the fact that he said it's like calling lying, truth-illization.
Truth-illization.
Well, they did call it truthiness.
Yes.
Yes.
Stephen Colbert specifically.
Save the elephant population.
All right.
So I don't have much else to offer on this one other than I think that it's a valuable,
like the, the hysterist, I like the fact that it's left up.
Maybe if they, I haven't read it in the rationality AI to zombies, maybe there's disclaimer at
the top or bottom that says, by the way, this didn't replicate.
If there's not, I would, I would support that, but I do like video of leaving it in because
it's like, hey, look, you can be well informed and wrong.
And that's a perfectly legit place to be.
So.
Yeah.
Likewise.
I appreciate people putting their like confidence intervals at the top of essays and the thing
Scott Alexander does where he has like posted his retractions just on, I think he still
has that on the new site.
I don't know, but there was just a menu link that was like a list of all the things I fucked
up on.
It would be nice if these posts had like a header or something that said, by the way,
this failed to replicate.
Yeah.
Nice.
Yeah.
Brian Dunning of Sculptoid does that every several months, you know, corrections or errors
or whatever it was.
Well, especially because, you know, entry into the rationalist community, people are like,
go read the sequences.
So like this is a 2007 article, but people are definitely still reading it.
I think Eliezer himself is busy doing myri stuff, but you could probably delegate somebody
to do that.
Maybe we should email him.
We can email the folks we talked to who like run less wrong and you know, email Rob Bensinger.
Didn't he have a big, big role in doing the AI to zombies?
Yes, but I don't know.
I haven't read it yet.
AI to zombies, I assume it's fixed or noted at least in AI to zombies.
Maybe.
I have it.
I don't remember it.
Okay.
I listened to the audiobook version of AI to zombies and they didn't say anything about,
by the way, there was no disclaimer in the audio version anyway.
Did they?
I don't remember that either.
Did they include this post?
Yeah.
Oh, they did.
Okay.
I don't remember that and I'm pretty sure I would have if they didn't included it.
So yeah, they probably didn't.
Yeah.
I listened to it this morning.
So per what Jason just said he likes, I'd say like 70% confidence on that.
Okay.
I do want to at least mention that there's still a note of good in here in useful information,
I guess, in here in that our brains do run in networks and activating one concept will
at least somewhat tangentially activate concepts that are strongly linked to that one, which
is, as pointed out in a Scott Alexander on politics recently, a common thing used in politics
where you just associate bad things with the other side and good things with your side.
And even if they don't have anything to do with each other, eventually in the listeners,
an association starts to form between good and our side and bad on their side.
And I think that's most of what you see on Twitter nowadays.
I think that, I mean, a lot of these, this is the sort of thing that, you know, I couldn't
cite a well done peer reviewed study on this, but it sounds like that makes perfect sense
to me and I'm prepared to endorse that.
Well, I mean, I mean, it happened just in the recent Scott Alexander article where he's
like Scott Alexander said a good thing about something Charles Murray said and Charles
Murray wrote the bell curve and the bell curve can be interpreted to be racist.
Therefore, Scott Alexander is racist.
And they didn't say that last line because that would be a lie.
But you know, they let all those associations just go together there in people's heads.
Sure.
Yeah.
And narrative.
You know that nobody who is evil ever says anything right or good.
Yes.
So.
Yeah.
I mean, and maybe just in the, in the effect of reading that sentence about Scott Alexander,
they believe it just in the, just in the process of understanding the sentence.
Are you trying to segue?
I mean, that, that does tie us into do we believe everything we're told, but I don't
know if I'm jumping the gun.
Yeah.
Well, I just, I'm trying to find out whether priming as a concept was replication crisis.
And I think it is just social priming or behavioral priming, having a hard time just
finding a clear answer on Google though.
I know that the, the behavioral priming definitely failed to replicate.
I was the one who were like putting hot things in people's hands or making them think about
old people and they walk slower.
Those ended up being just complete crap.
That, I mean, that, that doesn't surprise me.
You know, like it's, I mean, if you can make people happier just by giving them hand warmers.
I mean, you know, I might be happier if I'm cold and someone gives me a hand for warmers.
