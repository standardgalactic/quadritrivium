And then try and spot the false.
Yeah, I do the same thing.
So it's quite good for first dates, by the way.
Cool.
Life hack.
If you like your first dates, like you like meeting your office co-workers.
Anyway, yeah.
So basically, this is another one of those that seems to fail to replicate.
So there's not much to really address in the article.
I want to point out that Gilbert Taffer-Rodie and Malone's paper was entitled,
You Can't Not Believe Everything You Read.
OK, that's a good name.
Which also, as the title of the paper, which you are reading is also funny.
The post does end with the suggests that we should be more careful when we expose
ourselves to unreliable information, especially when we're doing something else
at the time, because part of the experiment was distracting people
while they were told false things.
I get this.
I just wanted to talk about this really briefly, because this seems to be a thing
that comes up a lot, that the more you're exposed to something,
the more you become willing to accept it.
And like this just seems to happen in the real world.
Even when we're not talking about this, you know, you automatically believe
things when you're initially told them.
Even if you disbelieve things at first, it seems like the more
you something is repeated to you, the more you believe it, which is why things
like the QAnon conspiracy can ensnare people, right?
Right.
Do you think that, yeah, there's definitely a tendency for I think that's
is that confirmation bias?
Availability heuristic is not a good example.
Like when I social proof or something.
Yeah.
I mean, there's like that's associated with a bunch of other
heuristics and biases, right?
So I mean, and here's a an adjacent example.
You know, like when you look at the or Jace to it, you might actually know
if you if you're looking at the moon rise and it looks really big on the horizon.
Do you know why that is?
Yeah, because it's close to other things that you can use for comparison.
Uh, I don't.
OK, so I read it at one point and I forgot.
Well, so I think I think you know, I was just right.
The but the the commonly accepted wisdom is that it's like a magnification
from the atmosphere, from hitting more atmosphere.
Oh, well, as it turns out, that's just not the case.
But but people, this was like a thing that I remember learning about like 10 years ago.
And I learned about the magnification thing five years before that.
And 10 years later, there are five years later, they're saying, yeah, you know,
we we correct people's belief on this.
And yet in the act of informing them about like, hey, here's this thing
and here's like the way that it's not true.
Here's the actual fact.
If you ask people, sometimes they'll just remember like the thing
that you told them first after the fact, even though it wasn't true.
And so like that might just be an availability thing and attention thing or something, right?
Yeah, I think there's a lot of other explanations like authority.
Man, I've heard you can test the moon thing.
Just put your thumb out exactly and see how much of it it covers.
And no matter where in the sky it is, it'll always cover the same amount.
And I'll be honest, when I first did that to test it, it blew my fucking mind.
Oh, really?
Because it looks huge when it's first coming up over the horizon.
And you're like, OK, it's about the size of my thumbnail.
And then you give it a few hours.
You're like, no way, no way.
Yeah, we're in a simulation.
We're empiricists.
We're empiricists.
That's that's the other virtue here.
Anyway, yes.
So you linked to a thing that found the opposite effect of
people who believed things like in the act of comprehending them.
Can you summarize that link?
Oh, basically, just that it was it was it found the exact opposite of what was linked
in this post that people tended to be more like the cart, at least the people
in their sample tend to be much more like the cart sample thinking
than the than the spinos thinking.
That's why I said, you know, it's certainly not something that seems to have been confirmed.
Um, so the thing I wanted to say, though, is like it seems a lot of time,
especially nowadays, people think that there are ideas which are dangerous
because if people hear them, they will be like mind whammyed into believing them.
And therefore we need to silence and suppress them.
Yeah.
And like, I kind of have a problem with that because it feels like it treats humans
as these very easily hackable, like we must protect people from this information.
Otherwise, their brains will be taken over.
And I just don't think brains are quite that hackable by humans.
Well, that's the whole thing with fake news, though.
I'm really glad that they started cracking down on fake news because there are a lot
of people who think that, oh, I saw it on the news means it's true.
Some people are, I mean, I think was it, I think Eleazar put it a nice way that,
like, you know, the human brain is not unhackable.
He put it more eloquently than that.
But he was arguing with or he is arguing with Neil deGrasse Tyson via Sam Harris
on Sam Harris's podcast because he was like, well, Tyson says that
if the if the AI in a box is acting up, he'll just shoot it with a shotgun.
And he's like, OK, yeah, sure.
But you are not like immune from outside influence.
Yeah. But he put it in a fun, you know, rationalist Yutkowski in way.
I can totally see that.
But like also when people start telling me, hey, how you shouldn't read
Scott Alexander's posts because he will, you know, trick you into being
an evil right wing person or something.
I'm like, I think I can read things and for my own opinions.
Yeah, I've heard of the the phenomenon you're talking about in two different
main guises, one of which is back in the New Atheist days.
Like some there were some argument like from the I guess you call them
like the moderate atheists where it's like, well, yes, of course, you and I,
we can survive without religion because we're we're sophisticated folk
and we can accept reality as it is.
But those poor masses out there, they can't handle it.
And I find that like demeaning and childish or treating people like children.
I mean, definitely it's possible that man, if you think that's demeaning
and treating people like children, you're going to love when we talk
about epistocracy later.
The other main content is what I've heard called the alt-right pipeline.
Whereas like if you listen to Neil deGrasse Tyson on The Joe Rogan Experience,
well, then YouTube will recommend another Joe Rogan Experience podcast to you.
And because he he's had right, that's also something we're going to talk about later.
So maybe we should just move on to the main point of the show.
Very well.
I'll just say that that's the other context that I've heard of this,
this weird infantilization of people in and that I don't approve of that.
If you, I mean, this is probably isn't advice anyone can really follow.
But it's like, if you think you're you're gullible and vulnerable to dangerous ideas,
make a safe, make a safety bubble.
But like no one would acknowledge that about themselves, right?
No one's going to say, you know what?
I think I might be susceptible to the next bullshit thing.
Someone tells me I need to form a safety bubble.
It sounds like I do the opposite because I think brains are pretty hackable.
Yeah, I think I think if you hear something repeated,
there are, I think the best book I've read on this is Influence and Science
and Practice by Robert Chaldini, which is pretty old book.
But it talks about a lot of ways that human brains can be hacked
and how advertisers exploit these to make money, which is how you know they're true.
But so, you know, I try to make an, I do the opposite of setting up an
information bubble.
I try to get information from a lot of different bias sources.
So that, you know, if you have, because if you have people telling you
conflicting things, then you're not just going to sleep on it and just
believe everything you're told because you can't.
I make it a point to every month, at least once or twice a month,
watch the conservative twins, some video of theirs on YouTube, because they're,
you know, really charismatic and seem to be representing the people who are,
who are Trumpers, who think that Trump has a really good point and represents them.
And I don't know, like I.
Sorry, since we, since that Scott Alexander post came out and the rationalists
are officially now concerned about class, the technical terminology we should
use is Trump and proletariat.
Absolutely.
Yeah.
What is that?
Trump and proletariat.
Yeah.
Trump and proletariat.
Yes.
Yeah.
Lump in proletariat with an L is Marxist term for proletariat who aren't communists.
And so yeah.
Yeah.
I try to listen to them once or twice a month and every now and then
I'm like, Oh, these guys have good points.
But then I'm like, Oh my God, they're just went off the crazy train.
And I also try to watch at least one woke video of Mount and I'd also always
really irritates me, but it's good to keep the two things, you know, in consideration.
Yeah.
And I think that's important not because they're, they have necessarily
have good perspectives, so they're giving you information you wouldn't otherwise get.
I think it's just important to hear opposing viewpoints so you remember that
they exist because if you don't, then that I think your brain will get hacked.
I think if you only ever hear one perspective on something, you'll just
kind of accept it as true.
Yeah.
There's the whole thing about bubbles too.
Like your social bubble, where you just tend to end up with a bunch of people
with the same political views, taste in movies, like clothing styles.
I do know there are some friends of mine though, that if they saw like the server
Twins videos that I watch once or twice a month, they'd be like, dude,
if they knew you watched them, yeah, are you?
I don't know if I would be cancel, but they're like, are you, you're, you're
going to be pulled into the alt-right pipeline, dude.
I'm worried about you.
Like this is, this is brain contamination.
Yeah.
It's like, I, I, I see the virtue of not merely like reading a Reddit thread on
like r slash no stupid questions, like what's up with QAnon.
But like actually getting like from people who actually believe it and who
can articulate it in a not crazy way.
Like you told me about these guys before, I haven't seen any other stuff, but
like if they're, if they're, they seem to represent the non-crazy end of the fact.
And so at least one of them is on the crazy end.
They want to move more.
I mean, one foot on the other side of the line.
The fact that they, that at least they have a diverse set of opinions among
the two of them then, right?
So like, I guess, because if you only ever, you know, read about this on
your leftist bubbles, you're going to be like, oh, they're all obviously closet
Nazis who hate minorities or whatever.
