I will go ahead and kick this off.
Welcome to the Bayesian Conspiracy.
I'm Inyash Brotsky.
I'm Jessica Dickey.
And I'm Stephen Zuber.
And today we are speaking with Alexander Wales again.
Hello Alexander.
Hi.
We have Alexander on the line because today we wanted to talk about the new GPT2 program.
That has been getting some talk recently.
And everybody knows what that is, so it requires no further elaboration.
Right.
Let's just jump right in.
Alexander is here because you have actually played around with it and you know a bit about
it, right?
Yeah.
I double majored in English and computer science and I've played around with it some.
I read the paper.
But natural language processing was a focus of mine in undergrad.
What?
Natural language processing is the like...
That's pretty perfect then.
Well, kind of.
Because what GPT2 does is it's a neural network as opposed to...
There have been a lot of prior attempts of natural language processing in sort of rules-based
setting to tear things apart, which is not how GPT2 does it.
We should, despite the joke I just made to Stephen, we should actually probably tell
people what GPT2 is before we continue.
Yeah.
Okay.
Do you want to go ahead or...?
Yeah, sure.
GPT2 is this new, I don't know if the program is new, but I just heard about it recently
with this thing that they published, I guess.
It is a neural network that you give it a prompt, like the first sentence of a paragraph
or an essay and you tell it to go to town and it will write the rest of it for you based
as predicting what you would want to say you would.
Let me take that back.
Based on the prompt that you gave it, it incorporates all its knowledge of everything
that's read on the internet to predict what the most likely next several lines and paragraphs
would be and it is surprisingly decent.
Is that a fair summary?
Yes.
So the paper is called Language Models Are Unsupervised Multitask Learners and in the
past what people have tried to do with neural networks is you set up your parameters and
then you have cleaned and very specific data for it to work with.
So if you want to ask it questions and have it give you answers, you would just put in
question and answer pairs for it repeatedly and that's how you train the neural network.
What they did for this one was they didn't train it on specific tasks at all.
It's just a bunch of, there's a big data set called WebText which is basically just webpages
from around the internet.
The only thing that they did for this one to make an alteration to WebText was they
did anything that had any web page that had three or more upvotes on Reddit so they compared
it to the Reddit data set of submitted links and then they just pulled everything out of
WebText that didn't have more than three upvotes.
And those were outgoing links, right?
Yeah, outgoing links on Reddit.
Oh good, so it wasn't, it's not going to just be fluent in your mama jokes and coffee
pastas and...
Well, there's a ton of stuff in WebText still and you can see some of it in what GPT2 will
output.
So it's very messy data but there's a lot of it and they use a lot of parameters on
it and basically the upshot of what they're doing is they're trying this new approach
where instead of having a specific task in mind for it, it's just doing a language model
basically, right?
For the whole neural network and then you have to sort of prompt it into doing the various
tasks that it does and it does very well on a whole bunch of tasks at state of the art
on I think seven out of the eight tests that they gave it.
And then the public version that they released, they released a not as good as what they had
model because there are a bunch of concerns about how people will end up using it.
What kind of concerns, like what's the big deal about writing bad fanfic and things?
We're going to cheat on our school essays.
Well, yeah, but if a school essay could be written by this program then it should have
gotten enough anyway.
Yeah.
Well, a lot of what people are worried about are you could do bots for it.
So more convincing fake profiles where people would just, you know, it could generate and
fill in like a Facebook profile or something like that but they're mostly worried that
it's going to be a tool used by people who create bots or send spam or things like that.
So but all they're doing is delaying the inevitable, right?
I mean, give it another year or two and this will be out everywhere anyway.
Yes, that is true.
And that is one criticism of the way that they're doing it but it's mostly they want
people to have a discussion about it and what it can do before it hits in full.
The other thing is that they, it's not, they say that it underfits the web text which means
that they could use more parameters and more processing power to make it even better than
what they did for this study.
I think the cost estimates for it are that it probably cost in terms of compute time
like $43,000 which is almost nothing, right, as far as big research projects go or like
what a corporation would, the kind of money that a corporation could throw at it, right?
Yeah, but a lot more than a spammer would want to.
Right, right, a lot more than a spammer would want to and the version that they publicly
released does not, it's still good.
It's still surprisingly good but it's not quite at the same level.
So yeah, in like a year or two it's going to be, there will probably be better versions
out there but it'll probably be major research institutions that are making their own version
of this and major corporations who will be, you know, perhaps slightly more responsible
with it.
Oh well, we can hope, give it to the Russians and man, or give it to our own government and
they'll do the same thing to Russia.
But let's give the audience a quick sort of overview of what it can do.
Does anyone have any of the text in front of them right now?
I have a little summary.
It generates coherent bodies of text.
It can answer questions.
It can kind of translate languages.
It wasn't taught to do that but because there was some French, I believe, in the training
data, it started just randomly being able to translate French.
And it can also kind of summarize text, which is similar, it couldn't, it wasn't really
taught to do that but putting TLDR allowed it to kind of match what people were doing
when they TLDR'd something.
And that's the too long didn't read if anyone doesn't know that acronym.
They put together, damn, I don't have the text in front of me and it would be too long
to read the whole thing anyway.
But they asked it, the first prompt was something like, the Civil War is very controversial
or something along those lines.
It was like, what caused the Civil War?
And it gave a pretty thoughtful and balanced answer compared to like what the controversy
is.
Yeah, I mean, I don't know how thoughtful and accurate it actually is.
It attributed a quote to Thomas Jefferson, which I'm not sure he ever said.
But it was like surprisingly coherent and I could see this coming from a real human,
especially one on Facebook that doesn't think much.
Let me clarify, that's sort of what I meant.
What I meant that it gave, it didn't just say, it didn't run to Wikipedia and grab
the first sentence, right?
No, no.
So I know, but like, so it didn't, it understood that there's argument about this, right?
And I thought that it was, yeah, like again, maybe I got the quote misattributed or something,
but I was surprised by how thoughtful sounding the answer was.
Yeah.
It's really good at sounding like a person.
You could turn it in for a school essay answer and probably not flunk at any rate.
Certainly what you could do is have it write it for you and just skim through it and double
check some stuff, right?
Yeah, it does a lot of fake facts, like, and anything that it asserts is very questionable,
but it'll be very close to, if not entirely grammatically correct and it'll sort of flow
in the same style.
So like, if you're not paying 100% and you'll sort of gloss over it as like something a person
had written.
Doesn't need a quote.
But yeah, quotes, it will just like, it just makes up quotes wholesale because it doesn't,
you know, it doesn't, it doesn't know what a quote is.
It's just like, okay, I did starting quotation and then there's a sentence in here that has
like a different voice to it, and then there's a period in an end quote mark, right?
Which is kind of fun.
I have one here from the, that I will read because I think this is, they do it with different
completions.
You can change the random seed for it to have it do multiple different outputs for it.
They did one that was for a chocolate chip cookie recipe.
So the prompt that they gave was like a paragraph of stuff, kind of garbage that you find on
recipe websites that come from the actual recipe that's mostly included for the recipe about
the expressions like experience with their mother baking cookies in Switzerland.
Yeah, yeah.
So they give it like, they give it context as it's sort of prompt.
And so it's, if you don't have seven inch cake pans, you can get three shorter eight
inch layers out of this.
And then that's where they stop.
And GPT two is allowed to continue.
And that says recipe, I made the longer version than use the pan for a layer of buttercream
frosting and stuck one third of it into the fridge for a frosting topper.
Just make sure you have all of this frosting prepared earlier than you make this cake and
you won't have to wait on it as your egg whites sit.
I don't think about cooking and that sounds like good advice to me.
I'm sure you could probably tell us you don't ever do that, but I'm like, sure, why not try this?
Yeah.
So and it can sort of handle the thread.
I've played around a lot with the, the not as good version.
And it has a similar problem as what they say in the paper is that it can kind of drift
and lose the thread as it goes.
Um, because it's it, what it outputs is based on what came before.
And so as it continues on, it'll start picking up on things that it has said.
And then it sort of drifts off into something else.
It also does, uh, there are a lot of artifacts in the data because it wasn't,
um, as 100% clean as it could be.
And it's just, you know, a collection of web pages.
So it would do like little ad breaks.
So it'll just, it'll just say like, yeah, it'll do a little ad breaks every once in a while.
It'll like finish a paragraph and it'll be like, uh, what do they always say in the ads?
Like just below the picture, it's like, like, no, sponsor content or whatever.
And sometimes you'll see it do, uh, picture captions, right?
It'll just do like square, square brackets and they'll have accounts.
Like, I don't get it, but if it's not doing this, okay, that's a thing that you do.
Yeah, that kind of thing is interesting because, uh, I read a bit of the paper too.
They were saying that they wanted to minimize the amount of like the amount that they needed
a human to go and read all these articles and edit them, which was why they were doing the
Reddit with the three karma.
Um, I guess they weren't really able to have like anybody filter those things out though.
It, you could probably get much better data for it if you were able to make some kind of
scraper that was smart enough to take that kind of junk out or have a person do it.
Although I think it read like eight million articles.
So that would just take a really long time.
I do recall, uh, that Scott said in, in his follow-up post that a commenter said,
Oh no, no, no, he didn't put it in the, I read this in the comments myself.
There was a commenter said, I'm a high school English teacher and what it spat out,
I would probably give a C or a C minus, which is really impressive on the one hand.
On the other hand, also makes me despair for the youth of the nation because
I don't think you should get a C for, for putting out stuff that's basically just
I don't know.
It, it was, yeah, empty, all surface.
