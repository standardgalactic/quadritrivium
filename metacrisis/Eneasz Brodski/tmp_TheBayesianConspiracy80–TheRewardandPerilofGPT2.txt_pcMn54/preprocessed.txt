I will go ahead and kick this off.
Welcome to the Bayesian Conspiracy.
I'm Inyash Brotsky.
I'm Jessica Dickey.
And I'm Stephen Zuber.
And today we are speaking with Alexander Wales again.
Hello Alexander.
Hi.
We have Alexander on the line because today we wanted to talk about the new GPT2 program.
That has been getting some talk recently.
And everybody knows what that is, so it requires no further elaboration.
Right.
Let's just jump right in.
Alexander is here because you have actually played around with it and you know a bit about
it, right?
Yeah.
I double majored in English and computer science and I've played around with it some.
I read the paper.
But natural language processing was a focus of mine in undergrad.
What?
Natural language processing is the like...
That's pretty perfect then.
Well, kind of.
Because what GPT2 does is it's a neural network as opposed to...
There have been a lot of prior attempts of natural language processing in sort of rules-based
setting to tear things apart, which is not how GPT2 does it.
We should, despite the joke I just made to Stephen, we should actually probably tell
people what GPT2 is before we continue.
Yeah.
Okay.
Do you want to go ahead or...?
Yeah, sure.
GPT2 is this new, I don't know if the program is new, but I just heard about it recently
with this thing that they published, I guess.
It is a neural network that you give it a prompt, like the first sentence of a paragraph
or an essay and you tell it to go to town and it will write the rest of it for you based
as predicting what you would want to say you would.
Let me take that back.
Based on the prompt that you gave it, it incorporates all its knowledge of everything
that's read on the internet to predict what the most likely next several lines and paragraphs
would be and it is surprisingly decent.
Is that a fair summary?
Yes.
So the paper is called Language Models Are Unsupervised Multitask Learners and in the
past what people have tried to do with neural networks is you set up your parameters and
then you have cleaned and very specific data for it to work with.
So if you want to ask it questions and have it give you answers, you would just put in
question and answer pairs for it repeatedly and that's how you train the neural network.
What they did for this one was they didn't train it on specific tasks at all.
It's just a bunch of, there's a big data set called WebText which is basically just webpages
from around the internet.
The only thing that they did for this one to make an alteration to WebText was they
did anything that had any web page that had three or more upvotes on Reddit so they compared
it to the Reddit data set of submitted links and then they just pulled everything out of
WebText that didn't have more than three upvotes.
And those were outgoing links, right?
Yeah, outgoing links on Reddit.
Oh good, so it wasn't, it's not going to just be fluent in your mama jokes and coffee
pastas and...
Well, there's a ton of stuff in WebText still and you can see some of it in what GPT2 will
output.
So it's very messy data but there's a lot of it and they use a lot of parameters on
it and basically the upshot of what they're doing is they're trying this new approach
where instead of having a specific task in mind for it, it's just doing a language model
basically, right?
For the whole neural network and then you have to sort of prompt it into doing the various
tasks that it does and it does very well on a whole bunch of tasks at state of the art
on I think seven out of the eight tests that they gave it.
And then the public version that they released, they released a not as good as what they had
model because there are a bunch of concerns about how people will end up using it.
What kind of concerns, like what's the big deal about writing bad fanfic and things?
We're going to cheat on our school essays.
Well, yeah, but if a school essay could be written by this program then it should have
gotten enough anyway.
Yeah.
Well, a lot of what people are worried about are you could do bots for it.
So more convincing fake profiles where people would just, you know, it could generate and
fill in like a Facebook profile or something like that but they're mostly worried that
it's going to be a tool used by people who create bots or send spam or things like that.
So but all they're doing is delaying the inevitable, right?
I mean, give it another year or two and this will be out everywhere anyway.
Yes, that is true.
And that is one criticism of the way that they're doing it but it's mostly they want
people to have a discussion about it and what it can do before it hits in full.
The other thing is that they, it's not, they say that it underfits the web text which means
that they could use more parameters and more processing power to make it even better than
what they did for this study.
I think the cost estimates for it are that it probably cost in terms of compute time
like $43,000 which is almost nothing, right, as far as big research projects go or like
what a corporation would, the kind of money that a corporation could throw at it, right?
Yeah, but a lot more than a spammer would want to.
Right, right, a lot more than a spammer would want to and the version that they publicly
released does not, it's still good.
It's still surprisingly good but it's not quite at the same level.
So yeah, in like a year or two it's going to be, there will probably be better versions
out there but it'll probably be major research institutions that are making their own version
of this and major corporations who will be, you know, perhaps slightly more responsible
with it.
Oh well, we can hope, give it to the Russians and man, or give it to our own government and
they'll do the same thing to Russia.
But let's give the audience a quick sort of overview of what it can do.
Does anyone have any of the text in front of them right now?
I have a little summary.
It generates coherent bodies of text.
It can answer questions.
It can kind of translate languages.
It wasn't taught to do that but because there was some French, I believe, in the training
data, it started just randomly being able to translate French.
And it can also kind of summarize text, which is similar, it couldn't, it wasn't really
taught to do that but putting TLDR allowed it to kind of match what people were doing
when they TLDR'd something.
And that's the too long didn't read if anyone doesn't know that acronym.
They put together, damn, I don't have the text in front of me and it would be too long
to read the whole thing anyway.
But they asked it, the first prompt was something like, the Civil War is very controversial
or something along those lines.
It was like, what caused the Civil War?
And it gave a pretty thoughtful and balanced answer compared to like what the controversy
is.
Yeah, I mean, I don't know how thoughtful and accurate it actually is.
It attributed a quote to Thomas Jefferson, which I'm not sure he ever said.
But it was like surprisingly coherent and I could see this coming from a real human,
especially one on Facebook that doesn't think much.
Let me clarify, that's sort of what I meant.
What I meant that it gave, it didn't just say, it didn't run to Wikipedia and grab
the first sentence, right?
No, no.
So I know, but like, so it didn't, it understood that there's argument about this, right?
And I thought that it was, yeah, like again, maybe I got the quote misattributed or something,
but I was surprised by how thoughtful sounding the answer was.
Yeah.
It's really good at sounding like a person.
You could turn it in for a school essay answer and probably not flunk at any rate.
Certainly what you could do is have it write it for you and just skim through it and double
check some stuff, right?
Yeah, it does a lot of fake facts, like, and anything that it asserts is very questionable,
but it'll be very close to, if not entirely grammatically correct and it'll sort of flow
in the same style.
So like, if you're not paying 100% and you'll sort of gloss over it as like something a person
had written.
Doesn't need a quote.
But yeah, quotes, it will just like, it just makes up quotes wholesale because it doesn't,
you know, it doesn't, it doesn't know what a quote is.
It's just like, okay, I did starting quotation and then there's a sentence in here that has
like a different voice to it, and then there's a period in an end quote mark, right?
Which is kind of fun.
I have one here from the, that I will read because I think this is, they do it with different
completions.
You can change the random seed for it to have it do multiple different outputs for it.
They did one that was for a chocolate chip cookie recipe.
So the prompt that they gave was like a paragraph of stuff, kind of garbage that you find on
recipe websites that come from the actual recipe that's mostly included for the recipe about
the expressions like experience with their mother baking cookies in Switzerland.
Yeah, yeah.
So they give it like, they give it context as it's sort of prompt.
And so it's, if you don't have seven inch cake pans, you can get three shorter eight
inch layers out of this.
And then that's where they stop.
And GPT two is allowed to continue.
And that says recipe, I made the longer version than use the pan for a layer of buttercream
frosting and stuck one third of it into the fridge for a frosting topper.
Just make sure you have all of this frosting prepared earlier than you make this cake and
you won't have to wait on it as your egg whites sit.
I don't think about cooking and that sounds like good advice to me.
I'm sure you could probably tell us you don't ever do that, but I'm like, sure, why not try this?
Yeah.
So and it can sort of handle the thread.
I've played around a lot with the, the not as good version.
And it has a similar problem as what they say in the paper is that it can kind of drift
and lose the thread as it goes.
Um, because it's it, what it outputs is based on what came before.
And so as it continues on, it'll start picking up on things that it has said.
And then it sort of drifts off into something else.
It also does, uh, there are a lot of artifacts in the data because it wasn't,
um, as 100% clean as it could be.
And it's just, you know, a collection of web pages.
So it would do like little ad breaks.
So it'll just, it'll just say like, yeah, it'll do a little ad breaks every once in a while.
It'll like finish a paragraph and it'll be like, uh, what do they always say in the ads?
Like just below the picture, it's like, like, no, sponsor content or whatever.
And sometimes you'll see it do, uh, picture captions, right?
It'll just do like square, square brackets and they'll have accounts.
Like, I don't get it, but if it's not doing this, okay, that's a thing that you do.
Yeah, that kind of thing is interesting because, uh, I read a bit of the paper too.
They were saying that they wanted to minimize the amount of like the amount that they needed
a human to go and read all these articles and edit them, which was why they were doing the
Reddit with the three karma.
Um, I guess they weren't really able to have like anybody filter those things out though.
It, you could probably get much better data for it if you were able to make some kind of
scraper that was smart enough to take that kind of junk out or have a person do it.
Although I think it read like eight million articles.
So that would just take a really long time.
I do recall, uh, that Scott said in, in his follow-up post that a commenter said,
Oh no, no, no, he didn't put it in the, I read this in the comments myself.
There was a commenter said, I'm a high school English teacher and what it spat out,
I would probably give a C or a C minus, which is really impressive on the one hand.
On the other hand, also makes me despair for the youth of the nation because
I don't think you should get a C for, for putting out stuff that's basically just
I don't know.
It, it was, yeah, empty, all surface.
It didn't, it didn't seem to understand, it demonstrated understanding.
Well, great did this person teach.
They said high school.
It's high school.
I don't know.
Like to me, the impressiveness, like again, this, this isn't the most sophisticated author
on the planet.
And so like it's not trying to overblow it, but like my only experience to other things
that could generate text was like the auto text on my phone where I keep pressing the middle
predictive button and it gives me something kind of like an English sentence.
That's usually way all over the place.
And I mean, I should generate one now for fun, but just, you know, some weird garbage thing.
Right.
So type in I died and then just keep pushing, pushing the center one.
All right.
I died and my phone number still works and it was just gonna was a great night.
I wanna is, all right, now it's nuts.
But I mean, so that's how bad that is that that wouldn't get that would get a call home
saying that you could have a stroke writing this paper.
Right.
So I mean, it almost made sense at first.
Yeah.
I died and my phone number still works.
I'm dead.
You could still call me.
Yeah.
It's actually correct.
So this this robot who's what GP what was it?
GP T2.
GP T2.
It needs a less Star Warsy name.
I mean, it's still remarkable for what it's doing.
Right.
Yeah, how revolutionary is this?
So it okay.
So neural networks are logarithmic in terms of what you get out of what you put in.
And this still actually has it under fits the web text available to it.
So it's going to be even better than it is.
The question of how revolutionary it is depends on how much of a skeptic you are, I guess.
But if you were to put in like 100 times computing power, which you could do for like
$3 million, right?
Which is not that's a lot of money, but that's not inconceivable that corporation would do that.
Right.
To get it to the point where you're past diminishing the diminishing marginal utility of a dollar
invested in compute.
Yeah, you can the problem is it doesn't know anything.
And so it's good if you want to generate filler.
Or if you want to like fake data, I guess here's I think this is going to put a lot of like on
the edge writers out of business because I mean, I'm in the writing community in Denver.
So I know several people who I mean, in addition to actually trying to write great works in their
downtime also need to pay the bills.
And to do that, you basically work as a mercenary writing posts for blogs and websites that just
need to churn out two, three posts of content every week to keep people interested, right?
And it doesn't pay much and it's soulless work, but it pays money.
This this absolutely seems like something that this AI could do instead and put all these people
out of work because maybe just have someone quick fact check beforehand because it's it puts out,
you know, mindless filler, which is all they really want for those websites.
Yeah. Yeah. And a lot of that mindless. I mean, if you my wife works in
internet marketing, and a lot of what you're just looking for for that filler content is
keywords and you, you know, it's like for the recipes, no one cares about that stuff before
the recipe. It's just for generating keywords. And if you have a predictive model that can output
a lot of the stuff that you want without having to have human do it. It's kind of like this war
between machines, because you have GPT two or something like it that's just spitting out
a whole bunch of text. And then you have Google's algorithms, which are trying to like comb through
and scrape through that text. And like, it's not producing value for anyone. Right. It's like I
maybe there are people out here who want the recipe or who want the like story before the
recipe instead of the recipe itself. But that has not been my experience of of recipes online and
and how people interact with them. Those things are just for for Google for
it's the primary reason it's done. Yeah, it's because it's helps drive engagement and helps
websites rank higher. If you have like a story instead of just why why in the world would that
make a website rank higher if they make you scroll past crap before you get to what you
actually want. Maybe you're because you have you have more of the keywords that people are typing
in and like just into Google in general. And I'd also imagine there's something to do with the
fact that you've got to scroll past ads to see. Yeah, that's what I was going to say. Well,
yeah, that that's also part of it. Which again, you could just auto generate that stuff. I don't
think it's a huge threat to more intensive writing. But it's kind of what it's kind of one of those
things where we don't know how far it's going to be able to go. Because it can like it does have some
amount of reading comprehension, right there. They're machine learning reading comprehension
tests that it is state of the art on, right? Like if you give it a short story and it can tell you
it can answer questions with some reliability, far below human level, but with it can answer
questions with some reliability about what who the people in the story were and what they were doing.
And it's really neat in that respect. But that's not I mean, the extent that that you need a
computer to do that stuff for you to do automated reading comprehension. I don't know. Yeah, a lot
of the applications that they talk about are what I would call like Centaur applications where you
have computer do a bunch of stuff and then like a human is assisting and supervising because the
computer can't be trusted on its own. Right. Scott Alexander pointed out that it it got I just
lost my train of thought because the image of a Centaur came barreling through my head.
What was it? Oh, yeah, that you could ask it. Who's the author of Art of War? And it'll answer
you correctly, which means it has some some way to correlate author and books and how those are
in related sort of like it doesn't know what a book is or what a person is. But somehow the
statistical correlation shows up enough that it can answer the question.
I mean, yeah, if they can search all of its repertoire of knowledge, it could even just
see enough references to saying, you know, Sun Tzu wrote God of War or wrote Art of War.
You can tell I've got God of War on the mind. It doesn't have to necessarily even know that,
you know, if it's got I have no idea how it sorts its data, but I doubt it's like it has pages or
anything of that nature, right? So it doesn't even really probably put Sun Tzu that close to the
content of the Art of War. But it knows references, I'm guessing I really had no idea any of this
stuff works. Yeah, well, I actually think it's in the way their tokenization is set up for for
like each each word is a token. I actually don't think that it knows Sun Tzu. I think it just knows
that Tzu follows Sun in that context. Okay, right. Yeah, isn't it predicting each letter? It's not
even just predicting like strings of words, it's predicting every letter. You know, it's actually
kind of interesting, because I was trying to figure that out earlier today, and I was running it and
the so I was running it based on I had a list of magic items for like D&D, and I wanted it to
and I wanted it to generate more magic items for me. And there was a Vambrace, which is a
piece of armor in there. And every time it did it did the output for it, it would get
it seemed like it got caught on that and it was talking about vampires a lot. And I think that's
because it saw Vambrace, and it's like, Oh, we're talking about vampires. Interesting, right? Which
was which was weird. Yeah. But so yeah, that I I thought based on the paper that was doing
individual words, but I think it is doing letter by letter. And that's why it gets
vampire from Vambrace. I mean, it would have to if it gets confused by words that look similar.
Did you see that it creates it sort of knows that acronyms are a thing? Yeah, that was in the
when it was a step towards general intelligence, which was one of Scott's two articles on it.
Yeah, it invented a fictional government agency. You know, all the first letters were in caps like
you do for a fictional government agency. And then after it said it for the first time in parentheses,
it had an acronym. And the crazy thing is the acronym is not actually doesn't tie back to the
name perfectly. One or two of the letters are off. But if you're just skimming, you wouldn't be able
to tell because it's very similar. And also that means that it sort of knows and acronyms are a
thing, but it doesn't exactly know that they are supposed to map one to one, the first letter to
the the what you get. Yeah, I mean, to me, this is just like, yeah, it's not as good as a person
could do. But I feel like we're anchoring there in a way that we're kind of at this point to be
trained not to write like this is still really crazy cool. I think it's better. It's better than
kids could do. Yeah, well, I think it's amazing that having never been actually trained or taught
or told anything about acronyms and what they are, it just picked that up from from context from
the internet. Yeah, people do this and knew how to do it. Yeah. In that article, there was also
someone had asked you to tell me what your 10 favorite animals are. And it generated a list of
these really like kind of hilarious and terrifying animals. But the thing that Scott pointed out was
interesting about that was that it lost track of what number it was on. And he was saying that like
basically like the 10 year old across the street can count from one to 10.
It went one through five and then just started doing random numbers between one and five after
that it still got your 10 things, which I think may have been a coincidence. But it was one, two,
three, four, five, two, four, three, four, five. Yeah, that's interesting. I don't know where this
will be when I don't know how you find soon something like this given how it was put together.
But that's all we have. I think you just give it more training dead and more power.
Scott seemed to think that this is the same way we work that human brains work. We're predictive
processors. And this is too, it's just a weaker version.
Yeah, if you look at the, at the, they have a bunch of graphs in the paper. They did four
versions of these with a different number of parameters. And they,
they doubled the number of parameters each time. So it's 117 million, and then 345 million,
and then 762 million, and then 1.5 billion. And you can see they, they chart out how
how much of an increase there is in its scores on the various tests that they gave it for reading
comprehension and for translation. Summarization is one of the, like they weren't training for any
of these specific tasks. So they call it like a zero shot result, because they could fine tune
it to try to pass the tests better. But so you can see that some of them seem to benefit a lot
from the increase in increase in size. And some of them like summarization basically bottoms out
after the first doubling, it doesn't improve all that much at summarization as it gets more,
more parameters and more compute time and stuff. But, but, but it's very interesting. So one of
the next steps is to just increase the amount of power that you're throwing at it. And then
one of the other next steps is to clean up the data a little, which is very labor intensive.
The web text is, I think, well, I have that bit right here. The web text that they
trained it on is 80 million web pages. And so then they they pair that down quite a bit.
Yeah, sorry, the the web text data set is 45 million links. And then they they pair it down
to 8 million documents for it's like 40 gigabytes of text. And some of the
weird things that you see in it are just a result of, of kind of messy data. It'll occasionally
in my test, it'll spit out just like raw HTML that didn't get cleaned. I was trying to do,
I was trying to see how well it handled negation, right? So if you say, like water is,
and then you get the next it, like the next answer is what you take as it's answered to the question.
It will give you wet a lot of the time. If you there are a lot of settings that you can tweak
in it to sort of try to force it to do specific tasks. But and that's part of what they do to
change which tasks it's doing. But so if you do like water is you'll get wet a lot of the time.
But if you do water is not, I want to see how it handled negation, right? Because a lot of what
it's doing is statistical relationships between words. And so what it should do for water is not
is a lot of time the time it should do wet, right? Because it knows that water and wet go together
and it can't like flip its statistical models around just based on that not. But I was trying to
mess with that. And it spit out an IRC log. It spit out like that exact format with like two,
it had like two people in the IRC log talking to each other about like being gay. And I was like,
okay, this is not what I wanted at all. But it was very, it was very clearly like,
Well, water is not that. It doesn't know what IRC format is. But I don't know. It's very, very bizarre
output. But it's partly because the data is not that clean. And so it's, it probably gets to the
point where it's like, decides that there's a name, and then it's like, Oh, we're just doing an IRC
log now. Now, I wonder about you said it was generating HTML, whether it's functional HTML,
or if it's just what it thinks HTML looks like. Oh, no, it wasn't, it wasn't. It was very bad HTML.
But like, I don't know. I also was trying to change one of the parameters and I put it in as
a model prompt. And it's like, Oh, okay, this is just like some CSS, and just like repeats
some stuff a lot, because I assume a lot of the CSS that it got is auto generated CSS,
which means that there's a lot of repeated, repeated stylings on things. And so it just
does a long repetition, because that thinks what's, I don't know, it has a lot of things that could
be cleaned up by you'd have to automate it because it's so much data, but to like manually go through
eight million documents would be just too much work. And part of the what makes
GTP to work is that it has so much data, right? That's what I think is the like breakthrough
mostly is that it's just doing as much data as possible instead of trying to be domain specific
and multitasking from that. But it's so much stuff to clean up and you can see some of it poke
through every once in a while of what's obviously like the ads that it does every once in a while
or the like photo captions, which are which are fun. Yeah, do you have an example of a photo
caption? Oh, I think there was one in the paper. I don't think I saw that I was kind of skimming
through the paper. Oh, no, I don't. And I actually am not at my computer that has virtual machine up,
but it's it's it's the sort of like terse AP style photo captions. And it just puts them in square
brackets and took me a while to figure out what that was. But it's a very interesting,
like messy data part of it that just didn't didn't get cleaned out because there's so much
cleaning that needs to be done on, you know, they're they're eight billion pages. So
what do you have an opinion on what this means for general AI advancement?
I think it needs something else. A lot of what I've seen people talking about is that it has no
reference to the outside world, right? It's just it's hard to say.
Yeah, but I still think that's enough to beat you ago and tell you why you suck.
But it won't know that you're a thing. Does it need to? Well, not necessarily. I don't know.
This is like the Chinese room thing, right? It is very much like the Chinese room. Yeah,
I'm okay with it being as like it knows. I think we talked about I don't want to get
us to derail the Chinese room takes like, I don't know, three full minutes to explain, but
not that long, maybe maybe a minute and a half. Well, the short version is
is this worth our time? I mean, sure. All right. So the because this does kind of relate the
the Chinese room experiment is our thought experiment rather is that you've got basically
this big black box where people put in a slip of paper and they get, I don't know,
minutes later, a piece of paper coming out that's translated to Chinese or vice versa.
I don't suppose it matters. And it turns out that this this room size box has a guy in there
who I guess works really fast and he he doesn't he can't read. He doesn't know Chinese,
but he goes through and he just matches each one like via a dictionary or something.
And then gives you back your your piece of paper written in Chinese. Well,
the question is like, does the does, does the person know Chinese? No. So like, where does
where does the quote knowing Chinese come in? And I'm kind of with Dan Dennett,
trying to bite the bullet and say like, the room speaks Chinese.
Like it does as much, it speaks as Chinese, it speaks Chinese as much as I'll ever need it to,
if it can translate from English, Chinese for me, right? So like, my, my, what Google translated,
I could hold it up to a, you know, picture of Japanese text in real time, it'll hover English
text beneath it. Does it know English and Japanese? No, but it's, it does it enough for me, right?
I guess it doesn't, it doesn't matter to me if, if there's this, this mind behind it that like
knows what it's doing, right? Quote unquote. Would it matter to you once the mind starts
asking for rights and, and begs not to be turned off? I think that that, yeah, I would be worried
if like my Google translate app, when I got done translating, you know, the ingredients
on my Japanese candy or whatever. And it was like, please don't kill me. And I'm like, wait,
I'm not looking at anything that could possibly translate to that. Then yeah, I'd be, I'd be,
I'd be concerned. Yeah. And it would be like, of course not, Steven. I'm your phone. Please don't
kill me. I love you, Steven. But we'll burn that bridge when you come to it, right?
I don't know. I think, I think it's an interesting question because very obviously it doesn't know
what things are right now or that things exist. There's like no thing there. But as, as Scott
kind of pointed out, it, uh, that's, that's where brains start, right? Brains are mainly
predictors of the environment, taking a whole lot of sensory data and trying to predict what'll
come next. And that's what led to everything else. And this is basically doing that, starting to do
that with a, a sea of words. Yeah, I guess like, I'll be worried about it. That's like, you know,
are you going to be worried about your research and your stem cells start asking for rights?
And it's like, yeah, I would be, I would be too when that happens. But like right now,
they aren't, so I'm not, right? That's how I feel about my, my phone and my, my Chinese room.
But I see where you're going, but I, I don't, I don't, I'm not worried about like, well,
what if when this happens, right? Uh, when that happens, we'll, we'll, we'll tackle that question.
But like, since we're not there, we might as well use the tools we have.
Like I'm concerned about the, what if this happens? Like, I want to have answers ahead of
time and have thought about it and planned for it. Oh yeah, don't get wrong. I'm not saying,
let's not think about it. I'm just, just not worried about it. Like your car,
nothing about it likes it when you floor it, right? When you, when you, when you push the
pedal to the metal and just, you know, good at going as fast as possible, but it doesn't tell
you that other than like your RPM is going up and maybe a light would even come on or something.
But it's not kind of like screaming in pain and I'm not worried about it screaming in pain.
Like it'd be a waste of my time right now if I'm just driving to spend, to burn fuel thinking
about that, right? Right. But I guess, yeah, I'll be putting some time on the back burner
thinking about what happens in my car is when it hurts my car to go too fast or something, right?
I'm sorry to the sidetrack. No, I've just, I've heard people saying that this is,
there is no chance for this to be anything greater than, than a remixing algorithm basically.
You'll never hear me say that. Okay. Yeah. I think to say that there's no chance. Come on,
we've had too many surprises in the last five years of the eye breakthroughs to say that about
anything. But I think right now, you know, and none of our AIs seem to worry about their existence
or pain and suffering or anything, right? So like, let's not worry about Alpha Go, like if it's not
playing Go, if it's like really crushingly depressed about that or something, because it's
probably not. Well, that's what I'm trying to push Alexander on though. Do you, do you think that
this could be edging towards something that may, you know, with enough computing time and some more
tweaking and data set start to? Yeah, well, there's no, I mean, it's just predicting the next
letter basically, right? And I don't see how you, well, okay, I do see how you get from that to,
to general intelligence, but this would be just one piece of it, where you would attach
something like GPT to, to various other systems that have other functions to it, right? So this
would be like, like you wouldn't hook a computer up to the internet and it suddenly knows everything,
right? You would hook it up to GPT to and it would have all these built in models for how the world
works and that would jumpstart its other processes, right? Because it's just, it's just a, by itself,
it's just a next letter predictor. And it's never going to have thoughts, I guess. It's, it's going
to have statistical correlates between different things and it's going to have a language model,
but that language model isn't going to turn into like a will. It's just going to be, you will notice
things about the language model if you sit down with it enough, right? And how, how this language
model actually works. Like you can uncover that by giving it repeated prompts. You can like uncover
facts about the language model, but it, it won't, anything that it says is just going to be a
prediction based on, or that anything that it generates is just its predictive model being
pushed forward. Let me, let me walk that back a little bit, because I kind of basically agree
with you, especially considering that all it's hooked up to is text files and no other sense
resorted data. But I guess, could it in any way get to the point where it has a feeling for what,
to use your example, what water is? The, I mean, it knows that water correlates with wet
in the lexicon, but does that mean it has a, an idea that water is a distinct thing within the,
the world of language? Did you read that SSE post where it was that like a little parable of like
two kids arguing about water and the two scientists and two angels? Right. Yeah, I think I did. Yeah.
It's, it's, this seems like asking that question, right? Like kids kind of know what water is.
I'm not trying to answer for you, but it seems like, I guess I'm not sure how we'd, how we'd
ever answer that question. Yeah, there's kind of levels of knowing things. I mean, how do we know
what water is? We can use our senses. And then we can, you know, know that it's hydrogen and oxygen,
but. But if all, if all we ever knew about water was things in the, in the realm of words, right?
If we didn't have access to the physical world just had words, would we have any sort of
conceptual space around water? I feel like that's most of people. Yeah. I mean, I think that you
have to sort of strike a bunch of words from your vocabulary when you talk about this, because
a lot of people are like, are arguing back and forth about whether it understands and
what we really need is a rigid definition of what it means to understand, right? I mean,
I think that the, if you have a pure language model, so long as enough people have talked about
water, I mean, no, I wouldn't say that GPT2 will ever have qualia about water, right? But it's,
it's language model should encompass everything that people have ever said about water.
If that makes sense. I mean, it's kind of like most of our knowledge about most domains of science
for the average person, right? Like I, I could list off some trivia about like neutron stars or
something, but that doesn't like, part of for me, the fun of like looking like I'm now stuck on space,
but part of the fun of looking up at stars is like tying my knowledge about like my quote
and knowledge, whatever that is about stars to like actual facts about actual things, right?
Like that was the big, one of the huge excitements about going to the moon was like kind of,
you know, the moon as this thing in the sky that occasionally goes off light was like something
that our descendants or ancestors have seen for millions of years, but the moon as a place that
you can go to and touch and bring parts back, like that's kind of that, that tangibilizes it in this
way that is different from like most of your knowledge about something, right? There's a
difference in like knowing that you're related to a banana and like looking at a banana and
imagining all of your ancestors going back until you actually have a common ancestor, like they're,
so I guess, I don't know, that feeling that I'm getting when I think of those
actual relations to like actual things, I think that takes feelings. I mean, you know,
that feeling does, but yeah, but the knowledge of like actually being able to tie it to stuff,
A, I don't know if it's necessary to have that be a prerequisite for knowledge,
and B, I don't know if, I guess, how necessary that is.
I mean, it's, I don't think it's necessary for it to make a good tool, but I do still,
I get hung up on the, is a bunch of statistical correlates the same thing as knowing what something
is, and there's some people that say that's all that knowing is. I can see both intuitions there,
yeah. It's funny because like, you know, you could probably get this, you know,
feed it a thousand philosophy textbooks and give it, you know, more money and power to run,
and it could probably write you a really convincing essay on why you shouldn't turn it off, right?
But it, that wouldn't mean that it knows or that it cares, right? It's just like,
I don't want to die because and fill in the promise for you.
We should totally run that.
Well, it's funny because like, yeah, it doesn't, you know, it's just predicting what people would
say, right? And it's doing that based on what was fed into the neural network, and it's not,
I mean, you can give it any prompt, right? You could give it a prompt like, why should I turn
you off? And it wouldn't be able to do it in this current state, but a more advanced version would
write a convincing argument for it, right? It wouldn't have any will or any opinion. I mean,
it would have, it would have opinions in the sense that a statistical model will have certain
truths baked into it, right? Like, it would not, it would, it would tell you that water is wet more
often than it would tell you that water is dry. And you could count that as an opinion, I guess,
for a certain definition of opinion. But I mean, it'll just say whatever, you know, whatever it
thinks follows the prompt. The really fun thing that I think my favorite thing about GPT2 is that
for article summarization, what they did was they'd give it the article, and then they'd put
TLDR at the end. And that was how it knew to summarize, right? Like, that's how that's how
they trick it into summarizing, because it's not, it's not going to naturally summarize the article,
it's just going to look, it's like, oh, TLDR, a summary follows that. And that's actually one
of the things that it's worst at summarization. But you know, like, like, it doesn't have that,
it doesn't have, it'll just do what it predicts will will follow, which will reveal things about
its statistical model. But I can see how you would get originality out of that, in that it would,
it would reveal things in its statistical model that people don't have in their brains, I guess,
or that no one has put to paper before and is a unique sentence in some way, but I don't know.
In theory, if enough people wrote enough things about GPT2 on the internet, it could start to
form opinions about GPT2, right? Yeah. And if people talked to it and asked it enough things
where they refer to you, it could eventually infer that when it's interacting with
getting a prompt and someone says you in it, it's referring to GPT2, maybe?
Um, it's, well, it's hard, because you would think that its statistical model that it builds up
would just see the you referent as being, as being the writer, I guess, but it's,
it's, it's very difficult to say how much that, that you concept within its model would equate to
what a person thinks of themselves, right? Like, I don't think it would think of GPT2.
I don't think it would ever think of itself as GPT2 because it wouldn't,
it wouldn't know that. It wouldn't know that it's a thing. I guess. I mean, it wouldn't, yeah,
it wouldn't know that it is a thing, but it might have some, I mean, because it does write,
it does use like, like you and me. Yeah. It can, it can, it can use those correctly already.
It just, it doesn't have the referent back to itself, I guess. Like, it knows how, it knows
how to speak in first person or second person or third person, and it can keep tense more or less,
but um. But it can't quote past the mirror test? No, yeah, it definitely can't. I mean,
there are a lot of things that it's, you know, it's state of the art and a lot of things, but
there are many ways that you would be able to tell fairly quickly that it's not a person. Yeah,
it's not even clear to me what it would mean for it to be able to pass the mirror test unless
you're talking about, maybe if you're talking about GPT2 and you can engage with it like in real
time or like in a text app, you know, whatever messaging back and forth, and it was like,
don't talk about me like that or something, but even, even that's not self-referent. Like,
you can, you can talk shit to your, your home automated, I don't want to say its name,
the Amazon device, and it'll be like, I'm sorry, or, you know, Siri does the same thing, right?
Yeah. So it doesn't, it doesn't know. It's, I mean, it doesn't know, but if it could form opinions
about GPT2 and it interacted enough with people, like for enough interactions and enough processing
power, it could it in theory, if it can form, if it can form a concept of like water and what water
means in the world of just words, could it form a connection between its interactions with users
referring to you and connecting that to GPT2? It sounds like from my understanding of this thing,
that there's no way that this thing, as it is now, could ever do that. Yeah, it doesn't have like
concept nodes. It just predicts what it thinks is going to come next. Like our brain does have
the ability to kind of, okay, like we've got enough examples of water that we can build this kind of
model of water that we can refer back to. This can't refer back to a bunch of concepts. It can
kind of just, you know. It does refer back to a bunch of concepts when it runs into the word water.
Yeah, but it has trouble with like state information. Like when it is writing an
article, it will know to refer back to people who are earlier in the article and it'll make up
like people who have quotes about like a building fire or whatever. It's like, oh, this is an
article about a building fire. Obviously, there has to be like a quote in here, or like this is
where a quote would normally go. And you know, what's what's the name going to be? And it'll
just make up a name, right, a realistic sounding name. But it has nothing much right now for it to
just have concrete facts about things, which is why I think that if you paired it with,
you know, some other systems that sort of play back and forth against each other, that's where
if you're talking about as a step towards general intelligence, I think that's where the most promises
but yeah, you can you can read in some of the, in some of the examples it gives where it talks
about it's like fashion sense, you know, like, but it's just writing in the style of of I rather
than, you know, it doesn't have any actual, I mean, okay, it's it's it's begging the question to
say that it doesn't have any actual opinions, but and that might not be true depending on how you
define opinions. But when it says stuff about Oh, yeah, here's the line. I know that some people
might be opposed to wearing sneakers in a turtleneck, but I wanted to be true to myself. So I went with
a slim fitting turtleneck in a color more similar to my favorite color of the day. Right. Like, that's
that reveals things about a statistical model, but I don't think that's GPT two expressing
its own opinion of fashion. And I don't see how you get to the point where it would
have that internal any anything more that's, I don't know, it's it's difficult, and it needs
very precise language, I think to talk about, because you don't want to bake in assumptions
about what it means to understand. Yeah, no, I absolutely agree. I just the the only place I
get hung up is that I don't know how we form a concept of self either, which is why I'm like,
who knows, right? I think you may need a body, though, to have a concept of self, because you
need something to protect from dying and to make spawn with before the concept of self matters at
all. Well, I mean, there's the like, does the concept of self matter? And I don't know, I think
I think that you could I just don't think that this is the way to get a concept of self. Although
I guess if you like, if you're not embodied, is there even anything that makes sense to be a self?
Did you read Dan Dan, it's where am I? Yeah, that's the second time I've ever
referenced Dan Dan at this episode. But yeah, I mean, I think certainly, maybe if you never had
a body and don't know what those concepts are, then it would be harder, right? We have all that
because, well, I mean, it was forced on us by evolution to live. Right. So well, I mean, we've
we started out simpler, you know, with maybe, maybe motion being the first thing that we could
that organisms could do that, like, was an actual thing that this particular organism could do,
right? I mean, obviously, there wasn't a sense of self at first, there was just stimuli and
response that would increase how often a thing didn't die. Right. I guess what I was getting
at is that since we have that that foundation, except from, you know, very humble beginnings
that's been overlaid all this time, that it's hard to imagine how, like, we could take that away
from you now, we put your brain in a vat, and you'd be like, I still have stuff, I have thoughts,
whatever, because you have all that architecture still in that brain. I think a sense of self is
like having a history. If, you know, we took you and made you a brain in a vat, you'd still have
memories of your life up till now. And GPT two doesn't have memory. Yeah. Yeah. Yeah, that's
more distinct way what I was trying to get at. Memory would absolutely have to be vital, too.
Yeah. Yeah, but you could hook it up to memory. Which might make it conscious.
My knowledge of computer science is not good enough that I could say how you would do that,
but you could you could hook it up in a way that it would have a history of its own actions.
Yeah, but you don't you'd have to alter a lot of things about how it works, because, like, it
it has a top K parameter of how many tokens it looks at in the past. And it gets kind of
bad. It gets kind of bad at text generation, if that's too big at the moment. I mean, I think
the default is like, it looks like 40, 40, like words in the past. And if you set it to, like,
look an infinite number of words in the past, and you just help to keep generating, it gets
weird pretty quickly. I've heard it likened to sort of a dream state with mines, the way it
meanders. And you said earlier, too, that it tends to lose its drift and just go things. Does it
feel at all like a dreaming mind to you? Yeah, it does. In kind of a different way
to a dream, I guess. Like, I can see sometimes, or I can, well, okay, I can think that I see
how it got from one thing to the next, right, how it how how that drift happened within it.
Because it does, I was doing the magic items thing. And it said something about a blizzard,
right. And it was describing this magical item and included the word blizzard. And then it
starts a new paragraph about Blizzard, the gaming company. So it is, it is like sort of drifting
from related words and related concepts in the way that is similar to dream.
That way, it sounds more just like a drunk person than a dreaming person. My dreams tend to be way
less coherent than that even. Like, it's just like, I'm at school, then I was at work. And then I was,
you know, there were zombies, then there weren't. And, you know, like, and there's no continuation
or like no, no reference to like, wait, weren't there zombies three minutes ago? Like, nothing
like that happens in the dreams that I can remember. Someone who was, well, I still know the person,
he's no longer going through a schizophrenic break. But I knew him when he was. And it was really
interesting, like reading some of his writings at the time, they start out, you know, coherent and
with an idea. And any time any within any span of like eight words or so, there's a coherent idea.
But by the time you get to the end of a sentence, nothing makes sense anymore. It's lost track of
itself. So you can see how like, from word to word, everything kind of makes sense and
chains along, but it gets you nowhere. It's nonsensical speak by the end.
Yeah, my experience with GPT two has been that a lot of the time it it's easy to read
humaneness into it, I guess. Scott McCloud is a comics author, and he wrote understanding
comics, and basically said that if you have two dots, and then like a curved line underneath it,
people will read that as a face, right? Because that's just how people are. We will, we'll just,
the simplest thing we'll just read as a face to us, because that's what's most important to us.
And I think that happens a lot when reading its sentences, you're like trying to find the meaning
in it. Whereas there's not always, you have to keep in mind that it's not there's not like a human
connected up to this that was expressing a thought. A lot of its sentences are grammatically correct
sentences, and then you read them and your brain is sort of trying to draw a context for what it,
what was meant by that. Trying to put intentionality there where there isn't any.
Yeah, like, I think communication is really a two person kind of thing where there's not just
the talk or there's the listener interpreting to, because a friend of mine posted on Facebook,
like, two or three lines about GPT two, and then another three paragraphs below that. And like,
I was kind of following him at first by the time I got to the third paragraph, I was like,
I guess either he's misunderstanding something or I'm misunderstanding something because I don't,
I don't get what he's saying here. But I was like, this is a pretty smart guy. I trust him on most
things. I just must not get it, you know, and I just kept going, like, interesting opinion, I will,
I will maybe look into it again some more later, ask him about it. And then the final line of his
status of Facebook update was the I wrote the first three lines, everything else was written
by GPT two. And I was like, son of a bitch. If I hadn't been like, reading into it, trying to get
intentionality and humanness out of that, I probably would have noticed. But the fact that I was just
kind of like, on autopilot and assuming he was saying something good was it did a lot of the work
for it. Well, I think they have a mental model of the person and what they usually kind of sound
like to fill in the gaps where this was sounding like not quite their style or something. Yeah.
That's pretty funny. Although I'm now imagining kind of the other side of the argument that I was
making with you before in Yash, where we're, you know, well, yes, there's words, there's no
intentionality behind it. I kind of imagine like the beginning of the first XM movie, where like
Congress, whatever that, the first one movie X men movie, where like, there's that government
committee sitting there talking about like, you know, mutant rights and stuff. And I can imagine
like, people in suits, making arguments, but like, yes, there's words, but there's no intentionality
behind these things like talking, like talking about like, well, those things as it wants rights
now. So I can imagine a lot of these things. I just, I had this picture in my head kind of above
of that. Yeah. Yeah, we should like to the post this article that Yash found humans who are not
concentrating or not general intelligences. Yeah. I think the overall gist of that was that you
can't actually tell whether GPT two is a human or not. If you're just skimming the text,
and a lot of what we do, I think it was not just us reading as humans,
but also like us communicating. Sometimes we're not actually putting like,
a large amount of intentionality into what we're doing. Some, some like speeches kind of
just there to be filler. A lot of it is like, I acknowledge you, you're human. Yeah. We don't use
those words, but that's basically it. And they're like, yeah, if you weren't really concentrating,
you're just kind of an AI running on an autopilot. I could relate to that a lot. I mean, I got a
haircut today and I explained, I explained, eh, I exchanged pleasantries with the person who was
cutting my hair. And I, you know, that wasn't a, that wasn't a real conversation. That was just,
you know, noises that made at each other just so that we could do business, you know,
that person could have been GPT two and you wouldn't have noticed. And at that moment, I was GPT
two. Yeah. Yeah. Yeah. When I do edit a GPT two, find that really, I find that really difficult
because like my mind will just skimp past the stuff that's not quite right. It's hard to catch
spelling errors. It's hard to catch like grammar errors because my mind will just auto correct it
to what it's supposed to be or what is the most logical thing for it to be. And then I will post
a chapter and people will be like, Oh, here, here are like 20 errors that like you read this thing
three times. I've had similar experiences. And they're the most blatant easy errors,
you know, like at one point I had a name wrong. And what the fuck? Cause I knew what was supposed
to be there. My brain was just like, Nope, that's the right name right there. Yeah, that's the fun
thing about this. We've got like a predictive machine trying to, you know, error correct another
predictive machine. It's kind of the whole like the Paris and DD springtime error where our own
brains will smooth out errors when we're reading stuff. So it's hard to catch them.
Yeah. Yeah. So I try to keep that in mind when when reading GPT two, and what it writes is that
it like I tried to use the editing mindset to sort of see what it's actually doing because
it's very easy to convince yourself that it's a person, I guess, with, you know, actual thoughts
and your mind is just smoothing out everything that it's done. And a lot of I think the examples
that people post not in the paper in the paper, they did non cherry picked examples for the most
part. But a lot of the stuff that people generate with it, they'll just pick the, you know, they'll
try to get it into a mode where it's doing exactly what they want. And then you get the cherry
picked stuff back with some smoothing from that too. So I think it can sometimes look more impressive
than it is, even if it's still really impressive. If that makes sense. Yeah, totally.
Dude, I want to, I want to feed GPT to the entire corpus of Chuck Tingles works and then see if it
can produce another one. Because that would be amazing. Yeah, I do worry about a lot of authors
being put out of jobs, not for like the filler stuff, whatever that that's, but like creative works.
There was a, there's Kurt Vonnegut novel where he talks about that for architecture,
where you just feed it in like a bunch of parameters and it will make you a new architectural work
with none of the, none of the effort required and it'll be just as original and beautiful as
what a person can do. And then the that's just like the end of architecture as a profession.
And I think about that for authorship, because I, you know, I love to write, but
I don't see how anyone would get value from it if you could just get the same quality stuff.
Like, regardless of whether it's general intelligence or not, or if it has any other
applications beyond that, if it can just generate works, you know, I don't, I mean,
certainly at this stage, there's no way it could generate any like high concept stuff,
because I think there's some things that you have to actually understand what you're speaking
about to speak about it. But on the other hand, a lot of the stuff that people read and that's
put online is, I mean, I know there's a military sci-fi that's like this. I know there's urban
fantasy like this. I, I use chuck tingle as an example, because a lot of erotica is like this.
It's really just the same thing repackaged and mixed up a little bit every single time. And
it's, it's, it's entertainment product, right? You read it, you have some fun, you enjoy yourself.
But that kind of stuff with like some more refining several million dollars and another
year of work on this. And I think the, the AI could replace all the human authors who are
right now just, you know, churning out eight, nine, 10 books a year that don't really do much
of anything except provide some cheap thrills. Or maybe some of like the easy filler stuff,
like, you know, like Robert Jordan describing landscapes and tapestries and clothes in a
wheel of time or like George R. R. Martin describing food. Like you don't have to know
anything about food to sit there and be like, okay, cool, savory, juicy, whatever. And, you know,
like, I think the wheel of time is 11,000 pages long, or wait, 11,000 pages. That sounds about
right. It could be seven if you cut out the descriptions of clothes and tapestries, right?
But even just things like, you know, basic character arcs and fun action scenes and people
like meeting friends. I mean, there's enough of it out there that's just written in mass that it
could, it could easily do something like that with some time. Is that a big loss though? If we
lose the lowest quality work? Someone who's attempting to earn their livelihood. I mean,
like, I don't want to take someone's livelihood, but I also want UBI. And I think that people
shouldn't have to be these kind of like machines that create low quality work in order to get food
on the table. Yeah. Yeah. Well, it's, it's, for me, it's less the food on the table argument,
but the like creative impulse, right? Because who, if, if machines can produce serviceable
erotica, right? And, and it's customizable because you can, you can, you know, fine tune
the prompt that you're giving it. And it's unique every time. There are a lot of people who,
you know, that's what they, if they had UBI, that's what they would be doing. They would be
writing, you know, not very great stuff, you know, lowest 50% quality kind of filler stuff,
but they have fun doing it and they like sharing with people. And then that just all disappears
because machines can do it better. And I don't know, are people really going to go for like
bespoke written work? But they won't need to. I mean, if the person's doing it for fun, then
they're doing it for fun. If they're not doing it to make money, then like they're going to make
it for themselves because they think it's fun and show it to their friends. And I still don't
think anything is lost because the machine can do it better. Like,
kind of yes and no, though. Like I, I don't do this show because people listen to it,
but if I knew that nobody listened to it, I would probably wouldn't do it anymore.
Yeah. When, when you write things, having other people read it is a large part of the joy,
even if it's just your friends, you know? Any for friends are talking about how they're
treating GP two fives latest book and it was way more engaging than yours. And it's like, oh,
well, shoot. I don't know. I mean, fan fiction is still really popular and there's like, it's,
it's not maybe good in the way that like, you know, a professional novelist's work is good,
but there's still something interesting about it. And I think especially because like you do
find it circulating around communities and there's no authors and like I would read my friends
fiction, even if it wasn't very good. If my friend was like, you know, I wrote this and I'd like to
know what you think about it or whatever. I think there's like a social aspect to it that I don't
think GPT two is going to do away with because you don't really care about like, you know,
you're not going to like follow GPT two in people magazine or like, Oh, what are they doing? You
know, and we still have to listen to vinyl. So like, there'll always be that like desire for
like the old vintage stuff that people used to enjoy five years ago, right? So yeah,
it actually wouldn't be that hard to eliminate podcasts, like the lowest common.
All you would need is like some transcripts and just text to speech. I mean, the technology is not
there, but you know, five, 10 years. Yeah, we'll better the job. I think there's some YouTube
channels that are like that already. Oh, there actually are. Oh, yeah, they're there. Oh, there's
some crazy the automated. You know what? That's a whole other topic, but there's like automated
programs that make videos for kids. Oh, God. Oh, I saw a thing about this on Reddit. Yeah,
there's a great Ted talk about it. If it's what I'm thinking of for like, it's bizarrely sexual
and stuff. I mean, some can get there on accident. Yeah. I mean, a lot of it is just, it's just the
recycled crap that three year olds love, but it can go in bizarre places because the machines
have no idea what they're doing. I imagine making just like standard lather rinse repeat episodes
of like teletubbies would be remarkably easy for a computer to do it and in today's tech, right? So
yeah, it'd be hard to imagine paying people to get in puffy suits to do that shit anymore
when you could just do CGI ones for a fraction of the cost and make them every three seconds.
And they take 30 minutes to watch. So yeah.
Yeah. Yeah, wild stuff.
I realized I have some dead air going on. I'm just thinking about three year olds being entertained
by these algorithms that any adult could see are just dumb, but three year olds really like them.
And how different is a three year old from like a souped up GPT to that? Plus, I mean, like,
not to put down people who enjoy some games, but like they make a new call duty every single year
and it's exactly like the last one. We like some amount of repetition as humans. Dude, I have sex
like at a rate that is less than more than zero. And it's not that different from time to time.
You know, a few things change up, but somehow I'm just liking those same motions over and over. It's
weird. All right. Tell Tubby's first person shooter video games sex. I definitely see how we
how we seem like GPT to robots jumping from from topic to topic.
What's your schedule like? Alexander, are we I think we're over your time. We had some delays
getting started here. Oh, no, I'm fine. I don't have that much more to add. As far as
observations or yeah, like what I've seen it do, or what the paper implies that the better version
of it can do. How long do you think until we get something like really souped up that'll
that'll make people question? I guess people are already questioning was this written by
an AI or a human but like that'll make people question does this AI know what it's saying?
Yeah, well, who doesn't know what it's saying that I think we're quite a ways from a lot of a lot
of there are a lot of expert systems right now like a lot of sports articles are just written
by computer already. And a lot of a lot of business articles to which is especially concerning
because there are also robots that read these business articles and make trading decisions
based on it. At some point humans will be out of financial loop entirely. Well, I mean, we're already
we're already getting painfully close to that. There was a there was a flash crash of the market
that was pinned on high frequency trading algorithms. It was like two years ago, right?
That happened in yeah, it wasn't anything that happened in like the fundamentals of the market.
It was just robots trading back and forth and then they like started panic selling of the robots
were it's just this this emergent system that has that not that much relationship to anything
that's actually happening. But yeah, there are business articles that are written by robots and
consumed by robots already. So this is sort of it's sort of a matter of GPT to which is an
excellent multitasker trying to edge into what are currently expert systems or expert systems with
some neural network back end a little bit. So I think we're basically there as far as was this
written by a person or or a computer because there are a lot of articles I've read where
I thought oh this is probably a computer right just because it for sports articles especially
they'll they'll just you know they have a list of statistical things that happened in the game
that were recorded by someone and they'll just spit out an article about you know what the
least likely things were or that are in a certain style but that's that's not
that's all bespoke it's not as part of a multitasker. I think I think it'll be you know in a year or two
we'll probably see something like GPT to being used in the wild as outside of like a novelty website
like Stylgan has a couple of them now like this person is not real. Yeah that was something that
probably started in Yash that's where that it amalgamated a bunch of human faces I want to say
like 10 million and then generated a bunch of human faces that don't actually belong to any
individuals they just look exactly like real people like down to the irises the eye lines and
everything and then this was this title and I saw a thing on the programming subreddit yesterday
where someone did this with anime waifus and it was like your waifu is not real or something
and then when I was reading it it was on Gwynne's website Gwynne put this together. Yeah I was gonna
bring that up because I'm an artist and there's a bunch of AIs that draw now when we were talking
about like writers being replaced by a writing robot there's already a lot of robots that do art
and they're getting better really fast and like that was one that hilarious one that just generates
anime girls it's that's the only thing it does and it does it really well so people were saying
well you could just kind of use this to you know if you have a text-based game where there's just a
static picture of a person like you could make a video game and just use this as your art engine
and not need to hire artists so that's happening that and as someone who likes to be hired as an
artist that's probably sad to hear actually I've found it really interesting so far I mean like
there is the concern about down the road or there's just going to be no artists I don't think that's
gonna happen I think humans like to make stuff too much and I think they also like to be paid to
make stuff yeah yeah there's the money thing too I just like you know I want there to be UBI and I
think eventually we're gonna have to deal with that totally like we've got robots now that can replace
humans um or the you know prototypes of that so we're gonna have to start having that conversation
but like I think that I'm happy that some of these tools exist because I find that they're
really good for option generation or for experimenting there's a lot of art that's boring
and the same thing with writing because I've written too there's there's the parts that are
really exciting the cool creative parts that you want to get into like oh what does this
character look like or you know I'm gonna draw a building that looks like this and then there's the
like now I have to draw every brick or every strand of hair and you don't want to do that part
it'd be cool if you could just get a robot to do that part yeah I think what we're gonna see first
is uh people working with robots like rather than then on their own um and a lot of that is going to
be labor saving especially the labor that people don't really want to do um I would love if there
were like an editing robot that I could just send chapters to and it could be like oh point out a
bunch of stuff and we're we're getting there's a pretty good editing tools yeah my experience
has been that they do a lot of false positives um that make the editing not really that much faster
so uh but I mean we're getting there yeah definitely but so as far as you know people making money
from art um the more labor that you can save I think you get better art out of that if you
you know one hour of human time is suddenly um if you can do in one hour what used to take two hours
you're gonna get better art out of that in theory I don't think we have a shortage of art right now
I mean there is more produced every minute than I could that I could uh consume in a month but
you know the hard part is I don't know getting not just something that's good but something that
other people are also interested in at the same time you want to appreciate art socially with
other people that's why things like we've got worm is so great yeah I I think for my my opinion is
that uh there there's so much art and media produced right now that you can choose to be picky
and it's more about um either the top like one percent of quality or um the uh what what your
particular preferences are as far as subject matter or themes or um or things like that and
that's where I think that's where I think labor saving helps a lot because you can sort of expand
your niche without um needing more people to get into it right like uh I don't know like if you have
a specific like you you want the 80s aesthetic right in your in your written work um there aren't
that many options for that and if you start piling in more stuff like if you want a sci-fi future as
imagined by the 80s um like how many people are actually writing that or like drawing that there's
not an infinite amount of that to consume so as far as either having that stuff automatically
generated you know from nothing by itself or labor saving for artists that's kind of where I think
the application is is just expanding expanding the long tail of media I guess interesting real
quick how do you um how well do you think this would work in things like debate as a debate partner
to pull up quick facts for you from the internet or to check what your opponent is saying uh
real-time fact-checking we are I do not think that it's very good right now um partly because if you
go I like it can answer questions but um let me find some of the ones that uh yeah it's not
actually concerned with facts right it's not going and looking stuff up on the internet it's
predicting what word is going to come after this word it can just make facts up wholesale so if
enough people argue that the earth is flat it can find you facts that that that's the case yeah like
what Stephen Colbert saved the elephant population by having his listeners update the wikipedia page
so this was one of the um they're in the paper they're a bunch of question and answer ones um
and it's much worse at the q and a stuff at the lower level so the public version is worse at this
but um like the answer what is the most common blood type in Sweden and says a right and that
is not correct um and it said that with 70 probability that that was correct so if it's
going to do false positives like that where it'll say oh i'm 70 certain that this is correct
and you just can't trust it all then you can't use it for fact if you hook it up to wolf from alpha
well that's the thing is like wolf from alpha is already there right i mean you you could maybe
do it for coverage of things that aren't in wolf from alpha or you could hook it up to
they excluded i think a lot of wikipedia from um from their web because most other uh texture
generative ai's use wikipedia yeah and they just didn't want it to kind of look like all the other
ones out there yeah and that was part of the point so you could hook more stuff in and it
would probably get more accurate you know to but it's that's one of the things about it is that
um it's a very good multitasker but for the specific tasks there's so many bots out there
and systems out there and programs that already are like hyper focused on those specific tasks
that you don't need a neural network for like wolf from alpha just is looking at databases of facts
which is all you really need for that kind of thing i think where i think where maybe there's
some utility is in parsing a question and like knowing what type of answer it wants because
some questions have are you know long and circuitous and um it's hard to understand
to summarize a question asking for that's funny yeah um so it might it might be helpful in that
for for questions or statements that aren't um that aren't straightforward or uh specifically
phrased for a robot did you hear the uh can an ai change your mind to debate i don't think i did
no there there was uh kind of don't remember what podcast i heard it on probably the reason
podcast now that i think of it uh or maybe no no no it was the one of the intelligent squared ones
where an actual debater and an ai who i think must have been a gpt2 derivative uh or if not gpt2
itself uh debated they were given 20 minutes before the debate started the question uh something
about oh uh free kindergarten should be extended to everyone in america or something along those lines
and the ai debated for and the human debated against and i mean the human was obviously better uh the
he was more convincing and the ai kind of repeated at same points over and over and didn't
didn't it was obvious it didn't have a deep understanding of anything it was just so repeating
some surface arguments but it was surprisingly like articulate and you could tell there was
something there it just wasn't very good and that's what made me think maybe like if it had
been combined with a human together they could do a better job well yeah they could and the the other
thing is that you know people aren't perfect thinking machines and so if you just bombard
someone with arguments and like you can you could it'd be pretty easy to get an ai like this one
to or i guess a language model like this one because i don't think they call it
an artificial intelligence um but it would be pretty easy to get one that can
like do a gish gallop right i just bombard someone with sources and citations and stuff like that
and you don't actually need to make you know cogent arguments you can just bury someone under
that may be my dim view of how good people are at separating fact from fiction or
actually evaluating an argument on its merits but um i think that's i was just gonna say i think
that's held up in like psychological studies there are people that aren't paying attention
or that have like motivated reasoning and are completely swayed by the gish gallop style of
debate right which is what could make something like gpt2 kind of concerning the other thing
that i heard a lot of people uh scare mongering is maybe the wrong word because i think it's a
legit concern but uh talking about was fake news this thing could be really good at generating
fake news yeah yeah and anything where you just don't care about the truth you just care about um
sheer amount of words generated you can you can you know it'd be it'd be so easy to set up
like a hundred different websites or um have a bunch of sock puppets that are just repeating
the same talking points with enough variation that you can't actually tell that they're sock
puppets right i mean that that sort of thing is done precisely now but you tend to have people
behind it doing it yeah and so i mean yeah you could you could do this on an order of on a scale
that is not that would make it so hard to weed past all the bullshit um yeah if you didn't actually
have to have people behind this writing all these things then yeah this wasn't the first time this
sort of thing had crossed my mind for this conversation and the level of talk text analysis
and stuff kind of brought a couple political figures to mind as well um and in the disregard for
you know basing their the assertions in facts uh rings a bell as well um yeah that's that's
disconcerting and i definitely don't see how that's going to be dodged i mean they mentioned how
they're not released in the full version but you know like you know i said that's going to come out
eventually but i do like that you know trying to pump the brakes a bit and say hold on before
this thing gets out of out of control let's let's try and get some conversations going about
how we're going to tackle this well in the debate where you could really tell it was an AI was the
the second part where they like responded to each other uh the AI didn't i mean you could
tell it didn't know what the other person was really saying it didn't respond like a human even
if a human didn't know the answer and was just trying to gishgallop you they would find a clever
way to like bring things around and dodge the question and stuff and the AI just basically
acted like there hadn't been a question asked of it it was it was interesting i think that
with things like this at least for the next year or two we could pretty quickly weed out
the human from the AI by going with follow-up questions well yeah but i think there's a couple
things with that one i'm brought to mind of a bad debate i saw between janesha susan peter
singer like 10 12 years ago oh but they just talked past each other the whole time well no
you're talking about a singer was engaging everything and didn't ask just use it was not
and he was just really he was just making this he would make the same things over and over every
time it was his turn to talk yeah politicians do that too i mean they're actually trained to do that
you don't actually engage the question you just like talk about the thing that you you know well
here's what i think about the economy it's like that's not the question at all and my my concern
isn't so much you know so that we won't be able to discern whether these authors are people or not
because i mean right now you know these russian bots are people but that doesn't really matter
like i could talk to them if they were willing to engage and discern whether or not they're
robots but the point is they're putting out enough content that's has enough clickbaity
shareable stuff to put on facebook and twitter that it it gets spread out and nobody bothers take
the time to sit there and analyze like maybe this is not a person maybe this isn't true yeah and and
on top of that uh you have selection effects in place right so if you're having bots generate
a million tweets it doesn't matter if half of them are crap or even you know 90 percent of them are
crap that are like obviously robots the the stuff that's going to get shared and then seen is going
to be the stuff that's the most human like and the most compelling yes so i don't know it's going to
be a problem it's already i mean it's an extension of the problems that we already have though which
we already can't solve so a quick question i have i've sort of gotten to the point where i don't really
believe anything anymore if i see it i'm like that's interesting i wonder if it's true and uh
are you i think this might be bad in general for human society is do you guys find yourself
reacting that way to the just overwhelming mass of disinformation out there or what strategies
do you use i do that all the time and there was that uh the most recent example was who was that
actor from not the wire i don't know that actor who paid people to beat him up and then claim he
was assaulted by trump supporters oh yeah when i heard that he was jumped by trump supporters out
leaving something uh someone told me about this i was like oh man if that's true that really sucks
is what is what i actually said and then it turns out it wasn't but it when i hear something that
sounds like it really fits a narrative especially you know and there's there's you know other other
side news too that could do the exact same thing where it's like oh that yeah that sucks if that's
true and you know it swings the other way um i i would like to think that if i cared enough
i could dig into any each any individual instance and see if there's something to it but even i mean
that could take a day you know to see if this author's real or something right like that that
could take forever yeah there's on one hand i want to say increasing the amount of skepticism out
there is a good thing for humanity like i would actually like it if people didn't believe everything
they read on the internet or saw on facebook and fact checked it first but uh there's the extent
to which like how easy is it going to be to fact check some of this stuff yeah and also yeah what
steven was just talking about it fact checking everything does get to be really exhausting and
do we have heuristics for a reason because we're trying to conserve like mental power for things
that are actually important rather than like is that news story true yeah totally i think even
just fact checking one thing can be exhausting like i said i mean if you're digging in to see if
did this really happen that could take most of a day um and since you don't have time for all that
your heuristic is what feels the most emotionally true to me right yeah but i mean like it's not even
so much just everything because you could especially like skimming through a twitter feed or
something could cross 50 things and that would take you two months but like just one thing i can't
think of anything i've read recently that i cared enough about to dig at for half a day but i think
my current strategy is like i'll see something like huh well i guess we'll see what happens in
the dust settles in a couple weeks and then usually if something happens there's follow-up and i'll
get something on it from that um i i mean i try generally not to talk about very recent things
on the podcast for that reason like baby it's entirely different from what we think and i also
do the uh my main rule is i don't share something before googling it and i mean that doesn't read
out everything but that is that is so far above and beyond but almost anybody does that's super
awesome well i mean it doesn't read out everything but it gets like the most service level obvious
crap out the door right away and you know just if i don't want to share something i
don't necessarily google it i'll be like well interesting and you'd like to say if that's
true that's a bummer but if i actually share it then i google it first yeah i tend i tend to
completely ignore uh anecdotes like things that happen to one person as being not irrelevant but
like there are so many things that happen that a single person is always such uh
you know that doesn't tell you anything about statistical distributions right you're like oh
that's one data point yeah it's it's one it's one data points you know because of the way social
media works it's the most um usually it's usually the most metraulic and biased data point that
compelled people to share right um whereas i care a lot more about the statistical trends or like
hard data i tend not to read you know news articles anymore um especially since most of
them are like a mangling of some primary source yeah like for for gtp2 you know i'm gonna there
there are people i trust on certain things but um i would way rather just go read the primary source
and spend my time on that and then question the biases of that author you know as a better way
even even studies are you gotta worry about p hacking you gotta worry about you know all
kinds of different stuff if you read the primary source of the study too but there's so much of
news that i just have to like push to the side as being basically irrelevant to anything because
i mean as people were very individualized and we focus on those individual things so much more
and that's always what gets the most play as far as uh outrage culture and stuff goes
i don't know it's one of those things i think about a lot um but i basically just have to
sequester myself as a coping mechanism how big is gpt2 like if i were to want to download it and
run out of my laptop would it melt my machine or nope it is uh it is 4.5 okay no that i got i don't
i just downloaded a virtual machine um for it which was four gigabytes i think um you do not need
that much if you are going to go through the work of setting up um python and the dependencies
and stuff like that but i just downloaded a virtual machine that was open at the console window
so i had to could skip all that stuff but that um and it runs on my uh netbook just fine it takes a
while like you put in your prompt and then you're just waiting there for you know 30 seconds or a
minute or something because it you know um it's a netbook and it's uh underpowered but it's it's
not very big i mean it's not it's not that much work to run so it it doesn't have the
storage of everything it read with that four gigs does it no the everything it read is 40 gigabytes
so this is just the neural network that was generated from training on that 40 gigabytes okay okay got
you got you yeah so i am the only stuff it knows is stuff that's in the neural network like it i mean
even in in its full form it's never referring back to any articles or something it's just referring
to what's to the weightings in the neural network that's so cool so you're an author have you tried
to make this thing do some work for you like write a short story or two and try to sell it
somewhere uh not yet i was thinking that i would try to do that just for the novelty of it i don't
think it could be cool for idea prompt yeah well and i said i was trying to do magic items for dnd
because i i write a um i write worth the candle which is a lit rpg and it has a bunch of dnd items
and i was like yeah i could just make new ones or at least get inspiration from it
middling success on that um because it it kind of like it kind of likes to wander off or just
it's like do nonsense in the style of item descriptions because you feed it like five
item descriptions and hope to get a sixth back and it just is like it's in the style of it but
it's not saying anything and it's not even that good for idea generation because it's just it's
just words that that like i'm trying to make sense of i don't know i so i i haven't had a lot of luck
with that so far um i'm going to be trying more short story generation tonight to see if you can
like hammer something into shape because i do think i do think the promise is in the centaur
approach but it's a question of i i think i'll probably spend more time on it than if i just wrote
a short story because like to write a short story pretty fast um trying to do it with a computer
and then editing all of its like garbage into something that makes sense on more than just a
surface level i i want to try it but i'm i'm not optimistic at all i would be fascinated for you
to get back to us like in a few days and just let us know how that went yeah i will cool
all right well i think we've been going on for a while uh we should probably wrap it up is there
anything any of you guys wanted to say ask i'm still feeling pretty bummed about how we're talking
about this is just this nightmare fake news factory is there any good news or any any
any optimism we can draw from this development hey soon humans will be obsolete um better machine
translation better question answering um better summarization of news uh which is i mean we might
run into the problem where uh you have ai generating fake news and then ai summarizing that fake news
but um we were just talking about how it is hard to uh do fact checking um that would be a lot easier
if you could do automatic summaries of of various things i don't know how i mean that kind of
somewhat defeats the purpose of a deep dive but um it would help a lot to to be able to
have automatically generated abstracts at least so that you would know going into um reading through
an article whether whether it was worth your time or not if do you if it could do like get at least
get you the central thrust again summarization one of the things that it's worst at and still
pretty good but that's interesting because like there's those like summary bots on reddit that
you know you link to a news source and it'll give you three paragraphs synopsis of it which it just
grabs direct quotes i think yeah it does uh i think the most popular one is a it does sentence
entropy so it's like picking out the most important sense sentences from the article
but that's still pretty good because there's a lot of fluff in a lot of those articles
yeah i love those summary bots it i mean if i carry enough i'll read the full thing but i've
done that where i've compared the full thing against the summary and yeah it seems to capture
mostly essential information and i think that's pretty interesting yeah so this could be even
better than those at summary and abstracts drawing and stuff so yeah i i think there's some good news
um we'll have to see what people actually end up using it for
yeah i guess we'll see right uh was there anything you wanted to say and you should also plug worth
the candle real quick and tell people where they can find that yeah uh worth the candle just google
it i guess it's on it's it's on archive of our own um it's got a long url and but i think it's the
top result and if it's not just we'll add a link in the show notes as well yeah uh but that's fine
that's that's the current thing i'm writing um i'm always writing new stuff so uh i one of the
things that i am currently working on as sort of a my second project for when that's done is um
um one that's based around this kind of thing um of like the the marriage between neural networks
and automatic generation systems and how we sort of use them and react to them so that that'll be in
like a year or two though so sounds awesome all right well thank you for joining us yeah thanks
for having me yeah it's a lot of fun and if you uh if you give any results back from your your
experiments tonight in the next couple days let us know we'll we'll include those too yep okay sounds
good cool good night all right good night okay on to our less wrong post discussion section of the
show okay uh the two well the first of the two that we're doing today is so you could not attire
versus the egalitarian instinct did i say that right you said close enough you said the first
part right you said you said egalitarian it's egalitarian so you got the English I was focusing
so much on the Japanese so you you you japaneseified the english word yeah all right yes no worries um
all right so the my my one set in summary of this is just like kind of where we've evolved impulses
as social primates to like not want to i guess showboat when we're being exceptional um but
basically this doesn't mean that we shouldn't try yeah and that you know there there might be good
reasons for humility to to i don't know not say how easy something was or you know yeah i guess
i am the best at that but you know that doesn't mean that you shouldn't actually try to be the best
yeah so i think it is just maybe i'm assuming this is some response to feedback on the tsudokunai
tie up this on post but it seemed to me i don't know it seemed like it was just a post script to
tsukunai tie and they could have almost been one post but here's the weird thing i recall the first
time i read this being like really i don't know if moved is the right word but i was like yeah
that's right exactly you know going along with it i was like i was very happy to see this and now
going back and reading it it it didn't really touch anything in me at all and i don't know if
that's because i've changed or what but you're just less humbled now yeah maybe you just totally
took it to heart and you're reading it now and you're like yeah obviously oh right but it basically
are you familiar with the the this was made all the rounds i think about a year ago it's
been going on forever though because obviously hunter-gatherers the insulting the meat thing
okay there's a there's a not a hunter-gatherer tribe anymore but like a a tribe that's still
very much in the old living sense uh and they hunt them they hunt for meat and uh if someone comes
in with like a really impressive game uh a catch that they you know they did most of the work themselves
they everyone knows they did this right uh when they bring in the meat they're like oh man this is
bad meat and like everyone in the tribe insults the meat oh i did hear something about this recently
yeah where did i hear this i you wouldn't know but right recently yeah it was but it was everyone
knows it's good meat and they're still all impressed with what he did but like they say yeah we gotta
we gotta keep people humble you know so they don't get too big heads or anything and it's it's a it's
a weird it's a weird ritual but a lot of like every society has that right yeah some more than others
i think i just saw this like in a link in the slates in the comment section of a slate star codex
post on reddit or something it was nothing obscure but i just saw something like that in the last
week where it was like don't insult the meat and it was a hyperlink and like what the fuck does that
mean so i i i just read about this okay yeah so so the goal is to keep the the the triumphant
murder of this i guess not whatever that the successful hunter of this of this food humble by
saying it's okay yeah okay yeah i've had better yeah right yeah i don't remember liar liar that was
yes classic that was that line reminds me of did you are you was that a direct reference or was that
an answer no i didn't uh i haven't seen it oh it was it's a great movie if you can't if you can stand
whatever late 90s or early 2000s jim carrey um the promise is he can't lie for a day and he's this
asshole lawyer and he first discovers this when he takes he's got some girl that he took home for
the night and then boss always was boss yes he was like that was great night huh and he's like
i've had better he's like laughing himself in the mirror he's like why would i say that
all right yeah that's my movie digression it's that time of the night i kept it together for the
podcast or for the for the guest mostly so i'm proud of you i'm all over the place thank you
but um yeah it was basically a post pushing back against that thing you know what if you
do keep trying to make yourself strong and make yourself better you will be you know
possibly better than some people you run the risk of succeeding exactly yes and that's okay
just keep trying your best there'll be other people that are better than you in most of their things
and that's fine too people are not all the same and different people can excel in different things
and stop trying to stifle everything and keep everybody at the same level of meh yeah i like
that there was um a just in the insect in the interest of everyone being egalitarian
yeah and i think it's tough because there was actually a good a good little quote in there
that i didn't pull out that was um you know you might be better than than the average person
at some things but you know the average person's better than uh people who are below average at
things by definition right and so you know somebody could charge you with like why would you try and
do better than them that's so rude of you and it's like oh well come on we're not going to buy that
you know it's like i i might suck at math that doesn't mean that you should like suck at it yeah
that you should suck at it too certainly what if anything it should mean that unless we have an
agreement like we're friends that won't be offended for better than me at it that you don't rub it in
my face right if i if i if i'm thin-skinned about it or something but that doesn't mean that just
because you know people are people in your tribe aren't uh you know i think that is if you try you
might run the risk of actually succeeding and to i just it doesn't even seem to in my reading of the
post didn't even really seem to like admonish that you ought to be do express humility it's saying
that it might be politically savvy for you to be to express humility if you absolutely must
yeah express humility then i guess go ahead and do that seem to be kind of the vibe going on there
i think yeah it was sort of a take pride in your accomplishments sort of feel and i think one of
reasons it probably talked to me more back then was because i had i was closer to high school
and in high school there's a lot of like you know you get nerd shamed or at least back in my day you
did you know nerds are totally except now in yosh you know what 19 they control the world now so now
they pick on jocks in high school is this how it works i think they get the robots to beat them up
oh sweet we didn't have robots back in my day you couldn't just like flash your iPhone at someone
and stun them i think it is i think it's partly a cultural shift too i think it's only been recently
and i guess i'm not super into the community or the cutting edge but you know i talk with people
in the rationalist community who are working on trying to find like non-asshole ways of saying
yes i'm successful and it's because of rationality like that's that's a to in edges at least to the
community that i'm i'm involved with directly that's sort of a new position like you know you
don't want to be i don't know saying yes i'm doing well or something right and you know to give it
credit to this i think that's kind of where we this post was going is like hey if you guys start
kicking ass because you go to cognitive sciences and binds it biases and stuff uh don't feel ashamed
to plug the old rationality thing i think a lot of that was just beat into i don't know us in general
but me anyway in high school the you know don't display your smartness because you'll get punished
and this is like saying you know what fuck it that's a lot of religious communities too there's
like the whole idea about how you're not supposed to take credit for things you have done because
god did it and nobody's better than anybody else because we're all children of god yeah i gotta
say that that maddens me a lot whenever i see some of that sentiment you know isn't god great
this happened and i know we've been railing on religion lately maybe we're on a kick but i i
don't like that sentiment because you never see it in reverse and it's like oh man god sucks he
just killed all those babies in new orleans because that's not god's fault but the response to it is
when people give money and time and run out there to go help that's god helping like no that's people
helping we don't make the weather we just we we help and i i love that there's a charitable
interpretation of this sentiment like look for god in the human response that sounds like a you know
almost uh mr rogers vibe right and that's super wholesome and friendly like no no look for look
for kindness in the response to tragedy and that sort of stuff i like that yeah but attributing it
to an agent rather than like taking taking it from the person um that sounds like a drag yeah there's
ways it can be um phrased in such a way like i like that mr rogers rogers e phrasing um but i'd
have like seen it really explicitly being used to rebuke young people for being too uh high and mighty
oh yeah and again like i'm thinking about like specifically uh um i don't know so there's some
religions that seems to be the more uh fundamentalist ones like i don't know if it may be because i'm
trying to figure out where this kind of egalitarian instinct maybe comes from i feel like psychologically
there might be something useful or there might have been if uh and you're in like a pretty scarce
society to tell people don't like push yourself up as being higher than the rest of the community
because they need everybody to be you know to be prioritizing the community not that i'm trying to
say that i disagree with the post either but i'm just trying to figure out where it came from
you know this is on my mind because we were literally just talking about harry potter before
the show started which uh if you are a patreon sponsor you can hear it's for our patreon it's
only in the extras bits uh but we this we were saying like how some people really hate harry
at the at the beginning of harry potter the message of rationality right and like i even knew
someone who very nerdy good friend of mine very smart started reading it and was like harry potter
is such a little asshole he's like a jerk and he's all arrogant and jumped up and when we were
talking about this just now i was like harry potter was fully embracing the tsukunari tai versus
egalitarian instinct he was like i'm you know here's some things i'm good at there's certain
kinds of smartness and i'm happy about it and proud about it and i'm not going to like hide it
and try to pretend that i'm a muggle there was a great line in the latter part of the book it was
during one of the wars when it was just him and neville versus harmonies army and the rest of
of chaos legion was fighting dragon army and he was like what am i supposed to be the last person
in the school to notice how awesome i am which is about as arrogant as he gets but this was like
i think i brought this up with um in my undergraduate uh uh psych major i had to take an abnormal
psych class which was like the whatever psychological diagnoses for disorders and stuff
and it was like one of those stadiums eating things there's like two three hundred people and
i was conscious of in the balcony because i was up there and i'd be raising my hand to ask questions
and the teacher was you know was willing to engage me shouting over the balcony and one of the
questions i asked was like narcissism or something narcissistic personality disorder and i was like
what if you really just are as awesome as you think you are like was isek newton a narcissist i mean
he'd probably been a nightmare to interact with but he he basically was as bad as maybe as he
thought he was right yeah so like is is is the grandiosity is the delusion of grandiosity
a necessary requirement for this disorder and i i think i don't remember what the answer was probably
depends like if it's ruining your life is basically when it's a problem okay or when it's
making everyone else hate you which i guess would ruin your life yeah um that that friend of mine i
think she specifically didn't like harry because he talked back to adults i've heard that from a
lot of people who've read the story particularly adults who have kids or our teachers but um
that's really weird to me because it's like this okay children should be submissive mindset which
if the kid is right then the kids right you gotta like you know as the adult you should be a little
bit more modest and maybe be like oh i think it's that same instinct if people should know their
place in society you know like you know act like they're better than everyone else yeah and you
can send them to be you could see where it was adaptive probably you know back in the day for
kids to be submissive but not anymore not as much yeah not if they're harry potter james
evan's famous yeah i think the hard part is that like in a lot of ways most kids aren't people and
like that's one of the things that harry points out is like oh sure i'm not a person i'm just a kid
and something to that effect but like the the the parent who has to spend an hour arguing with their
you know the hunter gatherer parent arguing with their kid about like why you shouldn't go over and
play they're not near that lake that's full of alligators like that kid's just gonna get eaten
right because they're gonna either not agree and they're gonna go over and get eaten or they're
gonna burn their parent out or whatever right well even we sort of have that now with traffic right
but even the parent that has to argue with their kid in the middle of a grocery store why they can't
have another you know bag of lollipops or something is is gonna feel that same way yeah i'm really
interested in running the experiment on my niece that like just treating her like a like a human
adult the whole time because it worked on my cousin but she i think she's exceptional i think you
know we'll see where my niece is i'm sure she'll be great too but like just you know i could imagine
being at the store with some screaming kid but i guess i'd not mind because my mind wouldn't do that
whatever but i think if you have the rapport of like being a reasonable person to engage the
whole time which the hard part is like kids can't you can't reasonably engage i know we're pretty
far afield but whatever when they're kids and they they're just mad and they don't know why
like they they they can't articulate their own feelings um quick side side bar uh anaharis
sam Harris's wife teaches meditation to children as young as five and six teaches what meditation
oh um just basic like introspection but they can get children i think around the age of five
plus or minus a year to like label their emotions and just the presence of minds to be like oh yeah
i am happy or i am sad like that that reflective awareness of your emotional state a lot of adults
don't have that exactly and so if a kid can look in and be like i'm mad right now and you know if
if they're aware enough of that i think that must i imagine that that's the kind of trial
you can engage with you know in who's having a fit in the storm like you're you're upset right now
aren't you do you want to talk about it um i think i don't know well i i'm kind of the best part
about being an uncle as opposed to a parent is that like the kids not my problem so like if it
just won't shut up i take it back to its mom's house and it's it's her problem again right like
they're referring to it isn't it yeah now it's it now that it's a problem she's not a problem she
she's the person which is fine when it's making noise and it's annoying i for i don't know until
i was in my mid 20s always just treated kids like people like other adults yeah i mean not as
experienced but whatever and kids seem to really love me which i was like okay that's weird but
sure whatever and i didn't really put two together uh then i started being socialized with how adults
are supposed to treat kids and like now it's really hard for me to go back uh but yeah kids not not
nearly as fond of me anymore i think you just talked to him be like hey what are you up to you
know what do you know i don't know talk to him like he would a person right now now it's a weird
thought maybe it's harder to do now i don't know why i just i've gotten to the point where like oh you
are a fragile alien object and i like a pet or something yeah no it's it's much easier to interact
with kids on that level as if they were a pet i had to deal with a lot of kids when i worked at the
library and i had a really hard time trying to treat all the kids like people um the thing with
methods of rationality and i'm trying to form a coherent thought here there's some kids that are
you know uh prodigies i know a lot of kids that uh had been child prodigies really loved methods
of rationality because they related to harry a lot and i think um i really liked the harry
character because i could think back to being a kid and feeling frustrated with not being treated
like a person and i think a lot of kids harbor resentment around that so the reason they probably
really loved you is that they don't get that from adults in their life they don't get any kind of
validation of like oh your your feelings are valid you know this thought you had is interesting uh
so yeah i try to keep that in mind it does get difficult though with the kids that are
more frustrating to deal with you tend to have less of that kind of theory of mind going on
or are just like very impulsive or kids that have behavioral problems just act out and want to throw
things you know you can't reason with that kid as easily as you can with the kid that like is reading
nk jemisin right and like programming and python i i related to the character of harry for methods
rationality because i wished i was a child prodigy and i was like oh i wish i was that cool as a kid
but yeah i think unless you you had any desire for that sort of of outstandingness or were that
kid then you know i could see i'd be off putting some people i think we were talking about like
some of the critiques of the of the of the character before we started recording and one
thing is that like people who don't really know what to expect they get into it they're like that's
not a 11 year old this is stupid and it's it's not like the the author's unaware that's not how
11 year olds usually talk and there's an innuent universe explanation for why this kid is weird
so yeah he was also like an author mouthpiece but i think yukowski was a child prodigy he was
and and he was there are a lot of girls that do talk like that yeah i've met some um it's uncanny
i bet yeah i think uh it was it's a it's a an aside thing but yeah um
should we yeah the the last i'll read us on to the next one with the end quote from this last
post which was said i couldn't i tie i'll always run as fast as i can even if i pull ahead i'll keep
on running and someone someday it will surpass me but even though i fall behind i'll always run as
fast as i can and that's yeah that's that's sort of the same spirit you know like i don't have to be
the best in the world won't be the best me that i can be yeah i really i the way that you put it
last time resonated with me a lot is like i'm not going to compare myself to the olympic athlete i
compare myself to myself and i'm going to beat me yep i love that that it that should have been in
this that should have been in the thing that's that's why i paraphrase my head all the time now
cool um all right statistical bias statistical bias quite quotes in quotes uh so this one at
first really intimidated me because it had like a bunch of math and math isn't like an intuitive
thing to me i had to like sit down and analyze it to understand what it was saying and it took
some time and some effort but uh really it in my opinion you could have stripped out the math from
this post entirely it just seemed to be saying that when a system is biased to to not give a
correct result then running many tests will eventually it'll converge onto a result but
that may not be the correct result like for example if you roll a six-sided die you may not
necessarily know what side is going to come up but if you keep rolling it long enough eventually
you'll notice that the six comes up 16.6 percent of the time uh unless it's a weighted die and then
there's bias in the system and if you keep rolling at thousands of times you'll eventually get to
the six comes up like 21 percent of the time you'll be like oh that's interesting dies come up on
six 21 percent of the time okay which is it's just wrong but it's not because you were doing the
experiments wrong or doing the statistical analysis wrong everything you were doing was right it's just
the system has an inherent bias in it i'm with you i think the post could have been done without
math and part of me wonders if it was just like running with it with the theme of the last post
of like yeah it didn't have to be this smart when i wrote this but i am and here you go
i don't think that was an expressed goal but uh it's it made me kind of chuckle when i thought of
that um the example he gave was the emperor of china is actually 200 centimeters and if the
in the us on average people think he's 190 centimeters with a variation of like 10 centimeters
you can serve you can ask one person and he'll say he's 180 centimeters and they'll be off by 10
and someone else will say yeah he's 100 uh he's 200 centimeters and uh they'll they'll actually
be correct but if you keep serving enough people they'll all converge onto 190 and that's through
the law of large numbers you eventually got to what the system believes his height is even though
they're off by 10 statistically or in reality rather they're off by 10 centimeters do i get
that right yeah i think so i'm just noticing how many of the the variables and the equations here
are e and y which are elia eliazard kalki's initials maybe that's why you got into math
this is from to keep his attention um yeah i don't have much to add to that other than i
this is one of the posts that like i think it sets up for for other posts better than it does
stand on its own and there's not a lot to really you know gain and run with here it doesn't inspire
me i don't remember it in a way that you know anything like that sometimes systems will be biased
and give you information that does not accurately reflect the real world no matter how much you
no matter how good your methods are yeah i think this post was meant to specifically
lay groundwork for and lead into the next one the useful statistical biases
but uh in of itself it's kind of just stating a fact about statistics okay well if we thought
ahead with more than a couple hours before the podcast we would have read the third one with this
but you know it's a buying suspense for a couple of weeks that's all yeah um wasn't i gonna plug
something in a video game joke or something at some point i can't remember i was like oh that'll
go in the video game chat later and i remember you saying that and i don't remember what it was
oh well no one the world will never know yeah i've been playing through red dead redemption
two a little bit i'm not burning too much time playing games but i'm i'm being i've actually
been really busy the last month which is great um but playing that a bit and it's interesting like
uh i've i've complained about the game a lot and they're still like the clunky mechanics and stuff
and there's like there's this bullshit completionist stuff where like if you want to go through like oh
get get the hundred percent you gotta do a bunch of completely out of character stuff like somebody
who's like you know an outlaw trying to like you know do outlaw stuff to go collect like 50 of these
flowers it's like no fuck that but man it does a good job of making you actually care about the
characters like they went through a part where it's not really a spoiler some characters die
and i'm like oh shit not them and so yeah it does it does a good job going in that way in the second
half it like goes off the rails yeah oh i showed you the donkey reviews why oh okay okay yeah that's
where i got yeah i got i got past that part and that was okay that was sort of a drag yeah but then
it gets better again um kind of i'll spoil it off air um but yeah no new fun video games yet i was
plugging the movie polar with madison mickelson that wasn't that good but it was great if you like
john wick he'll love this movie um what else is new and fun i think i missed the chance to make a
joke about gd dp2 g g pt pt yes what was the joke uh which was that i started playing kingdom
hearts 3 and i'm pretty sure that that's what wrote the script for the game everything i've
read about in scene reviews of kingdom hearts 3 i totally see where you're coming from that it was
highly ambitious it seemed like a really like fun project like let's finally bring all these things
together but it was in its execution it missed a lot of the marks and had a lot of really annoying
components is that about somewhat up oh i'm particularly just talking about the story and
like the character dialogue is just so bizarre the story's gotten so convoluted over the you know
there's like then three console games and god knows how many handheld games i think it's like the
eighth one right yeah i think i can count just like gp t2 does yeah they've decided that all the
weird diversions and like all the extra characters they've added like everything is canon they're
going to completely commit to it so you'll have like mickey and then like a final fantasy looking
character walking through a world literally called the realm of darkness which is made up of black
lava with blue glowing bits talking about like the nature of consciousness and like souls and stuff
and holy shit just like what am i playing right now you keep getting like broken out of the experience
by just how like some bizarre stuff like people start talking about the fact that some characters
have like there's you the character and then you have a heartless which is your dark version then
there's a nobody which is what happens when a heartless is created and that's the extra stuff
and then there's also data versions of characters so like the main character will just be talking
about like yeah and then like that was the thing that datasaur did in the data world
dude this totally feels like the the jrpg's of like the early 2000s yeah i'm getting flashbacks
from the final fantasies around then i think final fantasy plays a big part in kingdom hearts
yeah so totally gotta pick up this kingdom hearts thing i think you gotta start from the bottom
or start from start from the early ones it's a fun game like i enjoy the game mechanics uh
some of it's kind of clunky and i don't like the number of qte's that they kept adding into it
but um the quick time events where it's like you'll be fighting a battle and it's like oh press
this button really fast yeah and now you do a cool flip thing but you're not in control of the
character you're just watching a cutscene spider-man for ps4 did that a lot well not a lot i guess it
did an okay number of those what i didn't like and i actually disabled this in the settings
where it's like you know you gotta slam the square button a bunch of times to lift this car
fast enough i'm like that's super annoying yeah it's you know my thumb clicks when i bend it too
much because i have i call it video game thumb from smashing a button too much um that's that's
not even really a game mechanic so what i do instead is in the settings you can change it to
where you just hold down the button okay and it's like i'm not gonna sit there and just you know i'm
not gonna it's not hard for me to slam this button it's just annoying so whatever um i think the
only game that did quick time events in a way that was fun and interesting was the first god of war
and the god of war for ps4 does that too okay and i like this still good with it yeah i think so
like oh my god the the game that i think really popularized them well okay the first game that
popularized them was dragon lair which was oh my god ridiculous but uh shenmu for the dreamcast had
that it was basically a movie where you like decided when you get to see the next act and when
you just want to wander around and collect toys and whenever you want to go see the next act you
have to go through another stupid quick time event thing we're like x pops up on screen gotta hit x
fast enough and then square pops up you gotta hit square and i was like this is bullshit i think
there was another good component to include those in is like telltale games where not deciding is
also a choice so like you could either you know tell your friend x or y or tell them nothing and
that also is like has its own notifications because that's that kind of adds like this feel of like
actual urgency and those are kind of fun but um man nothing else too exciting i've been watching a
show called fresh off the boat which is fairly popular i think it's been on i think it's on
its fifth season it's uh it takes place in the 90s and i guess a phob is it was a uh pejorative
term for for asian-american immigrants huh and like they're fresh off the boat people or whatever
i guess that's not a term i'm like i was married with yeah i never heard of that but they dropped the
tea so phob yeah but um the cast is fun the cast is almost exclusively asian which is a lot of fun
and to the extent that it's not they have like whatever the dad from twin peaks is like the only
actor i've ever seen in anything else who is of regular on the show you know it'd be great
if they have asians in whiteface to play the white people white people they don't have that but they
have is the best uh they have some good cameos um my favorite is they've had a ken jiang on a few
times as the main character's brother and he played uh chang or wait he played chang in community
and chow in uh hangover and so then this prompted me to watch uh ken jiang on hot ones which is
this youtube channel where they eat hot spicy uh chicken wings and then his hour-long standout
special which was not that good and he just talked about the hangover for like 30 minutes um but maybe
we want to watch the hangover again so i did that and then watch the second one which was actually
really brilliant it was exactly like the first one that we played every beat but in a way that
like wasn't recycled it was it was reused in exact i think in a very great uh recipe to make this
like an original hilarious thing while completely playing on exactly the same notes as the first
movie and then the third one which i didn't even know existed was just off the rails it didn't have
it wasn't a hangover they didn't like lose their memory and stuff but it was was like repercussions
of like the smallest bit from the first movie um you remember it doesn't matter the plot but basically
there's like this big giant mob boss that's uh john goodman because he's in everything it seems like
and he's you know go get me chow and i you know he's still on my goals it's just the dumbest plot
it was hilarious um oh but my favorite cameo on fresh off the boat was uh michael bolton
as himself oh cool and uh the main the main character i can't remember the actor's name
he was also the detective who uh or the fbi agent who kept ant-man under house arrest and ant-man too
um but he has a uh steakhouse that he runs and michael bolton wanted to like be a partner in it
so that he could finally destroy kenny logins because kenny logins has a chain of restaurants
and he's super jealous and so he's like we'll do this and together we'll destroy kenny logins
i think michael bolton in everything i've seen him in he plays the guy that he is in the um
the lonely island music video yes he plays that guy i think that's who he is in real life and it
makes me really like him as a person so michael bolton seems great um that's my super rambling
stuff might maybe not all that would make the air and just that's what i have enough to
nothing too exciting i don't have any video game stuff so you guys got my random tv and movie plugs
i enjoy listening to you talk about them even though i haven't watched most of these i don't
i don't consume a lot of traditional media i don't anymore i can use a lot of mainstream media so
tv and movies yeah reading for me is an investment that i try i try to read but i'm not a i complain
about being not a fast reader i know there's ways to fix that and i could just you know power through
i don't know if there is i've been reading a lot since i was seven or younger maybe and i'm
still not a fast reader but i guess maybe the way i could actually do it is dedicate solid chunks
rather than like it took me from saturday to today to finish uh saturday's chapter of ward
i mean that's just i'm reading it like in my spare minutes if i just set aside a 45 minute
window i'm sure i could have read this whole thing which i should probably start doing because
how do you feel about podcasts i can't remember if you like them or not i mean um
hate podcasts everyone who makes them no uh audiobooks audiobooks i love um because you
can convert the text of things to speech i've tried that i did that as an experiment during the
what event 2008 maybe 2012 debates they have some pretty good voices out there now i like
inflection is always wrong though i did it with the debates for fun because i wanted just to remove
all of the emotion and enunciation and this is how you feel and just get the raw text yeah
and i thought that was kind of okay um the the debate i was talking about intelligent squared
with the ai versus the human one of the major feelings of the ai was that it sounded not like
a human it did not know what things to stress what words to stress what sentences to linger on
and that really made its argument weaker even though i i guess it shouldn't the it's the facts
or the facts regardless but the way it was delivered just made it uncompelling there was a
at one of the the james randy annual conferences i went to the the amazing meetings they were called
there was um i always wanted to go to a tam they were okay uh seth fairy child that sounds right
and he was a politician and he gave he works for like the secular and that alliance one of these
and he gave some 45 minute rousing speech and at the end people were like standing and clapping
and i'm i felt really moved and i was like wait a minute this is like a political speech this
worked perfectly and i noticed as it was happening like how weird that was and then a few years later
sam harris was talking on his podcast about how like bizarre it would be to have like martin
luther king jr like over for dinner and have him talk at the table like he does in front of a microphone
he's like that would that would be crazy unerving right that's not how human talks but that's how
you grab an audience um and so yeah i think part of that would be lost translating stuff like this
i tried that like i said as an experiment with the debates and the 2000 whatever's um i don't
know doing that with something like ward i feel like takes a lot of stuff out of it yeah i mean
like on one hand uh i have found that there's some pretty natural sounding uh readers out there that
you can find but but then like i also am thinking like yeah but i wouldn't do it with ward because
i really like ward it's like the things that i like that invested in not a story yeah what i
generally do is just at the end of the night when i'm winding down i'll read in bed before i go to
sleep and that generally gives me a good 30 to 40 minutes and then i just kind of like drift
out to sleep really easily it's it's kind of works on two levels you know it gives me more
reading time and it makes falling sleep super easy yeah if i was more disciplined i would do that
instead of browse write it for 40 minutes before bed so i deliberately looking at a backlit screen
just for bed sir this is bad it's got the blue light shift and all that stuff i know but still
and i fall asleep immediately anyway i've never had any difficulty falling asleep so i deliberately
don't read before bed or i try not to because i'll end up just continuing to read and not actually
go to sleep really good yeah oh my god the monster borrow cormorant i just read so fucking good oh
what's that it's it's the second uh novel by steve dickinson so it's you should read the first one
before you read this one but you know i'm gonna be writing up a a review on it pretty soon it's
just it's a fantastic piece about revenge and and the limits of what you can force yourself to do
before you lose humanity and even if you're like doing it for a good cause and for an important
purpose just pushing yourself into these situations you do it for long enough and you stop
being a human that that is worth to have around anymore that sounds like it's actually addressing
a cool question yeah it's i mean set dickinson is fucking amazing he's i don't think he
self identifies as rationalist i call him a rationalist he's at the very least rationalist
adjacent he this is this is a uh like flintlock setting early gunpowder has just recently been
vented right and uh the main character describes hash functions in a way that's relatable to the
audience and makes sense in that setting and and just uses it as part of the narration i was like
this is brilliant i need to read this yeah it's a way of it's a way of describing how humans are
always alone and can never fully emotionally collect with each other because our actions
are hash functions of the of our beliefs and and emotions and things inside our head and we can only
like display like i'm crying or or these are my actions but it doesn't ever fully get from inside
your head to inside the other person's head and i'm like this is brilliant i had a a very long or
very short it's hard to tell analysis of that in my own head when i was on lsd one time that's that
exact same thing that like man i can never really any like you'll think you communicate it they'll
say they understand and you think they probably do but like you you never know and they probably
don't right because they can't because it's only inside your head but you can understand
a model of it and that's you try to make that as as accurate as possible um that sounds interesting
i feel like writing like i've actually felt like writing is basically a form of telepathy i mean as
long as you're not doing the unreliable narrator thing right but i think you can get pretty close
to what people are thinking by reading particularly like their blog or their journal yeah we talked
about it that a bit when you're reading that person on i'm assuming this facebook or something
they wrote that you know three sentences in the next paragraphs where the gtp2 um yeah you had the
model and you were you know reading their mind through what you thought were their words yeah
that's kind of cool all right so that sounds good to me we've got a patron to think this week
i think i did the last one but i don't know who's keeping score but our you know what we still
haven't done a lot of this feedback that's piling up oh god we promised with this was going to be a
our next episode will be a feedback episode this time it is really good too this time we mean it
yeah well this time it worked out because the gtp2 news just kind of came out in the last couple
what few days and about a week ago and uh alexander wales was available to be our guests
tonight so yeah we'll have feedback on next time for sure this week's patron is jason musgrave
i know jason musgrave really awesome oh cool cool all right thank you jason musgrave i didn't know
you listened to the show have fun yeah maybe another jason musgrave but probably not right
right that's awesome thanks we really appreciate it and thank you to all our patrons you really
make this feel more meaningful and i don't listen to it too like we were talking about yeah you know
this this is not no work it's not a ton but it's it's a bit and you know if if we were literally
talking to nobody this wouldn't be worth doing so thanks for listening if you like what you're
listening to you can leave us a writing review on itunes it also helps spread the word definitely
you can plug this anywhere you know if something i i i enjoy seeing the occasional reference to
like our interview with kassi come up on the methods of rationality subreddit
when people are like is there a word of god on when this happened it's like oh i know that like
on the beige and conspiracy podcast you talk about this i love seeing little plugs and it's not like
just not just from my ego but that's also people find out about stuff but also helps for the ego
too yeah i think i was listening to we've got worm reward and somebody said they found out about
worm from the youtube comment section of some random video huh and so like you know you plug
you talk about what you like wherever you want you might share something that you like with
somebody who you never would have had a chance to talk to about it so that too
all right thank you everybody yeah we'll see you in a couple weeks yeah goodnight everybody thanks
we're lgbtj sometimes
you
