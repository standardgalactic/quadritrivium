how it values things, how it thinks about things,
is its own devising.
It's just not as efficient.
It uses a lot of random generation of...
It comes up with ideas using effectively random number generators,
like variations of its own strategy, its own experiences.
And for reasons that are not yet clear,
there is a skill that humans seem to have.
There is a efficiency of processing
where they are able to parse out
what are good things to look at
much faster and more efficiently than AlphaGo on its own.
It's providing ideas that are much more than some of the parts.
So AlphaGo does all the really detailed looking?
AlphaGo looks all the way to the end of games,
many, many, many times.
Every second it's looking at thousands and thousands and thousands of entire games.
And humans don't do all that.
So AlphaGo spends a lot of processing power playing out games,
and the humans can spend a lot of processing power doing other things.
How they're coming up with these ideas is not clear,
but that's one of the areas that I think DeepMind and others are interested in trying to figure out,
is how do humans imagine things?
Like how are humans so good at imagining things?
But actually on your topic about the fighting,
that's already been proposed.
There's actually standing off already for robot versus MMA fighter now.
It's a tricky thing because I think that there's...
I'm assuming they would pad the robot or something?
I don't think that there's any...
I also just don't think that...
I don't know.
I mean, maybe you could find the right person,
but to me I think that it's a difficult thing to watch a human versus robot fighting
because it just seems so clearly like,
dude, you can just make the robot...
Like, I mean, I already have experience of what it's like to try to fight a car
driving 70 miles an hour at me.
There was a Rick and Morty episode that references that.
They did one of the inter-dimensional cable episodes.
It just flashes between these random bullshit improv shows.
And one of them was human-spiding cars.
And then like, oh, look, he's going for it.
And then, oh, no, he got tripped and he's being chewed up by the tires.
And then it's like, wouldn't the car just win every time?
I think that's exactly what would happen.
You just make the robot too hard to hit.
You can't dent-steal with your fists.
Right.
So there have to be some other rules.
If you hit it hard enough, it registers as, I don't know, something.
You'd have to make the robot vulnerable in some way.
It could be like a pointed system, like an attack 1-0 match or something.
But that sounds a lot less boring than watching a robot try and kill a person
who's like, agreed to try and not be killed by the robot.
Right.
I'm not a violent person, but I would watch the hell out.
I might watch the hell out of that.
I'd see how gruesome it was first.
Watching two robots fight each other, though.
I mean, it's one thing if they're just doing the whole spinners and flipping, you know.
But like, if they got to meet specifications with, you know,
if they look like people and they're cyborg, robotic or whatever,
and it's literally just remote-controlled and there's two humans fighting with the cyborgs.
Oh, that would be interesting.
Pacific Rim.
Yeah.
I got a feeling that if you just have the robots use machine learning in order to figure out how to fight,
it might end up being much less compelling of viewership.
It might be awesome, but I bet the window of where it's awesome to watch is relatively small
before both robots are, like, weirdly hiding on the edges of the cage
and, like, just spastically bouncing around in some, you know, like, unknowable pattern trying to position.
Yeah.
You know, they're trying to arrange all the atoms in the air into a way that...
90% of it is just them standing at each other, and then there's one flash of movement and someone has decided to win her.
Yeah.
Yeah, yeah, yeah.
So I'm not so sure that...
I mean, I don't know if you've ever seen...
There's a video on YouTube of machine learning playing Super Smash Bros.
It's weird watching.
It doesn't really play like humans do.
It mostly hangs out off the edge of the map, like, exploiting, being able to jump off the end,
and it bounces around in a way where it's just...
Yeah, it's not...
It's weird to look at.
It's like, okay, I guess this is Super Smash Bros.
Like, if you think it's obnoxious when people play Street Fighter II and they just do ducking,
or just trying to trip you over and over again, the AI is shameless about being exploitive in its strategy.
Because it literally has no shame.
The first thing we gotta do is program shame into our computers.
I don't know.
I feel like that might be how it all goes south, though.
I mean, yeah, well, what do you do when you're sufficiently shamed?
You lash out, right?
We don't want that.
If all it cares about is winning, it doesn't care about, like, shaming us right back.
You know, I don't know, whatever.
One of the current exciting next steps for AlphaGo is moving on to other games.
It's got new challenges, right?
One of the things it's trying to do now, which seems like it would have been unimaginable a year and a half ago,
is it's learning to play StarCraft.
Yes!
Now, this is fucking amazing.
Oh, yeah.
So one of the parameters that makes it particularly interesting is that they're going to limit it,
its number of actions per minute, to being like a human.
Because already there are programs, like, it's already...
There are already ways that people have demonstrated that you can literally just brute force certain things
by allowing the computer to just make thousands and thousands of operations in a minute.
It's like, okay, yes, if you're just a monstrous hive mind and you can control...
Your micro is just so far off the charts, you can brute force the game.
But instead, AlphaGo is going to try to learn how to play StarCraft
with only having as many, you know, as many operations as humans get.
You know, as many...
It's micro, yeah, exactly, being just like a human, but it just rely on its strategy.
That'll be interesting to see how that one goes, you know,
and actually Blizzard announced partnering with them in this way and letting them kind of go in,
because normally it's against the terms of service of StarCraft to let bots play.
Yeah, you're not supposed to actually have bots playing the game,
but they're going to allow AlphaGo to take a crack at it and supervise that whole thing, but...
It seems like if you ask first, and your Google Blizzard should be like,
yeah, that's... Okay, you know, you're not some asshole trying to, you know,
boost your score on the boards here.
Right.
You've asked permission.
It would be weird if they're like, no, no robots, that's the rule.
They actually partnered with a couple companies, like both Blizzard making Hearthstone
and Wizards of the Coast making Magic the Gathering, where AlphaGo effectively...
Same thing, DeepMind was learning how to read specs,
like the specifications by designers of what cards they wanted implemented for Magic or for Hearthstone,
and then writing a script for how to implement those cards in the digital versions,
the digital card games, because it's part of the language.
All this stuff has to do with ways... DeepMind is trying to learn how to think
and how to think like a human and how humans think.
And one of the biggest areas is with language.
Language is very, very, very challenging for machines.
And so to be able to read the specifications of what it wants,
of what the humans want made, and then instead of having to pay an engineer to like literally write the code,
AlphaGo would just write the code for the humans of what they wanted,
and they would evaluate how good was AlphaGo able to figure out what we wanted
and then literally write new scripts to implement it.
That's reaching into the scary territory, in my opinion.
Yeah, plus I don't want to be out of a job.
Well, I mean, that too, but...
And in the end of the world.
Right, just the fact that it would be able to...
I mean, at that point you're actually doing thinking.
One of the challenges, though, is that so far,
one of the reasons that one doesn't get publicized as much is that it's not ready yet.
It's not good enough at that. It was okay, and it got better,
but it capped out and still just wasn't good enough to do...
Yeah, they need to make some serious advancements because it's curved.
It isn't getting enough better to be...
It's missing a vital component of being able to figure out new things.
It can do derivative things, but it's missing a certain ability to grok novel concepts
that it wasn't making progress on yet,
but they're going to keep working and they want to revisit eventually after AlphaGo,
or after DeepMind, going some new ways to think.
I'm somewhat excited about this StarCraft thing because there's so many variables in StarCraft,
so many different ways that units can't interact,
and so many units you have on screen at one time,
plus the way they act with their environment,
it doesn't seem to me like a thing that is easily translated into a machine.
So one of the things...
Well, it's easily is doing a lot of work in that sentence, right?
That's true.
There's a reason it wasn't done 15 years ago.
Let's put it this way.
One of the biggest challenges is how do you simulate an entire game of StarCraft?
You can just play games of StarCraft,
but humans can only play so many games of StarCraft.
There's just not enough time in the day.
One of the advantages to go is that AlphaGo could think about...
AlphaGo has thought about more games of go than all humans have ever thought about, put together.
So it's a very different thing.
How is AlphaGo going to think about StarCraft
without being able to simulate the games all the way to the end?
Because that is actually impossible, right?
It can't play against itself.
Impossible is a funny word.
I don't know how impossible works.
The only three types of impossible are we can conceive of how to do it,
we just don't yet have the technology,
or we can't even conceive of how to do it,
but it's not forbidden by physics,
or it's forbidden by physics,
so we would need to have a new framework for how to think about physics.
All three types are just defined by what it takes for them to be possible.
That is a very interesting way of looking at impossible.
I'm going to try to remember that.
Those are the three types of impossible.
I mean, what is impossible?
I mean, impossible.
There are some people who think about the system as being all...
Like, it's just this is the only thing there is,
and all there is is inside of this.
But there's more than just playing with this.
There's more than just playing within the framework.
There's also playing with the framework,
