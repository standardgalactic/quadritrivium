Hi, this is the Bayesian Conspiracy. My name's Katrina Stanton.
I'm Inyash Brotsky, and I'm Stephen Zuber, and Inyash, do you want to introduce our guest for the day?
Yes, today we have on the line Robin Hansen, who is a professor of economics at George Mason University.
Yay!
Hello, everyone.
He's also the blogger at OvercomingBias.com, which is very popular among our circles anyway, and recently authored the book The Age of M.
That's right, with many other credentials besides that. For example, Robin Hansen also invented prediction markets.
Well, at least certain variations on them.
Certain variations of prediction markets.
And for a while, you had a prediction market running with DARPA, right, as a sort of a research thing?
So most recently, it was IARPA, which is a spin-off that's kind of like DARPA.
We had a research grant with them, most recently on science and technology questions, a little bit before that, on world event questions.
That's in the last six or seven years. A long time ago, I had a DARPA project in 2003 that hit the news when it got killed quickly.
I remember hearing about that. I didn't actually realize it was you at the time.
I don't think I knew about the whole less wrong rationality scene yet at that time.
Well, we're really excited to spend most of our time together talking about your recent book, Age of M.
But I was actually hoping I could ask you some other questions about your involvement in rationality.
Sure. It's all fair game, until I say it's not.
Okay, well, that's fair. So when you started the blog Overcoming Bias, what was the state of the rationality community at that time?
There wasn't one, I guess. There's lots of people in the world who think they want to be rational, but they didn't see themselves as part of a community.
Did you have correspondence with those sorts of people frequently before Overcoming Bias became a thing?
Well, I mean, I've always had correspondence with lots of people, and many of us share common interests.
I'm actually not so sure it would be that different a group of people if they identified them around some other theme.
So once upon a time there were people interested in futurism and futurist things, and then there's rationality and more recently effective altruism.
And these various labels attract somewhat different groups of people, but honestly not that different.
They're mostly relatively smart, sincere, mildly contrary, and people interested in the wide range of topics.
What was your goal when you started the blog Overcoming Bias?
Well, my colleagues had started a blog a little while before, and I was being left out of the whole blog thing.
So I wanted to have something to talk with my colleagues about, and it did seem like an interesting process.
I had just gotten tenure, and so I just struggled for many years to achieve the sufficient number of publications of sufficient prestige,
and then having that big thing blow up in the news actually helped about the policy analysis market.
And then this blogging thing is tempting because you can just read all sorts of different interesting subjects,
and then spend a few hours crafting a few paragraphs that in your mind at least contributes to a subject that makes a new point and insight,
makes it clear, communicates it to people, and then after a few hours you're done and you can go on to the next topic.
So people like me who really like to think about lots of different topics, it's very tempting to think that you are contributing that way,
that you are instead of spending months to produce a paper, you spend a few hours to produce a blog post,
of course it's not as deep as a paper, but it could still contain insight and the net effect of blog posts today over many months
can be a lot even more than the number of papers you would have produced at that time.
Especially because it's so much more accessible. I can read a blog post, I can read several dozen blog posts every day,
but reading a single paper a week tends to be a problem.
Yes, although the key question is whether you build on it.
So in my mind there's a big difference if you write a newspaper column and 100,000 people read your column and they understand it,
they still might not do anything with it, and if you publish an academic article and 10 people may read it,
three of them may do something with it.
In some sense you have more intellectual descendants when people do things with your idea,
not just nod and say yes that sounds interesting, but build on it, accumulate.
Do you have examples of people reading your blog posts on overcoming bias and then making something beautiful,
building on your ideas, your original ideas?
Well, I've definitely noticed times when they seem to have been influential and I appreciate that.
I'm influential in the sense that I've taken some ideas from other people and passed them on, such as construal level theory,
so a large number of people appreciate construal level theory perhaps more than they would have if I hadn't blogged that.
I once blogged the idea that if you want to look at a bunch of empirical studies, say regressions and decide which coefficients you believe,
you often might do better to look at a bunch of studies that use the variable that you're interested in as a control variable.
It wasn't the focus of attention of that article and look at those estimates.
That's less subject to selection bias whereas when there's a parameter that everybody has a strong opinion about what the parameter value should be,
then it's hard to publish parameter values that differ from that and the publications can have selection bias.
I heard some other economists at some point say, yeah, I start using that technique now.
I don't have any rationality related questions.
Oh, it's okay. I was actually going to ask a little bit more about the prediction markets.
Okay, yes, let's do that.
Okay, so I went to dinner with my dad recently and I was talking about prediction markets.
My father has been in politics for his entire adult life and he just had this look on his face just kind of scrunched up
and he was talking about how polling is so great and really good polls are more useful for predictions than prediction markets in political races and legislation.
So I was wondering if you could help out by letting me know how you would convince my dad that prediction markets are a very useful tool.
So I would distinguish three levels of things that you can do.
One level, the first level is data, sources of data and a poll is a source of data, definitely.
A second level is a kind of analysis. What do you do with the data?
And there are of course standard ways that people analyze polls statistically so they don't just take the poll literally.
They process polls in order to produce better estimates.
But there are many ways to process data to produce estimates and people often disagree about how to do that.
Statisticians don't all agree and analysts don't all agree about how to analyze data.
So a third level of analysis is how we can set up a forum or a competition where different people who have different kinds of analysis and perhaps also different sources of data can compete
and the rest of us can just sit back and not make very many judgments about who to believe but just trust some overall process to produce an estimate that we can all believe.
And that's where our prediction market lies.
It's that that third level of a forum or a competition or a process where different people with different expertise play in that world
and the rest of us can just look at the market odds and believe that we don't have to decide how much we trust 538 because they got it right in 2012 or something like that.
In your experience, how have prediction markets fared against expert poll takers?
There are polls and then there are experts who process polls and then there are prediction markets that have those experts participate in them.
But again, I wouldn't want to put the prediction market up against the experts.
The prediction market is a process by which experts can express themselves.
So there are many different experts out there who have polls, which ones do you believe about what?
That's a key hard question and you'd rather not have to make those judgments.
You'd rather have some process that you can use that aggregates all of those different experts together in a reliable standard way and you can just go to that standard source.
Can non-experts participate in prediction markets?
Well, it depends on what you mean by the word expert.
If you mean by an expert, a credentialed person, a person with a degree or some sort of institutional affiliation such that we nod and say, ah, yes, that must be a good person because they have that sort of degree or institutional affiliation, then yes, of course.
Because as most of us know in the world that we know best, the people who have degrees and institutional affiliations don't always know best.
For any particular question that you might ask, the key real issue is how much has someone thought about and studied the relevant pieces of information for that particular topic.
Whoever has studied a lot and the most in another sense of the word expert, they are the experts.
And what you want as a process is where the real experts participate and other people back off and shut up.
And prediction markets are such a process that gives people a strong incentive to think about whether they are the real experts and participate if they think they are competitive with the real experts and then back off and shut up if they don't actually think that.
Because they would be risking their own money on their predictions.
Right.
They will lose on average relative to the other people who are the real experts and either people know whether or not they're the real experts and back off immediately or they're wrong.
And then they start participating and they find out by losing that they aren't as good as they thought.
In practice, has that happened?
Yes, yes, quite consistently.
How do you measure the accuracy of what comes out of the market versus, let's say, what is it, 538?
Yeah.
Versus 538.
So most of these institutions are modern institutions and the things they put out are probabilities.
That is, they don't just give you a number.
They give you a probability distribution over the various outcomes that could happen.
So when people put out probabilities, there's a key question about whether they're well calibrated.
So a well calibrated expert, well, when they say 70%, 70% of the time, I mean, when they say 70%, if you ask what fraction of the time are they right when they say 70%, it should equal 70%.
Somebody like that is well calibrated.
Now, you can be really stupid and ignorant and be well calibrated.
Being well calibrated is not the end all of everything, but it's a nice thing to be.
Because if you are well calibrated, then the answer to the question how useful or accurate are you is in the probabilities.
The source that can consistently give more confident probabilities and still be well calibrated is more accurate.
So that means you can just go to any well calibrated source, such as a prediction market, and if it says that the current odds for Trump being elected are 27%, then you can say, well, that's how much they're telling me.
You know, there's three-quarter chance that they'll lose and a quarter chance they'll win.
So if you have different sources and they disagree about probabilities, as long as they're both well calibrated, you, of course, will prefer the source that gives you more precise estimates.
If you had another source that told you Trump either had a 90% chance of winning or a 2% chance of winning, then you'd say, oh, that's a more accurate source because it's telling you it's more accurate if it's well calibrated.
So the key question is, is your source well calibrated?
So people who do statistics carefully tend to have well calibrated sources and prediction markets have consistently been proven to have well calibrated estimates, but many pundits and other sources you might go to are not well calibrated.
It's because they have incentives to skew things in their favor.
Yeah, they have an incentive to pretend to have more accuracy than they really do and people aren't really checking them on it.
Speaking about incentives to participate in the prediction markets, we had a question from our forums from a listener.
You said before that on the question of manipulating the price markets, that the fact that an event may be manipulated would make the price more accurate because other traders would come in and try to take that person's money since they're trying to manipulate a price and the actual probabilities don't change at all.
So the heightened possibility of there being such manipulation going on induces more trading, which allows us to have more relevant info and the effect is more accurate prices.
Now, the user, not without incident, asks that as soon as the prediction market is tied to a policy or the prediction has any other real world impact, they don't understand how this could still hold, particularly in cases where manipulators are also able to manipulate the outcome of the event in question.
How would a prediction market deal with that sort of situation?
So your initial quote was about manipulating a price that is influencing a price to distort estimates, which is different than manipulating an event.
So I will use the word sabotage to distinguish. I will say that sabotage is where you go change the world in order to look good in your forecast, whereas a forecast manipulation is where you go change the forecast to get the decision you want.
Those are two very different sorts of problems.
So the things I said are true about forecast manipulation that in a prediction market, as long as some people suspect that other people try to manipulate the forecast, they will come in on the other side and at the end result is the prices actually get more accurate as a forecast.
So it's not a problem for manipulation of the forecast in order to induce better decisions.
Sabotaging events, of course, is an entirely different problem. So it's generically true that predictions and actions interact.
So this is just always a caution to be careful about any process by which you're making predictions.
So first of all, if you make a prediction, then people might use your prediction and react to it and change the world, and that might reduce or increase the accuracy of your prediction to see what happens.
But you need to take that into account when you make predictions that if people hear your predictions, they will change the world in response.
That's why I tend to recommend trying to make conditional forecasts about what happens if people do things, and that is less subject to that problem.
If you say if we do this, then this will happen, and if people choose to do that or not based on your forecast, you can still make that as a reasonable forecast and your forecast isn't changed by the fact that people chose to make a certain decision.
That's one set of issues. Another set of issues is as this person alluded to, which is if you're in a contest to forecast things, one way to win forecast is to change the world to make your forecast come true.
And unfortunately, often it's easier to change the world by making it worse than making it better.
So if you have a large complicated system like a company, it's generally hard to make that company better by making its products better and its service better, etc.
It's often easier to make that company worse by somehow sabotaging its products or its distribution or something.
So there is always a risk that by giving someone an incentive to forecast well, you're giving them an incentive to sabotage some process.
So I definitely think that's generically true for all ways that you might encourage people to forecast things, and it's also true about prediction markets, and there are a number of very straightforward standard cautions to take into account if you want to deal with that.
How would you prevent this sort of thing from happening, or is this a fatal flaw that would keep prediction markets from ever being implemented?
Well, again, if it's a fatal flaw, it's a fatal flaw in the idea of predicting.
So all systems of prediction suffer this flaw, which is that if you give people an incentive to predict the future, you might give them an incentive to change the future.
Yes, but like Nate Silver, for example, probably doesn't have enough incentive to go out and try to assassinate someone to change the outcome.
So it matches his prediction, whereas a line worker at an assembly plant might have incentive to make a few thousand dollars by sabotaging his product to make sure it comes in at his lower prediction.
So now you're changing several things at once in your two examples.
Okay.
So you're talking about the election versus a particular product on an assembly line.
So the particular product on an assembly line is just a more influenceable event that anybody could influence, including Nate Silver.
So if you ask Nate Silver to predict that event, he might also be tempted to mess up with that assembly line.
So several considerations.
One is who has what ease of influencing the event.
So in general, if there are some people who have particular potential for sabotage, you might want to make their actions more visible, including their predictions and to watch for them sabotaging.
That's a standard thing you might do.
You could also try to adjust their incentive so that they don't want to sabotage.
So for example, I recommend that if you have a project forecasted a company and you want to say predict whether the project makes a deadline.
If you allow lots of people to participate, you have the risk that they might sabotage the project to make it not make the deadline in order to gain from that forecast.
And so you probably just want everybody who has an ability to sabotage the product to have an overall positive interest in the project.
So what you can do, for example, is you give everybody $100 if the project makes the deadline.
And you let them bet that $100 if up or down, but never below zero.
So you make sure they can take the $100 if down to $50 if or down to $20 if, but never negative $20 if.
So they all still have a positive incentive to make the deadline, but they can still express their probability beliefs by moving that amount up and down as long as it stays positive.
So that's a straightforward way to handle sabotage.
Again, I recommend that for any system by which you allow people to participate in some sort of forecasting process where there's a risk of sabotage.
It's not particular prediction markets. It's just part of the general idea that people, if they have an incentive to forecast and an ability to influence, they might be tempted to sabotage.
Okay.
Thank you.
Yeah.
That was very educational.
So are you guys okay with moving on to the age of M?
I am, I am.
Yes.
Okay, let's do that.
Actually, can we try something?
Since we're about to get to the most important part.
This is an earbud mic.
Oh, that's better.
That is definitely better.
Really?
Yeah.
How disappointing.
This is the cheap one and this other one was the expensive one.
Oh, yep.
Well, I've been carrying around this more expensive mic with me to make sure I have it available to use. Maybe something went wrong with it recently.
All right now, this is the built-in mic.
Actually?
This is by Mile, I think the best.
Yeah, this is the best one.
It's got a lot of echo to it though.
Oh, it's got a little echo but it doesn't have annoying wine and that's important.
Okay.
I find the wine less annoying than the echo.
All right, we'll keep this one.
I am, I voted two to one here.
I wouldn't be too discouraged.
Maybe your other mics are optimized for other situations rather than like third-party Skype recording apps or something.
That's the main, that's my main use I got this for.
Oh, well.
I've been doing a lot of podcast so.
I have noticed that the really expensive mics are fairly delicate.
