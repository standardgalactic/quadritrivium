touring you know if I'm at a conference you can follow those hashtags or something but um sorry I'm
getting sidetracked where were we um curmudgeony science versus cynicism skepticism um yeah I think
oh I do remember you were asking if we should if I'm advocating these things for the more
prominent people in the community or for the average person and honestly I am advocating
as for the average person because the people who are already popular in the community have a kind
of social momentum going for them at this point and it's that's something I've actually like studied
how to generate pretty thoroughly but we can talk about that a little later but I think it's more
important on the lower level I don't want to say lower but on the more grassroots level
what's more important specifically just having like your average joe being your average jane
being more active and uh talking about and seeming awesome for doing this sort of stuff
yeah yeah but like here's a question I've been considering for the last like 48 hours or so
Robin Hansen worked on prediction markets correct yeah and have you read the books
super forecasting I've not but I'm familiar with it but for those of us who aren't go ahead and
summarize it uh pretty much I feel terrible now I cannot remember the author's name but he was
using prediction markets with essentially pseudo money to make people capable of making
predictions on everything from arctic ice melting to stocks to national takeovers
and what he discovered is most people I think it's like 60% or about as good as a monkey throwing
darts at a dartboard with fake money or real money I mean I believe there was some tie-in like they
had some kind of point system so people felt invested okay and about I think it was
I think it was 35% were pretty good they were like better than average like 70%
but there was like 5% of people who were super predictors and if having a working theory of
the world is having theories and philosophies that pay out rent as we were talking about like beliefs
that do help you predict the future then being a super predictor or having access to one gives
you the more accurate map like by default you are more rational because you have a better working
map than someone who has all the same skills as you but a less accurate map well they've discovered
that you can do some daily practices to help increase your predictiveness score I believe there
is like a cap so if you're truly terrible at it you can get better but the fact that you can improve
it at all should be something every rationalist should be interested in and if we all did that
and pulled our money which I'm sure there's a cryptocurrency that could allow why wouldn't
like why shouldn't rationalist start their own stock funds that actually use correct data that
everyone else seems to ignore because it's socially unconventional like we could just
start winning economically that's a good question I guess I don't have a good answer for that but
I can turn that around why aren't you doing that David my personal goal is I am working to mix
my real estate with robotics and permaculture to create like to become a land developer that makes
resilient anti-fragile systems and honestly I am human and this goal is as big as I am
capable of doing so I've invested most of my energy in this and otherwise trying to be a sane person
mild success at both well for I mean it's it's a it's a journey right it's on a quick step
and you know what you're right like I could if anyone out there has the information that could
help me get started or can point me in the right direction I'll do my best to try like
it's worth doing but it's just something I find weird because I don't think I'm that clever
and this community has a lot of very smart people in it like can you imagine a rationality
hedge fund that just would in a matter of time using prediction markets and enforce contracts
not only be ethical but automatic and make huge dividends maybe not huge but pretty good ones
that's a really good idea uh yeah I haven't thought about that before uh you're convincing me
fairly quickly that there's low hanging fruit here that we haven't grabbed I guess that's not
particularly a little hanging but uh I that's a good way to put it like I think that there's a
lot of things that rationalists could do both individually they're low energy and that we
could do as a community because we have such a good and diverse skill set and if we're going to be
a little bit flatteringly honest a lot of us tend to be above average in more than one skill
like we could diffuse the work for a lot of very ambitious projects pretty easily like I'm
very astounded and it makes my heart glad when I see all the work the effective altruism community
is done yeah I agree and that's you know I don't that didn't really come explicitly out of the
rationality community but it's been highly adopted there and it's just one of those like hey here's
this norm that doesn't make any sense let's let's challenge the parts that we can like the taboo
against bragging um and say look among our community it'll be okay to like broadcast charitable
donations and where they're going and you know to make a public giving what you can pledge
or something um and then you know that way you know a real effective altruist if if they posted
on facebook and they're like yep here's the three places my donations went they'd be receptive to
feedback and be like you know what number two say like the pink ribbon breast cancer fund or whatever
you know that's kind of a waste of money if you're even like if your goal is you know reducing
incidences of breast cancer you don't want to give it to the I can't remember the the person behind
the pink ribbon campaign but you know what I'm talking about um I do I think it's like 95 cents
to the dollar 90 cents to the dollar goes towards more marketing for the pink ribbon and uh so it's
like even your own goal there of wanting to to stop breast cancer you're not even doing that
effectively um so uh just having an openness to that sort of you know because that's a pretty
intense criticism to give somebody like hey you know what you just wasted your charity your charity
money it's pretty hard thing for most people to stomach I think but the EA community has worked
to uh make it I think more acceptable to like discuss where charity money is going and which
ones are best in a way that doesn't make it seem like you're so pretentious philanthropist right
I think a big part of what they've done correctly is pull on the heart strings in the right way
where they're not trying to scam you out of your money and then like precisely the opposite
they're trying to prevent you from getting scammed in a way they almost act like a consumer
protection bureau but for NGOs and nonprofits and stuff yeah I like that and that is something that
people often don't want to admit that they need because it feels paternalistic but in a society
as complex as ours with all these moving pieces nobody can be an expert in everything you need
like someone to protect you from the worst human follies yeah I mean that's that's why I like the
you know give well organization that you know they do all the legwork for us and so if you're
if you're the kind of person who's ready to ask yourself okay I've got x amount of money to give
this year how do I do the most good with it well somebody's already done that homework for you
you don't have to go from the ground up and figure this out they apparently the two people who
started that I forget their names they had a really hard time getting initial data you know there was
like kickback from charities saying you're just trying to steal ours our our secrets to like sell
to our competitors or something which really weird mindset to take if you're like goal is you know
helping the world like what you want to help someone else help it better than we are but just
like there there weren't like statisticians on hands to you know give them numbers like you
know how many people are you saving with this like what how could you even ask that um so thankfully
you know since these aren't easy questions people just to call up an answer they've already done
some of the legwork for us if you uh you know just want to you know maximize your good from your
charity dollar and that works like I think this isn't something I think can be fixed per se but
maybe I can bring a little bit of awareness to it a lot of times I don't think this is even a
rashless thing I think this is a human thing when we notice someone has a belief that is in error
either it is epistemologically incorrect the sun does not rotate around the earth or it's practically
incorrect they should not have turned left now it's going to take you guys 15 minutes longer
and our first instinct when we see that I believe is often to point it out in a matter of fact way
but the same way that humans are really bad like have you ever heard if two people are punching
each other it just gets worse and worse over time because we're really bad at judging like
how much damage we are dealing in relation to ourselves because so every time you get punched
you'll just punch a little bit harder than you have to and the other person will feel it
words are the same way so you should soften everything you try to say that's a correction
by about 50 percent that's interesting and you mean like a conscious effort on top of like
I thought about this I'm doing this nicely to like stop yourself again and say how can I make
that even more palatable yeah like ask yourself how can I frame this or this person understand
that the only reason I'm even bothering to bring it up is because I want their life to be better
see partly that's why I just like hanging out with other nerdy people like me because
you know if I'm driving with a friend and I take the wrong turn they're gonna say you took the wrong
turn it's 15 minutes faster if you go this way and I'll be like great thanks for letting me know
rather than you know them having to say you know I know you're just doing your best and listen
that I can't I'm I think being untradable to your point but I'm thinking of
Robin Hansen was just on Sam Harris's podcast and he talked about
and I'm paraphrasing poorly something along the lines of like enforcing norms or having communities
that enforce the right kinds of norms so like you know we talked about the EA group before you know
if I go to like if my family was giving to charity and I pointed out how bad most of the
charitable donations were it would be received poorly because they're not effective altruists
but like having a community that has norms that like make you stronger and better is like one of the
most like reliably good moves you can do and I think that's why I like the little rationality
community in Denver was you know being challenged and proven wrong is like exciting and fun rather
than like feeling like you're being being beaten down and conceding a point you'd rather not concede
actually that's one thing I think the rationality community gets right
that is something I noticed a lot at the meetup which really encouraged me
just people being less attached to their beliefs like as part of like their personality or their
their personhood and yeah like being told you're wrong is almost never a bad thing to a rationalist
it's a thing that incites curiosity like can you please explain to me more and that gives a level
of mental resilience and it's confident like I don't I think rationalists should actually play
that part of their personality up because it shows such a level of confidence in who you are like I
can afford to be wrong about this it's not a big deal yeah I like that and I and you know not only
does it look good but like it also makes you just feel good you know if I if I'm doing something wrong
at work and someone shows me some faster better way to do something I'm like oh thanks for saving me
the time in trouble um if I'd known about that keyboard shortcut two weeks ago I probably would
have saved myself like 30 minutes by now every time that I go to the tab bar and or the task bar
and do it there or something right um and those are just little things where you know if you
point out hey you're doing this wrong to some people they'll take it poorly but uh if your
attitude about being wrong is different that like you're not I think that the other thing that I
I think I'd be willing to put out there that the rationality community is doing right I think it's
closely tied to this is making an explicit distinction between uh like you and your beliefs
you know your beliefs aren't you and if you're wrong about something it doesn't mean you're a
bad person like I don't think anyone really believes that but they act like they do and
you know I mean you can choose a politically charged topic and you know gun control or or drug
regulation or something um and they suddenly like you know if they're presented with challenging
evidence they get you know their heart rate goes up they get stressed they get they get upset they
get angry and uh that's not I think the right way to approach being wrong right um and it might not
even be being wrong they're just having a difficult conversation and the ability to calmly look at this
and say okay you know what I'm not wrong my belief might be wrong just just having that
different framing makes you much more open to being able to be receptive to that sort of stuff
I think that that is also a side effect of trying to integrate Bayesian reasoning which
is something we talked about when I was in Denver a little bit but I think trying to actively like
ask myself okay I just saw something that contradicts what I believe does this snowflake
of evidence move my belief meter one way or the other about this topic because it should even if
it's like 0.01% I should be willing to acknowledge it was at least that convincing
and that makes you humble because you can't really have a binary belief if you do that you
always have to keep the possibility that you're wrong in your head and then anytime you see
something that contradicts you it's not an attack it's just something that weighs slightly
more on the other side yeah and I think just like you know like you said just one of the
byproducts of that is that you know counterpiece of evidence isn't this you know hammer blow to
yourself it's just uh you know if your beliefs aren't binary and you can accept evidence and then
you know it's not just to accept evidence like okay cool that was that was interesting and then
just keep believing what you believed if enough evidence of enough counter evidence shows up
but to actually be able to switch and say okay cool I'm now leading this way
yeah I am not feeling very articulate I feel like I was onto something and I lost it so we
can we can keep going sorry we can move on if you want the thing I'm kind of contemplating now is
if I'm going to advocate this what are some practical suggestions yeah no I wasn't meaning
to move on I just meant to find some way to segue away from me and into my train of thought
so yeah practical ways I think we just did practical ways to implement this and you already
put forward the idea of just like talking about it you know when when you can to the extent of
not being obnoxious I wonder like for most people though that doesn't click like most of my friends
and family know the kind of stuff I'm interested in but they don't find it compelling themselves
it's just like it takes a certain kind of I use the word nerd endearingly it takes a certain
kind of nerd to like find the stuff really exciting and interesting right you know well you should
okay so let me give you a hypothetical scenario imagine if over the next year and a half
you became one of the top 10 healthiest people that you knew you double or tripled your income
your relationships and your personal life all increased in both quantity and quality
and let's say on top of it you got another awesome pet if all that happened in such a short frame of
time it might not get everyone in your immediate family and social circle interested but I think
it would probably get a good number of them to ask you like hey what what happened that's pretty
amazing but each of the things I just mentioned if like the self-help community is full of a lot
of trash but you don't have that much literature without some gems and they can get you some
amazing results especially the people who are a lot more data driven for example tim ferris
writer of the four-hour work week and not necessarily a founding member but definitely
a big advocate of the quantified self-movement has a section on meta learning where he pretty
clearly details how he goes about not just learning a new skill but organizing his schedule
so that he can master it and understand 80 of it in the most efficient way possible
and like that's something that's free online every rationalist should have that skill set as
quickly as possible now I'm feeling dumb I haven't not read that I mean here's the thing I honestly
forgive the rationality community for that because his books sound like the cheesiest things in the
world the four-hour work week four-hour body and four-hour chef he does have two new ones but I
don't remember their titles but to be fair to him he got those titles in pretty much the most
rational way I ever heard of he wrote like 10 different book titles he could use he made google
ad plays for each of them and that led to like the same website and he just counted at the end of
the month which one got the most clicks and use those for his names that's a pretty awesome approach
and it was brilliant and he explains it in the book and I just couldn't help but giggle that's
awesome yeah and I mean you know to to his credit like you're right the the cover at the bookstore
you know looks like another one of those random like oh here's how to like turn your life around
in three easy steps um but I've heard the guy talk on podcast and stuff and he's very articulate and
I think he he's definitely coming from a place that makes sense so it's weird that it wasn't
compelled to check him out more I mean I have the four-hour work week I just haven't read it which
I don't know what that says about me finally good um but yeah like the ability to to pick
up new skills quickly um is the kind of thing that you can cultivate you know like it's probably a
lot like prediction or super predictors right where you know some people are good at it some people
really suck at it but whoever you are you can get better and that's super valuable the returns
aren't are so amazing even if you put in minimal investment I think that's what always kind of
made me confused about why there wasn't more interest in it because
