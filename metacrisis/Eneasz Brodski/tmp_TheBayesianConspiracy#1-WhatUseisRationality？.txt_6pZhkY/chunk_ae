That's a fun counter example that was worth exploring at some point.
I think yes, totally.
Okay, so let's go back to the after all the what was it.
So after all the Bayesian priors for any real life problem aren't available.
And if you're estimating, how are you doing better than someone using their knowledge and intuition.
So we so our non steel manning was that the the author of the question is maybe a little bit confused about what we mean by Bayesian priors.
So steel manning.
What what could they mean?
What do you think they do mean by that?
I for some reason I thought this was the easiest part of their question to answer.
And that's just and that's because like, so a well informed expert will get things right more often than others because they have a better background to work with.
That's just what it means.
So like, I'm trying to think, you know, like chess grandmasters, they, they can, they can speed through.
And I, I'm not going to edit this out of camera before I was going with this.
But I think this is actually the chess analogy good for steel manning would a perfectly rational Bayesian who is not a chess grandmaster just kind of familiar with the rules.
Would he be better at chess than a non Bayesian chess grandmaster?
So would deep blue be the chess grandmaster?
Because deep blue, but only knows the rules.
Yeah. And the deep blue doesn't know anything else.
Right. So I think it can also go quickly.
Right.
I think deep blue went pretty quick.
I'm not sure about the speed, but I bet and that was what 20 years ago.
I'm sure the best chess playing computers now are are crazy good.
We need to talk about that computer one at go next sometime.
What if, what if you're a human go is a much bigger deal because as far as I recall deep blue just basically brute force the problem, right?
Right.
Yeah.
Because chess is like computable.
Yeah.
In a way that go just isn't right.
So you were asking.
So let's say that our perfect rationalist is a human being.
Yes.
And they're nearly perfect rationalist, but I think that you know, compared to somebody with deep experience.
The truth is that it only works if they have the evidence that they need in order to process a solution.
Right.
Yeah, I think that's fair.
I have to have the input in order to make the output.
I think the perfect rationalist would expect it to lose to the chess grandmaster.
Yes.
Because the chess grandmaster has a lot more knowledge and has those techniques, you know, almost internalized.
I would assume I haven't met any almost internalized to the point of intuition.
Whereas the Bayesian doesn't have all of that experience on his side.
I think you're right.
I think they probably bet on themselves losing.
And therefore win.
Right.
Lose the game, win the bet.
But the question of encountering, I guess, Bayesian priors.
Read the sentence again.
The Bayesian priors for any real life problem aren't available.
If you're estimating, how are you doing better than someone using their knowledge and intuition?
Well, you aren't.
Everyone just uses their knowledge and intuition.
And I think, I think that it's not even, it's not, it's not being uncharitable to say that the first part of that question is, is factually incorrect.
Because the priors are given a lot of cases.
I think the point with rationality is, is that if you are dedicated to epistemic rationality, you will have better knowledge because you will have, you know, weeded out the bad knowledge that you have and kept only the good stuff.
And you will also tend to get better intuition because you'll be able to figure out that all these intuitions usually don't work and I shouldn't rely on them.
And these other intuitions tend to work better and I'll adopt them instead.
Like either way, you're working on knowledge and intuition, but if you apply the methods of rationality, you have generally the hope is better knowledge and better intuition through the, you know, rationality process.
I think that's a good answer.
I've got nothing to add.
Okay.
So we move on in the question.
Sure.
Is that too arrogant sounding?
I always feel like I sound like an arrogant prick when I say that rationality is the best way to get these things.
I mean, you're not saying I'm the rationality expert and, you know, that's why I have everything I want.
I'm just trying to get a little bit better.
These are the tools I used to get a little bit better when I can.
And I think that's a fair way of putting it, right?
So like, and I'm not sure if it's unfair to put it this way or not, but like, what's the alternative?
It's like, am I going to get there by other means?
Like just trusting my friends over and over.
Trust your gut.
Yeah.
But the thing is like, what if your gut sucks?
Your gut does suck.
That's the whole point of this.
Exactly.
And just using the example of chess again, they can intuit through a game.
That's why you can play speed chess and kick ass if you're really good at chess.
Because they're not even thinking about it.
They just, they can look at a board.
They've seen it a hundred thousand times.
They can just go right through it and play it, you know, as fast as it takes to move the pieces.
But the difference is that, I guess, what other things would you use to guide your decision making?
I don't know.
The person tries to kind of clarify that previous sentence here by saying, I don't include empirical decision making as inherently rational here.
So for example, if give directly, we're the best charity, I see that as more of a data driven outcome than a rational one.
So I guess what they're saying is, they don't see data, evidence-based decision making as inherently rational?
I challenge politely.
You challenge what I'm saying?
No, what the assertion is.
One of the most important tools of rationality is data and empiricism.
And yeah, so like, if you don't count empirical decision making as rationality, I think maybe it would be unfair to equate them.
We may have just differing definitions because rationality doesn't have a lock on data and empiricism.
I mean, that's been with humans for a long time.
So maybe he's discounting it for that, but we use data and empiricism.
Or he's asking for examples outside of empirical data that count as rational decision making.
Because that sounds like a harder question because we've had empiricists around, you know, formal empiricists for at least, I think empiricism was a school of philosophy and starting in what, 15, 1600?
So like, I mean, there's been people dedicated to that for centuries, but they haven't been Bayesian rationalists.
So I guess where does Bayesian rationality come in outside of empiricism?
I think Bayesian rationality incorporates empiricism but isn't equated with it.
Well, Bayesian rationality is a little bit different.
So the way I was trying to explain it to my mom the other day was Bayesian rationality is like the difference between Bayesian statistics and the standard statistical model.
Frequentist.
Frequentist.
I believe, yeah.
Okay.
This is the term that I've seen anyway.
So, and we've seen it work better, get closer to the truth in statistical models, which is why there's a huge movement towards using it in physics and genetics, right?
And it handles new problems better.
Yeah.
And it's updating, it is updating your priors, it's updating your probabilities.
I don't want to.
Right, based on additional evidence.
Yes, it is.
I don't want to paint Bayesianism as like the ultimate end all be all of statistics.
But I think it's another tool that if you don't use it, you're handicapping yourself.
But I've seen arguments for why Bayesianism isn't always the best way to go, that there's other ways of analyzing data as well.
Well, it depends on the problem too, right?
Yeah.
But I mean, the fact that Bayesianism is getting a lot more, the reason I like Bayesianism a lot is because it is the formalized version of how I prefer everyone to think intuitively, that rather thinking in absolutes, you always think in probability distributions.
And when you get into the nitty gritty of which statistic is best, I'm not a scientist or statistician for that point, for that matter.
So I don't want to lay down my flag and say, no, Bayesianism is better in all cases and this is why.
But I think that Bayesianism has a lot going for it that if people applied it more to their day-to-day lives would help people update their beliefs, I guess.
But the base that's what it is is statistical method, right?
So it is at its base empirical, right?
Right, but we don't use it that way in our day-to-day life.
I would on an 80% chance that I'm going to get to work without, you know, within my 15-minute window.
And why not? You could never be late.
But the thing is, I do that every day and that's why I leave 10 minutes early, right?
Right.
Because I have a heuristic now for about how much time I need to get to work to be on time 90% of the time.
Right.
But I guess that was calibrated through that sort of updating.
Your first step is to look at your phone. Well, it says it's a 36-minute trip and then 55 minutes later you roll into the parking lot.
I started working this job before we had those smart phones that could tell you the minutes, so yeah, for me it was just a bunch of trial and error.
And I update it a little bit every time.
But you should be, one, you do assign probabilities to things automatically.
Yeah, but not consciously.
Not consciously.
And two, it might help to make it more conscious.
It probably would, yes.
That's why I'm still aspiring.
For me, the problem of always applying, trying to put numbers on it, is I always feel like I'm just, like, humoring myself.
Because I'm not sure if this is 80% or 90% sure that I'll make it to work on time, but I'm pretty sure and that's why I'm leaving now.
Keep doing it and you'll get better.
I guess. I need to, maybe I should start writing it down or something.
Calibrate those.
Nope.
Oh, okay.
Do you do it with anything?
Probably.
Like, I mean, like, keep track of it.
I can't think of something offhand, but I've definitely had conversations with friends in which I ask them to put down a probability on what they think is true.
I'm going to take an example from my life of someone who I consider not entirely trustworthy.
And this is a coworker that whenever, no matter where she's working or who she's working with, it's always a terrible place and everyone's out to get her.
And so I have a prior now that if she says something bad about her coworkers, it's probably a problem with her and I'm not changing how I view about the people she's talking about at all.
The horns effect.
Well, just from falling in the hole.
No, just from my experience with her, her, her narrative of other people is not reliable.
So I can't use it to update one way or the other.
I think the horns effect would be assuming the opposite of what she said, necessarily, or I guess maybe a little bit.
I'm assuming that since she is an unreliable person in general and because you have this previous experience with her as an unreliable person, you're using your experience, but also it might be an emotional like, oh, she's complaining again.
I've had that with a coworker too.
And you know what?
It resulted in me not listening to some really good ideas.
And yes, it would be if it was something accounting related that I was dismissing because I was, you know, used to dismissing her opinions on people, that would definitely be the horns effect.
I trust her to do her job entirely well.
It's just when she talks about other people, I don't pay attention to that.
But I think that is where the probability comes in.
I have assigned very little probability to what she's saying being accurate and I still listen to it and kind of file it away, I guess.
You know, I've never actually put like, I put 99% on her not being reliable when describing other people.
I just think, yeah, I'm not going to pay attention to that.
And I don't think people generally do think of numbers on those sorts of personal day-to-day issues.
I do think that the difference though between that and the horns effect is that you're not looking at, how do I feel about her?
So that's how I'm going to assess what she's saying.
You're saying how reliable is this person been in the past?
And that, I think, is a much more sound way of looking at things.
So if you have a really highly...
It's a piece of evidence. The question is, how good is it?
Also, if you have a really...
I've been working with her for five years.
If you have a really reliable doctor with great reviews online or something, you might trust their diagnosis more than your friend in med school who is getting straight Ds.
Right.
So you're intuitively putting percentages on things, but you don't have actual numbers in your head.
And you might even like your friend more.
Right.
But it's just, well, I'm in this area and on this topic, this person probably knows more.
So, I don't know. But, yeah.
Was there anything else in the question that we have to address?
Let me just double check. I don't think so.
So then they ended by thanking you again for putting together the Harry Potter and the Methods of Rationality podcast for me.
The podcast version and they're very nice and I thank them and hopefully we'll get their Reddit name.
So we can thank them properly for submitting a question that we then pulled apart and probably terribly misinterpreted.
I would like to, yes. I would first of all like to invite this person to, once they hear this, to write back and tell me if they think we addressed the question, if they think we were fair.
If they have any follow-up questions.
