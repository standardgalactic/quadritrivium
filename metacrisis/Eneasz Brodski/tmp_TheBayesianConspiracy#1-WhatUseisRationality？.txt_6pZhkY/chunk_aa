Hi, this is Enesh Brodsky.
Hi, I'm Katrina Stanton.
Hi, I'm Steven Zuber.
And this is The Bayesian Conspiracy!
And we're gonna have music at some point here.
You're doing the music?
Excellent.
So this is, as I've been telling people, a conversational podcast
for people who are rationality adjacent in the rationality sphere anyway,
but are not smart enough to be really the hardcore leaders.
That's not fair.
Is that not fair?
No.
Okay, so let's cut this out and start over.
How about more casual?
Okay, how would you introduce us?
This is staying in, by the way.
No, this is not staying in.
This is totally staying in.
We're working out what the show's about.
Everyone's gonna be bored hearing what the show's about.
Oh, everyone's gonna be bored anyway.
Oh, damn it.
I'm gonna listen again.
No, this will be fun.
No, we gotta cut out this boring part.
Now that it's gone on this long, we may have to.
Great.
Congratulations.
Hey, you gotta win somehow, right?
Sorry.
I think the introduction was fine rather than the stupid part.
I should not say the stupid part.
I don't think that we need to call people stupid.
I think that is antithetical to what we're trying to do here.
Yeah, you're right.
Okay.
Yeah, this is for people who are interested in rationality.
There's tons of podcasts out there for skeptics, which...
And I'm willing to defend this, I think, is like rationality 1.0,
or rationality is like skepticism 2.0.
Okay, I could see how you say that.
I don't see that there's much out there for rationality, audio consumption.
So, yeah.
We'll see if this sticks.
We'll find a way to put that all together.
No, I thought that was pretty good what you said.
Cool.
I thought it was good, too.
Yeah, we'll use that.
Everyone will probably hate it.
It's possible, but in the meantime, we can have fun
and we can chat about rationality topics, how they apply to our lives.
That is what I'm hoping for.
We'll take the risk of public chagrin in stride.
Yeah.
But the thing with Julie Gale's podcast, which is great,
check it out rationally speaking, but it's not about rationality in general.
It's sort of they'll pick any random topic and talk about it at a level
that a rationalist can enjoy, but it's not about rationality in general.
And this isn't going to be about that, I think, every week forever.
So, like, the second most recent rationally speaking episode was on false memories.
Cool.
Yeah, it was awesome.
It was with Elizabeth Loftus, who I actually saw give a talk at the amazing meeting.
And the reason I brought that up is because Julia in the podcast was like,
I think I saw you talk at something once.
I was like, yeah, Julia, we are at the same thing.
But there's, I think, the first episode, they try and tackle what is rationality.
But that was years ago and I don't even know what they said.
So that's not really the focus of their show.
So we get to go from scratch here.
And we're staying on scratch for a while anyway.
I do assume that most of the people listening to this will have some exposure
to the less wrong rationality type tools.
These won't be a complete new thing to them.
Not some of my friends.
No.
I can't imagine how they'll stumble across it otherwise unless someone shows it to them.
But hopefully that's their only exposure.
Yeah.
I mean, hopefully even with minimal exposure over time, listening to this podcast,
you'll be able to pick up some things.
Right.
It's kind of the hope, right?
Yeah.
Okay.
And since we haven't mentioned straight up, there's a long series of blog posts
on a website called Less Wrong.
And this is the, we're aiming to be less wrong inspired,
but less wrong podcast.
So it's not necessary to have the familiarity with the website or anything,
but we want to be, I don't know, I'm picturing sort of like the level of discourse in the comments.
Yeah.
So we'll see.
We'll see.
We'll be drawing heavily from less wrong source material along with probably other blogs,
which we'll hopefully cite correctly.
Try.
Yeah.
Oh yeah.
I grabbed some definitions from them.
So we'll be using this as we go on.
Do we want to jump right into that question that we got?
Yeah.
The only thing I think the only other thing I wanted to mention was about the,
about citing other sites, sources and stuff.
There will be on the website in the episode descriptions,
we'll have links to more or less everything we talk about in every episode,
especially the website.
Oh yeah.
Oh, the website is the Bayesian Bayesian.
Okay.
The BayesianConspiracy.com.
And I guess every time we put it up an episode,
we'll have links to relevant things.
You bet.
Thanks for setting that up.
Yeah.
No problem.
Thanks to you guys for maintaining it.
And you all should 80, 90% of the legwork we're setting the website up in exchange
for us doing the maintenance work later.
So.
All right.
So do you want to introduce this question?
Yeah, sure.
This was fantastic because we were talking about setting up this podcast.
We were trying to figure out what our first topic would be.
We're like, let's introduce, you know, our favorite rationality tool.
Then like a day later, I got this email that was a very good intro question.
And I was like, Hey guys, I don't really know the answer to this.
I kind of sort of got an idea, but it's actually a fairly hard question for a
fairly basic thing.
Let's, let's start with this because this would be a really good way to start off
the podcast.
And the two of them said, yeah, we think that's a great idea.
So here's the question.
It's a multi-part question and it starts, is there evidence that a rational
approach to decision making either on the personal or institutional level will be
more likely to achieve desired outcomes?
For example, Harry Potter and the methods of rationality implies that a perfectly
rational decision maker will do a better job than a very smart and informed ad hoc
decision maker.
But I don't understand why this should be the case.
After all, the Bayesian priors for any real life problem aren't available.
And if you're estimating, how are you doing better than somebody using their
knowledge and intuition?
I don't include empirical decision making as inherently rational here.
So for example, if give directly were the best charity I see, that is more of a data
driven outcome than a rational one.
Obviously, the two are not mutually exclusive.
So I could be missing something.
That's really long.
We'll tackle it piece by piece.
Yeah, just do the first line.
But I wanted to say really quick, hey, do you have this person's name?
You didn't put it in our forward.
I did not put it in the forward.
No, it came to me on Reddit, so it's their Reddit name.
And I will credit them later.
We'll give you a shout out on the website because I think that's awesome.
That sounds like a non...
A complex question.
Yeah, that sounds like I would assign a non-zero probability to that being
LEI zero in disguise to see if you knew what you were talking about.
Really?
This is the test.
No, that covers everything.
You don't give the right answer.
That's the intro question of a 101 class that would just really piss off the instructor
because it's like, well, I was going to teach, but we'll just cover this one
question for 90 minutes because it's that in depth.
But I think it's great.
Is Eleazar often going undercover and...
Oh, he is secretly everyone in the Bayesian conspiracy.
What?
Yeah, just with different voice modulators.
But if he was, we might not know.
If he was, we wouldn't know, right?
Right.
And he can neither confirm nor deny that he's actually all of us.
Fair enough.
Great.
Until we get him on the show.
But then that could be him playing the, you know, deeper game.
Okay, okay, do you want to start with the first sentence?
Let's do it.
Is there any evidence that a rational approach to decision making either on a personal or
institutional level will be more likely to achieve desired outcomes?
Did you say you had some research on this?
I said that I was aware of some research on it and I did check into it again recently.
Drilla Galev runs the Center for Applied Rationality and one of their, their object
level goals is to acquire more research on exactly that question.
So they did, they're doing a longitudinal, a blind study of a statistically identical
group of basically the way it works is people who wanted to be, they took a bunch of applicants
who wanted to come to CFAR classes and a CFAR sort for Center for Applied Rationality and
then took half of them.
And so then they compared the base demographics and stuff made those all the same.
And last time I checked, they are still doing the research.
