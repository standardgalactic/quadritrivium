Let's talk about Donald Trump.
Oh.
Nice.
Okay.
Welcome to the Bayesian Conspiracy, I'm Minyash Brodsky, I'm Stephen Zuber, and today we
are going to be talking about, well we're just going to have one of those episodes where
we talk about a few things that we have found interesting recently.
And we're kicking off with something that was in the news, not as recently now, still
kind of recently, but by the time this airs, it's going to be like ancient history.
There's going to be something new and more outrageous that has happened because that's
the world we live in and we're actually recording a little fair bit ahead of time now.
So we want, because we want to get ahead of things for Thanksgiving.
And let's be honest, if we released this, we're recording on Saturday, if we released
it on Wednesday, this Wednesday, then there'd be already a new scandal to talk about.
That's true.
Yeah.
So we're not talking just random stuff.
There's a theme around the rest of this, but we're getting kicked off by an interesting
thing about, I guess, why truth matters and we're going to put up a fun example of untruthing.
Yeah.
All right.
This really blew me away.
As probably everyone knows by now, the Trump administration kicked out Jeff Acosta, I believe
his name.
Yeah, but he actually won the suit to be a lot back, but that's not really the point.
Yeah.
They kicked out Jeff Acosta saying that he had like manhandled or attacked an intern
or something.
He's a journalist from CNN.
He's a journalist from CNN.
They were asking some questions.
An intern came and tried to take the microphone away from him and he, I don't know, didn't
let her, I guess.
It's not like he pushed her or anything.
He just held onto the microphone and the White House said, okay, we're evoking his press
credentials.
He assaulted our intern and they released the thing is this was on TV.
Like everyone saw this.
And if someone who didn't see it could see it very easily, you know, it was one of those
things where look at how ridiculous this White House is.
And if you watch any of the comedy shows, you saw footage of it.
And then they said he accosted our intern and put up this doctored video footage from
Infowars, the conspiracy theorist guy that's been kicked off all these media platforms.
So to be clear, this video was, this video was tweeted out by the official Twitter handle
of the press secretary for the White House.
Yes.
Yeah.
And this is why he's putting this out, which would have been egregious enough.
This was the official link from the press section of the White House saying this is
why he's not allowed back.
Yeah.
Yeah.
And the really like the crazy thing is we know Trump lies and his White House lies blatantly
without shame.
Don't acknowledge it.
Don't care at all.
Right.
They will just say whatever they want to say.
It's, it's not even like lying for the most part because lying implies that you keep some,
some image of what the truth is in your head so you can keep your life straight or just
say whatever the fuck or lying at the very least is trying to spin a narrative.
You know, it could be all false presentation, but you're, you're doing it with the goal
of saying, no, believe this instead.
It's not even that articulate with this.
It's just more like, I mean, here's our version of the truth.
Yeah.
Ultimate facts came around just directly.
Yeah.
I remember, you know, when George Bush's White House had the, what, reality based community,
there was that line about that.
The alternative facts is the one of this one, which is, oh, no, you guys have your facts
of our turn.
We have our alternative facts where, you know, starting on inauguration day where he's where
Trump said I won by the most votes or had most votes since Ronald Reagan, I had the largest
turnout ever.
Yeah.
Um, you know, hours after being sworn in minutes, these things were already pouring out.
So what really blew me away was that they released doctored footage, which literally
everyone, even his most ardent supporters can see is doctored.
No, it's doctored and just accept people, expect people to go along with it.
I guess.
But they do.
I don't, I don't understand.
It was like, this is the first time, I mean, there have been lots of comparisons made to
1984 already, but this was the first time that I saw something like this.
And I thought, oh my God, I literally remember the scene from 1984 where everyone is shouting
about how glad they are that we're at war with East Asia.
And then at the stroke of midnight, the government says, actually we're at war with Eurasia.
And everyone's like, we've always been at war with Eurasia and all the banners come
down and are replaced with different ones.
And everyone simply starts touting the new truth as if that was always who they'd been
at war with.
You know, I'm like, everybody knows it's a lie and they're, they're going along with
it.
Like why it blew my fucking mind in 1984, at least the whole society had been explicitly
trained and programmed to behave that way, but it's kind of sadder that people just naturally
behave that way.
Yeah.
That's way worse.
You're right.
It's one thing it was brow-beaten into over, I don't know, I'm just a bigger generation
or two instead of people just like eagerly lapping this up and pushing this out.
So the, the doctored version is, is subtle.
I had to see a side-by-side to really see the difference, but what, what, what shows
up and I'll put a link to the side-by-side, basically Acosta is asking, I guess, challenging
questions.
I saw a gift side to see the sound and somebody kind of ushers this woman over to go take
the microphone.
She goes to get it and he kind of just holds it.
He doesn't surrender the microphone.
You see her kind of tug it and him not let his arm bend.
In the doctored version, there's like a jerking of his elbow when she like moves back as if
she was kind of pushed.
And there's like this quick chopping motion of his other hand as if he was hitting her.
Yeah.
It's, it's a, it's enough to, yeah, it seems like it's a bad.
It's not even a good doctor.
Yeah.
It's a good doctor.
It's, excuse me.
Yeah.
It's a bad doctoring, but it's, it's also like not super egregious.
It's not like, oh, look, and here's the, you know, the, the moment when his fist made
connect, you know, catch where their face looked.
It's just, but the weird thing is you don't have to watch him side by side.
At least I didn't.
Cause I'd saw the original footage first when it first happened and I didn't think anything
of it.
And then I saw the, you know, the doctored footage and it looks convincing enough on
the first pass, but like this was not at all what was in my memory.
And it was so fucking weird to see something like that because I, you know, immediately
I was like, that's not what happened.
How is this, how does this video exist?
I wonder if other people see the second footage and kind of just, oh, that's not what I remember
happened.
I guess I'll just update to maybe this is not what happened.
I guess, I guess I just misremembered.
Yeah.
I didn't remember being that harsh.
Huh.
Yeah.
It's, it's a subtle enough changes that what I'm saying is it's not like they changed
out the, the players involved or something like that or moved the room or something.
So like there's a roundhouse kick involved or something.
But I mean, yeah, the thing is, I don't know, it's, it's hard to not sound like a scare
monger or something when you're saying, oh, look how big a deal this is.
You know, comparing it to 1984 or whatever, people will be like, oh, you're just, you're
freaking out.
This is just one little gift, whatever, you know, three second video.
But I think that the, you know, nothing jumps straight to 11, right?
It's always a crawl.
And you know, for me, there was a few moments already when at some point last year, Trump
said that he had never said the whole got him by the pussy thing, even though he admitted
to it during the debates.
Oh, that was just locker room talk.
And then later he said that never happened and nobody bats an eye because this is already
things that he says every day.
But then when he, he was presenting or he was talking to the, the assembly of the UN
what a month ago, two months, and he had said, you know, my administration's accomplished
more than any other in the, or in history.
And there's a collective laughter from the assembly, which since this isn't a comedy
club, that's not really something that happens a lot.
And when Fox News aired it, they cut the laughter out, which is already kind of 1980 for me.
And that's, that's already doctored in a way.
That's definitely doctored.
Yeah.
It's not like they, they, they put in applause, but that's the thing is it's gradations, right?
So it gets, oh, we just cut this little part out, whatever.
But, oh, we just inserted a few frames, whatever.
Yeah.
So it's, it's, it's little things at a time.
I mean, what really blew me about this, like all the other things were just him lying,
you know, I'm used to him lying.
This was putting out fake evidence and expecting everyone to accept it as real and the fact
that they're expecting us to accept this is what really, and I don't know, did anyone,
a lot of people probably are.
You think that the people, his like, I think are, yeah, going to believe whatever he says.
Yeah, they're going to say our versions doctored.
I mean, like people read info wars.
Yeah.
People are on r slash the Donald people read info wars.
Like it's, I don't know how many of those people are just like explicit trolls.
How many of them actually, you know, exist and how many of them are actually, like true
believers.
There definitely are.
They're, they're out there.
I mean, I've already written off the people at info wars that believe were ruled by lizard
people or whatever the fuck, you know, who they're, they, they're not write them off
because they probably voted for Donald Trump.
Well, yeah, they're both kind of as much as yours, which is
Damn it.
Democracy.
But like his base, if his base believes that stuff, I don't even know.
I guess the other thing too is that this one was put forward by the press secretary of
the United States.
Yeah.
And not the, not just Fox News, which is basically the press secretary, but not, not legally.
Right.
Not officially.
Yeah.
So I think I agree with what you were saying, though, that it sets a bad precedent when
you let things go, like even the lying, even the cutting, not so much the adding, you have
to call it out, I think, every time because it will get normalized over time when people
just go, Oh, of course we just expect Donald Trump to lie about everything.
It loses its impact.
It already has.
Like that's the thing is, I mean, you know, every time something insane happens, you're
just like, Oh, yeah, that's, that's Tuesday.
And, you know, even like at a larger scale, I know this is like not exactly related to
the truth stuff, but, you know, we had the largest massacre of Jewish people on United
States soil, but a month ago, that synagogue got shot up.
And, you know, this didn't even, I was talking with a friend of mine who's Jewish and he
took off the date next day after work or the following Monday, he just, you know, needed
a day to decompress and whatever.
And we talked about it.
And I think, and I totally agree with his stance or his, what really perturbed him about
this, like this just didn't even really jar anybody.
This is just like business as usual.
Just another shooting.
Yeah.
And I mean, in, in a way it definitely is, but the fact that we're so blasé about it,
there's no, I mean, there's definitely probably local, there actually was a great local response
and all that stuff.
But, you know, this isn't, remember how like the world stopped and Columbine happened and
stuff like there's, there's not just the time for that anymore, nobody, nobody's, nobody
bats an eye.
I was most perturbed by the fact that in two weeks later, there was a another mass shooting
and the CNN intro that I saw real quick because, you know, I want to know what happened.
The cameras would just do the, the anchor and he goes, the worst mass shooting on American
soil in 12 days, like, fuck, we now say, yeah, in a double digit number of days for that
sort of shit.
Yeah.
We need a, we need a place in Times Square where it's just like day since our last mass
shooting.
I was just thinking about that.
Somebody has to go by.
Like the workplace injuries calendar.
Exactly.
Yeah.
It's all weird, but someone, I guess this is going to be a bad segue, but to push us
into today's topic.
So what man?
It's, you know, that's your version of truth.
This, this their version of truth.
What's, what's the matter?
What's the difference?
Who really cares?
I know we're not talking so much about truth today, but we're talking a bit tangentially.
Yeah.
So, you know, whatever, right?
This, that's, let them have their, their alternative facts.
They're just as, you know, that's, have your, have your real facts in quotes that that's
what you care about.
What are you, what are you going to say?
These are not real opinions of Steven Zuber.
He's just using air quotes left and right here.
Yeah.
Um, I say that that's bullshit.
I don't know.
I guess I, I don't really know what to say when I, if someone were to earnestly come
out with that question.
Yeah.
And I guess I have something more fleshed out because I've been thinking about it already,
but the, I once had somebody when I was a teenager, we, back when I was in my days of
how much fun it was to like debate the existence of God with people and I kind of maybe moved
her to think that God lot, there's no logical basis for her religion.
She's like, so what?
Then what's the point of logic?
Oh.
And like, then I was kind of trapped for a while because like, how do you logically persuade
somebody, how do you use logic to persuade somebody who's not moved by the necessity
of logic?
And so I was like, oh, I guess, you know, the whole thing, I can't reason somebody into
position that they haven't reasoned themselves into a reason, somebody out of position, but
I think when you're talking more fundamental than that, like truth and logic, you really
just show them like, you do care about the truth and logic of these things.
You know, like, I can imagine somebody, you know, oh, well, you know, I don't really care
about truth and I get by just fine.
It's like, sure you do.
And if you care about alternative facts, if the vaccine that the doctor gave your baby,
he thought it was a measles, mobster, Bella vaccine, but it turned out to be nothing.
You'd be pretty fucking pissed.
They're alternative fact of, oh, I just told you this, what it was and charged you for it.
You obviously care about the truth.
So I can lay out a billion instances where you care about the truth and you can't.
So then it's up to you to defend why these few instances you're willing to say, oh, truth
doesn't matter.
I'm going to wave it away.
Well, it's motivated reasoning.
Yeah.
You really want to believe in your religion.
Yeah.
So you'll say anything to defend it.
And if your religion is your political party or your, your favorite alternative therapy
or something, then your beliefs about climate change.
Yeah.
So that, that doesn't actually bring me to this next post, but I swear that these are
related once we get to it at less wrong.com.
Sailor Vunkin, Sailor Vulcan posted, no, really, why aren't rationalists winning?
And I believe this is the same Sailor Vulcan that comments sometimes at our subreddit slash
the bait, our slash the basing conspiracy.
And because Sailor Vulcan has asked this before on our subreddit as well, too, the, they
say that when others win in places where we fail, it makes sense to ask how, what skills
or knowledge they have that we don't and how might we obtain them to say this came up
before, didn't we kind of cover this before in an episode, the wired rationalist winning
thing?
We talked about it a bit.
In fact, this, this quote here is right after they, they point out what our kind of argument
was on the podcast that we had, we had put forward, I don't know if it was our official
conclusion or kind of are just throwing our hands up and suggesting this.
It sounded like more of a thing that was come up with on the fly.
Yeah.
Okay.
So we, I guess, first of all, we should talk about what we mean by winning.
But before that, I wanted to, this, this, this quote that you just put out was right
after they had said that our position or at least argument we made on the show was that.
Wasn't that like winning relative to past you?
That's right.
Or yeah, it bumps you up a certain amount.
You know, it can give you an extra 20 points of success or whatever, whatever your metric is.
I believe we brought up the example of someone who was living in a developing country somewhere
and said that after learning the rationalism thing, he just noticed huge increases in life,
life outcomes, because nobody else was thinking in those terms and they were failing at a lot of
things that are pretty basic.
Once you have some, you know, standard structural thought patterns down,
he said, if the entire society was structured like this, I could see how things would be much
better.
But, you know, for himself, he was doing a lot better.
I don't remember that actually.
I just remembered that our, our kind of vague answer was saying that it could give you a bit
of a boost relative to your, your starting position.
And this thing here was a, was a response to our kind of cop out there.
That's what Vulcan called out, that, look, it's not to say you get a little bit of a boost.
If you're getting anything, you need to be able to say, yeah.
Like, why aren't rationalists the leaders of industry?
And yeah, or better yet, like if, if, if you're a rationalist and I'm not,
or rather say, if you started from a higher place than I did, I could still ask,
why are you doing better?
If I have the tools that rationality gives me, I should have those capabilities.
Yeah, the ability to actually break it down and systemize it and do it yourself.
Yeah. So, so winning here is achieving your goals.
We've talked about instrumental and epistemic rationality before,
which I've also argued are kind of the same thing.
But the idea that epistemic rationality is using all of your, your awesome rationality skills and,
and background concepts from science and the scientific method to arrive at
accurate beliefs, get a map that reflects the territory.
And instrumental rationality is getting to where you go, where you want to go and achieving your
goals. And you use the truth to do that, unless some people would argue that you use,
you know, phony truths to do that, if that's what helps.
I think some people who argue in favor of like the mysticism or magic would say,
look, it's not so much about epistemic rationality.
It's about getting to my goals, whether I have to lie to myself or not.
I think it's still the same thing.
I mean, talking about why does Donald Trump keep winning, for example,
even though he's a baffling social scientist and psychologist.
But um, whether it's intuitive on his part or not,
like maybe he actually does have some kind of systemized understanding of how psychology works
and he's manipulating that, or maybe it's intuition.
Maybe he's just really good at that naturally.
But it's still because, because of a truth about social science, about psychology that he's winning.
I would not call him a rationalist in any sense, though.
Not even an instrumental one, really, because it's hard.
I don't know enough about his full biography to give an account, but like,
I couldn't say that you're, you're winning a lot.
If you, if you declared bankruptcy, you know, eight times on, you know,
if you've had so many failed businesses, all of your businesses would flourish.
Or you could say you're winning because, look, I fucked up a hundred or a dozen times,
and yet I'm still making money.
Yeah, it didn't affect him.
So, uh, Sailor Vulcan says, uh, rationalists are very good at epistemic rationality.
But there's this thing that we've been referring to as instrumental rationality,
which we're not so good at.
I wouldn't say it's just one thing, though.
Instrumental rationality seems like many different arts that we're all lumping together.
And, um, I, I disagree that instrumental rationality is different arts lumped together.
I feel like it's just applying epistemic rationality to a variety of applicable problems.
Like, I don't think that there's different arts of self-help or of, you know,
improving a business.
It's all just applying rationality to whatever you're trying to do.
I think certainly that applying rationality to what you're trying to do
increases how, how likely you are to do good at those things,
because you have a more accurate understanding of how things work.
But I really, like when I say I wouldn't consider Donald Trump a rationalist,
I think in large part that's because he doesn't seem to care about the truth
or having an accurate picture in his mind of how the world really works.
And no matter how instrumentally successful he is at his goals,
I still wouldn't call him a rationalist.
So I think a large part of what rationality is, is the focus on epist, um, is it epistemicism?
Epistemology?
Epistemology, yeah.
The, the, you know, actual trying to figure out the truth part,
which is less instrumental, really.
And I think, I think you guys are kind of conflating,
or I don't know how much time we'd burn tabooing, uh, rationality here, but, um,
the word rationality.
Yeah.
But the-
Like I call it truth-seeking.
Yeah.
So, so the truth-seeking is different than winning slash doing your goals.
So like epistemic rationality,
there are facts to be known about what steps you can take to win.
And then there's like doing those things, right?
So, I mean, imagine how useless Contessa's power would be in Worm,
if she saw the path to victory, but couldn't do any of those things, right?
So it's like, I see all the steps I have.
It's just a crazier.
Yeah.
So she's just got like this awesome, a crazier power where she can see how to win,
but can't actually do any of it.
Well, I mean, what good is it to know, you know, exactly how you should swing a bat
in order to hit a ball to get a home run,
if you don't have the physical skill necessary to actually swing the bat that way.
Yeah.
So that would mean that you'd have to train up a whole different thing, right?
Actually swing the bat.
So I think that's sort of what people are talking about with the different-
I still think it's the same.
You're still applying the same epistemic rules.
It's just, you do have to do this separate thing of, you know,
achieving the bat swinging skill.
But like, I don't think that you combine them together now.
It is a new skill.
Yeah.
No, I agree.
I think to quote Sealer of Vulcan again,
the art of epistemic rationality is how you achieve the value of truth.
And up until now, instrumental rationality has been a catch-all term we've been using
for the arts of winning at every other value.
And I think that's been a problem, that instrumental rationality has been over-defined,
has been used as a catch-all for just doing good at life,
which does not necessarily include the things that we care about
when we speak about this whole rationality thing.
Yeah.
Obviously, we want to do good at life.
There's also the puzzle of using the baseball analogy.
I could be hitting homeruns left and right,
but I have no idea the physics of a baseball.
Right.
Which I think is what Donald Trump is doing.
Yeah, exactly.
And so while hitting a few foul balls and whatever,
torturing the analogy as I often do.
But the, I guess, the claim then from the rationalist community would be that,
no, look, if you really understand the truths of everything involved with hitting a baseball,
you'll be able to more reliably hit homeruns or something,
or maybe knowing why you're hitting homeruns,
you can generalize that to other things.
And yet, there are people who would still, like I said,
be able to hit homeruns without knowing anything about it.
I don't really know how that plays in here,
other than to maybe illustrate that there are kind of two different things,
which I didn't think about, which I didn't,
that wasn't my position going into this,
but now I'm kind of leaning that way.
Can you explain that more?
I guess other than like, you could get really good
without leaving your house about knowing everything about how to hit a baseball.
You could, you know, Stephen Hawking might know everything there's about,
you know, hitting a homerun, except for actually being able to do it.
Whereas somebody else, probably most major league baseball players can hit homeruns,
but they couldn't show you the calculus of how baseball hitting a bat
moves out a certain angle or something, right?
So I guess maybe those truths aren't related to hitting a homerun.
I think rationality might be something that would tell you how better to train your,
or how better to practice so that you get better at it faster.
Or telling you some things like you should improve your upper arm strength
to get more force behind the swing.
Or, you know, if this is an option, which it probably wouldn't be,
make your bat out of different material in order to more effectively get the ball going.
Yeah. And then dark arts rationality, like tricking yourself would be
going with all the superstitions that professional sportspeople have,
like always wearing the same undershirt or something.
Is that dark arts? Because I, well, maybe I don't know if you're hacking your brain.
But if you know you're lying to yourself or you're doing it anyway,
like somebody who writes sigils or prays or something.
I think rationality would be the thing that tells you not to waste time with that,
because it won't make any difference.
Yeah. I thought dark arts was actually using the correct epistemology, but for bad reasons.
I think you're right. I misuse dark arts, but there's a technique of self-deception
that some people advocate of saying, look, I know it doesn't actually do anything,
but it helps because it helps me trick myself.
Well, then it is doing something.
You just have to be careful with it, though,
if you start believing that it works because of magic rather than me tricking myself.
And I couldn't make you a better baseball player by telling you
not to wash your undershirt before you go to play or something, right?
So I feel like I've gotten off track. Sorry.
So they want to know why rationalists aren't winning for real?
I think A, winning is a hard thing to define.
I mean, I feel like my life's gotten better in the last several years,
but I didn't live the counterfactual life where I didn't figure in learning this stuff.
And so it's hard to... I mean, I think Jess and I talked about this a bit yesterday.
Like, unless you're going to do longitudinal kind of blinded studies,
like I think the CFAR organization tried to do a bit of those.
And I don't know if they ever got enough results to publish,
or if I just haven't come across them.
I didn't actually look for them, so they might be out there.
But yeah, unless you're going to teach a random sample of people, all this stuff,
and then follow up with them for the next decade and see how they're all doing,
there's no way to know if it's helping.
You know, who knows, maybe my life would suck if I didn't get into this stuff.
And now it's pretty good, so maybe I am winning.
I do think that'd be a great thing to do if anyone could do that.
Like, if we had the funding to study that.
I think that CFAR is studying that,
and I think there just hasn't been enough time.
But anecdotally, I know people who have gone through the CFAR program
and highly recommend it said that it did actually make a significant difference in their lives.
I know my life has been improved by the whole rationality thing.
Yeah, but I guess why aren't we all as successful as Donald Trump?
Maybe is the implicit question here?
Well, I think it's...
I'm not very afraid of that, because that's a bad example.
We don't want to be as successful as...
Yeah, no, thank you.
I don't know what successful means if you're a miserable, fat old dude, but...
Right.
Well, I think part of it...
His age doesn't come into it, sorry.
Yeah, anyway, yeah, he can't help how old he is.
I mean, I think part of it would be like asking,
well, why isn't every baseball player as successful as Donald Trump
if they're so good at hitting home runs?
I just don't think rationality is supposed to be a thing where no matter...
It's not like some kind of Bene Gesserit magical skill
where you learn it and instantly you're better at everything.
I mean, I think that everything that I try is influenced by this
and made slightly better by the fact that I have these patterns of thinking,
but it's not an instant win code, you know?
It's...
Rationality itself is focused on having a more accurate view and seeking the truth,
and in as much as that helps you achieve your other goals,
it's beneficial, but it's not a thing for winning at other goals in itself.
There's also...
We've gotten a question a few times,
and I wish I could find the person who wrote it in,
but I keep saying we're going to get around to this and we're going to eventually.
This isn't the full reply, but let's be part of it.
Someone asked, or multiple people have asked,
like, what does rationality look like in your real life?
Like, what do you do with this?
And I think there's several things,
but if there's one thing that I do most days is try to imagine
and account for failure options for how things could go.
And so I think as a result, I have a lot less massive fuckups
than I would have had otherwise, because I'm visualizing,
okay, look, maybe it's not the best goal
to invest all of my money in cryptocurrency, right?
Or something like that.
So one thing that this, it's maybe not winning,
but it's definitely not losing to plan for how things could go poorly
if you were to follow through with this option.
And if it looks like, hey, this is definitely...
Your odds of losing here are like 90%, then you just don't do the thing.
And so that's not losing as a kind of winning.
Yeah, kind of betting on probabilistic futures
based on your actions or inactions.
Yeah. In fact, I think Seller Vulcan gets into that too
with betting markets and stuff.
Yeah, although that's more talking about just winning money
by betting on outcomes, not betting on what your actions are.
But that's like, why aren't we all rich from, you know,
or just like highly successful at prediction markets?
Yeah, you're right. That's another thing.
Because I don't lose every time I don't buy all the lottery tickets
and empty my accounts, buying lottery tickets every day, right?
Scott Alexander had an interesting reply to this,
which part of my reply has also been influenced by.
He replies in the comments to the post,
so I'll link the direct link to that as well,
that it was wrong to ever focus on individual winning
and we should drop the slogan.
He says that if you are good at knowing what is true,
then you can be good at knowing what is true
about the best thing to do in a certain situation,
which means you can be more successful than other people,
which is probably where this rational should win idea got its real legs.
He says, I can't deny this makes sense.
I can just point out that it doesn't resemble reality.
Oh, you have a thing in here?
I threw in one because we already brought up the example
and Scott Alexander did too, that Donald Trump continues
to be more successful than every cognitive scientist
and psychologist in the world combined.
And this sort of thing seems to happen so consistently
that I can no longer dismiss it as a fluke.
He, I just wanted to give us credit for thinking of the same,
or he thought of the same kind of, not even wild card,
just like this phenomena that we were discussing.
Yeah, so not necessarily correlated.
He points out that in the history of medicine,
it started with wise women just using traditional herbs to cure things,
and very smart people like Hippocrates came up with reasonable proposals
for better ideas and did much worse than the wise women for thousands of years.
And a lot of people died, but eventually things got better.
And personally, I would not draw the line at Hippocrates
because I, he still didn't use the scientific method.
There, that, that was basically just a different version of, you know,
superstition in my opinion.
I can see why someone who's taken the Hippocratic oath might be,
might come to Hippocrates.
But yeah, I think anything done pre-science is like kind of not really fair.
But even so, the scientific, I don't remember who pointed this out,
but the scientific method was invented over two centuries ago.
And well, over two centuries before we started washing our hands.
Yes, right. It took, I mean, it's, when you think about it,
the scientific method is the weirdest fucking thing.
It was basically just some people, most usually guys,
because they had like the, the extra time and money to do this sort of thing.
Just some people who were like interested in nature and was like,
all right, let's fuck around with nature,
tinker a bit here and there and see what we can find.
Whoa, that was fucking weird, I'm writing that down, you know?
And they just did this in their spare time for 200 fucking years
before we've got anything of use out of it.
And that is, first of all, that is a hell of a project.
And I'm really admiring them and glad that they did this
for so many years with no results.
But on the other hand, it did take 200 years of groundwork
before we got anything actionable out of it.
Yes, Scott said, he's not sure that we can short circuit
the spent 2000 years flailing around and being terrible step,
which I think is one of my hypotheses also for why we're not dramatically winning.
We just haven't had enough time.
We're the first generation of rationalists,
the enlightenment to the extent that such a thing can be said to exist
didn't happen overnight.
And maybe the most important thing that we could do
as the first generation is just keep building momentum.
Like if you think of rationality as a martial art or school of philosophy,
how do these get passed down and built up through generations?
And like even Harry Potter for methods of rationality was overconfident
in his ability to figure out the science behind magic.
And he discounted things like entrenched systems and stronger players.
So maybe we do need to get better at epistemic rationality before we can start winning.
And maybe the legacy of our winning will be that it took us 50 years other than 200
because we were able to actually build on knowledge of human psychology that,
you know, A, I guess standing on the shoulders of giants kind of thing,
but B, just not fucking around for as long, you know, going at it with real gusto instead of...
Or achieving more in like the same amount of time.
I mean, hard problems do take time because you do have to do a lot of hard work.
It's not just clever insights.
Yeah.
It's like, you know, elbow grease.
Yeah, a lot of the low-hanging fruit was already grabbed.
I wonder how much faster rationalists would have grabbed it
if cognitive science was introduced in 1600 rather than 1950.
I don't know.
I also wonder how much of us failing to win is just that we've solved a lot of the low-hanging fruit
and that we need to find a really important problem to work on.
Well, and I think Scott Alexander goes on to point out a couple of those, you know,
artificial or friendly artificial intelligence, effective altruism.
Those are some wins that kind of came out of this community.
Yeah, I think those are like just the fact that we're noticing them and kind of
we got the rest of the world to start paying attention to.
For example, AI safety is kind of a big win.
I think so, yeah.
I mean, I'm not that old, but I remember everything about AI used to just be terminator and stuff
and that still as a joke is, but, you know, now...
There was that thing with Google recently where they said that they weren't going to
fund the project of AI based military technology.
Yeah.
And what would they have come to that same conclusion, you know,
if we hadn't been proselytizing about AI being dangerous?
Yeah, that's a good point.
And, you know, we're getting big players on board.
You know, Elon Musk has a big platform.
You know, Bill Gates, Bill Gates has a visit.
Yeah, he's been out on this.
Yeah.
I mean, even Stephen Hawking in the last years of his life.
Yeah.
Hawking, Sam Harris, isn't really up there with those guys,
but he's, you know, to his podcast of a million people, he's made...
He's, in his words, made noises about this for the last few years.
I found it kind of frustrating that we haven't gotten the credit for that.
Yeah.
We know we've got the credit for it.
All right.
But that's one of those things that could increase awareness of the rationality community
and that epistemic rationality is a good thing to learn.
It's true.
That's why I think instrumental rationality is important.
If you do help people get measurably better in some sense,
people will take notice and ask, why did you, you know, what happened?
What caused you to get so much better and then we get more people on board?
Yeah.
Although, like, focusing on finding artificial intelligence is kind of like another,
like a bigger example of me not losing is counting that as a win, right?
It's not a public win because like, oh, look, we didn't destroy the world.
And it's like, who do we give credit to for this?
And so it's less, less obvious, but it could be the kind of thing,
like in retrospect, we look back and be like, oh yeah, thank God,
these people were doing that stuff back then.
Because otherwise you might have done this differently.
And we can view all the timelines.
We're like, oh man, look at what we dodged there.
Yeah.
In fairness, I would rather that the world be saved and we not get the credit for it
than we get the credit and the world not be saved.
So that's, that is my main focus, but yeah, it would be nice.
And it almost makes me wonder if we as a community should target like smaller problems.
You know, I mean, I don't want to take momentum away from effective altruism
or developing friendly.
That's the problem.
But I mean, if we could pick certain things to work on,
and then we'd actually have some measurable, you know, success
that we could kind of wave around like a flag.
Do you have any suggestions?
No.
Oh, okay.
Maybe that'd be a fun, fun project to think of some, some smaller goals that are,
you know, achievable within a few years that you could say, look, we did it.
But, but even then people would ask, did you do it because you were determined and smart
or because you're rationalists?
Because it's probably not the rationalism thing.
Rationalists are a weird group of introverts.
But I think I am with you guys.
That, you know, focusing on big things like EA and FAI are, are big wins, even if like,
technically one of them is just not losing.
You know, I don't know, EA is more of a, I'm trying to think that's, it's not,
I think to some object, objectories that might not be like solving a problem.
It's like, great, now actually cure, and I actually fix world hunger or cure malaria or something.
I have to really commend 80,000 hours for actually identifying the problems on the
effect of altruism side and prioritizing them.
Oh, me too.
I was just saying that I'm trying to think of the, of a cynical objector
might say, look, yeah, you guys pointed out that this is wrong, but like now do better.
It's like, we kind of fucking are.
So not wasting our charity budget is sort of a huge deal.
And advocating, you know, getting, successfully getting lots of people on board.
I don't have figures, but I'm sure people like
McCaskill and Peter Singer do of people who have been influenced over the last 40 years
by people writing about the sort of stuff to, you know, instingers words do good better.
Or wait, no, McCaskill, that was his book, doing good better.
Yeah.
Um, Scott did say one thing I wanted, one last thing I wanted to pull out from his reply
is that he compared instrumental rationality to self-help, which is kind of not entirely
inaccurate.
I would say it's, it kind of feels like a self-help thing, right?
Uh, I think that's where I was kind of getting into whether or not we should taboo it or not,
because, you know, again, the baseball player wearing the dirty jersey is self-helping in
that way, right?
Where they're, they're tricking themselves.
If they have to believe this mumbo jumbo to hit a home run, then that's what they have to do.
But you can't sell that to somebody else.
And so that's the thing with a lot of self-help things that Scott points out,
that this, this advice isn't generalizable.
And if it is, it sounds like, like woo, right?
Yeah.
He says that once you start becoming a self-help community, you start developing all sorts of
norms that help you be a self-help community.
And you attract the sorts of people who are attracted to self-help communities.
And then 10 years later, when someone asks, Hey, shouldn't we go back to being pure truth
seekers?
It's a very different community that discusses the answer to that.
I don't know.
Another one of my hypotheses as for why we're not winning is just that we kind of fail to work
effectively in groups.
Someone brought that up in the comments on Sailor Vulcan's post too.
Yeah.
Research shows that effective groups of average workers outperform geniuses,
which is kind of the whole idea behind why rationality could help someone succeed.
Geniuses who can't work effectively with other geniuses or with average workers in groups
actually perform worse than the effective average groups.
And we demonstrated that with AIs too, where in games, AIs beat humans.
But if you combine a human and an AI, make them work together, they outperform the solo AIs.
So I think if we want to win, that we do need to get better at this.
And I don't think I wouldn't want to just throw the whole self-help angle under the bus.
Is that a problem unique to our community?
Or is that just like in general, something that we've identified as a weakness,
and that we have the capacity as rationalists to work on?
Because I mean, a lot of people, I think a lot of industry suffer from like the,
no, I'm better at this because I'm the smart one.
Leave me alone.
Coordination is classically an incredibly hard problem.
And people have been trying to solve it for millennia.
I think we might be a little worse than most groups at trying to solve it though, because we're
lots of thing oriented people.
Yeah, we're more introverted than the norm.
And we're more like...
Well, we have a lot of geniuses and we have a lot of people that work solo
and don't like to work in groups.
And I think a lot of that comes from maybe the atheist community,
people that have deconverted from group thinking type groups,
are just naturally suspicious of wanting to do team building and form a community that's kind of church-like.
And I understand that.
But I think that we shouldn't let that come between us and performing effectively in groups,
considering that performing in groups is a really major hack.
Yeah, I think I agree with everything you just said that
this is something that we've identified as a failure of our community.
And we're smart enough to realize it.
We should be smart enough to do something about it.
It's hard to know what to do.
I mean, we are comprised of a lot of thing oriented people.
And someone at one point on the last rung had mentioned that was unfortunate phrasing,
but we really need more stereotypically feminine women.
In our community.
But what they mean is we need more people oriented people.
We need more of people geniuses who are really good at running groups.
But again, that runs into the issue of, first of all,
how do we get them interested in rationality because they aren't now?
How do we market ourselves?
And then secondly, if we do start getting a lot of the people who like doing team building and community stuff,
are they going to shift our focus away from epistemic rationality
towards the self-help-y sorts of things or whatever else?
And for that matter, what do we listen to them?
Because I still, you know, get shivers of you when I think about doing things in group that feel any
at all like church, you know, or like the military,
like anything that is meant to help people coordinate sort of,
I have an allergic reaction to, which is bad.
Well, when you're coordinating, you're giving up your autonomy.
Exactly. I was going to say that, but you're giving it up in the sense as long as you want to keep cooperating.
You know, like you still have it, you can leave, but then you're,
if you're exercising your autonomy, then you're not coordinating with the group.
Part of that is going to be like, look, just trust me and do it.
And that's never something that I think our community will be receptive to, maybe.
Yeah, prove yourself first.
I consider trust me to be the magic words that always mean don't trust this person.
Right.
As soon as you hear those words, it's like, uh-huh.
Unless it's believe me.
Right.
He said making small hand gestures.
Yeah, I don't think we can solve that right away.
But that's definitely.
Identifying as a problem is the first step.
Yeah. And I think it's been identified and I like that it's being broadcast.
And there are people working on ways around it, or at least like part of it.
I think one thing that would help a lot.
Well, there's, there's CIFAR, there's group houses.
There's like unschooling centers that people are kind of talking about.
I'm not sure if they've actually taken steps to making any of them yet, but.
Well, and just like serious conversation about getting rid of the, the allergy to
having leadership in the community.
Yeah, like solstice.
Yeah. You know, one, one reason I think that it's hard to get people to rally behind it.
Cause like if we had an obvious or several obvious case examples of again,
torturing the baseball analogy, but like awesome home run hitters that look,
I've been crushing it left and right.
I can show you how to, that sounds like the title of a self-help book.
But if there were people from the rationalist community who, who were big and had a platform,
that could, that could be models for success.
If you do this stuff right, I think that would go some distance.
Maybe we just need better PR.
Better PR, better bigger, you know, more high name or more high profile names.
More people willing to put the label rationalist on things that they do.
Yeah. And, you know, it's nice hearing, you know, I just, cause I was,
I've been reading Sam Harris' books since he started writing them in what 2004 or five.
And in the last few years, he's been talking, you know, he, he, he, he drops terminology from
us wrong community. He, and then he, you know, he's openly talked about, you know,
concerns from AI and talking with Eleazar Udkowski and this and that.
And this was somebody who's already a high profile figure who, you know, got into this stuff,
learned from a, learned all the, you know, and was otherwise, well, you know,
smart and respected and got into rationality and then came to the same conclusions of the,
the concerns of the community shares about, you know, AI and that sort of thing.
Effective altruism. He had MacAskillan too. So it's a, that's, that's one way to go.
Or at least one thing that would be nice. Yeah. If, if Elon Musk got in front of a microphone
tomorrow and said, yeah, reason that I, you know, am a, a billionaire is because I was a big fan of
Les Rong. That'd be kind of cool. So we're using people to do that. So I think he's been doing his
business thing since before Les Rong was a kid though. Yeah. That kind of comes back to the
issue though that I meant Elon Musk like figures. Okay. Although he could say the reason that I'm
not bankrupt yet or something, right? I don't know. He wouldn't say that, but something like that,
right? You might say the reason I got kicked out of CEO of Tesla is I don't mean to cut you off.
Sorry. Oh, that's okay. It was, I was thinking about, there was some post on social media recently
where somebody had been writing about Bill Gates and Elon Musk and a bunch of other people, you
know, they don't slack off. They get up early every day and they read the news and they're always
working. And if you had their work ethic, you could do awesome things too. And bullshit. Yeah.
Well, yeah, because I forget who brought it up. Well, I forget who brought it up, but there are
also geniuses. I mean, some people do start off at different levels and I'm never going to become
Elon Musk. I'm never going to be as good an engineer regardless of how many hours in the day I have.
Well, not with that attitude. With these, with these nine simple steps, who sure can.
Well, in addition to being geniuses and having a good work ethic, they also got lucky. I mean,
there's other people as genius as them out there who didn't. And there's people doing their laundry
and buying their groceries and, you know, they're freed up from a lot of stuff that people have
to do as well. So that's worth considering. Even just like, you know, not being a third living in
the third world or, you know, being impoverished or being sick. Yeah. Yeah, total health is huge.
Well, and like you said, the slack that you get from being able to spend all the time you want
doing real stuff and not spending four hours a day doing menial tasks like the rest of us,
or 10 hours a day if you go to work, right? Like what are we supposed to do in our free time?
It's hard to do things in your free time when you're burnout too.
That's exactly. That's the point I was going to go into next was that there is something to be said
about the work ethic slash motivation. You know, I remember there was a some talking head thing of
Elon Musk 10 years ago or so where he was talking about how he, one of the things he realized when
he was working on as, you know, a younger engineer was like, I realized I could get twice as much
done if I just worked 80 hours a week rather than 40, like my competitors, I could work at the same
rate and finish twice as much. And it's like, sure, Elon, you can just say that and you can have
what it takes to work 80 hours a week. But like most of us don't. And just not having, you know,
enough fuel in the tank to do that is something that slows at least slows me down. I had a friend
who, you know, he long story short, he was a very energetic guy. I mean, he was just, you know,
always able to do things. And I would look at this guy and like, man, if I had his energy,
I could take over the world. And while that might not be literally true, I feel like I could get a
lot more done. If I wasn't, you know, just a lot of us are just tired. And if you are some freak
of nature like Elon Musk, and you don't get tired, it takes you three times as long to get tired,
then you can get three times as much done. Mental disorders mess with you a lot too.
Yeah, or physical disorders. Yeah, exactly. And there's something, the opposite of mental
disorder, I don't think it has a word, because it's not the kind of thing you go to a doctor to
get diagnosed. But if you just happen to be three times as happy as everybody else, or, you know,
three times as energetic, and it's not disrupting your life, that's that opposite of it's still
it's what I meant by geniuses. I'm not referring to raw IQ, referring to maybe just like has more
motivation than average. Okay, yeah, then that's I would different uses. That's a definition of
the term genius that I think is very on. Well, it's just for lack of a better word. I don't
know what else you would use to describe someone that has the opposite of a mental disorder,
like what you were saying, lucky sons of bitches, maybe genetically gifted or L sobs, we can just
call them that. Oh, okay. Yeah, lucky son of a bitch. Yeah, I mean, like, you're casky might be
someone who's a classically a genius, but suffers from motivational issues, right? I don't know
where he's at with managing that in his life now. But I remember, at least in some of his posts,
he's talked about that being a blocker for him. And I mean, if something like Madaf and L2.0 was
the cure that you could just drink every morning and have no no downsides from please someone
invent Madaf and L2.0. And if it's someone in our community, anybody who's listening to this,
I want it. I'll buy it. And if you need to have a bunch of Madaf and the one point,
do it, then do that. We'll call it Rachelonium. So people will never miss the connection.
So it's gonna have a picture of Harry Potter, James Evans, very snapping his fingers on the
bottle. Perfect. And I mean, so I don't want to belabor that too much or use that as a cop
out, but I don't want to dismiss that as a big factor that we don't all have the the factor,
the luck, the prior powers that people like Elon Musk and Bill Gates have, right? I don't
think we all have to be like them, just being able to be better than we would otherwise is
a win. Yeah, but we would be winning harder if we were all if we had whatever that is, right?
I mean, I guess that's true, but everyone would be winning harder if they were better,
smarter, faster and stronger. Well, that's why I think combating Acreasia and then also coming
up with the Madaf and L2.0 or whatever important steps, important problems that we haven't really
devoted as much time or attention to. Yeah, that's something else we should be working on.
I'm going to say we and not me because someone else who has the time and energy and money to do
it. So we in the you sense. Yeah. I'm planning on actually going to school for clinical research,
because I do actually want to try to develop new drugs and new like medical technologies.
That sounds awesome. Yeah. The closest I noticed somebody doing that was somebody I knew who was
really into psychedelics when they were like in the early 20s and wanted to go learn everything
about that. Now they're like a biomedical science or biomedical pharmacologist or something.
Doing psychedelics did have something to do with it. I had the idea before then,
but like I've always been fascinated with drugs and the way you can when you break the brain,
you can really kind of like see how it works and realize this is just a computer
in some sense that like you can actually you can you can fix this you can make it better than it was.
That's an important insight that yeah, if you're if you're starting from like Wallace,
what I've got to work with, then that's realizing that that's a defeatist attitude,
not a realistic one is an important insight. I like the insight that the reason people
see spiral so much when they're on psychedelics is because that's literally how the the retina
is wired into the visual part of the brain. Yeah, it's super cool. Like you can actually start to
see like your own cognitive biases in a way and just like, for example, I combined two drugs that
I shouldn't have at one point. And I got like really high and weird, but I started being able
to see how my visual system worked. I saw like what looked like lots of photos every time I would
move my eyes. And I realized how much blank space that there was. I was like, how do people do
anything? How do we see how do we drive? This is we're like really bad at seeing and processing
you were able to like see that when you move your eyes, your vision blacks out for a second.
Yeah, I saw like saccades of images. And there was so much blank space, I could see all the
space that was missing in my peripheral vision. Oh my god, what were you on if you don't mind?
I combined a prescription drug with a think it was cemax and midephanel. And there might have
also been caffeine. I don't know. I'm not sure exactly what the combination was that messed me
up. Cemax. Cemax is a what is it a peptide nitropic. It's a Russian developed drug.
Okay, interesting. It's pretty good. So it's more difficult to get now that serotropic doesn't
exist anymore, but you can buy it from Russia. I thought you were gonna say like, you know,
something in mushrooms, but these weren't even psychedelics. This was a nitropic.
Interesting. Okay. And a pretty good one. If you like midephanel, you might like cemax.
And if you don't, if you don't stack them. Yeah, probably. Yeah, don't stack things.
I think Scott had warned about that too. That's a tangent. But if you take the
tropics, probably don't stack them together. I did want to also point out the rash, the last
rationalist on his blog also replied to this and addressed a, like the where they view the root of
this coming from, because the whole rational should win thing is from a, a post when entering in
the sequences. So the last rational says rationality is systemized winning is a slogan that was
adopted to patch a bug in human cognition, namely our endless capacity to loot ourselves,
delude ourselves about how we did in an attempt to save face, because, you know,
it's really easy for someone to say, look, all my plans were great, the expected utility of this
plan was great, but it just failed because of bad luck. And really what a rational agent,
a rational agent is an agent that always chooses the action that maximizes expected
performance, right? You can't always know how something is going to happen. But you know that
you should always bet on black over double zero, because half the items are black on the red light
wheel where there's only one double zero, assuming that they pay out the same, which different
conversation entirely. And alias are objective that saying that in practice, this always leads
to people saying my expected performance was great. I just got unlucky this one time, which was
why he went with the slogan rationalist should win, that if you're losing a lot, that's a sign,
and rationalist should be winning overall. And I think there's some truth to that.
There is. The idea that I'm a great rationalist, but my life's in shambles and I can't get anything
together. You're doing something wrong. You don't have to be a professional pilot or helicopter
pilot to see like if you see one crash in a tree, like, oh, that guy probably screwed up,
probably, or like maybe that was their best emergency landing or whatever, but that's the
parable, right? Like, you don't have to be an expert to see like, oh, yeah, if you knew what
you're doing, that wouldn't have happened. But then people always like get into arguing about
why don't rationalists win? Like every single time something comes up, it's like, well,
rationalists aren't at the top of this. Why aren't rationalists winning? Maybe we're just not that
good at rationality. I mean, that could be one too. But I think it's more like the question is,
as Eliezer said, what wins systematically? And then let's define rationality to that.
What decision algorithm, when it's implemented, will win more than any other? And as opposed to,
you know, have you won in every single goal that you've sought to go after? Yeah. And if there was
like a community of people that was, I think that was seller Vulcan's argument saying that like,
you know, there are people that are winning at business or there's people who are better
super forecasters, although somebody argued in the comments that actually they had met a
bunch of super forecasters and they were rationalists, but oh, they were. But yeah, that was the
seller Vulcan's whole argument was like, we're not doing instrumental rationality as well as
we're doing epistemic because we should be looking at what these people are doing and figuring out
how to do it ourselves. Yeah, but I think what we talked about that a bit that a lot of the success
of those like individual cases was like luck or, you know, having a huge safety net or something,
right? I can afford to take a million dollar gamble if I have $400 million left. Yeah. I think
the other issue is like things like prediction markets aren't something that interests me personally.
I'm not going to go bet on things like they were saying, well, why aren't we all just betting on,
you know, prediction markets? That just doesn't interest me. It might be a good idea to do,
but like it might be a good idea to go start a business. And I probably could run a pretty
good business based on like, you know, what I've learned from rationality, etc. I just don't want
to. Yeah, I think that's like the metrics of how you measure this sort of thing, you know,
but it's just having a lot of money and being happy then. And people define success differently.
So like saying that it's winning, like I think a lot of people kind of automatically jump to, well,
why aren't rationalists winning at these things? And they're, you know, not really looking down at
why aren't you winning at whatever you value. Right. Why aren't rationalists winning at being
rich and famous and in power? And like it's also hard to tell who's not failing. Yeah.
And avoiding failure. Exactly. And that's why I like, I mean, not feeling is a lower bar than
winning, but it is a kind of winning. You can't, you can't keep playing if you lose. So I mean,
it's, I don't know, getting better at that seems like a win. And that doesn't,
that doesn't put you, you know, at the top of society, unless you're trying to get there or
something. But yeah, I mean, I, I'm, I've got this thought half baked in my head that I'm trying to,
to verbalize while it, while it's coming together. And that's not going to work. So
I'll, it's not quite coming together for me, but it's something along the lines of like,
there are examples of people that are kicking ass in the sense of winning and why aren't more
rationalists doing that. But I don't know if they're all following a kind of like similar
techniques that we're all, that we all don't have. I, I would, I, I would suspect that many of the,
like winning cases of people, you know, Bill Gates, Elon Musk or whatever, they had some prior
things in common, they had some luck factories in common, and now they have, now they have outcomes
that are similar. But those aren't the kinds of things some of them aren't anyway, the kinds of
things that you can just have. Again, Elon Musk's work ethic is something that I just don't have.
Can I point out what I think is an example of rationalists winning on the small scale a lot?
Totally. Please do. Okay. Boot camps. Because right now, absolutely everybody goes to college,
which is, you know, driving the price of college up insanely high, and also leaving all these people
with tons of debt. And they've gone through four years of schooling, which is sometimes
spending a lot of time and money on things they don't necessarily need. Whereas the boot camps,
I first really heard them pushed in the rationalist circle, and they're kind of ideal for people who
have the rationalist neurobiology, because we're already somewhat analytical and, and
thinking in those terms anyway, that make for good coders. And the boot camp gets you in there,
teaches you the things you really need to go out and start a job, and doesn't cost that much,
doesn't take, you know, relative to college, doesn't take that much of your life relative to
college again. And you can right away get out the door and start at a pretty decent income,
like generally starting at 60,000, which is much more than an entry position is in almost any other
industry, and move, you know, just move up from there. It seems like this is a small scale win for
a lot of rationalists. And I mean, the community kind of found it by itself. That's what I did.
And it was a pretty large scale win to me. That's what I'm going to do. The clinical research is
also a boot camp. What is the clinical research program is a boot camp as well. And I think that's
the way to go. Maybe, you know, so it's one of those just kind of identifying a failure mode in
the way that things are usually done and saying, no, fuck that, what's a better way to do it?
Not, well, here's what everyone's doing. I guess I'll just do that too. And, you know,
people would argue that there's other benefits to college or something, but I don't know if those
benefits are worth, you know, $80,000 worth of debt. So, you know, if you can go to a boot camp
for $10 or $20,000, yeah, that's that's a big chunk of change. You need to have that, you know,
ready or be able to get a get a loan for it or something. But the idea that you can go through,
knock this thing out in three or four months and then hopefully start working and being able to
to earn that money back very quickly. It's the kind of munchkinny shortcut that sounds like
right up our alley, right? And it works. Yeah, there's there's large successes from it.
One of the things that I also think boot camps have over traditional schooling is that there's a
goal at the end of it. Like if you're going to a coding boot camp, you're being specifically
trained to work. The reason that people want to hire people who come out of boot camps is because
they know that they've been specifically trained on like Python or whatever they need clinical
research. Yeah. And school, you know, if you go to a four year college, you do learn a lot of other
stuff and that's cool. It's great for personal development. But you don't come out of college
necessarily trained to go right into a career. I wasn't at all. I got an art degree. I wasn't
trained to be an artist. I had to teach myself how to be an artist. They didn't teach you anything
about pricing or about getting clients or about marketing yourself. It was like it was terrible.
Whereas in a boot camp, they do teach those things. I don't know about art boot camps,
but in I don't think there is an art boot camp, but I feel like there should be.
I don't want to run a business. But I mean, part of what they do less so at the boot camp,
I went to but more at others, they do focus on resume development and practicing interviews
and like here's how to get a job because that's what you're here for. Yeah, you're not here to
learn the fundamentals of computer science and learn, you know, the history of the computer.
Yeah. Here's the long definition of a touring machine. Here's Ada Lovelace's birthday.
Like you're not here to memorize a bunch of, I don't know if it's that trivial, but like
a lot of other classes are. You look at dates of famous scientists or something, right? So
none of that bullshit in a boot camp. But you're in there to get a job and the boot camp looks
good if a lot of the graduates get high paying jobs. So they want you to do that. It's one of
those great reciprocal relationships where what makes them look good and what they want is also
great for you. College, I think, is less focused on that because it's a great, it's a prime example
of a lost purpose. I do have one final quote from this, from the last rationalist reply. It's kind
of a long one though. If you guys want to let me, okay. So this is in reply to Elias are saying that
rationality is more like a systematized winning. Last rationalist says systemized winning is not
an actionable definition. Most domains already have field specific knowledge on how to win.
And in aggregate, these organized practices are called society. The most powerful engine of
systemized winning developed thus far is civilization. Most people trying to explain the value of
rationality assume that there is such a thing as instrumental rationality methods to systematically
win over and above the usual practices of civilization. If someone asks, look, if I go to
college and get my degree and I go start a traditional family with four kids and I make
120k a year and vote for my favorite political party. And the decades pass and I get old, but
I'm doing pretty damn well by historical human standards. Just by doing everything society would
like me to do. What use do I have for your rationality? Why should I change any of my actions from
the societal default? You must have an answer for them saying rationality is systematized winning
is ridiculous. It ignores that systematized winning is the default. You need to do more than that to
be attractive. I think the strongest frame you can use to start really exploring the benefits of
rationality is to ask yourself what advantages has over societal defaults. When you give yourself
permission to move away from the systematized winning definition, without the fear that you'll
tie yourself in knots of paradox, it is then that you can really start to think about the subject
concretely. So I guess my ultimate question is what advantages does rationality have over societal
defaults? Alright, he wants to go first. I'll go first because I already said my answer. My first
one that comes to mind anyway is that it helps. It's the art of not losing. I think there's a
post related to this. There definitely is a post related to this that not sucking is more generic
than like six, like then being great at what you do. But just the ability to identify weaknesses
in your plans and in your, your steps is immeasurably valuable. I think that that I mean,
there are probably definitely other avenues that teach that sort of thing. But it's one thing that
I've noticed from it. I, when I think about how am I going to address this problem? I have
inner dialogues that I ask myself questions like what if this happens had what, you know,
are you sure you're not just thinking about it, you know, because it makes you feel good.
All of the, the ways that, you know, whether it's, it's a failure mode of just like making a wrong
bet or whether that's like buying a bad lottery ticket or running a red light or something,
or just falling into the trap of believing something because it feels good or, you know,
slipping into a bias or something like that, right? It gives me, I keep picturing bumpers
like when you're bowling, you know, putting up those bumpers doesn't make you hit strikes,
but it keeps your ball on the track and you're going to hit a pin, right? Whereas otherwise,
it could go off at any point on the track. That's a really bad analogy, but that's what
I've been picturing this whole time. That's a good analogy. So yeah, for me, I would say that
it trains you on how to inflate those little bumpers that they used to get the bowling
ball on the track. I'm enjoying the metaphors. I like your answer. That's a good consequentialist
answer because I guess people who are thinking about rationality being systematized winning,
it's kind of, oh, like, why aren't we all Elon Musk? But you have to think about, well, even if
just like the marginal utility you would get from increasing everybody, just like a few steps up
from where they are now in the world, kind of like related to, I guess, the idea of raising the
sanity waterline, how much better would the world look if fewer people were losing? And maybe that's
something we should be focusing on more. Maybe that's even a more achievable goal. My answer,
I think, just comes down to picking good problems to work on by knowing what's true. And that's
still going to be different for different people. Like we were talking about before, you know, you
get to pick what your definition of success is. But like, say that a lot of people have the goal
of improving society, which I think is a pretty common goal, they'll be better able to achieve
that goal if they know true things about what a good society looks like, what actions actually
improve it, and how not to delude themselves into thinking that they're pursuing this goal when
they're not. If they have that knowledge, they'll do better at improving society than they would
if they went with the societal defaults. Yeah, I like that a lot. And, you know, societal default
might be, sure, you had your four kids, your 120k or whatever, but you spent 80 of that getting an
education that you didn't really need. So, you know, what would you have won if you'd done a
bootcamp instead to get into your career? You would have won $60,000. Yeah. And three years of your
life. Yeah, exactly. And societal default right now is you get to about 75, 80 years old and you die.
Right. So, fuck that too, right? Yeah. So, maybe there's a separate thing that I don't want to
try and get sneak two answers in, but this isn't really so much of something that you get. This
is just a viewpoint that you're, but at least one thing I've got out of this approach, this
rationalist approach to life is not being content with like the way things are, basically
transhumanism. I was already into that before this, but it was the best defense I've come across
with the whole thing and the idea that transhumanism for, well, I guess, transhumanism for people,
but for society as well, for the world, you can look at this and say, no, we can do better.
Rather than say, how can I make what they're, you know, you can build better mousetraps rather than,
or you can figure out other ways to solve the mouse problem than just build better mousetraps.
It's maybe the analogy. The skillset to say, no, I'm going to start from scratch or what's another
let's make everybody Elon Musk, right? That's better drugs or, you know, genetic engineering.
Yeah, rather than teach everyone to just do what they can with what they've got,
we could say, no, we can give you more, right? Just the ability to do more start from scratch
questions. Of course, delivering on those is something that we need to start doing, but
I think it's valuable to at least say, no, we need more time and we need more members.
But, you know, imagine like if all the, the, the progress in transportation had just been
building faster trains and nobody thought about building planes, right? Like this,
this is the kind of thing that's like, no, we can, we can build planes too. And I'm
hoping my metaphor is just landing because I don't know how to.
Yeah, you have to be able to pick good goals. Right.
Like do what 80,000 hours is doing and okay, like let's actually assign people the career of
identify priorities. Yeah. No, totally. All right. What's your secret answer,
Enyash? So my secret answer is kind of, it's very related to your guys' answer in part being that
lots of times, okay, so what people really want is to be right, right?
And society has a lot of defaults and you follow them, generally you'll be okay.
But there's a lot of ways for people to fool themselves in the thing they're right and for
society to fool itself into thinking that things are going just fine when they really aren't.
And I think rationality is the, the art of noticing when you're wrong
and allowing your yourself to be made right by the facts of the world.
Instead of trying to argue vehemently that you're actually right and you were right all along,
or that society is just fine and there's no problem with AI and you guys are all, you know,
crazy chicken little sky is falling type of people. It's, it's the practice of really looking at things
and updating yourself when the evidence is against you.
So I think it comes back to the whole truth seeking aspect of things, not trying to deny how
things actually are and changing, changing yourself, being proven right by changing yourself
so that you now have the right position as opposed to arguing that things were right all along.
And I think that society has a lot of problems with that too, that saying, no, we're fine,
you know, America is the greatest or we don't have any problem with this drug use or whatever.
My facts are the right facts.
Yeah, yeah, exactly.
My facts are just as good as yours.
Right. Yeah.
The, the actually evaluating facts and being able to say these facts are right and these so-called
facts are wrong.
And there's already an enterprise that does that, but one of the posts, one of the wrong posts we
might talk about if there's time today, deliberates on that a bit, that like science already tries
to do that, right? And scientists try to do that as people.
And yet it's possible to be a scientist with a PhD and a job and everything and still think
they're the 10,000 years old.
Should we segue right into the rest long posts then?
If you're, if you're ready.
I mean, that was a great segue, but I'm done here.
But do you guys have other things to say as well?
No, let's move on.
No, I think that was a good, good segue.
Okay, cool.
So that brings us directly into our less wrong post section of the show.
Okay, our two less wrong posts this month or this episode where some claims are just too
extraordinary and outside the laboratory.
Steven, you were just talking about outside the laboratory, but let's start with some
claims that just too extraordinary because chronologically that one came first.
Totally.
Okay, cool.
So some claims are just too extraordinary.
Okay, is a post about the nature of evidence and how it relates to extraordinary claims.
And sort of a defense, a defense of the hubris of science.
Yes.
Yeah.
If you want to call it hubris, rather defending what science is, isn't hubris.
Exactly.
The post basically says that some claims are really absolutely extraordinary.
It starts off with a quote from Thomas Jefferson who says,
I would sooner believe that two Yankee professors would lie than that stones would fall from heaven.
And that was his take on meteors.
And the post points out that there is a method of getting to the truth that is optimized for
weeding out false claims.
And so it counts as extraordinary evidence and can thus substantiate extraordinary claims
like rocks fall out of the sky.
The quote that I pulled from this is a replicated scientific report is a special kind of extraordinary
claim designed by the surrounding process to be more extraordinary evidence than simple verbal
claims.
It is more extraordinary evidence because the surrounding process, and I would place a far
greater premium on replication than on peer reviews, by the way, is constructed to deny
entrance to claims that are in fact false.
In this way, the replicated scientific report becomes capable of overcoming greater burdens
of prior improbability.
So yeah, it was basically a post on why science scientific evidence can be trusted, right?
Yeah.
And I think I had that joke before about like, I won't take your word for it that were always
exist.
But if you brought me up with dead werewolf, I believe you, that's sort of the extraordinary
evidence to just to substantiate that extraordinary claim.
And that's what science does.
And I want to reiterate that when I said that there's already an enterprise that sort of
does the truth seeking thing, that's what science does.
But they do, I think in my experience of not being a real scientist, they focus less on
like the self improvement part of science, like, you know, it's less important that like,
you're a better and more updated, well, well, rounded calibrated person, just more that
your test results are accurate.
Whereas rationality is like, no, it can be about you to there's a virtue of rationality,
but there's a practice of science, maybe there are virtues of science.
I don't know.
Yeah, science does double blind, which, you know, shows that they have some awareness of
the fact that we dilute ourselves, that there's been a lot more work on that like,
pretty recently to true replication.
Crisis and yeah, I found it interesting that he posted in here that he puts far greater
premium on replication than on peer review.
And this was before the replication crisis where he said, you know, peer review is okay
and all, but I the reason I point this out is because I was, you know, part of the whole
atheist scene during the early days.
And whenever people tried to bring about, you know, like, I know that God existed because
I saw my mother being healed from whatever she had.
I the one of the go to replies was, that's great, but that's your anecdotal evidence,
which I don't believe because you're easily fooled.
Is it, you know, has it been published in a peer reviewed scientific journal?
And there was always this focus on peer reviewed.
And apparently that has not really been high enough of a bar.
Lots of things get past peer review because people are just sort of reviewing what you said,
right?
And having the having things actually be replicated is where the big deal is.
And that's where we got the replication crisis when people started trying and failing to
replicate things.
And to be fair, peer review is a higher standard than most people hold themselves to.
Right.
So most people just allow themselves license to believe whatever they want.
No, they won't ask their friends or they're, they're trusted smart allies to, to corroborate.
So doing that, at least science is ahead of the curve there, but it's not high enough.
They can do better.
And I specifically remember because I'm multiple, many times myself said, you know,
peer reviewed scientific journal.
And then I felt stupid.
Yeah.
Cause I used to do that too.
I was specifically focused on the peer review aspect.
I don't even know why probably just cause I heard so many other people say that.
Right.
It was a teacher's password.
Yep.
Yeah.
Well, and, and the, to the thing of scientists having double blinds so they can correct for
their own biases, that's true, but they, but it's possible to do that as merely a thoughtless ritual
and not do that as like a cognitively sapient person, right?
Or again, the, the, the scientists who can fully believe in whatever magic bullshit they want,
but get paper published cause they're, they're doing the rituals, right?
That's where the next post comes in.
But I won't skip straight there, but I'd see.
I did really like the Thomas Jefferson quote because like there, there were three quotes
at the beginning of this post and the latter two were both posted very approvingly.
And when I first read that Thomas Jefferson quote, I was like, aha, that's funny.
Look at how wrong he was.
But after I read the post, I went back and read that quote again.
And I think that was also meant to be an approving quote.
Like this is the correct way to do science.
Like Thomas Jefferson heard from two guys that rocks fell out of the sky and that was
not good enough for him.
And yeah, it really shouldn't have been, but the scientific method does exist.
And so people managed to replicate this.
And at this point in time, no one doubts that rocks fall out of the sky.
We all know about meteors because science has proven it and over and over.
And I don't know if Thomas Jefferson lived long enough to actually see that proven by science,
but, you know, the fact remains that he might have been convinced eventually,
whereas enough scientific evidence accumulated because scientific evidence is a very special
kind of evidence that will convince, you know, anyone in time.
I wish it would convince anyone in time.
Well, it should anyone, anyone who's trying to be accurate.
Is like taking the evidence in good faith.
Yeah, what you're saying is that Jefferson's rejection of the meteorite hypothesis was
it was correct, fully, fully reasonable from where he's at.
And it might have been unreasonable for him to hear this from two people and be like,
that's it.
I believe that rocks fall out of the sky now because all he's had is just two anecdotes
or rather anecdotes from two people.
Well, specifically from two professors, which I think is an important part of that too.
When we were talking about peer review versus double blinding or versus, you know, replication,
the people who are peer reviewing you were also presumably experts in the field,
but you're assuming that that means that they're impervious to biases.
They're not.
Right.
That's fair.
Yeah.
It's like argument from authority.
Yeah.
Jefferson accurately, you know, correctly applied Occam's razor there.
Yeah.
Yeah.
And he happens land on the wrong side of the position, but that's because he's using the
best tools yet at the time.
You have to imagine that if he had been presented with evidence, he would have said,
Oh, now I have the evidence.
So I'll update in favor of rocks falling from the heavens.
There you go.
And I mean, that, that wasn't just the thing that happened back then.
Continental drift wasn't really accepted until what the late fifties, early sixties
up until that point.
There's still people alive today who, you know, thought that the earth was an unchanging,
solid thing and had to be convinced over a period of time with the accumulation of
evidence that no, it actually moves and changes, which is kind of fucking crazy.
If you think about it, right?
The only reason it doesn't seem crazy is because we already know it and accept it.
There's a lot of wisdom to draw from that last sentence that sure, you know, sciences,
I guess you see that all the time where people don't give science all the credit it deserves
because it's like, Oh, of course we already knew that like stuff's made of atoms and that
germ theory of disease.
Yeah, exactly.
The germs are real or something because we are, we're all taught that in elementary school.
But it's like, yeah, but this was hard to figure out.
And this wasn't, this wasn't born knowledge that our species had from the beginning, right?
This was hard one.
Yeah.
You see a lot of people kind of look back in history and laugh at how dumb everybody was.
And it's like, you're standing on the shoulders of giants right now.
You would have believed exactly the same shit.
Exactly.
And I think it's, it's hard to, uh, you know, I can't remember.
I read Bill Bryson's a short history of nearly everything like 10 years ago,
which is not very short.
No, but it's, it's a short, it's a sort of nearly everything.
Yeah, nearly every comparatively, but he did talk about continental drift.
And I know that like the fact that the continents looked like puzzle pieces that was led together
wasn't lost on people through the fifties.
I don't know how they rationalized that 100 years ago, how that could be a coincidence.
How unlikely is it that the earth has moved so that these massive landmark masses
have moved away from each other?
Well, but it's, it becomes more likely that that's the case every time you look at,
every time you look at the coasts of other continents and be like, look, those fit right together.
But they don't fit right together.
I mean, there's been erosion and other stuff.
They, they, they've roughly fit together.
That explains fault lines.
Yeah.
I guess it, it's one of those things that I think that was one of the, the fact that they
look like they aren't just random shapes, you know, with relation to each other was, was.
That was another piece, but it was, you know, it wasn't
determinate.
No, no, no, it couldn't be.
That's not enough.
You'd have to explain how this is happening and that like land isn't,
I mean, everything about your senses and every experiment you can do without really good
instruments tells you that the land is just sitting there and goes all the way to the center.
And it's just, it's all, it's land all the way down.
How does, how does this move like, like a, like something floating on the water, right?
And even if it isn't land all the way down, how does just solid earth like this move?
It's not like it's floating.
Right.
Even if it was floating, there's other earth pushing against it, holding it in place.
So challenge is intuition.
Yeah.
But I guess for me, it was, I think that was always something that people would have had to
answer going back a hundred years ago or up to, up to whatever, seven years ago when they figured
finally that they bought onto this tectonic plate slash continental drift.
They'd have to at least say, look, why do they look like they kind of fit together?
And they can't just say, that's a coincidence.
And maybe they did, but that seems like a, that seems like a bad answer.
And if anything, that's like enough to incentivize people to keep looking into it and then come
to the right answer.
To me, that's like someone asking, well, why does that tree look like a, like it has a human
face in it?
If it wasn't, you know, if it doesn't take some essence from the body that is buried beneath
it, right?
It's like, look, the bark just happens to look like a human face.
Yeah.
There's a lot of things, but the answer to is, it's probably just a coincidence.
Or it's a not understood scientific phenomena that we can't like explain yet.
It's always frustrating when you do have to give those answers to people.
And it's not like the West Coast matches against Asia at all, right?
Okay.
Yeah.
You got to rotate some stuff.
All right.
Yeah.
That's fair.
It's, it's a funny puzzle and it's not perfect, but it's, yeah.
It's, it's, it's a hint.
Yeah.
It is a hint.
That's, that's what I was getting at.
Thank you for distilling it down.
It took me five minutes to get there.
Dark energy was also a thing that I remember.
Do you guys, were you cognizant of science yet when dark energy was discovered?
I don't know about when it was discovered.
I remember a lot of discussions around it.
Which I guess continued to this day.
It was the craziest fucking thing when, when people first discovered that the universe is
actually accelerating.
And I mean, that, that was quite the talk of, of me and my friends at the time.
Cause this is a whole new force we'd never known about, right?
I remember the buzz and discussed at least in historical context and books by like Tyson
and Hawking and stuff.
But none of us doubted it when we heard it.
Well, this actually kind of brings me back to like, I have this thought about the argument
from authority that, and I think actually, I think I've brought this up on the podcast
and received flack for it.
Now that I think about it, maybe this is a blog post back when I have a blog.
Do it again.
That if Stephen Hawking says dark energy is real and here's why, I am fully justified in
just believing him because he's an authority on it.
What would be wrong for me to say is that it's true because he said it.
What I, what I say instead is that I think Hawking says it because it's true.
Yeah.
And I, I'm not equipped to challenge him on that.
I'd update more in favor of this being true because Stephen Hawking believes in it.
Yeah.
In fact, I would bet that he's right.
I literally bet with my money.
And if someone wants to take me up on that and then go prove Hawking wrong, they're welcome to.
So it's sort of just, there's this, because this was like one of those things that you get a lot of
easy practice at arguing with religious people in your teens.
If you say, oh, well, you know, the science says that the, you know, you say, you tell somebody
a religious creationist that you're wrong, that the earth is 10,000 years old.
And they say, well, you just believe that it's 14 billion years old because your scientists say
it's 14 billion years old.
Why do you believe them?
That's an argument from authority too.
You're claiming I'm being using an argument from authority just believing my favorite book.
But it's a different kind of belief in authority.
Yeah.
It's because one, one has extraordinary evidence behind it.
Right.
They have this prestige that your book doesn't.
And if they were, if there was some big update in the community of the, you know,
in the next 50 years, they discover something, you know, another weird force of nature or
whatever.
And it's like, holy shit, guys, the universe is probably closer to 50 billion years old
than I'm going to start believing that it'd be weird of me to stick with the, with the
elder science of 1990 that said the universe is 14 billion years old.
Right.
So there's, there's a difference there in that it's flexible to the current consensus
and that consensus has huge incentives to be pushed more and more towards accuracy.
Yeah.
That's another, you know, argument you can give to the person who says, well,
you're just believing in your authorities.
It's like, well, science isn't dogma.
Right.
Yeah.
That's, that's never been good enough for them either.
If they were, we would have, we would still be sitting on Aristotle's shoulders rather
than on Newton's than Einstein's.
Right.
So there's a reason that this, that this evidence is accepted more highly than just
someone's word and it's just the bizarre irony of having that argument online of like,
look, we're having this conversation at like the speed of light and one of us works.
Yeah.
We have shot rockets into space.
We've cured diseases like, you know, what has the Catholic church done?
We have absolutely not shot rockets into space because the earth is flat.
And this is all a conspiracy.
I see.
Touche, sir.
Walks away quickly.
So it ends with the question, what about journals that came to publish replicated reports of
ESP?
So extra sensory phenomena is that what the sense where it's been a long time.
So I know what ESP is.
I just remember if I knew the acronym.
That's the idea that like, I can read your thoughts or.
Or you can push things over with your brain.
Or detect the tragedy on the side of the world with a disturbance in the force or something.
Right.
It's like remote viewing.
Yeah.
All the weird stuff that people are supposedly able to do in their heads.
Yeah.
That's just proof that scientists were, you know, fell prey to cognitive biases twice.
Yeah.
Or a motivated reasoning or whatever.
They wanted it to be true.
They, you know, like because it's.
Why are you rejecting it out of hand though?
Because it challenges everything else that we've uncovered through the laws of nature.
But then we're just trusting other authority, other peer reviewed papers.
Right.
Yeah.
This was the kind of thing that like James Randi, I mentioned, I think Project Alpha
a couple of steps ago where, you know, he sent in dummies to, or not, he sent in students to go
in to do more of like the same magic research that people like Erie Geller were being paid to do.
And at any point if they're asked, are you, are you tricking us?
They were supposed to say, yes, James Randi sent me and they were never asked that.
Because you get motivated, scientists are people too.
And, you know, they're motivated by the same things the rest of us are.
It'd be great if they were just like the super smart robots that were giving us,
you know, just pushing out truth every time.
But they're, they're asking their own questions and trying to answer them themselves.
And the other problem I think with peer review is that like you could,
you could get a peer reviewed creationist journal, and I'm sure they exist,
where a bunch of other deluded morons come together and say, and, you know, nod their heads
and say yes.
There actually are peer reviewed ESP journals.
Yeah.
So it, it has to be in the, the, the special community of real science.
But that, if that doesn't sound culty, I don't know what does.
Right.
And like, how are you defining your real scientist?
Just because it was replicated, I'd still want to look at the studies design.
You like, was it double blinded?
You know, um, yeah, okay.
I did jump too hard onto dismissing it out of hand just because of what Steven was just
talking about, like we've seen this before.
We know why this happens, but.
I would absolutely dismiss ESP out of hand too.
I just had to think for a while about why I would.
I mean, I think part of it is because it directly contradicts a lot of things that are already far
more better established about physics and how reality works.
And because there are much less unlikely explanations for those phenomena as well.
The explanation they give has, has a better answer than ESP exists.
It's easier to believe that some scientists diluted themselves than that ESP exists.
It's kind of the same Jefferson answer.
I'm still open to being proven wrong if they came to me with some extraordinary evidence.
That's the thing.
If like the entire scientific community were to be like, guys, dude, we were wrong.
There is like this whole sigh thing that taps into this other quantum dimension.
And a few people have evolved, you know, enough to be able to influence it just slightly.
And here's how it works.
I'd be like, holy shit.
Yeah, they, they discovered another aspect of reality.
That's awesome.
And we'd all love that.
And that was the, like James Randy's million dollar prize was always like a.
A little bit hopeful, right?
Well, it was, it had a sharp and a dull edge.
It was used as a weapon to call out charlatans.
But it was also like, if we ended up paying out this million dollars,
we'd be stoked because we discovered something new.
And I think, I think James, I think Richard Dawkins asked James Randy,
like, if you had this challenge, you know, 120 years ago, wouldn't you have paid out
if somebody was like using a radio and Randy thought about it.
And it said, yeah, I guess so.
If somebody had invented a radio before they existed and was using it to win our,
or to pass our, our judgment and our tests, then yeah, we would have paid out the million
dollars.
But then, hey, we would have been the ones to have demonstrated that radio existed and
worked.
Sure, they invented it, but we were the ones.
We would have happily paid out that million dollars.
Yeah, and then you'd get the radio, you'd take it apart, you'd figure out how it worked,
and then you'd have a radio 122 years earlier, which would have been a big win.
Exactly.
And so then, then the, the today analog would be like, what if somebody, you know,
proved psi or something through, through a similar thing?
It's like, well, then we just helped discover or helped seriously validate a new discovery
as important as something like that.
And so.
At which point, you can measure it, figure out what causes it.
Yeah, exactly.
And replicate it.
Totally.
So in that sense, I like the fact that you can't do anything with these
supposed ESP powers except some occasional parlor tricks is really indicative.
Right.
And.
Yeah.
Ask Wild Bo what he'd do with it.
Actually dull because he'd probably just destroy the world with monsters.
Yeah.
The, I think, oh man, I had something.
I guess I was going to just reiterate that the point that yes, if science did come out
and say, yes, ghosts are real or something, we'd all be stoked on that.
I'd be stoked.
That means death is fake.
Exactly.
I've always been my thing on ghosts or at least like the last 10 years.
You know, I've, I've always, if, if ghosts are demonstrated to be real, I would be,
I would be stoked.
But the thing is, A, I'm, I really want to be real.
So I need to be extra careful and B, I, I, because of that extra carefulness, I need
to have a very high standard of evidence.
You know, if somebody, we went to a haunted house and a cup fell off a table, I wouldn't
be like, oh my God, spirits are real.
I, you know, so like what would constitute proof for ghosts?
Like a number of people passing that Houdini seance test, right?
I don't know what this Houdini seance test is.
So, so Houdini every year, he'd said, Hey, when I die, I gave my wife a password.
You guys conduct a seance for me.
And if the spirit in the room can tells her the password, she'll know it was me.
So they now, they still, they keep doing the on his birthday or on his death day or
something.
They do the seance every year.
Oh really?
I don't know if anyone alive.
Does somebody still have the password?
That's what I was going to ask.
I don't know if anyone alive has the password.
She needs to pass it to her kids or something.
But something like, you know, if your grandma came back and, you know, it was like,
Hey, the combination that's safe in my closet is this.
And then you went in and the safe actually opened or, you know,
check behind my dresser.
I dropped my diamond ring back there and it's back there.
You know, just enough things that were verifiable communications from the afterlife.
That would be good evidence.
But, you know, a cold spot in a room?
No.
Right?
Who even said ghosts are cold?
That was my, that was one of my big rights about it.
Dead people are cold.
Sure.
But these aren't, these aren't bodies, right?
If anything, they're concentrations of energy, which might be hot.
I don't know.
But this whole thing of like, you know, we were talking about,
Oh, before, before we started recording about using like a heat gun or a thermal
reading gun to read which parts of my rooms are drafty or something.
If I see a cold spot over there, who decided that that's a ghost?
If anything, a hot, I think a hot spot is like just a priori to me and more likely to be a ghost.
So what I'm getting at is that's bad evidence.
I would need good evidence like verifiable tests.
I really like ghost hunters who kind of just decided a bunch of,
Okay, like ghosts are this, this and this.
And we're going to use these tools to find anomalies.
Yeah.
Like, like, you know, ultra low frequencies or those radio scanners that just jumped
between the radio and like, Oh my God, we just heard the word fuck.
That means the ghost is mad at us.
You know, those, those are, if there was,
We don't know anything about ghosts.
So how, how, you know, like, we've never actually had any evidence of ghosts that we
can say, Okay, this is more or less likely to be a sign that this is a ghost.
Exactly.
I remember reading an interview with a surgeon who,
on like the top of a shelf in the surgery room or wherever it was.
They put a card.
Yeah, they put something and whenever anyone had not a buddy experience,
they'd be like, Oh, cool.
What's, what's that card say up there?
And they're like, what, what card?
And I'm like, Oh, you didn't actually see anything, man.
Yeah, you didn't see that.
Put a jack of clubs up on top of the light.
Yeah.
I don't want to derail us, but we, we talked a bit about the, the next post.
Or do we want to move on to that one officially?
Yeah.
So this one was outside the laboratory.
And this one starts with the kind of tongue-in-cheek quote that outside the laboratory,
scientists are no wiser than anyone else.
And we should be very disturbed by that fact.
So we talked about a bit of, we can kind of skim parts of this because,
A, that's kind of true in some cases.
But as Yukosky, I think eloquently puts that if that, if, if a scientist is only a scientist
when they're wearing the lab coat, they're not a real scientist.
They're, they're following the rituals of science, but they don't know, they don't know why.
Did you want to read his awesome apprentice shepherd analogy?
Yeah.
Also, isn't there an audio version of this full story somewhere out there already?
I don't think there is actually.
Didn't you do it?
I don't think I did.
I don't remember there being one though.
I feel like one should exist.
I mean, I, obviously we've all read it, but I don't think I did an audio version of that.
No.
I will double check.
I think you might have, but I think you would know.
So, suppose that an apprentice shepherd is laboriously trained to count sheep as they pass
in and out of a fold.
Thus, the shepherd knows when all the sheep have left and when all the sheep have returned.
If we then give the shepherd a few apples and say, how many apples?
And the shepherd stares at you blankly because they weren't trained to count apples, just sheep.
You would probably suspect that the shepherd didn't understand counting very well, right?
And I think that's a great analogy.
The shepherd, it's just a ritual.
He doesn't understand what numbers are.
Exactly.
And if it's, if it's the kind of thing that they could only do in this one sense,
whether standing outside the, the, the paddock or fold or whatever you call it,
the, the cage of sheep when they're leaving and coming back and they can't
do anything else, they don't, they don't understand the principle and they're not.
So in this case, this, this shepherd isn't not a scientist, but not a real counter.
Mathematician is probably too strong of a word, but
I'm kind of just breaking my brain, trying to think of like,
whether that would even be possible that someone could count sheep and not apples.
Like, are they using a different kind of math?
Well, you know that after two comes three, after three comes four, after four comes five.
And then once the sheeps are coming in, you go backwards.
So it's just walking up and down, you know, a, a, a path,
but it doesn't necessarily apply to apples, right?
So what I think you're saying, what Jess was saying is that, is that,
is that possible that a human could be that compartmentalized?
And I don't know if it's possible with counting if it's cognitively possible with humans,
but it definitely is in other slightly more complex domains, right?
It's obviously possible with science, with beliefs about the world.
But yeah, I think like math is, I don't know, I know we should just move on.
That was just like, I was confused by that analogy because I was like,
I don't think math works that way.
No, I see what you're saying though.
Like, can you really be that broken?
And maybe not that broken, but slightly less broken.
Okay. It still makes for a very vivid analogy though.
Yeah.
Yeah, kind of ruined it, I'm sorry.
I disagree. I think it's fun to think about.
So yeah, I mean, is it a racialized tradition for testing hypothesis experimentally?
Like, why should you test them experimentally?
If you're, if you're a scientist and that's your job, that's why.
But if you're a lowercase s scientist and it's your job, that's why.
You're capital s scientist and that's who you are.
It's because you want to have an accurate map of the territory
and testing is the only way to do that.
Yeah. He has this thing that I sometimes quote, not verbatim, but I make this analogy
as well that when you look down to see your shoes to see if your shoelaces are untied,
photons arrive from the sun, bounce off your shoelaces, strike your retina,
are transduced into a neural firing, are reconstructed by your visual cortex
into an activation pattern that's strongly correlated with the current shape of your shoelaces.
So to gain new information with the territory, you have to interact with the territory.
His, his thoughts are correlated with the, the photons which are correlated with the shoelaces.
There's this direct chain that ties everything together.
There has to be some real physical process whereby your brain state ends up correlated
to the state of the environment. To find things out, you have to go look.
And then he goes on to say that, uh, what about a scientist who is competent in the lab,
but outside believes in the spirit world? If he says something along the lines of,
well, no one really knows. And I admit that I don't have any evidence,
but a religious belief, it can't be to prove disproven one way or another by observation.
Then, uh, there's just says, I cannot but conclude that this person literally doesn't know why you
have to look at things. I think that's the, that that's, um, the puzzle that that you're
thinking about, Jess, when you brought up the, the counting person, like, is it possible that they
really, I don't know, it sounds like he's being uncharitable, but it might really be the case,
right? Yeah. Like maybe they just see apples in their brain just blanks. Like, no, that's not
what you do with apples. You do that with sheep. Apples are for eating. It's, it's really frustrating
that, um, whole paragraph about the shoes and the sun and the photons, because I wish there was a
simple way I could use that when I argue with people who don't understand why you have to look
at things. Like people who believe in ESP, it's like, well, there's like a, what, what is your,
you know, proposed mechanism for how you can communicate with someone on the other side of
the world with your brain? Do you understand how matter works or energy or neurons? And like,
they just don't, or they just don't care. They're like, well, there's some kind of energy that does
it. I'm like, no, that's not, we, no. And I wish I could just kind of quote this at them, but then
like they, you know, you can't realistically, okay, let me get my phone and pull up this sequence.
And then I'm going to talk at you for a while and you're going to listen.
I could think of a really butchered way to do it, which where you grab a coin and a gun,
catch it in your hand and don't show the person and then say, is it heads or tails? If you guess
wrong, I'm going to shoot you. And do you want to look first? And if they say no, then they're
being crazy, right? But if they say yes, then they're admitting to the value of looking at things,
right? Yeah, but that's not how they think of looking at things. I have actually quoted this
thing to someone before. I mean, I just remember the basic gist of it, you know, did it work?
I don't remember. Yeah. And I think it helped to illustrate a little bit more of what, you know,
what I meant by entangling your beliefs with the physical world.
For virtue, for the virtue of being right, sure. But I think that the literal gun to the head
analogy does illustrate that like, no, look, if you really don't want to get shot, you have to
like admit, you probably want to see what the coin came up, right? Yeah.
It's not socially acceptable to point guns at people. Maybe you could bet a large amount of
money. And I thought about that, but the guns seem to be more intense analogy. But not in real life,
but just the idea, you could give this thought experiment to somebody, you don't have to actually
have a gun, right? Yeah. So I guess, yeah, if you encounter someone that says that like, I can do
ESP, like me and my brother can communicate, that's like, okay, I'll give you $100 if you guys can
communicate something. I bet people money. I've never had anybody take me up on it. Yeah. But
I've also, back when they were doing it, referred people to the James Randi challenge.
And you can't just offer to give them $100. You have to get an actual bet. So they give you $100
as well if they lose. Right. Yeah. And I will do like, Hey, if you can do this, I'll give you $100.
If you can't, you give me $10. Yeah. Yeah. I'll do a 10 to one bet with you as high as you want to
go. Yeah. 101 to one bet, like screw it, let's do this. So yeah, I think that's the virtue, I guess,
of literally putting your money where your mouth is, I guess, figuratively putting your money
where your mouth is, because literally joke about eating money. So the idea that like, no, look,
if you really believe this, you should be prepared to take this bet. If the fact that you won't take
this bet means that you don't really believe it. Right. I think there are, I think it was mentioned
in the post as well, though, that the the sheeps and the apples thing is, because lots of times,
I mean, we live at such a higher level of the world than where physics happens,
that lots of times it does look like different rules apply to different things. Like birds can fly,
squirrels can't. Why exactly is that? I don't know. You know, they appear to work with different
rules. Like the sun is in the sky and doesn't fall down. Unlike every physical thing we've
ever seen. Why does that work? I don't know. There's different rules for the sun and the moon
and things that are up there. And I think, and he, Elias pointed out that once, once you know
why the rules work, you can see that they're the same for sheeps and apples. And where was
what did he say? Oh yeah, Isaac Newton is just revealed, revered, not for his outdated theory
of gravity, but for discovering that amazingly and surprisingly, the celestial planets in the
glorious heavens obeyed just the same rules as falling apples, which is kind of a big deal.
Yeah. I liked the, well, I'm a bit of a digression. I liked the, you know, the bad answer to why
might things be this, you know, if you could be that compartmentalized, it's like, all right,
so if seven sheep go out and eight go out, 15 had better come back. Why 15 and not 14 or three?
A bad, you know, if someone doesn't really understand counting, the reason might be because
otherwise you don't get dinner tonight. If the wrong number come back, but
But if you understand the rules, there's a deeper reason.
Right. And then that's more generalizable. Yeah.
So at the very end of this post, he brings it back to, this is entirely a coincidence,
by the way, I did not plan for these two things to coincide like this, but he brings it back to,
maybe we can beat the proverb, be rational in our personal lives, not just our professional
lives. Maybe we can do better. An ambition that lacks the comfortable modesty of being able to
confess that outside of your speciality, you're no better than anyone else. And that, yeah,
I mean, I guess that helped spark the whole rationalists should do better in the world than
people without rationality thing as well, because you should be able to do better, right?
If you're able to really actually understand the rules.
Yeah. If you think of winning is making your beliefs pay rent rather than a, you know,
your terminal goal should be to run a successful business or to be the next deal on musk,
then that makes a lot more sense. It's just a way of checking yourself.
So you wreck yourself less. Yes. Nice. Yeah. I was, I was, when I read that,
when I read that, I was very, he, he links the comfortable modesty back to the post about that
we covered, I think either one or two episodes ago about false modesty. I almost didn't pull this
to include it in here because I felt like really scared and challenged by this line.
As in I was like, oh, shit, now I have to do better in the real world. I can't just say, look,
you know, I'm doing the best I can. I, I'm just, I'm just another guy like everyone else.
And now I'm like, fuck, this, this is calling on me to be better and not just hide behind the
false modesty of, oh, what can you do? Well, and that's what the community is asking us too.
And that's how it ties in really well to the episode, right? The community wants to know why
aren't we crushing it all the time. And there's people looking at answers for that and how best
approach is, but the sense that there's, there's this sense that I think I agree that we shouldn't
be content to not be doing better. If there's, if there's avenues to success, we should be damn
well able to incorporate them and use them, right? Especially if there are things we actually want.
Yeah. And there are things we want. We listed a bunch of goals that the community did have,
you know, improving AI, improving, you know, epistemic rationality, improving, you know,
people's cognitive awareness of biases and whatnot, effective altruism. If these are things
that we do all agree that we want, then I almost think it's a cop out to not pursue them.
Yeah. And we win by not destroying the world every single day. Yeah.
Baseline winning. That's not losing. All right. I think it also helps us to function
better in a society that is not optimized for us. Yeah. What do you mean by that?
I don't know. I think that society is more optimized for people that.
That just want to, you know, follow baseline reality. Yeah. Have the two kids and the house
and certain salary. I've always felt that I don't fit into the world very well, that I'm kind of
weird and odd. And this has helped me relate to the world and understand it and how I fit in
quite a bit better. And also like finding a community of like-minded people has helped
quite a bit too with that. Yeah, I agree. There was someone in the comments of one of the articles,
I forget, it might have been Sailor Vulcans said that it was a mistake to make a community out
of rationality. And I kind of chafed at that because I was like, well, first of all, I don't
think that it would ever not be a community. If you get enough people who are like-minded,
like they were saying, less long should have just been a project group in the moment that
we tied all of our relationships and our friendships and everything into it. That was a bad idea.
I think not. I think a lot of people actually have like improved their lives a lot by having
groups of people that are like-minded. Yeah, strong disagree as well. Even it just gives me
more accountability if nothing else for like, why are you achieving your goals? If I'm in a
community of people who care about the same things I care about and notice that I'm deluding myself,
you know, I can't check myself all the time, but it's useful to have other people around
me that can say, hey, you said you were going to do this and didn't, what happened?
Yeah, cultivating a community that holds you, that can help you hold yourself to higher standards.
And remind me what my values are. It's pretty important too, because it's easy to fall back
into the, you know, societal default mindset. Yeah, if you're just doing what everyone else
is doing, then you won't even know if you're making a mistake or not, right? You're just
following the script. Jess, I totally believe you can wait six more days for a new phone.
I don't know, man. It's really inconvenient. It's just a few more days. You can do it.
Yeah, I might have already picked out the phone I want anyway, and I doubt there's going to be a
really good Black Friday sale on it, but it's worth waiting just in case.
Okay. And that's the shocking way that I realized that today is November 17th and
not way earlier in the month. So, all right.
So I'm going to get working on that time machine too.
Yeah, geez. At the very least, it's a time-turner. If I could just have a few more hours each day.
I, that's one thing that I just love about this irrationality was his, like, wanting to have a
three-hour wedding with him, Quirrell and the time-turner. It's like, I totally get your love
for the time-turner. I'm as infatuated with it as you are, and I'd be just as ecstatic and
protective of it as you are. Yeah. My favorite thing about it was he's, like, immediately,
oh, I've got the ability to control time. What should I do first? Prank myself.
I only get one chance to fuck with myself this hard. I'm going for it. So delightful.
All right. Next episode, we will talk about the episodes. Politics is the mind-killer.
Dun, dun, dun. It shows up. And just lose hope already. And there will be links to both of those
at TheBasinConspiracy.com. Yep. Cool. Let's see here. We've got, I think we've
been not going for quite a while, right? We have. Oh my God. We should just do an episode on feedback
then, because I want to get to this feedback, but we've been going for more than two hours.
It keeps being more feedback. Yeah. Yeah. Next episode, you want to just hit feedbacks?
Yeah. We'll find some time in the next month to hit a feedback episode.
Cool. Because, yeah, I do, I really do want to get into these, but not enough time now.
I think putting in the less wrong posts is cutting out time for like rat chat and feedback.
So that's true. Yeah. But I think it's fun. So yeah, I really like doing the less wrong posts.
I want to keep that in. Me too. But we'll always have time for us to thank a Patreon every episode.
Hell yeah. This week we've got Glenn Willen.
Thank you so much for your support. It means the world to us.
Thank you, Glenn. Thanks, Glenn. Let's see. If you want support the show, you can find,
you can do so at patreon.com slash the search TheBasinConspiracy.
If you don't have the time or money and don't want to, that's totally cool.
You can give us a review on iTunes. You can comment in the subreddit on the website,
be part of the community building stuff that we're talking about.
Or attend local less wrong meetups or whatever it is you feel like doing.
Yeah. If there's a local less wrong meetup, that,
that, I mean, it'll make your life better to go probably.
Probably. Okay. Good frame.
Okay. Oh, good. Yeah. I went to a couple in Fort Collins before I came out to Denver.
And I didn't have a great time. Well, I mean, I was new to the thing and they were like kind of,
they were standoffishly. And there wasn't, there was like three people there too.
So, but it was fun. They got together every two weeks for coffee or something.
I thought that was great. And then, yeah, then I realized there wasn't one in Denver.
So I wanted to make one happen here. And this one is more fun. It's also way,
like, there's more people here. No, there's was casual. This had a coffee shop. It was just,
you know, they weren't like doing any kinds of exercises. No, no, they just,
they just got together. One of them, they were like two in their early twenties and
one woman was in her thirties or forties, but they just got together and chatted like we do.
But it was just a, maybe I'm also older and more sociable than I was. That's probably
the majority of the factor. So scratch the whole thing. I'm going to cut that all out.
Now you can leave it in. You had, you know, a different experience.
Yeah. So I guess I'll leave that in for the sense of if you don't have fun at your first one,
try again or make your own. You're going to have two competing rival,
less wrong groups in the city. We can have blue and green, less wrong groups.
That's right. I'm going to destroy it, racism, beat each other up.
Exactly. Yeah. I think that's all I got for this week.
All right. Thank you, everyone. Thanks, everybody.
All right. And thanks for joining us again, Jess.
Oh, no, you're welcome. Thanks.
Bye.
