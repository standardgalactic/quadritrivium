why aren't rationalists winning at these things? And they're, you know, not really looking down at
why aren't you winning at whatever you value. Right. Why aren't rationalists winning at being
rich and famous and in power? And like it's also hard to tell who's not failing. Yeah.
And avoiding failure. Exactly. And that's why I like, I mean, not feeling is a lower bar than
winning, but it is a kind of winning. You can't, you can't keep playing if you lose. So I mean,
it's, I don't know, getting better at that seems like a win. And that doesn't,
that doesn't put you, you know, at the top of society, unless you're trying to get there or
something. But yeah, I mean, I, I'm, I've got this thought half baked in my head that I'm trying to,
to verbalize while it, while it's coming together. And that's not going to work. So
I'll, it's not quite coming together for me, but it's something along the lines of like,
there are examples of people that are kicking ass in the sense of winning and why aren't more
rationalists doing that. But I don't know if they're all following a kind of like similar
techniques that we're all, that we all don't have. I, I would, I, I would suspect that many of the,
like winning cases of people, you know, Bill Gates, Elon Musk or whatever, they had some prior
things in common, they had some luck factories in common, and now they have, now they have outcomes
that are similar. But those aren't the kinds of things some of them aren't anyway, the kinds of
things that you can just have. Again, Elon Musk's work ethic is something that I just don't have.
Can I point out what I think is an example of rationalists winning on the small scale a lot?
Totally. Please do. Okay. Boot camps. Because right now, absolutely everybody goes to college,
which is, you know, driving the price of college up insanely high, and also leaving all these people
with tons of debt. And they've gone through four years of schooling, which is sometimes
spending a lot of time and money on things they don't necessarily need. Whereas the boot camps,
I first really heard them pushed in the rationalist circle, and they're kind of ideal for people who
have the rationalist neurobiology, because we're already somewhat analytical and, and
thinking in those terms anyway, that make for good coders. And the boot camp gets you in there,
teaches you the things you really need to go out and start a job, and doesn't cost that much,
doesn't take, you know, relative to college, doesn't take that much of your life relative to
college again. And you can right away get out the door and start at a pretty decent income,
like generally starting at 60,000, which is much more than an entry position is in almost any other
industry, and move, you know, just move up from there. It seems like this is a small scale win for
a lot of rationalists. And I mean, the community kind of found it by itself. That's what I did.
And it was a pretty large scale win to me. That's what I'm going to do. The clinical research is
also a boot camp. What is the clinical research program is a boot camp as well. And I think that's
the way to go. Maybe, you know, so it's one of those just kind of identifying a failure mode in
the way that things are usually done and saying, no, fuck that, what's a better way to do it?
Not, well, here's what everyone's doing. I guess I'll just do that too. And, you know,
people would argue that there's other benefits to college or something, but I don't know if those
benefits are worth, you know, $80,000 worth of debt. So, you know, if you can go to a boot camp
for $10 or $20,000, yeah, that's that's a big chunk of change. You need to have that, you know,
ready or be able to get a get a loan for it or something. But the idea that you can go through,
knock this thing out in three or four months and then hopefully start working and being able to
to earn that money back very quickly. It's the kind of munchkinny shortcut that sounds like
right up our alley, right? And it works. Yeah, there's there's large successes from it.
One of the things that I also think boot camps have over traditional schooling is that there's a
goal at the end of it. Like if you're going to a coding boot camp, you're being specifically
trained to work. The reason that people want to hire people who come out of boot camps is because
they know that they've been specifically trained on like Python or whatever they need clinical
research. Yeah. And school, you know, if you go to a four year college, you do learn a lot of other
stuff and that's cool. It's great for personal development. But you don't come out of college
necessarily trained to go right into a career. I wasn't at all. I got an art degree. I wasn't
trained to be an artist. I had to teach myself how to be an artist. They didn't teach you anything
about pricing or about getting clients or about marketing yourself. It was like it was terrible.
Whereas in a boot camp, they do teach those things. I don't know about art boot camps,
but in I don't think there is an art boot camp, but I feel like there should be.
I don't want to run a business. But I mean, part of what they do less so at the boot camp,
I went to but more at others, they do focus on resume development and practicing interviews
and like here's how to get a job because that's what you're here for. Yeah, you're not here to
learn the fundamentals of computer science and learn, you know, the history of the computer.
Yeah. Here's the long definition of a touring machine. Here's Ada Lovelace's birthday.
Like you're not here to memorize a bunch of, I don't know if it's that trivial, but like
a lot of other classes are. You look at dates of famous scientists or something, right? So
none of that bullshit in a boot camp. But you're in there to get a job and the boot camp looks
good if a lot of the graduates get high paying jobs. So they want you to do that. It's one of
those great reciprocal relationships where what makes them look good and what they want is also
great for you. College, I think, is less focused on that because it's a great, it's a prime example
of a lost purpose. I do have one final quote from this, from the last rationalist reply. It's kind
of a long one though. If you guys want to let me, okay. So this is in reply to Elias are saying that
rationality is more like a systematized winning. Last rationalist says systemized winning is not
an actionable definition. Most domains already have field specific knowledge on how to win.
And in aggregate, these organized practices are called society. The most powerful engine of
systemized winning developed thus far is civilization. Most people trying to explain the value of
rationality assume that there is such a thing as instrumental rationality methods to systematically
win over and above the usual practices of civilization. If someone asks, look, if I go to
college and get my degree and I go start a traditional family with four kids and I make
120k a year and vote for my favorite political party. And the decades pass and I get old, but
I'm doing pretty damn well by historical human standards. Just by doing everything society would
like me to do. What use do I have for your rationality? Why should I change any of my actions from
the societal default? You must have an answer for them saying rationality is systematized winning
is ridiculous. It ignores that systematized winning is the default. You need to do more than that to
be attractive. I think the strongest frame you can use to start really exploring the benefits of
rationality is to ask yourself what advantages has over societal defaults. When you give yourself
permission to move away from the systematized winning definition, without the fear that you'll
tie yourself in knots of paradox, it is then that you can really start to think about the subject
concretely. So I guess my ultimate question is what advantages does rationality have over societal
defaults? Alright, he wants to go first. I'll go first because I already said my answer. My first
one that comes to mind anyway is that it helps. It's the art of not losing. I think there's a
post related to this. There definitely is a post related to this that not sucking is more generic
than like six, like then being great at what you do. But just the ability to identify weaknesses
in your plans and in your, your steps is immeasurably valuable. I think that that I mean,
there are probably definitely other avenues that teach that sort of thing. But it's one thing that
I've noticed from it. I, when I think about how am I going to address this problem? I have
inner dialogues that I ask myself questions like what if this happens had what, you know,
are you sure you're not just thinking about it, you know, because it makes you feel good.
All of the, the ways that, you know, whether it's, it's a failure mode of just like making a wrong
bet or whether that's like buying a bad lottery ticket or running a red light or something,
or just falling into the trap of believing something because it feels good or, you know,
slipping into a bias or something like that, right? It gives me, I keep picturing bumpers
like when you're bowling, you know, putting up those bumpers doesn't make you hit strikes,
but it keeps your ball on the track and you're going to hit a pin, right? Whereas otherwise,
it could go off at any point on the track. That's a really bad analogy, but that's what
I've been picturing this whole time. That's a good analogy. So yeah, for me, I would say that
it trains you on how to inflate those little bumpers that they used to get the bowling
ball on the track. I'm enjoying the metaphors. I like your answer. That's a good consequentialist
answer because I guess people who are thinking about rationality being systematized winning,
it's kind of, oh, like, why aren't we all Elon Musk? But you have to think about, well, even if
just like the marginal utility you would get from increasing everybody, just like a few steps up
from where they are now in the world, kind of like related to, I guess, the idea of raising the
sanity waterline, how much better would the world look if fewer people were losing? And maybe that's
something we should be focusing on more. Maybe that's even a more achievable goal. My answer,
I think, just comes down to picking good problems to work on by knowing what's true. And that's
still going to be different for different people. Like we were talking about before, you know, you
get to pick what your definition of success is. But like, say that a lot of people have the goal
of improving society, which I think is a pretty common goal, they'll be better able to achieve
that goal if they know true things about what a good society looks like, what actions actually
improve it, and how not to delude themselves into thinking that they're pursuing this goal when
they're not. If they have that knowledge, they'll do better at improving society than they would
if they went with the societal defaults. Yeah, I like that a lot. And, you know, societal default
might be, sure, you had your four kids, your 120k or whatever, but you spent 80 of that getting an
education that you didn't really need. So, you know, what would you have won if you'd done a
bootcamp instead to get into your career? You would have won $60,000. Yeah. And three years of your
life. Yeah, exactly. And societal default right now is you get to about 75, 80 years old and you die.
Right. So, fuck that too, right? Yeah. So, maybe there's a separate thing that I don't want to
try and get sneak two answers in, but this isn't really so much of something that you get. This
is just a viewpoint that you're, but at least one thing I've got out of this approach, this
rationalist approach to life is not being content with like the way things are, basically
transhumanism. I was already into that before this, but it was the best defense I've come across
with the whole thing and the idea that transhumanism for, well, I guess, transhumanism for people,
but for society as well, for the world, you can look at this and say, no, we can do better.
Rather than say, how can I make what they're, you know, you can build better mousetraps rather than,
or you can figure out other ways to solve the mouse problem than just build better mousetraps.
It's maybe the analogy. The skillset to say, no, I'm going to start from scratch or what's another
let's make everybody Elon Musk, right? That's better drugs or, you know, genetic engineering.
Yeah, rather than teach everyone to just do what they can with what they've got,
we could say, no, we can give you more, right? Just the ability to do more start from scratch
questions. Of course, delivering on those is something that we need to start doing, but
I think it's valuable to at least say, no, we need more time and we need more members.
But, you know, imagine like if all the, the, the progress in transportation had just been
building faster trains and nobody thought about building planes, right? Like this,
this is the kind of thing that's like, no, we can, we can build planes too. And I'm
hoping my metaphor is just landing because I don't know how to.
Yeah, you have to be able to pick good goals. Right.
Like do what 80,000 hours is doing and okay, like let's actually assign people the career of
identify priorities. Yeah. No, totally. All right. What's your secret answer,
Enyash? So my secret answer is kind of, it's very related to your guys' answer in part being that
lots of times, okay, so what people really want is to be right, right?
And society has a lot of defaults and you follow them, generally you'll be okay.
But there's a lot of ways for people to fool themselves in the thing they're right and for
society to fool itself into thinking that things are going just fine when they really aren't.
And I think rationality is the, the art of noticing when you're wrong
and allowing your yourself to be made right by the facts of the world.
Instead of trying to argue vehemently that you're actually right and you were right all along,
or that society is just fine and there's no problem with AI and you guys are all, you know,
crazy chicken little sky is falling type of people. It's, it's the practice of really looking at things
and updating yourself when the evidence is against you.
So I think it comes back to the whole truth seeking aspect of things, not trying to deny how
things actually are and changing, changing yourself, being proven right by changing yourself
so that you now have the right position as opposed to arguing that things were right all along.
And I think that society has a lot of problems with that too, that saying, no, we're fine,
you know, America is the greatest or we don't have any problem with this drug use or whatever.
My facts are the right facts.
Yeah, yeah, exactly.
My facts are just as good as yours.
Right. Yeah.
The, the actually evaluating facts and being able to say these facts are right and these so-called
facts are wrong.
And there's already an enterprise that does that, but one of the posts, one of the wrong posts we
might talk about if there's time today, deliberates on that a bit, that like science already tries
to do that, right? And scientists try to do that as people.
And yet it's possible to be a scientist with a PhD and a job and everything and still think
they're the 10,000 years old.
Should we segue right into the rest long posts then?
If you're, if you're ready.
I mean, that was a great segue, but I'm done here.
But do you guys have other things to say as well?
No, let's move on.
No, I think that was a good, good segue.
Okay, cool.
So that brings us directly into our less wrong post section of the show.
Okay, our two less wrong posts this month or this episode where some claims are just too
extraordinary and outside the laboratory.
Steven, you were just talking about outside the laboratory, but let's start with some
claims that just too extraordinary because chronologically that one came first.
Totally.
Okay, cool.
So some claims are just too extraordinary.
Okay, is a post about the nature of evidence and how it relates to extraordinary claims.
And sort of a defense, a defense of the hubris of science.
Yes.
Yeah.
If you want to call it hubris, rather defending what science is, isn't hubris.
Exactly.
The post basically says that some claims are really absolutely extraordinary.
It starts off with a quote from Thomas Jefferson who says,
I would sooner believe that two Yankee professors would lie than that stones would fall from heaven.
And that was his take on meteors.
And the post points out that there is a method of getting to the truth that is optimized for
weeding out false claims.
And so it counts as extraordinary evidence and can thus substantiate extraordinary claims
like rocks fall out of the sky.
The quote that I pulled from this is a replicated scientific report is a special kind of extraordinary
