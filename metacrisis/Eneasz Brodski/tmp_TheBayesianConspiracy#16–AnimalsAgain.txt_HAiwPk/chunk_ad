No, but, like, I guess I'm putting that to...
Think of an ant...
Of a conundrum that actually makes you answer the question,
like, do you say, well, you know what,
despite the fact that the street will be a little darker,
there might be a higher risk of car accidents,
and, you know, kids getting run over because it's dark,
I'm not going to weigh that distant possibility
against the actual lives of these ants.
No, but I think that we're getting a little lost in the weeds here.
I think so.
So, the other part that I wanted to respond to,
one is, again, why even talk about thermostats?
It has nothing to do with...
It doesn't even compare to any animals except,
I don't know, maybe sponges.
Well, I think all life, all intelligence
is basically a computational process.
And if thermostats do any sort of computation,
then they are somewhere on that spectrum,
even if it's really far from pretty much anything.
And that's a way of asking,
where do you draw the line?
How simple does the computation have to be?
And different people draw the lines in different places.
All right, and then what happened was
you started to talk about our trolley problems, right?
And in this trolley problem,
there is a dog on one side,
or there are not just a dog,
there are 50 dogs tied to one set of tracks,
and there's one human tied to the other set.
Right.
The other thing that convinced Steven
was that kind of thought experiment.
It wasn't specifically the dog's thing,
because I would put more moral worth on a dog
than, say, a flatworm.
But, like I said, if we could simulate
10 times the number of flatworms that exist on Earth,
and kill all of them,
versus killing one innocent person,
I guess I would wonder...
I mean, it's pointless to put an actual number on it,
but is there a number where you would say
there's enough flatworms here to where,
sorry, best friend, you're gonna have to die?
So, you said it's your best friend.
Let's put something else.
Let's say...
Let's imagine an actual dog in the room.
Let's imagine an actual animal
that we know and care about,
like Dio, who is here licking his paw right now,
adorably, and making lick noises,
which is not so adorable, is it?
He's trying to lick off all my pets.
He says, you are a speciesist.
I no longer want your pets on me.
So, there's Dio, and he's tied to some tracks,
and he's about to get hit by an oncoming train,
but there's someone from work who you really don't like,
and who just makes life terrible,
and you think they probably have a negative overall utility
tied to the other side of the tracks.
Are you asking me specifically?
Because you already know what I'm...
You are looking at me,
and you already know what I'm gonna say.
Kill Dio.
No, because...
I'm telling you what I would do.
Yeah, I know.
That's not what you said last time.
So, after we finished recording,
you said to me and Dio
that there are many humans that you would sacrifice for Dio.
There are, but no one that I work with.
Even the most unpleasant person I work with,
I think is worth more than a deal.
But, I mean, if we're talking about murderers
or rapists, child molesters, then yes, totally.
Yeah, no.
Dio's worth more than one of them.
There's something to be said there.
I had a...
I lost a pet recently,
and it is quite possible.
I mean, I would have actually had to think about it
for more than five seconds
if the doctor told me,
hey, we can kill five people you'll never meet
and your cat won't die.
I would have thought about it for a second.
But if the doctor said,
or some mad scientist came to me and said,
I can kill five people or a random cat,
I'd be like, well, you're insane.
Kill the cat.
But that's not...
So, the thing is that it's not talking about
the internal value of the animal.
It's value as an instrument to my happiness.
Right.
But that's a different issue from its complexity
and its internal value.
The reason that I'm bringing this up
is because I think that it's totally the way
to go about deciding what's worth more
this life or that life.
What's worth more?
A dog or a cat?
What's worth more?
A dog, easily.
As an alien, it has four listeners.
Including a third of your hosts.
So, this is where we're running into some serious biases.
Okay.
Right?
And this is a place where we might be able to benefit
by stepping back and trying to de-bias ourselves.
For sure.
I will just mention that I don't think
that trolley problems are a great tool
for coming to real-world answers either.
What they are are good intuition pumps.
And if you do sit and think,
you know what?
There's probably no number of thermostats
that I would trade for a person.
But you might not say that about, say,
a sufficient number of flatworms
or a sufficient number of more complex
artificial intelligences or something, right?
And certainly, those conundrums will be coming
with computers in the future.
So, like, you can't just declare now,
or I guess you can, but you have to back yourself up,
about, like, oh, yeah, no.
No matter what the computer can do, I don't care.
What if it can perfectly simulate you and your mom?
Like, then do you not care still?
So, like, you know, these things are brought up
not as real-world problems today,
but they're brought up as intuition pumps to say,
all right, let's think about what you're actually,
the implications of what you're thinking.
And there are real-world problems, right?
Like, oh, how many low-paid workers
might lose their jobs
if this form of factory farming
is changed or abolished or banned?
There are those real-world problems,
but my suggestion for some of the thinking,
the thought experiment is to get away,
far away from real-world problems.
And imagine that you are on an alien world,
you have X information,
and you want to know what decision somebody else might make,
and you're guessing.
So, I guess all I'm saying is a good exercise
is to really try to remove yourself from it
and talk about the zergles and the blurgles.
And all you know about the zergles
is that they seem to have rudimentary tool use
where they can attach up to five sticks together
to make creative new tools
and carry them to a place where they're going to use them, right?
So, they collect the materials beforehand,
and they carry them up to 10 miles
to where they can actually use them to retrieve food.
And the blurgles...
Okay, I forgot which ones I was talking about, but...
You were talking about the nergles.
The nergles? Oh, I never said nergles.
Whatever.
I heard nergles and blurgles.
I thought the zergles and blurgles.
So, also, you know that the blurgles
are able to cooperate with another third species, the nergles,
in order to hunt because they use different hunting strategies.
One of them flushes them out.
One species flushes the prey out from under rocks.
The other one can eat them when they are out in the open,
and the other one, if they're going after something in the open,
it goes under a rock.
Is the prey the nergles?
No.
Okay.
It's an additional prey item.
Okay.
The blobs.
And you get this information,
and then you ask, well, what would Sarah...
So, Sarah is the commander
of a group of Zyridians who have just landed
and they're running dangerously low on food.
They need to add some food source,
and they are considering hunting either the zergles
or the blurgles and nergles.
