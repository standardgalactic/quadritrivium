This episode is mainly a continuation of the previous episode.
If you did not hear the previous episode due to volume reasons, we did get many reports that the volume was very low.
The next day we updated the episode with a higher volume one.
If you have not heard that version yet, it would probably be a good idea to listen to it.
To do that, delete the local copy of that episode and then re-download it from whatever your podcasts are used.
If you're streaming, you shouldn't have noticed a difference if you listened to it more than like a day after it came out.
So, yeah, you should be good.
Welcome to the Basing and Conspiracy. This is Katrina Stanton.
I'm Uniesh Grotsky.
And I'm Stephen Zuber.
And today's episode, we are going to begin by covering some points from last week's or last episode on the topic of animals, some corrections and updates.
And then if there's time, which there probably will be, we're going to move into the topic of emotions, which I know we've brought up in a previous episode.
I think one of the first five and finally getting around to it was mostly sparred by a commenter whom we'll mention when we get around to that part of the episode.
So, Katrina, you were eager to talk about animals. What's new?
Well, last time I talked about, are we smart enough to know how smart animals are?
The lengthy title by a book by Friends DeWall, the animal, he does not call himself a behaviorist, but he's definitely been very active in the field of ethology and a bunch of other fields that he mentions, animal cognition, evolutionary cognition.
What is ethology?
Ethology? You're going to have to read the book.
Oh, shit, okay.
Well, because it actually goes through the history of the study of animal cognition and intelligence and it starts with a feud between ethologists and behaviorists and goes from there.
It's really interesting from historical perspective and also has a lot of great stories, many of which are anecdotal and some of which are experimental.
And science beeps are always fun.
Yes, exactly.
I actually read this, even though the title is really unwieldy, I totally recommend this book.
The best thing about science beeps is that unlike regular beeps, the more petty they get, the more fun they get.
Watching two scientists just be sneering and bitchy at each other is the best.
Oxford comma!
Oh my god.
Yeah, that's a science beef.
Okay, my favorite science beef was someone perfectly just calm, commenting back and forth about whether .99 repeating equals one or not.
And someone mentioned, it was like a sentence or two, but it ended with, and so you see, .99 repeating does equal one.
And the reply was, why don't you come here and say that to my face, you bitch?
That is not the nice way to speak.
Yeah, they fell short of that before the rules.
But yeah, this is a fantastic book. I read it.
And if you recall from our last episode, Edgar sent us a really nice message asking, I'm sorry, maybe we're commenting that it's impossible to get inside animal minds.
Everything is just kind of guessing.
Mind projection fallacy, etc.
And just like Steven said.
It was a long, you heard the whole thing last time.
Yeah, you heard the whole thing last time.
And now that I've read this book, I'm like, wow, this book exists pretty much exclusively.
It's like a two answer, Edgar's question.
I guess the moral of the story is, wow, we have done a great deal of science with animal cognition and it's come a long way.
And it's very, very interesting.
And I know that they would love to read this, but they should love to read this because I did and everyone should.
It came out this year.
Would you say, I don't want to throw a wrench in your game plan, but would you say that it is as unreasonable to doubt the cognition of animals as it is to doubt the cognition of other people?
No, but from an evolutionary perspective, it is kind of unreasonable to start from a perspective where animals do not.
Think, have cognition.
Like they have literally nothing going on up there.
Yeah, like it's a black boss. They're just stimulus response machines.
Considering that we evolved from a common ancestor and evolution is gradual.
And you took a soul into us 60,000 years ago.
Right.
That was when Jesus came down and said, now you have souls.
Well, people would talk about a spark or the soul suddenly being put into whatever ancestor, our hominid ancestors.
Or something like that.
Oh my God, Matt.
Do people actually make that kind of argument?
People do.
Because the Catholic one version of Catholic.
Well, okay.
Do non-religious people make the argument that animals are just stimulus response machines?
Yes.
Or they'll talk about, again, a spark or they'll for some reason have a bias that makes them think that evolution just doesn't include your brain for some reason.
And human brains kind of sprung, fully formed, just in humans.
Okay.
So I think that sounds, I mean, I don't know.
Maybe there are people to say that, but those people should not be considered representative.
Because they're walking straw men.
Yes, exactly.
How dare you get up and walk around with your straw body?
Maybe because you don't get us, get around that point.
I didn't get you derailed.
There's a big difference between saying it's nothing but a stimulus response machine.
And saying that animals do not have the sort of reflective equilibrium that humans have that was, you know, supercharged over our recent ancestral environment.
Right.
So, DeWall addresses a bunch of different parts of cognition.
So theory of mind, right?
The ability to model others, the ability, self-awareness.
And I got to say, his view is much more nuanced than the mirror test that I was talking about.
And then he also addresses the mirror test.
And actually, just quick, quickly, the cool thing about the mirror test is that they're only a handful of animals that pass it.
I guess humans start passing at the age of two.
But even animals that don't pass it, a lot of them understand what mirrors are or seem to through other ways.
So, for example, great apes pass it, but monkeys do not pass the mirror test.
But, like, capuchin monkeys are perfectly capable of, even though they don't touch a mark on their face, they still will take a mirror and, like, use it to look around a corner.
Oh, neat.
That's like a more clever use of a mirror than finding it.
I don't know if any value to it or something, which still is more important.
Maybe they think it would look really handsome with those marks on their faces.
That's true.
I'm like, thank you, sir. Can I have another?
Who's that sexy monkey?
Oh, that's me.
I'm worried I could have turned myself on.
Additionally, with capuchins, they don't treat the mirror if they have a full-length mirror.
They don't treat the mirror image as another monkey.
So, when they had either a mirror, a monkey who was a stranger, or a monkey who was familiar to them, they treated the mirror completely differently.
If it's a stranger, they turn their back.
Like, I don't even know who you are by.
If it's the mirror, if it's a known monkey, they would interact.
And if it's the mirror, they just ignored the mirror.
Okay.
And we're not afraid of it.
No, wait, that doesn't make sense with them using it. Never mind.
Right. So, it seems like...
I was obviously joking too, sorry.
Yeah, so it seems like there's something that doesn't quite catch exactly what it wants to using just the mirror test.
There are lots of different aspects to cognition.
Interestingly, and I think we talked about this a little bit, in the cognitive realm, non-humans in several ways, you know, they do better than humans at certain tests.
Some of the tests that I didn't know about, there's a chimpanzee.
Oh, is this the... having the numbers flash on the screen and it has to touch me in order?
Yes.
Yeah, that's an awesome one.
So, I Moo You is the name of the chimp.
I Moo You too.
And yes, he can remember strings of up to nine numbers and that flash on the screen for a fraction of a second.
And then he'll touch the numbers in the correct order on the screen.
Humans can be trained to do that with a string of five numbers, but for a longer amount of time to memorize a string of five numbers after a couple seconds.
Adult humans?
Yes, adult humans.
Damn.
So, in response, kind of funny, in response to that experiment coming out, a bunch of people, a bunch of scientists got together and they just kept training themselves, really trying to see if they could beat this chimpanzee.
And I don't know if they succeeded or not, but it's certainly not something that an adult can do easily and without significant training.
Additionally, when playing against each other, you might know from learning about chimpanzees in the past that they're very strategic, they're very social animals, and a lot of what they do involves deception and long-term maneuvering, social maneuvering.
So, in another experiment, two chimps were playing a computer game against each other, a strategic computer game, and they found that these chimpanzees reached optimal playing strategy much more quickly and more reliably than adult humans playing against each other.
That's cool.
So, they postulated that it's because the chimps need that kind of strategic thinking for their lives.
And, for instance, a wall makes the argument over and over again that kind of like beak length for the types of nuts that you can crack or seeds that you can eat, your cognition is also adaptive towards whatever your situation is, right?
So, if you need to be able to think strategically, then chimpanzees can do that.
If you are a J, caching nuts and worms, they're much better than humans are remembering where they've cached things and also remembering what they cached where, and they did that test with perishable items and non-perishable items that they give the J's.
I think sort of what we were talking about last time was that what you're cognitively adapted to do depends on your environment.
Yes, yes.
Yeah.
Absolutely.
So, like, you and I have very little intuitive skill of like what it takes to be a good squirrel or be a good fish, right?
Just because we didn't, our more Disney ancestors weren't really doing a lot of that stuff.
So, how does this tie into...
Most of us have no idea how to be so adorable that someone else will feed us and house us for our entire lives.
The dogs are back for this episode, I'm not sure if that was clear from the tenor.
Well, so, Amyash made the point that the only thing that he cares about, like literally the only thing that gives an entity moral worth is its intellectual complexity.
So, talking about how different animals are more complex than humans, more intellectually and cognitively complex than human beings in certain areas,
kind of helps make the point that maybe we don't know all of the areas because we haven't found the right way to test them for a lot of these animals.
So, for example...
Well, I would argue that being very good at certain tasks is not necessarily a complexity thing, it's a specialization thing.
And what makes humans special is that we do have the complexity across a large domain of different types of commission.
Does that make any sense?
Yeah, but we're really crap at finding things that we've hidden if we hide a lot of different things.
Yeah, we are, but we can think ahead and make organizing strategies.
So, right now what we're looking at in terms of animal behavior is we're taking inspiration from our own behaviors.
Saying why aren't they like us?
And then we're saying, are they? To what extent? How do we know, right?
Right.
We aren't even looking at a bunch of the amazing cool things that an animal mind is capable of.
Right.
Because one of the things that Debal's frustrated about is all we're asking over and over, our central question is, how are we unique and special?
How are humans unique and special? Well, we really need to feel special, so we better figure out how we're unique and special in terms of our brains and pinpoint that.
And there's a lot of goalposts moving.
And he talks about those, you know, when he's talking about the history of this, of exploring animal cognition.
I don't know if we've touched on the phrase goalposts moving in the past.
I don't know if it's a formal logical fallacy or either an informal logical fallacy or if it's just a bad reasoning tool.
But basically when your position's been defeated, you move to another position and say, all right, well, we didn't talk about this thing, this whole new thing yet.
That's goalposts moving, where you move the victory condition from one place to another once your position's been beaten.
I've heard that be a complaint too about artificial intelligence that people say, well, a computer could never play chess.
So it's not smart. Then a computer beats the world chess grandmaster.
And they're like, well, that's obviously not really that important, but a computer could never beat a human at go.
And then the computer meets a human at go and they're like, well, I mean, that's not really the essence of what it means to be human either.
A computer could never write a poem and then a computer writes, like, could be interpreted as a poem.
And they've been writing jokes for years. They're driving better than people are now.
Right. So every time a computer does something better than a human, it's like, well, that's not really what it means to be human.
They're beating people in flight, fighter pilot, flight simulations.
I was actually surprised that that hadn't happened a long time ago.
Like when I heard that that was a new thing.
They've been using it for a long time.
Yeah, but when I heard it was that they were just recently started beating people, I was like, oh, I was apparently wrong at how long this has been a thing.
Well, it's recently beat the best person who's pretty much his entire job is to play computers, play artificial intelligences.
Cool. In flight simulations.
Yeah.
That's so cool. And terrifying.
Well, and best of all, the computers will not be limited to high energy forces.
Like the human body can only put under so much stress before it blacks out or dies.
They can do some maneuvers that we could not ever physically pull off.
And he actually says best of all, but...
That's exactly what I was thinking.
Well, we want these machines on our side in case of a war, right?
This all will be horrifyingly good at it.
This is incredibly worrying.
Well, I'm very happy that machines can lift and haul dirt much better than humans do.
It makes our house building much easier and faster.
Yeah. I also wanted to point out, in terms of adaptive brains, I wanted to mention a couple other animals.
And Deval mentioned this in his book too, like maybe in order to study strategic thinking, you study chimpanzees,
maybe in order to study conforming to a social norm, you study schooling fish or guppies.
These animals all have different strengths.
And some of them have very generalized strengths that are similar to ours.
And those would be animals like great apes or dolphins or elephants.
Although elephants are really understudied because they're huge.
And you might be interested to know that they have three times as many neurons as we do in their giant brains.
Right. And whales, there's a lot of animals that do.
A lot of the function of the brain is just to move your muscles and react to your environment.
So as you get bigger, your brain tends to get bigger too.
I think elephants also pass. So yeah, what you're talking about, I forget what the formal name is,
but yeah, the brain size isn't just it. It's the brain size relative to body size.
Like, corvids have really tiny brains compared to humans, but smart as hell.
Right. And I think that elephants pass the brain size to body size thing, even how big they are.
Oh, maybe. Some animals. Maybe it was great apes or something. Some other animal did.
So that reference on the zone is completely useless.
I don't think my argument was ever that animals have no moral weight, just that it is significantly less than that of humans.
It's okay. I do want to mention one thing.
While it kind of briefly addresses the idea that it's the body size to brain size,
instead of the number of neurons, it says that it's been shown to be the number of neurons.
Huh. Okay.
I mean, I don't think whales do have more neurons than we do. I just think they have much larger brains.
I think it's the elephants that have many more than we do.
And if I'm wrong about that, I will post a correction for myself.
I didn't get to my corrections.
Oh, please do the corrections then.
I'm going to correct myself about some things.
One, I said that I thought that the mask that experimenters wore while banding crows
and then that crows were able to communicate to each other about was a president's face.
It was a vice president's face.
Oh, my God.
It was Dick Cheney's face.
Do we need corrections to this level of minutiae, though?
Somebody will get on us about it.
Oh, those bastards. All right.
It doesn't defeat the argument, though.
Yeah.
We spoke about a monkey study in which there were more and less desirable treats
that a monkey would happily eat cucumbers, which are not as desirable as grapes,
until they saw the other monkey getting grapes.
And you asked me, and Yash asked me,
so the monkey with the grape, did they refuse the grape,
seeing that the other monkey got cucumber?
And I said, I don't think so.
And they did. I was wrong. Yes.
The monkey that got the grape refused the grape?
Yes.
Oh.
They're like catty two-year-olds,
which like they just want the toy the other kid has.
No.
No, no, no.
Because I remember the monkey with the cucumber threw the cucumber down.
I was like, I'm not taking your cucumber.
He's getting a grape.
But you're saying the monkey with the grape refused the grape, too.
Out of concern for fairness? That's awesome.
Yes.
They're a very reciprocal group of animals.
Kapuchin share their food,
and they share very generously with individuals that they like
or want to curry favor with,
but it would be unseemly
and probably not necessarily go well for that monkey in the future.
Yeah.
So there's some potential future planning there.
That's pretty cool.
I wonder if it's...
I was going to say it sounds almost exclusively like future planning,
but not necessarily.
It could just be, you know,
to try and still man the position that monkeys are automata.
It could just be basically like a robot reaction of,
I'm programmed for fairness.
That's not fair. I'm going to stop doing that.
Well, you could say the same of humans.
Right. That's what I was going to say, too.
But the other way to think about it is that,
yeah, they are thinking, well, shit,
as soon as that researcher leaves and puts us back in the same cage,
he's going to kick the shit out of me,
seeing that I have all these grapes while making eye contact with him.
I'll stop now.
He should load up on grapes so he has all those calories
to fight off his attacker.
They have some long-term goals.
I thought it was kind of cool the idea of male chimps,
alpha chimps going on safaris with sexually receptive females
to avoid competition.
Safaris?
I know. They call it safaris.
She can do air quotes.
Oh, yeah.
For those who aren't watching the video feed,
there were air quotes around safari.
Everyone could hear the air quotes.
Okay.
Anyway, yeah, when a female comes into sexual receptivity,
a lot of time the alpha male will escort her
for several days to the outskirts of the territory
where they can enjoy alone time without any interference.
It's like exactly what high school kids do at their first car do, right?
It's cool to talk to make out point, right?
Where there aren't other jocks to compete for your favor, right?
Or parental figures, yeah.
No, that's really cool.
There's something to be said about where we, I guess,
draw the lines in this, not even the lines in the sand,
where we draw the grid.
What kind of, what am I trying to say?
We want to make sure we identify in advance what sport we're playing
before we say that animals aren't any good at it, right?
Like we say, you know, not even the same league or whatever.
Yeah.
It is interesting that, yeah, many animals are better than humans
at many things because they need to be.
And that's what the ancestors were good at.
I don't know, maybe it's my, my species, species.
Speciesism.
Speciesism.
Speciesism.
Sure.
Bias leaking through my humanist bias that I would say that,
you know, my, my ability to, to, as much as I, I'm going to have a squirrel lover,
but as much as I love squirrels, I wouldn't say that like their ability to remember
where they put stuff, like makes them smarter than me in a meaningful way.
Makes them better at finding stuff where they hid it.
I guess that really depends on what you're doing.
Exactly.
And if I'm a squirrel hiding nuts, and if I was, as, if I was a squirrel and as bad
at hiding nuts as I am now, I would die.
But it's not a squirrel.
So yeah, that's it, right?
It depends on what you're doing.
And then that comes into where you want to weigh in on what does it matter what you're
doing and put the value judgments on what we can do versus what they can do.
Right.
So that makes it much more of a value game than a just intellectual game.
A lot of the problems with people's research is that they were comparing in large part,
they were psychologists who were comparing children to chimpanzees.
And the experiments were just simply not set up in the right way, partially because the,
the person who's running the experiment is a human being, right?
And if there's a human being who is running an experiment with two small human beings
and explaining it to them, usually they have a, one of the kids, the kids have a parent
there, maybe even are sitting on their lap.
It has to be, if you're, if you're doing human stuff, it has to be comfortable for the kids
versus an experiment or a human experiment or working with a chimpanzee where they...
Well, you'd think if a chimpanzee was smart enough, you could bring a chimpanzee mom in
to explain to the chimpanzee kid how to do this, right?
I was just going to say, let me go ahead and see if I can put words in your not just mouth
and feel free with them, which is if the chimps are running the experiment, they do it the other way,
but they're not because they're not as smart as us.
Would you say something kind of like that?
So we, so experimenters have been able to organize things like the computer game that I just mentioned
where it's chimp versus chimp and various experiments where they're chimp doing things
that they're actually interested in.
Like noticing if another chimp has noticed where an experimenter hid a treat to see if
they have to either run to it or if they'll walk past it,
pretending they didn't see it and come back later when no one's paying attention.
See, that is the really cool stuff that you don't start thinking of doing until you actually start doing better science, right?
And that's awesome.
Yeah.
Because yeah, putting them up against kids is great for seeing how well human kids compare to the average chimp,
but it's not really the best, the best litmus test for like chimp native intelligence, right?
Well, it's not even very good for seeing how they compare to chimps
because the situation is so basically different.
That's true.
How they compare to chimps under like basically duress circumstances
as opposed to like pampered baby human.
Right.
So yeah.
If you have two kids doing a game with each other,
but in terms of the chimps, they're in separate cages.
They have to interact through bars.
Great apes are notoriously difficult to control and work with.
And they can be very dangerous.
An experimenter, you know, can't touch them, can't really interact with them.
Maybe.
It turns out shockingly that apes care more about what other,
and I'm saying apes, we're apes.
Right, right.
So let's say chimps.
Chimps care a lot more about what another chimp is doing,
where another chimp is looking, what another chimp is interested in,
than what a human experimenter is doing.
Those speciesist sums of bitches.
Although, you know.
We probably, yeah.
Sorry, go ahead.
No, no, no.
It kind of seems like these great, the dangerous great apes,
maybe doing a bit of game theory.
Like if we're always really unpleasant and mean and attack humans all the time,
they'll be less motivated to keep us in captivity to experience on us.
So anyone who gets caught, just act dumb and attack the humans all the time
and they'll leave us the fuck alone.
They had this at the big meeting before the humans moved in to capture them.
Yeah.
Yeah.
I have a very high bar.
I guess I should mention that Inyosh prefaced the last episode by saying
that he didn't expect to change anyone's mind,
or that rather he didn't expect the episode to change anyone's mind.
And while my position hasn't really been flip-flopped,
I'm still, I think, on the same side of the fence as Katrina,
but I think I moved my camp a little closer to the fence.
Just one way of thinking about it was when you made that analogy to,
like, insect mines versus, like, your thermostat.
And I kind of just missed it because I'm like,
well, I mean, there's something different.
But then the more I thought about it,
and I mean, yes, there's differences,
and I don't want to be, like, pedantic and point out all of them,
but really, you'd set something along the lines of, you know,
how many thermostats would I have to count up
before I would sacrifice a human for it or something.
And I realized the answer would be, you know,
all of them, times however many there possibly could be.
And then I was thinking the same thing of, like,
well, that's sort of true of, like,
and we actually had this at our last local meetup,
there was a wasp bugging us at the table,
and I was like, I think, you know, barring the harm to the environment at large,
I'd be willing to sacrifice hundreds of billions of wasps for the sake of one human,
because they're just, like, they're just mindless wasps.
Right. You've got one wasp, you've got every wasp.
I think that's probably mostly true.
But maybe there, I mean, I'm sure there's some differences depending on varieties.
I'm sure wasp is a large category.
Yeah, so Stephen, Stephen made that statement
just a few days after we recorded two weeks ago,
and I was devastated.
Yes, I was devastated because I thought that I had failed
at responding to clearly flawed arguments that Enyash made.
And then I shared what my answers to those would have been,
and apparently it didn't change anyone's mind.
But hopefully it'll change your minds.
Here's what I didn't say when Enyash said that a thermostat is the moral equivalent to a slug.
We made thermostats.
We know exactly how thermostats work,
and how complex they are, and exactly what's going on.
Humans, although we've been trying an awful lot,
haven't even been able to simulate something as simple as a flatworm,
as simple as platihelminthes, right, which is an adorable flatworm.
But it is a flatworm.
It is much more simple than, say, an earthworm, which is an anelid.
It is much, much more simple than a slug.
It's got just over 100 neurons, right?
Yeah.
Like 103?
It's got a little bilobed brain.
We haven't even been able to figure that out,
and I think that goes back to the,
are we smart enough to know how smart animals are?
We are just kind of piercing the surface of the complexity of even simple animals,
not to mention somewhat complex animals like wasps that have differentiated jobs
and do amazing things like taste with their ovipositors.
What are ovipositors?
Feet tongues?
No, not quite.
An ovipositor is where, is the tube on their butts where they lay eggs,
and it's also a stinger for animals in that group of animals.
Can't sting me and lay eggs in me at the same time?
Kind of.
God damn it.
Now we're definitely killing all of them.
Yeah.
So, I mean, so here's an organism, which, really cool,
it can kind of sting, lay eggs, lay larvae, and passive venom, right,
and taste so they can like feel around inside a cocoon,
figure out by taste where the right place to lay their eggs are,
lay them with paralyzing venom.
Then they can, I was just reading this article,
there's a wasp with, that has a felting ability, also on the ovipositor.
So as they pull back out, they felt the cocoon closed.
See, when you say really cool, I feel the same thing that you guys must have felt
when I said it was awesome that the jet fighters could,
computer jet fighters could out-fight the human ones.
So to me, that is just horrifying.
But, you're like wasp, whatever, who cares?
Wasps are learning creatures.
Wasps can do amazing things that we are still,
like that article just came out.
Oh, they can felt certain parasitoid,
ecumenum wasps can felt with their ovipositors.
Well, that's cool.
All of these things were kind of just discovering,
and it's not necessarily cognitive stuff,
but it's also cognitive stuff.
There's a lot of people working on wasp behavior.
Compare that to a thermostat,
which we seriously know exactly how it works.
And it's very simple.
So that's the one point that I just wanted to respond to,
is that one, and then I'll get to your other one.
You bet.
You know, so the thermostat thing is,
I sort of used it as a jumping off point for like say,
at the meetup I was talking with somebody,
and I said, alright, so forget actually getting a billion wasps together.
What if we simulated a billion wasp minds on,
we emulated them on a computer?
We can't do it yet,
but there's every reason to think that it would be doable in the future.
We can emulate great chess players on computers.
Would it be like a bad thing to delete the program and get done looking at it?
Like it would be with a person,
if you're emulating a full human mind.
Would it be a bad thing to,
if you were able to emulate a chimp mind,
to get rid of it when you're done looking at it?
Right, and so I think this comes into like,
when you say, look at all the complex things wasps can do,
it's not the same thing as saying,
look at how smart they are, how important they are.
I feel like you're conflating,
conflating the complexity of,
you mentioned we can't make flatworms,
like you're conflating their atomic complexity,
their intellectual complexity,
and the things they can do complexity into all like this one thing.
And I think they're very different things.
Okay, why is this important?
Because they're different goalposts.
So I'm judging the thermostat based on what it can do,
what use it has.
Thermostats have a great deal of use.
They're very helpful.
They probably save lives.
Yes, because people die of heat and cold.
Thermostats are there to help people not die.
They're very useful, right?
Right.
Thermostats do cool stuff.
They do very simple cool stuff.
So if we're comparing a fucking thermostat to a wasp,
you know, there are different places to compare them on.
I think if we're comparing a thermostat to a flatworm,
a flatworm can do some cool things too,
but they're really simple.
They're not that simple.
It turns out not as simple as a thermostat,
because we can't even figure out how we can't make a flatworm if we want to.
But it's like the thing with like how complicated they are,
like with thermostats matter more if they're more complicated to make.
I certainly don't think so.
Well, the thing is we don't...
Like, would flatworms be less important if we did understand them?
I don't think just the fact that we can or can't understand something
is what determines whether it's of moral value or not.
You spoke about, if we were talking about aliens,
and we didn't know that many things about them,
that you would err on the side of caution.
All right?
I'm talking about the known versus the unknown.
And if something is complex to the point that it is in the unknown
and you don't actually have a complete bearing on all of its abilities,
all of its capacities,
what its wealth is, what its inner life is, how it sees the world,
then why would you try to make that equivalence?
See, I totally err on the side of not torturing animals,
of not killing them needlessly.
But on the other hand, I do not walk with a broom sweeping my steps
before I step in the fear that I might step on a worm or something,
because I do not think I need to err that far.
There's a difference between killing a dog without needing to
and stepping on a worm when you're walking.
I don't check my steps for those kinds of insects,
because I just don't care.
I don't think you need to err that far,
where you're literally starting to get incapacitated.
But that said, you also don't seek out ant hills just to set them on fire.
Exactly.
And that's why I feel like I'm still on your side of the fence,
and you're on the side of the fence on that particular issue as well,
that there's a difference between saying,
like, look, they have no value whatsoever,
and they're utterly pointless, and saying that I would...
Like, if there's an ant hill in my way where I want to build a building,
I'll bulldoze the ant hill.
Right.
And you'll probably also bulldoze the prairie dog colony,
and poison the prairie dogs, and...
Would I have to poison them?
Hopefully not.
Yeah.
But, oh, it might be a little bit more expensive for you,
so you'd have to kind of try to figure out
how much you not poisoning the prairie dogs is worth.
You know, like, there's...
Right.
That is something I would have to consider if I was a land developer.
But then that said, like,
I guess what is the answer to that conundrum, right?
So, like, yeah, there's going to be a cost-benefit analysis
where some number of beings on Earth will be harmed by something that you do,
and, like, building a dam or a building is a good example,
because it will necessitate those things.
Humans, including humans, are going to be hurt by the things that you do.
Right.
But then, like, do you not do them?
Because, like, what if it's literally an ant hill,
and you just want to build...
You just want to put up a light post.
And, like, there's an ant hill right there, right?
Like, and that's all that's going to get out of the way.
Like, do you not put it up because of the ant hill?
Or do you put it two inches over to the side?
No, but, like, I guess I'm putting that to...
Think of an ant...
Of a conundrum that actually makes you answer the question,
like, do you say, well, you know what,
despite the fact that the street will be a little darker,
there might be a higher risk of car accidents,
and, you know, kids getting run over because it's dark,
I'm not going to weigh that distant possibility
against the actual lives of these ants.
No, but I think that we're getting a little lost in the weeds here.
I think so.
So, the other part that I wanted to respond to,
one is, again, why even talk about thermostats?
It has nothing to do with...
It doesn't even compare to any animals except,
I don't know, maybe sponges.
Well, I think all life, all intelligence
is basically a computational process.
And if thermostats do any sort of computation,
then they are somewhere on that spectrum,
even if it's really far from pretty much anything.
And that's a way of asking,
where do you draw the line?
How simple does the computation have to be?
And different people draw the lines in different places.
All right, and then what happened was
you started to talk about our trolley problems, right?
And in this trolley problem,
there is a dog on one side,
or there are not just a dog,
there are 50 dogs tied to one set of tracks,
and there's one human tied to the other set.
Right.
The other thing that convinced Steven
was that kind of thought experiment.
It wasn't specifically the dog's thing,
because I would put more moral worth on a dog
than, say, a flatworm.
But, like I said, if we could simulate
10 times the number of flatworms that exist on Earth,
and kill all of them,
versus killing one innocent person,
I guess I would wonder...
I mean, it's pointless to put an actual number on it,
but is there a number where you would say
there's enough flatworms here to where,
sorry, best friend, you're gonna have to die?
So, you said it's your best friend.
Let's put something else.
Let's say...
Let's imagine an actual dog in the room.
Let's imagine an actual animal
that we know and care about,
like Dio, who is here licking his paw right now,
adorably, and making lick noises,
which is not so adorable, is it?
He's trying to lick off all my pets.
He says, you are a speciesist.
I no longer want your pets on me.
So, there's Dio, and he's tied to some tracks,
and he's about to get hit by an oncoming train,
but there's someone from work who you really don't like,
and who just makes life terrible,
and you think they probably have a negative overall utility
tied to the other side of the tracks.
Are you asking me specifically?
Because you already know what I'm...
You are looking at me,
and you already know what I'm gonna say.
Kill Dio.
No, because...
I'm telling you what I would do.
Yeah, I know.
That's not what you said last time.
So, after we finished recording,
you said to me and Dio
that there are many humans that you would sacrifice for Dio.
There are, but no one that I work with.
Even the most unpleasant person I work with,
I think is worth more than a deal.
But, I mean, if we're talking about murderers
or rapists, child molesters, then yes, totally.
Yeah, no.
Dio's worth more than one of them.
There's something to be said there.
I had a...
I lost a pet recently,
and it is quite possible.
I mean, I would have actually had to think about it
for more than five seconds
if the doctor told me,
hey, we can kill five people you'll never meet
and your cat won't die.
I would have thought about it for a second.
But if the doctor said,
or some mad scientist came to me and said,
I can kill five people or a random cat,
I'd be like, well, you're insane.
Kill the cat.
But that's not...
So, the thing is that it's not talking about
the internal value of the animal.
It's value as an instrument to my happiness.
Right.
But that's a different issue from its complexity
and its internal value.
The reason that I'm bringing this up
is because I think that it's totally the way
to go about deciding what's worth more
this life or that life.
What's worth more?
A dog or a cat?
What's worth more?
A dog, easily.
As an alien, it has four listeners.
Including a third of your hosts.
So, this is where we're running into some serious biases.
Okay.
Right?
And this is a place where we might be able to benefit
by stepping back and trying to de-bias ourselves.
For sure.
I will just mention that I don't think
that trolley problems are a great tool
for coming to real-world answers either.
What they are are good intuition pumps.
And if you do sit and think,
you know what?
There's probably no number of thermostats
that I would trade for a person.
But you might not say that about, say,
a sufficient number of flatworms
or a sufficient number of more complex
artificial intelligences or something, right?
And certainly, those conundrums will be coming
with computers in the future.
So, like, you can't just declare now,
or I guess you can, but you have to back yourself up,
about, like, oh, yeah, no.
No matter what the computer can do, I don't care.
What if it can perfectly simulate you and your mom?
Like, then do you not care still?
So, like, you know, these things are brought up
not as real-world problems today,
but they're brought up as intuition pumps to say,
all right, let's think about what you're actually,
the implications of what you're thinking.
And there are real-world problems, right?
Like, oh, how many low-paid workers
might lose their jobs
if this form of factory farming
is changed or abolished or banned?
There are those real-world problems,
but my suggestion for some of the thinking,
the thought experiment is to get away,
far away from real-world problems.
And imagine that you are on an alien world,
you have X information,
and you want to know what decision somebody else might make,
and you're guessing.
So, I guess all I'm saying is a good exercise
is to really try to remove yourself from it
and talk about the zergles and the blurgles.
And all you know about the zergles
is that they seem to have rudimentary tool use
where they can attach up to five sticks together
to make creative new tools
and carry them to a place where they're going to use them, right?
So, they collect the materials beforehand,
and they carry them up to 10 miles
to where they can actually use them to retrieve food.
And the blurgles...
Okay, I forgot which ones I was talking about, but...
You were talking about the nergles.
The nergles? Oh, I never said nergles.
Whatever.
I heard nergles and blurgles.
I thought the zergles and blurgles.
So, also, you know that the blurgles
are able to cooperate with another third species, the nergles,
in order to hunt because they use different hunting strategies.
One of them flushes them out.
One species flushes the prey out from under rocks.
The other one can eat them when they are out in the open,
and the other one, if they're going after something in the open,
it goes under a rock.
Is the prey the nergles?
No.
Okay.
It's an additional prey item.
Okay.
The blobs.
And you get this information,
and then you ask, well, what would Sarah...
So, Sarah is the commander
of a group of Zyridians who have just landed
and they're running dangerously low on food.
They need to add some food source,
and they are considering hunting either the zergles
or the blurgles and nergles.
So, what should Sarah decide
for her also alien species?
So, I forgot the names of all the things.
So, the zergles have the two of you.
I mean, some of them seem to eat something that aren't other animals,
so you might consider eating those.
Eating the blobs.
The blobs.
I mean, maybe.
So, that's the kind of thing, too.
Everything that can be said about a flatworm
can also be said about a flower,
or like an acorn.
So, like, I mean...
That is not true.
They're complex.
They have dividing cells.
They...
So, flatworms have brains.
I know, but is there any...
I guess...
I don't know.
So, I guess...
A lot of tree networks can communicate with each other,
which is, you know...
So, they have a brain.
Flowers open their petals and respond to stimuli,
being as flat traps to eat things.
I guess, I mean, so, I don't know, I guess...
I'm sorry, I don't want to belittle...
I don't want to belittle the other kingdoms that aren't animalia.
Okay.
But...
Kingdomists here.
If we could just...
Yeah, I'm sorry.
But we're sticking with the alien.
We're sticking with the alien.
To be clear, I didn't mean to completely derail.
That was just something that was on my mind.
I knew that there was this nagging thing in my head
that was trying to come out,
and that was it, that I wanted to make that comparison
ten minutes ago, but it's gone forever.
So, we'll move past the zeroes and blurtles.
Right.
So, what should...
We should ask Katrina later on
if what's the moral worth of a network of trees
compared to a flat worm?
There's larger costs, though, with trees.
Like, they house lots of things.
Yeah, they sequester carbon.
So, that too.
But, I guess...
I forgot which ones did what.
It's okay.
It's okay.
It was...
So...
The two losing ones and the cooperative hunting ones.
There's literally nothing else on the planet.
So, there is...
Apparently, those are the only things that are editable
by our aliens.
Fair enough.
Those are the only things that the aliens can eat,
so they either have to...
Can the aliens eat each other?
They're not going to.
They can, but they won't.
I asked that because we were talking about this before,
and, you know, like how we place value on things
because you care more about them and stuff.
And I think this is off the air last time,
and I'm not...
I'm not a cannibal, but...
I said that, you know, there are circumstances
under which, you know,
otherwise decent human beings would kill and eat
other human beings.
Yeah.
I mean, they can leave.
Because they care more about themselves
than other people, right?
They can leave or put themselves in stasis
and wait, or they can...
So, I think that you might correctly identify
that we don't have adequate information
to make that judgment.
Yes.
One species can make shows, rudimentary,
tool use and forethought,
and another species does cooperative hunting
with the third species.
Well, that's true.
Did you answer, like, answer?
What?
The question.
The usable one?
What would you advise Sarah?
I mean, so, like, it sort of depends,
I guess, and this is kind of defeat the thought experiment,
because the point you're making is fine,
and it's a good intuition pump,
that we have limited information.
How can we make this judgment?
And the correct answer is mostly that we can't.
But, like, you know, if it literally is, like,
your whole crew starving to death,
you just eat the one that's bigger.
Or the one that looks like...
Or the one that's easier to catch.
Right, so, like, I mean,
that's why I brought up the cannibalism thing,
is because, you know, if it really comes down to it,
you're gonna do what you need to do.
If it really comes down to it, I'd eat a chimp.
Like, I wouldn't want to,
but if I was literally starving to death,
you'd bet your ass I would.
Oh, so, if you were starving to death,
you would kill and eat a chimp.
You wouldn't kill and eat a child, right?
Or, I'm sorry.
How hungry am I?
I should have said that as...
You are so hungry that if you do not do this, you will die.
Right, I mean, like, that's...
Like I said, I guess I...
Is the child smart enough to eat me after I die?
So...
Because if the child can keep going,
that's an important consideration.
That's true.
I might be willing to die to keep the child going.
Is it two years old or, like, ten years old?
Like, if I said, look, eat me in the...
Like, actually, this is a great thing in the book, The Martian.
When they did the...
If you haven't seen the movie, do so.
But I'm going to go on, assuming that you have,
because you're all cool people.
So...
The crew on the Hermes spacecraft makes a flyby past Earth
to pick up supplies and then loop back around Mars to save...
Well, spoiler, whatever.
Halfway through.
One of the crew members is talking with her parents
about what they're planning and all that,
and they're like, yeah, but look,
what if you miss the drop-off?
They're all going to die.
And she's like, well, look, you can't tell everyone.
But we're not all going to die.
I'm the smallest.
If we miss the drop, they're immediately going to take cyanide capsules,
and I'm going to subsist on the raining supplies
and them for the flight back.
I'll make it home.
And so that is a calculation that you can make,
and they made it based on her size and the relative size
to other people, the amount of nutrients that she would eat to survive.
Those are the kind of calculations that you make
if it's literally starving to death.
So, like, if the kid could eat me,
I would last longer than the kid as far as a food supply.
So all of the things being equal,
that would be a decent trade, right?
But, you know, if it's a six-year-old,
so if we're talking about...
I actually probably would not kill the kid.
I would just starve,
and I guess the kid would probably have to end up starving too
if he doesn't know how to roast and eat me,
because I would rather die than to kill a child.
That's sort of where I would end up, too.
But we're also, again, going back into speciesism
with this kind of thought experiment.
We should really be thinking Alien A, Alien B, Alien C, right?
Right.
Well, again, I never actually answered when you asked about Sarah,
but I would leave it up to the aliens
because I don't see why I'm involved in this
if they want to eat one species or another.
What do you think Sarah will say?
What do I think she'll say?
So they are an interplanetary traveling species
that arrived on this planet, but something went wrong,
and what decision do you think that Sarah will make?
Oh, what decision do I think she would make for her crew
as in telling them which animal to eat?
I don't know.
Again, probably whichever one is easiest to kill
or whichever one provides the most calories.
Okay.
So your model of Sarah, who you don't know much about,
is that the intelligence and that stuff,
it wouldn't really matter to her.
Not while she didn't have time to assess it.
I mean, because those two species that you laid out
are complex in their different ways, right?
And then that comes kind of down on a value judgment.
Maybe Sarah's species cares more about social interaction
than they do about toolmaking, although they're in a spaceship,
so they kind of care about both.
And she's not alone, so she cares about social interaction.
What if Sarah is not an alien species?
What if she's human?
Then what would she say?
Yeah.
Probably the same thing, I guess.
Okay.
Yeah.
Yeah.
Okay, so kind of on the same.
Which would you kill and eat?
I would say that we don't have enough information.
But like, while you're got the information,
your crew's starting to death, what do you do?
Like, you're the captain.
You got to make a call.
Or not, but if you...
Well, I'm also...
Yeah, I'm a pretty...
I'm speciesist, as you are.
Yeah.
And since we're choosing whatever Sarah's race of people
to identify with as ourselves,
then I don't know, the cooperative hunting ones.
Okay.
You'll eat them first?
Yeah.
Over the planning head tool-using ones?
See, I think I would go back on...
I would only have my own experience to draw on.
I'm a little bit biased towards tool use, I guess.
I'd only have, like, my own experience to draw on.
So, like, I imagine that Sarah would be in a similar boat
where she'd look back and be like,
what are the animals on Earth that do these kinds of things?
How complex are they?
Well, if I had to guess,
I'd probably say that these ones are dumber.
If she cared about which one's dumber, right?
Do you hear that?
I mean, recently they saw a...
I don't remember if it was a crow,
or if it was some species of Corvid,
used a tool to carry another tool
to someplace where it could use that other tool.
Yeah.
That was awesome.
I just...
I love these birds, man.
Yeah, actually, the other weird thing about this book
is I had just finished a section
on new Caledonian crows in the wild
using a hooked twigs as tools.
Okay, cool.
And I was just listening to that on the radio,
and they're like, this is the first time
that tool use has been shown in these birds.
Oh, no.
It's been around for a while.
And I just read about it in this book,
which admittedly came out in this year,
in 2016.
Yeah.
And I saw a YouTube video
at least five years ago of a crow
unbending a paperclip
and reaching into grab stuff.
It wasn't even a tool.
Captive.
So the difference is captive in wild.
Ah, okay.
So the captive new Caledonian crows,
that's the one that had been shown a while ago,
is that they would literally bend paperclips
in order to use them as tools
in order to fetch something.
And friends of Wall said,
in his book, he's like,
nobody should have been surprised about that,
considering we already knew
that wild new Caledonian crows bent sticks.
Oh, okay.
And then so it was kind of funny
to now hear on the radio.
For the first time,
it's been shown that wild new Caledonian crows
bent sticks.
Right.
In other news, for the first time, fire hot.
What was, there's a word for it,
the type of animal that lives in conjunction with humans
but isn't domesticated.
Specifically like city birds, squirrels.
Or elephants.
Or elephants.
But elephants aren't domesticated.
No, they do their thing.
No, they're very wild.
They do their thing as opposed to like...
They're often trained and used for...
Well, I think Stephen is referring to animals
that are not trained but just live near humans,
like coyotes and pigeons.
Well, I was thinking crows specifically,
because I saw another YouTube video
where they were throwing nuts
at crosswalks in the street.
Go over at crosswalk time.
So like, not only were they using traffic to open nuts,
but they were smart enough to use it
when the new traffic would stop there.
And so, but I don't know if that would count
for captivity or non-captivity.
Oh, that's wild.
Oh, good.
Yeah, because that's all.
Yeah, they're referring...
Honestly, I probably wouldn't have thought of that.
Not in the lifespan of a crow, anyway.
So, that's awesome.
No, and I don't want you to be too disheartened.
I don't think anyone should ever be cruel to animals.
I care deeply for them, you know,
to the extent that people, I guess,
are permitted to be cruel to animals.
It's like, when you have a really good reason,
like you're starting to death,
or, look, it's going to take us 30 apes,
but I think we can crack uploading human minds.
Like, that, I mean, you'd be hard-pressed for me to say
those 30 apes aren't worth the potential immortality
of the human species,
and whatever other species we want to immortalize.
So, but I mean, those are high bars, right?
So, you know, things that don't fit the bar, fun.
What are the stupid reasons people torture animals for?
Food?
Not food, I think.
It depends on the food.
When you have other options?
When you have other options, I think.
I don't know.
Oh, we didn't talk about this last time.
I remember that was the one thing
I mentioned seconds away from turning off the mic.
Vegetarianism?
We didn't talk about food preferences at all,
and I don't know how far we're into this.
We want to get to emotions at all on this one.
No, we did talk a little bit about it.
Did we?
Yeah, yeah, about chickens versus pigs versus pigs.
Oh, sure, sure.
Not too much, but we did touch on it.
Right.
So, I'm vegan, mostly vegan,
and the two people,
Anyosh and Steven, that I'm here with, are not.
They're not only not vegan,
they're also not vegetarian.
I know that a lot of people maybe,
you know, get that distinction.
I guess I'm trying to say that they eat meat.
I feel like I'm being shamed right now.
To further shame you,
I will say that I feel bad about eating meat.
Well, I don't, as much as possible,
I don't eat any pork products.
I don't eat pork either.
One of the reasons that I was...
Because they're like dogs, and I love dogs.
Trying to come up with some ways
to do de-biasing is because
if people are eating meat,
they might have motivated reasoning.
Okay.
It actually would be really nice for you
if you put a lower moral weight on animals or...
It's true.
It makes my life easier.
It makes your life easier.
It means you don't have to live with this much guilt.
So, trying to get away from that scenario
where we're coming into this with incredible biases.
I think de-biasing is one of the
core techniques of good rationality.
And there are lots of things that you can do,
even quick little ones.
And I don't want to get into one of my favorites
until we do a whole episode on it,
but we should have done it at the beginning of this one.
And we didn't, so I won't even mention it until next time.
There's a good one coming up eventually.
So...
But this is kind of an emotionally charged topic,
especially since Katrina was bummed out
that my position updated in the wrong direction.
I was so bummed out that I asked to do a second part.
I was like, no!
I must represent this better.
No, I love animals.
I always have.
That's why I've dedicated my life to helping them.
And I think that I love animals, too.
So, I mean, there's a difference between, like,
how much they matter, because I love them,
and how much they matter if I wasn't around.
But, you know, as far as all of that emotional attachment goes,
it is a decent segue into talking about emotions
as a larger topic.
Except, I think, how late are we?
How long have we been recording?
59 minutes.
Yeah, so we're...
I mean, if we don't want to start another one-hour episode
at this point.
So...
It's a beautiful segue for next week?
Yes, if you are okay with waiting until next week.
That's fine.
We'll be back next two weeks from now when we do this.
I'll even be more prepared to engage with you guys
about emotions.
That sounds good.
Emotions and rationality.
In the meantime, do you want to get into some
of the listener feedback?
Yes.
I will remark that we now have, as of recording,
on August 11th?
10th?
What's the date?
As of August 11th, we have a handful of reviews on iTunes.
I'm not going to read all of them, but we're stoked.
Thank you so much for taking the time to do so.
Thank you so much for the reviews.
You are really great.
We read them to each other, and we felt really good just now.
So thank you very much for making us feel happy.
Yeah, it was great.
Let's see, as far as listener feedback...
We got one comment from someone named Kevin McFarland
on TheBaysianConspiracy.com
in response to the Street Epistemology episode.
Hi, guys.
Just discover your podcast this week in the trending section
of my app.
Podcast addicts, BTWs.
They said BTW.
After listening to number four, Street Epistemology had a question.
On one hand, you espouse rationality as a goal worth pursuing.
I do too.
But then, you spoke of the goal of increasing happiness.
No doubt, you have found happiness through your skeptical and rational friends,
but I've generally laid down my quest to de-convert
in the realization that most of the people who are deeply religious in my life
are themselves and families and communities that are religious.
For them to reject religion,
bring them possibly the greatest suffering
because the family, friends, and community would feel rejected
and that their beliefs are being attacked by that rejection.
So, de-conversion is hard and usually produces immediate unhappiness
that I'm sure you've experienced.
Where would each of you say you lay on the spectrum
between choosing rationality and happiness
if they were mutually exclusive?
They don't have to be, but let's make this a thought experiment.
Thanks for looking forward to listening to more good stuff.
It's kind of like, if you had to choose between killing Matt when Hitler,
who would you kill?
I mean, I see where they're coming from,
but I don't necessarily think that you can draw an argument
or a plausible real-world scenario where they're mutually exclusive.
It's like that kind of makes just burning rubber and wasting fuel
trying to find a good answer to it.
I think, for me personally, there's some world that it's not worth living in
and if I have to choose a world where I'm either happy and, you know, of the...
I mean, if you can't use rationality, I'm assuming I'd have to be like
of the mental caliber of a dog or something.
If I have to be happy and stupid or if I have to be miserable and rational,
I'd really probably rather just kill myself
because that is not a world that I want to be in.
Option C. There's always a third choice.
If it's literally be unhappy and don't de-convert or be rational
and be happy but irrational, I would choose being happy.
I guess I wonder what necessarily means to be irrational.
Like, does it mean, like, incapable of being...
Does it mean incapable?
Or does it simply... are they simply talking about...
So if Kevin was simply talking about religion,
like, you have religious beliefs that are wrong
and you're happy versus you don't and you're unhappy,
I would definitely choose having religious beliefs that are wrong.
I live in a world right now where I have beliefs that are wrong.
I am the opposite because if it was just, you know, religion and happy
or irreligion and unhappy, I would choose irreligion and unhappy
because I would much rather know the truth about the world than be happy.
Why unhappy are you?
What, right now?
Because I have been extremely unhappy in some stretches of my life
and I managed to get through it so I could be very unhappy
and still be okay with it.
I do not want to be miserable.
I don't want to be miserable.
I want to have a good life.
I highly value happiness.
I value happiness more than being right.
The good news is being less wrong makes me more happy.
See, that's the thing that initially it may not
and for many people, and this is going to be a judgment call on anybody
who wants to try and approach somebody about this,
but initially, yes, if you're going to look into these things
and de-convert and, you know, lose a spouse or connection with your family
that would suck for a while,
but it's quite possible that on the other side of what's called the valley of bad rationality
you could retire peaks where you not only get the joy of finding a partner
that you can get along with again and, you know, whatever forming new connections,
but also the joy of, like, I guess...
Further exploration.
Further exploration and there's a kind of happiness that comes from being right
or being less wrong.
There is, totally.
And I guess that's not quite exactly how I want to put it.
I'm not sure if I can articulate it in the course of the sentence,
but there's something to be said about...
I know I said this before about the...
I think maybe it was even the last episode that it's better to be a miserable Socrates
than a happy pig, which is a statement I agree with.
But I mean, part of the problem for me is that basic simplistic religion
is so simplistic that it feels like a sort of a lesser order,
a less... a qualitatively lesser way of being, you know?
You lose some complexity in your life.
Yes, I was.
And I know that's not necessarily always the case,
because there are very complex types of religion made for people who are, you know,
the highly introspective type.
There's the Jesuits who are basically the atheists of the Catholic community anyway.
I mean, I know they aren't really, but...
As close as you can get while still being Catholic.
Exactly, yeah.
And they... that's where all the really high, high-functioning,
highly analytical Catholic people go into the Jesuit branches.
So there is those outlets in religion, which is nice.
But if we're just talking about standard, basic, you know,
Jesus loves me, this I know religion,
to me that's just... that's a different level of thinking,
which is less rich and...
And like I said, I put moral weight on intellectual complexity,
and I would feel like I am less of a human
if I were to reject thinking those things,
just for the sake of being happy.
Let me think of it this way.
If you were told you could go back to that,
you would say, no, I feel diminished.
Is that about what you're saying?
Totally.
I think I completely agree.
But coming from another perspective,
where my brother-in-law, his face gets him up in the morning,
his faith comforts him when he's down,
his faith helps him get through every day,
and he doesn't feel like he would be able to do that without his faith.
Well, then he should probably keep his faith.
He should keep his faith.
Yeah, that's why I think it's definitely a case-by-case basis.
Yeah, if it's literally to the point where
you probably could not get out of bed and you might kill yourself,
if you don't have that, then you shouldn't risk it.
It is... there are people who... and I guess...
I can't be sure, because I don't have a large enough sample size,
but there are people who are going through what your step-brother...
or your brother's step-brother, you said.
Uh, my brother-in-law.
Your brother-in-law.
I knew it was... I got this confused earlier, too.
There are people who are going through the exact same feelings that he has,
but can do it anyway, even without religion.
So, like, there are... there are ways to get around those problems
that sound like there's one cure for it,
and it could be that having these other tools to get through it
are more generalizable to other kinds of ways of being happy.
There's a lot within science that is inspiring,
like awe-inspiring and mentally-inspiring,
and just makes you love humanity
and want to... want to do things with your life.
It's not... that doesn't all just come from religion
and from thinking that the Sky Daddy loves you, you know?
Right, yeah.
Uh, it's one of the great lies that religion has a monopoly on.
All right.
Those kinds of experiences.
Also, we can move away from religion a little bit.
All right.
Well, I did want to say really quickly,
uh, in reference to him about, uh,
that his relatives would lose a lot of happiness
if they were to leave their religion.
Uh, I kind of feel like that is a sort of hostage-taking.
It... to me, it feels very similar to...
in the 50s, people would say,
uh, you don't want your children to be gay
because they will be miserable.
Mm-hmm.
And the reason they'll be miserable
is because society is fucking horrible to them
and would make them miserable,
but that wasn't default of them being gay.
That was the fault of society being shitty.
So if their lives are made miserable
when they leave their faith,
that's probably because their faith is shit
and makes the lives of unbeliever shitty,
as opposed to them necessarily being less well off intrinsically.
Right.
But they have a different environment, right?
Mm-hmm.
So if we're talking about existing in a certain environment
and adapting and a huge amount of what we do as humans
is conform.
Mm-hmm.
Um, it's really important that we...
we conform socially in many ways.
Weird environment where we can conform
in ways that we think we want to.
And, um...
And in whatever town he's living in,
that might not be the case.
Yeah, well...
Is that an argument for staying in a closet in the 1950s?
It is.
Yes.
Yeah.
So I guess that's the case.
If you live in the equivalent of the 1950s with regard to gayness...
It also probably depends a lot on your own personality.
I'm very much a kind of,
fuck them all, burn the place down
when it comes to that sort of thing,
but I understand that a lot of people aren't,
and if everyone was like me, society might be worse off.
I'm not sure.
Maybe it would be better off,
but I see where there's...
Katuna's shaking her head.
No, she's like,
everyone should be like you, Enne Ash.
That would be terrible.
But no, there's a lot of people
who just don't aren't...
See, I get a charge out of fighting sometimes.
I'm like, yeah, bring it on.
Fuck y'all, I don't care.
You too.
You never had fun arguing with or looking with somebody?
You didn't enjoy today's discussion?
I did.
I don't know.
I don't like when it's negative.
I don't like it when it is the fuck you all approach
that Enne Ash is describing.
Or, you know, some of the things that...
and it never mind.
Yeah, no.
And it takes all different kinds of people,
and that's one of the wonderful things about humanity, right?
So I can see for some people
it may not be the optimal strategy to be like that.
Right.
But there's also my self-survey question lens,
and this reminded me of it,
where if you learn the truth about X,
and it was horrible,
would you still want to know?
I always say, oh yeah, I still want to know.
I still want to know.
But that's also because I kind of have a little bit of faith in myself
that learning the truth about whatever
is not going to plunge me into a deep and horrible depression
from which I cannot emerge.
It is... God, what is it?
Is it the litany of Egon?
The litany of Tarski.
The litany of Tarski?
Well, that which is is already so,
and acknowledging it doesn't make it worse.
That might be Gendlin, I forget.
There's Gendlin and Tarski, who knows.
But the...
The other one where everything boils down to normality.
Like, no matter what you learn about the world,
the world itself hasn't changed,
so it all reduces to being normal.
Right.
And Krishna, what was the last thing you said?
A jarred something that I wanted to acknowledge,
but I forgot.
It still passed me with it.
I just mentioned the survey question.
If you could...
If learning the truth about a thing,
if it's horrible, would you still want to know?
Yeah, of course I'd still want to know.
But the question wasn't,
would it make your life horrible?
It was, is the thing is horrible?
Right.
No, I totally understand.
But that I think raises what it's like to come out
on the other side of the valley of bad rationality.
So, like, when you're on the low peak over on the side
where, you know, you're in a faith-based environment
and you're okay with it and everything's jolly and whatever,
you may...
Some people, I didn't, but some people might...
In fact, many people probably do.
I don't want to generalize from my own personal experience.
Find a period of decreased happiness.
But I think part of coming up on the other side of that
is that you'll have better habits of thought
that will let you confront situations like Katrina was positing
where you're confronted with, you know,
do you want to learn this bad truth
or do you, you know, want to persist in delusion?
You know, you could have, man, my...
You're no longer held hostage by your false beliefs?
Exactly.
And you're not afraid to confront them.
So, like, and you're not afraid...
You don't have the mental habits of saying it's okay
to blanket yourself from doubt.
So, like, you know, that way when you're, like,
you're having, say, like a medical symptom
that you're worried about, you know, one approach might be
to be like, well, you know, I'm gonna just not think about it
and everything will be okay.
Another thought will be like, I should get that checked out
and then it's cancer either way.
But checking it out and knowing before, like, it's visible,
you know, to the naked eye or something or however bad it gets
is probably a better prognosis.
It depends on, yeah.
It depends on the cancer, I know.
And it depends on the very specific situation.
Right.
So, for example, we de-incentivize sex workers
from getting checked for HIV because we have laws in place
that make it illegal to be a sex worker if you have HIV.
So, if you know you have it.
Right.
So, people are incentivized not to ever get tested for it,
otherwise they're going to potentially lose
an important source of income and possibly be jailed.
Don't we also have a law against being a sex worker
in the United States?
Yes, we have those too.
Yeah, but it gets a lot more serious.
The punishment gets a lot more serious.
If you're knowingly spreading HIV, or if you're...
Not knowingly spreading, but just knowingly have HIV.
While being a sex worker.
Yes.
Yeah, you can be a sex worker without spreading HIV.
But as the consumer, I would share, you know,
like some disclosure there.
And it's better for people's health to know
what their HIV status is, of course.
Not just for, yeah.
Yeah, what if you're on cancer?
You've got some crazy communicable disease that you picked up
and you're ignoring the coughing
because you're worried that it might be this scary disease
and because you want to ignore it,
you're going to spread it to everyone you know and love.
This is kind of like the...
It's kind of like religion.
Well, like Clifford that I mentioned in the episode
on street epistemology, the boat captain, right?
Are you going to look at it or not?
Well, you're culpable either way if the thought occurs to you.
And if you're going to suppress that thought,
you're culpable, you know.
So even if you didn't get it confirmed
and then spread it anyway, it's still your fault for not checking.
So, yeah, that's where it kind of comes down to on that.
But I would posit that, I mean, some people's mileage may vary.
Maybe some people, you know, they lose their religion
and their life sucks forever.
I'm sure those people exist.
And so be cautious when there's a whole lesson
to be learned about other optimizing, right?
You don't necessarily...
What works for you might not work for them.
And a lot of religions are very happy to take the fallen sheep
back into the fold.
Also, consensual epistemology, probably.
Consensual street epistemology have these arguments
with people who consent to speak with you about it.
Right.
Who aren't like my brother-in-law, who'd be like,
No, I don't want to talk.
I don't want to talk about this.
This is so important to me that I don't want to do anything
that might endanger it.
Yeah, I wouldn't advocate really doing a lot of things
to somebody against their will.
But especially shattering worldviews.
I mean, that's a whole other thing.
I don't know how you approach somebody delicately.
I mean, that's the thing.
For a lot of people, it's a cat that's fairly easy
to let out of the bag.
And for others, you know, the bag is just powered shut
with animantium and mithril, right?
So like, you know, those people you're never going to get to.
But other people just raising the doubt or like, you know,
just voicing your own doubts and proximity to them
being able to hear you could shatter their worldview.
So like, that's a tough thing to do, right?
Or a tough thing to consider and how cautious you want to be.
This is Santa Claus question.
Let's get away from religion.
I got a lot of kids pissed at me because I told them
there's no Santa.
And I was the kind of kid who's like,
I don't care what you want to know.
This is the truth.
Santa's not real.
You're living in a lie.
Get it through your sixth skull.
And that was really, I was,
I didn't have good social skills.
She's done that.
I honestly don't remember my,
my de-conversion from Santa Claus.
I remember, I remember roughly the, not the incident,
but I remember never really believing it
because Santa's handwriting was a lot like my parents.
And I remember being super proud.
I was proud, not bummed.
Maybe that says a lot about me as a child,
that when I was between four and six,
I stayed up late enough to catch my parents,
put in the presents under the tree,
and thus confirming my hypothesis
that they were behind it the whole time.
Stephen de Science.
Right.
But other people might have been devastated.
So I don't really, my,
that's, that's why maybe I was never bummed
moving down from the peak into the,
into the valley of bad rationality was,
that's just kind of spoke to more who I was
on a, on a gut level.
So.
I'm not sure you're using the term correctly though.
Isn't the valley of bad rationality where you learn
some rationality techniques and you can apply them
to make your life worse?
Yes.
Not necessarily unhappy, but to make,
like use rationality to defend things
that are not actually correct.
It's a bit of both, I think.
The short version is your version.
Well, no, the short version is both.
So there, I guess maybe there's two versions.
Yeah.
It's been a while since I read about it.
You can, you can, if you know enough rationality
to say, like become a sophisticated arguer yourself
and being able to like point out to other people,
oh, by the way, you know that's so and so bias,
but you're not smart.
You're not strong enough to put those,
to turn those techniques towards your own beliefs.
That's a bad place to be as well.
I don't know if that's the same thing as the bad valley,
but it sounds like a bad valley.
No, I think that is what the bad valley of bad rationality is.
Yeah.
The moral of the story is turn that rationality inward.
Yeah.
Yeah.
And be, be cautious, but not necessarily completely
unwilling to engage others about it.
That brings me to a comment which I wanted to read.
It was on our street epistemology episode.
Mr. Aliva said one problem I have for teaching street epistemology
very early is that it is so easy to become a good arguer
and not a good rationalist.
It's the same reason that I think before we teach hordes of biases,
we need to teach the moral right of wanting to have true beliefs
more than wanting to not change your beliefs.
If not, you knock down all challenges to your beliefs.
I see that street epistemology is much epistemology is much
harder to turn to reinforce your own beliefs because it is based
on encouraging rationality, but people are surprisingly resilient
to changing and use every tool to make others believe what they do.
Truth.
Yeah.
I was a good arguer before I was a good rationalist for sure.
Yeah.
Same here.
Yeah.
And I actually, I responded to that saying I agreed.
There's a lot of conversation going on in the subreddit.
I mean, you know, not hundreds, but you know,
Did I tell you, did I mention this on the podcast?
Because I know I told you personally, but when I was
like, oh fuck, what was it?
Maybe sixth, sixth, seventh grade.
I would argue now in more than sixth grade, seventh or eighth grade,
I would argue a lot on a BBS's, which is what the internet was
before there was an internet with this guy who was maybe two or three
years my elder and he was an atheist.
And I was like, so why do you believe in this devolution stuff?
Devolution?
That is so cute.
You gave a shout out to this guy.
I think that episode, whatever episode.
I did.
I reckon five.
Okay.
Yeah.
I really thought he did repeat it because he didn't say devolution
before.
I'm not sure if I use the term then.
I am now familiar with it.
I really hope that.
I'm disappointed.
Yeah.
I feel bummed out having, even though like I wasn't around for it,
knowing that it might not have happened now makes me sad.
I don't know what to say about that.
I was, I was very into arguing and I thought I had a lot of things
behind me.
So I was, you know, I was practicing rhetoric even back then.
That was one of the things they teach you actually in Jehovah's
Witness church, you're supposed to go three times a week.
And on Thursdays, they always dedicate one hour to rhetoric, to how to argue
people out of their beliefs and turn them into Jehovah's Witnesses.
This is self-extreme.
Apologetics.
Yes.
Yeah.
Apologetics is another way to put it.
But it wasn't just apologetics.
It was just general arguing techniques.
Oh yes.
Apologetics is more like defending yourself, not arguing against other people.
Well, I mean, apologetics is specifically about religion.
Yes.
Apologetics is specifically about Christianity.
Sure.
And this was in general ways to, to convince people that you are correct.
Sometimes it was apologetics, but other times it was just general techniques.
We can't get around all the, the topic or the comments here in the subreddit.
But there was one other one that I wanted to mention.
User.
Oh, molten glacier.
I recommend your name for one of the reviews on iTunes.
Thank you so much.
Asked, isn't being a dick more a more general problem than just with the atheism
slash rationality?
Well, yeah.
Yeah.
I find, I find people are dicks whenever they believe something that someone else
should believe.
Wait.
Something other than what they do.
No, I totally agree.
And I, I, I responded saying that, and this is something I ought to have clarified on
the episode.
That's why I'm bringing it up now was that it is a problem with a lot of groups.
So there, there are two, two reasons why to bring it up for us in particular.
One is that our message is a harder sell.
Like it's a hard sell already.
You know, you're telling people, this is basically a quote verbatim from Phil Plates
talk.
The, the sales pitch is like, no big deal.
The, the sales pitch is like, no God, no afterlife, no miracle cures, no souls, etc.
You know, basically all the things that, you know, make some people's lives great,
that's all bullshit.
And so we're, we're not going to get that message.
That's a hard sell anyway.
And if you're a way of conveying it is by getting at someone's face and calling them
an idiot.
You're definitely going to, to lose that person.
There's a subset of people who don't like know it all.
There's a large.
There's, there's a separate majority of people who don't like know it all.
Yeah, for sure.
We're trying to win hearts and minds, not just arguments, right?
And the molten glacier replied, and I totally agree that we also have the ability to change
us, not them.
Right.
If, if by saying, hey, you shouldn't be a dick.
And they're like, fuck you.
It's like, all right, well, I tried.
Yeah.
But I, I cannot be a dick.
So, and I'll probably get more people if I am as all of the things being equal, I might
get more people on my side than on them because I'm not being mean to everybody.
You catch more flies with honey.
I also, I want to make a distinction between being a dick and being affirmative.
I, I recently got in a, not an exchange.
It was a brief, just one email back and forth, no big deal, where I mentioned that just my
atheism in general, and this person was like, Oh, well, yeah, but you know, we can't know
everything.
And so there's just as likely that this could be the truth as that, you know, and I, I guess
the non-dick position would be like, Oh yeah, well, I guess you're right.
We don't know everything.
But I was like, No, I dismiss your God belief out of hand.
These are the reasons why I don't have any problem saying that.
And maybe some people would consider that to be dickish, but I wasn't getting up in
his face.
I was just being firm about, I think this is easily dismissible.
And I am not going to make any apologies about it.
Or you can say you're right.
We absolutely don't know everything.
We know a very small fraction of the things that there are to know.
And every God I've ever been presented with is easily not.
But we do.
It lives in the same category.
Yes, exactly.
Right.
But we do what we can to assign probabilities to things based on what we do know, what we
can reason.
And this is, this is why I've come to this conclusion instead of this other one.
Right.
And that might be a nicer way to say it.
Well, I also mentioned, which I don't know if this was nice or not, but I did mention
that I hear this argument a lot and it's true that we don't know everything.
But that suggests that if this is your evidence, then the position that suggests is strong
agnosticism.
But whenever I hear someone make this claim, they are never a strong agnostic.
They're always kind of the wishy-washy spiritual, but this is why I can believe in my God.
Right.
And I don't accept that.
That is not a good argument for your position.
It doesn't.
Sure.
I have definitely heard the argument we don't, there's so much we don't know from strong
agnostics.
I have too.
In fact, that is the argument that strong agnostics tend to make.
I have heard that online.
I've never met anyone in person that made that claim as a strong agnostic.
Different different friends.
Yeah.
But I think, you know, at this point, it stands, and that's true.
That is the correct position for an agnostic.
But you know, at this point, it stands that I do, I've met people too, where they say
we don't know everything.
Therefore, Jesus was born of a virgin and, you know, et cetera, et cetera.
And it's like, okay, so how do you know all that if we don't know everything?
There's a lot of things we know that we can be more sure of than that, right?
Well, no, because it's their catch-all refutation to challenge, right?
They're not actually out there endorsing what they're saying.
They're just saying that phrase.
Maybe it's part of a more complete argument.
You start with, we don't know everything.
Just to, you know, like get somebody off of the 100% ledge.
And then you go, here's some things that we do know from the Bible.
Or from this, or from that, or whatever.
Right.
Yeah.
And it was said that Harry Potter would fight the dark lord.
There was a prophecy about it.
And it happened in a later book.
Where does that sound familiar?
One of the key pieces of evidence, apparently, in support of the efficacy of the Bible is
the fulfilling of prophecy.
Okay.
Well, that would be, I mean, if the prophecies were fulfilled, that is how we get good signs.
Yes, but how hard is it for an author to write another book saying that the prophecies were
fulfilled, right?
Oh, it's not.
Not at all.
Yeah.
That's why we dismiss the religious prophecies, but we're kind of in awe of the science ones.
What's the claim?
No, not the claim, but the quote.
I don't remember if I'm recalling it exactly correctly, but I love this quote, so a paraphrase.
Priests say they can move mountains and no one believes them.
Scientists say they can move mountains and no one doubts them.
Right.
It's pretty awesome.
Scientists talk about moving mountains unless it's, you know, arogyny, a mountain building
event, you know, caused by plate tectonics.
I think we've moved a number of mountains, if there was gold under them, or other valuable
minerals.
I see.
Yes, I guess we have been responsible for more mass wasting than...
Someone's going to use that gold, right?
Point is there was a mountain there and now there isn't.
There's one last thing to say is that when you get further into the rationality community,
you'll find people that are more not just comfortable, but like eager to be challenged.
Not with necessarily dickishness, but with the bluntness that you know I was just talking
about.
If I'm wrong about something, I want my friends to come right out and say, you know, Stephen,
I'm not going to cherry coat this for 20 minutes.
That's stupid, and here's why.
This is why I want sharies.
That Aussie thing of things commented that when people come to rationalist forums, they'll
argue with them, and the rationalists are like, ooh, they want to be friends, and they argue
back, and the people in our rationalists are like, these assholes are arguing with me.
Why, yeah.
So that's how rationalists make friends, by arguing.
Some of them anyway, not all.
We'll talk about Crocker's rule at some point.
Do we have any more comments?
That is all I had.
We want to address?
There were a handful others, but I don't think we have time to get to all of them, but you
know, I do encourage the discussion.
I'm happy that people coming by the subreddit and writing us via email are coming to the
website and sharing your thoughts and feelings.
If you want them public, email us.
If you want them semi-public, post them on the website, and more public, maybe subreddit,
I think, in that order.
So I think more people probably visit the subreddit than the website, but you can't track the
numbers of visitors, although I don't think you can.
Anyway, thank you so much for listening to us.
We always appreciate it.
Thanks for writing in, and we will talk to you in two weeks.
Thanks.
Bye.
Bye.
Erogenous when mountains are made, that's the term.
It's a mountain building event.
Yeah.
That sounds kind of erotic.
Erogenous?
Yeah, yeah.
It's like you have erogenous zones.
