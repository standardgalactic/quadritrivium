But like if you, if you're, if your model didn't have that already in advance,
then you didn't, you, you weren't modeling this at all.
You were just like, yeah, you're just pointing at weird things and going, Oh,
what about that? Uh, that's, uh, something that I've seen brought up recently
with some shoddy science where there's, there's a bunch of ways you can do
science bad and something that is getting more attention lately that I'm
pretty happy about is people pointing out that you did not, um, theorize this ahead
of time. So people will do, I don't know.
It's like a study about asthma and they didn't have any kind of hypothesis
ahead of time.
It's just then like after the fact they're looking at it and being like, Oh,
look, it looks like, uh, I don't know, you can skew the data this way to make
it look like the, the drug that we're testing helped in these ways.
And it's like, did you predict that that was a thing that the struggle is going
to do? If no, then like, that's useless.
And I, I think I, uh, one of the things that is stressed throughout this post is
that, uh, beliefs generally shouldn't be binary on off theories, either true or
false, that they should be held with, uh, a certain probability, like 95%
confidence that this or that this coin comes up heads 95% of the time, something
like that. Uh, because one of the things that he mentions is that, uh, even
with a correct model, if it is not an exact model, you will sometimes need to
revise your belief down. If an iota or two of evidence happens to counter
support your belief, that's okay. Just shift your belief downward a little.
If it's true, supporting evidence will come shortly and the probability will
climb again. If the theory is false, you didn't really want it anyway.
Mm hmm. Yeah, I've found myself getting really uncomfortable with that.
Like, or rather, I've like caught myself and tried to fix it.
But, uh, um, darn, there was a recent example, but I can't think of it.
But, you know, when, uh, oh, no, I remember it about, um, roundup.
So I was getting really frustrated with people talking about that, like roundup
being toxic. And I looked it up at the time and I was like, no, studies have
shown that roundup is toxic. Uh, the mechanism of action doesn't even make
sense for it being toxic. It like deletes an enzyme from a plant that lets
it photosynthesize. You don't photosynthesize. But, um, last night I was
like having this argument with people and I was like, oh yeah, this is a big
pet peeve of mine. And somebody said, well, actually there have been some studies
recently that had a possible connection to carcinogenicity. So I was like, uh,
all right, show me. And then they did. And I was like, hmm, hmm. Okay.
Yeah. Thanks. Like revised slightly. Yeah. In the down, but I like noticed
myself wanting to like start defending my point. Right. So I didn't look dumb
or something. And then it's like, oh, that's not a good, it's not a good
impulse. You did a good thing. You were a good rationalist. Congratulations.
Yeah. He says that, well, the way he ends his post is, uh, that, uh, maybe some
more counter support comes in just a tiny bit. So you rise down again just a
little bit and new upward support is slow to trickle in. You may find your
belief drifting further and further downward until finally you realize from
which quarter the winds of evidence are blowing against you. In that moment of
realization, there's no point in constructing excuses. In that moment of
realization, you have already relinquished your cherished belief. So by, you
know, slowly just updating a little bit, uh, you can get yourself to becoming
less wrong without even having to have any major, you know, existential
struggle over it.
Hey, that's the name of the show.
He did mention earlier up, which I didn't re quote, but, uh, the rationality is
not for winning debates. It is for deciding which side to join. Oh, yeah,
that's a good line. Yeah. If you've already decided which side to argue for
the work of rationality is done within you, whether well or poorly. Yeah, it's
worth noticing, um, when you, when you do have a position on something in
your not sure how you got that strong of a position on it, trying to trace your
line of thinking backwards and being like, did I get this from first
principles? Did I look this up? Or is this just something that I'd heard
repeated by authority figures enough times or something like that? That's
another thing I'm trying to notice too. Like, uh,
I think that's part of the reason he tries to distance rationality from
political stuff, or at least did at the time, because politics is much more
about winning debates. Yeah. And if you're trying to figure out which debate,
which side of the debate to argue from first, then that's, that's a slightly
different thing. Yeah. Well, I think that was mainly meant to be for, I think
that was mainly like politics is a really bad area to start in, because we're
just as a species so hardwired for tribalism. Yeah. It's better to like, yeah.
And that was the other thing that I had forgotten about the, um, politics as the
mindkiller was that he actually says, like, this is for advanced rationalists,
not, we don't talk about politics around here at all. Ever. It's just more, if
you're just new to this, you're just starting out, like hone your skills in
the areas of scientific fact or like, you know, something that's less, uh,
stabbing directly into your soul first. Anyway.
No, and I think that's, I mean, I'm looking forward to the politics of the
mindkiller series when we get there. They kind of come up.
Didn't we really come up? Yeah, but I think some of more of the points like
keep coming up like that. And I like the, that admonition about like, this isn't
something that we can't not discuss. This isn't something that we just don't
discuss. It's just like, this is a really shitty intro move, right?
Um, I mean, it's antithetical to a good approach for an outsider. Right.
All right. Let me say after having argued about politics 20 minutes ago.
Well, that's because I mean, we're also having fun. Yeah. Well, I was, I was
almost going to say that, but I'm not going to pat myself on the back like
that, but what it will say is that like, we're not, uh, I mean, we kind, well,
A, I didn't know we were starting the episode. That was more discussion among
friends. Yeah. Like if I was trying to tell somebody like, oh yeah, here's what
this is about. And here's how it applies to your favorite candidate for
president. Oh God. That'd be the worst. Exactly. Right. So yeah.
Yeah. Um, another thing I did want to point out with this one is I like when
these posts get self-referential, this one said, uh, this one links to people
wanting their debates to be one-sided, which is an earlier post, uh, debate
should not appear one-sided. What was that one titled?
I think so. Okay. Yeah. That's, um, a benefit that you do get from reading the
sequences in order.
Yeah. He covers previous concepts.
Yeah. It keeps building on them until you've got this, uh, much bigger model
in your head than you started out with. That's why sometimes I do find it
frustrating to like try to say this. Oh yeah. There's this whole thing about
how you shouldn't want your debates to be one-sided. And then I'll link the
original post. I'm like, this doesn't look as strong as I remembered it being.
This just kind of seems like, well, there's also the thing where like,
stuff building up to it. Yeah. Yeah. It's, it's hard to get all that context there.
It's like, well, you really have to just read the secret. Uh, that's a lot of
text though. I'm sorry.
Yeah. It's, it's like he's trying to bridge a very large inferential gaps and
has to do a lot of work to get there.
Yeah.
Moving on to, yeah.
Um, one argument against an army. Suppose the country of Fredonia is debating
whether its neighbor, Sylvania, is responsible for a recent rash of meteor
strikes on its cities. The meteor struck cities close to the Sylvania border.
There was unusual activity in the Sylvania stock markets before the
strikes and the Sylvania ambassador, Trantino, was heard muttering about
heavenly vengeance. And then you encounter some arguments by pro-Sylvania
traders again and again and again. But each time the new argument sandally
defeated three to one.
Can I really quickly interject?
Yes.
I cut out a part in the middle where it said that a pro-Sylvania trader, in quotes,
approaches you and says, but look, it doesn't make any sense for the, for the
common strikes to be the work of Sylvania because of this. And I don't know,
they point out something from astronomy, right? Like meteors are very, very hard
for humans to direct. It would be basically impossible. And you go, yeah,
but they all hit cities close to the border. And there was unusual activity in
the stock market beforehand. And the ambassador did talk about heavenly
justice just before this happened. So, you know, I got my three points of
evidence against your one that like, we think humans don't know how to do this
yet, but maybe they do. So I'm going to stick with my argument here.
Because, you know, it just seems there's more, but there's more weight to this
side. Yeah, three to one.
Yeah, exactly.
Yeah. By rehearsing the arguments you already knew, you're double counting
your evidence.
Yeah. And then people keep coming to you with another argument. And each time
you're like, yeah, but I got these three against your one. And then someone
comes with another one. And it says, and on every occasion, you feel yourself
becoming more confident that Sylvania wasn't irresponsible, shifting your
prior according to the felt balance of evidence.
Because it's three to one every time. Yeah. But by the end of the week, it's
30 to 30 to three. But you're not thinking of it that way. Because you're
not keeping score. This reminds me of a similar post where it was like a
religious like a intelligent design argument or something. And like every
time they'd be confronted with a new piece of anti information, they'd give
back the intelligent design, you know, spiel. And they'd be like, hi, I need to
feed another and another and another was, I think it was just a similar point
about like cognitive stop signs or something. But it's the same sort of
failure. Yeah. Yeah. And he ties this back right into the previous post, which
is why we grouped them together, saying that the balance may the balance of
evidence may still support your cherished belief. But you still have to shift
the probability down. Yes, down from whatever it was before you heard the
contrary evidence does no good to just rehearse the supporting arguments
because you have already taken those into account. So if someone does make a
contrary point, even if you think it's a not a good point and your points are,
you know, better and outweigh it, you still should as adjust down just a
little bit. So that if you keep getting all these little arguments over time,
they can build up to, you know, bring you to where a 30 to three should be.
Yeah, this reminds me of the argument says soldiers, which I think we
covered earlier too. This is the kind of mindset where you're not thinking
about how to debate like factual, factual facts correctly, you're thinking
about, I've got these three magic items and every time someone comes at me
with a new magic item, I'm going to use these three and they keep, they keep
working. So I'm just going to keep using them. Ha ha, I've got my three magic,
but like it's, you know, you're not trying to win a fight. That's that
shouldn't be the point of what you're doing. Like, if you're actually trying
to find out the truth, then that is just a very wrong way to think about how
to do it. So speaking of wrong ways to think about how to do this, if I'm in
dialogue with a moon landing denier, they will have, if they're, if they make
a living out of it, like some people do, they'll have 4,000 arguments about why
the moon landing was fake. And I've got like three about why it was real. So
like for every one that I hear, I've got to update down a little bit in my
confidence that the moon landing happened. I mean, depending. First of all, if
it's an argument with some validity, then yes, you probably should update down
a little bit. Just how little that little bit is might be very little if it's
really weak. But there's also some arguments that you can dismiss by
actually looking at the argument. Yeah, like looking at this and being like,
no, this, this argument counts for zero because it's so bad because of, you
know, reason X, Y or Z. I think this is more like you cannot use the arguments
you already know to be like, ah, I see, maybe you have a point there, but I
have all this other evidence on the other side. So I'm going to ignore that
point if it is a somewhat valid point to take into consideration.
This is a particular analogy that's trying to get at the heart of why this
kind of why this style of trying to argue is not actually useful for getting
towards the truth of something. But just because they're talking about the
numerical error that some people make that like there's also the point, the
point that this is like physically impossible for people to have done
argument should actually win. Like it doesn't matter whether it's one to three
arguments, like, oh, but it looks suspicious versus this is physically
impossible to have. Like obviously that argument's going to defeat any other
like, but this is weird and isn't that weird. But you're like, this is still
physically impossible. You could just keep using that argument because
Or if that moon landing denier has like extremely good evidence, one single
piece of evidence could overrule everything else. You can be like, oh,
shit, you're right. You know, even if it's just one argument, if it's that good
of an argument. Yeah, this is much more valuable from the perspective of a
moon landing denier with bad arguments where they're like, well, the flag
looks like it moves for a minute. And like, if they just had that to every
counter piece, every every piece of information about why I think the moon
