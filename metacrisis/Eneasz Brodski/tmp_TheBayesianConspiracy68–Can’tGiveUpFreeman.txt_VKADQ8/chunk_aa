Welcome to the Bayesian Conspiracy, I'm Meneesh Brotsky, and I'm Stephen Zuber.
And today we are just chatting amongst ourselves as we sometimes like to do.
That's right, and since we have a hard time keeping on subject, we decided to pick two
or three or four rationality-related topics or articles to discuss throughout the episode.
And I'm running with the theme of taking notes, so do you have anywhere you want to start?
Let's start with yours.
Cool.
So my first pick was an article by Matt Freeman, aka Morgana Mail, aka Matt Freeman of the We've
Got Ward and Doof podcasts.
We had him on our last episode, and this is actually a direct follow-up to the conversation
we had last time.
I think the next day, or maybe that night, he went home and wrote a dialogue on rational
activism on Less Wrong, which we will link to on the episode notes.
And it's just a really wonderful and short distillation of the argument that Matt made
on our last episode about rationalists needing to overcome their fear of being the least
bit culty if they actually wanted to get the sanity waterline to go up.
And it's done in this fun dialogue form where you are visited by an alien, and they hand
you this tome of saying, hey, here's the tools you need to join the galactic civilization.
This will be on your way to figuring out the faster-than-light travel, everything.
You're going to achieve all of your goals better.
You just need to get through this.
And the person's reading this or skimming through this 3,000-page book, and like this
looks kind of like a really dense textbook.
You know, this would be a lot better if it was a sequence, a short post, and he links
to the sequences.
And the exchange is basically, you're mainly voicing the objections that Matt anticipated
and talked about during our episode, where it's like, well, you know, humans are really
resistant to joining like movements, and the kind of people who would even be interested
in this sort of thing are the kind of people who have high memetic immune systems to kind
of evangelizing and seeming passionate about stuff.
This won't work.
And the human race is heard forever, you know, just read this one thing and you will be saved
or whatever.
Right.
Oh, I haven't heard that a thousand times before.
Right.
And so, you know, I forget what the book was called at first, but you know, he's like,
how about like a catch your title and the aliens like, oh, you mean like how to be less
stupid?
I was thinking more like how to be less wrong, but even that still sounds kind of condescending
or it was like how to be more rational or something.
The protagonist is arguing that, look, people are going to see that and be like, I'm already
rational enough.
Fuck you.
Rationality, that's for nerds.
What are you talking about?
We've been much more inclined to read something like, you know, 12 proven steps to be happier,
sexier, and wealthier.
Number six will shock you.
So there were a couple of cool quotes I wanted to pull out of it and then we can talk more
about some of the meat of it.
So this was after the point where the protagonist had said, okay, I, you know, I believe you,
I want to try and make this work out, but I still feel like this isn't really going
to sell.
And I'm even kind of resistant to it, even knowing that I just talked about how that
resistance, that resistance is irrational and automatic.
And the visitor says, can you not reflect on how you're automatic and therefore probably
not rational?
Suspicion is ultimately self-defeating and probably not even meritorious, since you
literally don't know what the book says this organization would look like.
Oh yeah, that's right.
The book, to get this to go out, they talk about this and they realize that organizing
would have to, would have to happen.
You can't just put this book on the shelves and get it out there.
It has to be marketed by a group.
All right.
So to continue, your world is full to bursting with powerful hierarchical organizations with
much flimsier justifications for existence than improving the quality of thinking and
therefore the epistemic accuracy of instrumental effectiveness of the species.
It's almost cowardly of you to insist that you can't possibly try to promote the one
thing you care about in the world, or you care most about in the world, which you honestly
believe could help save your world, while all around you thrive countless powerful
political blocks promoting intellectual snake oil.
So they go on to say, and if you aren't capable of making that choice of committing
to actually try and allowing your deep conflict over the endeavor to make you productively
paranoid and engender the necessary level of constant vigilance, then you get the bad
ending, which is to say you get more of the same.
And it's fun.
In that part of the post, he links to the sentence, you get more of the same.
He links to the wiki pages for like the Holocaust, wars, the Crusades, famine, or just like general
bad shit, but it was great, just big high level stuff.
It's like you get all the stuff that sucks that you've had this whole time.
Rationality doesn't become something that the world cares about unless the people who
do care about it care enough to actually convince the world that they should.
And I really like that quote.
So I don't know, thoughts, feelings, responses?
I agree.
I still, I mean, I agree that rationality is a wonderful thing that would make the human
race better.
If more people embraced it, I still don't know how to go about promoting it, though.
I mean, I was raised in an evangelical religion and they just don't work all that great.
So, but have you actually thought about it after saying I'm going to set aside my trepidation
about evangelizing and stuff?
About how to evangelize it?
Yeah.
I mean, the closest I can think to do is doing like what the street of cosmology people do.
That sounds like actually a pretty nifty approach.
And that's just engaging with people one-on-one in a nice way.
Yeah.
In a personable manner and not having anything to sell necessarily, just getting people to
think about things and question their own assumptions.
I like that too.
The problem with that, and I think Matt would agree, is like that's only going to work with
the kind of people who care about what the word street of epistemology means, right?
Well, I mean, they don't, you don't even say the word street of epistemology to them.
That's true.
But I think it's always been my opinion that if you engender enough of a love of truth
into people, then they will eventually make their way to the scientific method and possibly
to rationality as well.
Because everyone I knew that D converted out of Christianity, most of almost all of them,
well, everyone I knew anyway, had just this desire to know what's actually true about
the world.
And that was eventually where it led them.
And so I've always been of the opinion, you don't have to evangelize atheism, you just
have to get people to love the truth enough that they want to know what's actually true.
I think that helps, and I'm going to keep playing devil's advocate just because I feel
like that's not enough.
Because not enough people have that as a priority, right?
Oh, yeah.
That well.
So you're right.
It's not going to appeal to everybody.
And I think for this to work, it doesn't have to appeal to 100% of people, but it has
to appeal to more than 5% of people.
I think if you're trying to promote people a love of knowing the truth, then that has
lots of other good knock-on effects as well.
And I would rather have that and get the, what is it called, the side effects of having
more people?
Yeah, and the externality of having more people get into rationality as well.
Because I think that is something that you can promote and that even everyone else who
looks at you, if they see you specifically promoting rationality, they're like, well,
you're just another memeplex trying to propagate yourself.
But everyone can get behind trying to teach people a love and respect for the truth, right?
I mean, almost.
Pretty much everyone.
Just 50% of people, maybe, 30, 10, that sounds optimistic.
In theory, I think most people would at least not give you shit for that.
There's some people that are like, well, all truth is subjective.
So really what you're trying to do is sell your own worldview.
But most people you can get to go along with, the truth is good.
And I mean, rationality and misconception is bad.
Yeah.
I mean, I think a lot of people don't care.
Like I don't think they, they might not ask themselves in a real way.
Not that they never do, but they never commit to thinking this way about like what they
think the truth is in a meta sense, right?
So they just think about, I've got this beliefs that I don't even feel like are beliefs.
I've got these facts in my head.
Yeah.
Well, that's the really hard part.
You got to like make them like both love the truth and have some doubt and have some
doubt that they already have the answers.
Like I've been surprised, honestly, interacting more with the non-rational world lately.
Just how many people have these crazy beliefs?
I met another person just recently who was like, yeah, I got psychic powers, man.
And I asked for a project when I sleep.
I'm like, I don't even really need this body, but I do kind of like this body.
So I'm sticking with it.
I'm like, that's, that's great.
This person reads like science articles now and then, but always reinterprets them the
light of their psychic worldview.
And like this, how do you get by?
Like that.
That's so weird.
I don't know.
It apparently has very little effect on your actual living.
Yeah.
Right.
Because they don't ask to projects like dodge a car accident or something.
Right.
Yeah.
So I don't know how to make, because someone like that already thinks that they have a
respect for the truth.
They just think they have it, right?
I think they think, I think they say they have one, like, because I mean, my favorite,
I've known people who would say things like that.
And I'd be like, Oh, have you heard of James Randi's million dollar challenge?
Right.
You know, if you can do this, dude, go get the million dollars.
It'll be famous.
You get a million fucking dollars.
That's, it's actually a pretty good one, but I don't want to like.
It sounds adversarial.
Yeah, it does.
But I do it and I try to do it in a friendly way of like, you know, can I get a 10% finders
fee?
Okay.
Like this is awesome.
Yeah.
You know, I guess asking for a demonstration might even seem adversarial, but then they
say like, well, I can't right now because I, the music's too loud or, you know, it's
like, no, come on, like, let's, what conditions do you need to make this happen?
The more you pin it down, the more they'll make excuses.
You know, they've got their dragon in the garage, like the Carl Sagan metaphor.
Right.
They think they can do that.
They think that they think they can do that maybe.
I don't know.
Yeah.
Like at some point you got to make people want to have a firm foundation of their belief.
