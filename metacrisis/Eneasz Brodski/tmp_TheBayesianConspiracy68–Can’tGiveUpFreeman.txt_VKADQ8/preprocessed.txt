Welcome to the Bayesian Conspiracy, I'm Meneesh Brotsky, and I'm Stephen Zuber.
And today we are just chatting amongst ourselves as we sometimes like to do.
That's right, and since we have a hard time keeping on subject, we decided to pick two
or three or four rationality-related topics or articles to discuss throughout the episode.
And I'm running with the theme of taking notes, so do you have anywhere you want to start?
Let's start with yours.
Cool.
So my first pick was an article by Matt Freeman, aka Morgana Mail, aka Matt Freeman of the We've
Got Ward and Doof podcasts.
We had him on our last episode, and this is actually a direct follow-up to the conversation
we had last time.
I think the next day, or maybe that night, he went home and wrote a dialogue on rational
activism on Less Wrong, which we will link to on the episode notes.
And it's just a really wonderful and short distillation of the argument that Matt made
on our last episode about rationalists needing to overcome their fear of being the least
bit culty if they actually wanted to get the sanity waterline to go up.
And it's done in this fun dialogue form where you are visited by an alien, and they hand
you this tome of saying, hey, here's the tools you need to join the galactic civilization.
This will be on your way to figuring out the faster-than-light travel, everything.
You're going to achieve all of your goals better.
You just need to get through this.
And the person's reading this or skimming through this 3,000-page book, and like this
looks kind of like a really dense textbook.
You know, this would be a lot better if it was a sequence, a short post, and he links
to the sequences.
And the exchange is basically, you're mainly voicing the objections that Matt anticipated
and talked about during our episode, where it's like, well, you know, humans are really
resistant to joining like movements, and the kind of people who would even be interested
in this sort of thing are the kind of people who have high memetic immune systems to kind
of evangelizing and seeming passionate about stuff.
This won't work.
And the human race is heard forever, you know, just read this one thing and you will be saved
or whatever.
Right.
Oh, I haven't heard that a thousand times before.
Right.
And so, you know, I forget what the book was called at first, but you know, he's like,
how about like a catch your title and the aliens like, oh, you mean like how to be less
stupid?
I was thinking more like how to be less wrong, but even that still sounds kind of condescending
or it was like how to be more rational or something.
The protagonist is arguing that, look, people are going to see that and be like, I'm already
rational enough.
Fuck you.
Rationality, that's for nerds.
What are you talking about?
We've been much more inclined to read something like, you know, 12 proven steps to be happier,
sexier, and wealthier.
Number six will shock you.
So there were a couple of cool quotes I wanted to pull out of it and then we can talk more
about some of the meat of it.
So this was after the point where the protagonist had said, okay, I, you know, I believe you,
I want to try and make this work out, but I still feel like this isn't really going
to sell.
And I'm even kind of resistant to it, even knowing that I just talked about how that
resistance, that resistance is irrational and automatic.
And the visitor says, can you not reflect on how you're automatic and therefore probably
not rational?
Suspicion is ultimately self-defeating and probably not even meritorious, since you
literally don't know what the book says this organization would look like.
Oh yeah, that's right.
The book, to get this to go out, they talk about this and they realize that organizing
would have to, would have to happen.
You can't just put this book on the shelves and get it out there.
It has to be marketed by a group.
All right.
So to continue, your world is full to bursting with powerful hierarchical organizations with
much flimsier justifications for existence than improving the quality of thinking and
therefore the epistemic accuracy of instrumental effectiveness of the species.
It's almost cowardly of you to insist that you can't possibly try to promote the one
thing you care about in the world, or you care most about in the world, which you honestly
believe could help save your world, while all around you thrive countless powerful
political blocks promoting intellectual snake oil.
So they go on to say, and if you aren't capable of making that choice of committing
to actually try and allowing your deep conflict over the endeavor to make you productively
paranoid and engender the necessary level of constant vigilance, then you get the bad
ending, which is to say you get more of the same.
And it's fun.
In that part of the post, he links to the sentence, you get more of the same.
He links to the wiki pages for like the Holocaust, wars, the Crusades, famine, or just like general
bad shit, but it was great, just big high level stuff.
It's like you get all the stuff that sucks that you've had this whole time.
Rationality doesn't become something that the world cares about unless the people who
do care about it care enough to actually convince the world that they should.
And I really like that quote.
So I don't know, thoughts, feelings, responses?
I agree.
I still, I mean, I agree that rationality is a wonderful thing that would make the human
race better.
If more people embraced it, I still don't know how to go about promoting it, though.
I mean, I was raised in an evangelical religion and they just don't work all that great.
So, but have you actually thought about it after saying I'm going to set aside my trepidation
about evangelizing and stuff?
About how to evangelize it?
Yeah.
I mean, the closest I can think to do is doing like what the street of cosmology people do.
That sounds like actually a pretty nifty approach.
And that's just engaging with people one-on-one in a nice way.
Yeah.
In a personable manner and not having anything to sell necessarily, just getting people to
think about things and question their own assumptions.
I like that too.
The problem with that, and I think Matt would agree, is like that's only going to work with
the kind of people who care about what the word street of epistemology means, right?
Well, I mean, they don't, you don't even say the word street of epistemology to them.
That's true.
But I think it's always been my opinion that if you engender enough of a love of truth
into people, then they will eventually make their way to the scientific method and possibly
to rationality as well.
Because everyone I knew that D converted out of Christianity, most of almost all of them,
well, everyone I knew anyway, had just this desire to know what's actually true about
the world.
And that was eventually where it led them.
And so I've always been of the opinion, you don't have to evangelize atheism, you just
have to get people to love the truth enough that they want to know what's actually true.
I think that helps, and I'm going to keep playing devil's advocate just because I feel
like that's not enough.
Because not enough people have that as a priority, right?
Oh, yeah.
That well.
So you're right.
It's not going to appeal to everybody.
And I think for this to work, it doesn't have to appeal to 100% of people, but it has
to appeal to more than 5% of people.
I think if you're trying to promote people a love of knowing the truth, then that has
lots of other good knock-on effects as well.
And I would rather have that and get the, what is it called, the side effects of having
more people?
Yeah, and the externality of having more people get into rationality as well.
Because I think that is something that you can promote and that even everyone else who
looks at you, if they see you specifically promoting rationality, they're like, well,
you're just another memeplex trying to propagate yourself.
But everyone can get behind trying to teach people a love and respect for the truth, right?
I mean, almost.
Pretty much everyone.
Just 50% of people, maybe, 30, 10, that sounds optimistic.
In theory, I think most people would at least not give you shit for that.
There's some people that are like, well, all truth is subjective.
So really what you're trying to do is sell your own worldview.
But most people you can get to go along with, the truth is good.
And I mean, rationality and misconception is bad.
Yeah.
I mean, I think a lot of people don't care.
Like I don't think they, they might not ask themselves in a real way.
Not that they never do, but they never commit to thinking this way about like what they
think the truth is in a meta sense, right?
So they just think about, I've got this beliefs that I don't even feel like are beliefs.
I've got these facts in my head.
Yeah.
Well, that's the really hard part.
You got to like make them like both love the truth and have some doubt and have some
doubt that they already have the answers.
Like I've been surprised, honestly, interacting more with the non-rational world lately.
Just how many people have these crazy beliefs?
I met another person just recently who was like, yeah, I got psychic powers, man.
And I asked for a project when I sleep.
I'm like, I don't even really need this body, but I do kind of like this body.
So I'm sticking with it.
I'm like, that's, that's great.
This person reads like science articles now and then, but always reinterprets them the
light of their psychic worldview.
And like this, how do you get by?
Like that.
That's so weird.
I don't know.
It apparently has very little effect on your actual living.
Yeah.
Right.
Because they don't ask to projects like dodge a car accident or something.
Right.
Yeah.
So I don't know how to make, because someone like that already thinks that they have a
respect for the truth.
They just think they have it, right?
I think they think, I think they say they have one, like, because I mean, my favorite,
I've known people who would say things like that.
And I'd be like, Oh, have you heard of James Randi's million dollar challenge?
Right.
You know, if you can do this, dude, go get the million dollars.
It'll be famous.
You get a million fucking dollars.
That's, it's actually a pretty good one, but I don't want to like.
It sounds adversarial.
Yeah, it does.
But I do it and I try to do it in a friendly way of like, you know, can I get a 10% finders
fee?
Okay.
Like this is awesome.
Yeah.
You know, I guess asking for a demonstration might even seem adversarial, but then they
say like, well, I can't right now because I, the music's too loud or, you know, it's
like, no, come on, like, let's, what conditions do you need to make this happen?
The more you pin it down, the more they'll make excuses.
You know, they've got their dragon in the garage, like the Carl Sagan metaphor.
Right.
They think they can do that.
They think that they think they can do that maybe.
I don't know.
Yeah.
Like at some point you got to make people want to have a firm foundation of their belief.
I guess one of the nice parts about God, I hate saying this, one of the nice parts
about growing up evangelical is that you, if you were spreading this thing out, you
have to defend your beliefs a lot to people.
And so you want them to be as firm as possible.
And that's one of the things that drove me anyway, to make sure that I did have these
things figured out.
And I could explain things and meet challengers when they were like saying, but evolution
is true because of this.
And I'd be like, no, have you seen this thing?
And that's one of the things that eventually led me to be like, oh, wait a minute.
And you would have said back then that seeking the truth was a really important goal to you.
It was.
I mean, was it?
Yeah.
Well, eventually I kept seeking the truth until I got to it.
Well, so I think you cared about the truth, but you didn't know how to find it.
And so when you found that there was an actual recipe to get things right, you were eager
to find that and you were stoked if I'm reading this correctly.
Well, the thing is I had heard about science before, you know, it's not like I didn't
know that scientists exist, but I guess as the average person, you don't really think
of the scientific method all that much and certainly not as something that's applicable
to yourself in your day to day life.
Or that you can do, you know, really without tools for the most part, just with just with
testing something.
Yeah.
Just test your own beliefs.
Yeah.
I think some people have that spark if they want to know stuff, right?
And so you can find those people, you can engage with them street epistemology style
or you can.
And I think David mentioned this on the podcast I did with him months ago.
And I think this came up with Matt too.
If there was a community of badasses, you know, who were just crushing it at life and
what did they all have in common?
Oh, they all, you know, are part of the church of rationality or whatever it ends up being
called.
Yeah.
They're all rationalists.
You know, I remember this was impactful when I was first getting into the rationality community.
I forget what podcast this was on.
It was one of the few that Eli Zou's been on.
It might have been pale blue dot.
I think he's in one of the last episodes of that podcast.
He was asked about why back then it was the Singularity Institute was doing what it was
doing.
You know, why, why aren't you guys doing something else?
And he said, there's got to be one project that is the most important thing humans can
be working on right now that we need to get right.
And we had the Singularity Institute, we're rationalists over here.
We think we found it.
That's why we're doing this.
And that, and it sounds, you know, preachy, but when he said, we're rationalists, this
is, this is it.
I was like, oh, that's, that's, that's awesome.
Yeah.
You guys figured, you know,
I love that about him.
Yeah.
He never tries to, to weasel away or anything.
He just leans right in.
And he does it in a way that I didn't find off putting it all.
No.
And so if anything, I found it dangerously entrancing.
So I've seen him on a number of, of those podcasts or talking head things where with
almost everyone else, they would be given some sort of challenge.
I'd be like, oh God, here comes the back pedaling.
And he'd just be like, no, I own it.
You know, there's, I'm, I ain't ashamed.
And I think that's also another big part of it.
Like as, as Jehovah's Witnesses, we were often told to stand up and be proud and be
like, I am a Jehovah's Witness and I am a witness unto the Lord with my actions.
You know, and if people are always like embarrassed and ashamed to say they're
rationalists, then that's going to come through.
You know, if you're willing to say, yeah, I'm a rationalist and here's, here's my
life, then that makes a big difference.
Like I don't know how many rationalists there are out there, but I'm pretty sure
there's some that just aren't willing to say it out loud.
I think it's probably a lot of them just because, you know, it's part, the exact
problem we've been identifying here, that it's awkward to identify as part of a
group, because that's something that every, every other dime a dozen weird group does.
I don't think even aspiring rationalist is a great term.
Like just rationalist.
I, I like aspiring rationalist for the, what it conveyed as like martial artist,
you know, like I'm getting better, you know, like I'm a rationalist.
I'm a black belt, right?
Okay.
Yeah.
But I realized that's not the connotation that it's now commonly used, but that's
the way that I always thought about it.
So I can, I'm happy to move away from that.
In fact, aspiring rationalist almost sounds more culty, right?
I haven't gotten all the, the degrees yet or something, right?
I don't know.
Right, right, right.
I'm only level, what?
Level one.
I haven't gone clear yet.
Right.
Still got some fatins in me.
I still need a few more thousand dollars.
Yeah.
So I think the approach like that, um, and this is what, like I said, we talked
about before is more of like a ground up approach, you know, grassroots, get groups
of cool people, you know, that eventually draw enough attention or somehow evangelize
enough, whether it's through, and we could talk about the different mediums to push
this out.
In fact, I've seen, you know, attempts to do this with like TV with, you know,
skeptics and stuff too.
Um, but it's hard to sell.
Um, but the other approach, and this is what something someone, um, uh,
quantical on the less, a commenter on that less wrong post, uh, pointed out the
other approach that I thought of too, but unfortunately they also thought of it
and wrote it down first.
Um, which was fortunately, cause it saved you the trouble of having to type it
up.
Well, that's true.
And they probably put it better than I did.
They, they top down, you know, rather than bottom up, have people at the top,
you know, they named, you know, like Jeff Bezos, Bill Gates or something.
If they said, Hey, you know, rationality, that's where it's at paraphrasing.
What I put after that was, uh, yeah, get famous badasses to start touting how
awesome rationality is and how it was a central role in their success.
So the closest I can think of was like when Sam Harris was introducing LAIs,
LAIs are on his podcast.
He said he'd read and enjoyed the sequences.
Um, that was like the most famous person I've ever heard say, other than, you
know, other rationalists say that they've read these and enjoyed it.
Nice.
Um, so I don't know how many people he got to dive into them.
I don't know if they're even linked to on the episode notes, cause no one
looks at those.
Um, actually I sometimes do, but I never do.
If someone mentioned something that I thought was interesting, I checked and
see if it was in there.
Okay.
Um, right now, unless there's people out there that are like that and haven't
come out of the closet yet, then this group of rationalists, this generation of
rationalists needs to grow up, be badass and then say like, this is why.
Um, you can be as badass as I am.
You need to do this.
Yeah.
And that was, again, this language didn't turn me off at all, but I can see how
it would in methods of rationality back when it was just on fanfiction.net and
the, you know, it still is there too.
Yeah.
But when I was reading it on there before it was on somewhere else, it was like,
if you want to know everything Harry knows and more, go to less wrong.com.
Yeah.
And I read, you know, I'm reading from Harry's perspective and he's a fucking
badass and like, I want to know everything Harry knows and more.
Yeah.
Um, so that was a fictional example of this, right?
So, you know, doing it in fiction is one way to get people interested.
I think, you know, doing it textbook style will attract a very small and lower
people doing it sequence style, um, attracts more with, it's more engaging.
Everything's in a nicely separated and coherent order that for the most part
is digestible and written in an engaging way, you know, with, with fun
hypotheticals, anecdotes and little bits of this and that.
You know, a segment that we should have on this show every week, we should
like read one or two of the sequences ourselves and then just comment a little
bit about them at the end of the episode.
I can dig it.
All right.
Not every week, but every episode, I guess one sequence per week since we do
these every other week.
Wait, a sequence per not a sequence, but a post.
Okay.
Yeah, it's going to say I, I'm a slow reader.
Yeah, but one post per week we could do.
Yeah.
I mean, I've got a dozen favorites.
I could go back and, you know, just, just so I'm not from the start.
Go through the whole thing.
Oh, okay.
Yeah.
Yeah.
Like an old school Bible study.
I mean, that sounds worth a try.
No, I'm serious.
Awesome.
Um, yeah, I'm totally down for that.
So the other avenues to get it, get it popularized.
I really, we can sit here and think of some, but the point is, is that I think
the, the meta point to make is that people are afraid to do that.
That, you know, it sounds like it's, it's too close to something that
unfavorable groups do.
It's got bad associations.
And I think Matt's point, and I think I'm sold.
It's like, dude, just own that.
Like whatever.
Yes.
It's got bad associations, but so does literally every successful cool group too.
Right.
Probably.
Yeah.
I mean, I'm trying to think of examples, but you know, if it's a great tech company,
you know, the employees, their tech pros, well, they're tech pros and they do tech
bro-y things, but they'll also say, man, we here at Apple, we love working
here.
Maybe they don't say that at Apple, but, you know, at Amazon, they do say, we get
paid a fuck ton here and that's, that's their marketing point, right?
Granted, it sucks to work there for the most part, but, you know, if you want to
make a baller amount of money and never have to look for another job, because the
second you just change your LinkedIn profile to looking for a job, you'll be
getting inundated at emails.
You know, that's the kind of thing that it's, I don't know, putting it on your,
your life resume rather than your professional resume.
So I don't know.
I, I feel like this is the kind of thing that maybe we could do some more arguing
about whether or not this is a worthwhile endeavor, but I'm sold that it is.
So I feel like if anyone agrees, spend five minutes thinking about what are some
ways to actually get this out there.
You know, maybe it's even just like, talk to your friends, share a blog, share a
post to the friend, whether it's, it doesn't have to be any of the Canon less
wrong stuff.
If you don't want it to be, it could be an adjacent article.
It could be a rationally speaking podcast.
It could be the Bayesian conspiracy.
It could be a Slate Star codex.
I don't know.
I think preferably not this episode where we talk about that.
Yeah.
This might be a hard, too, too steep of a jump, but honestly, I'm going to
share the, um, Matt's essay with a bunch of people or at least a few.
I'll have to come out slowly.
Like people who aren't rationalists even.
Yeah.
Oh, okay.
I want to know, I want to know what reaction you get when you share that then.
So I have that, uh, I don't know if I can get them to read it.
And honestly, I mentioned, uh, actually Matt was here.
I have that smart co-worker who, you know, had heard about Roco's
bassist, bassist and was like, Oh yeah, I've heard of that lesser on community.
I'm interested to get his reaction, but honestly, he's so much smarter than me.
He would be very, you know, he's not mean, but he would make a very, I anticipate
a very compelling counterpoint and, uh, I would be intellectually defeated.
But I think that might be a fun endeavor anyway.
So why not?
I'll share it with him too.
If he has an eight minute time to read this.
So yeah.
All right.
I'm ready to move past that one if you want to.
Okay.
Uh, yes.
What was our next thing?
Uh, yes.
The, our ethical asymmetries from property rights, uh, which sounds like a hard,
that almost sounds like a typo in that.
I know what it's saying, but that sounds like a hard way to phrase that point.
So I, I like it.
It doesn't sound like a complete sentence to me from property rights.
I guess I'm just dumb.
That's really just me.
That's, oh, I see.
Okay.
It is, it is kind of like pointing in the direction of just a concept.
I actually don't know what it is tripping with about it.
It just doesn't sound like a complete sentence.
That's not a point about the article.
It's great.
I just dumb.
That's all I'm pointing at.
So, all right.
No, I guess it could have been, it gets right to the point, which I like our
ethical asymmetries, consequences of property rights are derived from or parallel
to, or due to property rights instincts or something.
Are they from property rights?
I, you mean like a place?
Again, it's my, I get what you're saying.
It's my hang up.
No one else's.
That's fine.
Yeah.
And this is not being such a nitpicking jerk.
It's just me being too thick.
Like I read it like three times and like, am I?
Dislexically reading that headline.
Anyway, this is from Katja Grace also on less wrong.
Heck yeah.
And Katja and I've Katja.
I don't know how to say it.
Okay.
Actually, I think it is Katja.
Oh yeah.
And she did like four or five podcasts with Robin Hansen like eight years ago.
Okay.
Way back in the day, I can't remember, I couldn't even find them.
I remember they come up way back on iTunes and I'd search for Robin Hansen.
And they were actually really hard to listen to because they recorded them
outside with a microphone and you could hear like people walking by and birds and
stuff and they sounded far away from the mic.
You could hear the wind, but they were fun.
Oh dude, did you hear the episode of Skeptics Guy to the Universe that they
recorded at DragonCon?
No, that sounds like a drag.
Their microphones broke.
And so the recording is from like, I don't know, someone in the audience
with a with a phone.
Yeah, it's I could not listen to it.
After about a minute, I was like, nope, can't understand anything.
This is horrible.
Yeah, sorry guys.
Oh, okay.
So the article are ethical asymmetries from property rights starts out pointing
out some ethical intuitions that people often have, such as that you're not
required to save a person, but you're definitely not allowed to kill them.
You're not required to create a person, but you're definitely not allowed to kill
one.
You're not required to create a happy person, but you're definitely not
allowed to create a miserable one.
You're not required to help a random person who will be in a bad situation,
but you definitely are not allowed to put someone in a bad situation.
Actually dire.
I don't know why I rephrased that to bad.
Okay.
You're not required to save a person in front of a runaway train because we always
have to come back to the trolley problem, but you're definitely not allowed to push
someone in front of a train.
By extension, you are not required to save five people in front of a runaway train.
But if you have to push someone in front of a train to do it, then you're
definitely not allowed.
Here's some other ethical intuitions.
You're not required to give me your bread, but you're not allowed to take mine.
You're not required to lend me your car, but you're not allowed to unilaterally
borrow mine.
You're not required to send me money, but you're not allowed to take mine.
Catcher points out that the former are ethical intuitions and the latter are
implications of a system of property rights.
But they look very familiar, right?
It almost seems like the former ones are just ethical intuitions, applying
property rights to people and welfare.
That your life is property and I'm not allowed to take your property, but I'm
not obliged to give it to you if you don't have it by default.
Your welfare is the same way.
I'm not allowed to lessen what you have, but I don't have to give you more.
Which is when it comes down to things like, why aren't people, why don't people
feel like they're obligated to give away all their money to people on the other
side of the world who have a lot less?
It's because we're not utilitarians at heart, right?
Yeah.
And the parallels between those things are stark as hell, right?
You can basically just sub out letters and like that's what she does.
The sentences are the same and they feel just as intuitive.
And like the Charlie Problem stuff, people have done those large surveys and
those all pan out to be true with how people actually feel.
So it's not just us odd people who feel that way about these.
God just says that further evidence that these intuitive asymmetries are based
on upholding property rights, we have moral feeling intuitions that are just
straightforward property rights.
Like stealing is wrong.
A wonderful one that I've always liked and that I've argued is that people
often say that if someone is worse than average, like for example, someone
that's got an IQ of 80, it'd be good to have a medical intervention that raises
them up to IQ 100.
Or if someone is in very poor health, it'd be good to have medical
and for intervention that raises them up to normal health.
But if someone is already at IQ 100, the average, not only is there no
ethical obligation to raise them to 120, it's sometimes even considered a bad
thing, right?
If someone is already in good health, there's no obligation to get them to
an even better level of health where they can do lots of things and have tons
of energy and be very capable all the time.
And these are the sorts of asymmetries that you talk about.
Eleazar wrote in one of his most famous essays that if more intellect is good,
when you're 80, there's no point where it stops being good to have more
intellect.
When you're IQ 80, it's good to go up to 100.
When you're IQ 100, it's good to go up to 120.
But that's not the way ethical intuitions seem to work out in the general public.
And I think a lot of it is due to the same kind of thing where people feel
if you have less than 100 IQ, something has been taken away from you.
And it's good to bring you back up to everyone else.
But there's no reason to give you even more that other people don't have.
So I totally agree.
And you're singing the beginning passages of the transhumanism songs, right?
Yeah.
Average, normal, whatever you want to call it.
Middle, middling is good, but there's no push to go beyond, to transcend
averageness.
That does strike me as distinct from the intuitions that she's making, though,
or the intuitions that she's marking out.
So because we don't feel the need to make other people average with regards
to really anything, right?
Right.
We walk, many of us walk past beggars every day and we don't feel compelled to
say, Hey, you know what?
I've got expendable income.
You clearly need some help.
You know, let me put you up for a night.
You know,
There is some social pressure to do that though, right?
Like there's a lot of people will cross the street when they see someone
begging because they don't want to feel that pressure to give them money.
Yeah.
I mean, just to be fair, people cross for other reasons too.
Like being asked is uncomfortable, but not like there's walking past them
silently.
It's also uncomfortable, but then being asked or being kind of hounded or
whatever is also super uncomfortable.
But yeah, the, but I guess the, the back to the, the actual property rights,
the whole ethical injunction to create many happy people does not exist.
Which is weird, right?
Because it seems to follow from many of our professed moral precepts, right?
That, Hey, you know, I mean, all of your caveats with what, uh, David
Parfit's repugnant conclusion aside, like a hundred happy people is good.
110 people should be more good.
We should be that much more good, goodness, however you want to measure it.
And yet we don't have that thing.
And yet we would say if they all fell down to 90, that's a drag.
We should get them back up to a hundred.
Or at the very least you're not allowed to reduce the number of happy people.
Right.
Yeah.
What was, what was the sentence he said about, um, cause I couldn't
paraphrase it faithfully.
It was, uh, your life is like your property or your, uh, what, how did she put it?
Ethical intuitions seem to be just property rights as applied to lives and welfare.
Your life is your property.
I'm not allowed to take it, but I'm not obliged to give it to you.
If you don't, by default, have it.
Your welfare is your property.
I'm not allowed to listen to what you have, but I don't have to give you more of it.
Yeah.
I like that.
Um, if you see a sick person, you're not ethically obliged to.
Put the rest of your life on hold and try to work to make them better.
And yeah, if you go to work sick, you're an asshole.
And certainly if you deliberately get somebody sick,
Oh my God, yeah.
your monster, if you like put tuberculosis in their cup or something.
Right.
Yeah.
Um, this is like the murder offsets question, right?
The, you remember the meat offsets, right?
Yes.
Okay.
Well, the murder offsets being the same kind of idea.
If I save three people's lives, can I kill two people?
I'm still not one life positive.
Our intuitions say no, right?
Yeah.
Um, and I think I guess I wanted to run at the spirit of this, of this post, like,
what should we conclude from this?
You know, our, does that mean that we should reexamine these, these moral
intuitions?
Do we just say that makes perfect sense that these we are intuitions?
Cause, you know, as apes, we care a lot about our stuff.
Well, I mean, we certainly do care about our stuff.
So the property rights and intuitions make sense.
Um, I don't know exactly when this happened sometime in the past decade,
maybe even longer ago than that, but I, I've, I'm of the opinion that ethics is
really a way, what did they, uh, what did Katja say here?
Um, property rights at least appear to be systems for people with diverse goals
to coordinate use of scarce resources, which is to say, somehow use the resources
with low levels of conflict and destruction.
In my opinion, ethics is basically the same thing.
Ethics is a way for people to be able to live with each other and do things
together with low amounts of conflict and destruction, which is why if you are a
single person alone on a deserted island, there's no such thing as ethics.
Right.
There's nothing that is morally good or nor morally bad that you could do on
that island because there's no other persons to interact with.
Unless you're a virtue ethicist or something weird, but even then I don't
think virtue ethics exists, but I think Plato would say you're living life
wrong or Aristotle would say you're living life wrong with your
pissed all the time or something.
Right.
You're not, you're not flourishing.
I will have to dig up a virtue ethicist for somewhere.
Well, I feel like I am a virtue ethicist, but I again, I wouldn't care.
You can have any virtues that you want once you're on a deserted island.
Okay.
So yeah, I think we're, I think this is just tangent, but the Greeks, I think
they use these ethics morality differently than we do.
Like to them, it wasn't just like this set of beliefs about like right and
wrong, it was about like living a good life in a well rounded sense.
They had certain virtues that they aspire to, but you know, the virtues are
determined by what works, right?
And on desert island, it doesn't really matter.
Well, I think what works to make life, to make society function or to make life
worth, make life good, even though it was just your life.
I think, I think you're right, it did actually do.
Yeah.
A lot of it was like, what is the good life?
Not just like, how do I interact with other people or how do I not go to
jail?
Yeah.
Um, but I think we're getting bogged down, uh, but the problem of how to, I
don't know, inject this is bringing to mind, uh, another thing I just heard, but
I don't want to get us off of the post just yet.
Um, but the very last very bad wizards podcast was on a very similar topic.
So yeah, well, I mean, Katja says that since, um, economic systems and
property rights, those systems don't have any specific goal, right?
Anything that is labeled as good.
It's just smooth sharing and resources and making things work together.
And when we think of ethics as, as utilitarians, we have a goal, right?
Maximize utility.
Uh, but I don't, I don't think ethics in general really has that goal.
And so utilitarianism is, it is, it is separate from ethics as it is normally
understood by people, I guess, because I don't think people are trying to
maximize utility.
Uh, it doesn't seem like that is the function of ethics in society.
And if we impose that goal on ethics, we may be misinterpreting what the
purpose of ethics is.
I feel like it's time to taboo ethics.
Okay.
You used it too many times in the sentence.
Oh, you're right.
Sorry.
Well, no, no, but I mean, I mean that not, not in a way just to, um, to be pedantic,
but also just because in a way, you're right.
Cause people are different.
I, I, it's hard to like argue people.
Oh yeah, that's ethics.
That's morality.
That's whatever it's like, no, I'm fine.
Let's just talk about making the world better.
Yeah.
Or making you a happier person or, you know, making, or making society happier.
And yes, happiness is whatever your intuition says, minus all your philosophical
objections to happiness.
Um, which was, uh, how Julia Gale of defined defines eudaimonia.
Um, which is the, what the flourishing that Aristotle talked about.
How does he define it again?
Uh, happiness, minus whatever your philosophical objections are to happiness.
Um, which I think, I think lands really well.
Um, it takes a philosopher to say happiness is a bad thing.
Or what do you mean by happy?
I mean, exactly what everyone thinks.
I mean, quit, quit being an ass.
Right.
Right.
So yeah, I think it depends on what kind of question you're answering there.
Right.
How do I be the best, best me I can be?
How do I, um, be the best me in society?
How do I make the best society that I can with or without me?
Yeah.
Um, I guess I just, I found what I'm saying is I think utilitarians are almost
sort of a good heart's law example, good heart's law being, I don't remember
the exact wording of it, but when the metric becomes the goal, it stops being a
good metric, uh, being like the purpose of school ostensibly is to educate the youth.
And we measure if we're doing a good job or if that or not by giving tests.
And once everyone realizes it, then the goal starts to become get students
better at tests.
Uh, and so we have lost the true purpose of educating students for this new
purpose of doing very good on the metric.
And it almost feels like utilitarianism is the same kind of thing where what we
want is human flourishing and happiness and people to work together.
And that is measured through utility.
And so utilitarianism now tries to maximize utility, even though the whole
point of making the flourishing happen is not necessarily maximizing utility, but
getting humans to live alongside each other in ways that are conducive to
cooperation and anti conducive to conflict.
Yeah, maybe.
I mean, at least that's my opinion of what most ethical systems, that what their
purpose is, I think you make a good point.
I think it does make sense to maybe compartmentalize utilitarianism as this
thing you do when you're sitting down with your checkbook every year, like,
where am I going to give my charity money to, um, you know, in your day to
day life, it's hard to think of, um, maybe in things that the average person
does every day, you know, what is the way I can maximize the goodness from what
I'm doing on this random little thing.
But you can be like courteousness and that things that cost you very little,
but are, you know, make a big deal to somebody else, um, or, you know,
make you both happy because you get your happy helping them, like giving up
your seat on the train or something.
Right.
And I think utilitarianism may be a very worthy goal.
It may be a great idea to try to maximize the amount of utility in the
universe.
I just don't think that's necessarily what systems of ideas of how we should
live together is for trying to taboo the word ethics here.
You did a good job.
Um, I think I'm not a moral philosopher, but I think some people, some moral
philosophers might just say, yeah, you're probably right.
Um, but I think the most eloquent utilitarians more talk about like, how
do we make the world suck less for the people who are having the hardest time?
Yeah.
Or for the things that are having the hardest time, you know, so like not
factory farming animals or not factory farming your meat rather, um, or, you
know, helping the bottom billion of the planet, you know, just not be sick and die
young, like that's the kind of thing.
You don't have to be a moral philosopher to say, yeah, we should do those things.
And so, you know, the utilitarian might say, okay, then let's try and find out
the best approaches and actually do those.
Whereas, um, lesser moral frameworks might just say, just do whatever makes you feel
good or something.
I don't know.
I'm straw manning on purpose.
But yeah, I think, um, I really like listening to like people like Peter
Singer and Will McCaskill talk about, um, what they're doing.
So I'm like, Hey, what do you do as what's an effective out to us to do and why?
Um, in fact, Will McCaskill was just on very bad wizards podcast too.
And, uh, I heard that one.
Yeah, it was fun.
And he's very eloquent.
I love hearing him talk.
And he does a really good job.
Um, was it on, he was on Sam Harris's podcast too in the last year.
So back before his podcast started sucking.
And I'm kidding.
But some of them are okay now.
Um, he's bouncing back, but, uh, I think effective altruism is probably one of
the greatest PR moves that rationality has.
That's a good point.
Yeah.
Cause rationality was a large part of the, the takeoff of effective altruism.
Probably definitely seen.
It wasn't all of it, but it was a large chunk of that initial getting it going.
Getting it, getting it popularized for sure.
Yeah.
Cause, cause rationalists saw it and like, yep, that's optimal.
Let's grab that and, and run with it.
Right.
Um, so like, I think I'm sure he wasn't the first, but you know, this, this got
popular, this was in what, New York times or the, another big journal.
I forget in 1975 was Peter singers, famine, affluence and morality essay.
Um, where he illustrated the whole, you know, walking past a kid drowning in a pond
thing, um, you know, well, I'm not going to go in cause my $50, my $50 shoes will
get ruined and you'd be, you'd be a complete monster.
And he's like, yeah, that's the situation we're all in now, except it's a kid
across the world and it's not even a $50 shoes.
It's your daily Starbucks or, you know, you're, you're, you're totally superfluous,
whatever, right?
So how do we put that in context of this essay?
Um, because most people would say, um, if you see a kid drowning in a pool, you
are obligated to go in and save it, even if it would ruin your suit, but that
conflicts with the, you are not obligated to give someone more life if it would
destroy your own property, right?
Hmm.
I think this may be a counter-argument.
Well, my first thought is that that's a lot of the like counterintuitiveness
pushback that singer got and that effective, effective altruism still gets.
And it's like, it's not my fucking job.
Right.
Um, so it's not your fucking job when it's someone across the world, right?
But if there was literally a child dying next to you, anyone who didn't sacrifice
their suit to save the child would be considered a monster.
I guess maybe like, you might feel more pressure to like, if your neighbor was
displaced due to a fire, you might say, Hey, spend the night at my house till you
get your back on your feet, but you're not going to like put up an ad to like
house refugees from across the world.
Yeah.
So I think that might just, I don't know if it contrasts with this essay or not,
but it might just be the same kind of psychological distance thing.
You know, that's them over there.
I can't see them.
And, you know, I can see my crying neighbor standing on the street watching
their house go up in flames.
I think that's, I think that's a decent pushback against this saying that, you
know, lots of times people use these systems of incentives, social incentives
to push back just past a property rights morality that property rights would say,
yeah, you're not required to save that child.
But since the loss of value of losing a child is so astronomical and the loss
of value in losing your shoes is so minor in comparison that if you are not
willing to lose your shoes to save somebody else's child, you will be very
harshly punished by the rest of society because that is just too much of a, um,
a defecting in one of those situations.
You defect when you don't save the child, you get more utility at the great
loss to the child's parents.
Whereas in a cooperative scenario, you lose your shoes, but the society as a
whole is a lot richer.
And so you get punished if you didn't cooperate there.
Yeah.
I think that requires some rewiring of our like other intuitions about how to
operate in society though, right?
Because we don't feel that way.
And it's weird.
Um, don't we?
Not really.
Like, I mean, I remember seeing someone dying.
You, you definitely feel that, but, but, but we don't feel that way with
people across the world.
No, no, well, because the purpose of the systems of social punishment and
reward is to make it so that you can coordinate with the people you actually
interact with, right?
Yes.
And no, I mean, I remember seeing numbers about like how many billions came
in donations, like the 3000 families affected by the 2000 or the 2001 September
11th attacks.
Oh yeah.
And that was, you know, billions came in from other citizens of the United
States going over to new, you know, families to people who worked in New York.
Yeah.
Um, I think I sent 10 bucks.
Sounds like a sixth grade.
Um, but that's because we all felt like family at that moment, right?
Yeah.
And so, but these aren't people we'll ever see or interact with.
And yet they're part of our tribe.
Yeah.
And so maybe that's the thing.
So our tribe doesn't have to be people we see every day or ever, but it has to
people that we feel identified with.
Right.
And that's why I meant that we'd have to recalibrate our moral intuitions to just
feel that way about everybody.
That is interesting though.
Cause yeah, I mean, when Florence is unraveling, it's, it's hurricane business.
I'm sure there'll be, you know, outpouring some money from people from citizens
of the United States to help them out.
Like there is every good hurricane.
And yet, or if anyone has numbers to the contrary, I'm happy to see them.
But I bet it's far less than like every other major crisis that hits the rest of
the world.
You know, we just don't care when a million people are displaced from Sudan
because not our problem.
I say that with the, all the contempt that that should feel.
But, and yet I didn't give anything.
I don't know why.
Um, I know exactly why they're very far away.
And it's not my problem.
I, I cannot literally help everyone.
That's true.
And yet like, I talk about being a nice person trying to do nice things.
And yet like, you give your 10% of the most effective places
as you can, right?
And hopefully as we knock more and more problems down, that 10% will move
to higher and higher places.
And we can rationalize and say, Hey, you know what, these, these large
scale problems will hit the news and other people will give money to them.
So I don't have to.
But like the against me layer foundation isn't the sexy charity to give to,
right?
But, you know, the save, save the kids from, you know, the salvation or not the
salvation army, the, um, salvation army too.
I was thinking, uh, what the, the Lord's resistance army.
Um, you know, that's, that was a valuable thing.
And I'm sure that got lots of people to participate.
Yeah, this is muddy.
I don't know.
But that said, Katja's essay short, and it's really interesting to just feel
the weird tickle when you realize like, Oh shit, I feel the same way
about my stuff is to do about like my morals.
Yeah.
Katja did also, um, make a point, which you pointed out here that, uh, it's
interesting, the article isn't trying to argue that property rights are good.
And, uh, it asks that maybe we should write off some of our moral
intuitions and reasons on consequential grounds or some of our moral reasoning
on consequential grounds, if they are outgrowths of property rights intuitions,
because property rights does not seem like a correct consequentialist way to
think of things like overall beauty of the human race.
Yeah.
Just had to throw that in before it moved on.
Um, well, yeah.
The article is not pro.
We should base all things on property rights.
It's just thinking about that.
It's just, it's just noticing that that is a thing that's out there.
And it's kind of interesting to notice and raise the question of how to
react to that.
I think it was the most recent episode of the Very Bad Wizards podcast was, uh,
well, they talked about another thing that I want to maybe touch on as a joke.
And we've ever gotten around to the, uh, random things to indulge Stephen
slash stir the pot section, but the, um, okay, we'll find a better name for that.
But, right.
The touch Stevens pot.
Yeah.
The second part.
So if you ever listened to very bad wizards, they, um, first of all, they
do that nice thing where they break up their sound file with like flags that
some players can see and say what section you're in.
So you can skip right past the intro, right past the, uh, thanks for, you
know, thanks and solicitations and all that.
Um, and so their first section is usually about something kind of random.
That's like between them.
And then the second one's first section is usually my favorite.
It's pretty good.
I'm like, I like hearing them talk about random shit that's going on.
It's good.
Um, but then the second one on this one, they talked about, uh, paper by George
sure called, um, could I be, or no, that could I be wrong?
Was anybody the episode?
I don't know if you're interested, look up the very bad wizards episode.
Could I be wrong?
But basically it talks about, um, among other things, cause it's
philosophy paper and I don't listen to podcasts, like with a pen and paper in
hand, I tend to just be doing other things.
And you know, I'm playing on my phone on the train ride home.
I'm catching most of it.
So it was much more in depth than this, but he talked about how people's
different lived experiences will come to different moral intuitions than you.
Duh.
But does this cast out on our moral intuitions because we're obviously
right and they're obviously wrong.
Um, can we, you know, I'm actually going to look up the name of the episode
because they put it really well.
Um, am I wrong?
I think it was the name of the episode.
Yep.
Number 148.
What happens once you realize that our moral convictions are not better
justified than the convictions of people who disagree with us?
Does this mean it's no longer rational to act on our moral intuitions?
And is the problem deeper from moral beliefs than it is for empirical or aesthetic beliefs?
I kind of had some issues with this episode because, um, it came from the
assumption that my moral beliefs are something that I arrived to because due
to, you know, how my life circumstances, how I was handed them and that everyone
else is more or less the same.
And so we should consider them equal.
And this, this just sounded like arguments made by people who have never had a
significant revision of their morals.
And I, I have a number of times in my life very closely looked at my morals and
made significant changes to my morality.
And so I do have a bit more, at least it sounded compared to them, a bit more
grounding and more certainty that I am as bright as I can be in the situation.
And I realize I'm not completely right.
Certainly not about everything.
There's some things that I haven't looked into that much, but I'm right about
everything I know about.
The things I don't know about, you know, maybe I'm not right about it.
Well, I mean, not even necessarily that.
There's things I can be mistaken about too, right?
But they were just like, well, you know, nobody's morals really got there
through any sort of logical reasonable process.
So we should assign all of them the same amount of uncertainty.
I'm like, no, no, there's a few things that I am very, very sure of.
And I don't think that's what they landed either.
They entertained it that way.
It sounded like they were saying that.
But they even said flat out, like we're never going to decide that rape is okay.
You know, that's not, that's not an ethical belief we need to be unsure about.
And anybody who says it is, is just wrong.
Same with, you know, murder, torturing kids, all the obvious things.
Yeah.
But, you know, those are the obvious things.
They were talking about some less obvious things, right?
Like the value of religion, or they specifically called that abortion several times.
And that is one of the ones that I'm actually rather sure on, you know?
And, and I am too.
And yet I can think of, like, I guess it wouldn't be so much like personal
experiences, although I could think of some that might flavor my, if, if are
somebody, you know, if I had known two girls, you know, who had, you know, I'm
not sure what the death rate is for getting an abortion, probably one in a
million or something really small, right?
But it's got to be non-zero.
So if I knew somebody who had died getting one, I might be, I might be more
anti-abortion than I am, right?
Especially somebody I really cared about.
So, you know, but I'd like to say, you know, nope, she wasn't normally, everyone
else would still have them, they're safe, whatever.
But I could see how far some people that might be an argument.
That one's maybe less, less defensible, although I could certainly think of
empirical judgment or empirical observations that could be made that
would immediately change our mind on the subject.
But, um,
Oh, unabortionment?
Yeah.
Yeah.
Yeah.
Yeah.
I mean, if we, if we, like, if you could prove that an embryo was a person or a
soul or a soul is a real, like, you know, well, no, if souls are real, then
all abortion should be mandatory because the soul gets right to heaven without
having to worry about sinning.
What if you could prove that an important soul went to hell?
Oh, well, yeah.
So, so, you know, whatever, you can twist that.
But, you know, or like, if you, if you learned that there's some weird magic of
physics, you know, some, you know, hitherto unjumped of biology where, you know, at
eight weeks, an embryo is more sentient and alive than you'll ever be as an adult.
Right.
Then it's like, oh, shit, we definitely can't do it at that point.
Right.
Maybe wait until they're born or something.
I don't know.
But, um, so I could think of empirical things to change our mind on that.
But I was trying to think of one, and this one actually worked because it got me
uncomfortable just thinking about, but like, I could see how someone's position
on something more gray, like immigration in the United States.
Um, that, that's probably almost largely colored by personal experience or lack
thereof, right?
Like my life's never been adversely impacted by, uh, immigrant, by, I'm trying
to say immigrant immigrants from legal or otherwise status.
Um, and yet I know people who have, um, you know, if you, if you work in a
rural part of the country and you're only good at manual labor, but you're
trying to, you know, live a life with a couple of roommates or whatever it is and
you know, make a living.
And yet there are people who are willing to do it for way less than you because
they're willing to, I guess, live in conditions that you're not willing to live
in, well, you're out of a job and I know people who've lost jobs that way.
Um, not in the last decades, but I'm sure it still happens.
But, um, in those things, I say, nope, this, I've seen it, it ruins small
economies and small areas or something.
And so they're, they're, they're justified in believing it for that reason,
right?
They're going to say, nope, that's why I'm against it.
And yet where the rest of us cosmopolitan people are going to say, no,
no, it's how good to be bad, um, or whatever it is.
I'm not sure, you know, my opinion on it is not very well calibrated.
Yeah, I know.
Um, so that's one that I think is pretty, uh, when we can assign a certain level
of uncertainty to your belief.
And so this is where, um, and McCaskill talked about this on his episode of, uh,
very bad research, which might have been the most, the previous one, 147.
He talked about making moral judgments under uncertainty.
And he used, he used a lot of the same language from the, you know,
the rationality papers, um, that you can, you can make estimates on what
your confidence is in on these moral propositions and then run your
Bayesian calculation and do whatever it says, um, just like the rest of us
good rationalists should do with all of our other beliefs.
Anyway, fun, fun episode.
I thought it lightly related to this and that, um, not only are our
intuitions for some weird reason tightly coupled with our beliefs about
property rights, but they're also, uh, some of our less, um, so, you know, I
could be 99% sure that abortion is a good, is, is a, it's valuable to have
around and that everyone should, they should be how to build Clinton.
Put it, um, safe, affordable and rare.
Um, so, you know, some, some of the people will say people should have
abortions all the time and they should be, you know, you should get 20 bucks
for getting one or something, but that's, that's not me.
So, uh, like if you'd be willing to get an abortion for 20 bucks, you
probably should get the abortion.
That's actually a good point.
Yeah.
Um, I can't think of actually money that if you're, if any amount of money
that you're going to offer somebody that said you probably shouldn't get it,
right?
That's going to give you $2 million to get one.
You should definitely get an abortion for $2 million, right?
Well, I mean, if you're going to have a kid, first you have an abortion to
get $2 million so you can finance the kid and the college and everything.
That's right.
Yeah.
Um, it did make me think that if we ever find something we really disagree on
that we can crux, uh, with a double crux game style thing that make for a fun
episode, that would be awesome.
So do we disagree that strongly on anything?
I don't know if we disagree on anything strongly that is empirically, I think
part of, part of the double crux game is that like your belief rests on
something that's true or false, that we disagree on the fact of something.
Right.
And that's the other thing about moral intuitions is that many of them come
down to matters of fact.
And so people, you know, like as long as pro death penalty or anti-death
penalty, I think they use this in the, in the episode too.
Um, you know, it comes down to like what you believe about redemption for people
or how much it costs to keep somebody alive in prison versus how much it costs
to kill them.
Um,
But the deterrence value of the death penalty is right.
And so I heard a wonderful point recently that, uh, their death penalty should
never be used for, uh, crimes of passion, uh, generally things like murder assault
because the argument was that people are usually not fully in their control of
their rational capabilities when they commit these crimes.
So the fact that there is a death penalty for them doesn't,
doesn't really deter them.
Totally.
Uh, whereas the place where you really want to implement the death penalty is
things like white collar crimes.
That's what I was going to say.
I hadn't heard this argument, but that's exactly where I knew it was going.
Yeah.
The cold, calculated crimes that you carry out, you know, are fucking people,
but you're okay with it.
If you embezzle a hundred thousand dollars, sorry, death penalty, because no
one's ever gonna embezzle money again.
Yeah, it's not true.
Some people still would, but it'd be more of a deterrent.
But it would actually be a deterrent in that case.
Whereas, you know, for a, uh, a flight of rage murder, you're not deterring anybody.
Everyone knows it's against the law to kill people.
I think it still deters some people possibly a flight of rage murder.
Like something in the back of your head being like, I could be killed for this.
I don't know, enough killers, I guess, to have a good mental model of what it's
like to, to murder, to decide to murder somebody.
But I've got to think that if you're deciding to, that's, that's, in
effect, the, the law takes that into account, right?
If you decide to murder somebody, then it's different.
And, you know, it, it's also me deciding to murder you.
If you and I are having a fight and I grab a pen and stab you with it.
But that would probably be punished differently than if I, you know, went off
and got poisoned and slowly killed you over the next two months with it.
Right?
Yeah, yeah.
Like I'd be a much more sinister monster for doing that.
And everyone recognizes that.
Yeah.
Um, I don't know where we're going with this.
Uh, and it matters the fact of being the crux of our position.
I think actually the, the immigration thing is a matter of fact, right?
Yeah.
Like you can actually test whether, um, loosening immigration laws leads to,
in general, better or worse outcomes for people in low wage industries.
Well, yeah, but they didn't have to make a moral judgment about whether
that's an okay consequence of doing the right thing.
I mean, that too.
Yeah.
So I do remember hearing a story about, uh, on NPR, of course, uh, about a chicken,
you know, one of those chicken plucking factory poultry farms.
What do they call them?
Where they kill a bunch of chickens and process them for food.
We'll just call it a chicken factory farm.
I don't know if there's a name for them.
Okay.
But, uh, basically chicken factory chicken factory, there was, uh, it started
like 10 years ago, what they hired one or two, uh, Hispanic people, um, and
Mexican immigrants, I think they were, uh, I don't necessarily want to say that
cause some of them might have been from Central America, but let's just say
Mexican immigrants for now.
Uh, one or two, everyone was like, cool with them.
Like, yeah, that's Maria over there.
She does good work, but, um, more and more started coming into the city
and, uh, eventually it got to the point where there was maybe only one out of
any, any 20 people there, uh, was not a, you know, Mexican native.
And, uh, and everyone spoke Spanish, the few people from the, that originally
had been in the town, like, didn't have anyone to talk to at work.
And they felt like really cheated because they, like you said, had taken all
the, these, these jobs for a lower amount of work and less, uh, and worse work
conditions.
And so there were a number of people in the town really upset about the whole
immigration thing, but they, someone came in and like looked at the town
economy overall and all the people coming in and working at the, the chicken
factory, now we're spending the money in the community on other things.
And that created new jobs in places like, you know, stores and yeah, like it's
possible that people may not realize that they're better off even though they
are by having people do these jobs.
Well, and some of it too might be, um, I, I now they also get much lower
prices on their chicken when they go in by chicken.
That's true.
And I mean, I saw a thing on Reddit just a couple of days ago.
I think I spent too much time on Reddit is what's coming out of tonight's
conversation, but, um, the, all thanks to the great Apollo app for iOS.
Sorry.
Uh, someone, you know, grabbed their chicken thing.
They're, you know, you buy that thing of wrapped chicken from the store and it's
like already pre-cut and it's got that wet, soppy thing in the bottom that
brines it or something and, um, they took it, you know, it was like $1.99 a
pound from Walmart and they bought four pounds worth of whatever and they put
on a scale and it was like three pounds and two ounces or something.
And like, yeah, but the whole wrapper and everything, it's four pounds.
And it's like, yeah, you're paying for the whole thing.
And the top comment was some Canadians like, I don't know how you guys
could possibly have chicken for $1.99 a pound.
Like that's the, that's the takeaway from this, right?
Is their chickens fucking super cheap.
So you're right.
The cool thing about cheap labor is that you get cheap products.
And I'm sure there's all kinds of terrible outcomes to that, that you get
nightmare factories, you know, where, uh, our iPhones are made from, you know,
people that don't want to make them.
And, uh, or I guess would rather have other options.
Maybe sometimes, I don't know.
I have mixed thoughts on such ops too.
Cause I don't think there are products that you're buying in the West that
often that come from people who are changed to desks, but some people work
there because they want to, you know, but it's one of those weird exploity things.
It's like, yeah, you want to cause or else.
And, you know, the or else thing is, you know, a real thing, but it's,
but I mean, the or else thing is just, it's a fact of life.
Like, even if there were no factories like that, your, your option was,
would be, I grow my own food or else I starved to death.
Well, totally.
I don't know.
It's something about when I first heard that argument, particularly that I
felt just like this kind of weirdy pugnance in my mind went straight to like,
cause I do this whenever I hear like a new argument.
It's like, all right, let's turn it up to stupid and see, see how it's, how
let's turn it up to 11 and see how stupid it sounds.
And it's like, all right.
So let's like go to, you know, war-torn Sudan and, you know, talk to some
refugees and like, Hey, you can come live in my house and clean it and do all this
stuff and I can have sex you the never you want, but, or I can leave you here.
What would you like?
So it's like, it's the exact same argument.
Kind of, but no one I think would say that's okay, unless you're going to just
bite the bullet and say, I guess she would rather be raped three times a week
than, you know, dying in, in this, this war-torn nation.
So, I mean, to be fair, I
would rather be raped three times a week than die, but I'd rather neither of
those happen.
Yeah.
And I think the person, yeah.
Making, I think the person making an offer is a bad person.
Yes.
And that's, that's my takeaway.
Not that like they shouldn't take the offer or whatever it is.
It's just like, okay, yeah, I see what you're saying and yet you're still kind
of fucked up for saying, you're not, not for saying it for, for being the kind
of person who wants to do that.
Yeah.
Um, I think that basically comes down to people saying that there's a
difference between getting raped and money.
That, that is where people would argue with you.
They'd be like, you know what, those are two very different things and you
cannot compare them in that way.
Yeah.
And like giving you literally no money is wrong, but giving you not joking a penny
a day, that can't be less, I guess, technically less wrong, but it's not good.
It's not better.
They're never going to not be able to not be your slave because they can't ever
save that money and go do something else.
Right.
Yeah.
So I don't know.
It's a whole thing.
And I'm standing probably like an idiot to anyone who knows anything.
So let's just, let's just pivot.
Okay.
Um, where do we want to go from here?
Spamming microintensions to generate willpower.
Yeah.
This was fun.
That was really cool.
All right.
Spamming microintensions to generate willpower, which is another post on less
wrong by Matt Freeman, AKA more than a male, AKA do podcast media fame.
Um, he's going to keep plugging that, that podcast, aren't we?
Well, I like it.
Yeah, I do too.
Actually, I've been really enjoying it.
And holy shit, their coverage on their last episode of We've Got Ward.
Yeah.
Uh, did you read enough of Worm to get to any of the interlude chapters?
Yeah.
So they did one for a character that, for really complicated reasons that
takes a long to get into, you never really see all that much.
You see him about half the time, maybe less.
Um, half the time, what?
Of the story that he, that, okay.
So he shares physical, he shares a body.
He shares physical space with his twin brother.
They both triggered with their met with their superpower at the same time.
Okay.
And for whatever reason, the, the way that powers work, they don't care.
I guess about twins being separate people.
So the womb, they're the same.
They, uh, basically, did you see Get Out?
Yes.
Yes.
They got that going.
So yeah, one of them is sitting in the chair, watching through the eyes.
Another one's driving.
Okay.
And then when they switch out, they switch bodies.
Another one's in the chair.
Okay.
And it's, that's that's as bad as it sounds.
Um, you know, they, they don't get along well.
They, they, they triggered during a fight where they were basically killing each other.
Oh, like it escalated.
One was strangling the other one.
The other one started stabbing them with a pen because he couldn't breathe.
Wait, how could they kill each other if they're never in the same?
This was before they triggered with their superpower.
So then, then the one wakes up and he can't find his brother and because they
don't know the other ones in there.
Um, so like they're not aware of it.
The, what happened is that from, since it's the interlude chapters, everyone
should read worm and ward.
So they, you get to follow the story of the protagonist from their point of view.
And then the author throws in, usually at the end of arcs, but sometimes in the
middle, a chapter from a perspective of the non-protagonist, some random character.
And it's never the same character twice.
And if it is the same character twice, well, they're a different person now.
So in this one, um, this is another part of the protagonist's team.
It just, it's really well done.
Everyone should read this.
Um, why did I talk about this?
Oh, cause I'm, I'm playing up to media and we've got ward.
Um, anyway, the coverage of it was really well, really well done.
And because they actually like read it with the intention of discussing it.
They, they typically read it more than once.
And they said what I, what, well, I only read the chapter once and they went
through and did a really balanced version of it.
And like, how the hell were you guys worked that hard to come out that fair
to the other person in this?
And they were like, on my first read, I was totally on this guy's side.
I was like, Oh, okay, that makes sense.
Cause I only read it once.
Now it's on this guy's side the whole time.
But then they point out everything that, uh, really makes it a much more
balanced situation.
It's now I'm totally going on about it too long, but if everyone liked how
articulate Matt was a couple of weeks ago, they're that great on their show
all the time.
And it's really funny.
So check it out.
Anyway, speaking of Matt being super articulate, he wrote a great post, which
tied into our one a few weeks ago with Jess, um, on spamming micro
intention intentions to generate willpower.
Yes.
So yeah, this was a really good post.
Yeah.
And it's like, and what I like about the new less wrong format is that what I
hate about it for one is that for whatever reason on my browser, text is
like the middle third of the page with these gigantic white bars and the white
on the side and the text is small.
So I got to zoom it in to read it, which is, I don't know if that's just me in
any case.
So that's the downside about the new less wrong website.
But I think that's like an aesthetic choice that a lot of places are going to
right now and everyone hates it.
Yeah.
Everyone hates the new Reddit design.
Everyone hates the new Gmail design.
Why do people take good things and destroy them like that?
Our friend, uh, Zeke Iran made a good, good argument on, or pointed this out on,
um, might have been on Facebook, which I somehow saw this week.
It was, um, that I think he had a good word for it.
I'm sure it's probably the tech word, but basically they, they plateau it.
What is good, but they can't leave it that way because it gets stagnant.
So they've got to just change it with the sake of changing it.
And that means doing whatever is popular, whatever.
So I am, people don't like how Gmail is now around as opposed to sharp
corners on things and this and that.
It's everything looks like it's made for five year olds.
It's, it's fucking ridiculous.
Yeah.
So that's, we'll see how this all shakes out with the end of the trends of, you
know, in a couple of years, things will be different.
Well, it's fun to seize.
All right.
Now we're getting way off track, but here we are.
So, um, you can, I can try and find this image if anyone cares, we can just
look it up of the evolution of app icons over the last several years, especially
Google's, um, they used to all look different.
And now they all look exactly like every other Google one.
So let's see where's my Google apps.
Uh, Gmail is a G, you know, in a white background.
The docs is a document with a white background and the document little
icon is smaller inside that little icon.
I don't know whether Google apps are, but point is they all look like
that every Android app too.
They all, they all do the same thing where they just get smaller versions of
themselves and they get rounder.
Okay.
That's the bad thing about the less wrong website.
Okay.
The good thing is that it shows the read time at the top of the article, which is
fine.
And I'm sure that's generated from the average person's reading speed, you
know, times the number of words in there or whatever, or divided by the number
of words.
For me, it's three times that cause I slow reading, but for me, it was a 10 minute
read, which is great.
And, uh, so for a three minute read, you can discover.
Did they say this is a three minute read?
I think so.
Jesus Christ.
Who reads that fast?
Hold on.
Let me double check.
Well, now that we're here, we got a, okay.
That said, the less wrong website looks great on a phone.
Cool.
My grand intentions.
Three minute read is what it says.
That's what it says.
Three minutes.
That's ridiculous.
There's no way I could read this in three minutes.
All right.
So it'll take you 10 minutes.
Who cares?
What is, this isn't a 10 hour investment to read this book or whatever.
It's a fun little thing that, um, I really liked and I'm eager to give it a
shot and I was going to, when I was reading this, cause he gives part two of
the post is here's an example to try in real life, but it was almost time to
come over and I didn't have time to do it.
So, um, I didn't have enough time to do enough micro intentions to make it happen.
So you didn't get the part two.
I, well, I read the part and I didn't have time to actually generate enough
micro intentions to get, to actually make myself do the thing.
Did you do 10 pushups and you read part two?
I did not.
Oh, well, I mean, I was at work.
Okay.
Yeah.
But so anyway, the idea, um, it, it, he was inspired by a, a Reddit post on, uh,
meditation sub Reddit and basically, um, the takeaway for the applicable part
here is that if you have something that you want to do, but you're having
difficulty generating the motivation to do it, especially if it's something
small, like I got to take out the trash or fold my laundry or whatever it is.
All that's required is a very light touch of intention as if you're trying
to brush a fragile snowflake with the tip of a feather.
When this quick, gentle intention is repeated consistently, perhaps with
every breath cycle or even two or three times during each breath, it grows in
the mind, eventually it complies.
I call these micro intentions to highlight their quick, light, gentle quality.
What's fun is that in the good rational sense, you find some synergy between
something unrelated and makes it to something that he can do more often,
um, with, with more applicability.
So, um, your first micro intention appears to do nothing because you're
just touching it with a feather.
You're just, it's just there.
But if you spam yourself with this thought and that's part of what you need
mindfulness, that's why this is a meditation thing, just over and over, you
know, every couple of seconds for a minute, you know, uh, maybe two.
And he, he talked about this and I got to this point in part two where he says,
it occurred to me that sustained micro intentions could be a very generally
powerful tool.
I've tested it enough to certify, certify it as something that I'll keep in my
toolkit and I figured I would just share it since I think it would be
replicable in the, its most basic implementation.
He says, all right, so try it out.
You probably don't want to, you probably don't want to do 10 pushups right now.
If you give yourself a push to do it and intention, you'll probably
encounter resistance.
If you don't encounter resistance to doing pushups, then find some other
small activity that you really don't want to do right now, but you feel, and
that you feel resistance to doing, but when in principle be doable.
Um, that's why I mentioned laundry or whatever.
He says, now that you found that resistance, just start spamming micro intentions.
That push you just tried to test for resistance, just do that again, but lighter.
So lightly, so lightly that you don't even really care if your body complies.
Just doing it roughly every one or two seconds or as frequently as it feels
right.
This is important too.
I found that it also helps to sustain a meta intention of producing micro
intentions to do pushups.
Otherwise there's a risk you'll quickly get bored or distracted because it's a
weird thing to ask your brain to do, especially if you don't have any evidence
that it'll work.
And about 15 to 45 seconds of sustained little pushes, you may suddenly start to
feel a little weird, like you're suddenly uncomfortable just sitting there.
None of the other activities that were on your immediate docket seem at all
the appealing anymore.
It may occur to you that the only way to alleviate this discomfort is just to
get up and do those pushups.
Then if you do them, it'll feel natural and inevitable to do so.
And there's, and the resistance is no longer present.
What I love about this is that I do a less, um, less gentle version of this, but
I'm going to try this, uh, next week, cause I'm not going to work tomorrow.
Um, cause I go to the gym over lunch and most days no one wants to go to the gym.
Occasionally, like if I haven't gone over like a three day weekend, I'm like, I
need to go to the gym.
I feel, I feel weird.
Yeah.
But even then, like, you know, the 10 minutes leading before it, you know,
you, you're going to go work.
It's not fun.
And yeah, I keep telling myself, no, you're going to feel great.
Let's do it.
I'm going to try this and just like, you know, sit at my desk for a minute and
just spam this over and over and be like, no, no, just, just get up and do it.
Get up and do it.
And I, but I, I did this with a pushups thing, even though I didn't actually
get around to doing the actual pushups.
And I felt that kind of like, I don't want to sit down anymore.
Maybe it was cause I, maybe it's cause he's steady.
You don't want to sit down anymore.
Maybe he's, he's mind, mind whammying us.
Right.
That I, I mean, I first time read this was today, but I work out when I get home
from work and I lots of times I also don't want to, but I'll just like flop
down on the bed and be like, ah, like, okay, gotta get up and do this.
Just think about doing it for a while.
Like visualize myself, myself doing it.
I'm like, yeah, I gotta do this.
And after about like three, four minutes, like not only do I get a bit rested
from laying down on the bed, but I'm like, yeah, I gotta do this now.
And then I do it and I never thought of it as sparing myself with micro
intentions, but yeah, totally, it seems to have worked for me at any rate.
And for me, I think it might be, and I'm not sure if one's more effective than
the other, but this is distinct.
I think from sitting there thinking, I gotta do this.
Oh yeah.
No, you can't just think the words.
I gotta do this or visualize doing it.
Well, that, that may be too, but I think that that's even more intense
than what this is saying.
Okay.
This, you know, this is just a light kind of like, if you ever tried meditating,
just that kind of gentle thing you do when you realize you're distracted and
just kind of get back to focusing on the breath or whatever noise you're
listening to or whatever.
Let's just get back to that.
Just that kind of just like, nope.
Yep, there it is.
Just that whatever, and it's, if you're, and I'm not a very
practiced meditator, but I've done it a bit, like I said, that realigning to
like getting back into the mindfulness part of it, when you realize you've
stopped being mindful and are being distracted, that's a gentle thing.
It's not a, if you, if you pull the brakes and, you know, are harsh on
yourself or whatever, you're not doing it right.
It's, it's a very just gentle correction.
I think it's, it's more like just that, that, that light little push.
So I, what I found fun about that was that I, it was just that kind of weird,
like, oh, I do want to do this.
Um, whereas like when I talk myself into going to the gym or to doing
whatever it is that I don't want to do laundry, it's more like, I finally just
like, all right, fine brain.
I'll do it.
Shut up.
It's not more like I want actually to do it now.
It's more like I want you to, I want me to shut up.
Um, so I'm, I'm really good to try this out and I'll report back.
Um, can I read something from the comments?
Yes.
Like this was short enough of an article and I was into it enough that I was
like, I want to read more.
So I just kept reading into the comments.
Uh, in one of the comments, more than a male says, part of what led me to think
of this was the recent straight slate star codex on motivation, quoting the post
now the straight, straight home, the straight home receives bids from other
brain regions, each of which represents a specific action.
A little piece of the lamprey brain is whispering mate while another piece
is shouting flee the predator and so on.
It would be a very bad idea for these movements to occur simultaneously
because the lamprey can't do all of them at the same time.
So to prevent simultaneous activation of many different movements, all these
regions are held in check by powerful inhibitory connections from the basal
ganglia.
This means that the basal ganglia keep all behaviors in off mode by default.
Only once a specific actions bid has been selected, do the basal ganglia
turn off this inhibitory control, allowing the behavior to occur.
And Matt goes on to say, think of the mind as an assembly of sub minds who
are bidding for control of the body, sweep all the complexity aside for the
moment and think purely of that bidding process.
It seems evident that sub minds can win the bidding war by being weak, yet
insistent.
You can get your mind to pay close attention to your breath by repeating
tiny intentions at a high frequency.
You can make yourself to push ups by the same means.
You're effectively hacking the bidding process by taking advantage of an
exploit.
I was like, that's makes perfect sense.
And it's really cool.
And it also, you know, reminds me of a certain rational fiction podcast
thing that I'm doing right now.
Before he even talked about the sub minds thing, that's exactly what occurred
to me.
And I would bet a hundred bucks that Max, Max Harms has read the, um, or at
least is familiar with the same neuroscience.
If he's not, then he's a fucking, he's already a genius, but that was way too
close.
Yeah.
What he's describing here is basically the, the, the crystal society, uh, the,
which itself is based, I think Max said off the, uh, the, well, partly based
among other things, uh, society of the mind, which was a book about neural, how
the brain works, I don't know, 10, 15 years ago.
That's right.
We talked about that when he had him on the show.
Yeah.
Um, yeah.
But anyway, so it was, it's fun to think about, and this is, I guess it's
knowledge I had in the back of my brain somewhere because I knew this, you
know, that there are different parts of your brain competing for stuff and this
and that.
Um, and yet I never applied that to this kind of intentionality before.
And yeah, you're right.
Parts just win.
In fact, um, this is, this is really demonstratable, right?
Like you could say, I'm going to fast for as long as possible.
Eventually you're going to stop, right?
Um, in fact, I just had a friend, one of my co-workers yesterday, um, was
fasting for Yom Kippur, which apparently you do from the night before to the
morning after.
Oh, it's like a 36 hour fast.
Yeah.
So I'd ask him was like midnight to midnight, was it dawn to dusk?
And he's like, no, it was from last night.
And I accidentally had, I accidentally had a midnight snack, but, um, he said
the hardest part was like caffeine cause he drinks three, four cups of coffee a day.
So you can't even have liquids.
Um, he said that you're not supposed to, but in his defense, they were at sea
level, the, the, you know, the Jews in the desert where all this
tradition came around and he's in Denver.
So he's like, I can allow myself to have water.
On the other hand, the desert's pretty dry place.
Yeah, I was going to raise that point, but this was yesterday.
So maybe I'll bring it up tomorrow with him about, uh, you know, that I, I
think that's cheating because you're right.
It's thirstier than it has been, but, um, yeah, apparently, you know, caffeine
doesn't count.
And I asked him was like, does like aspirin count?
Um, and then I was like, you know, et cetera and has caffeine in it, but
shit.
Now that I told you that you probably would feel guilty, you know, cheating that way.
If I'd said here, this will make your headache feel better.
You might have taken it, but now I told you that's caffeine in it.
And that would be a, anyway, wait, even just caffeine, like just caffeine pills
counts.
I don't think it was in the Bible.
So I think that when in doubt, if you think you feel, if you, I think, right,
I'm guessing as far away from potential sins as possible, I guess.
Yeah.
If, if you can considerably feel guilty about it, then you can't.
I think that's the, the thrust of religious discipline.
I don't feel guilty about anything.
That's right.
Um, anyway, this, this post is awesome.
And it's, you know, meta point about the posts, which I already said, but I'll
reiterate because it's late.
I'm getting repetitive is that, um, this was just a good application of the
kinds of things rationalists can do.
They can read about one cool thing and transfer that seemingly fun nugget of
trivia, or maybe something that helps with one small domain to be like, wait,
this kind of thing looks like it would work really well over here.
And that's, I think just generally something that smart things and people
can do, but rationalists are good at finding those things, maybe, or something.
Trying to sell us is awesome.
So yeah, yeah.
Cool.
Yeah.
Alrighty.
I think we've been going on for a while.
Are we about ready to wrap things up?
Let's indulge Steven for five plus minutes.
All right.
We'll start with the nice one.
All right, let's touch Steven's pot.
Let's find a different way to put that.
Um, okay.
I think we can have a section.
Maybe it'll be just me because I'm the only one who cares about throwing random
stuff in, but we all can have a grab bag random quick things section on our notes
here, grab Steven's bag.
Well, that sounds less bad.
All right.
So, um, I played, I'm not sure if the hour count or if I got it before we did our
last episode, but something I'll, I've still got the receipt.
I'll find out something like 70 hours this month during the last five weeks.
I played the hell out of horizon zero Don, which was a game that came out in
2017 and would have easily won game of the year if it had come out three days
before breath of the wild, but it was amazing.
Okay.
Um, so I don't know how much I can talk about what made it amazing and might make
it appeal to people who are interested in sci-fi and rationality, um, without
spoiling some of the plot, but if you play video games and you like, um, it's
similar to like, um, kind of like shadow of, of, of Mordor or, uh, Batman,
Arkham asylum, um, but basically if you want to know why a world that you're
fighting T-Rex robots and with a bow and arrow, if you want to know why that
world makes perfect, awesome sense, play this game.
Okay.
It has, uh, this is something that I noticed because Rachel watched me play
it quite a bit too, um, that I was happy to notice and share was like, this has
a like very positive representation of basically everything.
There's, you know, this is, this is a society that doesn't care about like
skin color, though it doesn't care about tribes because it's, you know, they're,
they're shooting bows and arrows.
It's all about tribalism, but it's not a skin color based tribalism.
Um, the protagonist is the most badass woman ever and the, see this is where I
don't know if it's spoilery or not to talk about.
Yeah.
No, it's, it's spoilery to get into.
Okay.
Um, anyway, it was dope.
And I didn't know until I was watching the credits at the end.
The main character is voiced by Ashley Birch.
Who was that?
She came, she was my first favorite female representation in a video game or female
character in a video game, female voice acted character, whatever.
She played Tiny Tina in Borderlands.
Okay.
Oh my God.
I vaguely remember playing Borderlands.
I don't know who Tiny Tina is.
She's the world's most dangerous 13 year old.
She's, she's insane.
She talks like everyone in that game is fucking crazy.
I love it so much.
Yeah.
There was that mission of like, you know, shoot his name was like shooty mix,
shooty face and the quest to shoot him in the face and he's like, shoot him right.
He's like, shoot me right here.
Shoot me in the face.
And the quest was like, shoot, shoot, shooty mix, shooty face in his face.
Do you shoot him in his face?
Yeah.
And then, then he dies and you get, you beat the quest.
It's just like the dumbest little thing ever.
These games are brilliant.
So, um, she did Tiny Tina and she did, um, Hey Ash what you playing?
Which is like a short lived, uh, YouTube video series where they would, you know,
showcase the game for like five minutes and they were just these random little
videos that she and her brother.
Yeah.
I remember, uh, a friend showed me an episode of that that they really liked.
I was like, yeah, this is cool.
Yeah, they're funny.
Um, and she, I think did a couple other web things that didn't really take off, but, um,
yeah, she also voiced, um, I didn't play these games, but I watched someone play them
because I have too much time on my hands called, uh, Life is Strange.
Oh, yeah.
She did not the main character, but the main character sprang the whole time.
Okay, cool.
Um, I played through the first chapter of that.
It was, it was really interesting.
Yeah.
I never got around to playing more of it.
I have a really hard time with telltale games.
Yeah.
It's not really gaming, it's storytelling and it's fun, but that's what makes
watching someone else do on YouTube just as much fun for me.
Right.
Um, because it is basically, yeah, like watching a movie, I guess.
And it, some might argue it's to choose your own adventures.
So doing yourself is the same, but it's really not.
I did the Game of Thrones one and like, no matter what you do,
your, your character gets killed in the end of the first hour or whatever.
Like, so whatever, spoiler alert, this Game of Thrones, everyone dies.
But anyway, really fun.
And she did a great job and I didn't know that she had that kind of range.
Like I've never seen to do like really like good emotional acting.
So yeah, fantastic game.
Everyone should check it out.
Cool.
I did, I did a lot of that.
Yeah.
If, as long as we're recommending games next week, I'm going to recommend one.
I don't want to like step on yours, but yeah.
Go for it.
No, no, no.
I got one for next week.
Yeah.
No, it's fine.
Oh, but I can drag it at you because you'll probably forget by next week.
I wrote it down.
All right, fine.
We'll save it.
Yeah.
All right, cool.
Only one regular game recommendation per week.
All right.
We can touch another thing, which was funny.
Well, it's up to you.
Yeah, go for it.
Actually, it's too long to get into.
We'll save it.
Okay.
The Intellectual Dark Web phenomena, which I hate, I think started off as a joke,
and now it's like this idiot brand.
It's like if someone else called atheists brights, and then like the atheists,
like I guess we'll just roll with it.
Yeah.
No, no.
It was maybe kind of like the new atheists.
Okay.
Except more obnoxious, no, except actually obnoxious.
The new atheists were great.
I don't know.
Intellectual Dark Web has that kind of like on Batman thing, you know?
Yeah.
Or it's like all dark and.
Except all that it is, is people are willing to say like,
there might be a correlation between genetics and IQ or between race and IQ.
Right, right, right.
And it's like, oh my God, you can join the Intellectual Dark Web.
Yeah.
And the reason I thought of it was it was really funny in that same episode of
Very Bad Wizards, Am I Wrong?
In the description, it starts off and they joke about the Intellectual Dark Web
phenomena a bit too.
And so I could just read this and I don't know their names from their voices,
but the one who isn't Tamler, I guess, I could just hear his voice saying this of like,
Tamler wades into a Twitter controversy about Serena Williams.
Could this be his fast track pass to the Intellectual Dark Web?
Nice.
But it's like, oh yeah.
Oh man, you're so in it now.
I just thought that was a funny joke.
And their their first half of episode 148 that we talked about today is on that phenomena.
So yeah, they talk about Louis CK doing more stand up and other stuff.
It was a good episode.
Yeah.
So anyway, that's that's I think what I got.
Oh, that was all for your back today.
Well, I thought we could dive into why I think it's a stupid thing.
Why you think what the Intellectual Dark Web is a stupid thing?
I don't like.
All right.
So I like the name.
I think the name is just kind of cool sounding.
That's true.
It sounds dope.
Yeah.
But if it wasn't like, you know, brooding pictures of Jordan Peterson and Ben Shapiro
and all these shitbags who are only, I mean, excuse me, not shitbags.
I will say the pictures also got me because I like the darker aesthetic.
You know, I mean, I guess as a goth, that sort of is my thing.
But I was like, these pictures are cool.
The name's cool.
I like it.
Man, what a cool branding they got when I was when I was a wee lad.
I used to my Facebook picture was black and white kind of like this.
But I think I guess I can't tell if they're leaning into it as a joke or if they're embracing it as
like an actual thing.
I mean, at this point, it looks like it's an actual thing.
And yet Dave and Tamler were leaning into it as a joke.
Yes, they were.
And so that I enjoyed.
Yeah.
Leaning into it as an actual thing.
I'm like, yep, we're the brave ones who are willing to ask these questions.
It's like, no, you guys are just jerking each other off and you're making really bad friends.
So that's that's my bird's eye view of it.
All right.
That's all I got for this week.
Okay.
In this episode, we keep saying week like we do it weekly.
Sorry.
It's every two weeks.
We're it's we're not busy.
We're lazy and busy.
And you know, she's busy.
Aw.
I'm lazy.
I do.
I don't do that many things.
But we'll eventually maybe do this twice or every week.
Take that out.
No.
I'm not committing to that.
I mean, you can if you want.
I still will not be able to join you every week though.
Fair enough.
Yeah.
All right.
Why have you been thinking about doing it every week?
Well, we keep saying it.
There is there is rationality from at least that's at least 50% enyosh every week.
On on Bayesian conspiracy weeks, you get this and on the off weeks, you get crystal society
or whatever.
Oh, I see what you're saying.
Whatever the rationality podcast is.
Okay.
Right.
Yeah.
You do it.
No.
You do to biweekly podcast, which come out on alternate weeks.
Yes.
I guess so for me, it does feel more like a weekly thing.
So maybe I'll do another podcast that comes out on the other on the other week, you know.
What's your other podcast going to be about?
But you see what I was saying the other week between the two, you know,
you can't alternate weeks and then have another week somewhere in the middle.
Oh, I was being, I thought it was funny.
Both time turn our way into this.
Yeah.
We'll figure something out.
Yeah.
I don't know.
I was just kidding.
I know.
But we're clearly what would you do if you had another podcast?
I wonder if I could talk Scott or Matt into doing one on video games.
That'd be fun because they do do media for, you know, TV, movies and books.
Yeah.
But video games are more of an investment.
Yeah.
Like, like I said, to really play this game, I probably didn't need to spend all 70 hours,
maybe 79, but probably at least 45 of those.
And that would have to be like a monthly podcast.
And even that's a pretty heavy investment 10 hours a week.
Not everyone has that kind of free time or the desire to do that.
So.
Right.
I mean, but a lot of people do.
The thing is, it's not work if you're playing the games anyway, right?
That's true.
But at some point I'd run out of games I want to play.
And I had to play games that people were like, hey, you should try this.
I'm like, I got to drag my ass through Undertale now.
You didn't like Undertale?
I tried for like 10 minutes.
Oh my God.
You'll try again.
The thing is I grew up on Final Fantasy.
I actually played the original Final Fantasy all the way through, but also two and three.
And I played a lot of the old JRPGs.
So Undertale wasn't Final Fantasy.
Ask.
It was a text based game, wasn't it?
No, no, no.
Undertale was totally JRPG.
But you're just talking to the things and like you can you can fight or you can talk
your way out of these altercations.
Am I thinking the one where it's like the little white creatures?
Yeah, I know you're you that's Undertale.
That was totally.
I mean, I know you haven't played like the original Final Fantasy games, but that was
I played Final Fantasy 7 back in the day.
Well, okay, that's similar.
Final Fantasy 7 is basically it looked good.
Yeah, right.
Sounded good.
Okay.
So it had all the things this game doesn't have.
But the battle system was you're on one side, the enemies are the other.
And you choose from a menu about what to do, right?
Sure.
And then after a little time period, you choose from a menu for another character.
After a time period, you choose from another and it's not like doing things
actively with the controller.
You're choosing from a menu every time a timer comes up.
Okay.
That's seeing the results.
Yeah.
Okay.
And now someone's listening to like Stephen, you should never do a video game podcast.
Yeah, I really enjoyed Undertale because it it was a it was a meta video game.
It was a video game about the whole conceit of JRPGs.
Okay.
So I'll give it another shot.
I think it's like, I tried to watch Twin Peaks going into it and like, oh,
someone, you know, Rachel's really into that show.
I tried like two episodes.
I'm like, this makes no fucking sense.
Everyone's crazy.
Right.
And then I was talking to somebody like two years later
about the philosophy of David Lynch's production style.
And it's like, no, dude, he just does weird shit.
Like it's a it's like a dream, you know, things are just happening after
and he talked about one of his movies where it's like a lot like that.
You know, in one scene, he's like having a fight at the kitchen table.
Next scene is off doing something else.
I'm probably butchering this.
Point is, it is just like sequence of events that aren't a story like you're used to.
I'm like, oh, okay.
I was going into it looking for like the kind of thing I'm used to put on a different hat
and go into it with different expectations.
I could probably enjoy it.
So I'll try Undertale again.
I was going into it looking for quote, a good game on quote.
Okay.
If I'm going into it looking for a different kind of experience,
maybe I can get nothing, something else out of it.
Yeah.
What's the classic text based video game?
Sorg.
Yes.
Okay.
I found that fun.
Oh, okay.
But you know, that's because I knew what I was getting into.
Okay.
Anyway, I think if there's a still going on the episode that's clearly gone too far.
If anyone's still left, thank you so much for listening.
Oh, and thank you specifically to KBrem, who is one of our Patreon supporters.
We really appreciate you guys showing that.
You like the show and you love us and it keeps us going.
It really does.
Thanks a lot.
Thanks, KBrem.
That support means, I don't know.
It does mean a lot.
You just said it, but I don't know how else to put it.
It's nice that it helps keep the show funded and keeps lots on, keeps the equipment functional.
But it also just means a lot that, all right, we're going to go on for another minute.
The episode that Sam Harris did with, it was episode 136, digital humanism with Jaren Lanier.
And they talked about how the kind of idea of consuming content for free,
everything on the internet should be free, all the information should be free.
There's all kinds of ins and outs that I don't really get.
But they talked about how, one thing it did give was pay for content that people actually
want to subscribe to, like HBO or Netflix or something.
And Harris made this argument on his podcast and I skipped through whatever his pitch for
donations because I've been giving, I donned it a dollar a month because the show got less
fun this year, but just enough to stay in the donation circle and get this stuff.
Yeah, that's still something.
Yeah.
A dollar a month adds up even if you have enough listeners.
Totally.
But I meant for the kind of, let me rephrase that because people give us a dollar a month
and it's very nice.
So I don't know if you want to chop that or if I can just salvage this.
I feel like you would be giving more if you liked it more.
I used to give a dollar an episode, which wasn't much, but that's what I give to Skeptoid.
Because in fact, Skeptoid's episodes have been getting better and better.
Oh, nice.
Can you choose to do whether it's a month or per month or per episode?
On Patreon, you can do whatever you want.
Or not whatever you want, it is per month or per episode.
Or no, what you can do is you can do per episode with a limit of X.
Okay.
It's all to give them a dollar per episode at a max of one per month.
Got you.
So cool.
But what I really like about that is that I only give to a few content creators and I
should give to more.
I should give to Wild Bo, who writes Worm and Ward.
I should give to more to Doof Media and We've Got Ward, the podcast that I like.
But I think I give like a dollar a month to Bending with Babish because he's that chef
on YouTube that I really like his stuff.
But the idea that you're funding things that you care about, and I like this model a lot
more than just buying a cable plan and you watch commercials and that's how they get
their money for making this worth it.
We do it because we love it, but the fact that you care about it enough to help keep
it going means a lot.
Man, I make really long points.
I'm not feeling eloquent.
So I thought it was a good point.
Okay.
Well, thank you.
And I think I should probably go and support a few more things on Patreon that I am right
now because there's a lot of things that I really enjoy.
And I would be sad if they went away.
Well, in hard part too, as long as we're on the subject, people don't really, at least I don't,
I don't buy books that often anymore, which is a drag because...
I still make it a point to buy every book that I read.
And you would.
That's a bad thing because you're an author.
Right.
And you know what it means.
I mean, but I've been doing that since I started having a job and having my own money.
Oh, they were raised that.
I'm not stealing books.
No, no, no.
I know, I know.
I'm just reading less.
Oh, okay, okay.
Maybe because it's investment, but also...
A lot of people in my book club, we meet twice a month.
A number of them just go to a library.
Oh, I see.
I mean, I don't fault them for that.
They pay their taxes and a couple of them are retired now.
And so they're on a fixed income thing.
And I'm like, one of them is like poor students.
So I totally understand.
I don't begrudge them that, but I'm in the position where I have a regular,
you know, middle-class job.
I can buy two books a month.
Did you read Frankenstein like two years ago?
About a year ago now, I think.
So the author's not getting any respect for that book.
No, that's true.
I guess I probably could have and should have pirated Frankenstein because it's been
over 100 years.
Or borrowed it or something.
Right, right.
Or yeah, it's probably public domain at this point too.
But in any case, I like what you're saying.
And what I'm getting at is that when you decide to give money to it,
that's a real, like he said, unit of caring.
Every single book that I've reviewed on my website,
I have bought even the ones that I didn't like.
And honestly, a review on public is another way, hey, of showing that you care.
Oh yeah, yeah.
So like, works for this show too.
But that was what the hey was about, was tying this in.
But yeah, I mean, talking about it, sharing it with your friends,
you know, me pitching, I'm not getting any money for pitching Apollo over and over,
or pitching Horizon Zero Dawn.
I wasn't involved in making that game.
I just loved it.
I thought it told a great story.
And it was really well done.
So talking about stuff you like too.
All right.
Jesus Christ.
We've gone on for a while.
I almost feel like this is one of those seven-minute Sam Harris,
why you should give money.
Yeah.
All right.
So we are done now.
What we're saying is thanks, guys.
You're the best.
We appreciate it.
Thanks.
All right.
Good night.
See you guys in a couple of weeks.
Bye.
