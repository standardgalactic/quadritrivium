Welcome to the Basin Conspiracy. I'm Minjash Brodsky. I'm Stephen Zuber. I'm Jay Sticky.
Hello, I'm Oliver Hebraker. Currently, I run the team behind LessWrong and LessWrong 2.0.
And I'm Ben, and I also work at the LessWrong team. Oh, Ben Pace is my full name.
Welcome, guys. And I recognize both your names. And like, I see your names often enough that I kind of think you guys were there from the 2007 beginning period.
But then like, I also realize how long it's been, and maybe it's just been more activity lately. How long have you guys been at LessWrong?
I think I discovered LessWrong when I was about 13, 14, which is now about 10 years ago. So I discovered it about 2010, 2011.
And the sequences have been finished. I remember being very excited because Alieza came back to write highly advanced epistemology 101 for beginners.
And I was there for the first time while it was being written. And then, yeah, I think I followed LessWrong.
I think I've just, I initially found an introduction to intuitive explanation of Bayesian reasoning by Alieza.
A friend showed up at me at school, and then I think I just read the sequences into the night for like months.
It was like, until like 3am every morning going, wow, this stuff's great.
And then, yeah, I think I applied to go to CIFAR when I was like 16. And they were like, yeah, that sounds good.
And then we couldn't organize it for like three years. And then finally, when I was 18, I think I pretended to be ill for like prom and graduation so I could fly out to San Francisco to go to my CIFAR workshop.
Priorities, I love it.
Yeah, yeah. And then, yeah, I just been sort of following the community and part of it since then.
Awesome.
I do want to at some point get someone from CIFAR on here to talk about it. Did you find it to be a valuable experience?
Oh, yeah. It was quite life changing. I remember, I think it was just my first evening there.
I had a conversation with someone where they were like, I was like, I'm trying to figure out what to do with my life and I didn't even know how to think about that.
And they were like, I think you should stay here in the Bay for another month. I was like, ah, but I have like a flight away on like Tuesday after this workshop or something.
And he said, have you asked yourself the question, if I made it my goal to stay here in the Bay for longer, could I achieve?
And I said, no, I have not asked myself this question. And then I stopped for about two minutes.
And I thought about it. And then I turned back and I said, huh, I think I could achieve that goal.
And then I did. And I, yeah, I think generally, like, it was a great place for like reflection on what I cared about and what my goals were and how to act in the world.
Oli, how was it for you?
Yeah, I mean, I guess, let me briefly answer your initial question, which is I've been also around since I think 2000.
I've been around since I think the 60th chapter of H.P.M. Wall came out. I think that's when I got. So that must have been around 2011, 2012.
That's my rough guess.
That's right.
So yeah, I'm sadly not one of the very old timers that has seen the original writing of the sequences, but been around for quite a while.
It does seem harder for me to have noticed it even earlier. I think it was also like 14, 15 or 16 around the time.
Yeah. And then, yeah, for me to story, like if I continue with Ben's strength of giving a quick rundown of kind of how I showed up here,
I ended up kind of finishing all the finished H.P.M. Wall, finished the sequences.
And then I sent Miri at the time and email being like, Hey, how can I help?
And then Miri was like, Well, I don't know, you can read all of our papers that we've released.
And then I responded and was like, like a week later, I had actually read like a large fraction of the papers they sent me, which wasn't the most wrong stuff, but it was technical stuff.
And I didn't understand everything, but instead like a pretty decent fraction.
And then I think Marla responded with like how I've told us to like 20 people, but nobody had ever actually done this.
I usually do this as like a method of like somehow not having to answer all of these questions.
And then we talked a bit more back and forth and then I ended up getting off at Intenship at Miri, I think a year later.
And then I was, I was living in Jimmy at the time, but then I flew over to the Bay and then turned out I wasn't actually that useful for me.
So I mostly ended up interning at CIFAR.
And so my first CIFAR workshop was actually done while I was interning at CIFAR, which was a very interesting experience.
Oh, excellent. Are you still working with CIFAR?
So technically what's wrong is part of CIFAR, it's definitely like fiscal sponsorship, like we don't have any like shared decision making structure or anything like this.
But we are like directly below CIFAR's office, like we render our office space from CIFAR.
And so definitely still collaborating with them quite a bit.
And of course fiscal sponsorship means today is like some obligation for them to check what we do in order to make sure that it fits with their share of objectives and stuff.
Ali actually had a especially fun time because he, he's German and I think the sequences was perhaps one of the first major works he read in English.
You just think certain words are in the dictionary that aren't in the dictionary.
So that's like, I like learned English like while reading.
I was watching Dr. Who.
I was watching Dr. Who.
My two sources of learning English was watching Dr. Who with subtitles and reading the sequences, which gives you a very weird set of vocabulary letters.
And so I was like, I had like, I was like fluent in English.
I was speaking English with many of my friends and I could talk to you completely fluently about stuff like quantum mechanics because that's one of the things that I had learned in English.
But at some point somebody else asked, like, can you get a broom?
And I was like, what is a broom?
That's standing.
What, do you remember any of the words that you thought were in the dictionary that actually aren't?
Well, I had all of these, like, there's definitely this thing where just like, I had this, this.
Sometimes it gets like some words, some somewhat like idiosyncratic meaning and I just totally thought that that was like the standard meaning.
So I think like, what was the biggest one here?
My brain is blanking on rationalist jargon for some reason.
I definitely got, I definitely wasn't very good at using semicolons, but that's mostly because Elisa does not know how to use semicolons.
Nobody in America knows how to use semicolons.
They are a lost art and sort of arcane and weird.
So did you get, I'm assuming there's a lot of cultural overlap between the US and Germany.
Did you understand references to like Star Wars and English pop culture?
Yeah, totally.
Like Germany, like, just like history wise, Germany is just like really, really deeply entangled with the US, even more than most other European countries.
Just because like Germany was like, like West Germany was just like occupied by the US for like, I mean up until like 30 years ago, like basically.
And so just the influence there is really massive.
I really love the fact that you were the only one who read all their papers.
Hopefully somebody came off to me.
I have some hopes, but yeah.
It just, it feels like that should be in one of those samurai origin story things.
It's almost the timing that people are like, well, I want to do this, but I don't want to like have to work hard.
And they just didn't read the, you know, do the back reading.
That's awesome.
Well, wait a rock.
You said you taught a Seafar workshop.
What's your focus?
So, sorry.
I don't know.
I don't know how to answer that question.
I think I guess I don't really have focus.
I guess if I were to take your class, what would I take away from it?
So the current Seafar curriculum is like pretty like the classes that I taught while I was like active as a Seafar instructor.
I think my favorite class was just like trigger action plans and I think Fermi estimates.
So both of those were kind of like the things that I like to like to teach.
Trigger action plans is really pretty straightforward.
It's just the way I like to phrase it is like there's a way to model a brain as just like a very large pile of statements.
And it's sometimes a very useful abstraction to like apply to like how your system one works.
We're just like, you can be like, like it's kind of in psychology, like in classical cognitive psychology is usually referred to as implementation intentions and something else.
It's like the basic idea where like in order to like reliably build habits, the basic thing that you want to do is you want to like concretely visualize a very specific trigger in your life.
Like when I like, like you want to reliably floss your teeth.
So you want to make it so that like when you decide that you want to floss your teeth, you're like very specifically and concretely visualize your bathroom and you visualize like the part of your bathroom where your floss is stored.
And you want to be like, this is the trigger that I now visualize very concretely.
And then I want to decide on a very, very precise specific action that I want to take.
And then in a class actually very frequently, we encourage people to take some trigger that they can use and then repeat it just physically right there a few times.
So you might go to the bathroom and literally just like stand in front of the mirror, open the drawer and grab the floss and then put it back kind of in order to get that trigger right.
And there's like the part that's kind of like more the self-helpy part where like, okay, cool, that's a neat trick that I can get you to learn habits.
But the part that I really like about it was this feeling of, I think when I first learned about it, it was this first kind of universal concrete cognitive model of how a brain works.
Where like, you know, I didn't really ask myself the question of how brain work, like how brains work that much before I kind of like encamp it that stuff.
And very frequently when we teach at Cifa workshops, it's kind of like, you can be like, well, he is one way to model your brain.
It's not the ultimate way. It's not the only way, but you can model yourself as being a large pile of if statements.
And that for the first time gives people something to like slot into their like, kind of section of them with the world of how brains work.
And that then allows really interesting other conversations to happen.
Would it be like, oh, I can now actually talk about like how people reason in general, and that opens up kind of everything up to the broader like, out of rationality and like, how does thinking work?
And why do I believe what I do believe?
So that's kind of really why I like that class because it combines this really, really practical benefit with this very universal lesson about rationality that I've seen have a really big effect on lots of people.
That's awesome. Man, I've never like, I've had this vague inclination like, yeah, maybe one day I'll take a Cifa workshop.
I don't know exactly what it was about what you said, but I've never had been more strongly inclined to actually start looking into sessions, maybe in the next couple of years when the plague is over.
I would love to. That sounds awesome. Yeah, all I could think of is like, I want to subscribe to your newsletter.
Well, I do run a newsletter. It's called less wrong.com.
Oh, great.
Curated emails, two to three times a week.
Oh, I actually didn't know about that feature.
Yep. Yeah, if you sign up, there's a small checkbox that says if you create an account, you can subscribe to created emails.
And that's actually how a pretty large fraction of people interface with less wrong.
Yeah, I think one of the things we've got a box, probably if you have an old account, we like didn't want to like suddenly take all the accounts from like, like there's like 50,000 accounts that were like registered before we created let's run 2.0.
And I didn't want to suddenly stop blasting all of them emails three times a week.
That's valid.
But yeah, I think created emails are like part of our, I feel like I don't know if I'm using the term technically correctly, but something like positive selection feels like an important part of intellectual progress where we're not just like weeding out the like bad posts, but we're like,
regularly saying this was great. Well done. This was people should read this sort of stuff.
And that's the wider audience.
The rationalist newsletter is just called that.
I'm less wrong. You sent it for created emails. I don't know that we have a thing called the rationalist newsletter.
Okay, maybe I'm thinking of something else.
Someone else does the rationalist newsletter.
Okay.
Yeah, but yeah, I think, I think when we initially we're getting started working on less wrong. We did a bunch of user interviews with people.
And they told us about like the first couple of times.
Like I specifically record Kai Satala, who's a great less wrong and has written great sequences about psychology and emotions in the brain and multi agent models of his own brain.
And yeah, and he gave a story about, I think his first time he wrote a post on that strong. He's very nervous. He'd been reading for like a couple of years.
And he just got a little comment from Ellie as I go, Hey, this was a great post.
A bird.
And he's like, Whoa, this was so much better than I expected the response. I expected some sort of like critical explanation of like why I was mistaken.
And so I think we took that to heart and we just like three times a week now we write on someone's post. This post was great. Let me tell you some reasons why.
And then like mail it out to a couple of thousand people.
So yeah, I think we generally, and over even over the years I've like updated more towards this model. I think there was a point.
I wrote a post about it about, I think two years ago, where Ollie and I looked into some of the scientific journals from like the twenties and thirties to try and figure out what they were doing.
And specifically, I think we've looked over all the papers in the journal where Turing first published Turing computers and Turing machines, his paper, when he was I think just either an undergrad or a PhD and also into a journal I think Einstein was
Yeah, my German came came in handy during that time.
The Einstein was curating or something like this.
And I remember being surprised, like I quite actively shocked that through the entire journal, through every page of every paper, there wasn't a single sentence of criticism.
There wasn't this person's wrong and let me show you every single way in which they're wrong.
They just were like, here are some papers I thought were good, and I'm going to build on them.
Or here are some other papers that I thought were good. At one point there was someone saying, I'm not going to take quite the same approach as this person.
But it was primarily a method of like promoting the best ideas as opposed to like cutting down the worst or something like this.
The pre internet culture.
Yeah.
And so yeah, we've done a lot and I think of trying to like, and similarly with the book, which I guess we'll discuss is like trying to reward the best stuff as opposed to just like cut down the worst or something.
How correct me if I'm wrong, but this is less than five years old the less run 2.0, right?
Yeah, we are, I think I've never been working on it for three and a half years, and I always forget that seems about right.
Okay, because I'm pretty darn sure it didn't exist yet when we first started basing conspiracy. And that's been almost five years now.
So yeah, when it first came online, I was like, this is awesome. I really hope it works out, but I don't want to get too excited right now.
And I'm really happy that it did work out because, you know, lots of times things don't and obviously it was in good hands.
Yeah, I won. I won a surprising number of bets at the time. Like we definitely were like presented with with a lot of criticism. I think I won. I won like a $500 bet with Nate.
See a machine talent research institute was just like, I mean, I think you're just obviously going to fail. And then, and then he said he would publicly announced that I was right.
If you take a bet that Ryan Kerry, I recall him predicting that we'd fail.
Yeah, I remember Ryan Kerry, I also had an informal bet with Critch.
Has he already publicly announced that you were right?
Yeah, I think he did on Facebook.
What was the like deciding factor in you winning that bet?
Did you like anchor on some metric like number of posts?
I think we had set up a system that was like, if it turns out to be like disputed, we would like ask like, we had some foot party agreed on, I don't remember who it was.
But in the end, he just sent me a message from being like, yo, okay, seems like you're right.
I love it. Yeah, on the, on the Beijing Conspiracy Discord, we have a all bets bear witness channel. And half the fun of winning is that typically the loser has to declare like, yep, this person was right.
Nice.
So that's almost, you know, that's what that's worth more than the $10 or whatever, you know, small amounts we tend to bet over.
Yeah, I really love taking bets on like major projects I'm working on or something with the, again, we'll get to the, I made some bets on the books, I'll tell you about them in a bit.
But I won those.
Well, we can, we can move to the books if whenever you guys are ready.
Sure.
Always ready.
It's not true. I'm definitely not always ready.
Do we.
So quick question, do we want to divert to the less wrong post we normally do at the top or since we're on a roll here, just keep going into the books.
Actually, you make a good point. If we're going to get to him, we should probably talk about near the beginning, huh?
Yeah, let's do it.
Yeah.
Yeah.
Yeah.
Yeah.
All right.
Well, we could start with Einstein's arrogance.
Yes.
And this is the in a nutshell, the post where basically when Einstein was asked, Hey, if Eddington's observations that he's going to go do during an eclipse, don't, or, you know, don't demonstrate the predictions of your experiment, what would you, what do you have to say?
He's like, Oh, well, I feel bad for Sir Eddington because my theory is right.
No, no, no, it's better than that.
Since Eddington was going to be measuring eclipses to try to confirm the theory of relativity.
When he was asked if the observations failed to match his theory, Einstein says, I would feel sorry for the good Lord, because the theory is correct.
Oh, wait, because he was Lord Eddington.
Oh man, I thought that he was saying he would feel sorry for God.
I mean, another level of arrogance that would be useful.
Well, I feel sorry for God that he said the wrong universe because my model is metaphysically correct.
That's what I was thinking that he was like, I'm sorry, got screwed up the eclipse, man.
That's delightful.
Yeah, that would be one more, another rung on the arrogance ladder.
That said, he was right.
So one Lord was wrong, at least one.
Lord Eddington wasn't trying to disprove him, but he was just trying to test it.
So that's the question.
Sorry, go ahead, Jayce.
I just was remembering, wasn't it Einstein that said God doesn't play dice?
Yes.
At least I remember being attributed to him, even while I have to flag that whenever anything gets attributed to Einstein, I'm not supposed to.
Oh, that's true.
I know Stephen Hawking repeated that attribution in at least one of his books.
I had to reread the original papers to be sure Einstein had even come up with relativity.
So much gets attributed to this guy.
He suddenly feels much less arrogant to me because just disagreeing with somebody else's empirical data,
maybe they wrote it down wrong, maybe their observations were incorrect.
I thought, when it says Einstein's arrogance at the top of the post, I was like, that is hubris.
That is the sort of arrogance I was thinking.
I want to add one other observation I see from the post, which is that a journalist asked Einstein why he'd do.
And I'm like, oh, I can imagine, in fact, being slightly more arrogant than usual towards journalists.
I don't know, they're often very critical.
It could be.
I just miss, like, you know, the journalist twisted the quote to make it sound kind of headlining.
Yeah.
I would feel really sorry for Einstein if he had to deal with the level of press.
Yeah, I guess it was largely less bad at the time.
I don't know.
They like had yellow journalism back then, which I think that's basically the same thing we have nowadays, just with a different name.
What was yellow journalism?
It's the same thing where people greatly distorted the facts and would say things that were in some cases just blatantly untrue in order to push their own agendas.
Scientists baffled.
Interesting.
Yeah, so moving through this one real quick, the that just is so since he's not in fact saying that the Lord himself is is wrong.
He's challenging Lord Eddington or he's challenging the possible outcome of the experiment failing to prove relativity or to demonstrate it rather.
So the question is, like, is he being super arrogant by saying that?
And I guess in a sentence to summarize, not really like the fact that he had postulated the theory of general relativity at this point and demonstrated it mathematically like that is more than him just saying, you know,
that already has so much weight behind it than it does if it was just him guessing on a dice roll or something, right?
The amount of bits of evidence it required to pull these particular equations out of the space of all equations.
There was an immense amount of like evidence already pinning down what the possible outcomes could be.
So we've done this far, he must already have had and given that he was correct, he must already had an immense amount of evidence suggesting this thing.
To the point where he felt confident that if someone said them perfectly, it didn't come out that they had messed up with their empirical tests.
This post ties very well with the previous one, how much evidence is necessary, because that one specifically talked about bits of evidence, which we kind of skimmed over because it was more technical and we don't have, you know, written format.
But he does say that to assign a 50% probability to a correct candidate from a pool of more than 100 million possible hypotheses, you need at least 27 bits of evidence.
And then says that just coming up with, what was it?
How likely is it that Einstein would have exactly enough observational evidence to raise general relativity to the level of his attention, but only justify 55% probability?
And it was like 27.3 bits.
And he was like, how likely is it that he had 27.3 bits of information rather than 28 or 29?
And he was probably pretty damn sure that it was true from all the info that he did have.
Anyone else on this one?
I have one unrelated thing, but I do want to, I wonder if he wants to say anything.
We were chatting a bit about Einstein's general like reasoning methods being also kind of surprising at the time.
Like it was somewhat controversial the way he came to his physical theories.
There wasn't like, like each step of it was pinned down by evidence.
He did a lot of reasoning from his intuition and building up sort of mental models, which was also kind of interesting.
I think that was sort of controversial at the time as a way of doing physics.
Yeah, there's just, I guess there's like two interesting directions that I can imagine going with this post.
We're one of the question of, okay, but why does traditional rationality as LEs are called that are just kind of traditional science?
They have this norm of like that kind of being bad form.
And number two is like, I think it's very interesting to like think about what kind of mind Einstein had that like caused him to be like arrogant in this way.
If we want to like call it arrogance.
I generally like, I mean, of course, Einstein has like to discover of like two biggest paradigm shifts and like physics of the last century.
I always find them a very, very central like kind of like data point in when I'm trying to figure out how good reasoning is supposed to work, which I guess is a bit, of course, like everyone tries to do that, but I still find it very interesting.
I've had a book since I was a teenager that my sister got me and I haven't actually read it, but it's downstairs called how to think like Einstein.
So you've reminded me that that book exists.
I will read that and get back to you if I actually learn how to think like Einstein.
Great.
I think this post is a very interesting contrast between how humans think and how perfect Bayesian reasoners think. And I think like Elia is actually at a point to doing that.
I don't know, maybe I'm wrong. But he does point out in this that if you have like enough evidence to find this hypothesis and hypothesis space that you need like a huge amount like he said 27 bits.
From a Bayesian perspective, you need an amount of evidence roughly equivalent to the complexity of the hypothesis just to locate the hypothesis in theory space.
If there's a hundred million alternatives, you need at least 27 bits of evidence just to focus your attention uniquely on the correct answer.
So like for a Bayesian reasoner, you need a lot of evidence.
And so you would be really sure that once your attention has been drawn to one particular hypothesis out of several hundred million that you've got the right one.
But like I don't think humans necessarily work that way.
Yeah, at the end.
Since the human brain is not a perfectly efficient processor of information, Einstein probably had overwhelmingly more evidence than would in principle be required for a perfect Bayesian to assign massive confidence to general relativity.
And he just didn't even use a number there.
So just a lot.
He does say that.
I'm not sure.
I don't know, because I think humans cut out a lot of steps and will give probabilities too high of a weight if they, you know, if it is convenient for them.
And I don't think any human would really consider 100 million possible hypotheses.
They already start with a vastly curtailed hypothesis space.
So I don't think a human.
I think an average.
But this is Einstein.
He might have had a lot of evidence.
For a lot to put anybody on a pedestal, it's Einstein.
I mean, I think the difference that kind of comes through in the post is that it just matters really drastically.
Like your perspective really matters a lot.
Like, I don't think it is it is bad for someone to ask Einstein to provide more evidence if they are not convinced, because of course, like, they don't have that those bits of evidence.
And I think there's kind of this.
I find this part of when I think about how science works, I find it very interesting that like, in particular in substantial parts of modern science, it's like very hard to have your internal credences diverge very much from what you think your public credences are.
Where like, it's very hard to be like, I am 99.99% certain of this.
But like, I think you should only be a 30% certain on this.
This is like a very like complicated mental operation and like verbally very hard to get around.
We're usually like, when I say that like, this is 99% likely and kind of asserting that you are also supposed to believe it is 99% likely.
And like, then if the other person is like, what, I don't think it's 99% likely.
We don't actually have a lot of like very elegant scripts to be like, Oh, I think I have the relevant evidence, even though you do not.
And I think a way in which like science has, has helped with this is kind of to make it so that like, when you assert confidence to something, you kind of assert the confidence that is known for the complete audience that you're like, like that, that is kind of like achievable via consensus of the scientific community or the full
audience you're talking to or something like that.
Okay.
So when you say that something is 99% likely, I think what it usually gets translated to is we have a set of evidence that we can all agree on that, like, makes this hypothesis 99% likely, which is supposed to drastically for a statement and saying, I think I have evidence that makes this 99% like
And I've recently been thinking about this where I was just walking home yesterday and I was mentally, I don't remember how I got into that, but I was mentally analyzing my internal affect for how I would react to a bunch of sentences prefixed with I think versus not I think and how drastically those changed
my, my affect towards them, like I was like,
So, um,
I think sounds so much less confident. Like, it's weird, because if someone says I believe if you know if you're talking to a and I don't want to put words in your mouth, but for myself, like, if I if I'm talking to Inyash and he says I believe this, I'm like, okay, he's really sure about that.
If I'm talking to, I don't like my mom, she says, I believe this happened. Like, that sounds way less sure than if she just said this happened.
Like, it's, it's a so like if someone says, Oh, I think this is it rather than this is it.
To me, it like cuts my confidence what they're saying and they're, I think we're trying to communicate the confidence what they're saying like it just cuts it way down.
I remember when I first started writing, I was still in the habit of speaking kind of like a rationalist, and that actually makes for terrible writing because we often couch things with I think I believe and this stuff.
And the first thing you got to do is get rid of all that unless you're specifically writing a character who is.
Didn't you didn't you want all of this important epistemic information about my epistemic state.
I just wanted to know what you were thinking about today.
This was so much more accurate before you asked me this.
So I do think it's not sorry.
I just sort of on the side.
But there's this book that is about a girl with OCD and I really related to this one of my childhood books because I also had a CD and it's the first time I ever actually saw it portrayed.
One of the things that she does is when journaling she realized that I can't ever be sure that something is true so she would start every sentence with I think.
And then this became a ritual where she would write just a bunch of I think I think I think at the top of the page.
But then that didn't feel good enough.
So she like took the words I think and made them into a symbol and then would draw the symbol repeatedly around the page.
So it's a really really make sure that she wasn't claiming to know something that she maybe didn't know.
And it would be things like I think I went to school today.
I think there's a lot of interesting neurological stuff from that.
But anyway.
What was the book called?
It's called growing any way up.
Okay.
In case anyone wants to read it.
Yeah, it's like a YA book but recommended it's really I thought it was really interesting.
Yeah.
Yeah, so back to one of the other points that we were talking about.
I think it is important for like healthy communities that are either intellectual or scientific communities or even like.
Building communities that like trying to build useful things like startups.
This is an important point to realize that people can have a lot of evidence that you do not have and they can be much more confident in a thing than you can be.
And not have norms where this is like inappropriate or something.
I think it's often the case that, you know, small teams of startups have like interviewed like hundreds of users and understood like a pretty accurate model of what problems are facing and is like tested trying to fix a little bit and making a prediction about how it would go and just being validated to the point where they
just have overwhelming evidence that there is like a product here that a lot of people sort of want to use.
And then they're very confident in their business, which out from the outside, I think people often call it kind of overconfidence.
Whereas I think you can just in fact, similar to Einstein here, although not exactly the same methodology, reach quite a high level like get quite a lot of evidence about a thing, but not in a way that is like easily communicable in like a short conversation or something.
Yeah, like I find it interesting about the I think distinction there's just like, I think English was just like well it kind of communicates a different level of credence but I find it very interesting that I think actually even when you explicitly
include the credence, my internal reaction to it is still drastically different where like the statement like that's at most 50% likely versus the statement I think that's at most 50% likely feel drastically different to me.
Yeah.
Like if you come to me in a conversation and say that's at most 50% likely, that sounds to me like you're asserting that we both are supposed to know that it's at most 50% likely.
The second one says this is my belief, this is what I think.
I do observe when you said that my internal responses to the two with the person who said, I think that's 50% likely. I was like I had some impulse to like asked about how they were viewing the thing and like get a better understanding of their
perspective or share a bit more of mine. And the person who said, that's no more than 50% likely. I just want to offer them a bet.
I can't help it. Well, I was going to digress a bit with the annoyance of trying to get some people to agree to bets but I find that people who aren't raised with the or who aren't raised necessarily but who aren't having adopted the like mentality of sticking your
out to defend a belief. If you offer them like, I'll just give the brief story. My manager was, for some reason brought it up like twice in a week. He wanted to say like, there might be some legitimacy to the false election claims going on.
And we should really just sit and you know, none of us have all the evidence. I think it's putting worse, you know, paraphrasing. I think it's epistemically humble of us to just kind of, you know, wait for the information to come in.
And I was like, I tell you what, I'll bet you $500 tier 50 that it comes out this way. And his response. Oh, I don't bet. I'm not a gambling person. And I'm like, you don't want you don't want $500? Like then, I mean, come on.
This has been one of the benefits of having prediction markets is that all of my housemates and friends have just been making money up.
Oh, yeah, it's been so insane. I'm so confused. I have so many thoughts on this.
I mean, you've seen there's been a bunch of prediction markets still sticking like until I think the last couple of days, but still for like a whole month after the election, put it at like 12% that Trump is still the president.
And so I think it just a bunch of my friends have put in a couple of thousand dollars into all the different prediction markets and just been making money.
Which is how I learn how to do that.
Isn't that technically not legal?
No, there's some legal prediction markets. So predicted is legal. And there's one other one that's legal in the US.
Okay, that's what had been stopping me because I kept hearing that betting on election results is completely illegal in any way.
No, definitely predicted has a specific. So I have looked into this good amount because one of our good friends, Jacob, who like currently is collaborating a bit with less wrong has a he is for a while been trying to get
No action letter.
Yeah, no action letter from the FTC, whatever, whatever the thing is that's supposed to like limit like betting and various various currency related things in the US.
A letter that like is the thing that predicted God that allows him to run a betting market on various interesting things.
And so I've read a good amount about all the regulations in the space because I've been thinking about things.
Okay.
That's a good update to have.
But I'm sorry, Jason, I think you were going to ask a question.
I was curious what like what things he wanted to include as things you could bet on, but also realized that we made we should like get through the first sequence.
Fair enough. I'll just I'll hold us up for one more second. What was the name of that website? You said predicted.
Predicted. Yes.
Just predict it.
Gotcha.
Well, I need to start making some money. So I'm going to bookmark that for now.
Can I hit one last thing on this post before we move on?
No, of course.
That was not an answer I was expecting.
It reminds me of the time we met with Robin Hansen. Remember, he came out to dinner and like the third time I started a like a topic with him.
Hey, can I ask you something? He was like, you can stop asking me that because you always.
Like he said it really nice, but I was like, oh, man. Yeah, it was a verbal tick of mine when when it's like someone I really respect.
I was like, oh, I don't want to use your time. Can I ask you this thing?
But no, the thing is, there's a post later on, which always never quite sat right with me where Eliezer says that a very powerful true basing predictor could come up with the theory of reality.
The probability of watching just three frames of a video of, I believe, a water drop falling on and bending a blade of grass.
And he said if it was powerful enough, it might be able to do it with just two frames.
And like that always seemed really ridiculous to me.
But reading this, especially at the end when he says that since the human brain is not a perfectly efficient processor, Einstein probably had overwhelmingly more evidence than he would need in principle.
Like maybe the more I think about more like maybe in three frames of video, you can get 27 bits of information.
And if you were a obscenely powerful, Bayesian predictor processor, maybe you could get general relativity out of that.
And that's what he was setting up with this post on Einstein's arrogance.
Yeah, I've been that far experiment is one that I've actually been thinking about for like basically the last decade, just like at least once a month or so.
It's been like one of the big ones.
And I've had so many disagreements with lots of people I respect on it who think that the number is much, much, much higher.
And even like, like I think I had at one point a disagreement with Luke Milhauser, where he thought that it was pretty likely that maybe not a perfect Bayesian predictor, but at least anything we're going to get in the form of AGI or something to that, still has probably will have to run experiments in order to like figure out to write like model.
Like at least extending beyond relativity or something. And I'm, I still think that's wrong, but it's like definitely I've talked to many people I respect to who disagree with kind of that free frame number, at least in the AGI case quite a bit.
It feels absurdly low to me, but I am no longer at the point where I think it's obviously wrong. Like it could maybe be possible.
It reminds me of, I think the guy's name is Douglas Hubbard, who wrote How to Measure Anything, which is a cool book I read as a teenager. And it's, there's one example in that which always stood out to me, which was people often talk about how you need more data and lots of data before you can like feel very confident about
hypothesis. And he was sort of counterintuitively making the claim that like, the first data point is most of the information you need. And his example was about guessing the weight of jelly babies. And if you went to someone like me, for example.
What are jelly babies?
Or sorry, jelly beans.
I'm really reminded of Free Worlds Collide, oh God.
It's like a jelly embryo, really. It's a baby at four days of gestation.
Do you guys not have jelly babies? Is it just a British thing?
Well, they look more like beans than babies to us, or to me anyway.
Well, no, you make them little bears or something. Anyway.
We have gummy bears.
Okay, well, ours are.
They actually shape the exact terminology of the sweets.
I really want to go to Britain and just eat jelly embryos.
Oh, God. Yeah, sometimes this is horrible. Sometimes our housemates just like, I think Daniel Phylan, who's from Australia, just particularly much.
Well, he just asserts that something is completely normal in Australia.
What I cared about in Australia, I would just believe it, regardless of what it is.
Is there an Australian thing that started out that way that's like, I didn't come here to wrestle spiders or something?
And have sex with snakes? I can't quite recall how it ends.
All right, I'm going to go with jelly beans.
So you're like, what is the weight of a jelly bean?
And if you're like me, who has not done much cooking for myself, I don't really know how much things weigh.
Or I certainly didn't when I was reading the book.
And you're like, is it 20 grams? Is it two grams? Is it 200 grams? Is it 0.2 grams?
I don't know the right order of magnitude for this sort of thing.
And then if I give you the first jelly bean and you're like, this is 15 grams, you're like, huh,
I think I have a pretty good guess of what the next one might be.
I've zoomed in on roughly what order of magnitude, I guess.
And maybe you gave me a weird one that was like a broken piece of it and you're a bit wrong or something.
But I think often the first data point can orient to just what order of magnitude or ontology are we even talking about.
And so I have some sense that like, like I've not really lived in any other like physical universes
and I don't really have much intuition about what they could exist, what could exist.
But if I had thought about what sort of physical universes could exist or something and like what physics,
what the space of physics is, and then you just show me a thing falling,
I can imagine going, oh, we're in that kind of universe.
The sort where the things are attracted to each other with this sort of rough like,
I can see the Pfizer thing the water droplet fell to.
I can see the size of the water droplet.
I can see the way it like bent over one frame, which tells me a bit about the fluid mechanics.
I can see, you know, I can see that there is like things of a certain level.
I can see what level of organization we're on with like how many levels of atoms or something you're going on.
And so I don't feel confident either way about how surprised I could feel for the first time watching the physics of universe player
and therefore how much I could update on it.
So I don't have a strong opinion, but I don't feel confident that it's not two or three frames.
That's a damn good point.
If you don't even know what sort of universe you're in, those initial frames are going to give you a huge amount of info.
Yeah, and I just, I just don't know how much because I don't know.
I didn't have a prior coming to this universe very much.
Yeah, I don't know how many self consistent theories of physics they are that are like close by two hours.
Like, it's possible that they're just undead many and it's like, well, if you actually write down like, of course they infinitely many,
like actually like try to like order them by complexity and you're like, well, I don't know, like they're only like there's a bunch of ones,
like the only self consistent universes that like can support life actually have like one of these like maybe 100,000 options.
And just like this one really looks like it's in it's one of these.
All right, well, shall we move on?
I come through.
Oh, I actually I did want to add one thing in about predict it. Sorry, I just didn't want to give people bad investing advice.
You should Google a couple of posts unless wrong. I think it was even one of the last year about predict it because the main thing that goes wrong is you can often look at a predicted prediction and think that's wrong.
But the issue is there's a lot of transaction fees such that if you were to try and make money on the on the very small margins or something, they would actually charge you more money for trying to make the transaction such that it would not be worth it.
So there's some difficulties there. So don't just if you see a prediction that's a little bit off, don't immediately expect you can make money.
I would look into it a bit more.
The one that the top one here under US presidential election is that 95% 95% is the has the Democratic Party winning that the presidential seat.
I'm imagining that there's more than a nickel on the dollar for transaction fees unless you're probably betting a lot right.
So the problem is you can't bet a lot. That's the thing that makes predicted legal is that the cap the bets are capped per person that I think something like 500 something between $505,000 of sticks.
To me, that's a lot.
Yeah, I just, oh yeah, you couldn't bet, you know, several figures of income on it. But yeah, I get you're saying is that per bet or like per month.
I think it's like your total stake you're allowed to have in the market, like how much money you're allowed to have tied up.
Oh, okay. Yeah. And if you're like making five, 6% margin, that's not nearly enough to live on.
Yeah.
All right, that was my point about predicted three talk about sequences for another 50 minutes and then wrap up the podcast.
No, that's great.
Thanks for clarifying that actually that's good information.
And then Occam's easy.
Are we ready for Occam's easy.
Yeah, let's do it.
Go ahead.
Yeah, no, you did.
Okay, well, I was going to say, just a real quick recap of Occam's razor. I'm assuming everyone already knows what it is, but for anyone who may have missed it, it is the the heuristic that the simplest explanation is usually the correct one.
And the one that you should go with it, I believe, formerly it stated something like one should not multiply entities unnecessarily or something.
Okay. And in the post, a laser says that the more complex explanation is the more evidence you need just to find it in belief space is kind of his version of that.
And he said that Occam's racers often phrased as the simplest explanation that fits the facts is the definition Occam's razor.
And Robert Heinlein replied that the simplest explanation is the lady down the street is a which she did it.
Which on the face of it, you know, seems to be the simplest maybe, but it hides a lot of complexity within the sentence that we just don't think about, because there's a lot of labels in that sentence that have stored complexity in them.
He pointed it out that we could shorten the entire sentence just to a sequence of a few letters and say, look, it's even shorter. Does that reduce the complexity?
And no, it doesn't because the audience already has to know what those few letters stand for.
And in similar way, like which itself is a label for a lot of extraordinary assertions.
So just because we know about a concept that doesn't mean it's actually simple. And in fact, the human brain is the most complex artifact in the known universe.
So positing a human brain as an explanation for something already has a lot of complexity built into the answer.
Yeah, I've definitely like, I was confused about that post for a while. And I made some confused questions on this wrong, like three or four years about it.
Because I think the post really is two very different things. And I totally got them mixed up at some point, where the two things the first thing that it asserts is that many concepts that humans think of as simple aren't really simple.
And I think that's a point that's actually pretty hard to make. That requires a bunch more additional justification that totally the post doesn't do.
And then it makes a second point that's completely separate from that, which is that an explanation needs to actually reduce the complexity of the remaining data,
which is something like, if you want to give me an explanation, after I have like, you've given me the like, like the ladies down the street is a which she did it.
The thing that he's totally separate point he's making is that like, that doesn't tell me that the sequence doesn't come out like a b c d e.
I like still have to say that because actually like, having heard the first half of the sentence of like the lady down the street did it.
Like, doesn't actually help me at all predicting the sequence. It gives me like zero Bayesian evidence about the sequence.
Yeah, you're right. This should really be two posts.
And I think the first one is actually kind of hard, because there's this really real objection to to the to the flavor of Occam's razor that Eleazar is proposing here.
That like usually goes technically under the name Salomon of induction, where you have this this giant free variable.
That's the choice of universal Turing machine.
And he talks a bit in a post about like, well, you can choose universal Turing machine however he wants.
But I've actually found it like a pretty hard thing pretty hard to wrap your mind around.
Because just like, indeed, just like, there's nothing in the laws of physics and nothing in the laws of reasoning that we know of that means that we can't use like,
witches as fundamental units in our programming language.
Like, I can totally write your programming language that like, I choose as my universal Turing machine that has like, simulate a like, universe with a single witch in it and an empty wide room.
That's like a print like it's a primitive at the same level like let's say instead of like, we have Python, and we have Python plus and Python plus is all of Python, except it has to which command, which allows me to type in which open
parentheses sentence. And then what the which command outputs is a string that is whatever the which response after I simulate her in a like, large like infinitely large wide universe with a booming voice speaking down the string that I input into that voice into
that void. And that's like a language that is like, I can use that as my universal Turing machine. And now suddenly which is a fundamental concept. And now we need to argue for some reason that that is an elegant that that is a wrong that that sounds like a really
really weird choice of fundamental entity in my programming language. But there's all arguments that have to be additionally made.
I wait, I don't know, I don't think I could agree with that because I mean maybe he should have made a post about what a Turing machine is but like a Turing machine is the simplest possible way that information can be processed in concept, like you would have to have
some way to simulate a which first and to do that you would need something equivalent of a Turing machine because information would have to be processed to simulate anyone right
So the like a Turing like, when you think of universal Turing machines, usually what like the key question is what is the ontology of the thing that you are described like of the of the language you're writing in.
I do really think it's very useful to just think of programming languages Turing machines like that's like, I find that much simpler to think about as opposed to weird thing that Turing wrote down which is like this weird, like robot that like slides on a tape to the left and right.
And we know that every universal Turing machine can be modeled as a simple programming language, and that every programming language can be modeled as a universal Turing machine with an appropriate translator at the beginning of it.
But a Turing machine at its simplest is just a way of storing information and then doing things to that operation, doing operations to that information to change it into a different type of information.
You can't really have any simpler form of information processing right.
I think that seems right.
I think, by the way, I am totally confused about it. I was like, oh, I'll come straight up. I notice I feel really philosophically confused about it. And then we talked about it for five minutes and I feel basically as bad.
Certainly, I think with a Turing machine, you can in principle run, I think, the very costly computation that Ali was describing where you could, with enough space, you could simulate or emulate or compute what would happen.
You'd like specify the physics and you specify that there is like a witch in this void, and then you like output some translation from whatever the like physical vibrations are in the universe to a set of ones and zeros and have that be a part of the output of the Turing machine.
Oh, absolutely. I think for me that the idea of having like a witch function and then calling that simple like the meat of the witch function, you know, you go into define it, like all of that's going to be enormously complex, right?
And so I think.
The problem is, in that moment, you're begging the question. When you say that it is enormously complex, what concept of complexity are you using to assert that?
Oh, nice. Good point.
Well, there's a complexity that is grounded on the idea that you already have some programming language in mind that measures the complexity of that hypothesis.
But the whole point of someone of induction is that, well, you need to first choose a programming language in which you measure complexity.
And so there's a separate thing of just like elegance where, well, like it's kind of like humans have some shared intuitions of elegance and that points towards some natural choice of universal Turing machine that makes stuff like, well, we just going to like have a witch function.
Sounds really dumb. But I think now we need to argue from that intuition as opposed to arguing from some kind of mathematical truth.
I see what you're saying. Yeah, I guess what I meant is that the witch function wouldn't be brief in what it did.
I mean, so I don't know if that's the exact same thing as not complex, but I can't imagine the model of this, of the witch function being like, you know what I'm saying?
It's just a brief. You know, it's not going to be like adding two numbers or rolling a die. I guess it depends on what the witch function does.
If all the witch function does is, yeah, well, within what bounds, right?
Does it turn random villagers into newts? Or is it just lighter than a duck? If it was just ways less than a duck, then that witch would be super easy, right?
So I do have a hard time imagining, and perhaps this is like the root of where my intuition comes from that some things are simpler.
I have a hard time imagining creating a programming language where it was simpler to simulate a witch in the universe in chat with her and get her output versus, you know, writing some if statements.
I feel like both in terms of like the programming language and the like hardware, like the actual amount of hardware I would need to compute one of them versus the other.
Kind of. I think this is, I actually think modern neural nets provide like a really useful intuition pump here, and added like more people are familiar with them.
Like neural nets are kind of this archetypical example of in the space of like neural net programming languages, it's actually kind of hard to end up with one that's just like really good at reliably adding numbers.
It's like, I get what you're saying, but like the the biological neural nets that we were familiar with before DeepMind were human brains, which as stated, were one of the most complex artifacts in existence.
And like the the computer neural nets we have nowadays are not simple either they they take, you know, massive.
Yes, I don't even know the correct order of number to say how many bits they use up, and they are not not understandable by us is due to how complex they are.
They're simply much more, much more complex than the laws of physics, for example, which can be encoded in surprisingly few bits.
Well, no, like that's you did the statement can be encoded and X number of bits does not have any mathematical meaning.
If you don't specify a programming language in which you're counting the number of bits.
So you like you can't say that the laws of the universe are generally encodable in such a small number of bits, you need to say generally encodable in a small number of bits in this programming language.
Well, I think that's why he brings up the universal Turing machine because that one has simply, you know, bits of zero and one on off that can be manipulated into, you know,
But there's an infinite, there's an infinite number of universal Turing machines, all of which will use different ways of like, like we'll have different description lines.
And the core insight is that you can write a translator between any of them.
You can write a translator between any programming language that is Turing complete and any other one.
And a Turing complete programming language will have an associated universal Turing machine.
But of course, the space here is infinitely large.
There isn't just like one universal Turing machine that is handed down to you.
There's an infinite class and Python, which has to which function is an element of the unit class of universal Turing machines.
It's just like you can grab it in a puzzle Turing machine and there's the one that has to which function.
I guess I don't get.
I feel like I feel somewhat compelled by the idea that in general, it is not clear to me which Turing machines will be simple to compute in my universe.
I do feel like my experience of my universe.
I don't know that yours is that, you know, a couple of statements and a couple of loops can be run with far less physical matter.
That's a really interesting inference to make.
But it also has a really weird amount of circularity where like you're trying to use a monofinduction to determine what the physical rules of your universe are.
And then you're trying to use your model of the physical rules of the universe in which you're in in order to determine which choice of universal Turing machine is the right one for your monofinduction.
And you're like, well, is that valid or not?
My current answer is I don't know.
I feel confused about this.
It does get pretty circular.
Yeah, it's interesting.
It reminds me of Abram Dempsey's got a great post on Lesserung but I think came out this year called an orthodox case against utility functions where he does make a case that a lot of the way we standardly think about utility functions and so on is from the perspective of the universe.
Like you have all of these different like laws of physics and arrangements of matter and we have a function from them to states of utility.
And he offers a quite different model where which is from the point of view of somewhere or someone who is like part of the universe where they don't really understand the rules and they're like gradually splitting up their world model into different high level chunks.
And it, I don't fully grok it and potentially I will rock it better than I do.
But it's, it's something that I think tends tries to grapple with this question of some of the circularity of trying to say, I didn't come into the universe knowing which universe I was in.
And therefore I didn't know which sorts of program languages were simple to run in this universe.
And as I have explored it a bit more I have come to that sort of conclusion and I have fed that back into my expectation of which further hypotheses are simple versus complex.
Yeah, the other thing that I think is really important to point out epistemologically about the Occam's razor post is the fact that like I actually am not that sold on the complexity prior on its own.
Like the obvious other prior that you might want to have is the speed prior.
Like when you have like when you run a Turing machine or just a program, they are like two major facts about the program.
Number one is like how long it is, and number two is it how much compute resources does it take.
And in a bunch of places in the sequences, Eleazar basically asserts that well just the length of the program matters.
But he doesn't actually argue for it very well.
I think it's totally reasonable to be like well I want to buy programs.
I like assign higher probability to the programs that like both give me the correct answer and give me the correct answer reasonably fast.
And actually I just have a speed speed penalty for any program that takes like aeons upon aeons, 10 to the power of 10 to the power of up arrow, up arrow, up arrow, three years to give me the right answer.
The key point was Adam's deep mind.
Wouldn't it be basically a the length of the of the program is a function. Well, the other way around the speed is the function of the length because in at least in a universal Turing machine, you can only execute one instruction at a time.
So the more instructions you have the longer it'll take to run.
So are you familiar with the busy beaver number.
Oh, it's been a long time, but vaguely yes.
So busy beaver is the number that the length amount of steps that a universal Turing machine of length n can take at most.
So the longest running machine that terminates of a given complexity class.
And those are really, really, really, really big.
They're usually like in when people talk about fast growing sequences to busy beaver numbers among them.
Well, like for like, I don't know, I know that the busy that I think we know busy beaver three but we like busy beaver four no longer fits on like our hard drives and busy beaver five is like much, much larger than could ever be represented in the existing known universe.
I might be wrong here by many orders of magnitude is very easy to be often.
But it'll be why it's called busy beaver.
I don't actually know, I think it's just kind of, I just imagine it as like, I don't know.
I just have my head cannon, which is just that it's like, I associated with a small beaver that does a lot of work for a really long time.
And it has a somewhat cartoony aesthetic and it gets really exhausted after doing this for Aeons and Aeons.
But I do not know if it was the head cannon that people had when naming that.
Yeah, it goes for, I think it there is a bunch of different ways you can set up the problem.
But for the one where you have for one of them with a two symbol, it's a two state Turing machine.
It can go for six for three state, it can go to 21 for four state and give 107 for five state and go for 47 million 176,870 for a six state.
And it goes for 7.4 times 10 to the power of 36,534.
And the seven state goes, the seven state goes for 10 to the 10 to the 10 to the 10 to the 18,705,353.
Can I say a random silly thing about the speed prayer?
Daniel Phylon, who is surprisingly now a housemaid of mine.
Well, I guess you maybe shouldn't be surprised. It's only of the last month.
When I was at Oxford during my undergrad in my first year, he came and he was looking for a place to stay and I gave him a space in my room for free for like a month while he was visiting FHI.
And he had a poster created and mailed him in one of those tubes for a presentation because he'd just done some work on the speed prayer.
And I think it arrived a couple months ago.
He just never arrived him and it's been four years and then a recently got an email saying some posters right here.
His paper on the speed prayer was the slowest piece of mail that he has ever received.
Order it from.
I do not. I mean, I guess maybe we should make updates about academia's speed.
So I have a question about this.
Like I didn't find it controversial that laws of physics are are easier to to model on a computer than a human mind.
And so like I found that part relatively like a skim past it.
I was much more had a much harder time figuring out the the last part of this post, which seems to be the opposite for you guys.
It says near the end here that if someone says the lady down the street is a witch, she made the sequence come out 01010101.
Your excuse your accusation of witchcraft wouldn't let you shorten the rest of the message.
You would still have to describe in full detail the data that the witch recalls.
So even after you say which since you start to describe the detail and fill data you have not compressed the total length of the message describing your observations by transmitting the message about witchcraft.
You've simply added a useless prologue increasing increasing the total length.
The real sneakiness was concealed in the word it a which did it a which did what my question is like what what does this mean exactly?
Why is the compression of the total length important?
So I like going back to the so we had a question of like, okay, I show you free images and you're trying to derive what the laws of physics are.
And there's like a question of and he said this thing of like, okay, you need 27 bits of evidence in order to like hone it down from a set of 100 million million candidates.
But what does it mean for an image to have 27 bits of evidence?
It like obviously has many more like an image like usually if it's like 1000 by 1000 will have like at least 100.
Well, I know at least 1 million and probably at least 3 million because of like color information and various stuff like this, and probably also gradients and stuff like this.
So the way I would imagine it is like, when you look at the first 10 pixels of the image, how good are you at like, how much better are you at predicting like the rest of the image or more concretely like the world like the laws of physics that you're trying to predict.
And you can check.
And that then after looking at the first 10 bits, you can ask yourself what message what information content did that have how many hypothesis did those rule out.
So similar for the which one you can ask is you can look at the first four words and say the lady down the streets as a which she did it.
And you can ask yourself, okay, after I heard those sentences, how good am I as a perfect vision predictor at determining what the correct sequences that like I'm trying to predict.
And you hear those words and you're like, well, none.
Yeah, not actually know this has given me indeed zero information about it.
And but if you and if you if you change it and say the sequence was X, the lady down the street is a which she did it.
And you ask yourself, okay, I first read the first, the first, like the first 10 characters of this of the sentence, how good am I at predicting sequence.
And you're like, well, I have the sequence.
I that's it.
I, I mean, I'm there.
And then I give you more words and you're like, well, okay, that clearly means that those words must be duplicates.
They can't give me more information about the hypothesis earlier.
And if someone gave you just the sequence, you couldn't derive the lady down the street as a which and she did it from that sequence.
Yeah, even though that's not another necessary requirement, you might have it like you did this, the party hypothesis don't necessarily need to be like correlated to each other.
You could.
But it's also like, I do think that if it is usually the case that for good explanations, part of them will allow you to explain other parts of the explanations, but I think there's more to do with explanations than perfectly predicted.
I guess I think that maybe speak a little bit more practically to my experience or something.
I think often a good explanation helps me.
Often I think what I implicitly mean by a good explanation is something I can think about.
I can use to think about a phenomenon without using up all of my working memory slots or something.
This is a very human answer or something, but I can imagine trying to get through a maze and you could be like, you need to go left, left, right, right, left, left, right.
And I'm like, okay, I'm not thinking about anything else for the next 10 minutes while I follow those sequence of instructions.
But then if you give me just always use the left hand rule and you'll be able to get out, which admittedly I think would be left, left, left.
I'm not quite sure what it looks like, but I think that could help me think of it in a much simpler way, whilst then being able to think about other things at the same time.
I think that's an example.
Yeah, I guess, thanks.
I guess it's not a, sorry, go for it.
No, I was just saying, I might steal that example at some point.
Yeah, I think often good math research often looks like this where they're like, oh yeah, we had this real complex model, but I've just turned it into a, like,
yeah, I think, yeah, when like,
first time you try and understand something in linear algebra or something, you're like, if I wrote it down in words or something, it would take me pages and pages and pages.
And then you can just get it down to a point when you, if you have the right concepts, you just write like three lines or something.
And you're like, oh yeah, I roughly get how the system works.
And I can like manipulate these sort of symbols and these sorts of ideas with some others.
I don't know, Ali, do you have a practical example?
I feel like mine were either too abstract.
That kind of explains the programming language thing too.
Yeah, yeah.
Where if you were to like write out in English, what this program was doing, or I go levels down deeper if you're using Python, like, yeah.
Yeah, I agree.
I was like, starting to understand bits of it.
I still feel like there's stuff going over my head, but I'm glad that we had you guys on for these sequences.
Oh, yeah.
And he actually said a text the other day that was just like, I'm serious.
He wanted his hired help.
And I like, it's like, how could it be?
I remember reading this and I like opened it and I was just like, oh yeah, that one.
I feel like I sort of missed the point on this post because I have a, I think a good working intuitive version of Occam's razor, which is just like, I mean, if I give you an explanation for how the engine in my car works,
and then someone else gave the engine, the description about the engine for my car works, and it was the same except they said, and also little invisible fairies push the pistons.
In addition to the, you know, the, the combusting gasoline, like Occam's razor told me no, I'm going to take the one without the fairies because it has an additional stuff on top of it that I don't need to explain this.
And that even leaves aside the point that like the fairy thing is really complicated, right?
Yeah.
And I think, and it's, and there's like another, the kind of close by intuition is it just didn't even help me think about the thing throughout the fairies.
Never mind that I know that fairies are kind of magical.
It just like didn't, I already understood the engine and I already understood how to interact with it fully or as well as I could.
And you like didn't help me by adding this extra thing to what I had to think about.
Yeah.
But I think the key thing that I think this post us is it gives you the, it allows you to handle the situations where, well, but like, it's not impossible that they are fairies, like not literally absolutely impossible.
But now you have to answer the question of, well, how impossible.
Like, and that's actually a really hard question that like philosophy for like, I mean, in some argument, like some could argue still not, but like philosophy hadn't had an answer for for like thousands of years.
We like post outcomes razor and we were basically like, well, the simplest one seems like the best one.
But we didn't have the language of probability theory.
So we couldn't tell you how much is the simplest one, the better one.
And the thing that he says in this post is, well, he has come very concretely.
If the thing adds this many bits of information, then it's in larger complexity class and therefore each additional bit of information must cut the probability that you assigned the hypothesis into two.
And it's a very precise answer.
That's very nice.
And because fairies is a very complicated additional piece of data that makes the probability much, much, much lower.
But if somebody were to give just give you a very slightly different explanation of it, of an engine that maybe only is one or two bits longer, then you still have to assign substantial probability mass to that being right.
If it fits all the facts as well.
Okay, yeah, fair enough.
I like that because you're right.
I think I chose to out there example the fairies, but I could imagine it's really satisfying to combine those two things where like, I think of great explanations.
It's usually being like two separate phenomena.
And now we have this thing where like, oh, I have this example that makes it so like if I if I pass it to fairy thing, it seems like that's really that's that sounds really dumb.
But if I pass it a thing where somebody gives a separate explanation, that's just a bit more complicated.
It doesn't sound that dumb.
And now we have a single formalism that explains why the slightly different explanation still has some probability mass, whereas the fairies has basically no probability mass.
Basically kind of know that there is a exponential relationship between a number of additional bits and the probability penalty it needs to get.
And that's like a really powerful intuition that we like because it takes these kind of two phenomena that didn't exactly know how they were related and combines them into one really elegant explanation.
I love it.
Yeah.
No, that's a really nice way of putting it.
Yeah.
I was, I was going to segue us straight into that's kind of like for me Occam's razor 2.0 speaking of 2.0 is let's talk about that's wrong 2.0.
We do have to quickly say what postword reading next time though. Exactly.
That's why it wasn't a good time to drop it.
We've got to say what we're reading next.
Real quick.
Did anyone have last words before we move on?
I'm good.
Okay.
Then for next time, the post we're going to be reading is how to convince me that two plus two equals three and the bottom line.
That's such a great like setup for next week because anyone who's not read that is going to feel a bit shocked.
It reminds me of this is a bit of a tangent, but Nick Bostrom once went on the Sam Harris podcast and Sam Harris went through Nick Bostrom.
They went through three papers by him.
And there's such bizarre concept and ideas in his papers.
And I remember the first paper was it wasn't the great filter.
The first paper was about the vulnerable world hypothesis where he talked about the need, the potential need for certain amounts of global coordination.
And it got Sam Harris to say the sentence, you know, if China or North Korea or a global dictatorship came down the next day, it's interesting now that amongst all the terror and horror, I would now after reading your paper see a silver lining to this Nick Bostrom,
I was just imagining Sam Harris's readers going, what the heck did he just say?
And then his next paper was on the simulation argument, which was had Sam Harris like assigning like actual probabilities or something to the possibility that we're in a simulation with an external power that's like playing the game or something.
And I just, and then he finally turned to Bostrom's third paper, which is a great filter paper.
And he said, and so your next paper is about aliens.
I just imagined the audience going, I don't think I'm ready to hear what Sam Harris is about to say about aliens.
So thoroughly, I just had the same feeling when you were like, next week, we're asking how you can convince me that two plus two equals three.
I was like, I don't want to know.
Brain damage.
Well, now there's a much better case than brain damage.
We should use Steven Segway now to talk about more less wrong posts, but of a different variety.
That's right.
So we talked a little bit earlier about less wrong 2.0.
And I remember getting the email and checking out the site when it first came out.
I guess at the top level, what separates less wrong?
Or is it separate?
What is the difference between less wrong 2.0 and 1.0?
And yeah, start there.
Yeah, I mean, the big thing is really just kind of when you look at a history of less wrong.
I think, I mean, kind of Eleazar started writing an overcoming bias.
He then moved to less wrong.
He increased like created kind of a whole community on there.
But then sometime around 2012, 2013, he kind of disengaged and a bunch of other people kind of started interfacing essentially less of less wrong.
And I think like pretty visibly over the years like 2014, 15 and 16, things kind of declined, even just like in very boring and obvious ways, like we just had a lot of spammers.
At some point, we had to turn off down voting because we had someone who like was down voting everyone, but we couldn't ban them because Reddit, like the thing was forked off of Reddit and the moderation tools weren't good enough.
And so it kind of had all of these problems.
And at some point, me and me and Matthew Graves Vannevar on less wrong kind of sat down and were like, well, we should fix this.
And he was officially declared benevolent dictator of less wrong for life by Eleazar and other people.
So he kind of felt like it was his job to fix it.
So we sat down together and decided on a plan.
And I had run a small web design and web development company in Germany before and had studied computer science at UC Berkeley.
And so I seemed like I hadn't that much experience with like building things like less wrong, but I also was like another horrible programmer.
And so we just decided to kind of restart everything from scratch in terms of code and in terms of the underlying architecture and really build it into a site that fell to me like,
would both enable to revive less wrong in terms of activity and trust in the system and the people being active here.
And technologically just make it so that, you know, it didn't completely break on mobile devices, which was a bit sad for a few years because the whole website was built on mobile was even a thing.
It looks so much more sleek and modern.
I had that nice minimalist design.
I got really excited when I saw it.
Even before anything was really working and it was just sort of the landing page with some text and I was just like, yes.
Yeah, the UX on it is nice.
It's pleasant to navigate, pleasant to look at, which shouldn't be a huge filter to keep people away, but when it doesn't hurt to use, that's a big perk.
It makes it pleasant to use.
I feel like you kind of breathe this like a sigh of fresh air coming off of, I don't know, BuzzFeed or wherever else.
It's just clean and minimalist and you can see where all the things are and what they do and it's like, ah, I want to hang out here.
So this is just completely random, but where did you get that picture for the new less wrong and what is it exactly?
Yeah, so I think I discovered it probably Huckabee News like many years earlier.
It's a map of the Mississippi River that was created in the 1930s by Harold Fisker.
And he was just like a purveyor, like he was like survey to land for the US military at the time.
But a really interesting thing about it that I like about it is that it's not just a map of the Mississippi River,
it's a map of the Mississippi River at different points in time.
So it's like a map that like changes with the territory or reflects the changing territory in this really interesting way.
Where actually each one of the lines is the Mississippi River at different points in time.
And I kind of really liked it as kind of a central metaphor for, you know, the whole map and territory metaphor was always really cool or too less wrong.
But also really liked it as like a map that goes beyond just like being this static thing that tries to capture the territory at one point.
It tries to display how the territory changed at other points.
And I felt like it really highlighted some additional dimension to like the whole metaphor of the map and territory to less wrong.
That like made it more excited, made me more excited, more excited to include it as like one of the central branding elements.
And it captures the metaphor of less wrong itself changing and becoming a new territory.
Yep, I like that one.
Yeah, the rivers are changing between 1765 and 1944, which is quite a lot of time for a river.
The parts that we've used are parts where it's like overlapping and looks kind of somewhat artistic.
I will warn you, the map is much, much longer and gets very Lovecraftian.
I just like to unravel where we cannot use it.
That seems fair actually.
Will it damage my sanity to look at the full map?
Well, it does kind of attack the impermanent like the concept of the permanence of rivers.
It changes them to these things that can just change and sometimes go in circles.
It's very confusing.
So this has been going on for like just like four years now and it's been growing over time, it looks like?
Yeah, it's been great.
We currently have like pretty substantial growth.
It depends a lot on which exact metrics you're looking at.
Like in terms of page views, it's been something like 30, maybe 40% year of year growth in terms of comments.
It's been more like 80%, 70% like kind of almost doubling every year, a bit less than that.
And then also in terms of votes and various things like that.
We're in terms of comments and posts.
We're pretty close to what like the highest peak was Deadless Wrong ever had in 2011 kind of during the time when all the HP will our discussion threats were going on.
Yeah, I think 2011 had about I think 2800 posts on this one.
And I think 2020 is at 3000.
So this is the first year that's like crossed over.
So kind of in terms of like restoring less wrong, I feel like we've done a pretty good job there.
And then voting wise, we're still quite a bit quite a bit below kind of all time historical peaks, which I mostly kind of set as a target is like I know that we can get less wrong to that kind of that kind of engagement and traffic pretty easily.
Well, pretty easily means we had a time needed to make it a laser full time project, which maybe isn't that easy seems at least humanly achievable.
And so I think we've been making a lot of good progress and this year has been great because well everyone has been stuck at home.
And so they couldn't they just started reading less wrong a lot more.
And so that's one of the small civil learnings that I have for for this year.
So it sounds a lot of the draw of the new less wrong is the awesome curation that you guys are doing.
And so I wanted to ask you about like some of your favorite posts.
Well, one of the things we've done in the terms of curation as we're going to chat about I guess a bunch is the fact that we've turned some of the best stuff on the new less wrong into a book set.
Which we, yeah, as I said, it seems one part of us love trying to reward some of the best stuff.
I can happily tell you some of my best posts favorite posts from the book.
Absolutely please do that.
Sure.
Actually wait before you do that tell us what since we the reason we got you on here was because of the book but I don't think we've actually talked about what the book is on the podcast yet.
Preach media technology.
I'm happy to look at it.
Yeah we interviewed a bunch of like users and like what would make them feel motivated about like writing was motivated them to write the great stuff what would motivate them further.
And several people were like, I'd love it if I was in a book, like a physical book that was like published and stuff.
And so this has been a project I've like wanted to do for quite a while.
We also wanted some sort of longer term feedback loops on the site, you know, I think when you post the social media, all of your sort of engagement happens in the next sort of like one to three days and then that thing sort of falls into the sort of
very whole history.
Whereas hopefully in science, this is not how the best papers work or something the best papers grow in like how much readership they get over time and like, like are picked up and like read by the entire next generation.
And so, unless wrong, it's still the case that we do better than that, but it's still the case that, you know, a lot of the engagement have the post happens in the sort of week where it gets published.
And so readership happens then as well.
It's not funny to actually I think a lot of old stuff like certainly the sequences and legacy content gets quite a lot of reading.
But so what we've instigated is an annual review process, which we're currently in the midst of the second one.
And so in the end of review, we have a two week period for nominations where you go through the post of the year that we're reviewing, and you say you click nominate and you try to show explanation of why you're nominating it to potentially be in the book.
Then we have a month long review period where people are encouraged to write reviews of stuff.
People have written pretty great reviews last year.
But the nominations are especially a section I really love because we just got to read people.
I just we don't get to see these comments very often, but we get to see these comments where people say this totally changed my perspective on this issue or this reading this post changed like my relationship with my father for the better or this post.
I just thought about it consistently and I've linked to it like dozens of times.
And I think that's not only like great to hear about how the site's working, but I think it's also really great feedback for the writers to go oh wow that's something that's happening is when I write on this room.
So we have a review and then we have a vote and we use quadratic voting which is a cool setup popularized by Vitalik Buterin and Glenn Vile.
And then this is the first year I've tried it and I tried to make something that's very distinctive and like has a coherent vision behind it.
So I took basically roughly the top 44 posts from that vote.
I think there were about 100 posts that got voted and I took the top 44 and we've turned them into this set of books sort of built around some key themes and we tried to make them very beautiful and we tried to like make them something you'd be proud to be written published in.
The five themes of the book are epistemology is the first one.
It all starts with epistemology agency the sort of notion of rational agency and being an agent in the world coordination of having groups of agents.
Curiosity, which is the first virtue of rationality and alignment, which is about being able to align other agents with your own cognition and value function, which we kind of care a bunch about because AIs are an issue and we're trying to build them.
Is there one book per theme?
Yeah, it's five books.
They're all pocket sized because empirically this was the size of book that our beta testers actually found they've read.
We'd like we printed them in a bunch of different sizes and I took them to parties and such and people would look at the big hardbacks that were kind of nicely formatted nicely edited and they'd go, oh, that makes sense that that exists.
And then they'd look at these four by six tiny books that were not well formatted and the text was a bit gray and the line height was awful.
Which should be clear we fixed it's not a selling point.
But at the time that's what we had and people just kept coming back to them in the party and just reading a couple chapters as really kind of surprised by that.
Even though the internals of it were not at the time we just not very well designed.
And so, yeah, this was like assigned.
This was a sort of book that, you know, many books are meant to look good on bookshelves and we've tried to make books that look good on bookshelves, but we also wanted them to actually be read.
And my own experience with many books is I buy very beautiful books that I intend to read and I don't often.
And so we tried to make them very unimposing was nonetheless kind of beautiful.
And so I ended up splitting into five little books.
Each one fits in my pocket or in Elizabeth's purse is a housemate of mine.
And yeah, that's roughly what the books are.
I could say more about them.
I'm curious if you have as parts of it you'd be interested in hearing about how many thousands of words per book on average would you say and how many posts per book.
Oh, I spent 10 posts a book.
Okay.
And each post generally several thousand words right.
Yeah.
Yeah.
Like I think a little different five books add up to something like 600 normal pages.
I think that's roughly what I 700 750.
750 of the slightly smaller pages, which I think so I think it adds up to about 600 pages in total.
So something that I've mentioned.
Okay.
Yeah.
And pulling it back to bets earlier on.
I had a bet with a teammate of mine about how many would sell because I know we've not the lesser community has not sold books of this type before.
I think only as assaults and books and marry assaults and books.
But these have tended to be shorter and often kindle or print on demand that Amazon offers.
And these are selling at like $5 or less or something or somewhere in $1 to $10.
This is like, you know, it's got a lot of color in it.
It's been printed by like professional press.
And these are more expensive.
So this you have an actual print run from these.
Yeah, we did an actual print run, which of course costs lots of anxiety because we're constantly we have really uncertain about how many we were supposed to print.
Yeah.
How many did you print?
So we initially asked them to print.
We went to print 500 books because we were like, I'm not sure how many are going to sell.
And as I say, my teammate bet that we would not sell 200 by the end of the year.
I had a one on one bet with him.
There's only for $10, but you know that we not sell too much by the end of the year.
We announced them for pre-order, I think last Tuesday.
No, not the most recent Tuesday, but the one before.
And on the first day, I think we sold 300.
And so far we've sold 1800.
Nice.
Great.
So now we're asking for a print run that is an order of magnitude larger than the initial print run that we had asked for.
That being 4,000.
Yeah, which is quite surprising.
And outside several of my teammates, 90% confidence intervals.
Yeah, that is a damn good feeling.
Holy crap.
How many years do these posts span?
Is it like the since less wrong 2.0 started?
So the full first full year of content from less wrong 2.0 is 2018.
And these are the best posts of 2018 in that year's review.
So we haven't even reached the 2019 posts yet.
Oh, no, we're reviewing them right now.
As we speak, I hate to confess it, but I briefly looked at less wrong and people are nominated stuff since we started the podcast.
But yeah, so we've sold 1800.
And I think the rule of a rule of thumb we saw on the internet was your first week of sales is probably half your first quarter sales.
So like maybe that's we sold the first week.
I think about 1400 or so 15.
1500.
So something between 3000 in the first quarter and kind of hopefully like as I'm toting around 4,000.
But we have to do another print run, you know, there are worse problems to have in life.
But yeah, the press was quite shocked by our sales.
They're like, you want an order of magnitude more books.
All right.
They had to be pretty happy about that too.
I do. I'm assuming you got a price discount for volume.
Yeah.
Printing is really horrible.
Like the unit price for us went from $20 per print cost to $7 per print cost.
Last 500 marginal books cost us like $4.
And the first 500 marginal books would have cost us like $45 per piece or something like that.
Yeah.
It's all about volume and publishing because once you have it set up, you can just run the presses as much as you want.
Yeah.
Yeah.
Until it just gets to the price of like raw materials.
Yeah.
Then you're stuck with a warehouse of thousands of books, which you will never sell.
Unless you're you guys, in which case you sell them all.
Yeah.
So of course, no one's actually got the books yet because this is only just, you know, this is the last two weeks.
And so I'm very excited.
We promised everyone who bought them by, I think it was in the first week that we get them to them by Christmas.
And so I'm very much looking forward to everyone getting the books and hearing feedback on them.
I'm sure people will be like, these are actually small.
Where did you say this?
I guess the first sentence of every bit of marketing about it.
But I don't know what people will say.
I'm really sort of looking forward to it.
I think they will love it.
Yeah.
I tried to make something people would love and I didn't know whether people would want it or not.
But I've been pleased to find out that many do.
Yeah.
I've also just been really happy about our printer.
There's this, I don't know what you know about this.
There's StripePress.
So there's Stripe to people who like, who build payment infrastructure.
And for some reason, they build a publisher, a book publisher, StripePress, where they just publish books about topics that they feel are particularly important.
And their books are absolutely amazing in terms of print quality and just like unit cost and all kinds of stuff.
They recently published Richard Hammings, The Art and Science of Engineering.
And that book is absolutely beautiful.
So we were like, man, we would like to make beautiful books that are as good as those.
Wait, what printer did they use?
What are their supply lines?
Luckily, one of our friends just knew someone who worked there.
So we just called them up, asked them about their supply lines and their printers.
And then we just stole their supply lines and printers.
Now we're using exactly the same things as they do, which I'm very glad to StripePress for saving us all the work of finding and selecting all the right people here.
Yeah, I think often in the nonprofit space, it is often rare to find someone who has attempted to solve similar problems to you.
And it's always like, in the for-profit space, like people like, oh, I don't want competitors often.
But I feel like in the nonprofit space, I'm often like, there are occasionally other people that like build web forums or something.
Or in fact, there's people who don't like our version of Lesserung and they have built their own UI of Lesserung.
And I think often you'd be like, oh, competitors.
But I'm just like, wow, you put in hours of effort to try and solve the same problem as me.
I am fascinated to see the way you've solved this problem and I learned from it.
And similarly, I'm very appreciative that StripePress has done a lot of the parts of building a publisher in this present day era.
The primarily works online and like tries to make very beautiful books that you primarily buy online.
You don't see in books to us.
And there's a lot of different design problems that they have faced.
So yeah, I really appreciate all of this.
They have done this.
That's awesome.
Yeah.
I'm sorry, go ahead, Stephen.
Oh, that was it.
Oh, okay.
So I was wondering, could each of you give us one or two of your favorite posts from the books?
Yeah.
I think my favorite essay from the book is probably Naming the Nameless.
It's a very weird essay written by Sarah Constantine that I don't know whether she really knows what to do with it.
It's an essay that's primarily about like what aesthetics are and how they work and what kind of influence they have on our thinking.
And it's really sparked when I read it two years ago.
It kind of had this very, very large effect on me because it helped me navigate something that I now consider something like the tyranny of system two or something like that is a common phrase I use in my internal monologue kind of where in many environments,
I feel like I'm being pushed towards type of reasoning that are very, very verbal and very explicit.
And I actually noticed how large fractions of my thinking actually don't really go through that and how in particular large fractions of like what I historically thought of as the rationalist aesthetic have fallen into this mistake of just like not having good art,
not having good intuitive handles for concept and instead often relying on things like relatively dense mathematics that is useful for verifying things but not actually very useful for explaining things.
And the post really goes into a bunch of analysis of society and a bunch of common cultural trends that try to point towards the effect of aesthetics on different parts of society.
And I think it's less to specific arguments that it made but more that it kind of like made it so that I could have the handle of aesthetics and its effect on thinking and its effect on culture as like a really specific element that I could think about and reason about and analyze its effects on my life.
But is that in the epistemology book then?
I could have imagined also putting it in coordination but I think it fits slightly better in epistemology.
Yeah, she has the phrase.
Yeah, well, I was going to say we'll be sure to put links to all these.
Sorry, go ahead.
I'm sorry.
Well, I guess neither of us is going to speak.
She has the phrase in it.
I don't know if you know the phrase double crux, which is a technique Seafar developed for helping disagreements work, which is about not merely finding things you disagree on, but finding cruxes of your disagreements.
So finding a thing that if you change your mind on, it would change your mind on the overall argument and trying to find issues that are cruxes for both of us.
And we're always arguing about a thing that could change either of our minds.
And this is often a very productive way of having disagreements.
And she says something like double crux is a great, but I'm looking for here is something like an aesthetic double crux, where people can try and like share parts of their aesthetics and share what would change how they feel about those aesthetics and try and have that sort of disagreement and sort of elicit, you know, some of the nameless things that are affecting our decisions and affecting our beliefs.
Now, is it possible to change your aesthetic through argumentation?
I actually recall, I'm pretty sure it's not a proper full story.
I'm pretty sure it's the story of, I think it was two Seafar staff members, one of them who likes eating onions, and one of them who did not like eating onions.
And, you know, I'm on the second side.
And the one who did not.
Same, onion here's unite.
Yeah, love onions and they're good for you.
And, and so they tried, you know, they said, what do you like about eating onions.
And they tried to, I wasn't present for the conversation, but I imagine they talked something about the taste or something about the like, feeling ahead in the math and encourage the other one to try taking a bite and paying attention to those things.
I think overall the other person, I'm going to use the phrase learned to enjoy eating onions, or felt that they could appreciate why the person would enjoy eating onions and could imagine themselves becoming that sort of person.
In a way that they did not expect going in that they would be able to get out of such conversation.
And I think this is a style of conversation I've tried to have more and more, where someone like doesn't like a decision or acts in a certain way or something.
And I'm trying to say what feels salient to you about this and communicate both there and my sort of aesthetic toward the thing or feelings toward the thing.
It's really cool. I'm going to have to read that.
It's relevant to some stuff that my partner and I have been talking about where, and also that like Guild of Servants just did their aesthetics class.
And, or it was like, just about how to cultivate a sense of style, like fashion style, or just like, I guess the accessories you surround yourself with, et cetera.
Can you tell me, Jase, what the Guild of Servants is?
Can I?
Apparently it's a secret society. I don't know if I'm allowed.
I do have to say I'm talking of secret societies.
I've been in the little restaurant community for almost a decade now, and I've been waiting for the sort of owl or some form of male to invite me to the Beijing conspiracy.
And here you are.
And so if you would like, you can just turn all of your questions into probabilistic estimates and I will answer them.
If at any point you would like me to give a probabilistic estimate, I am ready and I'm willing.
Excellent. Yeah, the Guild of Servants was described in episode 117 when two of the founders, David and Alex came on.
I think in a couple of sentences, the goal is to curate actual life betterment skills that actually work, which for me, I kind of encompass everything that actually works into the umbrella of rationality.
In addition to, in a broader way, solving the PR problem that rationalists occasionally run into.
I wouldn't say that's even a primary goal, but the one long-term goal is to have large community impacts where the people who get to claim responsibility say, yes, we're with the rationalist community via the Guild of Servants.
Nice.
Interesting.
Nice.
But if you're interested in more, like I said, check out episode 117 of our podcast, which was just like, I guess bi-weekly, it would have been sometime this summer.
Alright, listen to it.
So Ben, did you have a post you really liked?
Oh, alright. I think I really love the Babylon prune stuff.
So it's three posts that come from a sequence called Babylon prune by Alkeja.
She's a great writer on the site.
In fact, just two weeks ago, I wrote some of the best stuff this year.
The Babylon prune is just again, another very simple model of how his thinking works, which is that, you know, similar to like brainstorming and then like picking the best ideas.
It's like coming up with quite a lot of like strings or like ideas or sentences or something and then just picking the best ones to say or something.
You can see the similarity in Scrabble where like people try and like start with smaller like sub sentences, sub words from what they've got and build it up and open.
And he felt like a lot of his rationalist training had been like on his prune skills of being able to go, this idea isn't good enough.
This idea isn't good enough.
This idea isn't good enough.
And you know, he like listened to people say such eloquent and interesting things.
He's like, oh, I understand those.
Why don't I say interesting and eloquent things?
But it's sort of internal setup just kept whatever he thought to say, it would just go not good enough, not good enough.
And then he just sort of not be able to say anything.
And so it's given me a sort of tools about practicing having good filters, having good generative and filtering processes.
It's in fact led to quite a lot of practical use.
In fact, just recently, Jacob Lagras, who has been collaborating with Lessrong and is the primary other person who is responsible for this book set being built,
did a great babble challenge on Lessrong where for once a week, for seven weeks, he would say, OK, here's what you're going to do.
You're going to babble 50 solutions to the problem I present you.
And he had great problems like how to light a candle.
How to light a candle was the last one.
You need to give me 50 solutions to how to light a candle or how to get to the moon or how to hide a notebook so that no one will find it.
Or I think how to hide a pen that it will only be found by a specific person like 100 years later or something.
And it was great, a bunch of Lessrongers who I think have never written comments before went, I think I can do this.
And they came up with such inventive and creative explanations or solutions to the thing.
And obviously a ton of insane ones.
And this is now just like a technique that like me and Jacob Van Olli and people use around like work in the office and Slack where they're like, oh, we have a problem.
All right, here's 10 solutions.
Just I will babble 10 solutions, which I think has been previously something we've been kind of scared to like say a lot of bad ideas or something.
But I think it's been a good kind of practice.
So anyway, yeah, I'll just write some really product stuff about different filters he finds in his own mind and different levels of prune and different gates and ways of increasing your babble and ways of
proving your prune and this sort of concept.
But yeah, I know it's permeated my thinking a lot over the last three years.
I think prune is kind of self-explanatory.
But by babble, does that mean just generating lots of options and not like without self criticism?
Yeah, I think he's opening example is I think how babies learn to speak, which is not that they like imitate as much as they just produce a lot of noise.
And they notice what sort of gets positive feedback or something.
The interesting thing about babies that is relevant to the Babylon prune analogy here is that babies can produce all phonemes that are present in modern languages.
They just like babies are better at pronouncing the th in English and on and on.
And then as they learn the language of the world around them, they lose the ability to pronounce certain phonemes and prune down the set of phonemes to the set of things that are actually being used.
And they generally produce just a lot of noise and then prune it down to the subset of noises that are correlated with a certain language.
And that's like a very interesting way in which like you can imagine getting that language where you can imagine doing the opposite thing where babies don't know how to produce any phonemes and then learn
iteratively at it at once that belong to a certain language that they're surrounded by.
That's fascinating. I now kind of wish we had a language that just used all the phonemes so that we wouldn't lose any of them.
Someone who's been struggling for like six years with this horrible th in this language.
I would also be glad about this.
German doesn't have the th sound then, huh?
It does not. We only have the rolling R, which I now have taken myself to repeatedly using in lots of words and those various expressions of emotions in order to
slightly compensate for my inferiority of not being able to pronounce all of your phonemes by demonstrating that I pronounce phonemes that you cannot pronounce.
I'm kind of bummed you didn't roll one R when explaining that.
Yeah, I enjoyed it really hard, but it was hard to find one.
Americans do have rolling R beautiful.
He just makes that noise when he goes into rooms now, by the way.
He just does it.
People have different catchphrases and nullies is just
Yeah, I was about to say it sounds like the noise you make when you want to get pets.
Yeah, yeah, he is the rightest girlfriend the most.
But yeah, I think there's a bunch of other essays in the book.
One of the one I would want to mention because of how much I like it is an untrollable mathematician, which is a cartoon.
In fact, yeah, I guess the curiosity book as a whole is it's a curious book.
I can't believe I just said that, but it is about it's not about curiosity.
Like curiosity, we care about a lot because as a motive is very pure and true seeking and like doesn't.
And it's like, there's that great earlier as a line, a burning itch to know is higher than a solemn vow of caring for students or to pursue truth.
And so I just love people getting real curious on this one just about sort of any subjects and they often find very fascinating things and they do great reasoning.
And so it's just a collection of essays of people getting curious about some aspect of the world.
The essay has got a title, which is a question like Scott Alexander's got is science slowing down.
And my ancestry has got what motivated rescues during the Holocaust.
He was trying to understand the sort of motives of the people that like did various sort of heroic things.
And Abrams is Abram Demsky is the author of an untrollable mathematician who's a researcher at Mary.
He was trying to get curious. He was curious about this a complicated relationship between probability theory and logic.
They have a weird probability theory.
Classically assumes a certain amount.
Sorry, assumes logical amniscience.
It assumes, you know, the consequences of your beliefs such that you can just do a simple update of like, oh, I have now seen this evidence.
Therefore, I can say that these beliefs are false and these beliefs are true.
And I can rebalance those probabilities.
Whereas, for my logic, you never know all the consequences of your beliefs like as a bounded rational agent in like with limited compute and limited time.
I cannot compute every logical implication of everything that I know.
This would just require a lot more compute and time that I have access to.
And one thing something girdle.
And so there's a setup where you're trying to like weigh these things where each one of them is like, yeah, actually has a very beautiful diagram.
I think of some scales trying to weigh probabilities.
But each probability is a plant that is growing like quickly.
And you're like, I don't know which of these plants is going to go quicker.
I don't know which way it's going to finally end up.
And one of the issues he is noticed is that in principle, I can start telling you if I went to troll you and you were like this mathematician trying to dutifully combined logic.
And probability theory, I could keep telling you consequences of your beliefs, logical implications of your beliefs that weigh on one side of these scales.
And I could repeatedly do that to make you balance these scales at in principle, any balancing I like.
I could keep telling you facts that are implications of what you believe or logical facts where you go, oh, that's a good point.
That makes me think slightly more likely that this statement is false.
And I can end up in principle getting you anywhere on this set of weighing scales.
And so his question is, is this necessary?
Can I come up with a way of thinking of combining logical probability that doesn't have this trollable nature?
I won't necessarily tell you the inclusion.
Maybe I will.
But it's just a fun cartoon that ends up very conversationally and with beautiful sort of diagrams.
Just telling you these little interesting things about logic and how it works and how probability works and how some of him and his friends got curious about it and how they were on a train together talking about it.
And so it's been one of my favorite posts that came out in 2018.
And I really, I also just like the idea of someone reading the Curiosity book going, oh, I think I know what's happening to me in this book.
We had his science slowing down.
We had what motivates rescues during the Holocaust.
These are people doing some like research and writing it up.
And then you turn the page and it's just a cartoon chapter headings anymore or something.
You're just in the middle of a hand drawn cartoon that's just chatting about girl serums and so on.
So yeah, it's one of my favorite essays in the book.
I really like it.
Awesome.
Yeah, I also really like it.
In some sense, I want to bring this up point because we hear the Bayesian conspiracy.
I think the biggest change and the most interesting thing that from my perspective has happened in kind of the development of theoretical rationality in the last two
Watch what you say here, Oliver.
This is the character.
The fact that I think just like I moved away and I think a lot of other people I respect have moved away quite substantially from the classical Bayesian model of rationality.
Because like actually just like the concerns around being a bounded agent just actually have all of these these very substantial obstacles that make reasoning like that, that make it very hard to even think about what it would mean to reason like a Bayesian.
The Bayesian studies really, really weird things where I think think Abram said it really nicely.
I don't know if it was controllable and additional and one of his other comics where he said that the fact about a Bayesian is that a Bayesian must have the ability to represent the complete territory as a like within their brain as a single hypothesis.
And like, in order to just represent a single hypothesis about the universe, you need to be able to have a hypothesis in your brain or in your representation in your model of the world.
That is as complicated as to fall universe.
And that itself is like very weird statement to make about any object.
It like, well, how would they even make that statement about something that is embedded in the universe?
Does it have a perfect self model?
Then you end up with all of the kind of classical problems with like, well, how can you have a perfect self model?
Can you predict what you will do in the future?
What does it even mean to make a choice in that context?
And all kinds of other weird logical confusions that happen.
And so just, just in order to make a slight jab at the Bayesian conspiracy, in some sense, I have substantially moved away from from thinking of the art of rationality as being the art of becoming a better Bayesian and think that now there is a much, much more richer and more complicated art here that we have started to discover in a lot of the writing that is kind of exemplified by Abram's controllable mathematician and embedded agency and other things in that space.
Are you one of these post-rationalists that is trying to schism us?
No, no, no, please.
I saw someone on Twitter the other day say, the dirty secret of all the post-rationalists is that they still read less wrong.
No, the thing that has made me excited about this is that we have found traction in a theoretical and grounded extension of our art of rationality into this domain of bounded computation.
I think I felt really stuck for many years between like 2013 and 2016 or 17, where I kind of knew that, well, okay, but I'm not a perfect Bayesian.
But I didn't really have any traction.
I didn't know what alternative model I would even start to consider.
And it's not like we're that much proper ahead.
But over the last three years, I feel like I've really gotten some traction and what, how I can formally think and how I can rigorously think about a system that is computationally limited and tries to, is not logically omniscient.
And I think that kind of, if I, I don't want to really bash on the post-rationalists, but I think that kind of makes me think that I wouldn't necessarily describe myself as being in a post-rationalist tradition,
because I'm still interested in a grounded kind of formal rigorous handling of the relevant philosophical and epistemological puzzles.
And I think we have successfully broken into that space.
And now I feel like there's this richness of new, interesting things to do in that space that feel very much in the realm of building another probability theory, as opposed to deeply meditating and uncovering the real truth that was inside of my soul all along, or something, something,
it's a strong and a post-rationalist.
I, I am, I mean, you already had me sold on this book series, I was planning to buy it an hour ago, but I am now like even more interested and slightly worried about some intellectual contagion that may take me over, but I'm going to read this anyway and take that risk.
Change the name from Bayesian conspiracy to embedded agency conspiracy, then I will, I will take credit.
It's still an awkward name.
It is really not a good name. Don't do that. Would be horrible for your brand name.
Yeah, we just, we just launched some merchandise. We can't go changing the name now.
Right.
Although the merch doesn't actually say that Bayesian conspiracy does it.
No, it's just the art.
You already, you can come ahead. Ready to change your mind.
Yeah, I think the relevant parts of this, I don't expect we'll, my epistemic state is not that we will like, we will not look back on Bayesianism.
We will not be like, ah, that was mistaken.
We will, there are some parts of the formalism that I think do not apply to agents that are bounded.
I think these confusions are best pulled out in another one of Abrams essays, which he co-wrote with Scott Garabrent in the, which is partly in the book, but it was in fact itself the length of, I think, two books.
We didn't include the whole thing, which is his embedded agency sequence where he just starts, and I think it's in a very fine manesque way.
You know, this is, this is quite complex and philosophical and mathematical questions.
But he just sort of draws a couple of cartoons and diagrams and you get a pic.
You go, oh, yeah, I think I get what he's talking about where he points to the sorts of confusions we have about what it means to be a rational agent.
Some places where our theory does not fully explain or fully account for some of the actual problems we face.
I think a lot of the classical ways people have used certain parts of Bayesian probability theory.
His fundamental contrast he makes in the book is between an agent that is playing something like a video game where the agent is not part of the video game, they're outside the video game.
The things that happen in the video game cannot affect the agent's mind and the agent in principle could understand everything that's going on in the video game within its own mind.
If you imagine just the relative like where the agent is in fact computationally got way more confused so they can think about all the possible states of the video game.
And then he like contrasts this with an agent which is a part of the video game trying to understand how the video game works, how thinking works when, or what it means to take actions when their actions can change their own brain and change how they think.
What it means to have other agents inside of them to be built up of some other sub agents.
And I think that some parts of the like formalism that we use of Bayesian probability doesn't make some assumptions about these that you are more like the agent that is playing the video game than you are the agent that is part of the video game.
And so they're like sort of wandering through the space and picking up little interesting curiosities and tools and trying to like adapt the formalism to better match the actual situation we find ourselves in.
But yeah, I think I, yeah, it still seems pretty, but it's totally pretty Bayesian. It's just, it does have some interesting changes to the formalism, or hopefully well, when we figure it out.
And all this is still ongoing on Lester on 2.0 right now.
Yeah, just very recently, like Scott Garibrand released this giant sequence around Cartesian frames that was in trying to think a lot about like how to be an embedded agent and how they can think.
And I do, I myself still have a variety of hours over the next few months set aside to like engage with it deeply. But it's really, it seems like a pretty exciting full formalism that has been presented within the last like two months that is making some really, really
interesting prophecy like we had a very cutting edge of like really philosophy of all time.
So I have two questions for people who are pressed on time. The first being, I'm assuming these are included in the, is it weekly emails you send out that have the best of them?
Yeah, usually sending out free emails and the emails are literally just the post like we take the full post, and we will just send it to you in the email. And there's no advertisement, usually no announcement, it's just the post.
And surprisingly, we've gotten even our latte to render. Okay, in Gmail.
So, so that's really, you can, you can press the subscribe button, when you sign up for an account, and then you get free posts per week in your email. And you don't even have to go to us wrong if you want to read all of them.
And the follow up question is, if you want to like read the back conversation here, but you don't want to, you know, go through everything you just want to highlight is there some place to find just those posts that have been sent out in email as like the best of read these.
Yes. So if you go to the front page, you will see at the very top of the post list, a set of posts that have a small star right next to you, you'll probably see three of them because we show three of them at any given time.
If you click on the star, you will be taken to a full list of all the curated posts over the last three and a half years that we've compiled. And that really is the first place I would send anyone if they are interested in seeing what like has happened.
What interesting things have happened on less wrong 2.0.
Although my first place is now this book set, which is pretty good.
I actually realized I didn't say, I think I talked about the book set from the perspective of like rewarding the authors.
But I think from the perspective of the reader, the book set is just a place to really sit with the ideas and engage with them that is not plugged into your distraction machines and the internet where you're not like 17 tabs open every second you're reading it.
You're going, is this better than clicking on the next tab?
Okay, I'll continue reading the next sentence. You know, this is not a comfortable reading experience.
There's a book that you can just, you know, walk to a park and you can not have your laptop or phone and you can open it and you can sit with the ideas and sort of take them in the more in your own pace and think through them at your own speed.
So that's one of the things I hope that people, I hope there's a lot of people that have not followed for whatever reason they don't have time to check it every week.
They do not like read every email that we might send them, but it does want to read the very best stuff that we like, I think has been written to us wrong in the last year in 2018.
And I think you can take this and you can sit and I hope to see people like go, huh, I now feel like I actually am up to date with what happened in the year and some of the best ideas.
And here's a bunch of ideas I've had based up of those.
That's awesome.
And I'll, I'll note too that if you have an existing account that you made before the newsletter or the weekly email was an option, you just go to your account settings and you can click a box to sign up for it.
So yeah, yeah.
And those are the ways of you if you're an RSS person, there's RSS feeds, etc, etc.
So how can we get this because we haven't heard the details on that yet.
Oh, great.
Good. Thank you.
The current way to get it is to go to less wrong. So we're currently in the pre-order stage. We're still, we're just printing, they're printing as we speak.
You go to less wrong front page and you can see the books at the top. If you're on desktop, you'll need to hover over and you can see the pre-order button there.
They're $29, which is what we've determined is the amount of money we need to make this thing not negative, hopefully.
And then, yeah, if you want to see more details about them, there's a learn more, there's an FAQ. You can see totally some of the images inside.
We've redesigned basically every image in the book to fit the aesthetics of the books.
You know, I think the images, especially in some of like Scott's essays are like crucial for understanding it.
And so yeah, we've redesigned all of those and you can have a look inside and hopefully you'll find those attractive.
I know you're going to get this question a lot and I assume you're going to hate getting it a lot, but is this available on Amazon?
The answer is it will be available on Amazon as soon. Amazon only allows you to sell things. So Amazon doesn't take pre-orders unless you give them 50% of your profits, which we didn't want to do.
Sorry, not 55% of your profits would be totally fine. I would be willing to give Amazon 55% of my profits, but they want 55% of your listing price, which really isn't the amount of money that I currently wanted to give Amazon,
given that we're barely breaking, given with the price as is. So they will go live on Amazon. My guess is in something between two and three weeks, hopefully.
Right on. And do you get all five books for the pre-order price or do you just get the map? Sorry, what?
All five.
All five. All right. Well, that's good because I just pre-ordered while you were talking about how to do it.
The countries we are delivering to are North America, says the US, Canada, Mexico, every country in Europe, Australia, New Zealand, and Israel.
Coming out to $6 a book, that's pretty damn good. Like, you guys really could have bumped up the price a little bit and made it some profit.
Yeah, but I really, I don't know. I just, first of all, I feel a bit bad about making profit on this book because I really feel like I would want to pass it on to the office,
but I don't, that would be a lot of difficulty. And second of all, I just really think of this as like a good introduction to Les wrong and the value that these books provide does not really come by the money,
but really via the people I hope it inspires to work on the problems that I care about and that like I'm working on this wrong for.
Yeah. I mean, the goal I've set myself is to try and make it like net profitable. If it's net profitable, then I feel very comfortable doing further projects like this.
But beyond that, I mean, I maybe don't need to tell you, it's quite hard to get profits in books and I don't think it would, I don't think it's a reasonable goal for it to cover the staff time that went into this.
But I did want to, you know, as most of the value is in people actually reading it. And so we've tried to hit like net profitability and we'll go from there.
I mean, obviously, with this book set, this is the first time we did it, we were willing to take some amount of risk that it's like, you know, to learn as we're learning at the first time we're willing to take some risk that it maybe doesn't turn out to be fully net profitable,
but we can do it next time or something. But I think we'll, I don't know, we'll ask us in a month.
Some people bump it up to $30 because then we know when I leverage in psychological pricing. And I find that pretty compelling to be like, we bumped it up from $29 to $30 because it costs $30 all along, we just told you $29 because it sounds slightly cheaper.
I like that. I think that the other, man, I had something and it just slipped my mind. Well, oh, yeah, as far as profitability, I mean, you know, it's probably too late to be thinking about it, but like, if your guys' pre-orders were, you know, a fraction of what you were expecting, and that was the price you were okay with, it seems like you guys are already doing pretty okay.
And, you know, if it works out to our next year, it's not going to happen unless you get X dollars. I'm sure people would help make it happen. So.
Yeah, yeah, it definitely, definitely the level of demand has made the, made it much more likely we'll be able to do this sort of thing again. I really appreciate every person who has brought us that so far.
The next thing I just want is the, is a beautiful, beautiful version of the sequences. That's, that's the thing I want to create, just all of them in print, finally.
Yeah, I also, hey, I have dreams of there are other writings on this run by single authors that I would like to maybe turn into books at some point.
I can see, yeah, I don't know exactly what we'll do next, but suddenly the demand on this and waiting for the feedback as well when people actually get the product and also, I guess the obvious other thing I would like hope is that people realize that we do this.
We're planning to do this annually, which means, if you would like to be in a set of books like this, you can just write stuff to less wrong. And if you write stuff, the less wrong community likes, it's a good chance I will put you in a book.
And I'll like make your images beautiful or whatever. So I hope people like back to in that somewhat as well from this book.
That's a compelling argument.
Yeah, I remember one of the authors, as I was telling them, you get to be in the book, they were like, huh, this makes me want to write on less wrong like considerably more. And I was like, Mission accomplished. And they're like, Oh, yeah, I see.
That was a good plan.
All right, well, we have been going for over two hours now. I should wrap it up, but I wanted to thank you guys so much, like not just for coming on here, but for all the work you've done for the rashless community over the years.
And of course, thank you for all the work you've done this podcast. And also, of course, thank you. And yes, in particular for all the amazing work you've done on the HP more podcast, which has very positively affected my life and many other people I know.
Yeah, many hours of, I remember cleaning the dishes as a teenager and the fruit coming on.
I mean, yes, Brodsky, and just you being the voice of all the Harry Potter characters, methods characters has been brilliant.
All right, thanks. That's awesome to hear.
Well, I can take both of those praises for you guys and for you as well. So, but you know, I already said it more, more articulately than I was going to so.
I did get recently to do sort of any ashes job to my close friends and not read methods. And we just read it aloud to each other, partly in person, partly of a Skype, and I got to do most of it.
And I really loved doing all the voices I got to like, I got to do, you know, Professor McGonagall's up high and Dumbledore's down low and Snape is like, we need to be and like, I did.
I'm not trying to say too much, but I did like Harry's is my normal voice. And then like, I also did curl is like my normal voice, but like a bit more refined. Anyway, it was really fun doing all of the character voice.
I remember seeing that.
Oh, it is, it is a total blast, especially if you really get into a character.
Mm hmm. But yeah.
All right, well, thank you guys for being here. We are going to take care of a few things at the end of the show. So we'll probably let you go here. Is there any final things you wanted to say or that we didn't touch on?
That's a good question.
Apparently not.
Okay.
Well, you know what to find us anything you want to add to the show notes that hasn't been included in our email chain yet. Send it on over this episode will go up in on Wednesday.
So, but I mean, even after the fact we can add stuff to the show notes and stuff.
This was great. I am, you know, like, like you know, I said, I think that you guys have done a lot for the rationalist community and this project in particular.
I mean, it's one thing to send somebody a URL link to be like, Hey, read this long essay. And they're like, Yeah, sure, I'll put it in my 60 tabs.
If you say, Hey, you know, hand them a book and say, send this, you know, hand this back when you're done. It's, it's a another way to, I think really engage people. And what the other thing I'm enjoying about just skimming over the page previews is that, like,
they're, they're pleasant to look at, but also it's not merely the sequences and, you know, some Slate Sarcotics posts. This is the community. And so it's, it's not it, it's, it's bigger than just the big names.
And I really enjoy that.
Yeah, 23 others and 44 posts.
Fantastic.
There's a lot really great. Let's run guys and rationalists.
Nice thing is you can have them to five people at the same time.
That's right. Yeah.
I definitely have some dream of walking up to some, I don't know, new people and be like, you guys need a better epistemology and waving at him.
We heard the good news of Lester.
Just hang around outside of churches.
But yeah, I love this podcast. Thanks very much for inviting us on it. It's the first podcast we've done. And if there are like this, this is going to be just basically fun.
Yeah, you should be on again and help us with the sequences.
Right.
You know what, we have to stop recording before you guys can leave. Do you guys want to just hang out for the, we've got just two bits of feedback to do.
Yeah, that we're totally down to say.
Well, it seems like the easiest way to do it without me kicking you from the call and I don't know what that would do to the recording. So perfect.
I know our hostages.
Well, we'll let you out here soon. What was the, we had two short pieces of feedback writing. Yeah.
So the first piece of feedback is from Richard J Acton at the subreddit to the base and conspiracy.
This was back when we were talking about the, the anti encryption laws that were being proposed in Congress.
Richard says making encryption effectively illegal is so practical I have no idea how people would respond to a law like that.
Most people would just carry on how they were with a few big players making nominal concessions and it would just become another three families a day thing that government can use to arbitrarily squash you.
And I also see that as a potential outcome because, you know, the government isn't, I guess they are going to impose backdoors on all major players if this comes in, but regular people aren't going to change their things too much and yeah, it'll just be another thing like,
you sent an email yesterday, we can put you in jail for that unless you, you know, confess to whatever.
Yeah, I, I find that interesting. I mean, like, you're right, for most people, let's go about doing our day. Like most people are on Facebook or privacy doesn't mean anything.
So like, I don't think that that'll like slow down the average person. And yet, like, there's, and, you know, I don't get up to anything illicit.
And, you know, my phone isn't a crime scene. And yet, knowing that it's secure is reassuring. I guess I would operate more or less identically to how I do now with the knowledge that, you know, anyone with a permit or the warrant could get in.
It's just, I don't know, it feels like the beginning of a very plausibly slippery slope.
Yeah, or just the marginal cost of making things a little bit shittier is, I don't know, like, it kind of sounds like, oh, it's just going to be another one of those things that suck.
And it's like, do we need another one of those things? I, I'd rather not.
I like that framing too. It's like, do we need things to be even more shitty? Come on. Oliver, Ben, any, any thoughts on that?
Well, champion from given that I work in web development all day, the big thing that definitely everyone is interfacing with every day is just that your browser uses HTTPS to talk to, like, basically any website you're on.
And that is just a type of encryption pretty straightforwardly. And that being outlaw definitely has really, really wide ranging effects because the thing that's like preventing that does is not only that like the government can access your data, but it means just that
well, you also know on a much more adversarial environment of people being able to read your passwords and various other things, if you're sending non encrypted data.
So that kind of is really, even if you were just talking to websites, you're actually talking primarily encrypted these days.
And if something has a backdoor that the government can access in theory it has a backdoor anyone with enough skills can access.
Alrighty, moving on to the second piece of feedback. This is from our last episode on career hacking. I found this one amusing, but also troublesome.
Wes over on the discord said, you guys left out the number one career hack, lying on your resume. If you tell you have degree, most of them won't check. And if you do in a clever way, almost none of them will check.
I thought I had mentioned that and I guess I didn't or maybe I was talking to somebody else about it. But like, when I got my library job, I did manage to backdoor in the way that I described in the episode but like Wes was like, hey, there's this
that you could get a masters in library science from the school that no longer exists, but it would have existed when you went to school and you could put it on at your resume.
And then like, no one will be able to even like fact check that because it doesn't exist anymore and then like even more like ways that I could be sneaky about it is just like I'm just not going to do it.
I don't like lying. Like, it makes me uncomfortable. But like, yeah, I think they could work and probably like, it probably would have been fine.
I basically really dislike lying. Not only because I feel it's like a way of deforming other people's maps and that is an inherently hostile act but just the repercussions it has on me like, then I have to think up of what I was doing during those four years and the people that I met and what college clubs I was going to like probably
none of that will ever come up. But it could somehow slip that you know I mentioned the last place I worked and someone be like, weren't you in school during that time I'm like oh yeah yeah I was a full time student and a full time accountant at the same time, which it's a level of headache I don't want
together together just the the hostility of lying and and the practicalities of it seemed terrible to me.
It is an outside the box solution. It's not one I would endorse for the exact same reasons like I don't like lying I'm uncomfortable with it for the reasons you described. And like, like he said the burden of having to keep track of your lies like the best thing about just being honest all the time is that you
don't have to remember what story you gave one person versus another. Like, yeah, it saves you all those headaches.
MPQ replied on the on the discord that maybe an example closer to the mark is life hack. If you see your neighbor's Amazon packages outside the apartment, just take them.
You'll have it for free.
Life hack if you go to an airport, they're just all of these suitcases that are just nobody is paying attention to and you can just take and leave with.
Yeah. Yeah, what was at the counter that it's most school doesn't teach any important career skills, especially depending on some of these degrees, and are there mostly for signaling, which is a, you know, a destructive game anyway.
So you get the benefits without having to go through the value destroying process of getting the degree.
Yeah, it's kind of, I feel like I personally don't want to do it, but I don't find it to be that morally egregious considering that we're in a system that wants you to pay like 15k to go get a piece of paper that says, you know, things that you
already know. Like in my case, my library director told me that like, oh, you could go get your master's but it'll be really easy for you. You already know all the stuff they're going to teach and I was just like, am I really going to have
$15,000 in so many hours of my life. Yeah.
I don't know if you guys are thinking you guys can get a slip of paper from a school for $15,000. You can get a semester for $15,000.
Not a master's degree. And it was an online program.
Oh, okay. Yeah, fair enough.
I still might be misremembering the price. It might have been more than that. But yeah.
I know that trying to get a, I don't know, lying about my degree would not have quite helped. The primary reason I stayed through the last half of my degree was so that I could get a visa to the US to work here.
And unfortunately, I got the literal, I think, worst grade you can get while still getting a degree because I didn't want to stick around for any other reasons.
That is an excellent motivation to go to school.
Yeah.
Half-asset with all you got was, I think, the chapter title of one of the Replacing Guilt.
Yeah.
Which reminds me, I want to plug that audio book again. John Luca has been doing a podcast that's been reading the Replacing Guilt series.
Oh, it's great. You can just search Replacing Guilt on any pod catcher.
We had an episode about it, I don't know, several months ago, and I was like, yep, I need to read that.
And kind of like with these books, I imagine, just getting it in a format that will actually entice me to get to it.
I'm now waiting for them every week. I've listened to all 30-something episodes.
And the best thing is people who I know don't read less wrong have told me that once I recommended this, they've listened to all of them and enjoyed it.
So just the virtue of getting things out there in multiple formats.
Yeah, that seems great.
I did. Is that, that's the word, right?
I have never heard, that's a very good, a legitimate, I remember the word, but yeah, it catches podcasts.
I didn't, I don't know where I got it from. I did not create it though.
I feel like I've heard it before. Like people who do podcasts use that word.
See, this is why they need to be fed to the dentist. They can be in on all the hip slang.
All right, we'll move to the other one.
You guys do need to look at the Denver, get in touch with the Jays. They've got a housing idea.
Nice. Oh my gosh.
Yeah, I want a group house, but there's the COVID hack and recommend.
Yeah, COVID makes everything really hard. Also makes group houses kind of more valuable.
I would have probably turned insane if I didn't have all my housemates providing basic connection.
I have a handful of coworkers to live alone and I, I try to do my best to like hang out with them while we're working together,
even if it's just being on a call, like while we're both doing our separate jobs.
Because I'm fortunate enough to live with somebody I love spending time with and that's enormous privilege right now.
So yeah.
I've just been slowly going insane. So it's been working.
Yeah, yeah, it's weird to miss humans. Like I'm such an introvert and it's just super weird to like,
I think I was actually texting Charlie about this. I was just like, do you miss people?
I'm starting to, I'm starting to miss people like going out and the other humans and talking to them.
It's weird. I never thought I would feel this way.
This is how extroverts feel all the time.
I mean, maybe we could ask them, but I don't know if we want to get that close to one.
We've identified extrovert and we've had like sort of joking, but not joking.
There's kinds of conversations like really you like that? So weird.
What's that like?
I think rather than asking them, I'd rather just make an M tuck.
So like, so I don't actually have to interact with anyone.
I love it.
All right.
I believe that's it.
So shall we just think?
Of course.
And then eat it for nutrients.
So, oh, is it my turn this time?
I think so.
Okay.
Yeah.
Scroll down.
Who are we thanking?
Looks like we are thanking Emilio Alvarez.
That was the pause for the Tadadoys.
Yeah.
Thanks for helping support this broadcast or podcast rather.
Where we can, you know, help bring you people like these on to tell us all about
fucking less wrong 2.0 where people are nowadays keeping the rationality thing going.
Yeah.
And you really, you really make, I don't know, all our patreons make this much more
rewarding, both in the, in the sense that, you know, we get money for it, but also in
the sense that similar to like how you guys were saying when people just felt much better
learning that they're in a book that's going to be published, it's, it's nice to have
people like monetarily supporting you in that way.
Yeah.
We appreciate what you do.
Yeah.
We're hoping that Scott gets some of that soon.
Yes.
Oh, cannot wait.
Some of that sweet unit of caring.
Perfect.
And thanks again, Emilio.
I was quiet because you know, I said everything I was going to say, which seems to be kind
of a running theme this episode.
Yeah.
All right.
I think we're good to call it here guys.
You're saving me.
I kind of just was like, thanks.
Where's, what are they?
Okay.
Yeah.
All right.
Well, thanks again, Oliver and Ben.
This was fantastic.
And I can't wait to get these in the mail.
I'm looking forward to it.
Yeah.
Great.
I look forward to it.
Tell me, tell me what you think of them.
I sure will.
And everyone listening, well, I guess, you know how to find less wrong.com.
I was going to say there'd be a link to find them, but you guys can't find that.
You know, good luck.
I mean, they would be one of the lucky 10,000.
Like that's, that's really.
That's valid.
Wait, this is online.
I could read it myself now.
Great.
Lesserong.com spelled like it sounds.
You know, we did actually, for the period where we were making Lesserong 2.0 and we
hadn't taken over.
We had the URL, Lesser wrong.
Lesser wrong.com.
Lesser wrong.com.
And then we then made our second sort of dev server, lessist wrong.com.
We then redirected Lesser wrong to Lesserong.
So if you go to Lesserong, it'll take you to Lesserong.
But Lesserong is still just our development server.
You can still go there and see what.
What does less wrong in a week?
That's awesome.
Even Lesserong in the story.
Yeah.
Well, if it's Lesserong, you can't get any Lesserong than that, right?
Well, arguably it could be least wrong, which is less wrong than Lesser wrong.
Lesser's wrong.
Lesser's wrong.
Lesser wrong is not financially available, so we stuck with lessist.
The ultimate one is just going to be correct.
Lesser wrong at all.
Once we get to the transhuman future.
That's right.
Correct.com.
Lesser long is our short form page.
Oh, yeah.
We're going to redirect to our short form page.
And then, I can't remember the other ones we had.
Well, of course, there's great of Ron, who is one of our competitors who makes a different UI for the site.
More right, which I think is like a conservative.
Oh, yeah.
Well, that's more right.
Are they still there?
I don't think so.
I think they collapsed a long time ago.
Sorry.
Cool.
Okay.
Thanks, everyone, and we'll see you in a couple of weeks.
Bye, everybody.
Thanks again.
Goodbye.
Bye.
