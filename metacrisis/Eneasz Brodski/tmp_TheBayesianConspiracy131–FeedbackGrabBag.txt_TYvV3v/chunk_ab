And people still used frequentist statistics like a bunch of cucks.
Oh, you're going to make people mad.
I know some people that still are really strong frequentists.
And there was a big fight at one of the solstices I was at.
Really?
I guess it was a debate.
Like it wasn't like people came to blows, but yeah.
It wasn't like one of those point zero, point nine, nine, nine is equal to one.
Why don't you come say that to my face, bitch?
It was a little bit like that.
I think it was Steven J. Gould when asked, like, what could disprove evolution?
He just said he said fossilized rabbits in the Precambrian.
Yeah.
But like that is that would definitely take a heavy blow, right?
But that on its own.
So like that that might be his scientific position or something, right?
I'm not sure what it proved time travel.
Right.
So like that time traveling rabbits that I think would be more likely or at the very
least, I don't I don't think that would overthrow everything we know about inheritance
and genetics, right?
So like now there's so much.
Yeah. So what I would say is that that would definitely take a hit that would
that would put a huge hit in my confidence in like the classic Darwinian model, right?
No, there's definitely something we don't know, right?
More likely like it's a fake sample, you know, bad carbon dating, something, something, right?
Yeah, or we're in a simulation and there was a glitch because that would just be fucking weird.
Yeah.
That all those sound way more likely to me than everything that we currently
understand about like just, again, the four easy premises of evolution being wrong.
But did you get to, I guess, going back to it, did you get to the feeling the feeling
that before you discovered Bayesian rationality, that it was kind of a enforced almost as social
rules, like you learned them in school or you learned them by reading about how valid
thinking works.
And you were like, yeah, these are the rules and we got to accept them if we want to come
to correct conclusions.
So I think of rationality now more as like social norms, less than social rules, so a
new non-traditional rationality, new rationality.
Yeah, I guess I would say, I guess I could see it like, yeah, these are the rules, right?
You know, that if you if you want to be a good scientist, slash, they didn't use the word
rationalist, but, you know, make falsifiable, falsifiable predictions, etc.
But like I said, a lot of there was no basically like Bayesian is number determined or like
decision theory in it, right?
So as far as, you know, I never got that far in science.
So before I discovered this stuff.
Yeah, I remember it being kind of prescriptivist.
I think that's the word.
It is the word.
It's like, uh, that's a damn good, yeah, way to put it, but it was more prescriptivist
thing than a descriptor.
Yeah.
So, okay, no, the first paragraph makes sense.
Yeah.
He says, viewing rationality as a social obligation gives rise to some strange ideas.
For example, one finds religious people defending their beliefs by saying, well, you
can't justify your belief, belief in science.
In other words, how do you, your religion?
Yeah.
How dare you criticize me for having unjustified beliefs?
You hypocrite, you're doing it too.
And if the rules of rationality are social customs, then it may seem to excuse behavior
acts if you point out that others are doing the same thing.
It wouldn't be fair to make demand evidence from you if we can't provide it ourselves.
I, uh, I invite everybody to YouTube search, uh, Mac, uh, or it's always
something Philadelphia evolution trial where it, I don't want to summarize the whole
sketch, but the Mac is basically trying to make the case that evolution is fake
because science makes you look like a bitch.
Sometimes I prove by, by, by you've been wrong about, you know, they used to think
the earth was round and then boom, he's an idiot.
And he's got like this whole board, took him three hours to put together.
Cool.
It's like a complete, you have to, if you don't have any vibe for the show
whatsoever, this will make no sense.
But if you have seen any of it, then it fits this perfectly.
I swear to God, my dad has used that argument before the whole like, you can't
really, I mean, scientists don't really know anything.
They change their minds all the time.
They used to think this and then they think that.
And you always see like, oh, it was, I forget the other analogy.
He's the earth is round one, but I've, I've had it on more than one occasion
with more sophisticated, argument, eventually retreating back to, I guess,
that science is your religion.
You have some axioms that you just take on faith and that you can't defend.
And that's no different than taking, you know, that God is the original cause on
faith.
So we're both religionists here.
At that point, I usually, like I haven't had one of those arguments in 10 years,
but I, I don't like clearly at that point, we're not trying to, we're
talking past each other, right?
And so it's like, all right, well, you know, yeah, I take like
parsimony, intellectual honesty and evidence as like my axioms.
And if you don't, then we have just different goals.
The thing is you do take all of those things and the rest of your life, you
carve out this one special exception and pretend like you're following the same
rules, but you're not like when you go to the grocery store and, you know, it's
on the left side of whatever the road, you turn left, you don't turn right,
thinking maybe this time, I'll be on the side of the street.
If I pray really hard.
Okay, I thought we were going to get a dog attack.
Should I continue?
Yeah.
All right.
To Bayseans, the brain is an engine of accuracy.
It processes and concentrates entangled evidence into a map that reflects the
territory.
The principles of rationality are laws in the same sense as the second law of
thermodynamics.
Obtaining a reliable belief requires a calculable amount of entangled evidence.
Just as reliably cooling the contents of a refrigerator requires a calculable
minimum of free energy.
If the rules of rationality are mathematical laws, then trying to justify
evidence-free belief by pointing to someone else doing the same thing will be
as about as effective as listing 30 reasons why you shouldn't fall off a cliff.
Yeah, I like that one.
Um, I thought I had something and it's not coming to me.
All right.
So if two parties in a contract both behave equally poorly, a human judge may
decide to impose penalties on neither.
But if two engineers design their engines equally poorly, neither engine will work.
Even if I'm doing XYZ wrong, it doesn't help you or exempt you from the rules.
It just means we're both screwed.
Yeah, I guess the, I like the, um, metaphor of engines.
I think they get more into that, but.
I think that's a, the, the, the primary thrust at this point is what, what Jay
said, you know, a little bit ago, that a lot of people think of the, these rules
as prescriptive, like you must follow these rules to get to correct thinking.
Whereas, or to get to a correct conclusion.
You got to follow these rules or you're bad.
Yeah.
Well, not necessarily bad rational or bad scientist or whatever.
Yeah, you may get bad answers or bad conclusions.
Whereas, um, Eleazar is saying, you don't have to follow anything.
You're just, if you don't, you're not going to run the engine correctly.
It's the brain is a thing that's trying to accurately model the outside world.
That is how it, you know, contributes to our surviving.
And if you, you know, use the laws in the same way that you use the laws of
gravity, you can do things with those.
Uh, and if you don't, then okay, you don't, but that doesn't change what
laws, uh, determine how more likely or less likely certain things are.
Yeah.
Or like, it doesn't matter how well you can argue, like why your engine
should work if you didn't build it, right?
It won't.
Yeah.
Yeah.
That's why I like the, the analogy.
Like he's, he's, you know, the, well, you can, sure you can argue about how
bad your, your contracts are to a judge, but like it, that's like, that,
that's not the same thing as saying, but here's the actual thing you're doing.
Yeah, you can't argue with the universe.
Exactly.
The only way to argue with the universe is to, I guess, you know, arguing
with the universe, you're, you're understanding it and then manipulating it.
Right.
Yeah.
And there's, there's one, there, there, there's a correct way to do that.
And there are lots of wrong ways to do that.
Yeah.
Yeah.
You can do it well or you can do it poorly.
It reminds me of the secret or like D-Pack Chopra or the, the various, uh,
what do you even call them?
Like philosophies where like people literally seem to think that they can
talk the universe into obeying their whims.
And like, like people are like, oh, don't jinx that.
I'm like, sure, like the universe is listening to see like, I hope I don't
get a flat tire on the, on the drive, you know, to wherever I'm going, right?
Like, like, and I mean, and I never, you know, it's never something like I
actually get, I sort of think more is like, don't tempt Murphy.
Right.
Yeah.
But even then too, it's like, because I said that.
So for example, uh, you'll all be horrified to learn if you don't know
the software that like, uh, apparently like hospital staff and nurses and, uh,
the associated, whatever, helpers in hospitals, it's a highly superstitious
bunch.
Oh, really?
Um, and not, not necessarily, I'm not generalizing to all of them, but if
you go to nurses station, like at a hospital and you're like, oh, it's a nice
quiet night, they're like, shh, don't say that, are you kidding?
If you say that, someone will hear you and everything will go wild.
And it's like, can I make a, not a steel man, but a, a partial defense of that?
Of course.
Like a plastic man, please do.
Well, cause this, this comes up a lot when trying to do large group
activities where you have a lot of people, you have very little control over, uh,
in, in my particular example, in case it comes up, uh, when raiding 40 man
dungeons, because that's just what I'm doing.
Now that's where my brain is, but like there's a psychology to it.
Like if everybody is on point and doing things well and focused, then things go
well.
And if people start to get demoralized, things get worse, even though like their
skill hasn't degraded in the last five minutes, you know, it's entirely a
psychological thing.
And like, as long as people stay on focus, uh, things are good, but like if
someone brings up this thing, they really want like a loot drop to happen or
something, if it doesn't, then everyone was thinking about like, Oh man,
I really hope that happens.
And then the psychology is damaged when that thing doesn't happen.
And then everything kind of degrades a little bit.
