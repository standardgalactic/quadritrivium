We should require evidence and reasoning as well
and make our judgments based on that.
So I feel like that was kind of a good hybrid point,
and the Christianity puzzle,
maybe I didn't deliver it right in that post,
but that was sort of brought up as a way
to kind of just bring an intuition pump
that there isn't, it's not enough to hear a counter position,
enough times to update.
There needs to be more to it than that,
and Cale Silverhand hit it on the head.
So, yeah, go ahead.
Oh, no, you, yeah.
Okay, I think, so this brings up a really interesting aspect
of the whole overcoming bias slash less wrong original reason
for being.
It's, I don't want to use the French version of that
because it sounds too pretentious.
Go for it, because I don't know what it is.
Raisin d'etre, I believe, is how it would be pronounced.
I've definitely heard that.
I didn't know what to, yeah.
Yeah, but the-
I'm uncultured, we're not that uncultured.
Okay, the thing is the, this all originally spawned from the,
God, was it the SI4 forums?
A correction, that's the SL4 forums, not SI4.
It was a community of people talking about how to build AI,
and the coming, I don't want to say the coming robot overlords,
but you know, the post-singularity world,
where we will have programmed beings that can both think
and upgrade themselves and interact with the world
as actual beings, right, except in machines, in computers.
Artificial intelligence, and so a lot of the discussion
pertains to how to think about thinking
when you are trying to create that sort of intelligence
and how they would work on updating probabilities,
how we can relate to our lives.
A lot of this is about making programming God, right?
Like, how do you make a God so that it turns out friendly
and so that it knows what we want
and informs accurate beliefs in general?
Yes, exactly.
So a lot of the rationality project was butted from this original,
kind of almost platonic rationality discussion
about like the ultimate true rational agents
that can see each other's source code
and backtrack through how that other agent came to this belief.
And so now you have shared evidence
and it doesn't quite apply to humans, exactly.
The platonic form of the rationalist.
Yes, the platonic form of the rationalist is a machine God.
So it's interesting that it doesn't always translate directly
to humans because, yeah, we cannot explore,
cannot see each other's source code, right?
We can't even see our own source code.
You what?
Except we can't even see our own source code.
Right, exactly.
And so that is why the rationality arts
do not translate perfectly to us.
For humans, they're more of an art than a theorem.
An exact calculation, yeah.
And to be fair, Kale Silverhand does say
as flawed rationalists, we can, etc., etc.
So we're doing our best.
But yeah, in the game where you're playing with perfect players,
then the rules are different.
And actually, I guess you can actually just follow the real rules
rather than approximate them like we have to.
Right.
And so every now and then that does come up in these sequences
where it becomes clear that a lot of the discussion
comes from thinking about the Platonic Machine God rationalist
and pointing out how that doesn't quite fit
with how we try to implement rationality as humans.
Which is where I think Eliezer was coming from
with the modesty post.
He was responding to the Amman's Agreement theorem
that says that two rationalists cannot agree to disagree.
They will eventually come to the same answer
when they compare all their priors
and the evidence that they've accumulated.
But that doesn't really work for humans
because we can't do that the same way
that a perfect rationalist would.
Yeah, I mean, and also there's preferences
that you can't agree on.
I don't know if that's relevant or not,
but for example, if I like pizza and Steven likes soup,
then we can talk about it all day.
And if we're two perfect rationalist gods,
we can give our best arguments.
But in the end, we just have two different preferences.
Soup is clearly the superior food
because you can carry enough thermos.
And I have a strong value towards carrying my food in thermos.
Yeah, no, that's a good point that none...
And I'm sure there's a word for this that I'm blanking on.
I guess, I mean, subjective versus objective truths, right?
So objectively, there's not a fact to be found about
what's better unless we can define important parameters,
but nutrition, taste, or whatever, right?
Mouth feel.
But subjectively, I might just like one more than the other.
And so, yeah, that's an important distinction to draw too.
And that's why humans are cool.
Yeah, I mean, it's not cool
that we're not like perfect robots,
but we do have this kind of cool experience
that we get from being awkward and broken.
Speaking of having cool experiences,
Jay Michael wrote in on my joking suggestion
for the aspiring supervillain
to pump a bunch of DMT into the local water supply.
I like Scarecrow from the first Batman movie,
the first good Batman movie.
Regarding the suggestion of, quote, DMT in the water,
unquote, normally I'm all for consensual participation as well,
but philosophically, if enabling people to experience the perception of correctness,
of connectedness, can help them be less despicable person
and actually be more mindful and empathetic of others,
then that would be theoretically increased
to consideration, cooperation, save lives, reduce suffering,
improve humanity as a whole, so on.
So it seems like grownups knowing better
and making their kids eat vegetables,
or at least an ask for friggin' investigator situation.
That said, I don't really endorse this idea.
That said, if you're seriously considering being a crazy supervillain,
there are worse things that you can do,
like blow up the earth or something, right?
So I'm kidding.
I never drug anybody without asking.
Unless you can drug the whole planet at once,
then maybe you just see what happens.
I kind of see Jay Michael's point.
It's the same kind of thing where
Ozzy Mondias murders all of New York
in order to get the world to unite
and not destroy itself in nuclear fire, you know?
Right.
This is the antagonist of Watchmen, not the blogger.
Antagonist or protagonist of Watchmen,
depending on how you read it.
Even though they always make the utilitarian the bad guy.
Yeah.
When he clearly, he's saved the world.
Yeah.
I mean, sure, people died,
but a lot less people than others would have.
That's the reason people don't like effective altruism either.
Yeah, bunch of nerds.
Ozzy did nothing wrong.
Yeah, so, I mean,
on the one hand, I see his point.
On the other hand, I think there's very strict norms around
consensuality, consent.
Yeah, that are there for a very good reason.
And I would rather blow up half the United States
than blow up the planet.
Yes.
Even if it's half the United States that I'm on.
Yeah.
Like I'm right in the middle, so.
Yeah, but I mean, that's assuming that you're in a situation
where you have to choose, you know,
you're in a trolley problem situation,
push this button to blow up the planet versus not like.
But he kind of was.
But you don't know where the earth is going to go
if you don't give people DMT.
That's, I guess Ozzy has this whatever hand wave
that he was supposedly way smarter than everybody else.
I thought we were still talking about DMT, never mind.
Oh, no, yeah, you're right.
With the DMT thing, I'm totally kidding.
Don't, don't, that's.
I think the poster was kidding.
Don't drug people without their consent.
Right.
Well, I mean, the poster kind of has a,
so I take this, I think people have to have done
something wrong first in order for you to take their consent
away to make them better people.
Like the clockwork orange.
Like children.
Like children.
Like children.
Like children for your child.
Yeah.
Well, I take the clockwork orange example,
where I think they absolutely did the right thing
by making, what's his name?
I don't remember.
I didn't see the movie.
Oh, okay.
The protagonist.
The kind of.
The main character.
