In that case, next time we will be doing radical honesty.
We don't really want your participation and applause lights and applause lights is a famous one.
Yeah, just gonna say that's one of my favorites.
Yeah.
So hitting another big one next week or next episode.
All right.
For tonight.
For tonight.
Yeah, that's a word we need in American English more.
I mean, we kind of have it, but not for the.
It's weird that a video game introduced it.
Is the length of time that you play in fortnight actually one fortnight?
No, I don't think there's any relationship to the concept of time.
And they're in your build forts.
Yeah.
Yeah.
Yeah.
Yeah.
I think it's not even a word and it is not a word in English.
Right.
So it's just it's a made up thing.
When you're doing branding, you have to spell words wrong.
Right.
It irritates the hell out of me.
And I'm always like, people who don't speak English as their first language must be like,
like very frustrated by every business name and app name.
And it's just okay.
Because Americans are illiterate.
What's going on?
Yep.
I remember being a child and like being like just outraged every time I saw kids with
the Z.
Couldn't we just make like school is cool.
But with a K and just like clinics and Xerox, those were both just made up words.
Speaking of making up words said way.
Our actual topic is GPT three, because we've been wanting to talk about this for a while.
And we have, we'll go.
I was going to say, I feel like this will be a lot of fun because we've got actual experts
on.
We talked about GPT to the years ago when that happened.
But and we had a, a.
It's like a cringe memory of mine because I was, I remember it was just like, I don't
know anything about this.
Yeah.
Here's some things I've read.
I'm still playing from that point of ignorance, but we've got more people on the air side
to get to listen and ask one or two questions that, you know, for the lay person who has
no idea what any of this is, what is GPT one, two and three and why does anyone care?
Go take it away, Daniel.
Yeah.
So, uh, all right, I have to have to mentally wind back for a, no, I got it.
I got it.
I'm ready.
All right.
Ready.
All right.
So it's sort of an outstanding challenge in the, the like research community around modeling
language and the abstract to be able to write programs that can sound like humans.
And, you know, for, for probably 30 years, there were a whole host of tools made for
this where they, people came up with increasingly clever and more clever algorithms that could
spit out, uh, you know, human, human looking texts.
There's a, there's a very famous example of a chat bot from like the sixties even that
could like, was Eliza the sixties?
Does anybody know that?
I don't actually remember the name.
I don't think it was the sixties though.
You know what?
We're gonna, we're doing it live.
The internet.
Eliza.
I see at least two people tapping away.
Oh, from 1964.
Oh, shit.
Yeah.
Okay.
Cool.
Made at MIT.
Yes.
I was right.
Um, but yeah.
So they, we've, we've had, we've had models that can kind of, kind of make language for
a long time.
Um, Eliza's trick was, was really a trick.
It was kind of a, a, almost a mirror for, for what people said to it and it had a couple
of like throwaway tricks where it'd be like, I'm just making something up and like, oh,
well, what do you think about that?
Like something like this where it's like a canned response that, that seems very human
like, but you know, doesn't, doesn't really contain anything because it's, it's, it was
just, it was made that way by the program to be, to, to, to kind of fool a human.
And there's, there's also this whole, you know, Turing testing where scientists want
to be able to make, uh, an intelligent agent that could trick a human into thinking it was
the, the agent itself was a human.
And, and this is, this is seen as in by many as a kind of grand prize of the language modeling
world.
Um, actual language modeling researchers would completely disagree with that because they
don't actually care about the Turing test, but this is, this is, this is the perception
of the Turing test.
Um, so over, over the decades,
I remember there was a chat bot that, uh, they said it like defeated the Turing
test, but the trick that they used with that one was the, I think they said that it was a
teen girl who didn't speak English as her first language.
So that she would just be snarky or like flippant.
Yeah.
There would be like answer or like, you know, would like pretend to be confused by the
language, I guess there used to be, there might still be like annual competitions on,
uh, Turing tests and you would get like the program that's like that rated the most human
and then the human who fails the most.
And I can't remember if this person was on rationally speaking, or if they were just
talking about this person or wherever I heard about it some five plus years ago.
But yeah, they, it was talking about the guy who was rated the least human out of all
the people because people, more people thought he was a robot than anyone, than anyone, than
any, whatever the number.
Yeah.
A great hack would just be like, I'm sorry, I really had a lot to drink.
Yeah.
Yeah.
So like, I mean, the point being here that like, it kind of became to beat the Turing
test, people kind of came up with tricks and, and over the years, the language modeling
community has been trying to try to understand what about language is so hard to like actually
mimic and not, not just in a, like a tricking a human kind of way, but in a like actually
solve interesting problems kind of way.
So there's, there's a whole bunch of different like, like tests that people have come up with
for, for language models that are, that are both hard for humans and, and hard for algorithms.
And a lot of these things are like, you know, it's like literally a list of sentences and
sentences or things like, you know, you pick up a cube, you put it on a table, you take a book,
you put the book on the cube, where is the cube?
And then it's the answer is something like under the book or something like this.
And people can like, programmatically generate huge lists of these things.
And they train language models on these huge lists.
And they, and by that, I just mean they, they write clever programs to try and
learn to do these kinds of things.
And they got, they're like, okay, at them, like they, you can, you can get, you could get human
performance at a lot of these tasks.
Yeah, that's really interesting.
Probably by the late 2000s.
Because that's also how you test your children's language or language and also just,
what is it, theory of mind?
And that probably is why language is so hard or one of the things anyway.
Yeah.
And it's also sort of just completely unstructured or rather it's, it's extremely structured.
It's more like, it can be about anything, right?
Like it's, it's, if you're a human trying to really detect whether or not a language model is,
is more than just a bag of tricks, it's, you can pretty quickly come up with these scenarios
where you, you know, you, you chain together a bunch of, of relationships, like things inside
on top of other things.
And most language models up to circa 2016 would just fail miserably and would also
fail at a whole host of other really hard types of language tasks like this.
What did you mean by it's really unstructured?
Um, I, I kind of misspoke, I meant more like language can be about anything because it's
sort of a universal representation.
So it's, it's like almost maximally difficult to try to, to solve in the abstract because
it, it's a, it's a nearly universal representation for almost any topic you, you can,
I mean, we, we use it to think about everything, right?
Like it's a, it's a multimodal can be about anything, can be tested on anything,
can describe anything modality.
And the sounds we use are chosen completely at random.
Yeah. Yeah.
If, if we can't talk about something, we just invent a new word and then we can talk about it.
Yeah.
And languages evolve strangely for efficiency or for style.
Yeah. Right. Right.
I kind of want to see GPT come up with a language.
Anyway, so GPT, GPT stands for, uh, actually I had to look this up because I was,
for some reason had the wrong idea, uh, generative pre-trained transformer.
I thought it was like general, general something.
Yeah. I thought it was general purpose transformer for a while.
I was going to guess general predictive text or something like that.
But yeah, this is a surprisingly poor name in the, in the research community.
They usually come up with pretty good acronyms for things like this,
but this is just, just GPT and it's a, it's a thing.
So it's specializing on language stuff.
They sucked at this name.
Yeah.
Maybe they didn't expect this one to be the one that solves it.
Can you rename yourself?
It's true. It seems like, it seems like open eyes names are almost, are always bad.
You know, I, I think they, they intentionally don't try to brand all of their models,
like DeepMind does or like NVIDIA or Microsoft or whatever.
Unless you're an astrophysics, then everything is named perfectly.
What's that dark hole looking thing in the sky?
We'll call it a black hole. Perfect.
No, physics is pretty good.
So GPT one, GPT one came out in 2018 and it was a,
I mean, not to dive too much into like technical specifics.
It's, it's just a, a very specific type of architecture,
like neural network architecture using a component called a transformer.
It's not super important what the, I mean,
it is super important for how it works, what the transformer is,
but a transformer is just a, a gadget that was invented a couple of years ago.
That just works really well as a general purpose computing unit.
So you can, if you just think of neural networks as kind of black boxes that you use
to, to learn representations and data,
there are a whole bag of different components you can put in these,
in these networks to make them do different things.
Transformers have been found to be quite broadly useful across the board on,
on lots of different types of tasks.
So everywhere from like text to images to sound,
they're very good at modeling sequential data specifically.
Um, can you go a little bit like more,
I don't know, like a brief overview of how a transformer works,
