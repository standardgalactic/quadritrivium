as big as GPT-3 with enormous context windows.
So I don't think this is a problem for like the next five years.
It's just hard research work.
Realistically, we don't really want an entire young lady's primer.
That was a cool sci-fi thing,
but we just want a number of teachers in various subjects.
If they could just know that,
you know, this is what I've already taught it in this level of this subject,
taught it, taught the child in this level of this subject,
that'd be probably enough.
Yeah, but I mean, right?
Yeah. I mean, it can already do that.
Like it's a, they found one funny,
one funny thing they found was that if you prime it with,
this is a teacher's, this is the solution guide for an exam,
it gets way better at telling you how to do physics problems.
So it's, it can, it knows, it knows stuff.
It's probably read most of the like, you know,
homework help websites on the internet.
I think, you know, it's,
you really got my imagination going with this idea of like,
what is a teacher when you have a kind of
tool or whatever word you want to use that,
that will kind of sit there with the, with the child or with the learner,
right?
It doesn't have to be a child and be like,
all right, what is the answer to this?
And then you give it the answer and it's like,
okay, this is your misunderstanding led you to that, right?
So then the teacher is someone who kind of stands a level above that
and is like guiding your path through the larger space of,
of the domain on a, you know,
on a, you know, maybe you have a weekly meeting with your teacher
instead of having to sit and listen to lectures all day.
And then the teacher is like, let me,
let me gauge your, your sort of integration of these concepts
into your worldview, things like this.
I mean, this, I think that'd be really, I mean,
I, I hate, you know, everything about the lecture model.
So stuff like this sounds really fun to me and exciting.
All right, we have been, we've been going for a while.
Were there things people wanted to bring up in our final minutes here?
Um, I've probably rambled.
I mean, I can, I can always ramble more.
I think I've hit all of my major bullets.
Yeah, I think that the one thing that I walked in telling myself
that I would do is not conflate what GPT three specifically is with
highfalutin expectations of, of possibilities in the future.
And I think we did okay keeping those two things somewhat separate.
I see, I see so many stupid conversations,
like like avoidable misunderstandings because it's like nonsense.
GPT three can't do that.
And it's like, no, yes, it can't do, it can't do the illustrated primer.
Something we'll be able to though.
And it probably will have something that looks kind of like a transformer in it.
I don't know if it's worth getting into because I feel like probably most of the
major like online publications have already talked about this,
but like any, you know, what's the new fear mongering?
Like, who's it going to impersonate?
Is it going to ruin politics?
Like, but, uh, I also,
I mean, it's a, that's a fair question.
I don't think so just because I think the, the sort of waterline of discourse for
that kind of stuff is already so gargling that it can't really fall much more.
It could only make it better.
And by better, I mean, maybe just funny.
I mean, it's like, I was only kind of joking when I said that I think
that the world will be improved without these like online
I didn't think you were joking at all.
I didn't, I didn't agree with the non-joking version of that.
Yeah. Like, like, and, and I don't know.
I think having something that is intelligent,
that we can kind of tap into at will in a way that we can current,
like we can tap into Google right now and get really good answers.
You can go to Wikipedia and find out about stuff.
What if you had something that's just smarter than you that you can ask questions?
You know, like that's, that's good for everything.
But I think one of the things that's good for is politics, actually.
And I'm not sure it would really detoxify the social space because
most of the people that I end up getting into, not most,
half the people that I end up talking to on Facebook are people that I know in real life
anyway and we disagree.
But on the other hand, we're still friends on Facebook because we can disagree cordially.
Yeah. And the friends of friends is where the real shit flinging happens.
Yeah.
Because I don't know them.
So how long until GP3, GPT, well, GPTX makes Alexa better?
Because lots of times I ask Alexa things and she doesn't know shit.
She's like, here's something I found on the web and I'm like, that doesn't help me at all.
Yeah.
I think I just saw an article about that.
Yeah. I mean, that's...
What is your prediction, Dale?
I...
Give us, give us tight timetables.
See, that's the thing is I love to make predictions.
Like, like we already have, like you've seen,
you've seen the thing where it can like hold a phone conversation with someone and the person
barely knows they're having.
But that thing doesn't know, you know, it doesn't have Wikipedia in its mind.
It's just good at having a phone conversation.
So it's like, maybe, like that's...
This is one kind of open question I have that I'm just freely speculating about is like,
is like, what's the path?
Is the path like, you take that thing and then you duct tape it to a transformer model
so that the transformer model is generating text and then the voice thing is saying it?
Or is that the wrong approach?
Do you want like an end-to-end fully coherent model that hears English and speaks English,
you know, verbally?
Like, and that's...
I'm curious to see...
Yeah, no, that's a good question.
I think also curious to see, I think there's a lot of hard problems in like prosody and like
how things are said in the sort of information content of delivery
that would make the stitching thing hard, because you'd have to like both turn text to
speech and then have some additional context seeking nugget that can like figure out how to
deliver it correctly.
Whereas you just solve that problem automatically if you do it end-to-end.
I don't know.
Good question.
I mean, maybe this can be a short answer or not.
So when we were speculating about stuff to talk about, my thing was the physics one and then
Jay said asked when you're brainstorming on discord, like an interactive chatbot for like
basically therapy.
And so like when I...
And I could even reframe like the let's learn the whole edifice of the, you know,
combined human knowledge and just say everything you would learn in an eight-year course.
Like that's just going to be two, three dozen books.
Like that seems super doable.
But if it can't remember what you started talking about at the one hour beginning of the session,
like, well, so there's, I mean, you could do the unsupervised training on, you know,
a course load of physics.
And then in principle, fine-tune additionally on top of that and then ask it physics questions
that could fit within, you know, a thousand.
I meant like even just therapy questions because, you know, I think they've got chatbots that,
I forget what it's called.
Well, Eliza from the 60s.
Yeah.
And it's, you know, little things like that.
But it could be a pretend buddy you're texting about your problems with.
Yeah.
Like rather than, you know, bog down one of your actual friends.
Someone did this.
Someone, someone actually...
A bunch of people.
I'm positive.
I'm actually looking at a Reddit that says,
Olivia loneliness during the pandemic with GPZ3 chatbot.
I just, I get the feeling it takes more than 1000 tokens to make a
accurate model of another human's brain so that, you know, you can interact with them consistently.
But you could probably have a...
I mean, I don't even, I'm not even joking.
I like, I think, I think a lot of information is, is like hilariously compressible.
So like, sure, you won't be able to like communicate, you know, the HD video of an
entire person's life.
But like, like you can, you can get surprisingly far with surprisingly few bits of data about
everything.
But you expect your friends to remember small, intimate details about your life that you
shared once when you were, you know, drunk and vulnerable, which just GPZ3 doesn't matter from
for you, right?
No, so yeah, yeah, totally.
So, but like, imagine, you know, GPZ3 plus a language, plus a memory module, which stores
a compressed representation of everything that you've ever done with GPZ3.
And like that, that sort of thing starts being kind of scary powerful because now it can,
in principle, remember almost anything.
There's a thing that OpenAI does, sorry, that AI Dungeon does where you can tell it to remember
something.
Like, you can be like, remember, that I have the dagger of or or or or orc rist.
And, and then I don't actually know what it's doing, but I assume what it must be doing is
just like reinserting that into its own prompt feed regularly, so that it doesn't fall off.
And yeah, probably literally, just at the top, it's like, here is a list of things to
remember all of the things you told it to remember.
And then the normal priming, I think what Daniel said, like, like, actually,
they'll just need to do the next generation and then we'll get there.
And I can imagine that you could already have a conversation with a friendly stranger,
like a therapist or a counselor, coach of some kind, because like, okay, maybe they
don't remember the previous sessions you've had, but each time if it's like, I don't know,
I'm having an argument with my significant other about this thing, like, what do you think I should
do? And it's going to be able to pull from all of the advice on the internet and probably give
you good advice. Could it write the personal data it finds out about you and use that as part of its
training data? Maybe privileged training data? Yes, but the main blocker is that it's really
expensive to train right now. But like Matt said earlier, like this is, I probably within like five
years, these will be trainable for not insane. That's awesome and exciting.
I have, I guess one final thing. This was some listener feedback, actually. MQP from a discord
said when we were talking about GPT three, while we're on the topic, I listened to the podcast
and it sounds like you guys are confused about the difference between GPT two and GPT three.
It's not the amount of training data. It's the number and arrangement of quote neurons, so to
speak. So it's not the case that quote running out of training data quote is the kind of bottleneck
for training fancier future versions. They might have misunderstood. Okay. So
yes, GPT three is also larger than GPT two. Like that is that is definitely like hugely
important that GPT three is like 100 times larger in terms of number of parameters. There's an
interesting like scaling relationship between how much data you think you need and the size of the
model and like whether or not the model will converge or something like this. So if you if you
literally made the size of the model three orders of magnitude larger, so like literally like 10,000
times larger or something or 1000 times larger, there might not be enough like if these scaling
laws didn't work the right way, there might not be enough text to successfully hold the internet.
But this might be a very, this is like a very technical thing. Like I don't think this is
actually a problem looking at at the sorts of scaling relationships that we see. I think
even if you used I think all of the the text on the internet is enough to train even even like a
five orders of magnitude larger GPT model. So that's that is not actually an issue. But it is the
