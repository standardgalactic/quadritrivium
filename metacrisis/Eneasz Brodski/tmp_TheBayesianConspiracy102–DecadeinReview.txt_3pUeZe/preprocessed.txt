Welcome to the Bayesian Conspiracy, I'm Inyash Brotsky, I'm Stephen Zuber, I'm Jess Dickey,
I'm Matt Freeman, welcome back Matt Freeman, thank you very much. Matt, so most people probably know you as the guy from We've Got Worm,
We've Got Ward and the Doofcast and also soon coming up and what's new Dark Tower one called? Kingslingers. Kingslingers, right?
This time I will be the Scott and Scott will be the Matt. It's gonna be so weird. Yeah, but we had you on before was it just once?
We had, I came to talk about rational parenting once and then another time I feel like we ended up talking a lot about community, although it was supposed to be I think to talk about seeing like a state.
That's kind of appropriate though. Yeah, I remember you didn't get to talk too much about the rational parenting because you had that terrible migraine that got you, which although update you don't have those anymore really.
Not nearly as bad yet, but it's much more easily handled due to the progressive technology and transhumanist development and so forth. So now I'm mostly fixed, which is, which is nice.
Fucking awesome.
Not transhuman yet, but trans Matt of three years ago.
Yeah, on the way.
Awesome.
I was curious how the rational parenting thing is coming along.
You know, I don't put a lot of conscious energy into engineering their lives, but I do certain things like I got a three printer and they're really like Marvel. And so we're basically very slowly building like an Iron Man suit.
Basically the purpose just being they think it's cool and it gets them exposed to all this technology and science concepts and I'll just like blather about the engineering behind what we're doing and if they pick any of it up. Great. And if not, we're still having fun and it's that's kind of what it's all about.
So I try to do more stuff like that and less like alright today we're going to sit down in a circle and practice our our catechism from the sequences.
Yeah, I might work up to that at some point.
So that's that's basically sounds like unschooling almost.
I mean, they're definitely going to normal school, but yeah, just kind of doing things through play because like they're not going to pay attention and they're going to be annoyed and they're going to go they're going to groan if you try to lecture them, you know, so at the ages they are anyway.
Do you have any opinion?
I only bring this up because Wes is very active on the discord so I see his comments a lot.
Do you have any opinions on the whole unschooling thing? Do you think it's a terrible idea?
I don't think it's a terrible idea. I think it depends on the kid and the situation in general.
I'm sure it works great for some kids. I kind of feel like it might have worked for me, but I definitely feel like I know some people that it wouldn't have worked for at all.
And I don't know, you know, I think you have to have a certain kind of infrastructure in place to even make it work.
I haven't thought about it seriously because I don't know how that would work with three kids so closely spaced together in age.
Yeah, lots of factors basically.
Plus you would need someone to watch them during the day while you're at work.
Exactly, and that's probably the deal breaker actually is like the function of school as daycare.
Yeah, that's like the structure part of that.
If I ever have kids, I'd really like to do the unschooling thing, but then yeah, it's also you never know whether or not you're going to.
Yeah, I mean like you have to have a parent to stay at home with them.
Would be great is if we had a big rationalist group house and one person that like didn't have to work anymore and they could just, you know, daycare the kids.
Long term goals, which could that be a segue into our topic?
It could possibly if that is our topic.
I don't know.
The problem is I haven't thought about this topic at all because I thought that Steven wanted to do a 10 year retrospective thing.
But on the other hand, like if Matt's here and you guys want to talk about the community thing we could.
Could merge those things together and just say like how the community has progressed over the past 10 years and where we want to see it go.
I'd be interested in talking about that.
That sounds good to me.
Well, once we get to the future part of the present.
Yeah.
Okay.
So in that case, Steven, you pitched this to us.
I will be frank.
The half the reason the other reason I invited Matt was because you sent out this cool email that was like you have.
It was like a kind of an open journal thing.
Oh, yeah.
And you were keeping track of like here's what my goals were in 2013.
I realized that was not structured enough to like actually track progress here.
They were in 2014 and 15.
And then it was just you actually like regimented in a way that at least more than anyone else.
I knew like actual goals and progress over the last 10 years.
And so I thought it'd be kind of fun.
I don't know.
It's a lot happened in the last decade, which I guess that's true for literally everybody.
And every decade.
Yes, exactly.
So much always happens.
Yeah.
But you know, it doesn't have to be all this boring personal stuff.
And yeah, I didn't have like a lot on the subject.
I just thought it would be a kind of a fun just first episode.
Oh yeah.
This is the first time we're recording in 2020 because we split the episode into two parts.
So yeah.
And sorry again for the audio quality on that.
We have learned from our mistakes.
Hopefully.
I thought that was fine.
We learned a little bit anyway.
It's going to continue to be probably a weird work in progress, but we'll we'll just gradually get better as one does.
It seems like that's going to happen when you do weird stuff involving people calling in and such.
I'm kind of surprised you write down your goals because I don't know.
I've never had the courage to write down my goals because then there's no evidence I failed at them.
Yeah, I can explain this.
I mean, since I wrote a thing about it, like this is connected to the fact that like, I guess it was like seven years ago now.
Me and and a handful of my friends.
We wanted to keep in better touch after college.
And so we would do this like biweekly or maybe it was monthly Skype call where we would just like talk about like some topic that we had agreed on beforehand.
In a very real sense, this eventually evolved into doof.
But it was mainly just a thing to keep us together.
And like I started like one time we were like, we should have we should have like a New Year's goal thing where we all have New Year's goals and we hold each other to them.
And I was like the only one who took this seriously.
But then I started like giving the monthly updates on my goals.
And then I just kept doing that for seven years.
Did anybody else get inspired by this and also start doing it?
Not really.
Although I eventually posted unless wrong about it and people were like, this is an awesome idea.
I'm going to try it.
I don't know if anyone's tried it there either.
But this is the closest thing I have to like a journal is like a monthly kind of roundup of like, what have I been thinking about and what is my progress been on whatever I wanted to do.
And I guess like the thing that I wrote in the thing that I sent to Steven and all the Patreon patrons was like, I have this.
I haven't quite solved the problem yet, which is kind of embarrassing because it's been seven years.
But like the first year I had like 10 very specific goals.
And then the next year I reacted to that.
I was like, that was stupid.
I'm just going to have like three kind of general focus areas I want to dwell on.
And then the next year I was like, that was stupid.
I couldn't tell if I accomplished anything because how do you know if you accomplished anything if it's just a general focus area?
I need five very concrete goals.
And the next year I like, I just like kept seesawing like, and I never at any point, like still I'm not, I, I don't know what I should do now.
Should I pick concrete goals or should I have a general area that I focus on?
The nice thing about concrete goals is at least you know if you accomplish them.
So you could always just keep waffling back and forth between the two.
That's true.
So it worked out so far.
That's true.
Yeah.
One year work on very specific things.
One year, you know, on general bettering.
I think I've, when I have tried to make New Year's resolutions, I will try to pick a kind of a combination of the thing you were talking about where it's like one or two specific goals that I feel like I will make.
I hate the smart acronym.
I guess that's the specific measurable, et cetera.
But like, it does kind of make sense where it's like, by this time I want to have achieved this and this amount.
And then some more vague ones where it's like, I want to do this more.
I want to like be able to point myself towards this thing a bit.
I always having a combo is nice.
I always kind of hated New Year's resolutions because I thought my thinking was if you want to do something you actually want to do it.
So you go out and do it and making a resolution is more like, I want to want to do this.
So then you just beat yourself up all year about not actually doing it.
Whereas if you wanted to do it, you wouldn't even need to make a resolution.
You just go and do the thing.
The art of wanting to want is really important though.
There's, I mean, I've described my, I've been trying to break down the process that I have used to improve for various people that are like interested in what I did.
It's hard to go back and think about what I did, but like, some of the things do have this very complicated structure where it's kind of like, I was describing it as,
I kind of had this goal far in the distance that I'll occasionally joke about, well, I want to be a scientist.
And then I'll kind of side eye it and I'll be like, well, whatever and slowly just sort of inch towards it.
But like by tricking myself into like not really being that intimidated by the fact that I'm doing it until I get close enough to it that I'm not scared of it anymore.
That's a really like complicated way of explaining the thing that I do.
There is something really intimidating about facing a very like long term difficult goal that feels pretty hard to achieve and scary.
And I don't know, some people probably naturally are just like, yeah, I'm going to do that thing.
And then they just can throw all their energy and self-esteem on the line like that.
I can't.
I when I when I wanted to write the book, I just kind of sat down, wrote the book because I wanted to.
Now I want to get back into writing because it's been a while and I fallen out of it and you know, there were there were reasons for that.
But now I feel like I have this goal of getting back into writing and it is almost anti motivating.
I'm like, I don't want to start working on that yet. I'm just going to wait a little longer.
Yeah, you want your goals to not be aversive. Like you're comparing yourself to this future you that seems unattainable.
I've probably given like $200 to B-Minder due to failing because I tend to especially like on those years when I have the really specific goals.
I'll set up a bunch of B-Minders and it's a horrible idea.
And I kind of like the concept of B-Minder but all it ends up doing is just like I'm convinced this is like part of the whole headaches thing is like is I like grind myself into doing the thing that I kind of like meadow want to do but don't actually ever want to do in the moment.
And it causes a lot of stress and internal conflict and friction and just like something like, you know, you want to get better at playing an instrument or whatever.
And it's like, OK, but practicing to get better is never actually fun. Playing songs is fun.
And so you're basically just making yourself do something terrible and it's it eventually breaks down.
And that's I think that is one kind of learning that I can take away from years of iterating on this process.
And it sounds just like you kind of arrived at a similar conclusion that like if you want to if you want to kind of get yourself to do something that you don't really want to do, you have to go about it in a pretty tricky circuitous fashion.
Yeah, I'm pretty sure all the guitarists that I've seen interviews with never really disliked practicing.
They just like noodling around on the guitar and they found that fun and they got better just doing what they thought was fun.
I have a yeah, something to say about that.
So the most aversive part of learning a new skill is being really bad at it and having it be completely incomprehensible and like pushing yourself to do it and just making no progress.
So when we learn skills, a lot of that process happens when we're a kid and everything feels like that when you're a kid.
But when you're a kid, you don't have the pressure of you should be good at things.
When you're a kid, it's like you're a kid. Of course, you suck at everything like do whatever you want, you know, play.
People encourage you to play with a guitar.
So when you're a kid, you're like, if somebody gives you a guitar, your family plays guitar and you're just like screwing around with the guitar being terrible at it.
Nobody like thinks that you're a terrible person because of that.
I mean, that's how I basically learned programming.
Yeah, that's how I learned art.
I mean, like somebody gives you something, you're a kid and it doesn't matter being bad.
But when you're an adult being bad at something and taking a long time to get good at it just feels terrible because we're adults now and we're supposed to be good at things.
And we're supposed to be able to be more logical at approaching it.
We're supposed to have that self discipline.
That's stupid.
Yeah, I don't remember being a kid.
I imagine that's probably what it was like learning stuff.
Stephen was old since the day he was born.
Basically that and I just I mentioned before my autobiographical memory is terrible.
Like I couldn't give a range unless it's a very specific thing like usually within like plus or minus two years.
But my my only way of like achieving goals as long as that's the subject, I need like an external motivating factor.
And part of that actually I got from reading Childini's influence science and practice and the like the public commitment and consistency I use all the time for myself.
And so like if I don't feel like putting together notes for we want more or something, I'm like, well, no, we're recording in a couple days and it has to come on Monday.
So like, no, it's going to get done.
And I if there's if there's any public commitment to do it, I don't think I'm trying to think of any time recently where I've like flaked on something or failed to do something that I committed to doing publicly.
Certainly I don't like misobligations that I made with people.
You know, I can't even think of anything that's come up in the last year where I've been stopped from doing something I wanted like I said, I'll be there be there meet somebody and I totally forget or something.
Yeah, when it comes to like learning hard things, I'm not a self driven person.
So like, since I wanted to get into programming, the option, I mean, there's if you're a self motivated person with the energy to get started and maybe a couple of good resources that's on points in your direction just from ground up, you can totally get going and do it yourself.
I'm not that guy.
So I found a bootcamp and I also didn't have a job.
So I spent I was able to spend like 100 hours in the eight weeks or so.
No, I don't know, whatever.
Yeah, a couple months.
That sounds about right.
I'm doing prep work and this and that.
But I chosen in person bootcamp in no small part because I'd have to go there every day and do it.
Now that I work from home three, three or four days a week, I have no trouble staying motivated because like now and even like learning new stuff for my job.
It's it's easier because the stick is there.
And it's like, if I don't learn this, I don't get to keep my job.
Like it's never, you know, that's never been a thread.
But it's like, figure this out now you have to because you're getting paid to do it.
That's that's plenty enough motivation for me to learn stuff now.
But speaking about not having energy for things, I have like a whole new level of respect for you.
And I mean, like, I never disrespected you.
Like you're you're awesome and I respect you a lot.
I'm going to read into that.
Okay, good.
Good.
But I so I'm not sure if I mentioned it on the podcast, but I managed to injure my back a few months ago while doing squats in bad form.
Note on everybody.
Don't get lazy about your form.
But your reps with less weight is better than like more weight with worse form.
Yes.
Yes, absolutely.
But I created a disc and I'm going in for surgery next week on Wednesday, which is great and all.
But the past two weeks, I have not been able to be on any of the anti-inflammatories, the good drugs, you know, and it is remarkable how hard it is to do anything when you're in constant pain.
I just I have no motivation.
I don't want to do shit.
I can't even like think of doing stuff.
And I'm like, oh my God, like Stephen has this intermittently his whole life.
Like how how do you get things done like blows my mind now?
I'm feeling embarrassed and spotlight on that.
Oh, shit.
Sorry.
No, no.
I in a polite way, I appreciate what you're saying.
It's not nearly as heroic or gallant as it sounds and your discomfort is no doubt worse than what I'm going through.
It's I at some point you just like I will not I can't generalize the way that it worked for me was when it became apparent that there was like no viable treatment options to like fix it.
All right.
Well, then what are my like non physiological things I can do to fix it?
You know, like I do nightly PT.
I am constantly like aware of like form and come, you know, all this and that.
But mainly it's just, in fact, Matt knows more about the terminology and stuff than I do because he directed me to an app that had all this cool vocabulary about it.
The way that I did it without the vocabulary was just basically it was the couple of times that have been turned down for surgery on the reflection of like, OK, well, that's not going.
I'm not going to get a fix.
Like, well, I'm also not going to let this ruin my life.
So you just kind of just decide to not let it and then you stop obsessing about it and just, you know, try and take it easy.
But don't let it ruin your life.
But it is.
I don't know.
Yeah, it's awkward.
So I don't know.
But anyway, yeah, I'm doing fine.
You're going to be doing fine in a week and that's super awesome.
So rock on.
Yeah, everybody kind of has a different set level of motivation of things that distract you.
I recently had some kind of stomach flu, like a gastroenteritis thing going on for like a week and a half.
And I had to miss a bunch of days of work.
I was just like complaining the whole time.
I was like, oh, this sucks.
Like, I hate being non-functional.
I hate being useless.
I was like, kept trying to, I like went back to work one day and I was just slowly dragging myself like through the office.
And so he's like, I don't, should you be back at work?
Like, no, it's great.
I'm fine.
And then like an hour later, I'm not fine.
I'm going to go back home.
But I had to like talk to my boss and he had to show me the handbook that's like, hey, we work with cancer patients and their immunosuppressed.
So if you had these symptoms in this handbook right here, then you should leave.
And I looked at it and I was like, yeah.
But definitely like, I don't know, I have two partners that have various like stomach issues just chronically.
And I was kind of just with both of them like, how do you guys love like this?
Like, it's, I do have a lot more respect for anybody that can just have like chronic diarrhea, you know, like, because that's just so draining.
And it sounds hilarious until like, you have to deal with it.
And then it's just like, wow, I feel terrible all the time.
The worst part, like, sorry for the TMI, but no, it's also there was a joke in there.
Like you said, chronic diarrhea is draining.
Sorry.
Yeah, levity.
Like when it comes to coping mechanism, though.
Yeah, exactly.
You got to make light of everything.
Like my general thing when it comes to like being injured or sick is like anything that affects basically like your neck, head or core like sucks.
Because you can't like, you can sometimes like lay in a better position to make your like stomach hurt a little less or whatever.
But you've got like a really sore throat or migraine.
It's just like, that's just there.
But if you have a broken foot, you just take it easy on it and it'll get better.
I don't know.
I would rather have a broken wrist than I mean, I guess I'd rather have a day of a broken wrist than a day of a migraine any day of the week.
Because you can just like be careful with an arm, but you can't be careful of your fucking brain.
That's totally people I'd rather have physical pain than like nausea and stomach things and serious about that.
Like, I just can't stand that.
Yeah, we're talking about B-Minder earlier.
And Stephen, you were talking about, um, what was it?
Well, you're saying, uh, like public commitment, I guess.
Yeah, commitment and consistency.
I think that was chapter two or three of Sheldine's book.
And that reminds me as B-Minder, like stick, where you like...
Well, that's what I was just going to say.
I think stick is where you, I'm not exactly sure.
I think you say that you're going to do something publicly and people hold you to it.
And then B-Minder is where you hold yourself to something, but you pledge a certain amount of money and that you have to pay back if you don't like make your milestones.
I think the other stick with stick, maybe that's why there's two Ks, was that it wasn't necessarily public.
You'd have like a, um...
Or you had a, um...
A person.
Like a contract buddy.
Yeah, exactly.
An accountability buddy.
Yeah.
Who you would say, all right, well, I've put up 50 bucks that will go to Trump's 2020 campaign if I don't quit smoking or if I have a cigarette in the next three months.
And then your roommate or friend, whoever you can count on to enforce that will, you know, make sure and you'll, you know, you can...
There's some self-honesty involved too, but if they watch you smoke, then boom, you've given money to a charity that you hate.
I think that's the other motivator behind stick was that you put it up for a charity that you really don't want to have your money.
Yeah.
The thing about B-Minder is it's very regimented and especially tailored toward like incremental goals.
So, you know...
Well, it was more of a kind of, you want to do more of this or less of that, right?
Yeah.
Like I remember I was trying to do like 100 words a day for writing.
Exactly.
They had like, what was it?
The yellow brick road that you have to stay on.
Yeah.
Yeah.
And then...
It'll give you a little bit of leeway.
Give you a little bit of leeway and let you kind of like reset the leeway and play with that.
Yeah.
But yeah, I mean the thing is I would just always just like eventually get to a day where I'm just like, I don't have the spoons to do this.
And I guess I lose.
I lose the game.
And then you're demoralized and you don't want to start over because now you had to pay money and you're pissed off.
Yeah.
I actually was talking to the co-founder of B-Minder when I was at CIFAR and I think that they've been developing it more too.
They're aware of these kinds of issues and they use it themselves.
I was really hoping to have him on.
I met Daniel and I know he is, I think his wife or partner created B-Minder.
It would be really neat to have them on.
Totally.
We talked about that.
So hoping that that might happen soon.
Yeah, that's cool.
So where does the money go if you don't succeed at your goal in B-Minder?
You said you lost 200 bucks.
Does it go to their company?
Did they donate its charity?
It goes to B-Minder, yeah.
That's the only way they make money.
It's free to use unless you fuck out.
Yeah, right on.
Which they were talking about.
They just take perverse incentives.
Yeah, we're aware that our business plan is kind of, you don't want to pay the money,
but they were saying that they try to make it as gentle as possible.
So it's like any time that you give them money, you don't feel like you've been cheated out of that money.
You're like, yeah, that's what I signed up for.
Yeah, as long as you're signing up for it, I think it sounds great.
They give you a lot of warning emails.
My inbox has like a thousand.
You are in imminent danger of derailing from your goal emails because I would always go right up to the line.
Yeah.
Did you take the Slate Star Codex survey?
Not yet.
Oh, I did.
Has it run out yet?
No, no, it's still open.
I was just curious because you said a million emails and one of the questions in it is how many unread emails are in your inbox right now?
Really like two thousand.
Really?
I don't care at all.
I put zero for that, even though I read ones that come into the Bayesian Conspiracy account,
then I mark them unread so that I remember to make a note about them and put them in the show notes so I didn't count those.
Okay.
But if I have an email, it's to me the little red circle is an action item.
And so if I deliberately left my statement for my HOA due payment unread until today when I paid it.
Yeah.
That's my thing.
I don't know how you look at that two thousand.
And then if one more comes in, I guess so don't email you if you want to get in touch with you.
If there's something important, then I will put it into my actual deal with this shit system.
Otherwise, it goes away into the memory hole forever.
Yeah.
I have heard that the shorter emails are much more likely to get responses.
Like not even to friends or businesses or anything.
Just in general, the shorter an email is the higher the likelihood of a response.
So I've gotten better at shortening them down when I forwarded you that email.
I was like, oh man, it has that whole digression at the beginning.
If I had known this back then, I would not have done that.
Yeah.
The email I sent ended up being really short.
I still haven't heard back, but cool.
I could confirm that the ones that come into the podcast email, if they're really long, I will often put off reading them because it's like, I don't have 10 minutes.
And then I'll read them and I'll be like, thanks.
I don't have time to reply everything because I usually don't.
And I do appreciate everything that goes into it.
All of the, you know, that's the whole point.
They've spent a long time writing it and thinking about what to put into it.
But I don't have that much time to put into replying to it.
So it's like, this was awesome.
Thank you.
It's all I can really say.
But if it's a quick one off question, I can answer it.
This is everybody's reminder that if you read SlateSarcodex, go take the survey if you haven't yet.
So it's very handy.
So speaking of SlateSarcodex and synthesizing the last several minutes of conversation into that, there was this post on r slash SlateSarcodex.
That was just like, how does, how does Scott Alexander do it?
How does he find the time?
And, and yes, he's extremely prolific and extremely impressive and so forth.
But, but I'm like, my thought was like, I think this is just fun for him.
He's playing.
And like, I was thinking like y'all were talking about chronic pain.
Apparently everyone here is a famous chronic pain sufferer.
And I'm like, I have only been for the past few months.
Yeah.
Well, like so, so I was thinking like most of my like less wrong posts, for example, get written when I'm having a horrible migraine or something.
Like, like most of my intellectual diversion tasks are when that's kind of all I can do, but I'd rather not.
And like, I don't have the, whatever willpower is, I don't have the willpower to do something that I should be doing.
And so I'll do something like a less wrong post, for example, or, or just comments.
Like, just, and so I'm like, think if you're lucky enough that it's the fascination lottery concept, which is another sort of codex thing.
But like, if you're lucky enough that, you know, the playing guitar is just fun for you, even if you're noodling around pointlessly on it.
No matter what, or even if practicing scales is fun for you, then you're going to be really good at guitar.
You lucked out.
You lucked out if writing 20,000 word blog posts about complicated top topics is your thing, you're going to get good for you, you know.
It's actually really surprising how much time there is in a day when you aren't...
Sweater bros.
What up?
It's surprising how much time there is in a day when you aren't distracted by other things.
Like, right now I'm playing World of Warcraft and I'm really enjoying it because I'm playing the guill leader game and that's just a whole different game from the actual game itself.
But before I was playing this, I basically didn't play video games much anymore, maybe a couple hours a week.
I didn't really watch TV anymore.
I just wasn't interested in most things that are on.
And so you...
I had all this time in the day for podcasts or writing or cleaning my house, you know, it was...
It's amazing when you don't have those little distractions just how much time there is to do things.
And I get the feeling Scott's probably also that kind of person where like, you know, he could read a nonfiction book for fun and then write about it for fun.
And that's his evening because, you know, like you said, the fascination lottery.
Yeah.
How do I get a good fascination?
Is there a trick for that?
Because I spend all my like, unconstructive time doing nothing productive.
I should be reading books that I find interesting.
Instead, I'm playing Clash of Clans and Browsing Reddit.
I don't know.
I think you're simple on something.
Or you probably already have things.
I mean, I...
My fascination was getting drunk up until I was like 31 or 32.
I think I should try that.
You have like seeds of things, I think.
Yeah, that's fine.
I have found...
This is something that made me really relieved that when there were things that I wanted to do and wanted to work on,
I guess first of all, there's something that makes you interested in them.
Like, I ended up with fascination lottery for drugs.
And that was...
I actually kind of got back into less wrong after I had read a little bit of HPMOR and then kind of fell out of it a bit like through Guern.
You should probably just...
The first place people's minds go when you say you got really interested in drugs is probably not where you are thinking of.
Well, actually, no tropics specifically or supplements and just like the pharmacodynamics and so forth, but like...
Maybe the average patient conspiracy listener got where you're coming from, but I hear that and I'm like,
Okay, you got really into cocaine for a few years.
I expect our listeners to know what I mean by that, but like...
No, I'm working on a CAR-T now, which is chimeric antigen receptor T cells for blood cancers.
And but the thing is that like anything that led up to that, it was kind of this like,
I don't know, like weird little fascination thing of like reading about pharmacodynamics on Wikipedia and it eventually became a career.
But that's how all of my career started.
It was this little nugget of like this thing's kind of cool and then just digging deeper and deeper into it.
As long as you approach it, I think incrementally and you don't exhaust yourself on it.
You don't force yourself into it very much.
I was just like, I don't know what you call it, praising and admiring what you like.
You and Phoenix are like hobbyists and neurochemists.
And now it's like a career for you, but it's like...
Well, I'm a hobbyist too, though. I mean, my career is very specialized.
Yeah, but like, I'm like, we were talking about the interactions of like medaffinil and other things.
And I'm like, Oh, you know what?
I bet not only can just answer that, but they can tell you like neurochemically and biologically what's going on with it.
And that's awesome.
Yeah. I mean, and I just love that.
I find it really cool.
And it comes from, I guess, like, there's something I want to use that for.
The reason I really liked reading Guern and looking at all of his N of 1 experiments was that science just seemed so intimidating.
And here was this guy who was doing N of 1 experiments and it made complete sense if you could kind of break it down into,
Okay, so he's taking magnesium and something that looks like magnesium every day and making a journal about it.
And then just throwing that into a spreadsheet and over time seeing whether or not it improved these different mental tasks that he was doing,
like a reaction speed test and a memorization test and so forth and so on.
That's like, Oh, okay. Like, I could do that.
I feel like a disproportionate number of my and your podcast listeners are graduate students.
So I just wanted to kind of follow up on that story with my story of like me and my friend Michael are like the only two people who I know who had a good time in graduate school.
Everyone else seems to just, it just seems to be the most miserable time of their life.
And I think for both of us, it was actually that we, we did kind of flounder for a while until we actually found a project that we just thought was intrinsically fascinated.
And we became kind of obsessed with figuring it out.
And then it was like our thing.
And similarly to how, you know, Neofarmacarp, yeah, that is your thing.
And it just, you got into it because you're interested in it and it's like a self-powering wheel.
Like that's, if you, if you can't find something like that in graduate school, it's going to be the most miserable grind of your life because someone's basically saying,
solve this really difficult problem that you have no real interest in and you've never done this before by the way.
And we're not going to help you. Good luck.
But if you're, if you're really fascinated, you want to solve it, it becomes your thing and you, you will quickly know more about it than anyone else around you.
And that's, because that's, it's not much, it's not much of an ask, right?
Like if, think about it, anytime you've been into, even if it was Pokemon when you were eight years old, like, like you probably knew more about Pokemon than 99.9% of people, right?
It's very easy to, to be an expert in something if you really think it's awesome.
I was once at the point where I had a friend call me on the, on like my parents' landline because we were kids and they had asked me like,
what was the code to do this in one of our video game?
And off the top of my head is able to give them like the, you know, press start and press in these 16 keys and then you're good to go.
I wish I could do that for something like real in my adult life.
But you totally could because you could do it with Pokemon.
That's what I'm saying is, is.
But I don't have the drive anymore to do stuff.
But if you find the right thing, then I think the drive would appear.
All right.
And I don't know, like, and like, you kind of asked earlier, like, how do you fabricate the drive?
I don't know. I'm sort of trying to, like, like the Iron Man suit and stuff like that.
I'm sort of trying to trick my kids and being fascinated with engineering and physics and, and science in general.
You should show them a random and rose what if, which I'm sure you're aware of if you haven't read it.
I haven't read it, but yeah.
Oh, I have a thing explainer, which might be better for kids because it's a big picture book.
I was going to say, what if it's probably too dense for little kids?
Yeah, but when they get older, as long as like the physics physics and engineering, it gives physics and engineering answers to absurd hypothetical questions like.
How much electricity could Yoda generate?
Yeah, what's what's the oldest force output and jewels?
Can you make a hoverboard out of AK 47s?
Oh, yeah.
Yeah, it's fantastic.
Fun one. What would happen when you do a if you pitched a baseball at the speed of light?
The relativistic baseball pitch.
Yeah, I have like a bunch of basic conspiracy topics that I wanted to propose and I just keep forgetting that I've got a minute text document.
But like one thing that I've been getting into is trying to find children's books written by smart people.
Because I was reading David Allen's GTD for teens.
And I just happened to like find it at the library, started paging through it and laughing a little bit and then like looking at it and being like, wait a minute.
Like smart people writing books for children.
Like it's kind of the idea of the explain it like a five or however old I forget.
Yeah, it's five.
Taking a complex idea and then breaking it down into simple metaphors drawings and like the idea is smart people know that children aren't stupid.
They just lack the life experience.
But they're as smart as adults.
So it's like if I can take this idea that maybe you lack all the background knowledge that I and that I'm assuming adults have and break it down, then I can explain it to you.
And the thing is that like people like David Allen or whatever expert is trying to explain whatever their expert topic is.
They're generally always making a little bit of the what do they call it the inferential distance bias where they're assuming that kind of OK, like average person knows about this much and average person is some kind of like avatar of you because you know you the best.
Yeah.
So like that you're always going to jump a little bit ahead.
They should really do like the Feynman approach, which I don't think he ever at least he didn't say he did in his books, but I like the quote that you don't really understand something unless you can explain it to your grandmother.
And that's what anyone who writes a book for kids should do is like just dry run it past like a parent or a grandparent or a child before you publish it.
Well, I mean, you're a programmer, so you probably know about Robert Ducking, right?
Yeah.
So if people listeners don't know about that, it's where a programmer like I don't know the I guess the myth behind it is a programmer is trying to get an answer from their like fellow programmer about something that they're confused about.
And in the process of explaining what their problem is, they were like, wait, I just I just figured it out.
And they were like, I could also just explain this to a rubber duck.
It doesn't have to be a whole person there because like in the process of you like pretending to explain it to someone who's sitting there, which could just be a rubber duck.
You might actually just like figure it out yourself.
Yeah, the parable was like an instructor at a college would say yes, you can come in and ask me questions during my office hours.
But first you have to tell your question and your problem to the duck that's sitting on the table.
And then knock if you don't know by then.
And I have two ducks in my desk at home and one in my desk at work and I never remember to actually talk to them.
But the trick is like, you're something's not working.
And you're like, OK, why isn't this working?
And at that point, your brain hits a wall for many people.
So what you try to do is train yourself to say, OK, let me explain what I'm doing to this my little, it looks like a grateful dead little duck.
I have my desk at work.
It looks like a grateful dead bear, but like the way it's painted.
And like, OK, well, here I'm doing this and I'm doing that.
And then, oh, I'm not doing what I think I'm doing.
That's why that's not working.
And that's that's usually the trick.
So, yeah.
Makes sense.
Back when I was more active with my blog, I would often find that by the time I was done with the blog post, I had to delete the blog post.
It's my position to change entirely.
That sounds like a fun thing just to leave up.
Yeah, maybe you publish.
Or I guess you add like a post script.
To be continued.
Yeah.
Or like, I've changed my mind.
All of this is wrong.
Yeah.
While writing this, I realized I've changed my mind.
See, you know, check next week's post.
Yeah.
Yeah.
Speaking of blogging and the 10 years thing and so on.
Scott Alexander did that 10 year retrospective.
That's one nice thing about having like a shitload of internet comments and so forth is that you can look back over it and be like,
that's how I used to think about things and I don't know if I can necessarily track my progress on intellectual topics the way
Scott Alexander can, but it's a fun exercise to do.
I do it occasionally just like look back through old comments.
Yeah.
So, since we were supposed to be talking about like the past 10 years, are there any major changes in your thinking over the last 10 years?
Or your life in general, I guess?
I mean, I want one of us to say, no, I was right about everything 10 years ago.
Yeah.
Oh, yeah.
Not me.
No, nothing's changed.
I mean, I just looked up my first less wrong post was apparently in 2011, which is almost 10 years ago.
So, prior to that, I didn't know about any of this stuff.
And I think like I definitely use a lot of the kind of less wrong inspired thinking and everything that I do practically.
So, to the point where it's hard for me to even remember that it used to be different.
Yeah.
I mean, it's that's that's a really interesting question.
And I kind of want to go back and like specifically think about that question.
It's not something that I can just ad lib.
Yeah.
I don't think but but yeah, I mean, if any of you have any ideas of like specific major shifts you've had 10 years is a long time.
I'm sure there's a lot of shifts in a 10 year period.
Yeah, we should do this on a yearly basis 10 is too much because I mean 10 for me, I was 20, which I think puts me the youngest in the room.
And let's see, I would have been finishing my community college degree.
And then I took six months or a year off.
Are we?
Yeah, about a year.
And then got my undergraduate degree met my wife while I was at CSU.
And oh, but cute.
This is the cute story.
We met in elementary elementary school, but we we reconnected when I was in college.
And then, yeah, at some point, in fact, I remember this as much as I remember anything.
I think part of why my autobiographical memory is so bad is I remember reading Elizabeth Loftus's work about how easy it is to fabricate memories and not just implant them in other people, but more or less recreate your own from scratch.
And so you cannot do that.
Right.
That's how memories form.
Yeah, exactly.
So that's just how it works.
And I think that that realization made me just like kind of put every memory I had into like the, this is probably bullshit bucket in my brain that eventually gets garbage collected.
So you just stopped forming memories entirely?
I think so.
And I'm kind of worried about that, actually, because this, you know, my ability to pin things down within a year or two is only like easier now, because I can usually reference it off of somebody else.
Like, I'm going to go see a comedian tomorrow, Beth Stelling.
She's really funny.
I knew that I saw her at some point in the last three or four years, but Rachel has an app on her phone that like this day and your history, your social media history.
And it was like three days ago, she's like, oh, we saw her two years ago, three days ago.
So it was two years ago, apparently.
If you had asked me how many years ago it was, I would have guessed one to three.
I'm terrible with the passage of time.
Yeah.
Um, like, how do you always know, like, what, what, what month of what year something fell on, even if it was eight years ago?
And like, she just, it's funny, because I must have never asked the question to her right out like that, because I've always been amazed by her kind of autobiographical memory.
And she's like, oh, I just have like, and she like waved her hand to kind of over her, over her head.
There's like a tape that I see with all the dates laid out on it with the events kind of arranged in order.
And I was like, what? You never mentioned this.
I don't have a tape.
That's pure fucking magic.
That's awesome.
Dude, does she have the perfect autobiographical memory?
No, it's not, it's not supernatural.
It's just like, I'm just continually like,
What is the thing where people have the ability to like see numbers as colors?
Yeah, it almost sounds like that.
It does seem like it.
Yeah.
I mean, it's, it's, it's to the extent that it's impressive to me, partially because I feel like I can, I don't, I don't remember numbers at all.
Like, which is not a useful thing.
I mean, like as an engineer.
As an engineer.
Yeah.
Right.
Yeah.
But yeah, I thought that was pretty funny because I was, I wish I was still moving every year because that was a very handy metric for knowing how long ago something happened.
I would count back, you know, the number of times I've moved since that happened.
But haven't, haven't moved regularly like that in good five, six years now.
Why were you moving every year?
Because I like to move every year.
Oh, I just like to change where I am.
I feel that.
But, you know, that's, that's easily doable when you're renting, much harder when you're buying.
Yeah.
I mean, I switched from buying to renting and yes, it's a, I don't know, it was, it was a really positive life change for me.
Probably like there's different reasons for why different people might do both.
But more on topic, the one thing I keep thinking about is when people are talking about like, how do you have a good memory of what happened or what you were thinking at that time?
I've kept a journal since I was about eight or nine years old, like pretty regularly, and I have all of them.
Wow.
So on one hand, it's like, I do, I can actually go back and look at what I was thinking or what I was doing in, you know, middle school or like, you know, when I was 10 or 13 or 18.
On the other hand, it's all written with pencil on notebooks.
And I've got all of these stored in my closet right now.
I have this project plan where at some point I would just want to rip all the binding out and mass scan these.
So I at least have a digital version of them because like when I had the house fire, luckily my filing cabinet that I had all these journals in was spared.
It was not just my journals, but all my drawings.
But like, I was just like, man, it was really close to just having all my memories destroyed, but
I was gonna I was grinning a little bit because I was thinking the obvious way to store these forever for posterity is to record them all to tape.
Because we've all listened to the Magnus archives.
You obviously just need to commit these to a tape recorder.
I forget where I read this.
There's probably some rat-fic or I don't know.
But like, I really love the idea of being able to take all of these writings that I have.
And then like, if, if, if slash when in the transhumanist future, we get the ability to like add memory to our brains.
I want to just have this like be stored there and I can be just pull it up.
The text would have to be parsable or it would have to be in some form that's beyond text in terms of like readability, legibility.
I don't know.
But I really love that idea of I'd like to be able to take all these memories that have been stored externally and then make them internal again.
I guess it depends on what you wrote down.
I mentioned because I the condition where people have perfect, near perfect autobiographical memory is real.
It's usually it comes with like heavy deficiencies in other areas though.
Yeah, like, well, they, they, they can read a book, you know, a textbook like the rest of us and they don't retain all of that,
which is a drag because that's also, I don't know how it works in your brain, but that's also autobiographical, right?
Like you remember reading the book.
You presumably remember what it says.
You remember what you had for breakfast at 743 AM on January 11th, 2010.
There's why wouldn't you remember what was on page 333 of your college biology textbook, right?
Different ways the brain stores different kinds of memories.
Yeah, but I guess the folders that I guess are labeled autobiographical are like arbitrary.
Well, that's the point. Yeah.
So different memories are to store different ways.
What TV show you watch, but you don't remember like, yeah, I guess the pages of that book were probably stored somewhere else.
I have this stupid thing when it comes to reading that like, especially with fiction books, I could tell you back, you know, five years later.
Oh, yeah, it was on the right hand page of the hardcover copy that I had or something.
But I can't do that with useful information.
Do people with that perfect autobiographical memory not change as much in their lives?
Because I've changed radically in my life.
My impression is that usually people in the autism spectrum and they tend to kind of live these very regimented lives.
The only other thing that's going to say that I knew about them is that it tends not to be a happy thing for them.
Oh, yeah.
Because you remember every schoolyard disc someone threw your way, you know, 30 years ago.
But then couldn't you also remember every time you had great sex or something?
I guess.
I think you don't like...
Maybe this is just a reflection on the fact that more bad things happen to you than good things.
But maybe that depends on the person.
I think it's not even bad.
I think you have so many memories of mundane things and they're so intrusive that it's very hard to actually process things in real time
because you're getting inundated by like very specific memories of very similar things.
Every time you go to poop, you remember every time you ever pooped.
That does sound super boring.
Yeah, I think I remember one instance where it was like, it was really clear.
It was about this one particular case where the woman was clearly just like ruminating on all these details.
Like, you know, she remembered that she had her coffee at 9.30 because like at the end of the day,
she would be like thinking about the fact that she had her coffee at 9.30, which like, I...
It's the end of the day and I don't remember what time I did anything today.
So, yeah, I don't ruminate that way.
But if you do ruminate that way, then at least you have a chance at remembering it, I guess.
So much of the thing that's important about thinking in memory is the selective forgetting process.
And nothing reminds me of that more than like, I've been getting back into my meditation practice.
And so like today, I just did 20 minutes of mindfulness meditation.
And when you sit there and you try to just be really conscious of everything your body's doing,
everything you're feeling and everything you're thinking,
I have this meta process of labeling where I go, ah, feeling.
I'm feeling attention in my lower back muscles and that feels unpleasant.
Thinking. I'm thinking a plan about what I'm going to do after I'm finished meditating.
I'm going to go put some tea on and that feels neutral.
And you do that for 20 minutes.
It's just like, yeah, this would be like, this is a really interesting thing to do daily.
It really helps you get an idea of how your brain works, what kinds of things it's doing,
and gives you more ability to focus and whatever.
But if you had to live like that all the time, then that would be all you were doing.
So much of like what we're doing is our body going into autopilot or us like thinking back about memories.
We're thinking about these like bright points of memory that we have crystallized as this is important.
This is important. We're not thinking about that coffee we had.
Yeah, I basically stopped meditating after kind of like doing it fairly intensely for a few stretches
because I don't mind being an autopilot.
If my life were rife with suffering, then I might want some distance from that.
And I feel like that's part of the motivation for why I was meditating back then
because I wanted distance from the headaches.
But now I'm just like, things are good.
I'm fine being swept up in samsara.
I don't need to be aware of my own whatever it is that I am.
I think meditation is fascinating though. I want to talk about it.
I did vaguely like regimented meditation for a few months, like 10-15 minutes a day.
But then I've been doing like not exactly like pop quizzes because it kind of just comes up randomly.
If you constantly have whatever muscle tension or something, one way to manage it is to notice that as a problem before it's a problem.
And so you're like, oh, I'm flexing my shoulders. Let me fix that before it starts hurting.
So kind of just like an auto reminder in your head to like just check in with your body and see how things are going.
But one thing that's kind of fun to do is if you, this is like you have to like,
I have to just turn this on and then I get bored of it after a few seconds or I forget.
But just like I watch the narrative train in my head go through and you know, I'll go walk to my car.
And that's usually like a 10-second walk, but I'll leave my, I'll watch my thoughts come in as they're doing it.
And it's just, it's, it'd be hilarious to like put this to, to, to the, like to write this down or to record my thoughts as they're happening.
Because it's just like, I'm saying things to myself like, oh, I forgot to check where my car keys.
There they are. And like, why am I asking myself these questions out loud in my head?
I mean, oh, look, there's, you know, there's the neighbor's cat in the window.
Oh, but it's like so soft. And it's just like, if I was verbalizing all these thoughts, that sounded insane.
And I think that's just kind of fun.
Yeah, there's two concepts of the arising and the passing away.
And then also like one of the ideas of meditation is the idea of the no self.
So what you're supposed to do is when you hear yourself saying something, then you go, who said that?
And then you're like, and then he said that. And now he said that.
Damn it.
And eventually you follow it all the way back and you realize that like, yeah, there's, oh, nobody.
Speaking, speaking of patterns noticing themselves, you all saw the post on Slate Sarcodex about the GPT-2 playing chess.
Oh, yeah.
That was awesome.
Then I got to share the original Slate Sarcodex post about GPT-2 with all my coworkers.
There's somehow a route of the loop on all this, which I thought was interesting.
Yeah, I love it. I think it's really interesting.
For anyone who hasn't seen it yet in the listeners, Scott and a few other people put together, I think Scott just played it.
Someone else put it together using GPT-2.
It's the text predictor program.
We did an episode on it earlier where you put in a line of text and it like spits out a paragraph or two of, you know, something that could come from that.
It's remarkably interesting.
Got to talk about that cool dungeon thing.
Yeah.
But they used it with chess moves because every chess move can be encoded as a combination of a few characters and letters that tell you what piece to move and where to move it.
And it could play chess, not well, but passively.
It played well for a bit and then like it kind of lost interest after a while, which I find really funny.
I think it was literally like it could play well for 12 moves and then like that was the length of its like memory buffer.
Or an attention span.
But it doesn't actually have a memory buffer or an attention span.
The really fascinating thing was Scott pointed out, this is literally just a text predictor.
It has no concept of chess or the rules of chess or that there is a physical space or pawns and pieces.
And that brings up, but we're not playing chess either.
Like we're also kind of just a predictor.
Right.
Or like an experience predictor.
I think that was his point that just a random, you know, a pattern recognizer and predictor could do remarkably robust and powerful things.
And, you know, eventually you get powerful enough, maybe this pattern predictor can recognize patterns that it itself is doing and then we become self conscious.
Oh my God.
It does make me wonder how many like nodules kind of like GPT2 you'd have to stick together in order to get a fully sentient being because you do get these like really bizarre emergent things out of very simple processes like that.
It's hard to tell how much of sentience is the result of these very complex like inner changing nodules.
I don't know why I keep saying the word nodules.
That's a weird word.
Yeah.
Like what if it's just like three GPT2 stuck together?
What if it's not, you know, and it's just this weird coincidence.
That's a good tie into the AI Dungeon app that you introduced just introduced us to at the meetup.
Yeah.
I guess I'll talk about it for a second.
First of all, I recommend it.
Just get the AI Dungeon app or you can just go to the website.
I think it's just AI Dungeon.com and it's basically somebody sort of made their own tailor made.
I guess the word is fine-tuned GPT2 model where you basically give it like a story prompt of like your Bob the rugged survivor.
It's the post zombie apocalypse and you're in your bunker and then it gives you a little prompt and then you basically treat it like one of those old text based adventure games where you type like look around or open the door or whatever.
The thing is you can type in whatever you want.
And because it's GPT2, it'll just be like basically it's constantly running the algorithm of, all right, what would happen?
Like, what would the text say after this?
Okay.
And then a walking dolphin comes in the door and says, I know your mother.
Yeah.
GPT2 is like, all right.
And then next.
Yeah.
Then your mother walks in and just like Bob the dolphin.
Yeah.
It's really, it's really creepy and incredible and awesome.
Like, what were we doing?
We had like a velociraptor come in and then there was a lightsaber and like, and of course, like it knows that if you hit something with a lightsaber, it burns them like it.
Oh yeah.
It was really neat because at one point, I think we met a skeleton friend of the velociraptor and that's when they coined the term the velociraptor guard.
They were like, it made up a word.
So the best thing about this was I like went outside to talk to somebody at our last wrong meetup and I came inside and people were like, and now they're like sexually caressing the velociraptor.
And I was like, what are you guys playing over there?
Yeah, I was, I think we're playing out on my phone and I'd put in like, all right, attack the velociraptor, the lightsaber.
And then it's like, all right, you hit it.
And I was like, now eat its heart.
And then it's like, or like it's something about the heart coming out of it when you killed it.
And I was like, all right, now eat the heart.
And then you put in after I looked like, put the heart, like save the velociraptor.
And it says you put the heart back in even after eating a piece of it.
Like it makes mistakes, right?
And this is the same as GPT2 always was where like it'll make these mistakes.
But the stuff that it does know, like I wrote a Reddit comment about this.
I was like, I don't think it's a language model.
I think it's a concept model.
It just doesn't quite get the concepts right.
I think it's, I don't think it's sentient.
I don't think it's super intelligent, but I think people aren't giving it enough credit is what I think.
I think it's pretty impressive.
I want to read how it primes the, because you can pick the setting or you can do a custom one.
And I did the, what, apocalyptic wasteland or something.
And it used words like super mutant, which I don't know if that's from, if that's just from fallout,
but that's where I associate it with.
And it described it as these big mean talking things and like, okay, so super mutants are the ones from fallout.
I wonder, so I want to look up on the website where, where like,
You gotta see what it's training material is.
But you talked about how you put it, you were basically writing like a worm, a wormverse thing.
And he said, go into your breaker state.
And it's like, and like, it doesn't know what breaker state means.
Well, I think what it's, I think it has read just a crap ton of the internet.
So I think it's read a lot of worm fan fiction, if not worm itself.
That's so cool.
And so like, yeah, you see, like, you don't tell it what a breaker is.
You just say, go into your breaker state and it's like your body disappears into a haze of electrical energy.
And it's like, yeah, exactly.
Exactly. Yeah.
Do you think the number of words of worm itself is greater than the number of words in like,
worm fan fiction or?
I feel like at this point there's more worm fan fiction just because there's,
There's a lot of fan fiction.
Yeah.
Just in general.
Many, much of it apparently read my people who haven't read worm.
Really?
Yes.
Oh yeah, that's a thing.
Yeah, like, I found that really funny for a while that something will get popular.
People will draw lots of fan.
People will see the fan art and kind of like, or hear about it from their friends and then just be like,
Oh, I know what that is.
And then start drawing more of it or writing stuff based off of it without having read it.
Yeah.
Or only reading parts of it.
I tried to do one because you mentioned that you had set up where you,
Your prompt was like, I'm an AI in a machine trying to convince my programmer to let me out.
I tried that for 10 minutes and it just, it didn't get what I was trying to do.
But that, you were, you tell me a little about what you did there because I think we didn't get the long version at the meetup.
Well, yeah, I was just trying to play around with this concept of getting it to do stuff that had nothing to do with the multi-user dungeon type experience.
I was just like, in one case, I was like, you are interviewer interviewing Matt Freeman.
And then I like wrote some details about who Matt Freeman was.
And then I basically was the interviewer and then the AI was Matt Freeman.
Just to be trippy and weird.
And I did one where I was like, you were an AI researcher talking to your AI that you built.
And you built it to be super intelligent and to solve any problem.
You just need to ask it a question and it'll tell you the solution.
And then I started asking you questions.
And what was funny is it would like, it would like cleverly evade answering the question.
Like it would be like, well, we need to define better what you mean by that first.
I'd be like, no, fuck you.
You're going to tell me.
And then there was one where I was like talking to my physicist colleague who had admitted cold fusion.
So I basically got GPT2 to tell me how to make cold fusion.
Apparently the key is a platinum catalyst with a gold plating around it.
The second, if someone ever gets an experimental result, they can go out and check and it's right.
I'm hoping that that explodes on the internet and everyone hears about it.
I mean, presumably you could feed it all of the scientific literature on everything.
It could synthesize some new information.
I think we're going in that direction.
In the way that it makes kind of, it gets a lot of things weirdly right.
And then it makes a lot of kind of obvious mistakes.
I think it's going to get better at that kind of thing.
It's going to get to the point where it can just be like, oh, I know everything and I can cross correlate across these different domains.
And it'll be able to find out things that you can sort of use it as Google now.
You can sort of be like, think of a topic you don't know anything about and then sort of ask it about that.
It'll know something about it, right?
Because it's read probably 100,000 words on that topic.
That's amazing already, right?
And it's not even made for that.
But you can't entirely trust it to get it right.
True, true.
But we're going to get there though.
I feel confident anyway.
You have a little mini oracle.
Yeah, basically.
Well, do we want to talk about what has happened in the rationalist world over the past 10 years?
I can start really quick with a very simple one, which is I mentioned sometime.
Oh, that was my long tangent on memories and stuff because I remember specifically assuming this memory is accurate,
even what stoplight I was at when I was listening to rationally speaking.
This part of the memory must be true because that's what I heard of.
At the end of the podcast, they would do the rationally speaking pick where they pick whatever book, video game,
or TV show, or whatever tickled the rational fancy between this and the last episode.
And Julia Galeff plugged Harry Potter and Methods of Rationality.
And the only reason I remember, the only reason I found it was because it was at a stoplight
and I was able to take a note and say, look at this later.
Was this 10 years ago?
No, this would have been, it's hard to say, something like, oh wait, almost 10.
Yeah, just about.
Because I would have been reading this.
I could look up whatever year I graduated from Front Range.
The community college I went to and it would have been around that year.
Within a year, it would have been before I graduated there.
Yeah, for sure.
So yeah, about a decade ago.
Perfect.
All right, this does line up.
Yeah.
I was going to guess six or seven, but when you think about it, yeah.
Okay.
So closer to 10.
And then yeah, we, although the only other thing that makes me feel like any time has passed with regard to any of this is that
I think Methods of Rationality wrapped up in 2015, right?
I'm looking up a publication date, 2010 to 2015.
Yeah.
So in March, 2015 will have been, well, we're hitting up, we're coming up on the five year anniversary of the Denver area, less wrong.
Yeah.
Because we had a handful of meetups that was like just you and me.
And then one with me and just one other person one time.
And then the big kickoff where people started coming was for the rap party for MLW or for, yeah, Methods of Rationality.
And because you're a local celebrity in that area, we had like 35 people show up.
And probably 10 or 15 of them, 10 or 15 of them still come.
So, and we met some cool people.
Yeah.
That's, I think, how we met the folks in Colorado Springs.
Yep.
Yeah.
So it's awesome.
Yeah.
And that was five years ago.
So, geez.
Yeah.
We've, we've moved from old less wrong and then less wrong died and then less wrong was reborn as less wrong 2.0.
Yeah.
And in between there was the diaspora.
There's the diaspora.
Everybody had their own blogs and.
Yeah.
So 2010 less wrong was still going pretty strong.
I remember going back to see just like what was happening.
And Eleazar was still posting the sequences at that point.
He hadn't finished them.
And there was a lot of posts by, by Scott Alexander, by Guern, by all the early movement people in there.
The people that ended up becoming the diaspora.
Yeah, exactly.
And then, yeah, after a while, Eleazar stopped posting there started getting more serious with a.
Miri, which at the time I think was still SIAI.
The Singularity Institute.
Yeah.
Yeah.
I think they changed their name in 2000, mid 2010s.
Miri is better because.
It's much easier to say.
C.I.
Yeah.
It's weird.
Yeah.
Well, and Singularity in what 2001 when he started the Institute wasn't as.
Something different.
Yeah.
It wasn't as pop sciencey of a term.
Right.
I think I admire a lot of the stuff that Kurt Ray Kurzweil has done, but I think he've ruined the word.
I think that's partly, I don't know how much of the, how the effort for the rebranding goes on his shoulders,
but probably some of it.
Speaking of Kurzweil and timelines, I recommend, I mean, I don't know.
I enjoy this kind of thing.
There's the, the Asilomar AI conference where Yudkowski was there, but he didn't talk.
You can see the back of his head when he asks a question at one point on the YouTube video,
which is a very Yudkowski question.
I don't remember exactly what it was, but I remember being very Yudkowski.
But anyway, Kurzweil does this thing where he's like, look, here's all the, here's all the trend lines.
Here's how I'm completely still right about everything and all everything still on track.
Like I've always said, and like, I've always, I've always liked Kurzweil because he dares to make these predictions.
Like people get on his case and I'm just like, okay, you make predictions then, you know?
And, and, and like he tends to be more accurate than not.
Right.
Like, I don't know.
Like you can always, you can always find ways to nitpick, but like very often kind of the spirit of what he's trying to say is,
accurate even if he fails to anticipate some particular change in paradigm.
I've always been impressed.
And the thing, the point of me bringing this up is like, this was a fairly recent conference.
And he's basically saying all of his kind of trend line predictions are still on track more or less.
So.
And don't get me wrong.
I like, I like Kurzweil too.
Yeah.
I think like, like I said, for me, it was the specifically around the use of the word singularity.
Yeah.
I've heard people who have no idea what any technical definition of that would even mean use the word.
And I think that's part of why.
So it's like it just got distilled too much.
It's not necessarily, it's not a, it's not like this guy's out there saying a bunch of nonsense.
And that's why, that's why it happened.
I just, I meant that word specifically.
Yeah.
It became kind of a marketing word and I get Mary wanting to move away from that.
The only thing that I can, and I, let's see, I'm trying to think of what I've read from Kurzweil.
I know I watched one or two of his documentaries.
But like Michiu Kaku makes, like by 2030 will, he'll make like highly specific predictions that have like five components in them.
And I don't know, maybe he's really confident.
And I guess we'll see in 10 years.
I'll have to double check exactly what I'm thinking of, but there was one about like in 2030 we'll have like basically super cheap TVs where it'll be like wallpaper and it'll be able to simulate environments.
And I forget all of the ands in the statement, but it was, it was several.
Yeah.
And he could just say like, maybe we'll have super cheap, you know, very thin screens.
Yeah.
Very thin screens that are, that are so inexpensive that you can plaster your walls with them, which would be kind of cool.
It'd be like the, what was the imaginarium thing that they had in community?
Good little closet.
Oh, okay.
Yeah.
I remember what you're talking about.
Troy and Abed had this like closet with just like yellow tape grid squares painted on it.
And there's going there and like imagine, and it'll be like that, except you get the, or like the holodeck.
Is that what it was called in Star Trek?
Yes.
Yeah, perfect.
All I remember is the version of that that they had in the X-Men to train the X-Men.
Oh yeah.
The danger room.
Yeah.
But that at least simulated like actual things.
It wasn't just vision.
Although I'm assuming the holodeck did that too.
Does it have force fields and they could materialize things?
Oh, smart.
Yeah.
Okay.
That makes sense.
Yeah.
We get force fields and TV walls and we're, we're all the way to a holodeck.
Perfect.
Yeah.
The porn industry is going to be wild with this stuff.
The porn industry is always pushing the technological envelope.
I mean, that's, that's canon in deep space nine.
The only purpose of the, of the holo suites is for, you know, prostitution.
So.
That makes sense.
Yeah.
They were seeing the future.
Not, not as if we want it to be, but as it will be.
It wasn't the only purpose, but it wasn't major.
I mean, if you think about the internet.
Yeah.
How much of the internet is like drug trafficking and porn?
I do want to point out.
Like I, I just got to thinking about this the last two days, the, you know, 10 year retrospective
on the rationality movement.
I think it's really fucking impressive.
Oh yeah.
Cause it was, I mean, it was literally started out just as like one guy's blog and then it
turns sort of into like a shared blog.
And at this point we've got multiple community houses across the nation.
At this, uh, the CIFAR workshop thing that they do.
And more importantly, there's like a lot of, um, thought influence that, that has come
out of this.
Like I think the major acceptance of AI as a, uh, existential threat to humanity by
technological and thought leaders is in strong part because of the original righteous community
influence.
Yeah.
The concern about X risks in general.
Yeah.
Like Nick Bostrom came directly out of less wrong and he's, um, but Oxford future of
humanity Institute head.
And yeah, I think that's very much on the shoulders of, of the rationalist community.
There's this whole EA effect vulture as a movement, which came out of that.
There's actually one state legislature who was explicitly rationalist, uh, legislator
in New Hampshire.
I think it is.
I mean, there's, it's impressive.
The strides that have happened in the past 10 years and Scott Alexander major, you know,
influencer, he's, uh, over a hundred thousand views on some of his blog posts and is quoted
by people in, was it the New York times?
Uh, you know, I hear him quoted all the time by like Ezra Klein and, and, um, people in
kind of the more San Francisco scene.
Um, I know there was, there was a couple major national publications that have responded
to him.
I haven't heard of that, but, but I believe you.
I mean, he's, he definitely has a lot of pull with the kind of the intelligentsia of the
country, which is great cause he's a great representative.
Right.
I mean, I mean, I think the movement's done great.
I think it's no, it's no small part due to his continuing work because Yidkowski did
a great thing with the sequences, but he's been disengaged for years now.
And that's fine.
He's doing his own thing.
Um, I do kind of miss his voice, honestly.
Yeah.
It seemed like he always wanted though to move into the domain of working on AI research.
And that was kind of what he was trying to rally everybody behind.
Yeah.
And he was a little bit disappointed when like all the readers of methods of rationality
didn't go into AI fields, but I honestly like think that the rationality community has,
well, I mean, uh, any ash already brought up effective altruism, but yeah, like the focus
on other X risks, like pandemics, uh, the fact that there's like meal squares, like,
uh, and other, you know, like weird Silicon Valley startups, uh, some of which are like
coming out of that kind of community.
And I really like how much progress people have made towards like rationalist psychology
and self-help.
Uh, I used to, I was kind of interested in that stuff, like in my like early teens and
then got really quickly turned off by looking at how much of it was woo or none of it had
been studied at all.
Just there's much better ability to find recommendations on how to combat a crazier.
But yeah, stuff like B-Minder and Compolis and so forth came out of this community.
And I, it's interesting because like, I, I like put in the little comment section of
my first donation to Mary, like this is, I got here from methods of rationality.
Um, and somebody who worked there wrote back, like commented on, because this is when I
had a blog for like a year.
Um, and they either commented on that or messaged on there and said, Hey, you know, because
it was only like 80 bucks or something.
Cause I was delivering pizza as part time, but they were doing like a fundraiser, like
a dollar for whatever, two for one or something for the end of the month.
Um, so it's like, that's, that's when really you should, that's always been my thing too.
Side note.
If I ever had like a, you know, one of the interview questions I got from my job was
like, if you had a hundred million dollars, what would you do?
And one of the obvious things would people say, I'd give a bunch of charity and it's
like, yes, but what I would do is I'd like double my impact by saying, I would have,
I would set it up in advance and say, I will do a two to one match or one to one match
for the whole summer.
And like then that way it'll encourage more people to give and I get to give money.
Um, the, but I remember when we had, we had Yusuke on the podcast, I wonder if he feels
any different now, because I knew at the time that he was in dialogue with Sam Harris
about like maybe like Harris was thinking about writing a book or something on the subject.
Um, which I don't think he's ever going to get around to doing cause I don't think he's
anything like novel to say on the subject.
Um, which isn't bad.
It's just, you know, he's, this isn't his, his thing.
Um, it's an interest, but not like a whatever you said I'm saying.
It's not like meditation.
Um, but I, I, I, because I pushed back on him cause he said like he, Yusuke said something
along the lines of, he didn't feel hopeful even though like this is getting more mainstream
attention.
And maybe that's cause you know, most articles have a terminator at the top of the pictures
or at the top of the article or something.
But when Neil DeGrasse Tyson was on Harris's podcast, Harris was writing his AI bandwagon,
you know, really hard that year or something and brought that up to him.
And Tyson's thing was like, oh, I just shoot it with a shotgun.
If I felt like it was trying to get out of the box.
And Harris failed to explain to a wide,
I would just switch the computer off.
Yeah.
And Harris failed to convince him that this was actually a hard, like not like,
like it wasn't that easy.
Yeah.
But he's come around recently.
Well, that was because when he had Yusuke on, um,
Harris brought up to Yusuke Neil DeGrasse Tyson's, uh, position and Yusuke's rejoinder
was simple as hell.
It was just like, I feel like he's not giving himself, he's not giving the intelligence in
the box the credit that he would give himself if he was locked in a box.
And there was a scientist pointing a gun at him.
And so imagine if this thing was a hundred times smarter than you,
it wouldn't be a matter of just walking over and unplugging it.
And then shortly after apparently Tyson listens to Harris's podcast and says,
that convinced me, I changed my mind.
So like we've got people who I don't know,
maybe this will come up on Cosmos season two,
which I don't even know if that's actually happened or happening.
It hasn't happened yet.
So maybe they'll do an AI episode and he'll mention that this is actually a thing.
And it'll air at seven o'clock on Fox on Sunday, right?
Like that's pretty cool.
You want to know something what really surprised me.
I mean, first of all, the rationalist community has always been five years ahead of everyone else
as far as I can tell.
Like I always feel kind of like an intellectual hipster when people tell me about this new thing.
I'm like, yes, I knew about that five years ago.
Yeah, pass that actually.
Yeah, exactly.
But on 60 minutes recently, there was a thing about reversing aging basically,
uh, scientist researching it.
And my parents like sat me down and showed me this because they're really, you know, into it.
And they are of the mainstream.
They watch like 60 minutes and shows like that, right?
And I was like, Oh God, here's going to be another one of those, you know, it's unnatural and all life must end or something.
And the interviewer was talking to the researcher and the scientist, something about like, you know, it would be,
it would be something positive about ending aging, right?
And the interviewer who looks to be somewhere in his 60s or 70s said,
Yeah, let's get on that.
I would really like that.
Not those exact words, but a very positive affect.
And I was like, Holy shit, the world has completely turned around from where it was 20 years ago.
Like that, that blew my mind.
And my parents were actually like believing it.
And I mean, believing in like, this is when I talked to them about ending aging five, 10 years ago.
They were like, Ah, that'll never happen.
Who would even want to have such a thing?
And now they're like, this is a great idea, son.
Wow, this is this.
I love how things have progressed.
I want to say the advent of CRISPR is probably one of the things that is primarily responsible for people becoming more hopeful about that kind of thing or more terrified.
I, what was the name of the book?
There was this audio book I was listening to and I went to the New York solstice because Phoenix and I drove.
So we had a lot of time to listen to audio books.
I was trying to, I think it was some book that was like talking about the 10 biggest things that are going to change the future.
And the view they had about ending aging was so negative or at least so like, you may not like it, but here's the things that might happen.
And like, I think it was just everything that they brought up about how like, oh, there's going to be genetically engineered babies that are going to be healthier and smarter.
You might have to never say goodbye to your loved ones.
Here's some bad news. In 50 years, your body will cease to break down and get worse and worse until you eventually die forever.
How bad does that sound?
I read that book Lifespan by that aging researcher recently, which is why I started taking in him in.
What, sorry?
Lifespan?
Is that right? Is it Lifespan or is it?
Was it Aubrey de Grey?
No.
Because he's the guy who looks like Gandalf, but he's like 41.
No, this guy's like the head of the Harvard Aging Research Lab. He's a much more legit scientist.
Oh, David Sinclair?
Yeah, David Sinclair.
But I bring it up to say like, I've started taking a lot of supplements from that book and they make me feel a lot more, I have a lot more energy because of those, but that's a tangent.
The point is, like, the first half of the book is a slightly highly detailed and technical explanation of like his theory of aging and why he thinks these supplements work.
The second half is like an impassioned argument why it's okay to want to live longer.
Which I was very bored by, but in light of this conversation, I'm like, yeah, I mean, good on you.
I guess that needs to be part of the package at this point.
Yeah.
And I'm glad that it is. I'm glad that the opinions are changing on that topic and about AI too, because like, I used to feel like, I used to feel like I basically was part of a cult whenever I brought up like AI around like acquaintances or like my extended family.
I just kind of mumble self-consciously because I'm aware that I sound crazy, but like now it's a mainstream topic.
And now it exists in the world.
We've got these baby AIs that still are very impressive, GP2-2 and the chess and...
AlphaGo.
AlphaGo and...
StarCraft, if you happen to know.
StarCraft.
If you happen to be able to know what...
StarGo.
Young enough to know what StarCraft is.
Old slash young.
In a certain specific geek window.
Yeah.
Like the people who know what muds are.
Yeah, right, right.
Maybe this is just a confidence issue, but I remember when I first was getting into cryonics, I didn't tell anybody.
Uh-huh.
I felt, for whatever reason, embarrassed.
You know, because it was a weird thing and it's, I don't know how much more widely popular cryonics in particular is, but I was giving the pitch to my co-workers this week and they were interested.
I gave it to two of them last week.
I've got three.
And then the other one was in the office this week and they were talking about it and it was out of the room.
And they're like, oh, Zoopz is back.
We've got here.
Tell them about what you're going to be frozen when you die.
And I have no problems whatsoever talking about it.
And they seem to genuinely interested in hearing about it.
And that's not, I guess that's only tangential in the fact that, like, I don't know if this is yet to hit, like, critical mass where people are going to be signing up a lot yet.
But I'm confident it will be.
Maybe.
Well, I don't know.
I'm leaning more towards the connectome preserving, uh, plasticine thing.
Which I think you guys actually interviewed the person that's working on it.
We did.
Before I was on the show.
Twice.
Yeah.
Downside is that that's not an option yet, is it?
It's destructive.
Well, no, you can sign up for it.
I think you can be on the wait list or something.
Well, but what happens if I die while I'm on the wait list?
Yeah, no.
No, it's.
And he's also, last I heard a couple of years ago, literally the only person working on it.
So.
It's really bizarre to me because this is such a hot topic.
At least have like an assistant, you know,
I think it's probably like at least more than literally one person working on it.
But.
Well, in his words, he was the only person that he knew who was working on it.
Maybe when he says he, maybe he meant he and his team.
No, I think he said that he was working solo.
Like one time I interviewed him.
He was like.
I said, hold on a sec.
Let me go change some, some files or whatever.
Cause he was literally mixing stuff in the lab because he doesn't have grad students to do it for him.
Huh.
Well, they now have.
Connectome the brain preservation foundation.
Cool.
Things are progressing.
Might just be this one guy's website.
But.
I mean, originally.
It looks.
Mary was just posting stuff.
Yeah.
Another exciting development on this front is the whole neural lace thing where the,
you know, the, the Elon Musk.
Fronted.
What's it?
What's the company called?
I forget what they're talking about the.
The brain computer interface.
Yeah.
The brain computer interface where we're like the presentation on, on that was way ahead
of where I expected it to be.
I mean, it's still sort of experimental, but like they're, they're very ambitious with
it.
Like, I don't know if you'll, if you'll watch it.
I could come soon enough for me because I like empathize so hard with Elon Musk talking
about how terrible it is to have gone from, well, we used to have these, you know, computers
with keyboards that you could use all of your fingers to type on.
And now we've got our thumbs.
And you're just deep, deep, deep.
I like, I feel so much pain when I'm trying to keep up with correspondence on my phone
and I'm not able to pull my laptop out.
Yeah.
I don't put much stock in presentations because they always show you the stuff that they
have working well.
And you know, you don't get to see all the things that break immediately if you try to
go off script.
Sure.
I mean, so they've apparently actually tested some versions of this in mice and it works
or whatever value of works means.
And basically their plan is to have a thing where like they drill a little hole in your
skull.
It's like an outpatient surgery.
The drill a hole in your skull.
They get this little robot that like goes inside your skull somehow and stabs like a thousand,
literally a thousand electrodes throughout your cerebral cortex.
And then there's like input output capability with these electrodes because that like, there's
a whole bunch of little innovations like the electrodes themselves being like able to
tolerate that environment and detect really, really small voltages.
So they end up getting like the voltage trace across basically your whole, you know, human
part of your brain, the outside.
And if our understanding of how the brain works is correct, then that should give you the
ability to like control things or even have it like shoot information into your brain.
Fucking awesome.
I know kung fu.
I know kung fu.
Yeah.
If I could just type with my brain, that would just be such a quality of life improvement.
Yeah.
Well, it depends on how fast you typed.
If I could type.
I mean, I only bring that up because Stephen Hawking, you know, could type with his brain.
Right.
But it took ages.
Yeah.
So.
Yeah.
But he was pretty prolific.
I think you wouldn't be able to get an MRI anymore though if you had that, right?
Oh, gosh, no.
I don't know.
Unless the metal was a non-ferrous.
Non-ferrous, but even then they'd probably freak out.
It has to be ferrous because it has to conduct electricity.
You know, it would be useful as an output.
I got a photo from a coworker of mine that was amazing, which was his, he was a former
neural, he worked in neurology, works in cancer now, but his wife still works in some neurology
thing.
And she sent him a picture of like, this is why you don't, I forget what the exact like
quote was, which is bad, but it was a wheelchair that was smashed.
Like just absolutely like as though like a giant had taken a wheelchair and like smashed
it into the front of an MRI.
Apparently somebody had left a wheelchair in there.
Luckily, no patient was sitting in the wheelchair, but it was just like, I was thinking about
like, this is why you don't let interns use the MRI.
Somebody was in the machine.
Is aluminum non-magnetic?
Well, I was going to say ferrous means it has iron in it and gold is super conductive
and has no iron in it.
Yeah.
Yeah.
But I don't know how, how corrosive that would be or how, how, again, part like titanium
might be a good, good go, go to, right?
And it doesn't, it's non-reactive with the immune system.
You can definitely get an MRI with titanium.
So yeah, I think they'll probably figure it out.
I'm, I'm first in line though.
My usual thing on these is all on things in general, but I think specifically with drilling
something into my brain, I'm second in line.
I, I want the gen two version.
I bought, I, well, I bought gen one versions, like the, the closest I've got to this is
I've got a trans cranial direct current stimulation unit.
And I bought what I think was the first commercially available one on the market.
Like when I was first looking into this like a decade ago, I, there was nowhere that was
making them.
And I was like, okay, well there's, and I, I don't know enough about electrical engineering
to ever hope of making a safe one to myself that I put on my head and zap my brain with.
So I was like, well, maybe I could pay somebody to do it.
And then when I was still tossing around the idea of trying to figure out how to get someone
that I could trust and, you know, how, like how to budget getting this all together, some
place online was selling these.
And so I bought one of the first commercially available units and I want to compare it to
yours because you just bought one a few weeks ago.
Yeah, it's a, I have the Halo sport, which is a consumer ready one that's been tested
in clinical trials.
And it is the second generation.
And I like it a lot.
I mean, it sits over the band of your ears and it is just for training the muscle memory
portion of your brain.
So it's for doing exercise or doing something like learning a musical instrument.
I have a lot of ideas for what I want to try to train with it though, like sign language.
I have been using it with Beat Saber, which I think I mentioned before, but it just looks
fucking hilarious because you already have to wear this big VR headset in order to play
Beat Saber.
And I've got a headset over a headset.
And then I'm usually playing Beat Saber like in my underwear because you get really fucking
hot playing that game.
So, you know, the weird cyberpunk feature.
I'm going full cyborg.
Yeah.
Well, they compared the surgery to, they wanted to be like a Lasik surgery.
And Steven and I have already, oh no, all three of us already have that.
You and me soon, hopefully, because I just got vision insurance.
Laser eye group.
So that, yeah, like a bit of a tangent, but I was told that I have a stigmatism and near
sightedness.
So they were like, if you get Lasik, then you'll have your distant vision corrected.
But when you get old, your close vision will deteriorate and you'll end up needing glasses.
And I was just like, oh, well, that's not worth it.
And then now I'm thinking like, yeah, but I'm not getting old.
And also like that happens to everyone.
Well, it wouldn't have happened to me or like, I'm talking like I've already gotten the
vision.
My close vision is very good and it would continue to stay sharp.
It's just that I'm going to need glasses forever anyway because my far vision is shit.
So it would reverse.
But I mean, I'm hoping that the technology gets better by the time I'm old, that there's
going to be better and better ways to correct stuff.
So I might as well do it now, especially if I've got the vision insurance.
And if you get it where I got it done, they'll give you touch ups for life.
Well, I guess basically they'll give you more surgery for the rest of your life.
I was hoping that touch up was less in like less of a ordeal than regular, but it's not
because they use the word touch up.
I guess that means that you spend two seconds under the laser rather than eight.
But like, that's not the hard part.
The hard part is the two weeks of disgusting, tasting antibiotics that run through your
like the hole in your eye down your throat.
Do you remember those?
Yeah.
Somehow it's awful.
I don't understand it.
And it's like, I mean, it's amazing how much of it gets into your throat.
Well, I mean, the trick is you can, you put it on this way and it drains out this way.
And then I usually just would drink tea when I was putting in the drops too.
But then, then the, the two or three weeks of paralyzing concern afterwards that I'm
going to scratch my eye and to, you know, written off.
And yet like the second morning I woke up doing this and I'm a light sleeper.
So that woke me up immediately and I'm, no one could hear me scratching my eye.
But I was fine.
And the main thing that also kept me saying about it was that like, this makes me sound
like I'm, what am I, like I'm, have a big ego, but like the average idiot gets laced
on all the time and almost no doctors have worked with a patient who's ruined their eye.
But you know, the guy who I got my lipstick with, he's done, he's worked with several
thousand patients.
And I think he said he's had one person who ruined their eyes afterwards.
And that's because they got wasted the night after and had been wearing contacts for a
decade and went to go remove their contact lenses.
Oh my God.
Oh, why did you throw me off?
I kind of wanted that reaction to know how bad it would be.
So yeah.
I mean, yeah, regardless of how much you get ablated away, they still have to peel your,
your cornea away.
So it's going to be a big recovery, but yeah, I don't have to.
They can laser directly on your current cornea.
PRK is what I got, but the recovery for that is so much worse.
Yeah.
You basically have to dare double it for like a week, right?
Yes.
For a week I had no vision and I had to have people leave me around the house and I was
just in intense pain for two weeks, I think, and then very decent amounts of pain for another
month after that.
And this was because you didn't want to be conscious during the surgery or?
No, this is because I couldn't, I couldn't have something touch my eye.
I got enough of a thing about eyes that they gave me a double dose of what is the thing
that calms you down?
Valium.
Valium, a double dose.
And I was still freaking out when it came down into my eye and they're like, you're going
to rip your cornea.
We're not going to do the surgery on you.
And I said, is there any other option?
They're like, we can laser right on the surface of your eye, but the recovery is awful.
And I said, do that.
They let you consent to that while on double dose of Valium?
I think I had already told them that this could be an option.
Okay.
Yeah.
Since this is not a horror podcast, I just wanted to say like, like I was, I was moderately
apprehensive.
Like I had kind of heard that it, that people, that it was kind of not a big deal, but like,
I was not prepared for how not a big deal it was because they gave me Valium and Dilaudid.
And it was just, it was just like nothing.
It was like having somebody like clip your fingernails as far as my like mind was concerned.
I was just like, oh, so that's what it looks like to not have your cornea on.
That's cool.
If you don't have like a weird thing about nothing can touch your eyes, then yeah, it's
fine.
Like I couldn't even wear contacts before I tried.
Yeah.
I couldn't watch other people put in contacts because that would freak me out so much.
How did you handle the month of eye drops?
I fucking just powered through it.
I mean, I would, I would literally hold my eyelids open and like force it in.
It was, it was a pain.
Yeah.
For me, the interesting part about getting it done was I, one of my co-workers had described
it and they do this thing where they kind of push down and not pop your eye out, but
they give it, they give it some extra pressure area to work with and it does, it does pressure
it out a little bit.
And he was like, it really hurts.
So be ready for that.
And like, I felt pressure.
Like someone was pushing on my face, like, but not, not hard at all.
And then yeah, when they, like you said, when they, when they peel back your cornea, it
was like really, really low res.
Yeah.
And it was, it was, it was merely interesting.
Right.
And I wasn't the least bit alarmed.
Exactly.
My co-worker got her Lasik done over lunch and came back and worked the rest of the day.
That strikes me as a little irresponsible.
I took, I went home and took a nap because I was with the doctors.
That was doctor's orders.
So my wife fed me a quesadilla because there was nowhere nearby to get like easy, like
feed a blind person food.
And so I had a quesadilla and went to bed listening or listening to the episode of Brooklyn Nine
Nine where one of the detectives gets Lasik surgery.
I got to say, even with the horrible recovery of PRK, one of the best things I've ever done
in my life.
And this was within the last decade.
No.
Was it?
Oh, it was right around 10 years.
May have been before 2010.
I'm not sure.
Really?
Yeah.
You still feel that good about it though.
Yes.
Yeah.
That's great.
We should probably move along.
But before we do that, any major personal life things changing over the past 10 years?
Let's go around the circle.
Yeah.
I have a lot of them.
I mean, I switched careers twice, moved, had my house burned down, changed genders.
Man.
Yeah.
Man.
Yeah.
I made a lot of these changes were directly the result of lesser on in the rationality
community or indirectly from inspiration that I got from reading Gorn and realizing that
this is a person putting science in a framework where I can understand it and I'm super interested
in it.
And then just like kind of changing the way I thought about, well, changing values really
like I had always kind of like held a bunch of the values that the lesser on community
held as important, I guess, but I didn't have vocabulary for them or any way to really
refine them.
Like, oh gosh, like, um, empiricism, I guess, just kind of, yeah, like focusing and doubling
down on empiricism really was the main thing that like helped drive me forward.
There are a lot of things doing experiments, seeing what happens, and then like not making
you, you know, forcing yourself to not flinch away from the data, what the data shows.
I don't know for going in a circle, I don't, I, I touched on some of mine already.
I mean, it's mundane stuff.
I like maybe if I had to put weight on it, probably 25% of the reason I got into programming
was because it seems like a, you know, a rationalist thing to do.
But the, the main thing that got me into it was or that let, let me do it rather was
just this, I don't know, I'm not sure where this would be in the rationalist vernacular,
but I don't know, the like just do it kind of mentality, like there's nothing stopping
you from doing whatever you want, given that you're not, you know, filing laws of physics
or whatever, but sort of just this, this serious attitude of like, okay, I've got to like take
charge.
Um, yeah, I mean, other than that, I don't know, all the, you know, regular life stuff
that people do, got married, um, got, I guess, a house, which, you know, is like a, it's
like a, my house is basically an apartment.
Um, I don't know, nothing super exciting.
I'm feeling rather like I've not done much, which is totally fine.
My life's in a good spot.
So, yeah, but you have a really bad autobiographical memory, so you're probably just forgetting
all this stuff.
It's all this really cool shit that I can't remember.
Yeah.
Oh yeah.
That time I saved the world.
Yeah.
I feel really good at, like, you know, from my perspective anyway, being really supportive
kind of people around you, which I don't know if you've always been that way.
I know that I think like when we first met and then like a few months at a time, you
were talking about like trying to deliberately improve on that.
And I think that that's a really strong point of yours.
I appreciate that.
I don't know how much credit I get for that being a rationalist thing or not, but you
get credit for it regardless.
Oh, thanks.
Cause that's a cool way to be.
I, I, it's been a long time.
It's been a lot to me personally.
It feels like I'm patting myself on the back, so I'm reluctant to do it, but like I feel
like it's just the natural thing to do.
I like getting people to do it to me.
I wish more people felt that way.
It takes no effort to do really.
So just go forth and be nice to people.
But yeah, I don't know.
I'm, I should have thought of a better answer for this.
I actually did have notes and stuff, but they're all just random little tidbits about me that
aren't, aren't interesting.
So I'll let you go ahead.
I guess, hold on, the cryonics thing too.
That is a good one.
That would have been around 10 years ago that I signed up.
So everyone should do that too.
Like, I don't know.
It's, I, when I,
Did you sign up for the 30 year term?
Uh, no, I'm, I'm on the annual term still through the cryonics Institute.
I'm even from my life insurance.
Yeah.
For your life insurance.
No, uh, Rudy.
Oh, that reminds me.
Rudy Hoffman was life insurance agent I worked with.
If you're curious about this, you should check out his book that he sent me for free.
And I, I think I forgot to email him a thank you, but he, he hit me up with this like longer
package where I think I'm paying into it forever.
Um, but if like, if I live to be 90 something, there's like $330,000 in it that I get to
just take out in cash, but it's not like I have to hit 91st, I can take out less money
before that.
Yeah.
And that's just mine.
Yeah.
I don't, I don't have to pay back.
It's on a loan or whatever.
I got a similar thing except mine explicitly ends after 30 years.
So I've got another 20 years in which I either have to die or come up with a difference between
what it pays out and what it'll cost.
So it does pay out in 20 years though.
So 30 years from the start.
At least it's not like a use it or lose it policy.
That would have been a kind of a shit deal.
Um, yeah.
So anyway, Rudy Hoffman wrote a book called the, um, the affordable immortal, which you
can find on Amazon.
And, uh, if you're curious about this and it sounds way too out of reach or something,
check it out.
I have made a note.
Yep.
Me too.
Me too.
So I, wow, I've had a lot of changes over the last 10 years.
I think 10 years ago I was still in my alcoholic phase where I was drinking close to a fifth
of vodka every night.
Um, it was near the end though.
Uh, and after I quit that, I started working out and I mean, I have, I have regressed a
bit since then.
I think I'm like eight pounds heavier now than I was a few years ago, but no one can
tell you look buff.
It's great dude.
All right.
All right.
I ever since the back of drive worked out much less.
But the, I mean, I think the big change happened.
I, I quit drinking.
I got surgery.
I lost weight and I started recording the HPMR podcast.
Uh, and wow, my life really changed around after that because like, like I said, it started
out with seven listeners.
So every week was just like another win when, as more people started listening, you know,
having constant unantrupted weeks of more affirmation for like two years in a row really
does a lot to build up your self-esteem.
And after that, I like started writing and I started like being social and having friends
and I had this wonderful relationship, which did not end wonderfully, but it was, I learned
a lot.
I learned a lot about myself.
Um, I learned how to have good sex, which was actually really important.
Um, and I know we're never going to do a not safe for work episode, but I'm curious
what, we don't, we don't have to do it, but I just, I, I'm curious at some point, just
you and me can sit down.
Yeah.
We'll turn off the lights.
We don't have to look at each other.
So for the record, I'm already awesome at sex.
So I'm curious what, what, what, what the reference was like, like, I sucked, then I got good
at it.
Anyway, sorry.
Um, yeah, but as long as we're boosting your ego, it's worth, it's worth pointing out
that like, well, I've had some major defeats in the past two years.
Well, everyone has, I mean, if it was all that, that's like, but, but this podcast,
one I'm doing that is still on your feed is completely piggybacking off of yours.
Okay.
I see, I'm not, I don't go to like, to the HPMR subreddit like specifically, but I see
on the front page of my regular feed, once every two weeks, someone's like, you guys
heard the audio book and it's like, it, this, this bring, this, this was my introduction
really to the rationalist movement because I was driving a lot and that's how I listened,
that's how I listened slash read the book and I met you.
You were at my wedding.
We're doing this podcast, this where you're coming up on four years.
Um, like it's, it wasn't just like this one thing you did.
Now it's behind you.
This is still happening.
And so don't, don't, uh, stop patting yourself on the back for that, or at least the rest
of us will keep doing it.
Yeah.
I think the thing that most surprises me is that when I was in my late teens and twenties,
I was really much sort of a violent revolutionary leftist.
I was very much a burn the system and start over because it's all corrupt kind of thing.
And now I am much more conservative and I'm still like extremely liberal, but I no longer
like want to kill everyone in power and, and eat the rich and burn down the city.
Like I'm like, most of my stuff is in the city.
Please don't burn it down.
Yeah.
People will get hurt.
Yeah.
Exactly.
Yeah.
So that's, that's very weird.
I don't know.
That like sounds a little bit like maturity.
I, I guess I just 20 year old me would look at revolutionary things sounds more like the
kind of YA like, yeah, it sounds more like you're just like, I would be disappointed.
Young me would be disappointed in my current self though.
That's a question.
Couldn't go back and answer that for the two of us.
Like how, how would you have 10 years ago feel about you today?
Yeah.
Because me of 10 years ago, I think would be stoked on who I am today.
Yeah.
Um, there are, for the most part, I don't, I don't feel any sense of accomplishment or
like anything like that, although I recognize that I probably should.
Um, but yeah, I, I think my life is better in every way.
It's just that my values have drifted somewhat and that would be concerning to younger me.
Yeah.
Younger you'd probably hate the fact that you own property or something, right?
Um, maybe.
Yeah.
Maybe.
Yeah.
Younger you was weird.
Yeah.
Well, I mean, I'm just remembering because I have, again, my journals, like telling a
friend of mine that if I stop believing in magic, then kill me because I'm not me anymore.
And he's like, no, I don't know.
Like the, like 10 years ago, me would have looked back at that, which I guess was another
10 years.
Like what, what the hell?
That's not 10 years ago, but, but yeah, like 33 now, so like 23 year old me would have
been like, well, fuck, like I didn't think, I didn't have the self esteem to think that
I could go into a scientific field or that like I was going to ever make money or understand
how to adult, how to have like stable relationships or manage money or any of that.
So like the fact that I managed to do a lot of that and I'm like, it's not like some of
this stuff is not even that hard.
It was just, there was a big barrier of it seeming unattainable.
The Ugg field also.
Yeah.
The Ugg field.
The just like, I know nothing about this, so it must be the hardest thing in the world.
Is that the word for that?
The Ugg field?
I mean, I mean, that's kind of the less wrong concept for it.
I would say, I mean, where I was 10 years ago, that's probably something I struggled
with a lot, which is the idea of like, I was in, I was in graduate school, but just like
everything about graduating just seemed impossible.
It's like this, you know, in a certain sense, you could say I was in grad school to avoid
having to go into the real world.
That's why I went to college.
Yeah.
And so like, but that wasn't really a solution because like that's just a stress, a stressful
thing too.
And one thing about less wrong is, you know, getting a name for it, getting a handle on
it and getting this idea that like, hey, just recognize that's what's happening, recognize
that you're having an aversive reaction to this idea or this, this deadline or whatever.
And here are some tools or here are some ways of thinking about approaching that.
I think personally, that's one of the ways less wrong and then rationality movement helped
me the most in a day to day sense.
Yeah.
Giving you all kinds of tools and frameworks, like here's the model I'm using.
Here's what the mental motions towards doing that thing look like.
I wish that I'd had a lot of that stuff explained to me earlier on, but it was still invaluable
having like, red blogs where other people talk about, here's how I do social skills
or like, here's how I approach something that seems just really difficult to the point that
it makes me so anxious that I can't think about it.
Like, it makes your problems seem less intractable.
The fact that someone else is like saying, I've had this problem and here are some steps
that you used to overcome it.
Granted, that's the opening page of every self-help book, but like, I think that there's
a lot to that.
Like you said.
But then there's actual steps.
Like I was talking about trying to read self-help books where it was like, I've had these problems
too, but then I just learned to believe in myself or like, I started reciting a mantra
every day and I was just like, I don't see how this relates to being able to like, I
mean, I remember when the field was first explained to me, the example was somebody
talking about a verse of mail and that resonated with me because I would always have this thing
where I'd receive lots of letters and like some of them look like, oh God, that's a tax
thing or like, oh man, I don't know what this looks like a bill.
This looks like, oh, did I get like a speeding ticket or something like they just pile up
and I'm just like, I can't even open those.
I don't, but like, you don't actually like consciously think the words I can't open
those or I don't want to look at them today.
Your subconscious is doing all of that in the background and your conscious mind is going,
oh, I really need to do this thing right now.
And I'll definitely get to that later today.
Oh, like, I guess I didn't get to that today, but definitely first thing tomorrow.
But yeah, you're like, when you realize like what's going on some consciously and that
there are ways to fix that, it's like, oh, OK.
Like, because like opening the mail and then figuring out what to do about it,
isn't even that hard.
It's just really aversive because you've like negatively reinforced opening
mail so many times.
Yeah, it's funny because I didn't even realize this about myself until you talked
about it, but like I used to have that, that exact reaction about mail.
I used to have that reaction about email, except maybe even worse because I had
like this horrible boss where I would like on an intermittent reinforcement
schedule, get these horrible like, like it's the middle of Saturday, but you're
dropping everything and working now because God because one of those.
Yeah.
And so I had this horrible relationship with both of those things.
And just over time, just kind of turning the crank of of using the right,
you know, the right mindset on them.
I don't really have any particular emotions about email or mail anymore at all.
So and that's a huge relief, right?
Like you're carrying so much constant stress and turmoil that you're not even
conscious of, but you're definitely carrying it and to not have that anymore.
It's, uh, you breathe, you know?
Yeah, I feel like we still a lot of your time.
Where were you a decade ago?
What have you been up to other than building a media empire that is going
to be challenged or has been challenged by Disney for its epicness?
Well, media empire was only in the last four years, but that's been a huge thing.
Obviously, I mean, in the last 10 years, um, I mean, I'm, I've got a PhD.
I graduated, uh, I moved to, um, I moved to the Bay Area and then I moved to Houston
and then I moved here.
I got married.
I had three kids.
I got divorced.
Um, uh, I got a real job and then I got a different real job, um, which is
where I am now.
And, uh, it's just a lot of other stuff in there, you know, then picking up
hobbies and such would young you think of current you?
I think they'd be impressed in some ways and probably disappointed in some
ways because I have always had and continue to have a, uh, delusion,
like delusion of grandeur about my, my destiny, like anyone who consumes a lot
of science fiction.
Um, so just to be honest, like I'd probably be like, Oh, you're not running.
Um, Tesla space X.
You're not president of Mars yet.
Right.
Right.
Exactly.
And, and, but, um, and I'd probably be a bit, a bit baffled and confused at some
of my like personal relationship decisions and I would absolutely not
understand, uh, my, uh, I, I, I had no conception of what it is to have kids.
And now I've, my oldest is seven.
So I've spent most of the decade having kids and it's, it's not at all what I
thought it would be and it's wonderful.
And I would have no frame of reference for it.
So that would just be kind of a big confusing, um, uh, maybe, maybe I
wouldn't be able to relate to myself if that makes sense.
Now that makes perfect sense.
When I was thinking about going back and tenure increments, I was like each of
the like different tenure increments of me probably like would kind of recognize
myself and each of me, but then also there would be these big gaps of this is
a different person.
Yeah.
If I look back, not, not even that far, I'm just like, that person was an idiot.
And, uh, I'm probably going to feel that way about myself in 10 years.
The weird thing about again, having the journals is that like, it was funny
because I first noticed this about my art where, um, a couple of years later, I'd
look back at my art from two years ago and be like, God, I sucked.
Oh my God, that's such crap.
I can't believe I thought this was so good.
It's spent so much time on it.
It showed a term.
And then like two more years, I'd look at it and be like, Oh no, that
was, that was pretty good actually.
Like, and then I feel the same way about like going back and reading my journals
where I'm like, Oh, I was such an idiot.
What embarrassing thoughts.
And then you get enough distance from yourself and you look back and you're
not seeing, Oh God, that was the embarrassing version of me a little while
ago, but that was 17 year old me and like they were really trying their best
and had all these ideas and thoughts and fears that are valid.
Like, and I guess I also like working at a library with other kids, pre-teens
and like kind of looking at it.
It's like, Oh, there's the frame of reference for like that age of person,
that genre of person.
And it's like, no, that like I was a pretty cool teenager and I was way too
hard on myself.
I don't know.
That's kind of an important, I think it's important to not look back and be
like, God, I was an idiot because like you're still that person, partially.
When I look back on how easy my parents had it with me.
And at the time I thought I was a rebel because I would get punished for
little things, you know?
And now I'm like, Oh my God, I did zero drugs.
I skipped zero classes.
You freaking bastards for jerks.
Yeah, I I never give my younger self a hard time.
Luckily, my period of like, you know, delusions of grandeur, if you want to call
it that only lasted maybe a year or two.
So I never got too entrenched in that.
But my like, I I'm hoping that, you know, in another 10 years, I'll look back
on 30 year old Steven and be like, Oh, OK, you know what?
Yeah, he wasn't nearly as awesome as he could have been, but he was doing
what he could and you're who you are now because you're because of who that guy
was. So that's how I feel in relation to Steven sub 2010.
So yeah, yeah, I like what Jess just said about being easier on yourself.
Because I do think it creates a lot of unnecessary internal conflict for
me to I think the label for as good ism, like, like just the constant pressure
on yourself that you need to be better and that you should be better.
And it's like, just go easy on like, first of all, that's probably not even
doing you any favors.
Yeah. And it's and it's causing you very real suffering.
I've done a lot of work in therapy where I feel like I almost was trying to hide
the person that I used to be because I felt like it was shameful.
And it was just because it was this person who had really bad anxiety and
depression and was bad at social interactions.
And like, and it's like that those aren't shameful ways to be.
Like that's like sad.
I would never want like some 14 year old to feel like they're a bad person
and don't deserve nice things because they're like bad at social interactions
or like can't figure out how to get good grades in school because they have ADD
or you know, like people are pretty good on the whole.
I that's another weird like mental shift that I think I've gone through.
I can't think of anything like sort of like sadistic torturer,
like unrepentant torture that I'd say you should feel bad for who you were
10 years ago, right, even if you sucked at all the things that you care about.
Like you're, I don't know.
There's some people that are just mean.
Well, they they take advantage and abuse other people.
Yeah, yeah.
Like maybe that's not even sadistic torture.
That's the soft version of sadistic torture, like an unrepentant dick.
Yeah.
Then then, yeah, sure, maybe you should feel bad about it.
But only to the extent that it makes you a better person.
Well, even if it doesn't, and it at least makes you stop being a dick.
And that in that sense, minor utilitarian is like, yeah, OK, you'd be miserable
if that stops you from making other people's lives miserable.
But for the most part, no one should ever feel bad about what any, you know, they're
like as a kid, I was probably a dick.
I had a lot of terrible role models.
But like, I think it's I don't blame myself for the things
that didn't as 12 or 13, right?
It's been a long time since I've looked back at the mean things I've done
and like felt bad about it.
I don't identify with that person at all, right?
Yeah, I mean, I share very few atoms with that person
and very few memories of that person.
There's some vague sense of physical continuity, but like other than that,
I don't I don't feel like I relate to that person whatsoever.
Yeah, I still feel vaguely bad about every single time I was mean to my brother.
But that said, I don't think it's healthy to like continue to
flagellate myself about that at age 30 something.
Some years ago, I apologized to my brother for one time as really
like I yelled at him because he ruined one of my save files on Majora's Mask
because that game has like a time thing where if you and I like yelled at him
and made him feel bad and like a decade later, 15 years later, I remembered it.
And then he was like, I have no idea what you're talking about.
And like, of course you don't because this wasn't this wasn't like a thing to you.
Like you remember it at the time and then it went away.
And I that's not often thinking about it for ages.
Yeah, it's life's weird.
That's the part of the podcast where I get inarticulate.
And we're supposed to do the last wrong post.
But we're once again, probably do we have time because I love we got time.
All right, good. Let's do them.
All right, on to the less wrong posts then.
Did you get a chance to get to that?
I did. All right.
OK, our first list was familiar with the blog, right?
Yeah, less wrong dot com.
He's heard of it.
You can find some of Matt's posts at more dinner mail.
In the mail with my hand for everything.
All right, so translate that again for me from the the old ancient language.
Death of hope. Death of hope. Oh, wow.
It's the kind of handle you choose when you're 16.
Yes. And then you never change.
I love it. No, I think it's great.
I knew I recognize the ancient language.
Is that what it's called? The old tongue.
The old tongue from from Wheel of Time, which gives me shit for mentioning
because it's the only long series I've ever read.
That wasn't Harry Potter.
But yeah, I couldn't remember the word parts are anyway.
Yes. So that cool.
Our first post was your strength as a rationalist,
which starts off as a him telling about
and thing that happened to an anecdote as one will
in an IRL IRC, rather, chat room.
Do people all know what IRC chat rooms are?
I think so.
They still explain for our listeners.
Internet relay chat.
It's basically discord back before discord existed.
It would you would type in real time to people one line at a time
and everyone in the room could see it and you would all just kind of chat like that.
You know how IRL is where you do that with meat space.
This was that, but in the computer, IRL IRC.
Perfect. Yeah.
Anyways, someone was telling him that a friend of theirs needed medical advice
over IRC that he'd been having chest pains and he called an ambulance.
An ambulance came, but the paramedics said nothing was wrong and left.
And now the chest pains were getting worse.
And Eliezer remembers that he was very confused by that story,
that he remembered reading that paramedics always have to take someone
to a hospital when they complain of chest pains,
because otherwise they risk being hit with a huge lawsuit if it actually was
a heart attack and they don't have to end up paying the person's bills.
So as a matter of policy, you always take someone to the hospital.
But he also remembered, you know, he'd gone to the doctor
complaining about chest pains before and the doctor explained, it's not a heart attack.
You have this or this or whatever.
And every time he'd done that, the doctor had always been right.
And so he was he was confused by the story, but like he waved it off and said,
yeah, the paramedics were probably right.
And then it turned out his friend came back a little later,
said that this friend of theirs made everything up entirely.
And at that point, Eliezer begins the self-flagellation
where he says that he he felt really bad about this
because he had explained an entirely fictional story
within his existing model by contorting his thought process to fit it.
And he should have at that period, as soon as he was confused,
stopped and noticed and said, I don't think this is in the post,
but it's become sort of a meme, or at least for a while.
I notice I am confused is the term that was used because whenever you are confused,
that is a sign that either the story is wrong or something about your model is wrong.
That if you can change your model to explain any anomaly, even one that never happened.
I believe the line was a hypothesis that forbids nothing permits everything
and thereby fails to constrain anticipation.
And the I wasn't in this post, but somewhere on the blog, too,
like the the the issue was that like that little note of dis dis concerning like confusion.
It's just a failure of human architecture that that's not a blaring siren.
It's just like a beep. That's confusing.
And part of the training that are as rationalists is to try and promote
that to conscious attention when you notice it.
And I make an effort of saying either in my head or out loud.
I notice I'm confused if I'm confused by something.
And that's one of the the core principles of skepticism
that Brian Dunning's articulated over the last 15 years of his podcast of like
before you move mountains to try and explain some bizarre event
that someone was describing to you.
First things first, make sure it actually happened.
This is that's a little more straightforward than trying to map
a something into your existing mental model and stuff.
But it's the same and it's in essence has serves a similar course.
I'm trying to say.
If I had to guess, I would say that this is some kind of artifact
of having minds that evolved to make models.
I mean, it would be OK, it's raining and now it stopped raining.
And maybe God is crying.
I don't know.
Like people kind of come up with stories to explain why things happen.
And then they I guess, like, corroborate them over time.
And the model has some kind of explanatory power.
I mean, we have like Newton's laws, which are exactly right.
But they had explanatory power.
But we have like as a as a species standing on the shoulders of giants
who have actually done the math, we have good models now.
And it makes a lot less sense for us to try to come up with an explanation
than to kind of pause and be like, well, it makes more sense
that this person was making something up.
Although the thing with the paramedics, the first thing, of course,
that jumped into my mind was that's actually not true.
The paramedics do not have to take you to the hospital if you refuse care.
Oh, yeah. I mean, of course, you know, the
elliors probably knew that and that was probably one of the things
that was disconfirmed early on.
But like it's just like me reading this story.
I couldn't get that out of my head because I was like remembering a time
when I was doing volunteer EMS and we showed up on scene of someone
who had cut their finger off and they refused care.
They're like, I'm just going to duct tape it back on.
And we had to leave because you're not actually allowed to force
somebody to the hospital if they don't want to.
But like, dude, you really.
OK, do you just need like two people to to affirm their verbal consent?
Or do you need them to sign something saying, OK, you're telling us sign something?
Or if they like are unable or, you know, uncooperative,
but you can use verbal consent, there's some like confusing legal
stuff around it. But basically, like I remember an EMS person telling me
that one time they went to someone who was having a heart attack
and they refused care because it would be too expensive for them to go to the hospital.
That was the same reason this guy with the finger said that because
even though we were the volunteer EMS unit, so it was like the ambulance
ride is not going to cost anything in the care we give in the ambulance.
But once we give you to the hospital, it's going to probably like bankrupt you.
Unfortunately. Yeah.
And so the EMS team left and she said like the whole time they were just hoping
I hope he falls unconscious soon and his wife calls us back
because once you're unconscious, you can't refuse care.
Yeah. And they show up.
Oh, there's an unconscious guy.
It looks like he's having a heart attack to the hospital. You go.
Yeah. If that feels you with this awesome sense of whatever,
there's a great subreddit for that called a boring dystopia
where it's like the whole sentiment is like, oh, yeah,
I have decided to discontinue a living because I can no longer afford it.
Yeah.
God. Yes.
Yeah. One thing I like, I think that both of the
the ones we're going to discuss today are on similar topic,
but like I find that people lie a lot
and it's a nice it's a nice framing for for being like
like I used to I think I used to be a lot more credulous and over time
just been a lot quicker with the filter of rather than thinking like
hmm, that's odd that that story doesn't quite make sense.
But I'll just be like, that's bullshit.
And like your people lie so much.
Honestly, like you're so but
you're seriously like you're so likely to be right
if you assume people are lying if their story doesn't make sense.
Even necessarily lying out of bad faith.
I remember when I was a little kid,
my mom would just make shit up all the time, like she would make up her own
science facts.
And like, I really think that there's this human instinct to like
that there's a comfort in like having things make sense or there being
some kind of story to something.
But I remember one time my mom was like bees.
Bees aren't scary because they just want to drink the flowers or and I was just
like, OK, and then another time I was wearing this floral bathing suit
and a bee was buzzing around me.
And I was like, don't worry, just think you're a flower.
But like before that, she had told me bees go and sting flowers
in order to like sting flowers.
She's like the bees go sting the flowers in order to like drink the nectar,
which she didn't know what the hell she was talking about.
She just made that up.
And then like, so of course, she's like, oh, don't worry,
it's just it thinks you're a flower.
And I'm like, oh, so it's going to sting me to try to drink my nectar.
Like, OK, I remember being like, I forget.
Like, I think I was not going to school at that time.
So I would have had to been like less than five years old and realized
like my mom was full of shit.
She's just making shit up.
Like I was reading books about biology at the time.
Of course, they were for kids or whatever.
But like, I was like, wait a minute.
So like really early, I was like, oh, my parents will just make shit up.
So like everybody must be making shit up to me.
If like, you know, if my parents are, I've been trusting forever.
I still am pretty trusting.
Unfortunately, I have this thing I've been trying really hard to work on it.
But I still do it sometimes where I lie out of like social nicety.
Like white lies, I guess.
Yeah, just something to like make things less awkward.
And the ethics are really confusing.
You get stuck in a web of lies, you know?
I mean, I would love to do a whole episode.
Actually, that's another thing about radical honesty, because the ethics
around lying get really confusing when it comes to like consent.
Like whether or not someone can this would be going off on a huge tangent.
But like the short version of this is like the standard culture.
It is acceptable and expected that you do white lies in order to not hurt
people's feelings or in order to go with whatever, like the, you know,
like socially acceptable way to respond to certain things is.
So doing radical honesty is actually subversive.
Most people don't want it.
I tried to do radical honesty, but like with people who have consented.
I was wondering, like sometimes you'll be telling a story and then I'll just be like,
OK, if I tell this as it happened exactly, it will be boring and take 10 times as long.
I can just make like a kernel of the story, which is not it's not a lie,
but neither did it happen exactly this way.
I almost feel like that's a public service sometimes when you're not altering
the facts in a way that's going to mislead anybody in a dangerous way.
But you're just you're just making a more exciting story or one that's more
palatable to listen to.
That's how I that's how I think about it, too.
I don't really worry about it too much, but I do sometimes feel like,
I hope this is my being unethical by making a better story for my friends.
Yeah, I'm holding back a bunch of anecdotes and sidebars because we're
running low on time, but I do the same thing and I feel dirty when I do it.
Like I'll be at work and I'm explaining, like, you know, something
that happened on the way in, and I'm like, well, I'll save them the long version.
And like, I feel like I'm not telling the truth.
And I feel like that comes off and it's it's it's weird.
And I don't I don't know a quick way around that.
I know what you mean. Yeah, we'll solve it later.
Deal. So yeah, the title of the post is your strength as a rationalist.
And the line, the title line is your strength as a rationalist
is your ability to be more confused by fiction than by reality.
If you're equally good at explaining any outcome, you have zero knowledge.
So that's that's on the boilerplate title page of my PhD dissertation.
Really?
The the if you're equally good at explaining any outcome, you have zero knowledge.
Yeah, nice.
Love it. Yeah, it was a good tattoo.
Yeah, it would be. Yeah.
So, man, all right, small digression.
The only like when you're describing your mom, like having just like any model
is better than no model and not realizing that she's making up stuff
as like on the fly or not caring that she is.
It makes me think of that scene in methods of rationality
when they're all trying to explain some big plot event that I don't want to spoil.
But they're people who have been part of like the cult of not the cult of Harry,
but like in in in his way, his sphere influence.
And they're like, well, luckily, we're all perfectly sane.
Right? Yeah, man, that must have sucked to be like the rest of those people.
And like, that's what I feel like right now.
With the same sense of irony.
I often I still don't notice confusion.
It's a skill I need to work on because, I don't know,
but lots of time when you're reading fiction, it may not be perfectly written.
And you're like, OK, so the author flubbed a little here,
but I don't want to be taken out of the story while I examine every little detail.
So whatever, I'll be slightly confused and it'll clear up in a chapter or two.
Same thing you're doing in like the whole rest of your life.
Well, this is confusing.
I don't want to not have my life make sense.
Maybe this. Yeah, that seems fine.
All right, I'll I'll permit myself to other quick sidebars.
One, I'm super gullible and I'm trying to work on that.
I don't know why. I've had that problem, too. Yeah.
I don't I'm just I'm you're a high trust community.
No, but even as a kid, I would believe that dumbest shit.
And it took like it would take minutes for it to go away.
Like my biology teacher and my chemistry teacher in high school
were both ex hippies with beards.
And one of them explained to me like, oh, yeah, we're actually we were
we were twins joined at the beard as kids.
And like I spent like a minute unpacking that in my head.
I'm like, that's not possible.
But I so I so trusted my teacher was telling me this that, like,
it I spent a good minute dissecting that.
Like, there's no way that's true.
It's kind of be a metaphor for some. What is that?
What is beard?
But for for a solid minute, I was trying to work into my world model.
How do people could be born joined at the beard?
And yeah, so again, this is not like a.
Oh, yeah, you could convince five year old Stephen something.
This is I don't know if I'd be that stupid today.
But anyway, you know, Jesse Cannonball Jenkins
sometimes just has the the flat effect
deadpan kind of joking that he does with people.
Yeah, and people like him. I hate those.
Yeah, because they hold a straight face.
And so when they just bullshit me, I'm like, really?
They're like, yeah. Oh, OK.
And the nice ones then say like, no, man, I'm just fucking with you.
But every now and then I go around believing something for months.
And it turns out it was just someone fucking with me.
I had a co-worker like that.
And I could share stories that were as humorous as that, but I'll save it
and just jump on one thing that you said about assuming bullshit.
Oh, I found something last night.
We got a new cat that we're both terrified
that something about will happen to it, something bad happened to our last cat.
And she read she read that, uh,
like the stuff in jet dry, like wipes on the wood floors is toxic to pets.
And then she showed me
actually, she went up to go look at the box in the closet.
So I looked at her phone because it had the article on it.
It was just a picture like shared on Facebook or something.
And I'm like, oh, this is all the kinds of bullshit that people see.
So I immediately called bullshit.
But I don't want to be like, it's fine.
You know, it's bullshit and just call after her.
So I went looked and then I actually read the thing and then I was like, all right,
you know what, let's check to be a hundred percent sure,
because I'd be willing to bet you a hundred dollars right now that I'm right.
But let's be sure.
And there was a Snopes article that actually had the exact cut and pace.
This is just a thing that's been going around for years.
Nice. So. Good job.
But but yeah, calling bullshit, I think is is a good default.
And not to say push it away as bullshit, never accept the fact,
but say, no, I'm not going to leave that right away until I verify it,
which brings us to our next less wrong post.
Our next less strong post is a snap.
I lost my position.
I defy the data.
Thank you. The title of the post.
Would you like to give the synopsis?
Sure. It opens with one of the great weaknesses of science is that it's
this mistaken idea that if an experiment contradicts a dominant theory,
we should throw out the theory instead of the experiment.
And I agree with what you put in brackets there that I don't necessarily think
that's true, but that is sort of what you're supposed to think.
Like, oh, we've just falsified Newtonian gravity.
We need it's out.
Throw it away.
Maybe that's like the perceived ideal in high school science or something.
I think that's closer to it.
Yeah. But that's not how science really works.
And also like this was written during the time of the great atheism debates
on the Internet and a lot of, you know,
scientific proofs of God not existing or scientific proofs that faith
may have magic powers, you know, or around at the time.
And basically lay people were using science very much in this sort of way
that like this experiment proved this and this and therefore science is on my side.
And so I don't think that like scientists necessarily maybe ever treated it this way.
But a lot of the at the time, the common perception was that this was sort of a thing.
But I think this is one of these rare cases where
Ali Azar's lack of formal training in an actual academic setting
shown through a bit because I'm not sure real scientists thought that.
I feel like 10 years ago, I would have I would have just believed this as it was.
But like, especially after reading a lot of Scott Alexander's posts about philosophy of science,
I would I agree with you guys.
It's it's that's that's not how it works.
And that's not how it's supposed to work.
But I mean, the post, I think is salvageable, despite that.
Yeah, because there's there's there's lessons that you can take out of it
that aren't necessarily about the truth of how academia works. Right.
Yeah. Yeah.
I mean, basically, he's saying, like, if you get if you get a new piece of data that
it's that's why I think it's related to the previous post.
It's like, if you if you get a new piece of data that doesn't make sense to you
and it's just one piece of data, then you can just say,
nah, you get one free, nah, and then and then give kind of the world
a chance to prove that, you know, get a better get a better experiment or something like that.
I think yeah, he says that if it contradicts the standard model, it's an important fact
that needs to be openly acknowledged.
And I think he he goes farther than that, which I like when he says
he he like almost coins this term defy the data, which I mean, never caught on or anything.
But he pointed out that, like, it would be interesting if experiments like this
that contradicted the model were published and with the note published, but defied,
where someone, you know, important member in the community could be like,
I defy this data, I don't think it's true.
And then, you know, there would be ongoing follow up experiments or something.
This was posted before the it was the replication crisis.
Curses, which so in that sense, kind of foresaw it.
Yeah, I don't know if that had anything to do with that.
But I do remember that was a thought that kept going through the rationality community
where people are talking about wishing that falsifications have more status.
Publishing like new data was always the highest status thing to do.
Doing new experiments, yeah, exploring new areas.
But like replicating and falsifying or confirming stuff was always kind of
and never made the front page of journals.
And I think that's one of the reasons we have the replication crisis.
No one who wanted to have a career in this would bother replicating things.
It was not something I got published.
And no one would pay you to do an experiment that while we already know that works.
Right. Yeah.
So and turns out there was p hacking involved and, you know, other bad things.
I think there was something that came out recently that showed even a bunch
of meta analyses tend to be skewed.
Yeah.
Where that's kind of upsetting.
Yeah. But also kind of predictable.
Yeah. He even says, you know, if someone defied the data, scientists could say,
I'm holding my breath waiting for replication rather than having to take sides.
And like literally, that's now what we do.
Whenever I see a new article, I'm like, well, I'm going to wait for that to be replicated.
Recently in the discord, someone posted something about a potential faster
than light communication, which first off, I just dismissed off hand.
But it could maybe I don't know the physics behind this shit.
So I'm just like, well, I'll wait for it to be replicated because this is
a popular science story about some possibly anomalous finding.
And every I mean, when I was on Facebook, every six months,
I'm going to come across the front page that would be like, oh, look,
we've got a cure for Alzheimer's.
And I'm like, I saw this three years ago, the science reporting is so bad.
I don't even look at very much of the science reporting unless I know
that it's from a source that like very is very, very diligent about like fact
checking and posting all their sources.
But generally I'll go right to the publication.
I really love the skeptics guide to the universe.
It's a podcast because specifically they ride this hobby horse a lot.
They're like, these are the current popular articles.
This is why the news you're reading is fucking stupid in the actual research.
That's not what it says at all, because generally the articles you read
are, you know, a reporter with maybe a little bit of science background
reading this and finding the most crazy headline they could make to grab
people's attention or not even like, yeah, like I remember a bunch of times
looking at some crazy headline claiming something and then going and looking
at the actual article it was based on and showing that it was actually
saying the exact opposite of what the headline said.
Yeah, it's ridiculous.
And so skeptics guide to the universe does that almost every week where they're
like, here's a thing that's been published.
You might hear about this from your crazy friend soon.
But this is what the actual study was.
Man, I used to be on Facebook, like being the asshole that was like the one
person out of my 20 friends who have shared this thing being like, and here's
the Snopes article that I feel like I like paid some enemies with people.
Yeah, that's my role on Facebook as well.
And then I just like mostly stopped going on Facebook, except to share memes
or to use Facebook Messenger with my few friends that refuse to use any other
messaging app. I really got to get that new one riot.
Is it that Matt was talking about the new message app?
Yeah. Oh, I don't know.
The only reason I have so many messaging apps now, yeah, it's like,
can we use less messaging app?
I like this, but I've basically stopped using Slack entirely in favor of discord.
I do like discord.
It has a few flaws, but for the most part, that would be nice if
I keep trying to find some kind of this is such a tangent app, like messaging app aggregator.
They claim to exist.
There's a few that I've tried.
None of them has impressed me yet.
The funny listeners know of one that works really well.
I'd really appreciate a recommendation.
Now I'm going to shut up.
I like discord because it has all the strengths and flaws of the old IRC channels.
I like it. But like, what about your friends that won't use anything but Facebook Messenger?
Yeah, there's a reason I say that.
They actually are dead to you.
Well, no, I use Facebook Messenger.
Yes. OK. All right.
I mean, so all right, back to the post.
So so here, you know, the anticipated reaction, I'll play the part of the
the person that he's reacting to.
Well, so so Eleazar, you're you're telling me that the the person that says,
oh, well, I whatever experiment after experiment,
keeps showing that vaccines aren't causing autism, but they just get to keep saying,
I defy the data. That seems like a really stupid argument you're making there.
He says, specifically, you can't defy the data on multiple experiments.
At that point, you either have to relinquish the theory or dismiss the data
by pointing to a design flaw or a larger body of experiments that fail to replicate it.
He. Yeah, he specifically is making this a you can defy the data one time.
It makes a lot of sense, because like just file drawer effects by themselves
are enough to explain a way like, oh, we did one experiment
that came up with a really weird finding. It's like, oh, yeah.
He's a what is it?
Confidence interval of point oh five.
It's going to happen all the time.
Yeah, there's lots of noise and data.
Yeah. All that means is, OK, run a real experiment on that topic now
that you have found that finding. So, yeah.
Well, he does try to make replication higher status by this.
I think it seems almost like this seemed like a hack
to try to get more things replicated because if someone prominent
defied the data publicly, then, you know, that would be news.
And then the replicators could get their names in the journals
as the people who, you know, either confirmed or or.
Not deny, but. Confirmed or defied.
Yeah, the defile confirmed defied the defile.
And then God damn it. Denied. Denial. Thank you.
And then the person who denied the data either gets more status
for, you know, sticking their neck out and defying this data
or gets to make look like an idiot when the replication went through.
And they're like, oh, OK, my bad, I guess.
Or they get they get props for defying or, you know, for denying the data
when it looks deniable. Right.
That's how it should be, right? Or it's just neutral.
It would be good to have a hack that makes replication higher status somehow.
Yeah. Yeah. Interestingly, in that sentence about you either have to
relinquish the theory or dismiss the data.
Um, neither of those are or you have to update your your model and say
that you were wrong and the data is actually right.
And it's a prize that wasn't wasn't one of the either's.
He does say defying the data admits that the data is not compatible with your theory.
Sticks your neck out, so your head can be easily chopped off.
Yeah. People are like, turns out your theory was wrong, Mr. Feynman.
Reminds me of Einstein, like some experimental result,
disagreed with his prediction for like some eclipse measurement.
He was like, they did their experiment wrong.
Nice. Yeah.
And what turned it was funny, because it turned out that they did
their experiment wrong, but his prediction was also slightly wrong.
But then he had a chance to correct his theory by the time
the next eclipse rolled around or the next experiment.
So but he came out looking good, obviously, because he's Einstein.
But to your point, what you were saying, yeah, I do think people can
and often do take this to a way big extreme.
But they're like, I just defy any data that doesn't fit what I believe.
But by that point, you're not playing in the spirit of the rules
and you're going to be able to just rationalizing anyways.
Yeah. Yeah.
Which is an unfortunate accident of English language history
that rationalization and rationality are so closely tied together.
Yeah.
Want to wrap this up?
You think of hatred and call it a night?
Oh, for next time, our our last wrong post will be absence of evidence
is evidence of absence and conservation of expected evidence.
There was a whole book I read on that first post
that I think before I read less wrong and I'd like to know if.
Oh, I had his name when I started that sentence and I forgot it.
But the book was called God, the failed hypothesis.
And he says that the lack of elephant footprints and
droppings in Yellowstone National Park are are evidence that there aren't
elephants that live there.
Right. Is the is the example that he gives at the beginning.
By Victor Stenger.
Thank you. Yes.
Who used to teach, I think in Boulder.
I think he subsequently has died.
I missed a talk that he went to
and I really should have gone.
But yeah, Victor Stenger wrote that book.
It's nice to have somebody at the computer handy.
Yes. Before we think our current patron,
I want to say that the previous patron that we thanked,
which was a while ago now because we didn't do one on our live episode.
We thanked thunk.
We thanked thunk and talk for a bit about who this thunk person might be.
Turns out, thunk is a channel
on YouTube creating educational videos that have their own Patreon.
And it turns out that if someone on Patreon
patronizes us, I guess, donates to us, I don't know what the term is.
We can just click on their name and go to their thing.
So yeah. Yeah.
So I found thunk after we thanked them and I love saying that.
And yeah, I found their videos and it's really cool.
So everyone check out thunk's YouTube channel, which I don't know
how to like hashtag YouTube channel.
But I'm sure if you search thunk, education or something or whatever.
We can post a link in the show.
That's probably the easiest way to do it.
YouTube's a weird spaghetti mess.
So it seems like this would be like up our alley, too.
I haven't seen any thunk videos yet,
but like episode 179, the most recent one is called Rationality Without Justification.
So yeah, seems like.
Oh, and there's 179 episodes.
Yeah. How long are they?
I'm assuming since it's YouTube, it's like 15 minutes or less.
That's a weird assumption to make.
10 minutes for episode 179.
Perfect. All right.
Sounds great.
And that's about the attention span of people watching YouTube.
Yeah. Every now and then there's an 18 minute video on YouTube
and I'm like, that's just too long for me.
Well, that's why you watch it to speed it.
Yeah, I make some exceptions.
Like ContraPoints is always awesome,
but usually anything longer than 15 minutes.
I'm like, this is not the time I have allocated for YouTube.
Anything that's like two hours on YouTube.
I like I've got that ContraPoints that's been open for like a month on my computer
or one of the videos has the big one that made the rounds recently has been open
since it came out, but I have to have my browser open the entire time.
It's like, now put this on a podcast app
and I can pause and play and leave the app.
That'd be great. Thanks.
Yeah. You can do that because you pay for good YouTube.
Yes. Yeah. It's worth it.
Yeah. It's true.
Yeah. I usually think that like, you know,
things that are really long, like debates that I watch sometimes,
it's stuff that I'll do at work while I'm doing bank reconciliation or whatever.
I can take it. Yeah. All right.
But the patron that we are actually thinking this week is whose turn is it?
I think it's been a while since I've done it.
OK, go for it. Jonathan Mast.
Thank you so much for your support.
You're super awesome.
And this podcast wouldn't happen without you.
If it sounds rushed, that's because it is because we've overstayed our
not our welcome, our window at Inayash's house where we where we record.
So Jonathan Mast, thank you very much.
You have helped make this decade a good one for this podcast anyway.
So partly the rationally rationality community.
And, you know, we're going strong to the next one.
That's right. You're the first patron thanked of 2020.
Oh, that's true. Awesome.
You know what I'm going to do?
I have the cyberpunk 2020 rulebook still.
I got to scan that and then post it on my Facebook, telling people,
this is the future I was promised.
It is it is not the future I have.
I mean, I'm pretty happy with my future work and like where a VR headset
with a brain stimulator in my underwear in my living room.
I mean, I am glad that I'm not living in a burnt out urban health scape
while the mega rich do whatever they want.
Hey, give it any election cycle.
Right. You know, hold your breath.
On the other hand, I really would have liked to be able to hack
into the matrix with my brain and, you know, have guns wired to my nervous system.
Well, it's only January.
Call you on us.
Maybe the neural lace will be coming out in, you know, second quarter of the year.
We don't know. Nice. All right.
We should wrap it up. OK.
Thank you, everybody. This was great.
We'll see you all in two weeks.
All right, everybody. Bye.
Big shout out again.
Thanks for Matt for coming. This is great.
Of course, my pleasure.
Willing to cast stuff on the show notes as well.
Yes, thanks.
