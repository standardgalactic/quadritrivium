Like you can always, you can always find ways to nitpick, but like very often kind of the spirit of what he's trying to say is,
accurate even if he fails to anticipate some particular change in paradigm.
I've always been impressed.
And the thing, the point of me bringing this up is like, this was a fairly recent conference.
And he's basically saying all of his kind of trend line predictions are still on track more or less.
So.
And don't get me wrong.
I like, I like Kurzweil too.
Yeah.
I think like, like I said, for me, it was the specifically around the use of the word singularity.
Yeah.
I've heard people who have no idea what any technical definition of that would even mean use the word.
And I think that's part of why.
So it's like it just got distilled too much.
It's not necessarily, it's not a, it's not like this guy's out there saying a bunch of nonsense.
And that's why, that's why it happened.
I just, I meant that word specifically.
Yeah.
It became kind of a marketing word and I get Mary wanting to move away from that.
The only thing that I can, and I, let's see, I'm trying to think of what I've read from Kurzweil.
I know I watched one or two of his documentaries.
But like Michiu Kaku makes, like by 2030 will, he'll make like highly specific predictions that have like five components in them.
And I don't know, maybe he's really confident.
And I guess we'll see in 10 years.
I'll have to double check exactly what I'm thinking of, but there was one about like in 2030 we'll have like basically super cheap TVs where it'll be like wallpaper and it'll be able to simulate environments.
And I forget all of the ands in the statement, but it was, it was several.
Yeah.
And he could just say like, maybe we'll have super cheap, you know, very thin screens.
Yeah.
Very thin screens that are, that are so inexpensive that you can plaster your walls with them, which would be kind of cool.
It'd be like the, what was the imaginarium thing that they had in community?
Good little closet.
Oh, okay.
Yeah.
I remember what you're talking about.
Troy and Abed had this like closet with just like yellow tape grid squares painted on it.
And there's going there and like imagine, and it'll be like that, except you get the, or like the holodeck.
Is that what it was called in Star Trek?
Yes.
Yeah, perfect.
All I remember is the version of that that they had in the X-Men to train the X-Men.
Oh yeah.
The danger room.
Yeah.
But that at least simulated like actual things.
It wasn't just vision.
Although I'm assuming the holodeck did that too.
Does it have force fields and they could materialize things?
Oh, smart.
Yeah.
Okay.
That makes sense.
Yeah.
We get force fields and TV walls and we're, we're all the way to a holodeck.
Perfect.
Yeah.
The porn industry is going to be wild with this stuff.
The porn industry is always pushing the technological envelope.
I mean, that's, that's canon in deep space nine.
The only purpose of the, of the holo suites is for, you know, prostitution.
So.
That makes sense.
Yeah.
They were seeing the future.
Not, not as if we want it to be, but as it will be.
It wasn't the only purpose, but it wasn't major.
I mean, if you think about the internet.
Yeah.
How much of the internet is like drug trafficking and porn?
I do want to point out.
Like I, I just got to thinking about this the last two days, the, you know, 10 year retrospective
on the rationality movement.
I think it's really fucking impressive.
Oh yeah.
Cause it was, I mean, it was literally started out just as like one guy's blog and then it
turns sort of into like a shared blog.
And at this point we've got multiple community houses across the nation.
At this, uh, the CIFAR workshop thing that they do.
And more importantly, there's like a lot of, um, thought influence that, that has come
out of this.
Like I think the major acceptance of AI as a, uh, existential threat to humanity by
technological and thought leaders is in strong part because of the original righteous community
influence.
Yeah.
The concern about X risks in general.
Yeah.
Like Nick Bostrom came directly out of less wrong and he's, um, but Oxford future of
humanity Institute head.
And yeah, I think that's very much on the shoulders of, of the rationalist community.
There's this whole EA effect vulture as a movement, which came out of that.
There's actually one state legislature who was explicitly rationalist, uh, legislator
in New Hampshire.
I think it is.
I mean, there's, it's impressive.
The strides that have happened in the past 10 years and Scott Alexander major, you know,
influencer, he's, uh, over a hundred thousand views on some of his blog posts and is quoted
by people in, was it the New York times?
Uh, you know, I hear him quoted all the time by like Ezra Klein and, and, um, people in
kind of the more San Francisco scene.
Um, I know there was, there was a couple major national publications that have responded
to him.
I haven't heard of that, but, but I believe you.
I mean, he's, he definitely has a lot of pull with the kind of the intelligentsia of the
country, which is great cause he's a great representative.
Right.
I mean, I mean, I think the movement's done great.
I think it's no, it's no small part due to his continuing work because Yidkowski did
a great thing with the sequences, but he's been disengaged for years now.
And that's fine.
He's doing his own thing.
Um, I do kind of miss his voice, honestly.
Yeah.
It seemed like he always wanted though to move into the domain of working on AI research.
And that was kind of what he was trying to rally everybody behind.
Yeah.
And he was a little bit disappointed when like all the readers of methods of rationality
didn't go into AI fields, but I honestly like think that the rationality community has,
well, I mean, uh, any ash already brought up effective altruism, but yeah, like the focus
on other X risks, like pandemics, uh, the fact that there's like meal squares, like,
uh, and other, you know, like weird Silicon Valley startups, uh, some of which are like
coming out of that kind of community.
And I really like how much progress people have made towards like rationalist psychology
and self-help.
Uh, I used to, I was kind of interested in that stuff, like in my like early teens and
then got really quickly turned off by looking at how much of it was woo or none of it had
been studied at all.
Just there's much better ability to find recommendations on how to combat a crazier.
But yeah, stuff like B-Minder and Compolis and so forth came out of this community.
And I, it's interesting because like, I, I like put in the little comment section of
my first donation to Mary, like this is, I got here from methods of rationality.
Um, and somebody who worked there wrote back, like commented on, because this is when I
had a blog for like a year.
Um, and they either commented on that or messaged on there and said, Hey, you know, because
it was only like 80 bucks or something.
Cause I was delivering pizza as part time, but they were doing like a fundraiser, like
a dollar for whatever, two for one or something for the end of the month.
Um, so it's like, that's, that's when really you should, that's always been my thing too.
Side note.
If I ever had like a, you know, one of the interview questions I got from my job was
like, if you had a hundred million dollars, what would you do?
And one of the obvious things would people say, I'd give a bunch of charity and it's
like, yes, but what I would do is I'd like double my impact by saying, I would have,
I would set it up in advance and say, I will do a two to one match or one to one match
for the whole summer.
And like then that way it'll encourage more people to give and I get to give money.
Um, the, but I remember when we had, we had Yusuke on the podcast, I wonder if he feels
any different now, because I knew at the time that he was in dialogue with Sam Harris
about like maybe like Harris was thinking about writing a book or something on the subject.
Um, which I don't think he's ever going to get around to doing cause I don't think he's
anything like novel to say on the subject.
Um, which isn't bad.
It's just, you know, he's, this isn't his, his thing.
Um, it's an interest, but not like a whatever you said I'm saying.
It's not like meditation.
Um, but I, I, I, because I pushed back on him cause he said like he, Yusuke said something
along the lines of, he didn't feel hopeful even though like this is getting more mainstream
attention.
And maybe that's cause you know, most articles have a terminator at the top of the pictures
or at the top of the article or something.
But when Neil DeGrasse Tyson was on Harris's podcast, Harris was writing his AI bandwagon,
you know, really hard that year or something and brought that up to him.
And Tyson's thing was like, oh, I just shoot it with a shotgun.
If I felt like it was trying to get out of the box.
And Harris failed to explain to a wide,
I would just switch the computer off.
Yeah.
And Harris failed to convince him that this was actually a hard, like not like,
like it wasn't that easy.
Yeah.
But he's come around recently.
Well, that was because when he had Yusuke on, um,
Harris brought up to Yusuke Neil DeGrasse Tyson's, uh, position and Yusuke's rejoinder
was simple as hell.
It was just like, I feel like he's not giving himself, he's not giving the intelligence in
the box the credit that he would give himself if he was locked in a box.
And there was a scientist pointing a gun at him.
And so imagine if this thing was a hundred times smarter than you,
it wouldn't be a matter of just walking over and unplugging it.
And then shortly after apparently Tyson listens to Harris's podcast and says,
that convinced me, I changed my mind.
So like we've got people who I don't know,
maybe this will come up on Cosmos season two,
which I don't even know if that's actually happened or happening.
It hasn't happened yet.
So maybe they'll do an AI episode and he'll mention that this is actually a thing.
And it'll air at seven o'clock on Fox on Sunday, right?
Like that's pretty cool.
You want to know something what really surprised me.
I mean, first of all, the rationalist community has always been five years ahead of everyone else
as far as I can tell.
Like I always feel kind of like an intellectual hipster when people tell me about this new thing.
I'm like, yes, I knew about that five years ago.
Yeah, pass that actually.
Yeah, exactly.
But on 60 minutes recently, there was a thing about reversing aging basically,
uh, scientist researching it.
And my parents like sat me down and showed me this because they're really, you know, into it.
And they are of the mainstream.
They watch like 60 minutes and shows like that, right?
And I was like, Oh God, here's going to be another one of those, you know, it's unnatural and all life must end or something.
