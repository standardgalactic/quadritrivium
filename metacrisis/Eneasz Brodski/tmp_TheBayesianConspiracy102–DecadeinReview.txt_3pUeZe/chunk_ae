Like, what would the text say after this?
Okay.
And then a walking dolphin comes in the door and says, I know your mother.
Yeah.
GPT2 is like, all right.
And then next.
Yeah.
Then your mother walks in and just like Bob the dolphin.
Yeah.
It's really, it's really creepy and incredible and awesome.
Like, what were we doing?
We had like a velociraptor come in and then there was a lightsaber and like, and of course, like it knows that if you hit something with a lightsaber, it burns them like it.
Oh yeah.
It was really neat because at one point, I think we met a skeleton friend of the velociraptor and that's when they coined the term the velociraptor guard.
They were like, it made up a word.
So the best thing about this was I like went outside to talk to somebody at our last wrong meetup and I came inside and people were like, and now they're like sexually caressing the velociraptor.
And I was like, what are you guys playing over there?
Yeah, I was, I think we're playing out on my phone and I'd put in like, all right, attack the velociraptor, the lightsaber.
And then it's like, all right, you hit it.
And I was like, now eat its heart.
And then it's like, or like it's something about the heart coming out of it when you killed it.
And I was like, all right, now eat the heart.
And then you put in after I looked like, put the heart, like save the velociraptor.
And it says you put the heart back in even after eating a piece of it.
Like it makes mistakes, right?
And this is the same as GPT2 always was where like it'll make these mistakes.
But the stuff that it does know, like I wrote a Reddit comment about this.
I was like, I don't think it's a language model.
I think it's a concept model.
It just doesn't quite get the concepts right.
I think it's, I don't think it's sentient.
I don't think it's super intelligent, but I think people aren't giving it enough credit is what I think.
I think it's pretty impressive.
I want to read how it primes the, because you can pick the setting or you can do a custom one.
And I did the, what, apocalyptic wasteland or something.
And it used words like super mutant, which I don't know if that's from, if that's just from fallout,
but that's where I associate it with.
And it described it as these big mean talking things and like, okay, so super mutants are the ones from fallout.
I wonder, so I want to look up on the website where, where like,
You gotta see what it's training material is.
But you talked about how you put it, you were basically writing like a worm, a wormverse thing.
And he said, go into your breaker state.
And it's like, and like, it doesn't know what breaker state means.
Well, I think what it's, I think it has read just a crap ton of the internet.
So I think it's read a lot of worm fan fiction, if not worm itself.
That's so cool.
And so like, yeah, you see, like, you don't tell it what a breaker is.
You just say, go into your breaker state and it's like your body disappears into a haze of electrical energy.
And it's like, yeah, exactly.
Exactly. Yeah.
Do you think the number of words of worm itself is greater than the number of words in like,
worm fan fiction or?
I feel like at this point there's more worm fan fiction just because there's,
There's a lot of fan fiction.
Yeah.
Just in general.
Many, much of it apparently read my people who haven't read worm.
Really?
Yes.
Oh yeah, that's a thing.
Yeah, like, I found that really funny for a while that something will get popular.
People will draw lots of fan.
People will see the fan art and kind of like, or hear about it from their friends and then just be like,
Oh, I know what that is.
And then start drawing more of it or writing stuff based off of it without having read it.
Yeah.
Or only reading parts of it.
I tried to do one because you mentioned that you had set up where you,
Your prompt was like, I'm an AI in a machine trying to convince my programmer to let me out.
I tried that for 10 minutes and it just, it didn't get what I was trying to do.
But that, you were, you tell me a little about what you did there because I think we didn't get the long version at the meetup.
Well, yeah, I was just trying to play around with this concept of getting it to do stuff that had nothing to do with the multi-user dungeon type experience.
I was just like, in one case, I was like, you are interviewer interviewing Matt Freeman.
And then I like wrote some details about who Matt Freeman was.
And then I basically was the interviewer and then the AI was Matt Freeman.
Just to be trippy and weird.
And I did one where I was like, you were an AI researcher talking to your AI that you built.
And you built it to be super intelligent and to solve any problem.
You just need to ask it a question and it'll tell you the solution.
And then I started asking you questions.
And what was funny is it would like, it would like cleverly evade answering the question.
Like it would be like, well, we need to define better what you mean by that first.
I'd be like, no, fuck you.
You're going to tell me.
And then there was one where I was like talking to my physicist colleague who had admitted cold fusion.
So I basically got GPT2 to tell me how to make cold fusion.
Apparently the key is a platinum catalyst with a gold plating around it.
The second, if someone ever gets an experimental result, they can go out and check and it's right.
I'm hoping that that explodes on the internet and everyone hears about it.
I mean, presumably you could feed it all of the scientific literature on everything.
It could synthesize some new information.
I think we're going in that direction.
In the way that it makes kind of, it gets a lot of things weirdly right.
And then it makes a lot of kind of obvious mistakes.
I think it's going to get better at that kind of thing.
It's going to get to the point where it can just be like, oh, I know everything and I can cross correlate across these different domains.
And it'll be able to find out things that you can sort of use it as Google now.
You can sort of be like, think of a topic you don't know anything about and then sort of ask it about that.
It'll know something about it, right?
Because it's read probably 100,000 words on that topic.
That's amazing already, right?
And it's not even made for that.
But you can't entirely trust it to get it right.
True, true.
But we're going to get there though.
I feel confident anyway.
You have a little mini oracle.
Yeah, basically.
Well, do we want to talk about what has happened in the rationalist world over the past 10 years?
I can start really quick with a very simple one, which is I mentioned sometime.
Oh, that was my long tangent on memories and stuff because I remember specifically assuming this memory is accurate,
even what stoplight I was at when I was listening to rationally speaking.
This part of the memory must be true because that's what I heard of.
At the end of the podcast, they would do the rationally speaking pick where they pick whatever book, video game,
or TV show, or whatever tickled the rational fancy between this and the last episode.
And Julia Galeff plugged Harry Potter and Methods of Rationality.
And the only reason I remember, the only reason I found it was because it was at a stoplight
and I was able to take a note and say, look at this later.
Was this 10 years ago?
No, this would have been, it's hard to say, something like, oh wait, almost 10.
Yeah, just about.
Because I would have been reading this.
I could look up whatever year I graduated from Front Range.
The community college I went to and it would have been around that year.
Within a year, it would have been before I graduated there.
Yeah, for sure.
So yeah, about a decade ago.
Perfect.
All right, this does line up.
Yeah.
I was going to guess six or seven, but when you think about it, yeah.
Okay.
So closer to 10.
And then yeah, we, although the only other thing that makes me feel like any time has passed with regard to any of this is that
I think Methods of Rationality wrapped up in 2015, right?
I'm looking up a publication date, 2010 to 2015.
Yeah.
So in March, 2015 will have been, well, we're hitting up, we're coming up on the five year anniversary of the Denver area, less wrong.
Yeah.
Because we had a handful of meetups that was like just you and me.
And then one with me and just one other person one time.
And then the big kickoff where people started coming was for the rap party for MLW or for, yeah, Methods of Rationality.
And because you're a local celebrity in that area, we had like 35 people show up.
And probably 10 or 15 of them, 10 or 15 of them still come.
So, and we met some cool people.
Yeah.
That's, I think, how we met the folks in Colorado Springs.
Yep.
Yeah.
So it's awesome.
Yeah.
And that was five years ago.
So, geez.
Yeah.
We've, we've moved from old less wrong and then less wrong died and then less wrong was reborn as less wrong 2.0.
Yeah.
And in between there was the diaspora.
There's the diaspora.
Everybody had their own blogs and.
Yeah.
So 2010 less wrong was still going pretty strong.
I remember going back to see just like what was happening.
And Eleazar was still posting the sequences at that point.
He hadn't finished them.
And there was a lot of posts by, by Scott Alexander, by Guern, by all the early movement people in there.
The people that ended up becoming the diaspora.
Yeah, exactly.
And then, yeah, after a while, Eleazar stopped posting there started getting more serious with a.
Miri, which at the time I think was still SIAI.
The Singularity Institute.
Yeah.
Yeah.
I think they changed their name in 2000, mid 2010s.
Miri is better because.
It's much easier to say.
C.I.
Yeah.
It's weird.
Yeah.
Well, and Singularity in what 2001 when he started the Institute wasn't as.
Something different.
Yeah.
It wasn't as pop sciencey of a term.
Right.
I think I admire a lot of the stuff that Kurt Ray Kurzweil has done, but I think he've ruined the word.
I think that's partly, I don't know how much of the, how the effort for the rebranding goes on his shoulders,
but probably some of it.
Speaking of Kurzweil and timelines, I recommend, I mean, I don't know.
I enjoy this kind of thing.
There's the, the Asilomar AI conference where Yudkowski was there, but he didn't talk.
You can see the back of his head when he asks a question at one point on the YouTube video,
which is a very Yudkowski question.
I don't remember exactly what it was, but I remember being very Yudkowski.
But anyway, Kurzweil does this thing where he's like, look, here's all the, here's all the trend lines.
Here's how I'm completely still right about everything and all everything still on track.
Like I've always said, and like, I've always, I've always liked Kurzweil because he dares to make these predictions.
Like people get on his case and I'm just like, okay, you make predictions then, you know?
And, and, and like he tends to be more accurate than not.
Right.
Like, I don't know.
