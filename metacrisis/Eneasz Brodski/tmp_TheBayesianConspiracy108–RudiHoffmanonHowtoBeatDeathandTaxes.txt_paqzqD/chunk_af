and said, if humanity on average is to foot taller in two centuries, we'll blow up your planet,
that wouldn't, that would be not, I mean, it would be an inconvenience. It would be hard,
but it wouldn't be difficult. It wouldn't be really impossible. I'm not gonna say that it would be
super easy for alien inconvenience. Yeah, right. So it might not be, it would be definitely an
inconvenience, but it's not like we would have no idea how to address this challenge, right?
It would be totally doable. I'm not hung up on the eugenics thing. Also, it's a very loaded word.
It was just, the idea that I think of is it always seems like Twitter people have,
you know, they try to make a nuanced point. That's what, I was on Twitter for like one summer
and I got to jargon with somebody about like female and male genital mutilation
and I realized that we're just talking past each other and that it was impossible to have a
conversation. I'm like, this is the worst platform ever for talking to people. Why am I here? And
then like shit on there for like Twitter. Yeah, movie reviews, jokes, I think is the absolute
platform for it. You can get great one-liners and zingers on Twitter. I think that's a great
place for it, but as for the rest of it, man. Twitter was a fun social experiment that we did
with the world. I'm not sure fun is the term I would use. Yeah, no, I don't think so either. I
worked as a social media manager for a bit and that was just like the worst two years of my life.
Yeah. I mean, that's an exaggeration that I have had worse things happen than having to be on
Twitter, but it was up there. Yeah. Just like the inanity, I just like.
Yeah, the, so to go back to the post, it says that in the ancestral environment,
there, anyone who said something with no obvious support was either a liar or an
idiot because there was no knowledge that everyone else in the band didn't already have.
Or couldn't easily get. Yeah, yeah. And conversely, if you say something that you think is blatantly
obvious and the other person doesn't see it, then that other person is an idiot or they're
being deliberately obstinate just to annoy you. And, and on top of all that, if someone says
something with no obvious support and expects you to believe it and gets all indignant when you don't,
then they must be totally crazy. So this, the issue of not having this common ground between
each other is, you know, a recipe for horribleness because listeners still assume that everything
should be visible with one step, maybe two. So they take two steps back to explain maybe three on
the outside and not realizing just how much distance there is in from universal knowledge to new
knowledge. So this is so many professors, or just probably teachers in general, but I remember
in college there would be like the sign of a good professor or somebody who understands
inferential distance. I think a lot of teachers like good teachers who care about the teaching
process are really skilled at this too. Like that that's probably the field where you need to know
it the most any, any field maybe where you're the main thing you're trying to do is communicate
something to an audience that's unfamiliar with it. But I remember just having really bad professors
who are, they start their PowerPoint, you're like, okay, you're taking notes on the first slide, like
alright, I'm following, wait, what? The next slide is just completely like, and then there's this vector
thing. And I remember I started out majoring in environmental science, I had this professor who
did that sort of thing, I have a page of notes, like before I dropped that major and switched
for like a bunch of reasons. But like, there was a page of notes that was just like slowly
devolved into a bunch of doodles. And I remember Vector Kitty was flying over the environment.
And just like, yeah, I don't have no idea what's even going on anymore.
Something something. I think I think it was the worst teachers were the ones that didn't
remember what it was like to not know the subject or teaching. Yeah. And so they start talking. And
to them, it's they've been doing over 30 years and like, yeah, this is old hat, I get this,
you guys will get it too, because it's really easy. But I don't remember 30 years ago when
they're open the first textbook, right? Dude, you it's surprising how quickly that sets in.
So taking just a stupid video game as an example. In World of Warcraft, you have to learn boss
fights, there's all these little mechanics, you got to do things got to watch out for it takes
some practice, right? And before you have it down, it's freaking hard as hell, you're learning all
these new patterns and tricks and things to watch out for. But once you have it down, it is super
easy. It is barely an inconvenience, as they say. So once people have beaten bosses, moved on to
other bosses, all the time, you see people saying, how was anybody stuck on this earlier boss,
they're super easy, just kind of blow through it. And like, literally, maybe two weeks ago,
they were in the position of, Oh, my God, this is impossible. How will we ever do this? Because
it's, you know, everything is impossible until you know how to do it. And then it's just trivially
easy. Yeah. And it's amazing how quickly you can flip from one to the other.
That's really hard to, it's hard to get in that mindset when you're a new learner as well.
That's something that I've kind of been reading about and struggling with, like when you're an
adult and you're trying to learn a new skill, it's really hard to be in the position of I'm an
idiot who knows nothing about this, like, I don't know, programming or, or I'm trying to teach art
to people. And I think the sequence actually gets into this too. But you the, the teacher also can
get really frustrated with people who don't understand what seemed like basic concepts to
you. But like, there are things that seem like basic concepts to me, because I learned them
when I was a kid, like I've been drawing forever. Yeah, I remember trying to teach like,
some older folks at the library, like, okay, like, here's how you draw a face. And
not under, like, that's another thing that's really funny.
Describing the anatomy of a face was like, okay, you have to like, you do the oval, you divide
the oval in half, that's where the eyes go, your eyes are halfway down your head. And like,
the seams, I'm trying to explain like the cognitive things going on. I'm like, this seems
unintuitive, because most people look at faces, and they don't look at the rest of the head.
So you think the upper third of the face has the eyes, but actually the middle of the head,
you have to draw the whole head that this part's covered with hair, no one looks at that. But
like, even as I'm describing all this stuff, and I'm trying to like go step by step as slow as I
possibly can, I'm walking around the room and people are still drawing the eyes on the top of
the forehead. And like, no, bad. Look at me, where are my eyes? Are you going to put them up here?
How weird would that look? Right? Yeah, just just bring it down. Yeah, it's, I think,
I imagine, I mean, part of it, that sounds, to me, that just sounds like a hard subject. I can't,
I, since I can't draw, maybe that, maybe I'd be a good art student, because I know I suck at it,
but I wouldn't be confident in my ability to do it right. Whereas other people, the part where it
could be maddening, he uses the example a lot of like scientists, trying to explain things to
not scientists, and how like, simplest explanation is a magic word of power among scientists,
because they've been inculcated with the, the legendary history of science from Newton to Einstein.
And it's like, so you hear a biologist say, Oh, it's the simplest explanation, but a physicist
who doesn't know biology can be like, Oh, okay, I will add a lot of credence to that,
because we are also scientists. They know how important that is. Yeah. And so that's,
like the annoying part is when you give like a long explanation of something to somebody who's not
in the field that you're, you're profounding from, you know, evolution to a layperson might be a
good example. Like they, you can explain everything, and they're like, Okay, yeah, I think I'm following
you. I think you're an idiot, I think you're wrong. Okay, well, then you weren't listening,
and he didn't follow because this couldn't be simpler. And you're the idiot. So that's not
how I feel. I'm saying that that that explanation to feel that way makes perfect sense. Yeah,
it's like very much, I think you get in this headspace easily of this person's an idiot, and
they're not listening to me. And the other person is thinking like, this person thinks I'm an idiot,
and that I don't know like basic stuff. Because like the thing about drawing is that people think
they know how to draw a face. And like, you know, even kids with crayons are usually drawing faces.
And it's like, I know how to do like eyes, nose, and mouth, you know, like, come on, but like,
you don't, that's, it's so hard to get in the headspace, which is like, actually, we don't know
this stuff. Yeah, you have to be really humble. Yeah, in the post that that to a lay audience,
it's the simplest explanation may be interesting, but that's hardly a knockdown argument. But from
the biologist's perspectives, they can see how, you know, it might sound a little unintuitive, but
when they reject evolution, even after they've had it explained to them that it's the simplest
explanation, they're just idiots, and there's no point talking to them. And it's clear to you that
this isn't what Eliezer means, you're either he's saying that that's the feeling that one gets,
because they're expecting short differential distances. When you correct for that, then you,
then you no longer view the, the unable to follow you along layperson as an idiot, you're like,
okay, I clearly didn't actually explain myself. That's why Richard Dawkins book explaining evolution
is, I don't know, 350 pages long and not five. And if to somebody who has the, and even that it
could be twice as long, if you wanted to explain, he probably does a bit of spending years since
I've read it. But like, if you wanted to explain little things like, here's why we value
short explanations, here's why we value replication, all the, the foundations of science,
if you wanted to dig into all that, then the book could be much longer. But I think he,
he probably does a bit, this is meant to be a, you know, top to bottom book. But that's my
point is like, you can explain evolution in three minutes, if not less, depending on who you're
talking to. But if you're starting from scratch, from somebody who has no idea what you're talking
about, then sometimes you need 300 pages, right? Yeah, I have a, go ahead.
Okay, but the joys of Skype. Yeah. Okay, well, then I guess I was going to say that he also says
that if people see you visibly attaching greater weight to an argument that is justified in the
eyes of the audience at that time, then they also think you're crazy, because, you know,
you shouldn't put that amount of weight on that evidence. So you have to go back and
first explain why the evidence that you're about to explain is, as weighty and important as you're
about to, you know, lay out with, and that takes explanation in itself. And so he's saying there's,
there's a very long chain, but you can't, you can't drop any hints that maybe you're working
a dozen inferential steps away from the audience, or that you have special knowledge they don't,
because then they think that you're condescending and arrogant.
Yeah, it's like, you know, trying to explain to somebody why astrology isn't a thing. And if you,
if somehow, you know, she believes in astrology, but we shared everything else in common, I could
just be like, you realize every physicist on earth thinks that it's bullshit, or knows that, you
know, had, would bet their lives on that being bullshit, you would immediately change your mind.
It like, you're like, oh, I, okay, if all the physicists who actually know everything,
there's no about stars, or everything that humanity can know yet so far about stars
thinks that it doesn't, you know, that the constellation stone impacts my life, then I
guess I'm wrong. I think to actually believe in astrology, I would first have to not know enough
of physics to not care what this is saying. I don't know, people are really good at compression
analyzing. I know, well, once you know that stars are giant gas balls and that they're so
freaking far away, what else is there to know? People are very good at compartmentalizing. I
have religious co-workers who, you know, spend their days like bioengineering cells.
Oh, God, don't these bioengineered cells look intelligent? Is it designed? It's like,
yes, because we made them here in the lab. That's not the same and you know it.
I think what this all comes down to is the punchline at the bottom he says, and if you
think you can explain the concept of systematically underestimated inferential differences briefly
in just a few words, I've got some sad news for you, which first of all is a reference to the fact
that this entire post is pretty long, but also to the fact that it links to three other posts
that he's made beforehand. And while he doesn't give it away in this, I think at this point,
it should probably be clear to most people that the purpose of the sequences and their, you know,
several Bibles length worth of word count is to bridge an inferential gap that he saw
at the very beginning when he was like, here's the mass audience of everybody in 2006,
and here is this conclusion I have reached. And I have to convince people of this, but
oh my God, it's going to take a while. And this is a freaking impressive project that one person
said about to bridge this massive inferential gap. Like just the fact that he thought he could do it
is kind of amazing to me. And then the fact that he actually did it is just crazy.
I'm very impressed by people who try to do hard things. I get pretty frustrated when people
shit, I don't know, generally I dislike haters, like in any field, but especially when people,
you see themselves as critics or badmouthing, like some artwork or project that someone has done,
or like, okay, what have you made? It's generally. Yeah.
All right, I guess that is the sequences. I do want to point out that somehow we accidentally
skipped over several dozen sequence posts to get to these. I'm not sure how that happened,
maybe an accidental pagedown or something. So we're going to be backtracking quite a bit.
And next episode, we will talk about the posts scientific evidence, legal evidence, rational
evidence, and is molecular technology, quote, scientific. So we have skipped a few inferential
steps to get here, but hopefully we can backfill them without too much trouble.
It seems like these were in the order because we just did hindsight bias and stuff.
Yes, we did. And if you go to the list of all the less wrong posts in order, the illusion of
transparency and expecting short inferential differences are a few dozen down from hindsight
bias. Huh. Yeah, I don't know how that happened either because we've had these listed as the
next ones for a while. But oh, well, we'll figure it out. It was good to talk about them and, you
know, it's set up for later and then we won't have to read them later, right? That's right.
Or we can again, we'll just do it really fast. Okay. All right. Well, this is fun. I know that
it's probably some patience on the listener's part listening to poor sound quality and the constant
overlap of our voices whenever any one of us want to start talking next because of the considerable
lag time on Skype. This will be the show for a while. We'll try and mitigate that as much as
possible. But anyway, thanks for being with us. Hope everyone's having a good evening here. So
hope everyone's having a good time wherever they are and whenever they are. I don't have
anything else to add. What about you guys? I do have one bit of listener feedback that I don't
want to put off any longer because it's directly relevant to the book that we were talking about
a couple episodes back, the Talking to Strangers one. So I figured we should probably hit that
right now. Yeah. And we can put off the rest to later. So this one is from Why We Cur on the Discord
says, it seems to me like the book Talking to Strangers is trying to say that strangers aren't
possible to read and that even trained professionals get it wrong. But that just seems wrong to me,
given my experience and the people I've seen. It just seems ridiculous to me to suggest that
people are as opaque as the author suggests. I'm pretty sure the book is trying to say that
it's mostly futile to even try to read people. When they talked about the book on the podcast,
they seem to mostly agree with its findings or at least not be surprised by them. To me,
this seems like quite strange claims. I wanted to read that because first of all, noticing confusion
is a huge foundational rational skill and Why We Cur has noticed some confusion and is voicing it.
And also, I wanted to know from Jess, since you're the one who read the book,
was that a correct summary of the book or did we overhype how opaque it says people are?
I think the point of the book is just that we are much worse at reading strangers than we
self-evaluate. It's not to say that intuition doesn't exist, and that some people can't be
good at this. But every chapter of the book cites multiple studies where they have shown
pretty definitive suggestions that...
Oh, I wish I had prepared it better yourself.
I guess the question would be, do you think this book is trying to
ratchet down how confident people are? Or do you think that it is saying,
quote, it's mostly futile to even try to read people?
I think I'm a bit surprised by how negatively a lot of people are skewing
the message of the book to be. I think that this was meant to be sort of cautionary in particular
because it focused on the case of Sandra Bland and began and ended with police violence. It talks
about court cases. Gladwell is trying to point out a legitimate problem with a lot of our systems,
which are that they are systems that were designed with illusion of transparency.
