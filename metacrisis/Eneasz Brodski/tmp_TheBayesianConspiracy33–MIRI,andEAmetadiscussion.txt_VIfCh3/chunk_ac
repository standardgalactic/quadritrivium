a more appropriate word than problematic. I mean, there's a lot of people I think that if there's
money to be made somewhere, but especially if it's something like building the first self-driving car,
if it's Google or Uber, someone's going to cash in big, right? So that's obviously not
a general intelligence, but somebody who is trying to win this race probably won't be likely to
help their competitors keep up, right? Or is that a bad guess on my part? Is there actually
more cooperation in the field than I would guess? So you're talking about the AI capabilities
research field? Yeah, I guess. Well, is it one unified field or are there different
institutions working on this that either are helping each other or are not helping each other?
You mean safety or capability? Capability, I'm sorry, yeah.
So capabilities, there's lots of research groups, right? There's like Google,
Google Brain, Google DeepMind, there's OpenAI, there's Facebook, Uber, yeah. I think there's
a fair number of companies that have substantial AI research groups and there's also academia.
That's my interpretation as well. I guess what I was curious about is are these groups helping
each other out? I imagine everything with Google is helping each other out, but if one company
makes a breakthrough, do the others find out about it when their product comes to market,
or do they find out about it beforehand and everyone's trying to help each other up?
I see. That's a good question. I don't know exactly. My impression is something like most
things are at least... Well, I guess I wouldn't really know because if it's secret, then it's
secret. I would sort of guess that a pretty large proportion of things are at least talked about
in publications. I mean, researchers like to publish results. Right, on that makes sense.
I guess I'm not sure what my... I might have guessed that there would be more competition
rather than cooperation involved, but it doesn't have to be really either or. And you're right,
like current secrets, if they're out there, which they may very well maybe we wouldn't know,
but I meant like, is there a history of breakthroughs only coming out after one company has quote,
one erase or something? Or is it... I think you kind of said that there's an impulse to
publish among actual researchers and other people can read their stuff and they want it to be read,
so that makes sense. Yeah, I think we're... At least for the time being, it's not the case that...
Like, I don't remember when the AlphaGo paper was published. I think it was definitely before...
And I'm making this up. I think it was before... It was well before they
had the match with Lisa Dahl, the Go champion, which... Just because they published the paper
doesn't mean someone can go and do exactly the same thing they did and scoop them. But right,
it's not the case that... I don't know that it's been the case that we've seen
external signs of deep mind, for instance, making large amounts of progress,
but not knowing what the technical stuff behind it was.
We did have this thing that we wanted to touch on, though, which you brought up.
I wanted to ask you, in your email to Inyash back here, there was this paragraph that jumped out of
me that I wanted to spend some time basically line by line going through. I don't know if
you can pull it up or if you remember it all, but you'd said, if I have an agenda, it's actually
not about that, which was AI safety research and popularizing that, I think, but you said it's
about the meta, namely promoting the message among EAs and rationalists of actually trying to figure
things out, develop your own inside view, build your own capacity, debug your friends, informed
giving, entrepreneurial spirit, and a handful of others. But that stuff, that really jumped out at
me and I thought that'd be a lot of fun to talk about. And it sounded like you wanted to talk
about it too, so I wanted to get to that. Yeah, that sounds great. Awesome. So we can talk about
however you want. You're welcome just to go through however you'd like to approach this. If you
want us to ask you each one and you can respond in turn, or if you want to just talk about it for
15 minutes, that's completely fine with me too, whatever you'd like.
What is it that you're most passionate about? What is it that really fires you up about this?
Well, I actually have a question. Do you feel like you're well grounded or well in touch with
the broader EA rationality community? Definitely in touch.
Definitely more so than the average person.
Right. The well grounded is an interesting question because I don't know how to judge that.
I'm not like one of the people who spends time on the forums discussing these issues, for example.
I don't even really lurk that much. My exposure is more through reading other blogs and seeing it
referenced and talked about there than actually being directly involved. But I could probably
follow what you're trying to say. If I can't, then I would stop and ask you for elaboration.
Oh, okay. Actually, I wanted to see if I could get information out of you that I didn't know.
Oh, okay. That is unlikely. But if there is, I can try.
Well, I might be sheltered. I wouldn't know if I were sheltered.
Or not sheltered, but like have my head in the hole. Well, so yeah, I guess I'll just jump in,
but you should interrupt me. In a word, the thing is ambition. It would be cool if
EAs and rationalists were ambitious about figuring out what's actually going on in the world,
how it actually works, what we should actually be doing.
What do you mean by what's going on in the world? Because the world is really big and
there's a lot of things going on in the world. Yeah, exactly. But I mean, so there's this effect
where we sort of just like humans by default, it seems to me, copy the ontologies used by other
humans in the sense that if someone has thought through what are the top five causes that EAs
should think about, not just the causes that they produce, but the ways of thinking about
cause prioritization, the ways of condensing the world into a small enough representation
that you can think about it with the human mind, are sort of like overfit to that person's,
to the way that that person is doing it. And then other people sort of copy that,
copy the ontology, copy the lens. Well, that is true. I totally agree with you. But on the other
hand, it's very hard not to do that because someone has already done all this hard work and
identified a problem that needs a lot of work, like for example, the whole elimination of malaria
thing. And you can spend the next however many years trying to find other ways to think about
this thing and find other causes. But when there's something as easy as not necessarily easy,
but when there's something as concrete and something that you can do things about as malaria,
it almost seems like it'd be for the average person a better investment to just try to go out
and fix that rather than if everyone were to spend all their time trying to think about better
ways to think about this, right? Or do you think that everyone should be doing that?
Well, I agree with that, like, certainly in theory, and also just like in practice. Yeah,
for lots of people, the right thing to do is like, make as much money as they can,
live a happy life, and like, give a bunch of money to the cause that seems good. But I think,
I think basically like, right, what I'm trying to do is like a pendulum swing,
where I think that the pendulum is way too far on a long bat axe, like in that direction.
I see that there's nobody left now thinking about these things.
Well, it's not no one, but it's like, inadequate.
Yeah. I think that's a fair assessment, certainly in my view. I don't know.
I mean, there are a handful of things. I probably came across like the idea of
combating aging independently before I heard about Aubrey de Grey, but I don't know if I
would have on my own thought of malaria as a great thing to work on right now with my money.
And I did sort of just delegate that work to other effective altruists,
as far as the cognitive leg work to say, you know what,
malaria, that's what we should be focusing on right now, or at least some of them, right?
So I think I see, is that, does that relate at all to what you were saying when you said
that you were interested in like trying to get promoting the idea of getting people to develop
their own inside view, or is that a different concept? Yeah, that's roughly the concept.
Can I ask you, like, have you done thinking along those lines of where best to spend EA
efforts, for example? Yeah, I do some of this. Oh, cool. I mean, it's sort of like bias towards
what's relevant to my decision making. Yeah. Do you mind if I ask what you think would be a
good focus? I'm super tempted to be like, the focus is actually figuring out what the focus
should be. Oh, okay. Oh, like, I actually think that. Okay. You think that there's other low
hanging fruit that we are missing because people aren't looking at for it? Yeah, I think that the
bottleneck is not really, this is sort of, this is sort of not true and sort of complicated,
but like, to a first order factor, to a first order approximation, the bottleneck is not
money and isn't even thinking of plans as such. It's like having people who can do
stuff and can do stuff that's important and hard and like a little bit weird.
That's a very good point because I know I, for one, don't really feel like going to a different
country and working on things that are really hard when I could be staying here in the US doing,
accounting or whatever and podcasting and hanging out with my friends. Yeah, I don't think that
that's bad. Like, I think it's great to like, yeah, doing things that you want is like,
that you want to do is like, probably a pretty great policy.
Right. If I understood what you said earlier about, you think that a good effort right now
would be actually thinking about what we should be working on rather than just like finding things
to work on, we should actually be dedicating actual time and effort into figuring out what we
should be putting time and effort into. That makes a lot of sense to me in that I could imagine
looking back in 50 years and being like, man, if only we had thought of this 50 years ago,
we could have taken care of this, you know, earlier on or it would have been a lot easier
50 years ago or something like that. Is part of your concern there that we might miss what in
hindsight was an obvious opportunity or something that would have been totally within our grasp,
you know, in the past, in retrospect? Yes, that sounds right to me. I mean, that fits
what's in my head. But like, to some extent, it's not that I think that we are lacking for plans.
It's more that I think that so like, maybe I think like in order to do stuff, you have to have
thought through, like you have to have thought through strategy yourself. Maybe I'm not sure
I believe that. It seems to me that coming up with a new thing to focus on de novo is, I mean,
it's nearly impossible. You would probably be better off just using a random number generator
and using that as a basis where most people, when they find something new to focus on,
it's because they are working in a particular area and they notice something that is, you know,
kind of relevant to their area or adjacent, which other people just haven't been paying
attention to. But it's not like, it's not like you can just come up with a problem that people
haven't been looking at from your living room. It's something you stumble across by being,
by working in a field, right? I want to say really quick, strong disagree.
Yeah. Certainly when you said might as well use a random number generator.
Okay. Like, I want you to weigh on this as well. But I think I can imagine a counterfactual world
in which no one was talking about aging right now. And it just, it didn't come up for another 20
years from now. See, I can't actually imagine that because people have been talking about ending
aging since, fuck, I don't know, the beginning of humanity. It's been a foundation of many myths.
But like, as far as like, this is actually a problem we should start attacking right now.
Like, I think it would be possible to have missed that, that mark. And so,
with maybe a little more reflective thought beforehand, they would have thought to do this
20 years ago, something. Oh, well, I mean, I think they should have started 20 years ago,
but I don't think it's for a lack of people having the idea. I just think it's for people
thinking, well, this is technically a biological impossibility. So why bother?
Well, I think that's the point, though, is that they're not spending enough time thinking about it.
Or, you know, thinking this is currently an impossibility. Let's change that. You know,
it's like, we'll see it and be like this intractable problem, kind of like in,
I hate to always bring up methods of rationality when we're talking about rationality stuff.
But like, every wizard's feelings about death, right? It's just this thing that they look at.
Oh, yeah, that's impossible. And they never question that. So I think that
it's certainly imaginable for me that someone or a possible world where people
went longer before they thought about attacking aging as a particular problem.
Yeah, but I mean, we have a lot of experience with death. It's something we rub up against
all the time. We would have never thought to implement latrines in the South if we weren't
people living in the South and seeing people struggling with anemia. This is referencing an
old book about, you know, when they started implementing large-scale public sanitation
projects in the South. That's fine. I think I'm using a real example because I haven't actually
put in this legwork that Svi was mentioning and thought of an original on myself yet.
So maybe I'll do that. And if I can think of something good, I'll get back to you and be like,
see, this is what I was talking about. I'm glad I thought about this.
It's not just like original is great. And also like, there's like a thing where like,
yes, we've thought we've like known about aging as a problem forever. But like,
there's a pretty big difference between like kind of knowing that it's a problem and like
actually doing, actually like making progress on the problem.
Yeah. But you're talking more about finding new problems to focus on. Yes?
Okay, that's, I think that's not really what I mean.
Okay, I misunderstood you.
I sort of, yeah, I sort of, so in the email, the last sentence in that paragraph was,
this claim is not well articulated in my head.
Is it more about doing research to make sure that we're focused on the right thing?
Well, maybe the real question is just, why haven't we already solved x for various values of x?
I mean, there's some reason. I guess when I trace that back, it doesn't feel like x is a problem
that can't be solved. It feels more like no one is really trying. How does that strike?
I think that makes sense. And that strikes me as, as, as sensible.
It's not like no one is really trying to cure cancer, though. But it's still isn't cured.
I think that's a different, at least I'm painting it differently in my head. I'm just
thinking of like, like you were saying, you know, aging has been an intractable problem forever.
I think it was probably likely that people thought of it as this will be an intractable
problem forever, long after it actually was an intractable problem.
All right. What about poverty?
That was probably a problem longer than, I think that was probably a problem that people
give me making progress towards fixing longer than, for more time than was necessary before
people could actually been working on it, right? Maybe. I think there, I mean, people have been
charitable forever too, but maybe not in an organized, useful way.
I guess maybe I just have a ridiculously high bar for really trying.
Like, like this is totally not about sincerity. I'm sure like many, many people are sincere
about various problems. I think I heard a interesting example of trying in the push
versus pull sense where a celebrity who is like outraged by what's happening in Syria,
they're like, well, what do I have? What tools do I have?
I am a celebrity. I have a microphone. A lot of people listen to me.
So I will get up and I will talk about Syria and I will say we should do something about this.
And that's more like push is I find out what strengths I have and I try to use these on the
problem. And that doesn't work very well because those strengths aren't very applicable to the
problem. But you can't say they're not trying. They're doing what they can with what they have.
Whereas the pull approach is what is the problem? The problem is that there is this civil war
happening in Syria. How can we fix the problem and you look at to what solutions are possible?
And then how can we implement these solutions? And then what can I personally do to help
implement these solutions? And then how can I improve my skills in order so I have the ability
to implement these solutions? And so you work backwards from what needs to be done
and then start working from there rather than working forwards from what do I have
and trying to use what you have. And one of them is a lot easier than the other. But
