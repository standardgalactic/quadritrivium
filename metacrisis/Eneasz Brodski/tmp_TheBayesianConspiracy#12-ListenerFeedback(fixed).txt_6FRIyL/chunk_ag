If you don't like how iPhones are manufactured, don't buy an iPhone.
Yeah.
But you're not going to shut down Apple by making that decision.
Yeah.
So I think it's kind of like, you know...
It's personal.
Yeah.
And you get some marginal benefit knowing that you're not helping contribute to a system that you don't like.
Yeah.
And I actually have an analogy for this that I used for vegetarian veganism that actually my husband came up with.
I don't know if he's the original person.
Anyway, when defending our diets, he said, imagine that you're in a firing squad.
In front of you is somebody who you know to be innocent.
But there are 20 other people in the squad.
Do you shoot the innocent person knowing that everybody else is also, you know, the person's going to die anyway?
Or do you not?
Oh.
Yeah.
If it's no cost to you to not shoot somebody who's innocent, don't do it.
Don't buy those sneakers.
Buy different sneakers.
Buy a different phone.
It's okay to stand up for what you believe in.
It is.
I also think it may be one of the cases of where you think you're doing something but actually not doing anything at all.
And so your energy is being wasted.
An example of this is the divestment movement, which is where a number of people convinced institutions, certain investing institutions,
not to buy stock in any company that has certain unethical practices and to sell any shares they had in that company.
And after a number of years, analyzing the effect that it had, it turned out that it had no effect at all
because people who were willing to buy shares in that company would just snap them up.
It was an efficient marketplace and so what one actor did didn't really matter.
Interesting.
Yeah.
So if you want to, if you want to make your products more ethical, do it on the government level.
But do what you want.
That too.
Do what you want to do.
Nothing matters.
We're all going to die.
Let's go watch some TV here.
If it's going to make you feel bad, then don't buy it, but...
Signaling is a real thing.
Right.
It's your life.
He goes on to say, or not he, they go on to say the most effective way to reduce negative externalities associated with consumption
would be to consume less and donate the difference in money.
He says they say all your money, but I'm going to go with the difference in money,
to charities that rank highly on GiveWell or other charity assessment organizations.
I think this is a wonderful point.
And I also would like to point out that there has been a suggestion made by Scott Alexander
that if you have trouble not eating meat, but still think that factory farming is unethical,
you should simply spend more of your money on offsets to those things,
either fighting against the...
Mostly vegan advocacy groups.
Those tend to be rated as the most effective charities.
Yes.
Either vegan advocacy groups or in other ways making up for that harm you're doing to the animal.
Basically...
By making more people vegan who are not you.
Moral indulgences, really.
Yes.
It's a weird way to look at it, but if you can buy carbon offsets, why not meat offsets?
Why not any offsets?
Right.
Murder offsets.
It does get into a weird murder offset place.
If you can save three lives, are you okay killing one life?
Because on net, you've saved more lives, right?
Good question.
Yeah, we'll find a link to that essay.
I think that's one of the more...
They're all fun, but that's one of the ones that I think you don't even have to come from any particular place to enjoy.
You don't have to be on either side of that question or whatever.
It's a fun exploration of that sort of trade off.
So, moving on.
JJ commented on the same episode.
I think the main issue is that people are so resistant to change, and once they get into a pattern of gathering data from one place, they stop looking for others.
This commenter came from a Christian background where, really, that was the best belief set for them given what they were exposed to.
And I think that that's a fair position.
I mean, you can't really be blamed, I think, for not having access to good information.
Especially if you're in the utmost position where you're homeschooled, controlled internet access, that sort of thing.
I think that part of practical rationality is the skill of knowing how to find and assess various pieces of information and sources.
And one typically needs motivation to want to change their beliefs.
I think this is also a great argument for having a large number of, not necessarily friends, but at least contacts and acquaintances across the political spectrum.
Because then you will see some of their arguments, and since they believe in them, they are motivated to present good ones, usually.
And that helps keep some of that in check.
I agree. I think that having a diverse pool of people to interact with on various topics is great mental exercise, and it's great to be exposed to various viewpoints.
And I would caution anybody who only has liberal friends or only has conservative friends or only has Christian friends to try and find some more friends.
But I think anyone who's that shut off probably won't be listening to this.
So it might be hard to reach unless they're already in their group, right?
Comment to JJ probably wouldn't have heard this podcast three years ago.
They wouldn't have heard this podcast three years ago because it wasn't made three years ago.
But they wouldn't have found something like this.
So I think it's sort of hard just to think of how to reach people who aren't authorized or reached.
I mean, that's a problem for another day. That's community and outreach and stuff.
It's also a good argument for being nice and being fun to be around, because then other people want to be around you and you can expose them to your views.
Like, don't be mean to conservatives and Christians and be like, oh, you stupid idiot Christian. Be nice to people.
Then they'll want to hang around with you and they'll learn some of the things you think.
I actually had a friend ask me. They are trying to protest some religious extremist group in their neighborhood who wants to talk about evil, trans, and gay people are and stuff.
And they were like, I don't really know how best to go about reaching people.
I want to try and set up something to where they can have an alternate information source.
And I said, well, really, I'm not the best at how to deal with getting kids to believe things other than not trying to argue them out of their religion,
but try, I guess, really just to A, be super nice and approachable. Don't go shout back at them.
And B, I think try and just slip in there that it's easy enough to find some common ground where they don't have to give up their religion
to agree that the the tenants that homosexuals and trans people are subhuman are not to be morally concerned or whatever it is.
This hate group church was advocating.
So there is a great episode.
Oh, I think it's 99% invisible, but I'm not sure I'll check and I'll update the webpage.
But there's this great episode about a small conservative conservative town in a rural area, which is one of the most protrans towns in the nation.
And it's because there's this one old guy who owns a movie theater that everyone loves and he's the best guy.
He owns the only movie theater in town and every now and then he would constantly dress up when a new movie came in town as one of the characters.
And as a lark, he would start out for every now and then like, oh, I'm playing the woman, you know, but he was trans and slowly he did that more and more.
And the thing is, everyone loved him.
So when he finally actually came out and he's like, yeah, this is just 2am all the time.
People are like, yeah, it's okay. That's cool.
And just the fact that he was their friend, he made the town one of the most protrans towns.
She even.
She, thank you.
She, yes.
The show started out with him.
He and then transitioned to she over time.
Well, they don't want to give away.
They don't want to give away the twist.
That spoiled the story and confused it a lot.
Um, David Youssef made a great point that in the book, thinking fast and thinking slow by Daniel Kenneman, the part of us that does rationality is really, really energy intensive.
Whereas our illogical and fast brain is really good at conserving energy on a daily basis.
Just this information taken on its own means that you're not trying to make people rational in the sense of them doing them with knowledge, but by building a set of habits and techniques and really simple rules of thumb.
When looking at someone who has done this from the outside, you'll notice that this doesn't make you on the surface smarter.
So they're talking about how it helps to develop heuristics to make rational thought easier instead of slow and clunky like everyone thinks it is.
And I agree completely. I think that's what I'm trying to promote.
The part that's confusing me of what they say though is that when looking at someone who has done this from the outside, what you notice is that this doesn't actually make you smarter on the surface.
I feel like it does.
When people think of smarter, they often think of book smarts like knowing, you know, the square, knowing what pi is out to 17 digits.
Okay, yeah, so maybe they put smarter in quotes.
Or they did, sorry.
Never mind, I read that backwards.
Sorry, David, you were perfectly clear.
Clack in whatever video I heard.
Oh yeah, this was another point that was brought up in that Raising the Sanity waterline.
It turns out my initial impression of Neil deGrasse Tyson's position on the 7% of religious people in the National Academy of Sciences was that Tyson was arguing that atheism isn't a solution.
That atheism isn't as obvious as the theory of gravity.
And that's why it's not as ubiquitous in the National Academy of Sciences.
I liked Inyash's interpretation more.
Yeah, it turns out Neil deGrasse Tyson was saying since there's still 7% theists in the National Academy of Sciences, that means you don't have an ironclad case.
And that made me very disappointed.
But I am a firm believer in death of the author and I will take that on a slightly more literal level at this point and say that I can interpret his words to be the words that I like.
The version of Neil deGrasse Tyson you heard in your head is right.
Exactly.
Thanks Clack for backing us up there.
On to Episode 1.
The last one.
We called that one What Uses Rationality.
Googleplexbyte says, default human decision making is founded in intuitive pattern recognition.
It's tempting to rely on this intuition because the human brain is machine-meltingly amazing at pattern recognition.
And when you're born with a hammer that makes artificial version look like a foam club, then everything is a nail.
Which I think is a very astute observation.
We are really good at that sort of intuitive pattern recognition.
He goes on to say, for this to be effective requires two things.
One, human-scale domain which we involved in.
Like where a baseball is going to land or whether a piece of art is forgery.
Or two.
Someone read that Malcolm Gladwell book.
Or two.
Someone has no idea what the two of you are talking about, but okay.
Sorry I said or two.
And two.
Number two.
Frequent exposure to similar events in order to develop an intuition.
Example, a baseball player or a craftsman running into these situations over and over.
In the rare cases where either of these requirements aren't met, it's better to use rationalist decision making.
As pattern recognition simply is not capable of handling variable outcomes or situations that they have been insufficiently exposed to.
Now I believe that the book was called Blink and he's making the same argument that Malcolm Gladwell did,
which is your intuition is great.
All of those pattern recognition mental shortcuts based from your experience are awesome,
but they break down in certain conditions.
That's it.
That's the whole book.
I wasn't really keen on it.
I enjoyed the hell out of the book.
I think Malcolm Gladwell is a very entertaining writer though, which is...
It was called Blink?
It was called Blink, yeah.
That sounds really self-evident and obvious.
That's the whole point.
Yeah, that's why I don't like Malcolm Gladwell.
Because he's writing obvious stuff, but he's spelling out obvious stuff.
He's entertaining about it too.
I will give it a skim and see who I agree with.
So yes, we agree and one of the reasons that rationalism became a thing is to handle the cases where we don't have a lot of cases that we can train our intuition on,
such as what happens if we create a superhuman AI?
Or biases like scope neglect.
We're not great at emotional multiplication.
Yeah.
So yeah, I think that's really interesting.
That's why we have rationality and thus that is a use of rationality.
For sure.
Russell says,
I consider it important to avoid idolizing Eleazar Yackowski since it's a common focal point of criticism of rationality.
Agreed.
I...
