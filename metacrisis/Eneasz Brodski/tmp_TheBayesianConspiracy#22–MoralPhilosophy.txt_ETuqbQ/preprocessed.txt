Hello listeners. We recorded last week's mini-sode and this episode in one sit-down
without really pausing in between. We didn't decide until after the fact that we were willing
to do two different episodes. So this one kind of picks up in the middle of a conversation,
but the transition into the actual conversation happens fairly fluidly. So forgive the unusual
opener and I hope you enjoy the episode.
I don't have a lot of practice slapping people. I might accidentally hit you in the ear and burst
your ear drum or something. I appreciate that. So there's a difference that Aristotle talks about
with voluntary versus non-voluntary and involuntary. Is this being recorded? Because Aristotle is a
this will come up so we can let's dive right in. I don't know. He's a voluntary versus a voluntary
harms. Let's say this can come up on that too. So like if I said hit me and you hit me and I
slipped off the chair and fell into this, well that's kind of on me because I asked for it.
But like if I out of nowhere pushed you and you broke the chair and broke that door, that's on me
even though like you broke it with your body, right? So that's a distinction that he draws
with between like voluntary and voluntary and non-voluntary. Non-voluntary would be like or
non-voluntary we'd be pushing in the door. Involuntary would be like succumbing to acracia
where you know you do one thing even knowing that something else is good for you. What's this
acracia thing? Acracia is when you act against your own self-interest knowingly because of a
failure of will. Okay. So you know if you're you break a diet or you cheat on your spouse or
something. I see. So you know like well I've been counting my calories but god chocolate donut
you know. I understand. So I bought donuts for the house for the first time in like months
on this weekend. No, why'd you do that? I felt like it. Probably acracia whatever. I don't really
have a I don't really have a policy against against eating unhealthy things so I have this weird
metabolism where I can eat whatever I want and never gain any weight so I've been the same
weight for like 10 years. Nice. Yeah. That's your introduction into moral philosophy. So Aristotle
is one of the the first known moral philosophers. He's big in the field. I'm not sure when we started
recording so this hopefully it was a good time. Is he? That's what the introduction to the book
that Stephen lent me today said. Okay. Or was it Socrates? It was Socrates. Socrates might not
exist. Well Plato did. It was Socrates as in Plato's writings. Yes. Well like so the interesting thing
so I guess let's start. It was a warm sunny day in ancient Greece now. My only real
beef with that is that people have been doing moral theory forever but I guess
were they really moral philosophers? Yeah. So what are could you could you list off the
eight moral philosophies? I kind of think of six or seven but I'll try. You find out whatever
one I miss. So I will say real quick though that that there is some disagreement.
It's hard to get like a straight answer out of any philosopher in general. Aristotle might not
have been a moral philosopher in the way that we would use their term now because morality had a
different connotation 2000 years ago in Greece than it does today. So like his big book on ethics
is less about like how to act right and do stuff like you know if you buy one of Peter
Singer's books it's more about how to live a good life and that doesn't necessarily entail
what we would call morality. So was he a moral philosopher? Who knows? What did you say? Okay so
the so one of them would be Aristotelian. Yeah so which is how to live a good life. Yeah virtue
ethics was Aristotle's framework in his book the Nicomachian ethics. So we've got virtue ethics is
one of them. So we've got consequentialism, deontology, ego. I thought that consequentialism
that there were multiple ones that fell under consequentialist. As of like the 1960s there are
they're basically interchangeable among philosophers up through then and today they
basically still are. Consequentialism is essentially utilitarianism. I would not say
interchangeable I would say they all fell under a similar school. So there can be vast differences
between different types of consequentialism. Now there can be and I'm sure somebody will
disagree with me. If you're a philosopher out there you're gonna find something wrong with what
I'm gonna say. But yeah so utilitarianism is the most popular version of ethical consequentialism.
Okay so I'm gonna be probably the most ignorant person in the room on this
but in the very short amount of research that I did I thought that there were multiple consequentialist
moral theories including utilitarianism and maybe egoism. Yeah so like but you an egoist
wouldn't necessarily say they're consequentialists. So like that's why I said like people use the
terms interchangeably. Okay. So consequentialism is just saying I'm gonna act in a way that will
maximize my desired outcome and that can be you know investment of your money into different
accounts or whatever. So like it doesn't have to be about you know what utilitarianism is about
in. Consequentialism analyzes the consequences. Right and utilitarianism analyzes the consequences
in as far as they maximize the well-being of the subjects of the subjects or if I ever want to
involve depending on the consequence or depending on the utilitarian. In moral philosophy I think
that they tend to conflate but yeah there is a difference. Like consequentialism is a broader
thing but if you say a consequentialist as far as your ethics I think I guess I might be wrong
but I think for the most part you're saying you're utilitarian of some flavor or another.
What what's egoism? So we know virtue ethics. We've talked about utilitarianism very briefly.
We'll get back to all of these. What's egoism? Egoism is doing it's basically what kind of what
it sounds like it's my ethical system is what's best for me and fuck you. There are better versions
of it but basically it's I'm gonna act on my own self-interest. Is that like iron randism?
Is that like objectivism? Yes no it depends okay but like broadly speaking egoism is saying
I care about what's good for me and you know if what's good for you happens to be good for me
then that's good but you know if I... An egoist would also argue that this is in general the best
way to run the world that outcomes are maximized for everyone if everyone is an egoist. An egoist
I guess that might be the case. My understanding would be that an egoist wouldn't really care
about maximizing what's great for the world. They care about what's good for them but a good
world is good for you too. Yeah and like in rand was a very strong believer that if everyone was
selfish like this the world would be a much better place that a lot of the terrible things that happen
are because people are trying to make decisions for other people that are in their best interest
even though they aren't. Well maybe that's why she created objectivism as something
separate from egoism. And maybe that's the one that's missing from my short little list here.
Yeah I'm not sure if she'd be an egoist or not. She may be an objectivist. So what is
objectivism? That's literally what she fented. Yeah it's that everything's the world is better
if everybody asks in their own self-interest acts in their own self-interest. Fair enough.
I think egoism is more personal than that so I think that that would be the distinction that I
would draw but I again if you're a philosopher you're gonna you're gonna hate this so writing with
any brief corrections. The the other couple to keep in mind are care ethics which is sort of
sort of like it's like egoism but a little broader I care about me and the people that I care about
hence the name. You know like my family friends and maybe my neighbors and you know my quote tribe
but I don't care about people in the third world or something. Another ethical framework
if you can call it that is religious motivation for ethics. I do what I believe or I'm what is
right is what's in the Bible or what God said or what my church teaches me. I've heard that called
I think command theory. Divine command theory yeah is what what's right is what God said in the Bible
right or what the gods want in. It doesn't necessarily have to be divine command every
time though sometimes it can be command of the king sure that he happens to know exactly what's
right but then you really then it's not religious motivation right yeah so if it's a religious
motivation I don't know where the word when and where divine command theory came in but in Plato's
dialogue the youth of pro socrates is talking to this guy and long story short he's asking the guy
or the guy says to him uh the guy's name is youth youth youth of pro youth of pro thank you
he said no no uh what's pious is what the gods say is pious and youth or socrates says well wait
is it pious and we can change out some of these words we can change out gods for god
and we can change out pious for good um is it good because god says it is well because socrates
points out the god the gods may disagree and so youth of pro says well it's what they're unanimous
on but since no one's since not many people now are polytheists uh we can change gods for god
so is something good because god says it's good or does god say it's good because it's good right
so if if it's good because god says it's good he could change his minds tomorrow and murder become
you know a a moral ideal right or beating children to death or something you know what
so if it's good just because god says it then it makes morality just the winds of a possible bully
right and if it's the other way around well then there's some underlying thing that god is saying
is good because it's good out there and it'll be good without god saying it too as well so
so there are things that are in theory good whether or not a god identifies them as good
yeah uh or or they're just his whims right his or her whims um I believe the the way that the
conversation went was socrates asked asked youth of pro youth of pro what is good and youth of pro
said good is what the gods love and socrates asked him do the gods love it because it is good
or is it good because the gods love it right yeah and that's that's the crux of the problem and
either way youth of pro is wrong right so or at least youth of pro doesn't know what he's talking
about which is which is kind of about every socrates and counterans yes um the the other main
problem with like a religious motivation so say you're just gonna say well I draw my my morality
from the bible but I don't like this part this part or this part but I like these two parts
so you know contemporary example might be like well I'm not gonna beat my slave there's not
have any keep slaves I'm not gonna you know stone my wife to death for for cheating on me or
something but I don't like gay people I'm gonna stick with that one so like that's a contemporary
example that some people in the United States would subscribe to but that to me suggests that
they have a separate criteria by which they're picking the rightness and wrong those things
out of the bible and they're coming to the bible with those things yeah I would I would uh phrase
it as and I think it's been phrased this way by other people that any divine command theory really
boils down to who interprets who interprets the command yeah or it could even be super straightforward
but you can look at it and say well it's it's pretty clear I'm supposed to you know kill somebody
for moving sticks on a sunday but I'm not gonna do that because I feel like that's antiquated
do you do you listen to your priest's interpretation or do you interpret it by yourself or listen to
god's interpretation that's written down in the bible well that's the problem is the bible doesn't
tell you anything directly you have to read it and interpret it yourself or take the interpretation
of someone who is more skilled in the bible reading skills as the expert extra-religionist
I'm gonna go ahead and let you have that one so it seems like we've determined that that one
we don't think it's correct yeah I think it's we don't I think I think it's the easiest to dismiss
it's one of the it's one of the easier ones to dismiss and and you guys jumped on it to dismiss
it well it totally depends on how you feel about god if you think that god does exist then it's not
quite so easy to dismiss I'm gonna make a case after we go through all of them that they're all
basically consequentialist at the bottom and I'll give you a teaser sounds exactly what like next
that sounds like exactly what a consequentialist would say it does no but so you're part of like
why you might say it's good for your kids to follow the teachings of the bible or the teachings of
your priest or whatever is because it's good for them to go to heaven afterwards well it's
got a good consequence that's what you're pushing for at the end of it right it might be good in
and of itself or the consequences god loves it and that's a good enough consequence yeah
this is not my part of it too um and that might not even have a consequence like if you don't
believe in heaven it might still be good but uh I think that that a large part of it is wanting
to go to heaven and avoid hell there are a couple others yes I'm missing the only other one I have
is relativism I want to do that one last deontology oh yeah I skim I skim to buy that really quickly
I mentioned the name of it but I mentioned what it was yeah so deontology is it's it's strict rule
based uh the most popular deontologist philosopher was Immanuel Kant and I guess the first main
popular one that goes back ages and there's contemporary ones now the the main thing is
constant formulation was called the categorical imperative where the moral action is or is to
act only in that oh what is it act only in a way by which you can uh at the same time will
that action become a universal law and that's constantly needlessly convoluted way of saying
that only do stuff that you could at the same time will everyone else do all the time without
being inconsistent uh so that rules out things like stealing and lying otherwise you're you know so
if you break a promise and you lie you're saying well I want everyone else to break their promises
to me and I want them to break their promises promises to each other and then promises don't
make any sense anymore or it's okay for me to steal but no one else well if you want a universal
law is stealing he makes this kind of case where you know if you're stealing from them they can
steal from their neighbors they can steal from you and you're basically saying it's okay to steal
from your own pocket so treat others as you would like to be treated yeah kind of but it's it's not
even how much like you would like to be treated but in the way that everyone could always shoot
each other all the time so like you might want someone to lie you might lie to your partner
and say yes you look great or you know whatever in that dress or something because you think it's
okay to tell white lies but there are no fuzzy boundaries for Kant so so the goal of the ontologist
is to find the best rules the ones that are most reflective of what actually is moral and then follow
them yes there's also a difference by what he means by moral so like the consequentialists
would say it's good by what actually happens the ontologist says the that moral moral action is
motivated from a sense of duty and the action itself is good it doesn't really matter what happens
all that matters is that you did the right thing which the goodness is evaluated by how closely
conforms to the rule rather than by what the consequences are yes so that does speak in the
worst situation where you could kill a million people and still have done the right thing but
that's i'm obviously not a deontologist so well that's that's the fun part of consequentialism
it's one of those things that does let you kill a million people and it'd be the right thing well
only if the alternative would have been killing a million and one people right whereas the deontologist
uh you know it could be killing is bad if you're a deontologist right yes yes but not so killing
somebody yourself is but even Kant gives this this long explanation of and i forget the name
the long name of the essay i sent it to you earlier um i'll put it on the the listing for
the website but it was he does articulate that in the extreme case where you're hiding somebody
who came to your door and said someone's gonna kill me you know i'm looking for sanctuary you
said yeah come hide in my basement and then that killer shows up at your house with an ax and they
said hey is that person here i want to kill him Kant would say don't lie to that person and if
that sounds like a straw man that's uh he that's his fault um he he says well you know you could
say no they're not here and then the ax murderer could wander away only to see that the person
fled your basement and is now running down the street but that seems to be like he's arguing
from adverse consequences consequences which makes him sound like a consequentialist and
presumably if you had said yeah he's right inside you would either have to kill the person to stop
them fight them to stop them or let them kill you and then or let them pass to go kill that person
i think in theory as uh as a person who is a deontologist uh the person coming to you run uh
asking for shelter would understand that you would not lie to hide the concealed presence
if they know that you're a deontologist which is kind of a bummer though right like so that
means like no hiding jews in your attic well uh it it it does mean that yes and i mean so there
there's there's no recipe by which to flex the rules at all even in an extreme case like you know
nazis at the door is this kind of like voting systems where every every moral philosophy every
moral theory has major problems in certain circumstances obviously right one no bias or
anything though no bias hey again i read the intro i didn't get much time to read the book that you
let me but the intro said that there are no right answers the intro is trying to be nice and that's
like that's like that's like that's like that's the philosophy you want to want to answer like
everything and so that's that's why i didn't say that there are no wrong answers either ooh so
like part of the reason philosophy isn't loved in the rationalist community partly because
it's bad that's an understatement pushing out bad ideas um if you can make a case for it then hey
you can write your book and we'll all read it um it doesn't matter how stupid your your belief is
we're gonna we'll take it we'll understand it as seriously as is appropriate for the field of
philosophy which is seriously indeed often the more more stupid ideas are more popular just
because they're more entertaining yeah there's that too um well not often but sometimes yeah we'll
we'll have to cover philosophical zombies and at some point yeah we had a little conversation
about that today when i was saying you know most of the philosophers that i meet don't even know
what that is but yet we and less wrong talk about how philosophers are really into it all the time
it's because it's the one thing that the primary sequences on less wrong actually talk about as a
philosophical uh topic in a way that's super clear um so i think that's the easiest hobby
horse we will jump on but it is popular like i said in philosophy of mind uh david chalmers
writes books on it uh den den it writes books against it and these people are all these are all
people that are alive today they didn't all die 500 years ago like you'd think an idea this bad would
have um so the the last approach to ethics and then we're gonna go back and do a little digging
into each of them is moral moral relativism uh everyone has met a moral relativist most likely
they're the people who would say that there's no such thing as right and wrong you know your belief
is just as valid as their belief and there's no criteria about which to judge which one's more
right or more wrong that sounds an awful lot like the church i grew up in yeah it's a great
wishy washy nice way to approach things but it it doesn't really hash out the the moral relativists
will also want to say it's wrong to be intolerant of other people's beliefs and they chip themselves
before they even finish tying their boots actually we again uh referring to church we had a lot of
discussions about that about how we needed to be more tolerant of people who are intolerance
because that was also okay yeah i my first irel encounter with a moral relativist was in college
it was my professors and she used the example of female genital mutilation saying there's nothing
that we can say is wrong with that and i'm like you're a woman you're the last person you're like
the second to last people that i think that would be saying that this is a fensible position i uh
people like that i always think of as strawmen but apparently they they actually exist some of them
actually exist why strawmen i think the impulse is like when she think about rape when she think
about um child rape i'm sure i'm sure so like the it's not saying that uh the more and i don't
want to strawmen them too much the strawmen moral relativists would say well there's nothing wrong
with it they would say it's wrong for our society but if there's another society that enshrines it
well we can't judge art their society by the basis of ours who's to say ours is better it's like we
are but that's not fair so i prefer the the type of moral relativist there's more of an emotive
emotive uh philosophy that says there is no actual grounding in any sort of like objective
wrong odds and right odds out there but we still make our own decisions as to what's right or wrong
and we can impose those on others but can you can you um imagine a culture in which it is okay
yeah there were cultures where it was okay to rape children there are cultures where it's okay to
rape children right and so like and i mean i'm gonna have to find the article and i apologize
ahead of time if i can't but um i i saw somewhere that in places where it's culturally okay to do
that the long-term impact on the victim is less severe significantly less severe than in cultures
where it's not okay to do that yeah i mean so that there are if we were to i'm trying not to pick
real world examples but it's it's hard not to so like you know i guess we could use you know
child rape as an example so yeah that could be the case where if it's if it's normal and hopefully
your uh your abuser isn't super savage about it then yeah you might not be that worse off after
the fact but uh you know the second you move to somewhere that doesn't do that and you try and do
that then you're gonna scar somebody um so i think it's not so much moral relativism isn't so much
about saying that you know you can't make a judgment it's saying that one culture can't judge
so like i think it again depends on the moral relativist yeah i'm trying i think most of the
ones nowadays are that way which is really sad but there's there's others that don't absolutely
go that far there are some that are also you know just like full on no no nothing's right or wrong
i'm trying to be as charitable as possible um you know but like so it would be nonsensical and wrong
of me or at least incorrect of me to say women in the united states are treated on average better
than women who live under the taliban they would say well you're just judging that
based off your culture you know why would you say you know they would say that they treat
theirs better than you treat yours or that they treat theirs appropriately or something
they the moral relativist would say you have no place to stand if i challenge you that and you
say no i'm right they're wrong uh that that kind of comes down to the bottom of the way to defeat
any physical philosophical argument is to attack their very first premise so the premise that like
well-being is good is the premise that you take if you're gonna develop any ethical system
and if you're gonna deny that and like what is well-being what is good like uh you can't
get off the ground and that's how you just stop anything in its tracks yeah i have a question
about that sorry i'm talking a lot no uh i want you to talk a lot since you're very passionate
about this subject um so my question is i'm pretty sure that i've been using moral relativism
incorrectly for ever um up until now maybe because i'm about to ask for some clarification
so i mean early on unless wrong when we met each other i said i'm absolutely a moral relativist
and what i meant by that is that um between species and we're talking about you know like
the the three worlds collide type situation or you know between different species of mammals
or animals in general or um that there is some there's some relativity in terms of what is good
for them and what is bad for them right so there you know it might be good to die for your offspring
survival but you know in our culture we tend to think it's not good to die for your off you know
to die every maybe that's not maybe that's not a good example um maybe to eat your your competitors
offspring so that your family has a better chance of living that's probably a better example yeah sure
we wouldn't be in favor of eating our neighbors kids so in some cultures that uh are primarily not
human i'd say uh that's a that's a good thing eat your eat your competitors children so that your
your genetic offspring have a better chance of surviving and that's not a thing that we condone
in fact we'd say it's really a terrible awful bad thing um to do here so i thought that that was
moral relativism in that literally there's no good or bad aside from what we assign to it what we as
humans assign to it and we can only assign it to humans yeah i think um a moral relativist would say
they wouldn't say we as humans they'd say we as americans or we as whatever this in group is and
we can't judge that out group but honestly if i i can't judge the ancient romans for the pedophilia
either or the pedorasty you i think it would be safe to say that we've made progress from the way
that they used to do things i can and i do i'm okay judging people yeah so like we're better than our
as than you know slave slave owners because we don't i think it's good that we don't have slaves
and so you know it doesn't mean that they're all monsters it was normal for the time or something
right i'm just gonna draw the line of humans yeah i wanted to mention really quick too that i think
that like why are you not okay with judging lions that kill the the you know the offspring of their
competitors because that's what they do yeah but it's still evil no it's good for them but there's
a lot of things that are good for an individual that are still evil they can it's not evil it's
how is it evil for a lion to kill its competitors offspring uh because they are murdering someone
it's it's not murder okay it's not murder they are killing a thing that does not want to die
yes they have to do that all the time in order to survive i also think that's a bad thing
i i think i can put some of this to rest as long as we're using the words like moral and ethics that
all the big names and moral philosophy mill cunt aerostodal i think all the books talk about ethics
with reasoning agents um it would be ludicrous i'm sorry it's ludicrous to apply that to non-humans
right well so but but even to assume that they that anything is good for them in the same way
that something is good for us we're using two different uses the word good there so like well
we might mean something that is good for them is great for the like reproductive fitness or something
but when we talk about good for ourselves we mean like morally right you know what i mean you don't
just mean like good for our reproductive fitness right but um you know there are social animals
that also have moral codes there are things that can be done and there are things that will be punished
right by the other animals in their community um if they're done for example uh there is a viral
penguin video um adultery in penguins oh i didn't see this one oh there was a there was a terrible
fight um penguins are like like many birds they're serial monogamous so they stick with one mate
through the breeding season although there are um a certain incidence of extra pair copulations
and which were kind of just starting to understand the extent of through genetic testing and increased
observations but there are things like uh there are songbirds that if they what you never told us
what happened to the penguin oh um i actually didn't watch the whole thing because i didn't want
i saw that the penguins were fighting and there was lots of blood involved oh shit they got pissed
didn't want to uh i didn't want to watch a bloody penguin battle but that's what happened it was a
bloody penguin battle so a penguin got caught cheating on its penguin mate yes uh so i think so
that's something that they consider bad in their penguin culture right so to the point that other
people not involved came in to punish well yeah it was the two male penguins oh okay yeah so it was
the original mate and then the extra pair okay mate so i think that there's there's still a
component missing with penguins of like the irrational agent involved where they're not doing it because
look you've you've transgressed our codes this is the last time it's more like that's my fertilized
egg repository not yours i'm gonna fight you for it right and like i don't think it's even
articulated on that level with a penguin i might be wrong there might be more to it in your life of
of a penguin than i think but i don't think so well how do you think that they form connections
i think that in some ways it's probably a similar to us i i guess uh if it is there might be something
going on in their heads that uh the trail love you know yeah but i think i think it's kind of
just like urges there i think the key the key component for for a more legion is a rational
okay so we're we're defining it as morality only applies to humans specifically well to rational
humans too not babies not mentally infirm humans like so it's wrong for me to hit inyosh but if
there's a toddler in here swinging around a toy bat or something to hit him it's not you don't
blame the toddler it didn't it blame the toddler you blame the parent if you're if you're gonna if
you want you know like you know what i mean though it's not like the toddler isn't it's just
basically a mindless robot running around swinging its arms no it's not it can learn
i i mean i would like for the parents to teach at these things but if the parents aren't going to
then i would tell the toddler not to do that and i might i might give it negative reinforcement
for sure you you would you would discipline it you would reinforce the toddler that's what
morality is but you wouldn't you wouldn't assign blame to it in the way that you would assign blame
to somebody like if an adult came in here yeah what if do came in here and bit you hard i would
give do some negative reinforcement as long as it would i could still come back into the house
i would i would give do to you and urge you to give do negative reinforcement
use the facial expression that i get yes if you can't admit me i'd do whatever i took to get
him off of me if it was actually hurting me well yeah i'd be stubborn i love dogs i wouldn't i would
hate to hurt it but i would i would get desperate at some point right you like your blood inside
yes um but yeah so you would feel a public service announcement if you're bitten by a dog
hold still until the dog opens its mouth to get a better grip and then remove the dog's reaction
to something being still after its first grip is to get a better grip huh if you pull away it'll
just keep on pulling and shaking okay i did hear once that if uh you managed to get a dog to bite
onto like an article of clothing or like a rope that you're holding to keep yanking at that and
the dog will not try to go after you he'll just keep clamping on to that thing this can all be
gleaned through careful observation of the game of tug of war with any dog right but so you'd have
also through personal experience with dog bites yes oh shit so do they open their mouth long enough
for you to yank your arm away yes you just stay calm stay still and then the the first bites never
in the right position right if if the thing's still and it's not trying to get away that means
they they have the instinct that they have the time to get a better grip huh you can do this with
the dog just play tug of war and like let him grab it and then pull really quick and they'll
they'll hold onto it yeah and if you hold it still be blooded up let them grab it and then
hold it for a second they'll adjust their grip see i've never done that and i just always assumed
the adjustment would be so quick you couldn't pull away in time i mean i guess maybe hopefully
they don't want to kick in anyway so deal bites you don't hurt him but he's so small and easy to
hurt he is which is why you shouldn't do it ah so another uh if if dogs and children are just
enough uh you wouldn't blame a car that the parking brake failed and backed into you no no because
their car can't learn well yeah i guess but uh i think that there is a component of i think there's
in the field and to me there's blame versus like reinforcing behavior yeah is there a difference
yes yeah one would say you're a bad person the other one would say i wish you won't do that again
and you're a bad person no no wow you people are not as judgy as me you say you're a good person
but that behavior was bad i think maybe i shouldn't be a parent depending on the moral
philosopher that you are you can't see somebody's a bad person no but uh i think you i think you
can't say that about things that aren't thinking like they're just doing uh i was thinking about
how to treat a child yeah oh yeah exactly you don't want to tell the child that's a bad person
kid runs up to you and kicks you you don't say like you're a terrible child you say you're a good
child who does stupid things they say you're naughty don't do that so it's incredibly harmful
it doesn't stop the child from kicking so drinking or short-term the question in short-term
versus long-term but we'll go into child-rearing techniques another time okay so uh see i don't
i don't i don't care all that much about this this blame or this reasoning i care more as to
whether i can change the behavior yeah i think that which is what i which to me is what morality
comes down to yeah i think irrespective of like what you care about there i think those are two
different things but also what's your goal right my goal is to not be kicked okay but if
deo comes in here and bites you you can make sure it doesn't happen again by killing him oh no
right or you can make sure it doesn't happen again by you know going through a different technique
right that's what naughty dogs do when he's not a naughty dog that's right he's better than that
yeah that's right so you have multiple goals i guess is what i'm trying to say yeah uh maybe you
want to raise a well-adjusted child or you don't want to like ruin somebody right i'm not gonna
kill the kid for hitting me with a bat right even though that would stop the bat hitting yes
they have other long-term goals so as far as like character stuff that was something that that uh
conch and aerosol will focus on more than mill and bentham the utilitarians so the the virtue
ethicist virtue ethics is aerosol's hobby horse and it's less about like doing the right thing and
it's more about being a good person um i'm a big fan of virtue ethics yeah people people like it
part of the reason people like it is that aerosol was super down to earth whereas playdough was like
super mystic and and fuzzy fuzzy aerosol being down to earth was cognizant of the fact that
reality is super vague and i can't give you a set of rules that you can follow all the time because
the world will throw something at you that i can't predict so you know here's the kind of
way to approach life in general and that that's that will lead you to be a good person um the way
things i like about instilling good virtues in people is that you can't predict every single
consequence of every single action which is one of my main beefs with consequentialism as applied
to actual real life sure uh so what you want there are always unintended consequences yes and and
we're not perfect predictors we we can't tell what all the consequences of something will be
but if you find a set of virtues that tend to have generally very positive outcomes
in you instill those in people then not only will you usually get positive outcomes
but they will be self um self motivated what are these virtues that's a good question what is what
is a virtue if i say that maybe um a virtue is being honest that doesn't put me into the
deontology camp of always tell the truth no because you're saying honesty is a virtue rather than uh
it is a categorical imperative that no one ever lie when and you can turn honesty you know down to
one or up to ten so you know honesty might be like being super brash and uh abrasive with people or
or being you know super wishy washy never committing to anything those would be kind of the two extremes
around honest the virtue of honesty right but the the advantage in my opinion that uh virtue has
over deontology is that there is no intrinsic motivation to follow a deontological rule unless
someone has already really drilled into that deontology is great and if you want to be a good
person and value by your society you will follow these rules but if you have the virtue of honesty
by the very fact of having that desire to be honesty you are already self motivated to be honest
yeah the motivation comes with having that virtue consummate a very uncompelling argument that if
you're a really rational person you'll be motivated towards deontology yes uh that that that's the
rational approach brandy or that's the that's the approach to to action that any rational agent would
do that's a very common um common thing for people to claim any round to claim the exact same thing
you have to perfectly rational person would be uh follow her morality which is why it's
objectivism because it is the objectively rational uh morality yeah when you get to name your own
stuff you get to sound really smart right um so let's think of another virtue does every it does
every moral theory claim that um probably not i i have from moral relativism i was about to say
yeah not relativism i don't even call that a moral theory that's like that's like not collecting
stamps is a hobby right so um well relativism is more descriptive than it is prescriptive yeah
i felt that that was the same with the consequentialism uh no consequentialism is absolutely
prescriptive okay uh they they're gonna say you should do these things and you should do whatever
will maximize happiness but i wanted to finish on virtues yes let's think of one more and then
we can find the common theme i'll leave you to you guys think of what is a virtuous thing uh to
work as a virtuous attribute uh show up on time sure i was gonna say not harm people but show up
on time is good so i mean like not harm people would be i mean there's there's cases where you
would harm people so i mean not how many people can't be the right thing all the time right so
maybe like no but if you have the virtue of of disliking when you harm people that'll prevent
you from harming people unless something much greater outweighs it right or you can turn it to
gather you know turn it down to one the other way and you'll never hurt anybody no matter what
and that also seems like a stupid position right you can end up being a jane and always
sweeping in front of you right yeah so but even janes would have doctors right uh i mean maybe
there's a consent factor involved i'm not sure okay um but like punctuality could be another virtue
too and i think it's harder to poke a hole in that one i mean maybe rigidly showing up at seven on
the dot if the party starts at seven might annoy the host whereas showing up five minutes you know
an hour early isn't appropriate and showing up an hour late isn't appropriate but something in the
middle well it would only annoy the host if it is understood that the cultural norm is for everyone
to show up a half hour late yeah i was i was really which case that wouldn't be a virtue that you
would hold yeah i was really stretching with with that one the the thing with the thing with
virtues is that it's it's a it's a middle point between two extremes and the extremes are both
vices and so Aristotle called it the golden mean or he didn't call it that he said it in Greek um
but that's that's what it's kind of been come to be called uh so you know like we said your your
disposition towards violence might be you know when necessary and not never right those those are the
uh that's kind of the way to put that but there's going to be a different golden mean depending
on the culture for example punctuality the the correct the correct way to be is going to be
an hour late if you're in Peru um correct me if i'm wrong Peruvians but i've heard some things
and uh whereas whereas in the US it's to be on on the dot on time or a few minutes early
no really well for for a meeting not for a meeting yeah okay right so isn't isn't that
relativism yes i don't have punctuality is but that's not relativism the you still want to be
there at the appropriate time it's just that the appropriate time is uh not the time that you are
told yeah but make the appropriate amount of killing people and being violent is different in
different cultures yeah and the appropriate amount of um i don't know sexual forwardness
forwardness is different and like isn't that make it relativism well so that that's one criticism
and that's that's partly why you know Aristotle isn't setting forward like a modern ethical framework
so i don't know if punctuality is is broad enough to be a virtue on its own but it kind of is so
like we kind of work with it um you know as long as you're working within the the appropriate framework
of what's expected you could extend it to um real reliability exactly in in which case it should be
flexible depending on what the the needs are right yeah i mean whoever you're working with that in
general you wanted to be a very strong desire but if there's other things that outweigh it
then it gets outweighed yeah you won't let my like i won't let my obligation to return the
$20 that you let me let my family starve right right i will i'll renege on that for the time being
so that's partly what makes virtue ethics uh not desirable to some people and super desirable to
others is that it's super flexible and uh it is the it is the kind of of approach that you can work
with that lets you adjust culturally right i'm trying to think of another example i guess you
know it's also the approach that i hope leads to less paper clipping of the universe can you
expand on that well uh when you have only one desire to make as many paperclips as possible
then you paperclip the universe but when you have multiple competing virtues and desires
then sometimes uh some of them will outweigh the making of one more paperclip when your need is to
be completely honest then you might have a uh undesirable outcome right right so it's kind of
becoming apparent that that is both the strength and weakness of of the virtue approach like it it
seems you know if you have two competing values how do you decide which virtue to go with uh you
know um do you love your well generally you go with the virtue that is not generally you always
go with the virtue that is stronger due to your programming the the question for the the ethicist
is what is the appropriate level of strength we want for each desire oh when building an ai or
something i meant for like for a human uh if you're building your own moral ethics how do you
where do you go yeah how do you live your life how do you be a good person oh yeah that so that
gets around to the other big greek word that arstall threw around a lot which was eudaimonia
and correct my greek if i'm wrong on the pronunciation that's the that's the good life uh that this
is more about and it wasn't so much of a moral connotation like it would be if we're talking
about stuff today right it was more about how how do you it's the kind it's hard to there's not you
use the greek word because there's not a good english word for it um you could say flourishing
but that sounds kind of like plants but it's more akin to like developing really well into the best
that you can be uh a good paraphrase might be the kind of life that if you could choose you would
choose for yourself and for those you love you know it doesn't have specifics to it um although
there are prerequisites to it but it's more just you know you want them to be as as best as they can
be the downside of that is that there are some prerequisites like you arstall argued and i think
he's mostly right that you can't have the great life that you wish for everybody that you love
and for yourself if you're born you know without a good physical body if you're born super poor
if you're born ugly and people hate you uh there so there are there are factors outside of your
control that come in to having a you down on life but he acknowledges that too i think i wanted to
just finish up on the virtue thing though that i think that it's it's a it's a strength of virtue
theory if the approach that you're looking for is something that is flexible for wherever you're at
so cons would hate it uh the consequentialist would kind of say you're doing it wrong but whatever
um you know you're not even he was saying not even you're not even doing it uh you know that's not
a that's not a moral theory um but it is based on it's in a way when you said it all comes back
to consequentialism it is based on the fact that this at least in my opinion it tends to have the
best consequences rather than trying to sit down and figure out the individual all udolans that
will happen from this action and all the possible knock-on effects for sure that having the the
experimental laboratory of the entire society we tend to have uh found some virtues that work
pretty well yeah i think and i'm not so say you right after our election so yeah i damn it proved
wrong by reality again i'm not a super gumball consequentialist but i think that that general
approach is right like when someone when someone asks if if you should uh murder a toddler
virtuous at this would say no but a consequentialist would say well if that toddler is hitler then
yes the consequentialist would acknowledge that in the real world you don't know if that toddler's
going to grow up to be hitler so that that you know if we're going to be charitable to the
moral realists or the moral activists let's be charitable to the consequentialists to
fairly i'll be fine and but that's the thing too is check all of these would say killing the kid
is wrong right so 75 to 90 percent of the time your moral compass is going to point in the same
direction no matter what your subscription is uh you know generally don't lie generally
don't steal generally don't kill people if you're a dentologist it's never but you know most of the
time you're not doing those things anyway um actually i was reminded of something that jesse
brought up at our lesson at our last meeting which is the idea of having a panel in your head um
that he got from elsewhere but we'll see if we can find the original person you talked about this
you have a panel in your head and it's made up of people with different moral theories
and how do you um how do you invite those people to your panel in what proportion
you might have um you know two seats for deontologists you might have um seven set aside
for consequentialists and you might have five for the virtue ethicists and you never invite the
moral relatives who knows i don't know um but certainly stay away from those fucking divine
command guys where where what you're what you're kind of doing is you're blending some of those
theories um in terms of how to apply it to your own life yeah because you can't if you're a
consequentialist you really can't predict a lot of the consequences to what you're doing so you
might want to take a shortcut through another moral theory and so there are different flavors of
consequentialism one of them is uh like rule or excuse me if utilitarianism there's rule utilitarianism
where you kind of set up kind of like it's it's basically deontology but you acknowledge that
you're doing it for the generally good consequences not for the good in its own action you know so
like you're not going to lie because you know other than like unless you have time to reconsider
that but generally you'll make a policy of not lying because uh that tends to be good so like
just this approach with the with the with the mind panel i know you had a word for it i can't
remember what it was that one works if you have the time to sit and deliberate but you're like
aerosol all acknowledges and and consequences and the consequentialist acknowledges everyone
if you take everyone who gives an actual thought says yeah you don't have the time to think through
every decision you're gonna make some things just come right up you know so you've you you know
you either have quick heuristics that you use to come to the right the right action or uh you try
and think through as many things as you can in advance or you know you have flexible rules or
whatever i think one thing that people try to poke a hole in in consequentialism in utilitarianism
by doing this thing well you can never you know you know the house is on fire you don't have time
to sit down to the pen and paper and figure out who's worth saving but that's not that is not when
the utilitarian is doing their their their calculation they're doing it when they're at home
they've got 10 minutes and they're saying well i've got a thousand dollar charity budget this month
what am i going to do with it well i could you know i could drive down the street and throw a
dollar at my window every you know every few seconds what are my other options right so uh it's not
necessarily about the the knee jerk reaction that you have in immediate circumstances it's about the
reason the moral action and then you do have time to consider as many external externalities as possible
if you're considering that you know if you've already decided it's a charity budget you can decide
what the best charity to give it to is you can give it to extremely very puppy disease you can give
it to an individual homeless person you can give it to give well you can give it to the
against malaria foundation and you'll think about if you have the time and the resources you'll give
as much research as you can into any of your options that are worth considering and go with
the one that you decide is best so based on how much you've been talking about this just now do
you think where people put their charity dollars is the most important moral consideration most
people will have not most people but like most people don't have the money exactly to be the
most important consideration that they have yeah exactly if you do have a substantial charity budget
i think everybody except for maybe conch would agree that it's worth considering where that money
is actually going so i don't know if that's the the biggest moral concern that a person would have
but it's the kind of thing that they they can give a lot of forethought to and that there are
um if you grant the premise that making the world a better place is a good thing so you know like
i find the arguments that like i said earlier attack the first premise to be pretty uninteresting
you know if you if you're gonna sit there and question every term and their first in their
opening sentence you're not really getting anywhere well um okay so every everyone who
thinks about ethics always says i want to make the world better that's that's what people in
general want but there are some people who say that the world is made better if women stay covered
up in burkas and can't drive right so that kind of comes down to yeah you why what why is your
your how do you how is your vision of the world different from theirs why why is your better
better than their better that's that's a good relativist question so um i would first say that
that that isn't everyone's concern that you know makes the world better if you're a doontologist
maybe you're a virtuosist you're a veneaguist that's not really what you're caring about
you're caring about what's good for you and you know what's good for you it's what makes you happy
the utilitarian would extend that and saying well people they see happiness if they're stopped
from it that's bad presumably being forced to live in a cloth bag when it's 120 degrees out in the
desert makes you unhappy presumably being shot in the face for trying to learn to read it makes you
unhappy so that if a consequentialist would say uh if you have to shoot uh someone in the head in
order to prevent all of society from disintegrating and us reverting to the level of barbarism that
you see in uh the movies yeah okay yes yes let's say we're we're losing half of our children before
the age of three to disease and there's people starving to death at fairly regular basis and
the only way to prevent that is to keep society strong keeps civilization running and that requires
making sure that a certain subset such as the ones with female genitalia don't know how to read
that is a worthy sacrifice right yes but that is not the the world in which it's like that that
changes what we were just talking about like so the the the world in which this is actually happening
now isn't that world right right so the problem is they're actually wrong or they don't even believe
wait like that long story promise to get laid out right i think a lot of them do they think the world
will fall apart yeah i thought they're doing it to keep their society strong because if they don't
society collapses i think i think they're mistaken about what makes a society strong well yeah i mean
it's impossible that people are coming from that angle i think we hear some of that from people
yeah my assumption is that in general people do want the world to be good they just are mistaken
on on what makes the world better okay i thought you're making a different argument so like good
is right well so i thought you're making a different point to like the the abhorrent conclusions
of some utilitarian calculations if you haven't played the game the last of us skip the next 30
seconds it's a long awesome story of the the main character and the like teenage girl like that he's
companion with he loses sometimes they're doing the thing at the end she's captured she has a resistance
to the zombie virus it's a zombie game um and doctors are gonna fungus yeah and she she has an
immunity in her and they're gonna the only way to get it is to cut it out of her brain and that
that kills the person so uh that would be the right thing to do they can cure the they can cure
the plague by killing it would not only be the right thing to do but there's a strong suggestion
that that's what she would want to do if she was caught if she knew about it yeah
double spoiler alert the protagonist of the game does not agree anyway so i thought that's
a fitting answer of the pugnic conclusion yeah takes her away and doesn't tell her about it
in order to save her life against her will okay and i totally disagree with his with what he did
because that's not it it's not a consequentialist or it is consequentialist if what you're
valuing is that one girl's life it's egoist in that case i think i think every basically every
human would agree with you that that was an immoral act and yet i've found so many people who think
it's an absolutely moral act and i think that they're probably virtue ethicists and deontologists
i think they're most of the egoists because in the game he killed a lot of people to get her out
of there oh he did so they're not deontologists and they're probably not virtue ethicists how about
care we didn't talk that much about um care ethics so i think that that was maybe that was that
cared about her in fact she was maybe the only person that he cared about
so everyone else didn't matter that's right yeah so care ethics is smaller utilitarianism bigger
egoism it's you care about the people in your network whether that's you know it's as big as
you want it can be me and my two best friends it could be me and my entire family me and my
family and all of their friends it's a lot of crime families work yeah and within the family
there's a very very strong moral stuff but anyone outside the family they're you know their marks
yeah they don't matter and uh it's it's essentially i guess how utilitarian would act if the people
outside of their sphere of concern didn't matter at all or not even didn't matter at all but mattered
significantly less so like if they were bacteria or something yeah or i mean maybe that wasn't even
quite fair it would be you know like a utilitarian might care a lot more about people than they care
about uh you know cats or dogs um do you think that the protagonist in the last of us was right
with what he did no uh hell no i don't i definitely don't think so but i think i'm on a youtube video
as it was somebody who does a great deal of um of video game commentary disagreeing with him about
that because he was like yes it's absolutely right how honorable how you know cool see that
that strikes me as some combination of of deontology and command so i think that's this
where people get tripped up on using words like right um that's what that's why when i'm using
outside of this conversation i i almost never used the words ethics morals or not even right
and wrong unless right and wrong or pre-established to me making the world a better place and that
kind of means exactly what your intuition think like what your intuition says it means uh where
people are more free to meet there to to do what they want enjoy themselves achieve their goals
whatever it is right the girl was his daughter right not some girl but the girl was not his
daughter oh no no relation i always thought it was his daughter nope okay i think it's care ethics
it's care ethics it's care ethics and i think it's also i think that there's there's a certain
extent that he was willing to go to and um to cure the world of of this horrible zombie fungus
and um losing this person that he cared about was not within that yeah so he's a bad utilitarian but
possibly good care ethicist bad utilitarian bad yeah and you know even even people don't like
utilitarians would say you know look uh if you could do this one thing that even ruins your life
and kill somebody and it saves the world you should do it everyone everyone says that there's
probably people out right are you you on slippery slope grounds and be like well then why do you
draw the line between that and killing a healthy people in person and taking their organs to cure
five sick people right i think you draw the line i mean at least in this case you draw the line at
being one person this one time to save everybody whereas like if we lived in the world so that
the one another you know alluded to another common thought experiment against consequentialism
baby chorisa what's baby chorisa oh it was the first it was the first chapter in the book you
lent me today steven i haven't read it in almost ten years baby chorisa was um an acephalitic
baby so um or ancephal oh no the winds are happening again
it's either ancephaly or acephaly but the point is that the baby is born without the majority
of their brain oh sure so they're born with the brain stem they're able to breathe and do um
impulsive reactions but there's there's no thought there um because because most of the brain and
the top of the head is the top of the skull is also missing so the question the parents wanted
their baby their baby whose name was chorisa her organs to be harvested to save the lives
of other babies yes and thus started the massive ethical conundrum that made it into this philosophy
book yeah and that that's a that's a different case uh than than the general main main criticism
i was going to bring up but that is important and that that raises the question of like what do we
have an ethical obligation towards like you would think any parent that would do that with
their healthy baby would be a monster well there's five other people here with sick babies i'll let
them go and just cut mine up and give them their organs that's that's all kind of screwed up but
we don't have i think the parents and the doctors involved understood that at some level we don't
have an ethical obligation towards this human it doesn't have anything that's like to it doesn't
have any consciousness doesn't have a personhood um so the the standard conundrum goes you're
visiting the doctor you're perfectly healthy is you katrina and uh you're visiting at the hospital
for some reason because that's important for the thought experiment because it happens to be that
there are five dying patients and they all need a different organ and they're all your blood type
and your doctor's like well one for five this is i i would i would try to switch on the trolley
problem i'm gonna go ahead and do this there's an obvious answer to that if um all of those sick
patients are going to die then sacrifice one of them should either they should draw straws
or one should volunteer to be sacrificed for the others since they're all obviously the same
blood type two if they're the same blood type as i am and that way and they all have different
organs that are failing and other healthy organs yeah one of them should die i don't have to even
be involved in that situation i stay healthy that is that is the most practical answer i've ever
heard to that but that was awesome you just came up with that right now on the fly that's actually
tim's answer oh okay so and that's a good answer but like to make to make the thought experiment
do its legwork imagine the least convenient possible world right so they're all dying of
some mysterious bone marrow thing and you have the same you have a matching bone marrow type
and they need all of your marrow it'll kill you to give it up but it'll be enough to save all of
them but they can't donate to each other because they're all sick okay that's always the case right
so i could give all my bone marrow well bone marrow you make more of they need a little bit
right now you're gonna get sick and die the point the the idea i know i know i mean there's such a
temptation to try to duck out of these when there's an obvious solution right um i think the standard
reply is that uh it has more negative consequences because then people simply stop going to doctors
because they're scared they will be harvested and killed and so the whole world in general is
worse off since no one ever gets any medical treatment at all exactly so that's that's that's
what i was going to try and go is the standard room but i do like your way of destroying it because
it was a it's a it's a that was baller it was baller as hell um credit credit to tim um if you
see him again before we see him which is probably going to happen let him know that we think he's
awesome okay so the the main critique of of consequentialism that you keep bringing up is
that you can't predict all the consequences and yet in this thought experiment they stop at like
you know two days later not a month later when it turns out that people are freaking out that this
can happen um so part of it is considering the long-term consequences and as in as much detail
as you can um or as reliably as you can i was just so the consequences it's um it's kind of it reminds
me of economics and economists trying to pitch important um tax policy changes to a focus group
i guess this is a planet money thing recently i didn't see it but i heard about it second hand
i've probably heard about it because i have heard every episode of planet money okay except for the
truffles one that's just a recent all right so did you know i think it's planet money and it might
be something else with money in the title that is also a popular podcast but i think it's planet
money um anyway they had economists from all over the board um all over the the right wing left
wing in the middle talk about different policies that they thought everybody would agree on i know
all economists would agree on and they came up with six and but they talked about why also it
would not be it never be proposed by a politician because reasons why all of them would be very
unpopular then the next phase of that was to try to pitch it to a focus group and i think what and
tim was the person who told me about this and he said that the frustrating part was that the people
in the focus group could only think of the first step they really had trouble uh conceptualizing of
any further implications so they could only think of the first part so take away um mortgage interest
deductions right but but then we won't have those deductions but then the cost of owning a home will
go up and that's it that's that's it that's as far as they could go conceptually um these these lay
people in the focus group anyway i was thinking about that um a lot of times when we're doing our
consequentialism as as lay people we can only think of one or two steps out right is that what
she was yeah exactly and i that's a really good example and i like the uh the the sad reminder
that the lay people aren't the best at thinking long-term prediction wise or long-term consequence
wise um and that that derailed me a little where were we as was pointed out on who's day yes we
know yeah yeah yes um unfortunately unfortunately this is true and that's why it turns out that
voting's a problem but which we have an episode about that's right that tim was also on uh not
that he's on this one but his voice that i'm remembering is on it uh he's on this one in spirit
in spirit uh what you were talking about steven is you know the people harvesting the bone marrow
organs or whatever um they're they're thinking it's hard to think beyond the first step of there are
five people who will survive if they have this compared to the one person the one healthy person
right it's not a standard trolley problem because there are there are other things to consider
outside of that absolutely um someone might consider like well what if it was done in secret
just once um so this i don't know what peter singer would say who might be a you know dedicated
utilitarian i would still say that you're doing something wrong by you know hurting that one person
you know maybe give them the option to donate what you know if they if someone is a kidney
well i've got two you know um the the what why can't you do it just in secret one time so it
won't ever have any effects except for saving you know four extra lives right is uh one of the
reasons that again i'm going to beat my personal hobby horse since i like virtue ethics is one of
the ways that i think virtue ethics has a leg up here because virtue ethics says that a person who
has the virtue of of not uh falling into the trap of killing people to save five and making the entire
world worse is someone who even when he was given the option to do it one time in secret to save
five people still wouldn't do it because that uh that revulsion in him of doing such a thing would
prevent him from doing it so the the one case that we want to avoid is avoided because of his
general desire to right but while we expect doctors to not make that choice to follow the
Hippocratic oath yeah right we expect that of doctors but there are plenty of people in the
world who we expect to make the choice of killing people to save others to save more people potentially
so rarely works out that way um and that's totally acceptable to us and that's within the
ethical schema is to have soldiers go out and and be honored for killing in order to save others
right or to save other interests or you know for whatever reason it's i i guess it is assumed by
people that someone made the calculation somewhere and said that the best way to preserve social
stability or our national interest or whatever it is is that we have to sacrifice x thousands of
people in war and that is better than the alternative consequence so we expect some people to use
x ethical system in our culture and we expect other people to use y ethical system in our
culture depending on their profession um i'm not sure about that like we expect soldiers to benefit
to like the command on high yes but i think that you want to do it with the commanders to kind of
be utilitarian and the commanders to be utilitarian and we want our doctors to be deontologists well
our doctors we also want to be utilitarian we've just made the decision that the best utilitarian
option is for them not to sacrifice the healthy person because then the knock on effects mean
everyone is forced off friendly reminder that there is a popular version of utilitarianism
called really utilitarianism yes that would let us know you're driving towards the consequentialist
and and not do this but the deontologists would also say absolutely not um it works it works in
both there's a lot of overlap so the and that that's kind of one of the themes of moral philosophy
right that they tend to go the same way like so the deontologist we mentioned the the categorical
imperative the other um so there are two formulations of it and it's supposed to be the
same general principle and these two derivations the other one is that you never treat people as a
means to an end they're always means themselves people being rational agents um if you're going
to sacrifice somebody as an as an organ farm you're using that person for for other ends not for
and they ask their own ends right what if you're using someone to help harvest your crops uh so
that that's kind of one of the problems again technology is kind of easy to poke into right
so like you know you're briefed at starbucks you're using as a coffee delivery machine right
you might ask their name and talk to them but for the most part you know can i get coffee thanks
bye um they're they're they're just coffee pots that you have to talk your order into right so
if you're not caffeinated if you're not caffeinated in the morning that's how you feel
now but you know you you it's okay and society recognizes that like you know you're not talking
as ending themselves while they're they're doing their job and just like you would society does
much smaller more close to society that would be considered extremely rude if you don't stop
by and talk talk with you for five minutes when you get your coffee for sure uh i also wouldn't
expect you know they're they're seeing me as you know a means to bring business in the company
they don't care what i'm doing there they're transaction they're transactionary relationships
right and then there are other kinds of relationships anyway there was one last point i wanted to make
on moral philosophy which was i sort of made the case that i feel like under the surface most of
these approaches are consequentialist at the bottom virtuosists argue for virtue because it
tends to work out well the dentologists the the maxims argued they're argued for there are argued
for because they tend to work out well um if the if the maxim was it's okay to steal go forth and do
it all the time that would be chaos so that wouldn't be a maxim that you could universalize i think
this is going to be the stretchiest one of these i think even the relativists could be utilitarian
at bottom or at least could be consequentialist have a consequentialist consideration because
the problem if we're to say our society is better than theirs well then we can do what we want to
impose our will on them and that might involve killing a bunch of people and that's bad so we
shouldn't so let's just stop it at the bottom and say we can't say what better that might be where
that is kind of going i was got some pretty decent steel mining there well i'm i'm also saying that
they're being inconsistent that they're being consequentialist and they're not being relativist
right so that's some good decent steel mining we will argue that uh their ethics are just as
good as ours so that we do not have to have this war where we kill a lot of them in order to impose
our morality i think that's sort of like the yeah we're saying we want everyone to get along right
yeah i think that's the fear that underlies most of more relativistic thinking that uh especially
you know like after a couple of bad centuries of imperialism by europeans and stuff it's like okay
you know what we can't just we can't say their savage isn't bad anymore whereas i would i would
argue that you can say that they are bad but you don't necessarily have to go and impose your will
on them you can use a softer form of power it's it's interesting right so i think like providing
birth control yeah steven pinger i think what steven pinger gave the analogy that if you learned
that one person held down a screaming five-year-old girl and cut her labia off with a with a sharpened
stone god i don't want this to be an episode all right well let me let me rephrase that if you
learned that your neighbor or if you learned that one person held down a five-year-old and
performed the procedures involved in female dental omethylation oh god there you go colloquially we
can't use that word sure we can it's the reality we can if you're squeamish about it we can say
it's a female circumcision it is a real thing it's a real thing it's a horrible thing about
facing so if you learned that one person did that the only question to ask would be you know
would life in prison be a severe enough punishment for him if so then if you learn that a million
people are doing it then then if thereby becomes culture and is magically above criticism i don't
think it's above criticism at all but the relative this does i don't think that's what's
happening in that situation either for why we why we feel that way about your neighbor doing it
versus a culture doing it doesn't have to be your neighbor it can be somebody in another culture
but if it was just one person that it's it's it's terrible it's a lot of people it's somehow if
it's one person it's easy to dissuade that by taking by throwing one person well that's one
way is to take them out of the culture the other way is to make sure they can't do it again in some
other way but we're talking about the gravity of what they did but yeah and and you know punishments
that are uh not atypical in cultures where that practice is also involved we're having emotional
reactions right now maybe i and their emotional reaction is appropriate with something that terrible
maybe i'm strange in that i think that if somebody does something horrible that the most
important thing is making sure that they don't do that again i don't think you're strange i think
you're just better person than i am instead of and i don't actually really think that people
should be punished if it can be avoided i i yeah i know i totally agree that's where i'm at all
that's where i i think a few weeks ago i made an argument that said i wouldn't kill a day you're
saying uh if there was another way to detain it right so yeah the important thing is to stop them
from doing bad things or the consequentialist is famously against the death penalty or reform him
right and then he can go out into the world and do good right and be a good person and maybe feel
so bad that he spends the rest of his life atoning and making lives better that's i mean that's the
punishment part is that he you want him to feel terrible like what if he changes his life and then
he can feel good about himself because he is actually making people's lives better no i totally
agree isn't that isn't that the nicer thing that is the nicer thing i isn't that better than i do not
have i cannot in my brain model someone who is a good person who knows that he did that in the past
that wouldn't want to atone for it for a long time if he didn't try to atone for it i wouldn't come
atoning is different than like hating yourself yes right did i use term hating myself you said he's
going to feel so terrible about it for the rest of his life and that's i guess i did say that didn't
i i meant he would have a strong uh desire to atone for his past actions yes as as one should
where were we oh yeah so uh i was gonna say the difference between the one person doing it and
the culture is you have to take a different approach to the culture because you know like
throwing people throwing everybody in i mean i guess that probably would help but um but you
can't it takes a lot of resources in order to yeah assault a million people and throw them in jail
and they're gonna resist and also that would be incredibly disruptive to their entire society
to have most of the people thrown in jail at that point that's just it seems to me the person who
says and therefore it's their culture and it's okay is someone who is blinding themselves intentionally
instead of saying this is terrible but we're not going to do anything about it because the costs
are so great we can't they they say oh but it's okay and i i dislike that sort of blinding themselves
yeah i think that that that is the blinding oneself to that consequence that the relativist
is doing they're not they're not saying it's it's wrong and i wish we could do something about it
but they're saying if i could press a button that stops them from doing that i wouldn't because
it's their culture you know and that that's the that's the weird thing that like philosophy in general
kind of has this problem but especially ethics like we're just talking about like the average
person on the street um everyone's a moral philosopher right um but well that i said that as a
joke and it's kind of my point that people people seem to think that in some weird way that like
peter singer's opinion on what's the right thing to do is worth just as much as you know
all that daddy's opinion of what what the right thing to do is and or what their opinion on the
right thing to do is right in a way that like we don't do with any other domain right uh my opinion
on physics is worth less than steven hawkins and no one would be tempted to say that well no we
should we should hear zuber out maybe he's got something to do this no he he doesn't not he
doesn't hold a candle to people actually know what they're talking about i think people are talking
about that with cons though where or i was like but this seems ridiculous this seems like this can't
be what his actual position is and then um i think he said something like yeah well i mean either of
us are famous philosophers and contests so and i said the tongue in cheek i i yeah no i absolutely
didn't mean and therefore we should take him seriously um i meant that as a point that philosophy
has a bad time pushing out stupid ideas so yeah no i i when i said that if you took me seriously i
didn't i meant that as a complete joke yeah we're not famous philosophers that actually sounds like
a somewhat serious argument though con was smart in a lot of other areas so that that i think is
the main reason that he's popular was popular and still is universal that universal universalizability
is that the word yeah it is actually a pretty important concept i don't think that was his
wording that came around a few decades ago but the same idea um is somebody trying to interpret
his wording it's it's desirable but it it's not the kind of thing that like actually works for me
think about for five minutes and there are there are other versions of the ontology i know less
about the ontology than i do about consequentialism utilitarianism and virtue ethics mainly because it
seemed on its face so ridiculous that i didn't spend a lot of time doing it and the primary and maybe
maybe you should well the prep the other reason is the the primary source on it con is uh notoriously
hard to read in a way that seems like he was going out of his way to be like confusing well i think
we learned a lot one of the things that one of the things that we learned is that i will no longer
call myself a moral relativist and that apparently um morals and ethics only apply to rational actors
and i didn't realize that before and that the kind of rationality that um animals have is different
i think that it applies in this extent that you can blame somebody for doing something wrong
okay so like and you wouldn't blame a lion for doing something wrong no you might you might analyze
it like man it really should have eaten that that pregnant gazelle because it was full of you know
extra food um and easier to catch exactly so uh and you might say it was wrong to do that because
it's you know lowering the chances to getting food next year but like it doesn't know it's just
doing what lions do um so that i think is why the the capacity for reason is stressed so much in
that field the last thing i was going to say is speaking of like rehabilitating people as far as
whether doing something wrong that is the only i think same way to deal with transgressors is to
rehabilitate you can there are like four ways that you can there are four theories behind punishing
people for doing something wrong the one is retribution you know i've or not you hurt me i'm
going to hurt you back just because that makes it fair and i forget the other two and one the other
one is rehabilitation you hurt me i'm going to try and make it so that you don't do that again
one of those other two is deterrence right i'm going to hurt you so other people will see
that this is what happens when you do this sort of thing right deterrence and then remove you from
society because you're a threat in the danger so um so we have removal deterrence rehabilitation
and retribution retribution yeah retribution is the only one that i really have a problem with
i think there's a lot to be said for deterrence and there there are people that need to be removed
yeah you said like you know some people feel bad about what they did and come to terms with it
some people lack that nugget that lets them have compassion uh there are broken people out there now
if we could fix that that'd be great but since we can't we're going to just keep you over here
behind these walls where you can't hurt regular people um like that's unfortunately the best we
can do you know we'll try not to torture you while you're in there but being a bit of a
bio-relative this i'm not bio-relative this bio-determinist myself there's something to be
said for uh at some parts in people's lives they're just much more violent and if those people you
can remove them for the decade or two that they are violent afterwards when they come out they aren't
as bad you know like boarding schools for teenagers with you know thick walls and locking doors
something like that for for people who have violent inclinations and i've met one or two
there's actually for some of them uh going into um military is is actually not a bad career
choice because that's the where they can get out there aggression yeah when i was uh probably in
middle school so when i was a preteen i was going through all of those different hormonal changes
and i remember having been really disturbed because i had violent ideation so i would be
walking down the hall and i think i just want to punch somebody and i think oh what a horrible
thing to think i'm a monster and those thoughts went away uh and i was just thinking about how
how you would talk to a young person or a kid and just be like hey let's talk about ways to deal with
these feelings for now in ways that don't involve actually being violent and then kind of let them
know that they'll probably pass how strong was your urge to actually do the violence i never hit
anybody yeah but um i was you know mostly it turned into self uh just really low self-esteem
and like self-hatred because i had a lot of uh violent visualization when i was a kid i just
like i'd be cool to mow down everyone in this hallway think of all the bullets flying in the
blood and everything you know but it was never a thing that i would act on and i never felt bad
about it because i was just like that's what guys do right we like action movies this would be really
cool looking it's like i was actually gonna kill anyone and were you like ever you never thought
you were going to no so did you just i don't know and now i wonder if that's like a gender thing i
had some deep like feeling like i had i wanted to punch somebody and i i never did it and i you
know i didn't even swear at a person um until i was in eighth grade once but yeah i think boys
might be taught to embrace their violence sides more it's possible i think i was also i was in
my head complaining uh ideate or ideation ideate people say in different ways yeah and visualization
and you guys talk about two different things i think they are so uh so i mean um i also had
plenty of visualization um i read a lot of fantasy books right and i would you know imagine different
things that were happening in those fantasy books and um if people were mean to me i would imagine
you know like the the ceiling falling in or whatever but the desire the strange desire
to to hurt somebody um that came from a different place okay and did you feel like it was deserved
though like someone had done something bad no it wasn't even for a person it wasn't even for a
specific person it was a i want to punch someone oh okay i must have had a different thing than
you then it was just like um it was just basic directionless violent feelings so i think i think
the takeaway is that it does happen quite a bit in teenagehood though i think it does i i like to
think i'm a very peaceful person and i like to think that i'm not the only person that that happened
too no i think you're you're pretty super peaceful and if it happens to you it happens to
everybody i'm trying to think of exactly specific times my memory sucks um yeah you know where maybe
an example you know someone pisses you off in traffic or maybe like is it have to be directioned
or is it just like in general like i would just love like just to just plow through all these cars
with my car right now like that kind of random thought my experience was directionless yeah if
it was a specific person then it is a whole different situation so it was just like a flash of
rage and desire for violence yeah but happened regularly for a short period of time and i was
just thinking if i were in it maybe if i were in a different situation maybe if i didn't have um
all of these other reasons to to not be violent maybe if it was even encouraged then things might
have turned out a little bit differently and good training and impulse control i assume
i decent impulse control i've never had good impulse control who am i kidding
all right um so yeah we made our at this point we've already made our conclusions we got a
little derailed and then i'm not sure if this is gonna seamlessly transition or not but here we are
we've wrapped up uh we didn't have any really listening feedback that we had stuff to comment on
so um no listening feedback section on this episode you can never tell how long our listener
feedback sections are going to be that's right so anyway this was a little different it was less
of a talking about you know a thing and from a rational perspective and kind of just laying out
stuff but i wanted to try and apply some reductionist thinking to what can we take apart from all of
these in a way that is actually useful maybe we'll attack a different philosophical problem
another time see if we can get to the bottom of free will or oh god no something come on that's easy
um all right so anyway thanks for signing up thanks for listening yeah come back in a couple weeks
and uh that's that bye bye
