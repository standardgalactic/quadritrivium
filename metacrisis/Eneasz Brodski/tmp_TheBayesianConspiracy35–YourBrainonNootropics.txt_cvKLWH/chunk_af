i think 23 of the 24 games were identical and they ended in ties okay so like there's it is it is
one of those things where yeah like tic-tac it's like a bigger tic-tac-toe board where it's just
like this is there's there's not enough search space to make this interesting okay so now onto
an actual question that we should probably discuss for a little bit uh google plex bite asks
i've always wondered about paperclip general intelligences why does the paperclip intelligence
care about making paperclips it just needs to convince itself it's doing its job like bending
and unbending the same paperclip over and over or erasing the memory of making the paperclip and
counting the first paperclip it made over and over again so this is going to be an ai theorist kind of
big problem for me like just to my my initial impression is that it's never it doesn't care
about making paperclips in the way that we understand the word care to mean anything
it's basically tell it make paperclips for some idiot reason and it's like make paperclips you
got it that's my only value and so that's that's my purpose is to you know cut butter or whatever
you pass butter oh my god whereas but that nobody even had the the the mental faculties to be
horrified at its life right we're talking about the butter transferring transport a robot from
rick and morty um which everyone should have gotten that reference yes uh you didn't get the
reference you should stop listening to the show and watch all rick and morty right now way more
important yes you can get through it in a day there's only a couple seasons so i think the the idea is
that why wouldn't it just trick itself to think it's it's making maximum paperclips i mean presumably
because you asked you you asked it to do the job right it's like if i asked you to help me move
you're not going to carry the same box to and from the truck right i think i think that some
paperclip maximizers might do that i mean it's possible that something could just modify itself
into cheating but on the the purpose is not to set to create this paperclip maximizer the purpose
is to help you see how it could go wrong yeah exactly through that i think that you know it
still stands that the paperclip machine is a pretty good example yeah of things that we didn't expect
to go wrong all of a sudden you have a universe of paperclips it may trick itself but it's easy
to see how if it didn't it could really go right and i mean it also depends on how well it's programmed
because a lot of humans trick themselves into feeling happy wireheading or whatever just using
heroin all the time and a lot of other humans are like that is i don't i don't really care about that
trick i want to actually do something that is that is purposeful so it depends on how good it is at
seeking out its actual goal if it's just a number that is trying to increment then yeah maybe it's
busy to to hack it and it's useless but maybe it actually for some reason cares or or wants
has a drive for there to be more paperclips much like humans sometimes have a drive for
i don't know creating a lasting legacy or having children that like them or whatever
shit people do totally but the whole purpose is just to say like hey this can go wrong can you see
can you see how it can go wrong yeah oh okay this is just a fun one senju says hey there's a project
where they're gathering data on what humans would want self drive and cars to do in trolley problem
like situations and he attaches a link which i will attach as well to the episode when it goes live
on the basingconspiracy.com but yeah i played with it there's 13 questions and they're really fun
it's like do you think this car should run over two dogs and a doctor or three old ladies
it's funny it was it was just it was fun to play through and then at the end it gave me some statistics
as to you value rules more than you value this other thing based on your answers and you apparently
value homeless people less than you value educated people which i was like you got me there
i'll definitely take it if it gives you like slap in the face results like that as far as like
useful implementations i was actually talking with a couple people throughout the show before
about this exact problem like trolley problem trolley probleming with self driving cars and
one of them was just super pissed about like why are we even spending a lot of time burning fuel
on this like this is not the considerations we should be having he he gave this one example
is like if it's going to drive me off a bridge to save three people it might as well just kick me
out and drive itself to a factory for itself and give it money to ea charities
but um i think i think the general point is that like you know whatever it is the death toll
will be so much less than it is now and like you said it's gonna it's not going to be operating at
the same speed that we're gonna be operating at it can stop faster uh there's also the question of
like why should i die because a family three is stupid enough to jump in front of my car
but i mean in a perfect self driving car shouldn't have trolley problems no right you know it should
it should say all right there's two dogs and a doctor and it stops yes or slows down enough so
anything that random might occur it yeah and that's hard for us to kind of think about because
we're thinking if we were in that situation you know we'd have to think about it um but if you
look at like some of the tesla ones they predict crashes before you can even think about there
even being i've done ones where i've like watched the videos multiple times and you just can't
tell that a crash is about to happen and the car has already realized it oh fantastic that's
reassuring i think i thought one of my uh really oh this is cool moments was when uh the car stopped
and wouldn't go forward at an intersection because its radar picked up a bicyclist behind a hedge
which the human couldn't see because it's behind a hedge it's like this is awesome because they can
see through walls yeah i mean they have they have radars or light ours um they can bounce them
underneath the car in front of them yeah they have perfect perception of of the world got that's
the immediate world around them and yeah i think a lot of people don't realize i think taryn i like
the way you put it trolley problems aren't going to be a thing yeah when this when this gets out
there speaking of which that was my least that was my most immersion breaking point in logan
when this isn't spoiler oh yeah the self-driving trucks well no i was finding the self-driving
truck so i didn't like was how they honks and said please move out of the way
they're stopping it's like no no you're not going to have self-driving cars barreling down
the highway carrying cargo and i can just be like moved and i they're gonna stop in our world
obviously but uh the i interpreted that as a world building detail where the director is letting us
know we live in a dystopia where corporations want they value the five extra minutes it takes
their product to get there more than they value the lives of the people on the street and they
just program their resting commentary and they've got to the laws yeah yeah that's actually that
that the the dystopian idea came into my head as i was formulating that but you put it really
poignantly and that's that's a that's yeah right fair enough thanks for rebuilding my immersion
from the ground yeah no problem all right we're saved so go see logan now it's now it's literally
hunted out of really good but now you just spoiled logan so no one wants to see it anymore oh god
they're self-driving cars oh this is a fun one and this is also the last one a gnome i believe
it's gnome on our website said i wondered about your approach to the idea of a race of super
intelligent ai of humanities making inheriting our place in the future i find that notion to be
very comforting as it describes a future in which even if humanity fails to make peace amongst itself
and go on to explore the universe we have left a better being to go on in our stead i find that
many people have very low expectations of humanity's ability to not annihilate itself within the next
few centuries and so if worse comes to worst the idea of humanity leaving behind a consciousness
that suppresses it is quite fetching i think i mentioned this on the show that one thing to
grapple with is that we might be making sentient beings that matter in every way that we care about
way more than we do like we like we matter more than ants i think i said something like that
this isn't something that i want to happen because i really care about my own persistence so yes it's
better than nothing like say if they turned us all into more computers think more of them out of
i mean you know it i guess it's better than a universe where all the lights are off everywhere
but i am not a fan given that like all of my values are kind of tied up in humanity and if
that's extinguished to make room for this cooler thing well then we're still gone right so that i
mean i don't know how coherent that thought is but like i guess the takeaway is that i for me i
feel like it could be worse but it's not desirable so i i have a take on this uh being that i well
first of all i i put my own life at a very high priority level so if something were to come along
and want to disassemble me to use me for parts i would have serious problems with that and you
know try to try to declare war or stab it or whatever i need to do to get this computer not
to take me to pieces because i like living uh but that being said if we're assuming i have to die
eventually at some point and we have descendants i mean that's basically what all of human history
has been right you you're gonna die anyway so you have kids and you hope they carry on the the legacy
and uh i find what he says right here to be very beautiful and romantic in that yes i would like
my descendants to be better than me more moral than me smarter than me stronger than me lives
live a better life and if it doesn't matter to me if that life is you know in a fleshy body or if
it's in a robot body or if there's no body at all it's just distributed across the internet and
various probes are sent out or whatever i i'm i'm not a as i believe they call them carbon
chauvinists where my descendants have to be made out of a carbon in the same way i am uh i'm totally
fine with uh with that sort of ai coming afterwards and taking up the mantle for humanity the problem
isn't that i don't want ai carrying on our legacy and you know hopefully we would be able to coexist
for as long as we can coexist until the human species eventually goes extinct uh that that
is not my worry the worry is that if we create something that takes over for us for it to be
recognizably human if this is a i believe the term i heard someone used before god i can't
remember who it was now a disney land with no children if it is a machine that is like
reproducing these environments and making wonderful places for humans to live but there's
nothing sentient there and it's just making stuff without anything that can enjoy it yeah
that's that's that's a future without any value there there needs to be
something that cares and feels and thinks to inherit it and the the the fear isn't that an ai
will take over for humanity the fear is that there is going to be some sort of machine that
inherits our place but that machine does not have any consciousness or feelings or if it does it
values things that are so orthogonal to us that we just don't see any value in that that they just
want to make paper clips or beautiful carbon crystals or whatever and there's there's nothing
left to pursue anything that we find valuable that's a much more refined version of what i was trying
to say like like if it carried on and it was just us bigger and better than i guess again
aside from mourning the loss of my personal existence that would be i guess somewhat okay you
know or or super awesome depending on how exactly that worked out but you're right like it could be
i'm picturing i forget the kind of wasp that like builds these cool little like clay vases that it
either like lays eggs in or whatever they do lives in and i'm imagining in the head of that wasp
there's not much going on it's just doing what it does it's doing its bossy business and doesn't
it's not thinking and i mean the evidence for like a lot of animal behavior especially lower
animal behavior just being complete autopilot all the time is pretty overwhelming yeah there's
i think you're you're in the distinct minority if you're gonna say no no it's reflecting and
thinking through things like just like you are it's definitely not or it's it's unreasonable
for you to say that it is anyway so we didn't talk we didn't throw around the word the c word a lot
in our ai episode consciousness um which is the c word when you're having a philosophical discussion
because it's um it's this whole other topic uh you know it is completely conceivable to me that
you could have ai's that would be just like this wasp they'd be building super awesome cool stuff
but there's there's not the lights aren't on in its head and there's no lights on in the universe
for to enjoy its creations yeah but it's it's just going to keep on plugging away because that's
what it's supposed to do and there's been a number of great sci-fi shorts that take that
concept they're um swarm by uh bruce sterling well i had that where the there's an erase of
somewhat insectile uh aliens which don't have any sort of thought process but they're reproducing
just taking over the the galaxy uh and um most famously recently uh blindsight by peter watz
is the same sort of thing with aliens that can optimize their environment but don't think
and we could conceivably make an ai that can do that sort of thing but doesn't have thoughts
also we could conceivably make something that does the exact same thing and we can't tell right
you know we honestly can't explain consciousness in humans to on even the simplest level like we
don't even know where to start as far as consciousness goes to sort of create a machine and and assume
that it's not conscious on any level i see steven waggling his head and i'm kind of oh yeah i'm
going i'm going with him on this there's a long running debate on whether you can make something
that acts identically without it actually having the same thoughts and we'll have to do a whole
episode on p zombies someday we'll do that but i was also just going to say that it's not that we
i think you came off a little too strong it's not that we have nowhere to start and we wouldn't
even know where to begin talking about these things we have we have some idea where we don't
have a full picture yet yeah so to say that we have a sample size of consciousness of one
yes you know and and not even one as in like a communal one like each person can only experience
a sample size sure but but to say that we have no idea of what we're talking about would mean like
it'd be equally realistic for me to say that you're conscious and the chair sitting on his
conscious like if i had nowhere to start those claims would be the same or have the same level
of probability right which i don't think is true i think that there's i assigned a much more
a much higher probability of you being conscious than i do of the the chair sitting on being
conscious well i mean like the whole problem goes back to whenever you say conscious what do you
mean yeah well i mean that's that's why it's such a big problem is because whenever i say we don't
know where to start i mean that whenever you say consciousness you you don't know how to define that
but i sort of know that starting by investigating a chair is a bad idea you should maybe investigate
other mammals well i mean i can give a quick answer that i think is pretty accepted at least
in the the philosophy community that uh thomas negle put forward which was in his essay i think
it's called what what it's like to be a bat and i mean this is kind of our field but this is just
the the the quick flyby of this endeavor like you said you don't know how to define consciousness
there is a loose useful definition that is pretty ubiquitous in the field that if you could transfer
your state of mind into something and have it still be like anything then it's then that's what
kind that that constitutes consciousness in some way so like you if we were to transfer as much
of you as we could into a bat body and or like if you if you were a bat for like we could we could
wave a wand at you turn you into a bat and then turn you back and you could self report about
what that was like you could be like man it was really weird i didn't have thoughts but i had
like these drives and i could see with my ears or whatever yeah there's something whatever you say
you like that's the whole problem is what do you mean you well so that's the consciousness is
different than personal identity yeah uh so though you've moved goalposts but we don't just
want to make that clear okay but okay uh yeah so i guess you could say that something's conscious
if there's something that it's like to be that thing or if there's any sort of subjectivity
that it that it could in principle express i don't think for example that it's reasonable to think
that rocks have a subjectivity but i think that probably anything with a brain does or most things
with a brain do like they have something that's like they again i picture it more like you know
drives like this wasp like it's just doing what it what it's programmed to do and it doesn't really
think about what it's doing it's just moving around and it's responding just to external stimuli
but you know i think this is you know thought experimenty but in principle you can be transformed
into that transformed back and report your experience or as if i turned you into a rock
and turned you back you'd be like did anything happen well no because because i mean a lot
if you think of consciousness as an ability to respond like if you if you look at like eastern
philosophies and stuff like that like they would totally say yeah a rock is conscious
it's just a more primitive form of consciousness because it responds disagree it takes in you know
this chair just vibrated it responded to what i did right i disagree not just with that the chair
has any lower level of consciousness but also that eastern religion says that maybe some of them do
but not as far as i know like buddhism or hinduism well i like like i think if that was um i think
if you're taking as your um your metric of consciousness an ability to respond then you've
redefined the word consciousness to no longer reflect at all what people are trying to talk about
because i mean everything people don't know what they're trying to talk about though i think they
know better they have some idea they they don't think that the ability of matter to vibrate is
what they are trying to talk about at all when they try to try to talk about consciousness
