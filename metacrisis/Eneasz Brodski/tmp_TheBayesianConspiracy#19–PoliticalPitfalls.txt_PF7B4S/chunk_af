feel bad about it. That's something that like thought experiments don't really work on, you
know, so like, you know, would you push the fat man in the trolley? It's like, yeah,
I feel really bad about pushing it. I think, I think that they work on that.
Well, but that's sort of one of the first ones to like kind of not the first ones, but it's one of
the popular ones that pushes on that actual point, right? But in other ones, you know, the, the, a
good example, you know, would you, would you grab a, if you're in the burning building with
yourself and some random baby and a Picasso painting worth $50 million?
You grab the baby.
Do you grab the Picasso because imagine how many lives you can save when you sell it?
No, I mean, I think that's a great point. You know, so like, you're literally,
Do you get a cheap the Picasso though?
Yeah, why in the world would you get to keep the Picasso?
See, it's yours. I don't know. Say, say you had this.
I would obviously not the sort of person that sells the Picasso to save people.
I mean, so I know what you're trying to say.
There's coming down this thought experiment to making it useless. I think the, the best answer
is you bite the bullet and say, look, I can save, I can save this one baby, or I can save
what's 3,500 divided by 50 million or 50 million divided by 3,500, right?
Right.
That many babies. So that might make you the kind of person that most other humans don't want to
be around.
And that, that is the kind of thing that that thought, that that thought experiment will
properly deliver doesn't really consider the fact that I wouldn't be able to live with myself.
Having heard that baby screamed to death while I carried this painting safely out of the room.
So while it has a correct answer, save the painting, I think it's the correct, the correct
answer because you can save more babies with it. But there is something to be said about the kind
of person you would be to be okay doing that and the kind of society we'd be if we were
encouraging that sort of behavior, right?
So the painting allows you to redirect somebody else's wealth.
Or yeah.
Into, into saving more babies.
Yeah. In a way that you wouldn't have access to otherwise. I mean, you can get rid of the
castle painting and whatever, just however it needs to be. It's something that you have that
is worth a lot of money, but it's not like it's not actual human babies, but it's potential human
babies, right?
I see what you're saying. That seems like the wrong answer, but I don't have an answer as to why,
right off the top of my head.
Actually, Will McCaskell had a good comeback. He had this like a date a few years ago.
And he's like, all right, so imagine that I'm in a room with a Picasso and one burning baby.
And right across the street is another burning building full of 100 babies.
And the Picasso is the only thing I can use to jam the door open on the other buildings to let
all those babies out.
He says, that's closer to the actual real world situation that we're actually in, right?
You can save one person for a fortune or you could use that fortune to save 100 people.
I see.
So I think that that's, that's what it wants to get at.
It's not just biting the bullet. It's kind of like deflecting it, right?
Right back at you. It's like, no, look, you're going to say you're going to kill those 100
people for this one. That's fucked up. So that's sort of the turnaround on it.
So I think that that is closer to the real world situation there.
And yeah, you're just not remember why we got on thought experiments in the first place.
I know. It's totally, totally off topic. And when you have a thought experiment,
you shouldn't come up with ways that you can get around the thought experiment
because that's not what they're for.
To the person who asked why we don't die down the interesting topics when they're raised.
That's why you spend 10 minutes talking about burning babies and precautions.
Well, I agree. I couldn't say that.
I guess briefly because this, this will tie this back into what we said earlier
or what I said earlier anyway. Westward 101 also had the question or the statement that
there is a difference between a simulated being and a real world one in quotes that while humans
may be able to map the neurons of a roundworm, we can't create a real world one.
So as a test, I substitute myself for roundworms and I would not want a real world version of
myself killed, even if there was a perfectly good simulated copy running on silicon.
Thanks, Westward. Yeah.
I think we talked about that a little bit. Yes, there's definitely a difference between
a simulated being and a physical being and obviously. So it would not be an equivalent
exchange to kill one for the other. Right.
But I asked him this because we recovered that before that the consent matters,
whether when you're killing one for the other, but I asked him why because I sometimes get
this objection. Why does what material the person is made of make a difference?
Like why is the wet carbon based animal or person superior to a dry silicon based one?
And he had a long answer that he went into, but he originally answered that he thinks the person
proposing what happens on silicon has an equivalent that proposes that what is happening on silicon
has an equivalent value to reality should have the burden of proof and not the other way around.
And what evidence do I have that what happens in silicon matters?
And my answer- Matters period?
Yeah, at all. And my answer would be that I have as much evidence that what happens in
silicon matters as I do that any of you are alive and thinking and matter at all.
And that is only that I can talk to you and it seems like you matter because there is no
as far as I know, and I would be shocked to hear if we have an objective test for consciousness.
Yet there is no way to tell if something is conscious or experiences qualia in any way.
And so you would I would determine if something is as important in silicon as it is in the real
world based on whether it acts like the thing the real world does.
And I think that consciousness is a very useful idea.
So if I were to talk to a computer which said she is Katrina derivative and
acted exactly like Katrina and I couldn't tell her apart from Katrina, I would say like, well,
I guess I should probably value your life like I would Katrina's, at least theoretically,
since you seem to be the same kind of thinking person.
I think that making the assumption that there's nothing magic about the squishy stuff between
our ears isn't like the proposition that needs defending. So like to say that the burden of
proof is on set is on the person who would generalize any computational process to any substrate
seems like saying it's on you to prove to me that the moon landing hoax wasn't faked,
right? Like no, it's on you to prove that it was. I guess I mean, I don't know how you this
seems kind of obscure since it's two future hypothetical scenarios, but one would challenge
current best guesses at reality and one wouldn't, right? So whichever one seems by what we can
agree is technologically feasible. That seems to be the one that needs the defending on saying no,
if you're running on on chips, you're not real or you're not a person, but if you're running on
squishy stuff you are, that doesn't seem sensible to me. Westward did make an addendum to that saying
that it's easier to reproduce someone that is on silicon. And it's as far as we know, there is no
way to reproduce a biological person so far. So ease of reproducibility is a factor, which is one
reason they would value the biological thing somewhat more. I guess that's a point. I mean,
we have no idea how easy it is to reproduce simulated people. Right, since we don't have any.
Right. It would probably be easier than I guess, yeah, we can begin that up in the air, but I
imagine it would be just as easy as doing a data dump and moving it on to a flash drive or a bigger,
you know, another computer or something, right? But maybe it does take a prohibitively large
amount of space, but I don't know why that would necessarily be the case. Star Trek. Yeah.
Okay. Are we done? I think we're done. Okay. Thank you all for joining us. Yeah, thank you so much
for the feedback. As always, you can write us feedback on our subreddits, Bayesian Conspiracy
subreddit, and you can come see our blog post at thebayesianconspiracy.com or write us at Bayesian
Conspiracy podcast at gmail.com. That's all the ways. And at our website, there are lots of links
with every episode to supporting things and interesting articles. Yes, do check it out. If
you find the conversation just, you know, stimulating or fun, and two weeks isn't enough,
well, there's plenty to read by coming to the website and clicking on all those links. We're
always trying to post enough to keep you busy. So until next time. Thank you for listening. Bye.
