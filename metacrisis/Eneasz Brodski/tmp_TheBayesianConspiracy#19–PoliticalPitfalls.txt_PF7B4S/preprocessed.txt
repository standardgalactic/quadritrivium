Welcome to the Bayesian Conspiracy. My name is Katrina Stanton.
I'm Inyash Brotsky. And I'm Stephen Zuber. And today's episode is going to tie over into
our next episode. It's a big topic and it's topical policy.
It's election season in the United States of America.
Yes. Are you doing an Elvis? No. That's kind of Elvis. Should I?
Do you sing? I love to sing. But do you sing is a very interesting question.
Like in a band? No. Okay. Actually, the number of Elvis impersonators goes up every year. Wow. Yeah.
At least it was a few years ago. Maybe it's tapering off. Is there a church of Elvis yet?
Not until the kings take over in New Vegas. Okay. So anyway, it's election season. So
this is a great time to bring up the very topical essay. Politics is the mind killer.
And the reason that Lesseron kind of shies away from political discussion
and not from policy discussion, mind you, there are a lot of economists talking about
different policies. And when you're talking about futuristic policy,
potential, then you're getting into policy. It's really hard to avoid that. But we want to try to
avoid touching on the red team versus blue team kind of politics. I will write the prediction
that somebody will write in pissed about this, or at least somebody will be at home quietly pissed
about this. Something where today has been bugged somebody. But why? People go funny in the head
when talking about politics, right? I would assume that's something we say, because it's off someone
every single episode. That's true. So that's a fairly safe prediction for me to make then.
Yeah. I think that we've established ourselves as not too into one of the candidates.
And it's a specific candidate and his last name starts with a T. And it ends with a rump.
That was unplanned and hilarious. Yeah, we can leave candidates out of it.
Yeah, we don't need to talk about candidates. We don't need to talk about candidates because
just like Eliezer Yuckeski's essay politics is the mind killer. Once you get into candidates,
and it things get a little bit difficult to hold up. And I'm not a good enough rationalist
that I'm going to avoid letting halo or horns effect come over me, even though I've made
strides to not be an either major political party. So that I can get a little bit out of that.
There is still the villainization of candidates. There is the Oh, they said that therefore it
must be bad. Actually, even even on local stuff, there's still that the other day I was looking
at Facebook, and my father is very active in politics. And I noticed that somebody was kind
of talking about the pros and cons of a certain amendment that was being proposed. And my dad
had commented, go take a bath. You're on the side of so and so. So simply by being on the side of a
group that they didn't like on a certain policy issue. Now that guy had to go take a shower.
He was unclean. He was unclean. And he agreed. Oh, wow. Yeah, the next comment was,
oh, gotta go wash myself in bleach. Oh, that's terrible. Yeah. I was never able to
debate my parents into political discussions. I didn't want to qualify one thing, though. I think
while the less wrong community strides away from disgusting politics, individual rationalists
don't and probably shouldn't. If you're if you feel up to engaging in something that
we're really hardwired to not engage in rationally. But if you're up for it, it is important to talk
about. But it's not their introductory topic. There are some people who do. And there was for
a long time a strong was the term social norm that politics was not discussed at
less wrong. Did we want to go briefly into why that was? Yeah. Yeah, what happened?
Well, I mean, nothing happened happened. It's people crying. No, no, it was okay. So
obviously people as we were saying go a little funny in the head when it comes to politics.
Because it is conjectured, at least that this was very important when your entire society was
150 people. And everyone knew what side you were on when lines were drawn and decisions had to be
made. And if you were on the good side of the guy who ended up winning and taking power, then he
would often reward you with things like, you know, resources, things that improved your genetic
fitness in general. And if you were on the wrong side, you might be shunned, you might not get
help when you need help, might even potentially be killed if it is a bad enough conflict.
Are we talking about chimpanzees again? This sounds like the Machiavellian evolutionary theory.
We are right now talking entirely just about humans living in tribes of one to two hundred
people. Because that's exactly what that sounds like. There is this big Machiavellian hypothesis.
And they did a lot of work on chimpanzees as people do in an attempt to understand our human
evolutionary heritage. What was the name of that book? Which one? The one with the two chimps competing
for running the local group, I don't really call it club of chimpanzees. That was mentioned method
of rationality. Okay, I don't know. Well, I'll take it up. It'll be on the website. But yeah,
there's a whole good long book on this that somebody I talked to read at one point and it was
very fun. So yes, I think we are modeling our ancestors like modern day chimps in regards to
their exercising of polygal discourse. But I think it's not entirely wrong to say that being on the
wrong side of a political argument in the past could have had some serious repercussions. Much more
than just discussing whether the minimum wage should go up or down $2. That was nowadays. And
for that reason, people have an emotional tie much greater than what they necessarily should have.
The having observed that, Eliezer in this post pointed out that due to this, arguments are often
treated by humans like soldiers that once you know your side, which you know which side of an
argument you're on, you must support all arguments on your side, no matter how bad they are, and
attack all arguments that appeared for your enemy side, no matter how good they are. Otherwise,
it's like you're stabbing your own soldiers in the back by not supporting the arguments that
support your side, even if they're bad arguments. So if you really are involved in politics,
that is literally how it is. So if you undermine your own side, you could lose
on policy issues that you really care about and that are very important to you.
And that is very much an anti-rationality sort of thing, as we are supposed to
in theory, at least one would hope, assess every argument on its own merits rather than
assess it on which side it supposedly helps. Yes. So as those of us in the room right now,
the three of us, we are not directly involved in politics. We don't have to do that. We don't have
to have arguments being soldiers. We don't have to stand by our strong club so that we can push
through things that we really care about and we have the power to do that. But we're seeing a lot
of people who are in a similar situation to us, not high-level politicians who actually have to
think about this strategically, doing the same kind of behavior where you take party line positions
and you can ask somebody what they think about one position and roll out what they think about
a whole bunch of other positions based on that. And I think the reason that, at least between three
of us, none of us have that sort of blanket endorsement for, well, I'm pro-increasing minimum
wage, so therefore I'm pro all these other things that are not tied to it whatsoever. And I'll defend
those as true even if I don't think they are because that will help my women's wage policy
thing go up. The reason we don't do that is because that feels icky and gross because I have an
epistemic attachment to the truth. And that's also why I left the political sphere. Because there
was some of that icky stuff going on where I was like, this isn't completely true. The reasons
behind this that they're actually using to promote it are not the good reasons, but they're the most
convincing reasons apparently and it's not good. It's really kind of a shame. There's a certain
candidate for a certain party that is not either of the two big colors that happens to be a trained,
highly respected medical physician and yet has had to recently take stances such as,
I'm not sure about the whole vaccine thing. We should look into it because her party line is
her party is very much the sort of West Coast wishy-washy kind of liberal that says, well,
vaccines are terrible. How many people can we alienate? All of them. It's horrible that she has
to say that for political reasons because her party, that is the line of her party. No, I agree.
It's gross and weird. That's why politics is gross and weird and why I don't have a huge mind
for it, which might be revealed over the course of this discussion. Yeah, we're not in politics.
At least I'm not and I can generalize to at least possibly somebody that because the idea of,
if you're a politician, the truth is sort of your enemy, right? If it turned, it can be. It often
can be. If it turned out, if it turned out that whatever, I'm trying to think of a good hypothetical
example. I don't know. Regardless of that, I wanted to get to one other thing, but there is
actually one less wrong trained rationalist congressperson or senator in New Hampshire,
I want to say. What was her name? I don't remember. We'll dig it up, but she's out there and I have
no idea how she's coping with this. I would love to talk about that. I guess you get by it by
thinking I'm doing enough good that it makes it worth being all sticky with lies all day.
So like, it's a very small district. It's probably small enough that she can get away
with not having to lie very much. Possibly. Yeah, I mean, that'd be the perk of doing it in a small
area, right? I mean, but there are so many things that are not political, right? So next episode,
what I hope that we talk about is things that are not brought up and are not politically charged
issues. The issue is that any kind of issue, once it gets into the political sphere, it becomes
politically charged. I have a way better and less inflammatory example to most of our audience.
And it sucks that as soon as something becomes policy, we can't talk about it anymore just because
suddenly it has become a policy question. And that means that it is the mind killer and we
can't talk about it. I think that's one of the reasons that there's been a bit of a retreat from
that stance that we cannot talk about politics because there are certain things that we do
want to talk about that are affected by policy. Like I said, I think it's on a good introductory
topic, but once you've been okay with being wrong a few times, then you're kind of warmed up to be
ready to talk about politics, right? Yeah. But it's not like, hey, there's this cool group called
Less Wrong, and we talk about how this politics thing, right? That's not the best sales pitch.
Oh, okay. Well, in his original post, Politics Is the Mind Killer, there's an example was that
in artificial intelligence, there's a standard problem that's demonstrating the difficulty
of a certain type of reasoning. There's a standard problem that says all Quakers are pacifists,
all Republicans are not pacifists. Nixon is a Quaker and a Republican is Nixon a pacifist.
And his question was, why the hell is that a standard problem that people use as an example
of the difficulty of this sort of reasoning? Why have you thrown politics into this question
so that right away people are polarized and that you insult anyone who leans Republican?
And this should not have been in here at all anyway. Take the politics out and focus on something
else. So he wasn't even saying that no one should ever discuss politics. He was more
saying that do not insert politics where it doesn't need to be. It's a distraction. Yes.
And a distraction that is hugely, I guess, hugely distracting. It's not just like it's
uselessly vague or something, but it's the idea that it's so charged that you're basically
guaranteed to make it inaccessible as a good example for a lot of people. It's like a good
example of a policy that has a political stance is global warming. There is half of the or one of
the two major political parties in the US. If you ask somebody, hey, what do you think about
global warming? And depending on what answer they give you, you can make a good prediction
about what political party or their political in general, right? Like any of those political
questions. Yes, absolutely. Well, so like it turns out that this question has a factual,
saddled answer. And if you're a Republican who otherwise is saying you can't go around saying,
yes, but I'm also very concerned about climate change when you get on this, because then the
rest of your Republican friends are going to be like, what are you sitting on our position for?
That's part of our our platform. Like you're you're stabbing us in the back, right? So that
that's part of what makes this so hard. And these these things, you know, whether you think big
government spending on, you know, etc. is a good thing or bad should not relate at all to your
position on climate change. So that that that to me is always what's been so weird. And
like I said, it's a weird icky feeling that's just repellent to me. And you should be able to like
in your example, if you actually have numbers saying like this very much against genetically
modified crops and the left. That's not I mean, it's the same people. It's the same people as
the anti vaccine. No, there's a lot of people I personally know that are very much against GMO,
which have nothing against vaccines. They're like, yeah, vaccines, of course, science,
it's a good thing. I'm going to say more than 60% of the blue crowd is. Yeah, we can look at numbers.
We can look at numbers. The people who identify more as independent or libertarian, probably not
just, you know, liberal in a social sense, but the ones that actually are Democrat, I would say
more than 60%. All right. What's your confidence on that, Enyaj? Because
pretty strong, pretty strong. Okay, well, the good news is there's polls out there and we can
check up on you. So listeners get ready to look at the blog. Or I mean, there's a chance you're
right. Yeah. So I did find one of their weird left, one of the weird beliefs that is more popular
on the left, which is the moon landing hoax. Turns out to be the one major conspiracy theory
that is more popular among liberals. Brian Demi, the three-part episode on the moon landing hoax,
which he's never done a two-part episode or anything. So three-part episode was fun and the
first part he talked about some of the origins and some of the things about it. And yeah, I didn't
know that, I guess I might have suspected only based off of, and I guess his explanation made
sense, but I don't know if I would have predicted that in advance. So that was kind of interesting.
Yeah, but the GMO example, I think is a good one where there's an obvious scientific answer,
although not so much to some people. I've had people that, you know, less wrong lead-ups that
they're not anti-GMO, but they're like, you know, it's not as clear-cut as that or whatever. Like,
so there's a lot of horns effect with bad business practices at the final incentive or something.
But as to whether or not it's actually safe, I think that that seems fairly settled.
We've talked about the halo and horns effect before, but I think it might be a good time to
bring up the definition again just because it's so important as an effect heuristic, right? So
it's how we feel about someone. Horns effect would be, I don't like Donald Trump because I'm offended
it, whatever these things that he said. Therefore, anything that he says, I think he's probably wrong.
Right, that's a good definition of the effect heuristic, but it's not a good way to think,
right? No. If Trump came right out and said two plus two is four, would you disagree with him?
Because Trump said it, you wouldn't want to be with Trump, would you? Yeah, or my dad, like,
go take a shower. Yeah, at least. What about, so, and then of course the halo effect is the
opposite of that if there is a person or candidate who you admire and you like some of the things
that they say, you're more likely to believe whatever they say is true. Which is weird.
Which is weird. And then that actually also rolls into part of that sequence, part of Yukowski's
sequence that follows the politics is the mind killer post about authority and the impact of
authority and that experience and expertise in the absence of a well thought out and convincing
argument do actually count for a lot. And we're often in situations where we don't have the nitty
gritty, the nitty gritty calculations, or even are in a position where we can understand the
calculations and we have to take authority in lieu of that, right? I think the vast majority
situations we're in are that way. And that's why heuristics are there, right? They're
programmed mental shortcuts for a reason, like if they were always unreliable and always
led to bad outcomes, we wouldn't have the opposite. But the effect heuristic is basically going with
your gut and if you get a gut reaction from something and then you go with that, that's
a good shortcut a lot of the time. The standard example is when I mentioned lung cancer, you get
this kind of quick sense of dread and it lasts a couple seconds maybe, right? And then when I say
the word motherly love, you get the opposite effect. And it depends on how you feel about your
mother. Motherly love is an abstract concept, right? You know, a mom licking her puppies,
how about that? Exactly. And then so the effect heuristic is realizing that or I guess
incorporating use of the effect heuristic into your real life is understanding that those gut
reactions don't necessarily correlate to the real world. And that you can easily set up situations
where people use the effect heuristic and end up making bad calls or are being inconsistent
with themselves or something. So that's that. Yeah, I also want to mention with the authority
or experts kind of example, Yikowski also mentioned that yes, it is rational to
to give more probability to the expert, give more probability to something that the expert says
rather than the non experts. The lay person says about something that they're the expert on.
But you should feel you should feel hollow inside. You should feel like something's missing. And what's
missing is all of the backup information. Because if then both the expert and the lay person can
provide all of that detailed information and you can understand it, then that erases the additional
probability of truth that you give to the expert person, right? Exactly. I think part of that
feeling of hollowness too is thinking, man, I believe this thing, but I can never really tell
someone why. Like, you know, Neil deGrasse Tyson tells me that the universe is 14.3 billion years old.
But if someone asks me and that's the only reason I can give them, I'm going to feel stupid. Appeal
to authority, right? Yeah. And but I don't know if you I don't know if you should feel stupid for
not knowing exactly how the universe is dated. No, but if the only reason I can give is well,
I heard Neil deGrasse Tyson say it on Cosmos, that does feel hollow, right? I mean, even if I
trust him on things astrophysics, I mean, it's better than if I said, well, my coworker told me
why do you trust her? I mean, she's she's my coworker. What do you mean? Great fashion sense.
Yeah, exactly. So like, that's that's why the appeal to authority isn't an intrinsically wrong
move. You know, you're short on time. If we all that I click all the time, we all be experts in
everything, but we don't. So I'll take Hawking's word for it when it comes to black holes. So
the appeal to authority fallacy is only a fallacy. If that's the only reason if the part of what makes
it less fallacious, I'm trying to be concise and not be confusing. Part of what makes Neil deGrasse
Tyson saying the universe is 14.3 or 6 billion years old, credible is that the scientific community
backs him up. If he disagreed, if he was the lone person, everyone else thought it was 100,000
years old, I would have to have some additional reasons to trust him, rather than trust the
scientific consensus. So scientific consensus isn't the same kind of appeal to authority as
well my coworker said so. And honestly, unless you were an astrophysicist, you probably couldn't
understand any of those arguments, you just have to go with the consensus. Understand is a tough
word there, right? Like, I mean, you can get a good example from a layperson accessible book.
But can you run the math and have you looked through the telescopes? No. But I mean, you can
look at pictures of, you know, red shifted and blue shifted stars and whatever, but photoshop.
Well, I mean, that kind of that's that's how Stanley Kubrick stage, right? This is sort of
like the defense that you get into if you attack someone's position on like GMOs, right?
If you're a leftist and someone says, oh, yeah, GMOs are fine. They're like, look,
that's just what they're paying people to publish. Like, you don't understand that there is actually
this thing going on. And if you tell someone on the right, look, climate change is actually a thing
they might say, no, no, that's just the Chinese trying to ruin our industry, right?
Not not adding a citation to that one. It was Trump. Oh, it was on his Twitter.
So, so you did a citation. Well, man, people are quoting Twitter an awful lot these days.
It was another time. Was that was another time someone quoted Twitter?
Just with with Donald Trump. It's just he tweeted this, he tweeted this.
Oh, my God, he's made for Twitter. He is the best. Like, if he wasn't, if this, if he was a
if he wasn't actually running for president, he's just pretending to like he'd be hilarious.
They'd be like great political theater. But it's kind of, are we getting too political?
Yes. Taking a stance. Yes. It's a little horrifying that he's actually going to be
actually might be present. Yeah. If he was just pretending, this whole thing would be hilarious.
Right. Like if it was a movie with him starring and pretending, like this would be a funny movie.
Yeah. And like all the horrible things that he says. But when you when you put the
when you take the movie out and put reality in, it suddenly becomes a lot less funny.
Well, I think I think it's interesting that there's a whole segment of the population,
which has never been really represented in politics before that is finally getting some
representation, which is what I think we're seeing right now. Which segment is that?
Do we really want to get into this right now? No. No. Okay. Well, I will say.
I'll link to Scott Alexander's post on the foundations of America with boarders versus
Puritans. I mean, there is one thing that I find refreshing about Trump. You guys ready to hate me
now? I love the fact that love is a hard word for it. You don't despise the fact. I like the fact
that he's beyond worrying about being politically correct. You know, I can't offend my my investors.
I can't offend my lobbyist groups. I can't he's not. He can't offend his base either.
Remember when he had such a hard time distancing himself from the KKK guys?
Because he knew that they had some influence with his base? Oh, yeah, that brings a bell.
That's a fun one. I guess what I'm getting at is how many how many how many people do you
suppose are members of the KKK? I was reading. You already read that spoiler. I guessed correctly
the first time. Oh, cool. Apparently, most people do. So how about you, Steven?
Somewhere in the range of 10,000 in the country? Half that.
So it's about 5,000. So it's interesting that we're talking about 5,000 people in the entire
country. So it's they're obviously not like a huge voting base, right? So it's kind of fun.
It's kind of fun that we're talking about the KKK and how important they are as one part of
you the other. And like, you can't be like, well, when either of us will have you, I mean,
I guess you can try, but whatever. But obviously, he felt that denouncing them directly would have
enough of a negative effect with some of his supporters that it mattered. No, I think he just
doesn't want to do anything directly because he's going to mess it up. He directly says Mexicans
are rapists. This might be too inflammatory, but I will say that I think that what happened was
he was asked about it. Why are we talking about this? Because he's so, why does the media always
help him? Because it's so damn like, oh, it's too interesting. It's too much fun. He literally had
no idea what was happening. I don't know what you're talking about. And then not wanting to back
down from that, that's where that's where his new stage was. He just there's like nothing going on
in his head, but confabulation, right? Like if you've ever seen somebody with like a memory problem,
right? And they get there or like, you poke someone in the brain and their arm moves and like,
hey, why'd you move your arm? Oh, I thought I was waving a bus down. That's actually what happens,
right? Yeah, I kind of picture this. We're armchair psychiatrists right now. We are getting
way off topic. Oh my, I'm going to have to delete all of that. Okay. No, that's fair. So yeah,
that's fair. Let's get back to the more abstract. I talked about kind of the evolutionary origins
of why politics is a tough problem or a tough topic for people to think about rationally, right?
Can I touch on quickly? Then we gave examples of why we're bad at thinking about politics rationally.
Yes, we did. Can I touch on a further furthering of this same concept? The
we feel like we have to pick a side? Yeah, sure. Okay. So this is a from a follow up post by Eliezer
on Lesseron called policy should not appear one sided, I think, where he says that Robin Hansen
once proposed that we should have stores where banned products could be sold. That way you can
still ban products that are dangerous. And they won't appear in any normal stores anywhere. But
you have these special stores where people can go to get banned product if they think the FDA or
whoever got it wrong. It's still possible to obtain these things just with some giant disclaimers on
them. And he said that yes, but you know, eventually some poor honest mother of five is going to go
into the store and buy Dr. Snake oil sulfuric acid drink for arthritis and die. And because of
that, because we tend to pick one side or the other, and we have to support all the arguments on
our side and attack all the arguments on the other side, it quickly begins to look like policies
are one sided that I think I hear very often is someone saying, I can't even imagine why that
person believes X. And because once you get into the sort of mind frame, it can get to be that way
where every single argument for is so obviously correct. And every single argument for their side
is so obviously stupid and wrong. How could anyone possibly believe that? Which is what happens when
you only tout the benefits of your side and only deny any benefits of the other side. And that is
one of the reasons why politics is so anathema to rationality. So the reason that Yikowski brought
that up, that somebody's going to go and die, and it's going to be horrible and sad, is not to say
that the policy itself of having banned object stores, ban product stores is bad, but that
there's definitely another side to it. Yes, he said specifically, saying that quote,
people representing the two sides saying that people who buy dangerous products deserve to get
hurt is not actually tough minded. It's a way of refusing to live in an unfair universe. Real tough
mindedness is saying, yes, sulfuric acid is a horrible, painful death. And no, that mother of five
didn't deserve it. But we're going to keep the shops open anyway, because we did this prior cost
benefit calculation. And we're sticking by it. And that's why people don't like economists.
He then goes on to say, can you imagine a politician saying that? Neither can I.
I do want to say that if you listened to the proposal for a store that sold banned things
and didn't flinch when Yikowski pointed out, yeah, someone's going to die, though, and it's going to
suck, then congratulations, you're ready to talk about politics. Because it's hard what's your
test to it to then agree that this thing that's good also will kill a mother of five and leave
them orphaned and sad, right? But if you're capable of doing that without flinching, I think
that's that's kind of lovely to be able to be at. Well, people people are commonly able to do
that when talking about war. I think about the Iraq war, it was very popular amongst amongst
the population in general. It was a is very popular war. I knew too many hippies. All my friends
were like, that's the bullshit. Anyway, hey, well, I mean, a lot of people got there. Eventually,
but you only got one senator voting against it. Yeah, it was very, very popular in the public.
And that was reflected in the voting. The Senate and House, I guess, just the Senate,
I don't remember exactly how it happened. Yeah, people are people are into that. They're like,
okay, it's going to be this cost in soldiers lives in other people's lives from other countries who
are foreigners. And but it's going to be it's going to have this benefit. So people are really
into this cost benefit analysis. I don't think people were doing cost benefit on the war.
If I, of course they were, if I can quote Richard Morgan, I think wars are generally mainly
hormonal. And my personal opinion on the matter was, we were still as a nation, not us specifically,
very traumatized and pissed off about the 9 11 attacks. And the war in Afghanistan was over
too quick. And we felt that we had not punched enough Arabs yet. And so we needed to go to
another country where there's Arabs and punch more of them. And Iraq was the next target. Speaking
of, I think it was very partisan political. No, I don't think it was it was a partisan thing.
Everyone in the country was on the side. It was just still this festering rage. And it needed to
get out through more bloodshed and destruction. Well, politics and war, I know coincidence.
I guess my point was that you have a lot of people who are not flinching at really terrible
decisions that involve killing people. And that involve destroying resources that involve, you
know, there's all of these. I don't think that that's the prerequisite for being able to discuss
things rationally. Fair enough. I might be wrong. I just, I, I thought it was a point in the example
because it is tough to say yes, I think it's a good thing. And yes, this mother five will die,
but it's still worth it. Like I think that is a level of thinking that I think even came out in
the comments and overcome bias wasn't super common. It came to be that if you pointed out a fact,
like some innocent person's going to die, that came out as speaking against the proposal, right?
Remember when we talked about straw men and steel men? And I guess we haven't really used that in a
long time. We should probably bring that a little bit more into our podcast. But this is another
situation where you want to argue against the strongest argument on the other side. And you
actually want to, um, you want to understand the other side and why somebody would come to that
conclusion. And maybe not just hormones once. Well, okay. Sorry. I think once you can understand
the other side of something very personal to you, like the in my personal case, it's the abortion
topic. Once you can understand why someone on the other side thinks the way they think and
realize that it is a legitimate, if in your opinion, flawed opinion, then you can actually
start discussing some of these things. And I'm not there on a lot of topics, but I am there on some.
So that's something, I guess. I think that's one of the, I guess I want to transition this later.
So I'll save it. But that is something that this is actually a good example, the abortion one. So
like if I were to point out, you're killing a human. People are like, you can't call it human.
That's not true. It's just cells. I'm like, it's a living human. It's totally human. It had two
human parents. It's got self-reproducing cells. There's nothing else to call it. You can attach
other terms to it that are useful in terms of, you know, measuring where it's at and stuff.
But to say, to say it's not a human being is factually wrong. But people, and I kind of
did this when I was a teenager, when I was talking about abortion with people, and I
thought it was weird, they were unwilling to admit that human fetuses are humans.
It's the personhood. Yeah. And the personhood is where it is.
They're probably using human with person.
And they were. But people, and this is another quote from the politics of the
mind killer sequence, is that very few people will understand that you aren't defending the
enemy, you're just defending the truth. So I happen to be pro-abortion, but I'm not,
I don't like pro-choice, pro-life. Those sound like their misnomers. So I say pro and anti-abortion.
You should say pro-abortion rights. You aren't necessarily for people getting abortions.
Fair enough. Okay. Then I'm anti-abortion. Unless you are for people getting abortions.
I think they're great. In which case we should go away from pregnant ladies.
Everyone should have free. I want to get either of them. I just so I can keep having abortions,
or start having them, and then keep having them. That was needlessly aside. So I guess that's an
important thing is that when you're tied up in a political discussion, like I said, the truth
becomes your enemy. The truth that GMOs have been looked at a lot, and have looked at and have been
concluded to be fine, opposes some people's political beliefs. The fact that the world is
undergoing climate change, that every month has been the hottest month on record for ages,
I guess for record. Not the hottest month, but the hottest month, like last August was the hottest
August, right? It wasn't necessarily hotter than the month right before that. The fact that that's
happening is true on average. And so people are coming around. It is also important to note that
for some people defending these things is very much sort of a life or death thing. There have been
in the not too distant past, arguments made for why certain groups of people should be killed.
And once your life is on the line, you tend to give less of a fuck about
sticking with old hard facts. And when someone comes around and starts making
rational, recent arguments for why these people are not as good as other people and society might
be better off without them, oftentimes you're not going to argue back in a reasonable way,
even though maybe, I don't know, it's hard to say maybe you should. That's a value judgment. I'm
not willing to make. Maybe it would be more effective for convincing them personally,
but on the other hand, can they even be convinced? What I'm trying to get it as,
once it becomes that personal, it's not surprising that people revan rationality and say,
fuck you, I will fight you on this and I will break out every tool I have in my kit for it.
Yes. We talked about instrumental rationality, right? Very early on in the podcast.
And that's what it is, if your goal is survival.
I just want to point out that if you are bringing up a topic that you want to talk to someone else
rationally about, and that is a very personal thing to someone, it's not necessarily fair to
say to them, why are you being so emotional and irrational? I'm just trying to discover that
truth. Oh, yeah. No, I totally agree. I mean, I'm sure there's a topic out there like that for
me. I'm not sure right off the top of my head what it is, but, you know, and as far as, you know,
in a pressure situation, yeah, if someone had to bend to my head, I'll tell, I'll talk nonstop
about what the earth is, right? But I could even rehearse the cash-aid arguments that I've heard.
But that doesn't, I don't think that translates to most political discourse in most of the developed
world, right? Now, you're right. Not to disempass, you know, there were people going around asking
these questions and you better have the right answer ready. But that's not really where we're at
in 2016. I think that's one of the things I like about our lesser on meetups. And for anyone
who doesn't have a physical space where they meet other rationalists, we, I personally recommend
it. Maybe we should do an episode on how to start one. Sure. Sounds like a great idea. Yeah. But
since, you know, you're going to generally be meeting only other rationalists, you can often
say things that you wouldn't be able to say in public. They under the assumption that everyone
here knows that right now we're only talking in a purely hypothetical what if this were the case
sort of speech and not actually proposing any policy and trying to find the truth rather than
trying to say what how things should be. No, yeah, it's it's generally refreshing. And that's
that's the main reason we have a meet space meetup. Or resorting to ad hominem attacks,
like we were doing recently about Mr. Trump. Right. Yes. And his his psychological profile.
Did I make an ad hominem attack? When you were saying that he acts like someone who is
annihilating? Yeah, I'm able to keep a not yeah, and coach a narrative in his head about how the
world works and just makes up whatever. Yes. Okay. I mean, it's not ad hominem. It's true.
Unless you're actually his psychologist or psychiatrist, though, you you're not qualified
to make that sort of distinction. What you've got is what we see in the media, which is by its
nature, always the most fantastic and shocking stuff, because that's what gets the most quick.
And I wasn't necessarily endorsing that position. I was just saying that it wasn't
necessarily ad hominem attack. You know, it's ad hominem would be saying he's stupid. So he's
raw, right? Or he's a crazy person. So he shouldn't be listened to. Yeah, but it's not it's not
ad hominem. If the person is actually crazy, and they're telling you that the CIA is peppering
their underwear with mind controlling, right? But you can't you can't say that he is crazy
because you don't know that. Oh, yeah. No, I wasn't necessarily
standing behind that statement. I was making as an example. Yeah. And if I did say that he
appears to be confibrillating, well, he appears to be and is our two different things. Right.
So a lot of people were saying recently that Hillary Clinton appears to have Parkinson's or
whatever they were saying. We personally think it's crazy.
We? Medical doctors and examiner? I'm sorry. That combination. But we imagine me and the
mouse in my pocket. I thought you meant we in the left is what you were getting at. And I was
getting back at it. That is kind of what I was getting at. Yeah. But like none of us are doctors.
None of us have ever looked at her. Right. So is there anything else that you guys want to
talk about in terms of biases before we shut off? Absolutely. There's a tendency
there's a tendency when talking about politics to I think I've mentioned already that some of my
most rewarding conversations, especially about politics have been with my friend who is on the
opposite side of most political issues than I am. Because we're both capable of, you know,
not shouting, not getting a rate. And we're both capable of listening to whatever's been saying
and saying, hold on. That's actually true. Let me think about that for a second. And not that
can't be true because this. So it's really rewarding. And it's really interesting. And if
if you have the opportunity to do that, go for it. If you can find a person who disagrees
with you politically, and you're both capable of keeping your heads, it's a lot of fun. People
have a tendency to assume that people on the other political, the other side of the political line
believe things for bad reasons. Or if they were only better informed would agree with them.
But that's true for both sides. And it can't be true for both sides. Right. So
wherever it's at, people act in a way that's internally consistent with them being good people.
Like if you're against abortion, you're not a monster who hates women, you're
a great person who wants to save babies, right? So like, acknowledging that isn't
a point for their position, it's just a better understanding of who they actually are. And if
you're, that is not the correct way to model your opponents in a way that makes them as
villainous as you're trying to, as you're imagining, right? If you're imagining them enjoying
being Voldemort, you're probably imagining them wrong. Voldemort's the outlier. So
does that make sense? I feel like that's a really important point. And it's one of the
best points made in the politics of the mind color sequence, that there is a lot to be gained
from understanding that your enemy has an internal narrative that makes them the good guy. And that's
true of whoever your enemy is unless your enemy is literally Voldemort. So even then you can
write some rational fiction where it's true of them again. You find yourself getting over the
next couple of weeks or the next month or two until politics is finally done for this this season.
In the USA. Yeah, in the USA. You're finding yourself getting pissed at your opponent for
being so stupid. You probably don't understand them. That's the point I'm trying to get at.
Right. Saying I can't imagine why my opponent thinks this just means you have the very bad
imagination. There's a failure of imagination. Yeah. But people also actually are stupid.
Especially those, those damn reds and blues, right? Those damn what? Reds and blues. Yeah.
Whichever side I am, the other side's stupid, right? Right. Yeah, that's not the takeaway
message. Oh, I guess I just meant that a lot of people are. I mean, we believe things for that
we haven't really looked into for no good reason. And we kind of just accepted it. And as we were
talking about before with the appeal to authority, a lot of times we just take an authority figure's
word for it. And that might be our parents or someone else. That's what's going on with other
people too. So they don't always have good reasons for believing things. I'm not saying they have
good reasons. They have what are to them good reasons. Yeah, or they haven't really thought
about it. That's possible too. But assuming the person you're talking to has thought about this
whatsoever, their reasons make sense to them. So like the reason that God doesn't want us to,
that that embryos have souls and God doesn't want us to kill them, that's not a good reason. But it
is a reason that is defensible given what they believe, right? Okay. That's so that's that's
where it's at. empathize with your political interlocutors and they'll be much more rewarding
for both of you. Right. That's my takeaway message. Empathy. Empathy is good. End of story.
Shall we move on to this sort of feedback? Let's do. All right. Right after these messages.
I'm starting with a this is from our website. Pierre Thierry says,
I wonder why it was said that we are not happier than our ancestors. We may have a different
baseline anxiety level, free time and access to a huge variety of informations and hobbies
that do make it possible to tap previously unused potential for happiness. Also, we right now might
very well not be at the human maximum for happiness because some of our current advantages might be
offset by some of the problems of our culture, like putting work or social success before
happiness, less care for childhoods and so on. Okay. Yeah. So I guess there's some evidence that
people suffer from more anxiety than they used to. I actually don't really have much to say to
that, but I thought it was interesting to his point that we may be at a higher happiness level in
general as humans than we ever have in history. And I thought that is plausible. Well, I guess
we're at a lower percentage of starvation, which is nice than than we have been for at least quite
a while. Yeah. I know that at least as a related piece of data that suicide rates are way higher
in developed first world countries than they are in like the countries we think people would be
average less happy. There does seem to be some sort of anxiety and pressure with just having
freedoms to do whatever you want all the time if you're reasonably well off. Like you have to go
to work and stuff, but for the most part, you don't have to work 16 hours a day. You know
where lunch dinner is coming from. So like having not not having that on your mind, I guess gives
you time to like what am I really doing with my life? We also have the internet. So we have all
we have an amazing ability to get information and work a lot harder and faster and we have
more productive. Yeah, all the best entertainment that humanity has ever created at our fingertips.
I was saying that that can maybe add to anxiety because it used to be that you could go and just
hang out in the library all day. Yeah. You know, when we were kids. Yeah. Or going back further,
you know, middle ages, you can go to a good old fashioned hanging or a cat burning or go back
further cat burning. That was a big thing. Oh my gosh. Yeah, a good bunch of them throwing a bag.
Not my favorite type of entertainment. But you know, like I guess previous, you know,
the city play once a month, like that was like when people look forward to like that sounds
super boring. But that maybe that's because that's where we're at now. Did we say we're less happy
now than we used to be? No, but we wondered if humans have some weird potential to be happier
now than they used to. And we kind of discounted that idea. Which episode was that saying maybe
that is entirely possible. I think that was it was fairly recent. I think that could have been
the street testimony one. Okay. Oh, I do remember seeing something along the lines of like, maybe
how happy it was to find a body of water when you're traveling no matter something. But I don't
know that sounds like it's more like relief and security and like the happiness from those things
not like the happiness of like, I'm really looking forward to the, you know, the next Marvel movie
right. I will say there was one time where through entirely my own fault, when I was in college,
I went nearly three days without food. And when I finally got access to food again on the third day,
I was so happy I almost started crying. It was, it was crazy how that simple biological need being
fulfilled could make you so happy. Yeah, where you're searching for a certain kind of bug all day
and you can't find it and you can't find it. And finally you do. And you're super hungry so you eat it.
My brother when he was in the military said that there were sometimes he just did not get a lot
of sleep for, you know, week or two on end. He and when those times when he could grab a nap
and sleep like on the hood of a truck for two hours was just some of the most fulfilling thing
ever. He was like, just just being able to rest for two hours. That is so good. That is true happiness.
Yeah. That all that all is true happiness. And I don't begrudge our ancestors that.
So and we don't get that very much nowadays. Because we have all those basic needs fulfilled,
which you would think is a good thing, right? Well, so it makes us not have to worry about
starving. So I think that kind of comes into where, you know, like depression and suicide rates
are higher in developed countries, at least as best as you can pull these things. Well,
maybe it's like a Maslow's hierarchy of needs thing. If you need to focus on some of your basic
needs, maybe it's harder to focus on some other things that might make you depressed and sad.
Well, the stress of self actualization is maybe like a problem our ancestors didn't have.
So would we all be better off if we're more miserable? No, no, no, I, I, it's interesting
that we came across that way. I'm glad Pierre pointed it out because I'm glad to correct the
record. I don't think that we're not happier than our ancestors think that we might be on average,
more depressed, but I don't think that means that we're less happy if that makes sense with what
I'm trying to get at happiness and depression are separate things. Right. So like we have more
things to be stressed out about, we probably many of us are maybe less happy some days than other
things because like our needs are met, we have the freedom to be unhappy. And so that like,
if you're, if you're miserable and hungry, like there's no tiny miserable, you're too busy looking
for food, right? Does that make any sense? Yeah. So yeah, like you said, once you've satisfied the
bottom of the hierarchy, you have the freedom to go on and be stressed out about the things higher
up. And that is double edged sword, but I think it's one that is worth it. Yeah, hands down.
Would you like to read the Westward part? Westward one or one wrote in and said,
Using hardware to replicate the intelligence or emotion of a living being is an interesting
thought experiment, but it's not actually real and may never be. Lots of people around here
treat it like it is. And that's not even the frustrating part. After it's brought up, all
the cool questions are ignored. I want to adjust. I was just the first part. Yeah. So
um, it's sort of taken like a given in the rationalist community that sort of adopts the
premises, premises of transhumanism. And I guess, futurism, like you, you, I guess there's this
sort of assumption that technology is going to keep going and keep getting better. And that these
things not being prohibited by the laws of physics will happen at some point. That's something we
don't die. There's there's no reason human level cognition should be stuck in our fleshy bio brains
that it can't be reproduced in some other on some other substrate. And since there's no reason
in principle that we can see that that can't happen, then it's assumed that someday in the
future it will happen. I think that's as long as human society doesn't collapse first due to
asteroid or Trump presidency or something. Or it's just as easy as you think it is.
Meaning very hard.
Very hard. But I don't know, it could be it could be a lot more difficult to to do general AI,
right? It could be a lot, lot more difficult and and take thousands of years.
Like who knows how long it'll happen. People don't people might not have the will to do it.
See, like just because something's physically possible, it doesn't mean that people are going
to do it because they've got plenty of other stuff that they can do instead.
Yeah, but I assume anyway that in the long run, meaning potentially billions of years,
if it's physically possible, it's going to get done at some point.
We would be very lucky to make it billions of years.
I'm optimistic in that regard.
Me too. At least I'm optimistic enough to to make preparations for it, not unexplored otherwise.
So yes, in general, most of the people in this particular community do talk about it as if it
is a thing worth talking about because it might happen someday.
Even Robin Hansen who, you know, say, and I guess this this didn't come out or this comment came
before the Hansen episode comes out. So if that's an anachronistic story,
Westward, or not anachronistic, but if that's temporarily, that doesn't line up temporarily,
that's on us. Robin Hansen points out in his book, Age of M, that, you know, look, I think that
human brain emulation is way easier of a problem than general AI. So let's just, I'm going to
assume it happens first and then take my book from there. And I think that's a fair assumption
to make. You know, you can get a really good picture and basically just reverse engineer
what we already have rather than build something new from the ground up. So that's another piece
of the puzzle. So that's the first part. Second part is that after it's brought up,
the cool questions are ignored. If you're going to the trouble of speculating on the emulation of
E's feelings times five, at least roll with it. It's a little boring to me since it's
unrealistic, but don't shout away once it's out there. Will such a simulation be more valuable
than E prime? Is it okay to kill critters if we keep the simulations of them? First of all,
I love the fact that I'm now E prime. I'm totally going to change my red attack to E prime.
Right on. You're E prime? I am the E prime. Yes. All other E's are derivations of me.
I think given the line of reasoning that we were taking, E times five is more valuable than E prime.
Yes. This goes back to something that I said. I think it was the first animal's episode that
depending on how you, how you consider value, some people may be more valuable than others,
but for reasons of, for all reasons of legality and morality, all humans should be considered
equal because then you start getting into all sorts of bad things happening that you don't
necessarily want to happen. As, as, as Stephen was saying earlier with me offline, that if you
don't assume that, if you take my position that intellectual complexity is what is important,
then things like babies, toddlers, the intellectually disabled are less valuable than normal people,
and super geniuses are more valuable than normal people. And that is not a place I want to go.
And that is not a place that I think the laws should go either. And so for that reason,
I draw a line at treating all, all beings that we consider sapient as equally valuable.
I will, I wanted to say really quick too, as far as to why we don't tend to go down these rabbit
holes, like once they're brought up, I think, because they're typically tangential. So, you
know, there's, there's some push to want to, to dig into these obscure and possibly absurd
thought experiments. We might do it, but I think the reason we didn't push on that too much was
just because it seems to be kind of digging us down the wrong path from where we were trying to
focus on. But your point's taken. The question, the other question was, is it okay to kill critters
if we keep simulations of them? And I say no. I agree. Because something that physically exists
is by the nature of it physically existing different than the thing that's a simulation.
Right. I would say it depends on whether you've gotten consent. And if it is a critter that cannot
give consent, then obviously no. The Prestige had this major spoiler. It's like a 10-year-old movie.
I think that's past the line. Okay. First of all, it is a fantastic movie. Nolan is an amazing
filmmaker, and this is one of his best. So, skip the next minute. I saw it recently. It's fun.
Yeah. Skip the next minute if you haven't seen it yet. But in the Prestige, Hugh Jackman's character
gives consent to have his copy killed, and he only has to give the consent to himself because,
that's who's making the copy. And so you have a very weird time morally condemning him for
killing his copy. But his whole shtick is he makes a copy of himself, and then he kills one of the
copies, and that's how he pulls off his magic trick. And every single time, the copy does not
want to die. In the moment, he's like, oh, fuck, I'm drowning. This is terrible. In the moment,
but they go through with it. It goes through with it to that point. Yeah. So he gave consent. So
it's, well, he should technically be able to withdraw consent. I think you can always withdraw
consent at the last moment, which is what makes the movie morally ambiguous and such a good movie.
But in the case of a Star Trek transporter, since you've given consent to be destroyed
and being somewhere else, then there's no moral obligation to keep both of you alive.
Isn't that, are you aware that that's how the transporter works? No. Oh yeah, the transporters
in Star Trek work by destroying the copy where you are, taking all that information. It's a
destructive scan, beating it over somewhere else, and then recreating you anew. That's messed up.
There's a few episodes where it fails, and so there's two copies of you. Nice. Yeah. Which
kind of makes you think- Which, why don't they do that all the time, right? This is one of the
problems with Star Trek. Oh my god, why do not they keep a copy of someone's buffer somewhere
at all times? So, okay, in deep space time, apparently it takes up so much memory that
we can't afford to do it. But Jesus Christ, if I'm a rich person, I'm going to keep a buffer
of me somewhere because it's immortality. Yeah. You break an arm, being yourself back to the
positioning word before. That sounds super handy to have around, right? Yes. It's one of those
annoying things about Star Trek where they do not follow through on the implications of their
technologies. Everyone is functionally immortal in that series, and yet people die all the time.
It would also make sense for Hugh Jackman's character and the prestige to rather than
drop into a suicide pit to just land on a mattress and shave your beard and leave the
state like that's whatever coffee has to do, right? There would have been a lot of freaking
coffees. Then you guys can all get together a year later and grab a coffee time below someone's mind.
Right. Sound your own Jackman City. Oh my god, you guys are a cool gang. Dude. Yeah. A gang.
We're the Jackmits. Right. All right, next one. Yes. So, Dave wrote this. Katrina mentioned
that she thinks rights are not a thing. I've read two interesting books taking more or less this
stance. Robert Anton Wilson, Natural Law, and L.A. Rowland's The Myth of Natural Law. Like many
other political and ethical concepts, the idea of rights gets abused by sloppy thinkers, making it
easy to argue against a weak version. But many philosophers consider rights to be obligations
viewed from a different perspective. My right is your obligation. My obligation is your right.
Does Katrina also think that obligations are not a thing?
So, I think that Dave is referring to me kind of going back on in the first animals episode.
I kept talking about how animals have intrinsic rights or intrinsic value actually. And then I
went back on that and I said they don't have intrinsic value. What they have is value to
value to other life forms and value to me, value to other people, value to themselves,
very importantly. And that's where that value comes from. And that's where, and the concept of
rights is something that comes out of what we value as a human society. Right. And same with
obligations. So, while I certainly do think that they are a thing, I don't think that they are a
thing that exists outside of us. Thank you. That's exactly the same. I mean, that's my
same position. That's what I thought you meant. Thank you. That there are, I mean,
some people talk as if rights exist outside of humans as some kind of mythological thing.
Endowed by God. Right. Right. No. And the only rights that exist are the rights we take.
And by take, take or give or conceive of, right? Rights are a legal fiction. And again,
fiction is not the best word. They're a legal construct. They are a thing that other humans
agree on. And nothing has intrinsic value in the sense that, you know, we were talking earlier
about all humans are equally valuable, except for in the way that the law treats them as all equally
valuable. Right. Yeah. Oh, I wanted to mention that we have laws that take away people's rights
as they lose their value. For example, when we imprison people and don't let them go where
they want to go or do what they want to do. Yeah. If you try to direct your consciousness
in the freedom of your own home with the use of a, with the use of an illicit substance,
you've lost your, your rights to person according to the state, right?
There's some aspects of your personal. Yeah, I guess that, that's just to me,
one of the most absurd examples of like how, what you can do to lose a person. Like if you kill
somebody, all right, we, maybe it's worth taking you out of the society for a while. But the drug
thing is the, I think the obvious joke as far as like how fucked priorities are. Yeah, the drug
war sucks. And if you disagree with me, you're wrong. Yeah, you alluded to the, the other source
of rights that a lot of people get it from. And that's like, if they're religious. So to, to the
secular mindset, there isn't at least not that I've encountered, maybe there's a good book out
there. So if someone knows of it, send it our way. I'm curious that like a, an external source for
rights as like a thing outside of human human construction, you know, if you're religious,
God made the inverse, God gives you these rights. And that's, that's what, that's one,
that's one avenue to get to it, right? But God doesn't enforce any rights. So
there are no God given rights in that, in the, in the fact that he doesn't enforce it.
Well, you're the Jehovah's Witness. I think you might know better than me. I was going to say,
so I'm speaking purely as a, as a materialist here, because obviously the religious people
say our rights are given by God, but since God does not enforce the rights and it falls on man
to enforce those rights, no rights are given by man. Rights are always given by the people who
are willing to enforce their rights. You seem really focused on enforcing. How else are you
going to, I mean, it doesn't have necessarily be violence. There can be things like social shunning
or just making you feel bad by calling you an icky loser. Those, those are always to put pressure
on someone, but there is no source of rights aside from telling people, this is something you have
to do and then enforcing that if they don't. Well, can't, can't you just get together and say,
hey, let's have these rights and don't, yeah, but then don't enforce it. And people just
either do it or don't do it, but they still feel like they have the rights.
If it's not enforced, it's not really a right. It's just I'm not, I'm not a legal scholar.
So I apologize, but yeah, interesting topic. I'd like to learn more. I just, I don't know,
something feels weird about the whole need of enforcement part of it. Just kind of like with
the value, like, well, I mean, if you know, if that beautiful little, little green metallic
bee that I saw the other day that I was just so in love with sharing the earth with this animal.
What has value to you? Yes, but it has value and it has value to itself, right?
I suppose. But does it have rights? Only the rights that other people are willing to
grant it and fight for. And if I gave it, if I gave it a right to, to like, I don't know,
the right to be around me. Sure. Okay. It's very limited, very limited in scope. Yeah.
Whatever. I guess I'm not sure what it means for it to have rights, like it has the right to access
food. Like, sure, the right to the pursuit of, of life and food and happiness. I mean, happiness.
If you were to actually try to encode a right to pursuit of food,
toward a bee, that would mean that anyone that you could influence that tried to
obstruct the bee from getting their food, you would impose some sort of penalty on them.
Well, or maybe I just, just lash out at them for not respecting the bee's rights.
Yeah, that's a penalty. If they like you, then they will feel sad that you have lashed out at them.
If they could give two shits about you, then, you know, they're just annoyed at having to hear
you yell, but unfortunately, that's the case with most people. And those kids at the bus stop
who kept throwing rocks on those worms. Oh, bad memories. What's that? I'm crying. I didn't even
give them a hard time. I told them not to do it. Maybe they saw her crying and they felt really
bad. No, no, no, I think that that was a reward for them. Oh, they are the bad kind of humans.
Yeah, children. What are you going to do? Yeah, children are the bad kind of human. They really
are. Kids are the worst. There was one actually quick thought experiment I wanted to put to you,
to Ina specifically, but you're welcome to take it. You mentioned that part of your
reason, or maybe your entire reason for drawing a shelling fence at, at Homosapiens for what gets
included in the, in the moral sphere kind of a priori is because if you don't draw the line,
now you get to weird places where like, it's okay to kill mentally handicapped people and it's
okay to, I guess, maybe not necessarily okay, but not as bad as killing someone who's more
but I mean, I think that's, I guess this is kind of a pointless thought experiment, but it,
even being implicitly tied to the idea that I'm going to treat them equally, if you're
in a burning building with two unconscious people, one of them is Isaac Newton and one of them is,
I don't know, somebody who was on the opposite spectrum, end of the spectrum is Isaac Newton.
Okay. Who are you going to, who are you going to drag out? Are you going to flip the coin? Are you
going to? Me personally? I'm going to drag out Isaac Newton. Yeah. I have my own values. No, Isaac
Newton's already dead. That's true. That was the trick. Damn it. I shouldn't have given a smart
person that would be giving. My first thought was fine, but I was like, no, wait, he's dead too,
so I just went from my, from my next go to a guy, which also I didn't bother to check is dead. So,
um, yeah, you know, living to living Bill Gates versus, uh, Donald Trump.
I might, I might make sure that Donald Trump is completely unconscious before I go to rescue Bill
Gates. If I was, no, no, that's, that's, that's evil. If I was in a room with a song, I've been
lauding Hitler and Toby and I had a gun with two bullets that shoot Toby twice. Who's Toby?
It was on the office. I never saw this show. I saw a couple of episodes. He was the HR guy that,
uh, um, Steve Carell's character hated. Okay. And so he hated him enough that he was in the
room with, with Hitler and has not been lauding him until we twice. So, yeah. And, and the thing is
when you are making those sorts of decisions, everyone will have some sort of criteria that
they judge by if they can only pick one, maybe it's whoever's younger, maybe it's whoever's healthier,
maybe it's just whoever's prettier. Uh, or if they know the people, maybe it's the person they know.
Sure. But illegally, um, they shouldn't be treated directly.
That's a very same thing that completely, that I think is a satisfactory, uh,
reputation of the, of the, of the thought experiment. So good enough for me. All right.
That particular one. Right. Oh yeah. There's many more. I'm sure someone will trip me up.
Can I read you a question? Uh, yes. Someone, someone will push you into somewhere where you're
pugnant with a thought experiment. It's just going to happen. All right. So Hanuman 1871 was,
wrote us a lovely message and also posted on Reddit to our animals, um, episodes.
Inyash framed the debate as one in which most likely no one would convince anyone else of their
position. If that is so, then from the perspective of people who strived to overcome bias,
Inyash has already lost. Unless there is something very, there's some very compelling
reason to do otherwise. We should always be correcting for an obvious bias like speciesism.
Now, um, Edgar's email, which started the entire conversation stated in part, it amuses me that
you all had a discussion about whether animals want to live based on imaginings of what the
insides of their minds might be like. It doesn't matter what answers you give. You're just making
it all up. It's true. Edgar did say that while it's true that we do not have a clear understanding
of what it is like to be a nonhuman animal. It's equally true that you don't know what it's like
to be any human being other than yourself. You're making it all up in a sense. Every time you try
to act with consideration towards another person. And that's a good thing. If knowing for a fact
what it's like to be someone else is the determining criterion for deciding whether or not to behave
ethically, there will be no ethics whatsoever, because no one ever gets to be anyone besides
themselves. This argument should be turned towards Eneush. Why do you have any ethical
commitment to any human being other than yourself? Is it simply the instrumental value of that person
towards your own happiness? And if humans have some value for you that is non-instrumental,
then why not extend this towards all animals? Okay. So first of all, I agree with him completely.
And that is actually one of the reasons I take the positions that I do take, even though I guess
he will find that, or they, sorry, even though I guess they will find this possibly counter-intuitive.
Not to get into solipsism here, because whenever something gets into solipsism,
I check out of the conversation because I consider solipsism bullshit and I will not discuss it.
Could you do a quick definition of solipsism for the listeners? Solipsism is the idea that we
cannot know anything aside from our own thoughts, for certain, that the entire universe could be
an illusion, that it could be the fact that no one else exists except for you,
and that no one can truly know anything. All right. Well, I guess that's all we need to know about
that. Yes. And so, yes, it is completely true that I do not know that any of you fuckers exist.
Yeah. Y'all might be some zombies or some robot sent here to trick me, and I could be the only
actual person on the planet. Well, if I'm a robot, a tricky robot, I'm still a tricky robot. I'm
still something. Right. Just wanted to say that. Yeah. So that is entirely the case. And when I
extend moral consideration to other things, I do so assuming that if someone can communicate like
me and convince me that they're somewhat like me, that's good enough for jazz. And that is why I
would extend similar rights to a computer that could talk to me and convince me it's a person
or an alien that I would meet. And that's one of the reasons I don't extend the same level of rights
to animals, because they have not been able to communicate with me and convince me that they
deserve that same sort of consideration. And when I know that Katrina is shaking her head right now
and giving me the evil eye. And when when he asks what reason do I have to extend rights to other
people, aside from their own worth to me, it's it strikes me very much as the question that people
ask. Well, if you don't believe in God in the afterlife, why don't you just go around murdering
everybody? And the answer is that, you know, I care about a lot of people. And I also care about
myself. And there's this thing where if I were to go to try to to not extend moral consideration
to other people, I would suffer greatly for that. That's that's basically what all morality is,
right, is creating incentives for other people to be more pro social, whether it's by giving praise
to them for being considerate and nice, or whether it's by scoring them for being mean and rude,
or, you know, even punishing them for doing things that are very antisocial. That's that I'm a big
fan of the zirism, which is a moral theory that was proposed by Alonso Fife, and was actually
where I met Luke Mulhauser online, like I'm not in real life. Originally, we were both somewhat
active commenters on there before we both discovered less wrong. Who's Luke Mulhauser?
He is a he ran commonsense atheism before he shut that down. He works for Mary now as their
director of something or another. All right, thank you for explaining. Sure. Luke Mulhauser is also
a guy who works at Mary, and possibly does work at Seafar, I'm not sure. I think he does. Okay,
but I'm sure it's going to be a big one. No correct guess. But yeah, what I'm saying is there are many
reasons that exist for me to be nice to other people, and to grant them rights and to expect
them to grant me similar rights in return. And that's how society works. And I don't know what
else to say about it other than that. How about how about this explanation?
Inyash, what if you were just born with empathy that extended to other humans,
but didn't extend to nonhumans? I want to back up that point by saying that's
pretty much what I was going to say, that it's no coincidence that many of our ethical values line
up with evolutionary incentives. So there's the punishment for other people if you were to go
around killing people. But there's also you would probably feel bad if you're an average person,
and that makes a lot of sense. And as far as not extending rights to animals,
I did want to just mention really quick that humanity did extend rights to great apes in Spain
a few years ago. The goal was that they had a right to live lives free of torture.
And would you extend some rights to the animals that we tend to domesticate and
keep in our houses? There are laws against animal cruelty in the US for things like dogs and cats
and the common domestic animals. That are specifically applied to domestic animals and not
evenly and not enforced well. And all those are because the animals can't enforce them themselves
and have to rely on the humans that care for them to enforce them for them, which is unfortunate,
but it's the way it is. I just wonder if some people can't feel empathy for animals and some
people can. I think that's possible. I know I certainly feel less empathy for animals than I
do for humans. But I don't know if that's learned or if that's innate, because apparently back in
the day, a lot of people didn't have empathy for people that didn't look like them. If you were
not of my tribe, you weren't really a person and I could steal from you or kill you with impunity.
Or enslave you. Or enslave you. Slaves were commonly considered property that you could do
anything to or with. So it may be learned that the fact that we have empathy for all humans
and for a greater amount of animals, I think that that's probably closer to the truth that's
actually out there. As you said, our attitudes towards other humans have been growing in what
I would say is the right direction, but they've been growing more general of putting every human
in the moral sphere, not just like your city, your skin color, your nationality. People who
endorse this position are typically frowned upon now, whereas they wouldn't have been in the past.
So it does raise the question, though, if we were to just skip ahead another century
in progress, would we feel that same way about other animals?
I think it's possible.
And I think it's possible, too. And I certainly don't think I was born with
like an empathy for not human animals as much as I was for human animals. But it is the kind
of thing that you can be reasoned into, even if it's not there for you to feel right away.
But I do suspect that in a century we'll look back and be aghast at certainly at least how we
treated great apes. Whether or not in a century we'll be looking back and be like, I can't believe
we did that to chickens, maybe, probably, but I certainly would be very surprised if we weren't
looking back in horror at how we treated some animals at the very least. So more time, I imagine
that sphere will grow.
Well, I mean, there's already a fair number of people that are horrified by how we treat
animals, which is one of the indications that I think that's going to become more of a thing.
There always have been.
Yeah. But it's been growing.
Yeah. Well, here's hoping.
I mean, at this point, it might be possible to get some laws passed in the near future,
whereas a hundred years ago that would have never happened.
There's already a lot of anti-circus.
Yes.
There are several countries in South America that have banned traveling circuses.
Oh, that's cool. I do know.
And the animals have been taken to sanctuaries, including one in our state of Colorado.
I've been there. It's awesome.
Well, the animal sanctuary.
Tons of happy sleeping bears.
And lions.
Lions, lots of lions.
Lots of lions, other big cats.
And there are some other attraction that too.
And those were from Bolivia, I want to say.
The bears?
The lions, like a lot of lions.
I remember several of the bears were from a circus that shut down, I think, in Russia or one of the
satellite states.
One of them, I think it was one of the big cats the tour guide was telling me, was literally like,
yeah, this was in someone's backyard.
Like, they had it chained up.
Yeah, there was a couple of large animals that were seized from a drug lord of some kind.
I mean, if you have a big enough empire where the animals have an acre to go play on, go for it.
But don't leave them in a cage in the garage.
What we're saying is, if you ever visit Denver, our wild animals sanctuary is super awesome.
Yeah, check it out.
It's kind of far away.
It's not exactly in Denver, but it's worthwhile.
If you're 45 miles northeast of Denver, you should check out this.
If you're willing to drive for an hour or an hour and a half.
It's a little closer to the airport than it is to here, so.
That's true.
All right.
All right.
Can I read you the next paragraph?
Please.
From Hanuman, 1871.
Real quick, the reason at the top that I said we probably won't convince anyone of that is,
I don't think an hour is enough time.
When I was religious, I had some very good arguments presented to me for why I shouldn't be,
but it still took me a number of months of processing and thinking to change my mind about
that.
I just don't think humans can update that quickly.
But now that you're most humans.
Now that you're a good Bayesian, you should be able to update like that.
You are not a good Bayesian.
I'm not that good.
None of us are.
We're working on it.
I need to do more maths.
Actually, something that I wanted to ask you, because you're talking about your shelling fence.
Yes.
And how you have to use a shelling fence to separate humans and the animals,
because you use an intellectual complexity model for valuing animals.
Since you yourself have admitted that it's irrational to do that.
Irrational in the sense that I think all humans should be valued equally,
even though they aren't all equally intellectually complex.
But not animals.
Right.
So there's a little bit of a double standard there.
So you said that that was irrational.
Why then does that not cause you to go back and reconsider the way that you are valuing life
instead of setting up your irrational shelling fence?
Because as a good rationalist.
All right.
Don't let this get out in public.
Don't publish this.
Anywhere worth thousands of people might hear it, but I do.
Are you sure?
Yeah, I do.
Do you want me to take this off?
No, no.
Unless you think maybe we should afterwards.
It's a bad enough confession.
Talk to me.
Okay.
I do actually value humans differently based on how smart they are.
Or by how intellectually complex, not necessarily smart,
because intellectually complex and smart are subtly different.
And so I really do value babies and toddlers less
and really brilliant people more than myself.
But I don't think that that is a thing that people should make any sort of
non-personal decisions around.
It shouldn't affect the legal system.
It shouldn't affect moral rights.
And that is why I consider all sapient creatures,
which at this point in my opinion only consists of humans, as far as we know,
equally for all those purposes.
But in my own individual valuation, I do still value even humans on that gradient.
That is not a blessing to murder.
I think I'm in the same boat.
No, wait.
What about non-human animals that are more intelligent than,
let's say human toddlers?
Of which there is at least some reason to believe that there are several species.
And at least individuals.
I mean, it depends somewhat on who cares about them.
If this toddler has parents, that's important, or people that care about him.
Then he means a lot to those people.
But sometimes pets belong to people and mean a lot to those people as well,
in which case I would also consider those pets more valuable because of the people that value them.
There is also something to be said for the fact that
a toddler would eventually become a human and that the human race would go extinct
if we got rid of all toddlers.
So there's some future knock-on.
So once we get to species that are you,
right, that are humans, that are very closely related,
and that you understand some of the complexity of,
all of a sudden it's not about intellectual complexity only anymore.
In terms of valuing, it's about who else cares about it.
It's about what the future is.
It's about what the fallout is.
In terms of animals, those are also the case though,
because I also value animals more if other humans care about them.
And puppy is of less worth than an adult dog who is well-trained and can understand things.
But on the other hand, a dog is never going to get any smarter than that once they're an adult,
whereas a human will continue to get smarter and become a full adult.
So there's differences in comparing where they're going to get to
within a lifetime.
Okay.
Does that make sense?
Yeah, I think that's why.
Is that consistent?
Because you're giving me a look like you don't think it is.
Well, you made some claims that the only thing that mattered was intellectual complexity
when judging animals and la la la.
And I'm just trying to get you to admit that actually there are a lot of different things.
Well, there are a lot of different things going on in your head that you consider.
Okay.
I don't know if it's controversial to say that chimpanzee is more important than a flatworm
in really every single sense of the word.
A chimpanzee has things it cares about.
It has things that it has fun.
It has parents and children that look after it and it looks after.
To the extent that a flatworm has fun, it's probably less fun than a baby chimpanzee has.
So you can slide those scales to whatever you want and include whatever species in those
scales you want.
And it works out that on earth right now, if you're to slide those dials, you get some overlap
with young humans and the mentally handicapped humans.
And then humans rise above other animals on earth when it comes to
cognitive tasks that we find important.
There's something we said like we're not the best at swimming or we're not the best at
burying nuts and then finding them later or something.
But the things that we care about, writing sonnets, painting paintings, building spaceships,
we're the best at all that.
Once we're not, though.
Yeah, once we're not, then that's kind of the thing.
That's kind of the worry, right?
Once the AIs are better than us at all that, do they matter more?
That is a big topic maybe to stay for another day, but the short answer would be yes.
The one sentence, the non-one word answer is it would sure be nice to build a super
intelligence where the lights were on, right?
Where it's basically a philosophical zombie and it's just
pumping, it's just moving information around, but it's not sentient in a way that like,
God would be sentient compared to us, right?
But if it was, well, then you're suddenly the most important thing on earth, right?
Yeah.
In terms of anyone being, the AI would, in my opinion, be more important than any one human.
Sure.
However, as an entire race, if it suddenly decided it was more important than I think we
really should team up and give it some negative reinforcement to not kill us.
Well, I mean, that's the same situation with the flatworm and the chimpanzee.
Chimpanzees, sadly, are uncommon to the point that if all flatworms were destroyed, it would
have a much larger impact on the world, more important impact on the world than if all chimpanzees
were destroyed in terms of what the fallout would be.
But of course, when you guys come up with examples, it's always one to one.
I think it's because including the externality of the ecosystem at large wasn't something that I
considered until we talked about it and something I'm trying to do more because it's a bad habit
of thought experiments to make it uselessly simple in a way that, you know, is a great
intuition pump but doesn't really lead to anything in the real world.
Good thought experiments aren't like that.
And good thought experiments include externalities like, yeah.
So, you know, like in your situation of, I don't know, whatever it is, or in any situation, you
know, if you run into a burning building, you step on the flatworm to save the chimp, right?
Right. And you might even run past somebody that you, you might run past the average street
civilian to rescue Bill Gates because Bill Gates' probable net impact on the world afterwards is
higher than some random model. And, but that doesn't mean that in the real world, you wouldn't
feel bad about it. That's something that like thought experiments don't really work on, you
know, so like, you know, would you push the fat man in the trolley? It's like, yeah,
I feel really bad about pushing it. I think, I think that they work on that.
Well, but that's sort of one of the first ones to like kind of not the first ones, but it's one of
the popular ones that pushes on that actual point, right? But in other ones, you know, the, the, a
good example, you know, would you, would you grab a, if you're in the burning building with
yourself and some random baby and a Picasso painting worth $50 million?
You grab the baby.
Do you grab the Picasso because imagine how many lives you can save when you sell it?
No, I mean, I think that's a great point. You know, so like, you're literally,
Do you get a cheap the Picasso though?
Yeah, why in the world would you get to keep the Picasso?
See, it's yours. I don't know. Say, say you had this.
I would obviously not the sort of person that sells the Picasso to save people.
I mean, so I know what you're trying to say.
There's coming down this thought experiment to making it useless. I think the, the best answer
is you bite the bullet and say, look, I can save, I can save this one baby, or I can save
what's 3,500 divided by 50 million or 50 million divided by 3,500, right?
Right.
That many babies. So that might make you the kind of person that most other humans don't want to
be around.
And that, that is the kind of thing that that thought, that that thought experiment will
properly deliver doesn't really consider the fact that I wouldn't be able to live with myself.
Having heard that baby screamed to death while I carried this painting safely out of the room.
So while it has a correct answer, save the painting, I think it's the correct, the correct
answer because you can save more babies with it. But there is something to be said about the kind
of person you would be to be okay doing that and the kind of society we'd be if we were
encouraging that sort of behavior, right?
So the painting allows you to redirect somebody else's wealth.
Or yeah.
Into, into saving more babies.
Yeah. In a way that you wouldn't have access to otherwise. I mean, you can get rid of the
castle painting and whatever, just however it needs to be. It's something that you have that
is worth a lot of money, but it's not like it's not actual human babies, but it's potential human
babies, right?
I see what you're saying. That seems like the wrong answer, but I don't have an answer as to why,
right off the top of my head.
Actually, Will McCaskell had a good comeback. He had this like a date a few years ago.
And he's like, all right, so imagine that I'm in a room with a Picasso and one burning baby.
And right across the street is another burning building full of 100 babies.
And the Picasso is the only thing I can use to jam the door open on the other buildings to let
all those babies out.
He says, that's closer to the actual real world situation that we're actually in, right?
You can save one person for a fortune or you could use that fortune to save 100 people.
I see.
So I think that that's, that's what it wants to get at.
It's not just biting the bullet. It's kind of like deflecting it, right?
Right back at you. It's like, no, look, you're going to say you're going to kill those 100
people for this one. That's fucked up. So that's sort of the turnaround on it.
So I think that that is closer to the real world situation there.
And yeah, you're just not remember why we got on thought experiments in the first place.
I know. It's totally, totally off topic. And when you have a thought experiment,
you shouldn't come up with ways that you can get around the thought experiment
because that's not what they're for.
To the person who asked why we don't die down the interesting topics when they're raised.
That's why you spend 10 minutes talking about burning babies and precautions.
Well, I agree. I couldn't say that.
I guess briefly because this, this will tie this back into what we said earlier
or what I said earlier anyway. Westward 101 also had the question or the statement that
there is a difference between a simulated being and a real world one in quotes that while humans
may be able to map the neurons of a roundworm, we can't create a real world one.
So as a test, I substitute myself for roundworms and I would not want a real world version of
myself killed, even if there was a perfectly good simulated copy running on silicon.
Thanks, Westward. Yeah.
I think we talked about that a little bit. Yes, there's definitely a difference between
a simulated being and a physical being and obviously. So it would not be an equivalent
exchange to kill one for the other. Right.
But I asked him this because we recovered that before that the consent matters,
whether when you're killing one for the other, but I asked him why because I sometimes get
this objection. Why does what material the person is made of make a difference?
Like why is the wet carbon based animal or person superior to a dry silicon based one?
And he had a long answer that he went into, but he originally answered that he thinks the person
proposing what happens on silicon has an equivalent that proposes that what is happening on silicon
has an equivalent value to reality should have the burden of proof and not the other way around.
And what evidence do I have that what happens in silicon matters?
And my answer- Matters period?
Yeah, at all. And my answer would be that I have as much evidence that what happens in
silicon matters as I do that any of you are alive and thinking and matter at all.
And that is only that I can talk to you and it seems like you matter because there is no
as far as I know, and I would be shocked to hear if we have an objective test for consciousness.
Yet there is no way to tell if something is conscious or experiences qualia in any way.
And so you would I would determine if something is as important in silicon as it is in the real
world based on whether it acts like the thing the real world does.
And I think that consciousness is a very useful idea.
So if I were to talk to a computer which said she is Katrina derivative and
acted exactly like Katrina and I couldn't tell her apart from Katrina, I would say like, well,
I guess I should probably value your life like I would Katrina's, at least theoretically,
since you seem to be the same kind of thinking person.
I think that making the assumption that there's nothing magic about the squishy stuff between
our ears isn't like the proposition that needs defending. So like to say that the burden of
proof is on set is on the person who would generalize any computational process to any substrate
seems like saying it's on you to prove to me that the moon landing hoax wasn't faked,
right? Like no, it's on you to prove that it was. I guess I mean, I don't know how you this
seems kind of obscure since it's two future hypothetical scenarios, but one would challenge
current best guesses at reality and one wouldn't, right? So whichever one seems by what we can
agree is technologically feasible. That seems to be the one that needs the defending on saying no,
if you're running on on chips, you're not real or you're not a person, but if you're running on
squishy stuff you are, that doesn't seem sensible to me. Westward did make an addendum to that saying
that it's easier to reproduce someone that is on silicon. And it's as far as we know, there is no
way to reproduce a biological person so far. So ease of reproducibility is a factor, which is one
reason they would value the biological thing somewhat more. I guess that's a point. I mean,
we have no idea how easy it is to reproduce simulated people. Right, since we don't have any.
Right. It would probably be easier than I guess, yeah, we can begin that up in the air, but I
imagine it would be just as easy as doing a data dump and moving it on to a flash drive or a bigger,
you know, another computer or something, right? But maybe it does take a prohibitively large
amount of space, but I don't know why that would necessarily be the case. Star Trek. Yeah.
Okay. Are we done? I think we're done. Okay. Thank you all for joining us. Yeah, thank you so much
for the feedback. As always, you can write us feedback on our subreddits, Bayesian Conspiracy
subreddit, and you can come see our blog post at thebayesianconspiracy.com or write us at Bayesian
Conspiracy podcast at gmail.com. That's all the ways. And at our website, there are lots of links
with every episode to supporting things and interesting articles. Yes, do check it out. If
you find the conversation just, you know, stimulating or fun, and two weeks isn't enough,
well, there's plenty to read by coming to the website and clicking on all those links. We're
always trying to post enough to keep you busy. So until next time. Thank you for listening. Bye.
