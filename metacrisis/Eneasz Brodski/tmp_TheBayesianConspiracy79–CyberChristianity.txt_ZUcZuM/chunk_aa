Welcome to the Bayesian Conspiracy. I'm Anya Arsbrowski. I'm Jess Dickey. And I'm Stephen
And today I am going to be telling you guys about Cyber Christianity, which is the stupidest
name ever, but I like it because I like warts with the word cyber in them. I just saw Battle Angel
Alita and like I was just feeling like the entire movie. I was like, I want a robot body. Oh man,
like there's like a bunch of scenes in that movie where people get robot bodies because that's like
the whole theme of the thing. And I was just like looking at the screen and making claw hands.
Like I want that. Me. Give me that. Although not with the creepy big eyes. I don't know. Like
that the super stimulus is kind of interesting in that you get used to it after the first 10 minutes.
And I actually found it to be kind of adorable. Like probably I would assume. I also thought it
was ridiculous though that like these are combat robots and they give them these like armored
bodies that then they keep their like meat head with their giant eyes and it's just like it's
just like you just stick a big target on top of them. Like, hey, my human brain's in here and it's
soft and squishy. Hit me here. That's why I like mannequin and worm. Yeah. Thought ahead. I think
it was a book that I read where they had they had robots with heads like that. The common knowledge
was that when you run into one of these combat robots, you take out the head. Turns out the head
like it has like some hard drive in there with some stuff that's mildly useful to the robot.
But mainly it's there to distract people to go for the head because they'll think, yeah,
if I take the head, it'll go down and then yeah, the robot's fine. Yeah, that's actually the whole
like drive back from the movie. I was thinking about that. I was like, why would they do that?
And I was like, oh, you know what? If you're really smart, if they actually stuck the brain in
like the chest cavity and like the head was just a decoy. Yeah. Left calf or buttock or something
random. It'd be hard to fit there. Yeah, maybe the buttock. I don't know about the leg. Yeah,
the main processing was like in the core surrounded by everything else. You could like cut it up into
quadrants and then stick each one at a different spot, assuming you could still network them together.
I think we need to design some killer robots, guys.
Thanks for bearing with me. We're now returning to our regular scheduled program.
Cyber Christianity. So you were asking in the last episode about how like you could be a
rationalist and a Christian at the same time. And I'm sure there's a number of different ways
to do it. So this is going to be just one of them. But it is one that I found very interesting
due to its focus on AI and singularitarianism. Singularity. Singularitarianism. Why can't I
say it either? Yeah, right? It's a weird word. Say it one more time. Singularitarianism. Singularity.
I don't know. Singularitarianism doesn't sound right either. It does sound weird, but. Singularitarian.
We're going to have to cut this out. Yeah. No, keep it in. It's funny. Oh, God, it's so tedious.
Singularitarianism. Singularitarianism. What the hell's wrong with us? I'm googling this shit.
Not that big a deal. All right. It's also weird to spell. Singularitarianism. All right. All right.
Anyway, so getting back to things. First of all, this is actually tangentially related. You saw
about how, what do they call it? Deep Mind, which was the basis of AlphaGo, which we had the
episode on when it beat the shit out of human Go players, which no one thought was going to
happen with what it did and it did. So they have since then created Alpha Starcraft or Alpha
Craft or Alpha Star, I don't even know what the hell they call it, a program that plays Starcraft,
and that has now beaten some of the top human players in Starcraft, like, handily. It was
nine out of 10 games, I think. Has it had a chance to play with the world's best?
They were, like, in the very top rank. They were, I think, among the top 10,
top 15 players in the world. I'm really happy for, like, the last person to be, like, the best human
before Alpha Star, whatever beats it. And then your title won't be like, I'm the best Go player in
the world. It'll be I'm the best human Go player in the world. But I was the last one to lose to the
robot. Nice. Yeah. And wasn't that also, I might be wrong about this. I think Alpha Star was the
one that proved the previously there have been this thing where if two or more humans teamed up
against an AI, or like if you had a human with an AI, yeah, it was like humans teaming up against a
singular AI, you could still beat it with numbers and then need that like disprove the, I don't know
if that was Alpha Star, there was something recently, were they? Oh, I don't know. Yeah,
previously, I think human plus AI is still superior. But yeah, I think, well, maybe it depends,
I'm not sure. But that's what I've heard is that, you know, the best whatever some of these players
are the ones that are, you know, kind of like cyborg cyborg co units where it's a human helps and
the robot helps. That still kind of gives me hope that like, maybe we can compete if you just, you
know, merge with an AI, like a little parasite. I was when I heard this, I was really shocked. I
did not think it would happen this soon, because there's so many degrees of freedom in Starcraft
compared to something like Go. Just, just so much more you can do in terms of, you know, what units
can do and what units you can recruit and how you use your resources and how you plan, you know,
going forward. Yeah, but what's funny is we're making these exact same arguments three years
ago about like, there's so many more things in Go than there are in chess. You know, that's true.
There's no way it'll be that fast. Oh my God, I was, I was shocked. And the thing is, it wasn't even
like, one of the advantages computers have over humans is that they can do an insane number of
actions per minute. So they can really do their micro, they throttled Alpha Star to be equal to
about how many actions per minute a human can do. And actually, Alpha Star had slightly less than
both its human competitors, which was also fascinating. So there was like, a lot more
thinking, not just brute forcing, right? The one big difference is that Alpha Star could see the
entire map at all times instead of just the, you know, part where the screen is. But they're working
on getting around that and forcing it to only see one, one small part of the screen at a time.
Yeah, that sort of sounds like cheating. Yeah, that could convey a pretty significant advantage
for the AI. But we can't be done once you realize that. Did they like play games where the humans
were also able to see the whole map where they just disabled the fog or something? Oh, no, it
didn't disable the fog. The fog was still there, but it was like, you know how you have the mini map
at the bottom, right? It was like the mini map was at the same resolution of the, as the four human
would be the screen, sort of, more or less, because they don't, the pixels not really mattered to
them. Right. Okay, I got you. Well, they, they should have found a way to correct for that. They,
well, they're working on it now. So it's not like true, true competition would be to allow the
human to see the whole map, right? Well, I mean, because the human can focus on everything at once,
whereas the AI, we won't be able to adjust for that. That's another point. Well, that means
so the point would be to make it so the AI can only focus on a area about the size of a screen,
right? Okay. Yeah. And can really only do most of its actions in that area. Gotcha. But they, you
know, they're working on that. They're pretty confident that given another couple months,
maybe a little bit more than that, they can get around that too and just have an AI that's
better at it than at the entire game than humans. And the, the thing that is interesting about
these deep learning networks, Alpha Star, you know, really drove it home to me, but it's been,
it's been a case for quite a while is that people don't know how they work. You like you set it up,
and then you let it go wild and learn things, but you can't actually like crack it open and
look into it and see like what it's doing. It's just like afterwards you look at it and like,
wow, that's, that's neat. I saw this cool thing about a deep learning network that was trained on
juggalos and clowns. And then asked, you know, given a number of pictures and said,
are these juggalos or are these clowns? And, you know, they don't know how it knows. But
afterwards they were like, tell us the ones you're the least confident on and tell us which one you
think they are so that they can go back and reverse engineer, like what criteria the system came up
with. It was a really neat article. I should link it in the show notes. This sounds pretty cool.
Yeah. From looking at its edge cases and how they, how the AI judged it, they said probably the biggest,
one of the major criteria for juggalos is that they're group photos, because normally they are.
So when there was a group photo of clowns, it wasn't quite sure of that one. And also juggalos
tend to not have red, whereas clowns generally have a lot of red. That's the only difference
that I could think of. And like maybe sharper, like it's not even, I was going to say sharper
eyeliner, but isn't like the whole thing juggalos black and white? Yeah. I would think of clowns
as softer to juggalos having harder edges. Clowns with black around the eyes were much more likely
to be borderline juggalo. And for those ones, they were like the pictures of the clowns from it.
And I'm like, it's basically a juggalo. That's not a clown. Ginger juggalos were the least likely
to be judges ginger as juggalos. Right. So yeah, apparently red is a very high clownness factor
and black around the eyes is a very high juggalos factor. But again, it's not like they could
look in and see databases or anything like that is just the AI learns and then you got to kind of
figure out how it learned from seeing where it goes wrong. That's just like a mind. That's exactly
what I was going to say. It's kind of like, it's kind of like your own mind or someone else's.
Right. So like training, training in AI might be like training a savant child where it's like,
how the fuck did you figure that out? I don't know if I could explain it to you. And then too,
it's like, you know, I don't know how I know the difference between juggalos and although I guess
the difference is that we could think about it and articulate our criteria. But we kind of can.
We're also not very self aware of our own brain's processes. Yeah. Like the clown from it really a
clown. I thought it was a demon. Yeah, yeah. It's that like took the shape of a clown because it was
like making itself look like things that you were scared of. Right. But it doesn't look like it.
I mean, it looks enough like a clown that you can tell it's supposed to be clown ish.
But it also looks different enough from a clown that you can tell this is not your normal clown.
This is a demon hell clown. Like every clown. Like every clown. I never was one of those people
who was afraid of clowns. I see how like they're creepy because they like push down candy valley
with their gigantic mouths and weird eyes and that sort of stuff. But there are people who are
like genuinely afraid of them. And like, actually, I think Rachel doesn't like clowns. She doesn't
want to watch it with me because I liked it. I thought it was fun. You should get killer
clowns from space for her. Okay. It's a great eighties B horror movie. That sounds like something
we could enjoy. But this was one of those things that really depressed me when I because for me,
part of the allure of being uploaded was that once my mind is in software, I can fix what
the fuck is wrong with me. I can just go in tweak some things and be like, ah, no longer suffer
from depression and all these other bullshit that I don't like, you know. And now I'm like, oh,
I can't even tell I'm with you. I don't know how that's changed at all. Well, I assumed that that
would be the case. And now you probably can't actually do that because people be like, well,
your brain's in there, but we still don't know how the fuck anything runs. So I think we're in the
process of like the reason we're developing these synthetic minds is to try to figure out
how our own minds work and to do jobs for us and stuff and to like, you know, yeah, I think it's
more than do hot dog or not hot dog. But there's because we can't even figure out how Alpha star
is doing things, right? Or how the Juggalo disorder is doing things. But like, we have a pretty good
idea neurologically what depression is and how it manifests. That's that's not like saying how do
you sort between like a chair and a seat or something, you know, like relating objects or
categories. This is just like, do you have enough of this in your head? Yeah. And so that sounds
like a really easy knob to tune, right? No, because what if you wanted to because one of the things
you discovered is that redness has a high a clown factor and groups have a high Juggalo factor,
right? How do you go in and change that in the program? You don't. But we're not talking about
adjusting your your category adjustments. We're talking about adjusting chemistry.
Well, there's no actual chemistry in your simulation. I guess you can simulate how much
chemicals are in the brain. There'll be something that's like, what functionally isomorphic to how
neurons work. Yeah, absolutely. How we do this, right? So like, yeah, so whatever, whatever it is
that we're simulating neurotransmitters, probably just the regular electricity. Yeah. And then if
it is, if it just does turn out to be a complete brain emulation, then yes, I can see how you
could simulate different levels of chemicals, but it still doesn't get you over like childhood
trauma and shit. I think we're actually closer to solving that in meat space. Yeah, like I would
bet more that we're going to be able to actually fix depression earlier than we're going to be able
to figure out how our mind works and figure out how to upload it. I think we're closer.
Well, I mean, how would how would you get someone who, for example, cannot form emotional bonds
because of a deep seated fear of abandonment due to losing a lot of people in their childhood to
get over that through tweaking bits? Really quick, though, that's a different
question than solving depression. But I mean, that's that's like a huge specific problem,
whereas like, right, just if the depression probably triggers because the person is lonely,
because they can't form relationships. But like, if if somebody who responds to antidepressants,
I think is like the kind of person that'd be easy to fix in the simulation or in an emulated mind,
this is kind of why we can model life and why antidepressants work. But for like your example,
I've ever tried alcohol for many years.
Yeah, for an example, like the one you were just saying there, I believe they're experimenting
with I forget which chemical it is. And I think it's a former psychedelic or former
street drug with causing you to forget or there might be two different applications. There's
ones that are just causing people to forget trauma. And then I at the psychedelics are
ones where they're trying to kind of do like a hardcore form of CBT, where you're reframing
your trauma. If you're doing it on psychedelics, then it kind of actually is more likely to reshape
those neural pathways. That's kind of like the cancer patients who don't fear death as much,
or at all anymore, after they're given like a high dose of psilocybin.
And depending on how all this works out to with us emulated, so like we could go kind of just like,
you know, again, functionally isomorphic robot brain, or we could do something more like a computer
today. And like, in that's the case, you just got this big box of shitty memories that you can
just throw away, right? You can ask today's computers to do that. Yeah. And then of course,
you get no pointer exceptions with a bunch of other stuff, because a lot of stuff connects to
that. You'll have a bunch of shit to fix. But you're just a broken human throwing out
errors every few minutes. Wouldn't necessarily want to delete things in my past anyway.
Yeah, exactly. I like the approach of reframing the trauma. Or rewriting it. Yeah. Like, well,
you still have it as part of your background. No, rewriting it. Oh, you guys don't like the idea?
That's that's that's basically, I know, I know. You're talking about like going back to like,
inserting like a clown in there. That's like, like brain rape, just going in and altering
yourself. No, it's like brain masturbation if you do it yourself. That makes me think about a
scene in methods of rationality where Harry was trying to like make Neville like less afraid of
everything. So he had like, people giving him chocolate, but they were dressed as dementors.
He's like, stop it. Stop trying to make me feel better. You're just doing such a terrible job.
Yeah, that's, I guess, I mean, I don't know how to respond to reverse mugging. If anyone wants
to try it, that'd be great. And I'll let you know. So where you cost me and throw a bunch of money,
I mean, I'll let you know how scared I am afterwards. It'd probably be proportional to how
much money you give me. So give me a bunch and then I'll tell you how scary it was. That is kind of
like, um, what is it called exposure therapy, though? Yeah, but except plus the it's like,
not just exposing you to it, but making you form positive connections with the thing that you
were phobic of. But if I'm phobic of being mugged, there's a good reason for that.
That usually comes with violence and pain. Yeah, but say if you're traumatized from being mugged.
If you're disproportionately afraid of it to the point where you never want to leave your house.
Yeah, I wouldn't want someone to mug me and give me money. I would want like people to walk past
me in the street and not have bad things happen. They just got me like pushed up against the wall
and like, Hey, here's $200. Exactly. It's the violation that I dislike. Here, have a cell phone.
Have some keys. You want someone else's wallet? There you go.
Yeah. So I guess what I was getting at is that you can't really tell how the AI is running with
the processes are at the root of it, right? You can't like read its mind. You can't read its mind.
I think that like people, it bugs me when people say this to a lot of people, like, well, we don't
understand how brains work at all. And I'm like, no, actually, we're getting pretty close to
understanding it. Like we know a lot about how brains work. Even like predictive processing,
