that.
So, uh, I'm just going to go with M because emails are not public and I don't
know if this person wants their name revealed.
Uh, M says, it seems to me that the most effective cognitive booster is sleeping
regular hours and exercise, that unless you're already doing that and really
need more, it's a bad idea to move on to untested drugs.
Someone mentioned that exercise was too time consuming, but I feel like they
weren't considering the additional health benefits.
Maybe if you're an astronaut, nootropics are a good idea since you got limited
time in, in space, a limited time in space for your science stuff and you're
already operating on the edge of efficiency.
And, uh, yeah, I, I think we did bring that up a few times that really the best
by far things you can do is get enough sleep and, uh, get exercise.
Those just have such ridiculously outsized effects that it's hard to compare
them to anything else, but nootropics really are, are sometimes you don't get
enough sleep and you don't get enough exercise and there, there are a way to
cheat.
Yeah.
I mean, I don't know a lot of people who sleep and exercise and still drink
coffee and coffee is nootropic by any measure.
You make a good point.
Like, and there's all kinds of other benefits to exercising.
I don't think anyone's shitting on exercising.
It is time consuming, but like, it's not just for the alertness factor.
You have all the, the awesome side effects of like living longer and feeling
better all the time, like those things are, make it worth the time probably.
Looking a bit better too.
Oh yeah.
It's a nice side effect.
All right.
I only have two things left.
Let's go with the one from our, this was also from a private channel.
So won't say their full name.
I understand it's hard to keep up on topic with podcasting, airing delay, but
getting back to repugn conclusion.
How long ago's we talked about the Republican?
Really quick.
I think this is an internet handle and this person was a Patreon supporter.
Okay.
So I think we can say that their, their handle was Roman.
Okay.
I don't know if they, I mean, that's not a whole lot of self identifying
information, but it's there.
Thanks, Roman.
We appreciate your contribution and we're reading your question on the air.
Yay.
I already had an argument with a friend about this, but it seems like a
simplification error.
You simplify the real world too much in order to draw this conclusion, even if it
seems perfectly reasonable, it doesn't mean that it can be applied to the real
world.
In reality, you can't have a society where everyone is of equal happiness, nor
can you simply tell some, nor can you simply tell that someone is happy
enough if he hasn't killed himself.
Which is true.
Not only this person might be counted as unhappy, but he can also make a whole
bunch of other people miserable.
I've personally had the misfortune of encountering some pretty bad people and
can't help but hold a very strong belief that if those people were to
disappear, humanity's total utility would go up.
And I think it actually has a really good point about that because it is a bit
oversimplified to get to the point like where everyone is just above the level
of having a life worth living and then you introduce another person and they
will bring things down because happiness is not necessarily tied to how the
resources are distributed.
And people do vary greatly in their happiness.
There's probably people right now that would fall far below that line of
wanting to keep existing necessarily.
And so, yeah, to make it all flat and consider everyone even like that, I
think, makes the thought experiment a bit too simple, like thinking of a
spherical cow.
So I haven't actually read Derek Parfit's whole version of that, but I can only
imagine that the comeback to that would be something like, well, you take an average.
Right?
An average is just a nice point.
But I don't think the point of the thought experiment was to get to the
point where adding just a few more people makes everyone much more miserable.
And so that is why we shouldn't add more people in the more extreme conclusion
when there's only like a million people around.
Are you very familiar with Parfit's repugnant conclusion?
I'm not like an expert on it.
But I would say that one thing that you just said, Enya, that resources don't
directly translate to happiness is important when you think about actually
applying this to the real world.
Because real human happiness actually is affected by the number of people around them,
the number of people they get to interact with, the number feeling like they're lost
in the crowd and feeling like there's so many of us people that we're not noticed by maybe
some people who are more powerful or whatever.
I think numbers of communities and numbers of people that you are expected to take into
account, but maybe you can't take that many people into account directly does affect human
happiness in a way that doesn't directly translate to resources, as you said.
And therefore, given that it's so, there's such this feedback loop going on,
how could you even calculate it if you try to make a practical implementation of this?
I think basically that last sentence, how can you calculate it if you're trying to make an
implementation of this, is like you come back to like 50, 60% of all moral thought experiments.
But I think the point, it's less of this is an actualizable thing that we're trying to work
towards and more of like an intuition pump. And I think the point of Parfitt's analysis of this
is that like, no matter what position you take, none of them work out well. So clearly we don't
have a great picture of what we actually want and are trying to do. So I think it's less about
like trying to prove this point that this is, I guess what I'm trying to say is that it is overly
oversimplified and confusing, but even the simplified version draws up these contradictions
from like what our preferences are and what we're working towards. And so that's more what it's
about. It's just that like, we don't have a coherent extrapolated volition when it comes to
like happiness levels in population. Well, I agree about that. But I think
that the thought experiment is so, it has to map onto something that to make it make sense.
It's not mapping onto anything. It's like the trolley problem.
Well, it is just trying to say like, if you had to choose between A and B, which would you choose
to let you investigate what you really care about more A or B? Even though in the real world,
you probably won't have to choose between A and B.
Right. Well, I mean, I think that makes total sense for things like the trolley problem where it
actually maps onto things in reality. But with the repugnant conclusion, like if one more person
were to be born today, would they bring down or increase the total happiness? I mean, maybe...
Depends on how happy they are.
Exactly. So that has absolutely nothing to do with how many resources. Well, not absolutely
nothing, but they... Right. It depends on how happy they are. If we're right at that level of
subsistence, you introduce one more person, maybe they'll increase the happiness level,
because they'll be more happy than people in general. Or maybe right now where we have,
I will go out on a limb and say, a high amount of overall happiness in society,
you introduce another person and they may drag down things instead of...
You have a low amount of happiness in society.
You think? Oh, I think it depends on how you phrase the question. Like the most plentiful
countries tend to be the highest suicide rates, which is counterintuitive. But I mean,
we are enjoying pleasures that our ancestors, they spent 16 hours a day tracking down lunch
and dinner and hiding from tigers and shit. And we're... Our downside is like,
ah, my TV show got canceled. That is such an awesome problem to have when our ancestors were
scratching the dirt trying not to die. But also they just didn't have time to think about whether
their lives were a good thing to continue living or not, right? They're so busy, they didn't
think about it from the existential perspective. And now all this free time means that
we have time to reflect on that and come to the answer that like, oh, shit, it's pointless.
So I feel sorry for them because they didn't realize. Oh man, I'm glad my ancestors didn't die.
At least, you know, not before they did anyway. So most of my ancestors are dead.
I think I might have pointed this out when we were talking about repugnant conclusion,
it's been a while. But one of my favorite people, Will McCaskill, was on Sam Harris's podcast
months ago, maybe a year ago. And he talked about this for 10, 15 minutes, and it was awesome.
And so unless you want to dig up Parfait's essays, maybe Roman read them and found them
uncompelling. And if that's the case, I want to come back to this once I've had a chance to get
into it more, and I will. You know what? Next episode we do, do you want to do the repugnant
conclusion and economics, like specifically how the capitalist system treats people right now?
Because I've recently been reading up, not reading up on, I've been recently reading a blog that
is making a very interesting argument, which has been changing my mind quite a bit over the last
month. And I would like to talk about this. Yeah, well, your market, that sounds fun.
Okay, cool. That said, I'm plugging Will McCaskill's presence on Sam Harris's podcast,
Waking Up is the name of the show. Okay, I would check it out. Even whether or not you care about
Parfait's repugnant conclusion, it was a great interview slash discussion. I will listen to that.
And I do want to say that the concept of a practical implementation that takes into
account their pregnant conclusion could conceivably be a thing you need to start figuring out how to
calculate when, if there is like a friendly AI that's taking care of everything, and you
don't need to actually calculate people's happiness and determine how it's going to be affected
by having more people. Which is another thing that ties into our transhumanism, which we're
about to jump into. Well, you know what, this other thing I can probably bring up next time.
So that's some of the listener feedback we've been meaning to get around to,
and have been too busy to do lately. So sorry about that, but thanks for your patience.
And I know we miss some other stuff. So we will definitely be on this more in the future.
Yes. You know how a lot of people, you get into arguments with them and they're like,
well, it's unnatural to extend the human lifespan and we all need to die and that's what gives
life meaning and all that. I have the exact opposite intuition on things. I feel that it almost,
so this is coming from a religious background where I was literally told,
God created all people to live forever, which is why that is what we're going to get after Jesus
comes back. So this is at least influenced by crazy religious upbringing. But I get the intense
impression that if you wanted to create a race of beings that would be very happy living forever,
you would create something much like humans that are constantly changing and constantly growing
and finding things that they used to do boring and finding new things exciting and who find
richness in interacting with others and all the different permutations that can come from that.
And also that forget things over time. So who you were like 70 years ago is a very different
person from who you are right now, both due to changes in biology and just due to changes in
circumstance and life experience. And it just seems like such a damn waste to kill someone off when
they're 90 years old and they've just gotten started on everything. If you were to create a
being that just could go on forever, it would be something like humans that that's the kind of
being that doesn't get bored. It doesn't eventually run out of things to experience because it's
already experienced everything. It can come back to a guitar after three millennia and be like,
Oh yeah, this thing. Yeah, let's do this again. Because I forgot how to make it fun or how to make
it sing. I think that's a really good point. I'd never heard it put that way before. And I'm
still unpacking it. But I guess I have one quick thought, which is that you mentioned like, you
know, killing somebody at 90. And I do feel like it'd be a different conversation if people lived
on average to be 1000. I don't think that anyone arguing that, Oh, they should die at 90.
There are some people that do not, I mean, either far fewer. Yeah, not specifically,
we should kill people that make it to 90. But along the lines of, you know, four score and 10
is as much as any human really should have. And after that, shuffle along and make room for the
new generations. And also that it would make your life meaningless if you just kept living.
I think, I think people only say that because that happens to be ripe old age right now.
Yes, I agree. So like, if, if, like just if our ancestors lived to be 1000,
and that was how long everyone lived, then they'd be saying 100 score instead, right? So
how much does a score 20? Then whatever. It's like that scene with Dumbledore was like,
Yeah, but I wouldn't want to outlive my 280 years, Harry. He wants to live longer than that.
Right. The only thing is that you mentioned that some people say it's unnatural. I don't know
what you mean by that word or what you think they mean by that word.
I think what they implicitly mean, even though they haven't thought about it, is that it is
how long people live right now. I guess why is what's natural? Like what's wrong with doing
something natural then? Not my word. I mean, if you had to, I just, that's what's uncomfortable
to them. Like there were people who said organ transplants are unnatural when that was first
introduced. They're super unnatural. The idea that like I could be walking around with someone
else's heart pumping, my blood is really weird, but I don't think it's bad. Right. I think people
have an intuition, a Chesterton's fence intuition that maybe they couldn't explain as well as
Chesterton did. Do we want to quickly cover what Chesterton's fence is? Probably. Would you like
to be honest? Well, if you come across a fence out in the open and you don't know why this fence
is there and you're like, well, since I don't know what it's for, I'm going to get rid of it,
then you realize that it had a purpose. Like you get gored by a bull and you're like,
oh, it's keeping the bull away from me. The idea is that you can remove the fence, but only once
you actually know what was put there in the first place. And yeah, to say like, I don't see the
purpose of this, let's get rid of it is not wise. So I mean, the reason that the Chesterton fence
