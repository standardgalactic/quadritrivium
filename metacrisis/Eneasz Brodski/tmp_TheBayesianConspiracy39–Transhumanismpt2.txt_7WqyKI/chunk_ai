But I was really attached to the, I'm imagining it as Machine Doggo.
Okay.
Who says things like, hi human, we are friends.
Are you sure you want to kill yourself today?
Dogs don't want you to do that.
I reminded a little bit of when you mentioned Machine Doggo,
what was that story that you linked to a couple weeks ago on Facebook?
Utopia Lowell?
Yes.
Oh my god, that was a fun story.
That was. I found it actually kind of, like you mentioned, it was kind of a roller coaster.
Like at first it just slapstick fun.
Yeah.
But then you get into it and you're like, oh, this is touching.
Yeah, we should link to it.
Probably too difficult to summarize in a way that would capture the essence of why it's worth reading.
But Utopia Lowell, fantastic story, very fun to read.
Very much in, I would say, the style of HPMOR even.
Yeah, well a little more slapstick, but it's also like what, half an hour read?
Yes, yes.
It took me maybe half an hour and I'm a slow reader, so.
Yeah, it's only 5,000 words.
It is a short story, highly recommended.
I was set to find out that.
It ended the way it did, kind of.
The AI was not the way that I would want the AI to be, that's it.
This part right here, we will put it on the next episode after people have had two weeks to read.
But go ahead, what were you upset about the AI?
Oh, okay, okay.
Well, we have the power to bend time.
It is inherent in computer technology.
We're going to spoil that story that we were talking about.
What was it called?
Utopia Lowell.
We're going to spoil Utopia Lowell.
I strongly encourage you to read it and then listen to it if you want to afterwards.
It's a really fun story.
It's worth getting it without the spoiler, and it doesn't take that long to read.
Cool.
And it's available free online.
Not only is it available free online to read, it is available in a podcast as well,
because Strange Horizon podcasts all their fiction.
Read by Anaela.
Who was also a voice in Harry Potter and the Methods of Rationality?
Cool.
Yeah.
Who did the voice in Methods?
She did, God.
It was a minor character.
I think it was the girl that snaped bribed with a large ruby in the dungeons in Confessor,
the interlude with the Confessor.
Have fun.
Chapter.
Yeah.
At this point, we talked about the story Utopia Lowell for a number of minutes.
We are removing it from this episode to avoid spoilers,
and we'll add it to the end of the next episode in two weeks.
However, if you want to hear it early,
it is available to our Patreon subscribers right now.
Otherwise, you can hear it in two weeks.
And maybe we should go back to the two topics that we were kind of in between.
One is, is the CEV even possible?
Can we even agree on what we want our transhumanist future to be like?
And two, like, in particular, what we made disagree on is the nanny-ing.
Yeah.
Right.
And I guess I also wanted to bring up the conundrum of, related to nanny-ing,
how much people should be able to alter themselves.
Maybe we can say that they should just have the autonomy to do whatever they choose,
but they should be warned strenuously.
For instance, like when I was talking about how maybe I want to expand my memory and brain
capacity to the point where I will get bored of my friends, even a whole lot of friends.
There are humans on earth who have, I forget what it's called,
super autobiographical memory, is what I call it.
I think there, I remember James MacGaha, I watched him give a talk about it,
like eight years ago, who is interesting.
It turns out it's different parts of the brain that remember different kinds of things,
like your declarative memory is different part of your brain than that's why people
in amnesia can still learn new things or why, you know, you can, etc.
But people with perfect autobiographical memories,
I don't think reported that problem.
They do report the problem of being less happy than the average person,
because they remember every bad thing that ever happened to them by somebody,
and every vindictive comment from every asshole in elementary school.
They also have, even with their enhanced memory,
they still have basically the same done bar number that an average person would have, I expect.
That's like 140 people.
I think it's like 150 around there.
I think it depends on the person, but I've heard between 100 and 200 with an average about 150.
For me, it's like 20.
We should really quickly define the done bar number for people who aren't familiar with it.
Right.
Would you like to, since you brought it up?
Okay, I will.
So the done bar number, or as I have heard it called,
and which I like to call it, because it is much more fun this way, the monkey sphere.
Yeah.
Oh my God, I've never heard of put that way before.
Oh, really?
It's awesome.
Okay.
Is the maximum number of strong personal connections that people can have with other people?
Is it strong personal connections though?
Because some people at the outside of your sphere are not strong connections,
but they're like the number of people you can kind of keep track of as being in your general
social vicinity.
Yeah.
Well, I mean, by strong personal connections, I think of people on Facebook who have 500 friends.
That's still sort of a social connection because this through Facebook, but it's not
one that I really consider as counting as strong.
Okay.
So I heard it like an ability to keep track of that many people in your mind of like,
oh yeah, that's Jim.
He's married to so-and-so and they like tennis, have that level of connection with people.
The friendly acquaintance level, perhaps.
Yeah.
There's probably an operational definition.
It's better than all three of these.
Yeah.
But think of someone that you know in real life as at least a friendly acquaintance level,
that about 150, with the one to 200 range being what most people can handle.
And after that, they top out and they just, they can't handle more people.
They have to lose some people.
And I can imagine that if everyone upgraded their Dunbar number, that could cause some
problems with socializing, perhaps.
Oh, what kind of problems?
Unforcing problems.
What kind of problems do you think?
Like people feeling lonely more easily if they're...
Oh, despite knowing more people?
No, well, because they now need more to have more relationships.
Do you think it changes how many relationships they would need to have?
I don't know, maybe.
Maybe that capacity is one of the things that affects our social needs.
Maybe just boredom, again, is one of the things.
If you can keep track of gazillion relationships, are you going to get bored with fewer?
I think that's an unknown cognitive question, because we don't have...
I mean, it's hard for me to speculate, because that's a very different kind of person.
I did have a good definition of Dunbar's number from Wikipedia.
Is a suggested cognitive limit to the number of people with whom one can maintain stable
social relationships, dash, relationships in which an individual knows who each person is
and how each person relates to every other person.
Yeah, I like it.
As far as whether or not having that number go up or down would make people happier or sadder,
I am struggling to imagine why it made people worse off.
I think it's not defined as the number of people that someone needs to know
to be happy and flourish.
It's just the number of people that you can just currently keep track of.
But if you didn't have...
I think dialing that knob a little bit wouldn't really ruin anything unless you'd turn it...
I mean, unless you didn't attune the adjacent knobs appropriately too, right?
You never know.
Maybe you'd need to have a complexity of a level where a certain percentage of that
is full in order for you to feel like you are living in a socially rich enough world.
Otherwise, the world seems bleak and empty.
And what if just increasing your IQ itself makes you more likely to get bored with shit?
Probably does, judging by the number of miserable artists that I hear about.
Yeah, and just in general, I think, isn't IQ slightly negatively correlated with happiness?
Probably.
I know that to the extent that religiosity and IQ anti-correlate, I know that...
I don't know what the nice way to put it.
People who would identify with smart groups like skeptics and atheists
tend to have higher rates of alcoholism and depression.
So that would seem to suggest some sort of relationship, at least loosely,
depending on how well you want to say those things are tied together very closely.
And it's hard to point, figure out which one is the causal factor.
Well, I don't know, being more depressed would make you smarter.
No, no.
But maybe religion makes you happier, and since being smarter means you're likely to be less
religious, that is where the unhappiness could come from rather than the smartness itself,
potentially.
As a non-religious person, I'm going to go ahead and just spell out the alternative,
where stupid people are more religious, and stupidness equals happiness.
I'm not saying that's true.
I just felt like the other side of the coin needed to be shown some light there for a second.
There is pretty strong evidence that religion itself is a causal factor.
Well, okay, I'm not going to say itself, but the social aspect of religion is...
Oh, sure.
Yeah, that's not, I mean, that's distinct enough from religion that you can get that in other places,
right?
Yeah.
Like we have our rationality meetups and stuff.
It is really hard though to get that kind of community bonding and social structure.
Yeah, if you're not going to threaten somebody with eternal torture,
it's hard to get them to do whatever you want, so come every week in tides.
But I've been thinking lately, I think the whole you have to come every Sunday,
sort of a good adaptation for once you get really busy and an adult.
Like when you're a kid or in your teens, early 20s, it doesn't really matter.
But once you start getting really busy and adult and you just don't have the time to get
together and socialize with other people, the being forced to show up every freaking Sunday
turns out to be a good thing.
Yeah, I guess I just sort of worry about what goes into it to make it forced, right?
Right, well, eternal damnation.
Right, so like I feel like that's probably a stick that isn't an ingredient in a good
mental architecture, right?
Sticks a little too big.
A little too big, a little too sharp.
Yeah.
Yeah, they're all kinds of things that I kind of worry about.
People having the options too, but then again, I just want them to be able to do it,
