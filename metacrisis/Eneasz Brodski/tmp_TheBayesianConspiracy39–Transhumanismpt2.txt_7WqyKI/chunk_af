is there, I don't know if there's a reason for that, unlike when we die is because our cells
run out of the ability to duplicate reliably. And that's like, I mean, there's not really a
why behind it. I think they're misapplying the concept, but it is that intuition
that you shouldn't change things. And there's a sense of like people have an intuition of
being designed by some creator. And even if they don't specifically believe in that,
there's still this weird intuition that a lot of people have about evolution being in some sense
purposeful. And then so there'd be like, if we lived for much longer than we do, then there'd be
all these unforeseen things that we evolved neatly and usefully evolved to avoid all those
terrible things. And now we have to deal with them and we don't even know what they are.
That's fair. So yeah, even if you're not running with the God made purpose, the people have this
intuition that things aren't the way they are for no reason. And so we should figure out what those
reasons are before we start fucking with things. I guess I can see that. But I mean,
AM much more willing to quickly swallow that pill of things are the way they are for basically no
reason, or at least no good reason, especially stupid biological things. Yeah, those are all,
I mean, the reason for those I think are pretty well understood. And they're not, I don't think
there's any moral backing to them, right? I'm also not super convinced just by data that because
something is unnatural means that it's bad. I think my favorite one version of that that I heard
of what natural means is using something for its intended purpose. And in that sense, homosexuality
was unnatural because you're not using your reproductive organs for the way that evolution
or God intended. But then I'm like, the best comeback to that is opening a beer bottle with a
hammer, like morally wrong. I mean, it might not be the best use of a hammer or the best way to
open a beer bottle, but if it gets a job done, like, it's not morally wrong. Like, I don't think that
they may say that you are degrading the beer bottle on the hammer, but it's much worse. Like,
it doesn't matter to degrade objects, but degrading your own body is something that matters.
My own fucking body. That's what I might come back. Don't you need to be telling me what to do?
Yeah. My bottle and hammer. Something, something.
I'm going to dive into that. Kind of reminds me of the feedback we got,
which I didn't get to, but I think it was also by Mr. Oliva saying that he's mainly
against things like performance enhancing drugs for kids, because it would be like a barbaric
Roman gladiator sort of thing to see people just smashing into each other and destroying themselves.
And I'm like, yes, but on the other hand, it's when it's a kid, then obviously that's bad thing,
but it's our own bodies. We can do what we want to them. People are regularly risking their bodies
doing things like driving in, in sports races or, or mining or anything you do that risks,
has some risk of danger to you. It's your choice. It's your body, you know, use it up how you see fit.
Yeah. I mean, those are different situations to one of the kids and doing it yourself.
But I'm also like, I could spend 10 years working out to become like as athletic as an
Olympian, or if I could do it in two years with drugs, it's hard for me to see like,
as long as there's no serious drawbacks, why one's better than the other.
Well, the thing is that there often are serious drawbacks, but and yet there are perverse incentives
that motivate people to, to value, to be willing to sacrifice their health for an Olympic medal
or whatever it is. Yeah. If there were no like physical side effects to, to taking those huge
making drugs, but people did get torn up on the, out on the playing field doing this
for our entertainment, is that, is that still wrong in some sense?
Like there was that huge outcry about the concussions that NFL football players suffer.
And they're still playing football. They are still playing football, but they have changed
the rules a little bit to make the concussions to take that into account.
I mean, boxers are still wearing gloves and, you know, ruining their lives too.
Like, in fact, he met Muhammad Ali, right? I did. You met Muhammad Ali? I did.
I get the impression that he probably would have been a healthier old person and an older
old person if he hadn't boxed his whole life. Parkinson's. Might have been linked to his,
you know, repeated traumatic brain injuries. I guess I don't know that much about the UTL,
I was, of Parkinson's. How was he when you met him? Was he still functional?
He couldn't speak. Um, yeah. I didn't mean to like name drop for you, but I remember that that
was interesting. And it was, I always think of like boxers when I think, I mean, football,
because yeah, they've tried, you know, better padding, changed rules and stuff with boxing
or like really any fighting. Uh, that's, I mean,
Head trauma is the point. Yeah. It's partly like they're for their glory, but it's like,
it's only glory for, gloryful, glorifying for them, because it's fun for us, right?
I don't actually watch professional fighting, but, uh, like for some people it's a lot of fun.
And that's why they get glory out of it. If everyone thought it was barbaric and gross,
they wouldn't, fewer people would do it. Yeah.
And even in the Roman times, most gladiators were, uh, people who wanted to be gladiators,
because it brought a lot of glory and money and you had rich ladies coming over and wanting
to sleep with you. Cause fuck yeah, you just tore some shit up in the gladiator arena.
And it probably beat other kinds of being a slave. It was what?
It probably beat other kinds of slavery. Right. So, right. So that's one of the
perverse incentives that, that leads people to do things like that. Like your life is going to be
pretty shitty. So why not go out in the blades of glory?
I'm going to go ahead and drop stars, uh, the TV show network, uh, version of Spartacus. Very fun.
Yeah. Gladiators.
But we can all agree we don't want to have modern gladiator arenas, right?
Where people kill each other for the glory and our entertainment.
I mean, do we want to tell people what they can do with their bodies?
You know, I thought we just settled on that.
That's what I'm bringing up just now. Yeah.
I'd be, I'd be okay with it if people really weren't free and didn't have these, you know,
pressures coercing them into it. If people like made that choice in the vacuum of some, some sort.
If they didn't need the money to feed their family.
Yeah. Or yeah.
I mean, I don't know how you'd remove all those incentives and have it still be a desirable
thing to do. Like I'm sure like playing football is fun for people, but it's also fun because they
like people watching and sharing their name and stuff. And like, I don't know if that
incentive is perverse or not.
Let's imagine the, the transhumanist future where some people decide to tell the AI to,
to build some kind of risk of death into their
activities. And maybe they do it for the sake of an audience as well.
A common thing to find in transhumanist fiction is that sort of risky play.
In every novel that I've read, society has basically shrugged and said, okay,
I'm not sure if that's a realistic depiction of how things would go.
And I would hope that the people who do that and the people who like to watch that
could be like in a totally different part of reality than me. So I wouldn't have to talk to them.
I'm not, not talking to them because like you would be sad or.
Yeah, it's just kind of like, oh, you like that? Well, I'm going to be over here.
Would you try to stop them?
No, I'd be like, that's, that's your deal. And also your personality is just tasteful to me.
I think I'm in your camp, but I'm also just like contemplating this for the first time.
So like, the idea is that they would do the same crazy fun stuff that all of us want to do,
but they'd like to leave all their backups first and then film themselves or something, right?
Like, is that what sort of you're imagining?
Well, that's, that's a good enough, that's close enough.
Again, part of me is like, well, do whatever you want, but I would also think that they've
got some serious priority issues if they care more about like the applause of the crowd than
like living till tomorrow.
But maybe they also have some, they're doing it partially for themselves, I bet. I bet the,
the thrill of I could actually die is, is part of it. And then also the audience
is also another part of it.
There is some risky behavior that I'm attracted to purely because it is risky.
That's perverse and your personality is just tasteful to me.
Whoa.
Aw.
Yeah, I'm, I'm pretty low risk guy. So that none of that appeals to me or even really
makes intuitive sense.
I am for the most part, but there's just one or two things that it's like, oh,
this is going to be fun.
Okay.
You've got a loss to at least one of them.
No, I don't.
Okay.
I thought that might work.
So, I mean, I don't have a good answer to that. That's an interesting thing to consider.
I'm sort of at a loss.
Well, this kind of brings up the issue and there's a whole article about it in the fun
sequences, fun theory sequences. And I wish I had read it more recently so I can report
what it actually said, but it was about dangerous options.
I'm not sure what the, the title was something similar to dangerous options, but it wasn't that.
But the idea that in the future, we should not allow every conceivable,
like doable option to be available to people because they'll screw themselves and we should
somehow like nanny them out of it.
I'm sort of in favor of, I don't know, I need to give this some more thought. I tend to be,
when I'm first exposed to an idea, I tend to just agree with whatever the first thing I hear is.
I'm trying to, I'm trying to, that's something I'm actively working on is to correct that and
just reserve my position. I can see the benefits to that position. I can see why some people
find it compelling. That's as much as I'm willing to say right now.
I think I strongly disagree with that. I'm reminded of the metamorphosis of prime intellect,
which is available free online and it follows someone who is, they're just a legitimately
crappy person. They're mean, they hurt other people and they are very masochistic as well.
They hurt themselves a lot and they're upset that they are in a reality
that is run by an Evelyn AI that won't let them kill themselves.
She's a protagonist that you're talking about, right?
Yes, she's a protagonist.
I don't remember her being that mean. I remember her being very masochistic and in some instances
vindictive.
It's very hard to be terribly mean in that world because you can't hurt people if they
don't agree to it.
But also she seemed to care about people.
But she was extremely self-destructive and I feel like the story was meant a sort of
an extreme outlier as if someone was this self-destructive and hell-bent on hurting themselves,
should we stop them? I think I kind of come down on the point of view that I think the
author was advocating that no, go ahead and let them hurt themselves. It's their body and their
choice. They're an adult.
I think the point of that story was actually something else.
It was to raise the question of whether people's lives should at all be safe.
Even have the option of a safe life.
I think you should have the option.
Because remember this protagonist destroyed the AI and returned everyone to
like prehistoric technological level.
Spoiler alert.
Spoilers.
Second, I disagree. I don't think that happened. I think that the AI allowed her to think that
that's what she did and created a special simulation just for her where she could go
ahead and be as self-destructive as she wanted after that.
I haven't read the story, but I like your version because it means that the AI is
thinking at one level higher than this person. That's awesome.
That's what I want from a super intelligent major.
The last chapter was from the perspective of a child of the protagonist.
Which if you're going to actually give someone that level of freedom,
you kind of have to let them have children as well, right?
No. If you're going to go to the point of tricking them into thinking that this is reality,
why not trick them into thinking they have kids also and rather than condemning a
non-consenting person to live in that reality?
I want to ask a clarifying question. How did this person end up in this world?
Were they just born into it like an average person?
They were dying of terminal cancer at very old age.
They lived through the singularity.
Yeah. The AI basically took control as they were dying and saved her,
but she'd lived for many years in constant pain.
Interesting. I could say that makes someone bitter.
And then once she was in the perfect world, she hated how perfect it was.
She said there's no meaning to life if you don't have anything to struggle and
there's no fear of distraction.
Okay. Which I disagree with.
I was going to say it sounds to me that the AI that put this world together did a bad job
in letting people in of that predisposition, but they've brought in already-existent people
of whatever disposition they were and had some imperative against changing them as people,
which is probably a safe bet.
Okay. Oh, they covered that already, I guess. That's a good point.
So I tend to believe that it actually did happen because otherwise,
why is there this person who's perspective we are now seeing through who is the child of her?
I see your point. I still like my interpretation.
Well, that would be nicer for sure.
So the real question that we're trying to figure out is like-
Should we nanny people away from things they might do to themselves?
For instance, I would make my memory perfect and I would not be one of those humans that you
describe that forget things over time.
Oh, really?
But should I be prevented from this?
What if I remember every person I've ever been friends with and then as time goes on
and get bored with being friends with each of them and I eventually become friends with everyone
and then there's no new people for me to be friends with,
but then we have to create new people, but then we have to calculate
