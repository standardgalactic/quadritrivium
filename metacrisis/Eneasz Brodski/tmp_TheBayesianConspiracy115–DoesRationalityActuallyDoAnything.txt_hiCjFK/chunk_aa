Welcome to the Bayesian Conspiracy, I'm Eni Ashbrotsky, I'm Steven Zuber, I'm Jay Sticky,
and today we are being led in by Steven, actually no, because we're doing the god my stupid brain.
The Sequences.
The Sequences post.
Thank you, we're doing the Sequences first, yes.
Oh yeah, I will be totally honest, I forgot them, but I'm ready to pick it up as we start
in.
Alrighty.
I didn't forget them.
Huzzah.
Should I lead?
Sure, go for it.
I'm just pulling up my notes, so yeah.
Yeah, so we've got My Wild and Reckless Youth, which is about Eliezer when he was a young
wee lad, and he apparently tried to come up with an explanation for neurons that involved
quantum gravity, and he considers this to be like one of his greatest mistakes or possibly
his greatest mistake, which sure, if you're Eliezer.
I'm sure there have been more mistakes made since then.
Well, there's like, there's a net, there's a post way later on in the sequences about
like my, my best and worst mistake or something, and this wasn't it.
I think that's just an example of him totally failing to reason properly.
Yeah, no, I think it was hyperbolic, but basically, yeah, that was his sin was he described it
as using a mysterious answer to explain a mysterious question, which he had been leading
up to in some of the previous sequences as well.
Yeah.
He said this was because he was a devoted capital T traditional capital R rationalist, and he
had not yet known the way of Bayes, which was also capitalized.
Yes.
He says that even after he invented his answer in quotes, the phenomenon was still a mystery
unto me and possessed the same quality of wondrous compenetrability that it had at the
start.
Yeah.
Um, I'm a bit like, I sort of wish he had explained what he meant by traditional rationality.
I'm pretty sure he just means the scientific method, the sort of norms of thinking philosophically
or scientifically like at that point in time.
Yeah, I got that.
I think that's the impression I got as well.
I get the feeling.
Yeah, I get the feeling it's like what people think of, of the like Victorian era, people
with beakers and, you know, writing in scientific journals and just using very formal language
and doing the best they can at the time, you know, but, but it's, it's moved on since
that point.
And some people are still more in that mindset of if I just follow the rules of science, everything
will be scientific.
I think that's way more traditional than what he was talking about.
But okay, like normally when I think of someone's contrasting something against Bayesian reasoning,
I think of frequentist, which, um, or even just like Popperian style, falsification,
right?
Yeah.
Um, like the, the science you taught in school, right, rather than the science you taught
in school, plus the actual ways to think about stuff.
He does specifically, uh, mentioned that falsification thing.
He said, uh, in this quote, I pulled as a traditional rationalist, the young Eliezer
was careful to ensure that his mysterious answer made a bold prediction of future experience.
But my hypothesis made no retrospective predictions.
According to traditional science, retrospective predictions don't count.
So why bother making them to a Bayesian on the other hand?
If a hypothesis does not today have a favorable likelihood ratio over, I don't know, it raises
the question of why you today believe anything more complicated than I don't know.
That is a very, I mean, it, it doesn't sound like a good sound bite, but that's a really
good sound bite.
I think it's a good sound bite.
Uh, I remember it.
Sorry.
Oh, I was going to say it's a bit long for one, but yes, go ahead.
Sorry.
This is the problem with Skype.
It's much harder to, to do this next, next episode, we'll all be back in one room again.
Thank God.
Hey, get to see your new digs.
Hail's to the yes.
Uh, I was put in mind of, I can't remember the exact quote, but there was a part of methods
of rationality where Harry's asking Hermione, do you know the scientific method?
And she's like, of course I know the scientific method and you state a hypothesis, you do
a test, you weigh the results, and then you make a cardboard, I was like a cardboard display.
Yeah.
Just cracked me up because I was thinking of, uh, you know, science fairs and the like
very, very formulaic scientific method that children are taught, but, um, Eleazar would
probably be glad to know that, I mean, at least, um, you know, in the field of medicine
and specifically like pharmacodynamics, uh, they do higher Bayesian statisticians to crunch
a bunch of numbers on the feasibility of different study designs.
They do look at the past knowledge that you'd be building upon.
So I don't really know, um, and it would be interesting to find out what sequence of events
led up to people updating in this way.
Honestly, I think it's probably just capitalism, like inventing drugs that work is more profitable
than not inventing drugs that work.
Unfortunately, it hasn't failed to, or it hasn't, we haven't been able to stop companies
from like greedily waiting until patents expire and then taking the same molecule and adding
a methyl group that doesn't do anything and then relabeling it, something new and doing
all new branding stuff.
Yeah.
Lune stuff.
I mean, that's also a technique, right?
Yes.
I mean, it sounds like what you're saying is that at least in pharmacological chemistry,
what did you say it was called?
Yeah, you could just say like, that's a, well, at least in the field of big pharma, it sounds
like one rationalist technique is winning because it actually works.
Yes.
And do you know how long they've been doing this?
Because I know the sequences are like 12 years old now.
I don't know.
I only got into the field like last year.
Okay.
You mean your bootcamp didn't include a history of the field?
Oh, they did.
They had to take for...
Oh, no.
No, yeah, I told you about some of the history of the field.
Well, you forgot all the useless shit.
The bootcamp was, if you remember, like Slate, Start, Codex, Rest in Peace, doing a like
genuflection, but you can't see it.
There was the...
Oh, it was called My IRB Nightmare.
We can link to the probably Waybacked Machine version of that, but they're talking about...
It was Scott, like, kind of deciding, I want to do a research.
I'm a smart person.
I can do this.
And then running into all of the terrible, terrible, terrible, like regulations from the
federal level.
Oh, yeah.
Yeah.
The review board.
A lot of...
And all he really wanted to do was give a survey to some people, right?
Yeah, yeah.
But...
And that was unethical.
It was because my bootcamp crunched this into us as well.
The history of clinical trials is paved with blood, or paved, I don't know, painted.
I tried to do a metaphor and it didn't work, but yeah, there was lots of unethical trials
that were done in the past.
And now, in order to make sure this never, ever, ever, ever, ever happens again, we have
to put, like, 7,000 bureaucracies in charge of everything.
As long as there's no trials ever again, there won't be any unethical trials.
It's like the cruelty to elephants problem.
I did, like, a small-scale, I don't know, I guess, a psychology experiment when I was
an undergrad and had to get board approval for that.
Oh, you had to get an Airbnb?
Yeah, the only risk to patients or risk to subjects was, like, possible emotional distress
or something.
Yeah, I love the...
There's some trials that are just so minimally, I wanted to say minimally invasive, I don't
think that's the right term, but there's such little risk of danger, but you still have
to list everything that could possibly happen.
And then you're also required to list the alternatives to participating in this study,
which Scott pointed out in his post, the only alternative that I and, like, the woman that
was supervising him could really agree on was not participating in this study.
I've seen that one a bunch of times, too.
I mean, like, working with cancer, there's less of the, I mean, like, your alternatives
are, well, I could die referencing the name of the old man shrugging.
Well...
It's easy to get people to sign off on it.
Well, yeah.
That reminds me, this is a super apropos to lead us into today's topic, because he goes
on to say, like, he, I'm just giving a bit through just so he can work through it, but
when I think about how my younger self carefully followed the rules of traditional rationality
in the course of getting the answer wrong, it sheds light on the question of why people
who call themselves rationalists do not rule the world.
You need one hell hell of a lot of rationality before it does anything but lead you into
making new and interesting mistakes.
Yep.
Yeah, just before that, he said that he's lucky he was at least a traditional rationalist,
because that led him to dig himself back out of the hole, because with that he would have
been totally screwed, but as he said, traditional rationality still wasn't enough to get it
right.
It just led me into different mistakes than the ones I had explicitly forbidden.
Yeah, I thought that was the next article, but let's move on to the other one, because
they tie into each other.
Yeah, there's one more thing I wanted to pull out of this one, too, where he talks about
how, and this is actually why I didn't pursue, I mentioned I got my undergraduate degree
in psychology.
This is why I didn't pursue the field, because I wouldn't get to pick the problem and I'd
get to spend five years digging into something that probably wouldn't a thing.
And yeah, and he says that the way traditional rationality is designed, it would have been
acceptable for me to spend 30 years of my life, or 30 years on my silly idea, so long
as I succeeded in falsifying it eventually, and was honest with myself for what my theory
predicted and accepted the disproof when it arrived, etc.
This is enough to let the racket of science click forward, but it's a little harsh on
the people who waste 30 years of their lives.
Yeah, honestly, I wish that traditional rationality or whatever, you know, the paradigm at the
time was had allowed people to do that for 30 years just in good faith, because often
I think what happens is that people refuse to accept their results, so they would screw
around with the statistics or do unethical study design things that makes it look like,
oh, look, we did find evidence for telekinesis.
Looking at you Zimbardo.
It's yeah, no, absolutely, but it's also, I mean, you can kind of understand how it might
be really hard for someone to accept that they've spent their basically entire productive
adult life on something which turns out to be completely wrong.
My life is a waste.
I think that it's not a waste.
I mean, like, I think that there is, yeah, there's the worst case scenario is that you
did decide to pursue something silly and you were really stuck on it.
So ideally, like, science would incorporate the Bayesian priors, Bayesian thinking and
deciding what you're going to pursue.
But then also, you know, there was the whole, I feel like I keep bringing it up too, but
the replication crisis scare quotes, which I'm not scare quoting it because it wasn't
a thing, but just because of the really melodramatic title.
But if there was more prestige to be had in replicating and falsifying or adding evidence
to previously, like, established work, then that would be excellent.
