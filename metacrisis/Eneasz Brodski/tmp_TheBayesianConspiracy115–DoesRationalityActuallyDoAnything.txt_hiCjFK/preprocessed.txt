Welcome to the Bayesian Conspiracy, I'm Eni Ashbrotsky, I'm Steven Zuber, I'm Jay Sticky,
and today we are being led in by Steven, actually no, because we're doing the god my stupid brain.
The Sequences.
The Sequences post.
Thank you, we're doing the Sequences first, yes.
Oh yeah, I will be totally honest, I forgot them, but I'm ready to pick it up as we start
in.
Alrighty.
I didn't forget them.
Huzzah.
Should I lead?
Sure, go for it.
I'm just pulling up my notes, so yeah.
Yeah, so we've got My Wild and Reckless Youth, which is about Eliezer when he was a young
wee lad, and he apparently tried to come up with an explanation for neurons that involved
quantum gravity, and he considers this to be like one of his greatest mistakes or possibly
his greatest mistake, which sure, if you're Eliezer.
I'm sure there have been more mistakes made since then.
Well, there's like, there's a net, there's a post way later on in the sequences about
like my, my best and worst mistake or something, and this wasn't it.
I think that's just an example of him totally failing to reason properly.
Yeah, no, I think it was hyperbolic, but basically, yeah, that was his sin was he described it
as using a mysterious answer to explain a mysterious question, which he had been leading
up to in some of the previous sequences as well.
Yeah.
He said this was because he was a devoted capital T traditional capital R rationalist, and he
had not yet known the way of Bayes, which was also capitalized.
Yes.
He says that even after he invented his answer in quotes, the phenomenon was still a mystery
unto me and possessed the same quality of wondrous compenetrability that it had at the
start.
Yeah.
Um, I'm a bit like, I sort of wish he had explained what he meant by traditional rationality.
I'm pretty sure he just means the scientific method, the sort of norms of thinking philosophically
or scientifically like at that point in time.
Yeah, I got that.
I think that's the impression I got as well.
I get the feeling.
Yeah, I get the feeling it's like what people think of, of the like Victorian era, people
with beakers and, you know, writing in scientific journals and just using very formal language
and doing the best they can at the time, you know, but, but it's, it's moved on since
that point.
And some people are still more in that mindset of if I just follow the rules of science, everything
will be scientific.
I think that's way more traditional than what he was talking about.
But okay, like normally when I think of someone's contrasting something against Bayesian reasoning,
I think of frequentist, which, um, or even just like Popperian style, falsification,
right?
Yeah.
Um, like the, the science you taught in school, right, rather than the science you taught
in school, plus the actual ways to think about stuff.
He does specifically, uh, mentioned that falsification thing.
He said, uh, in this quote, I pulled as a traditional rationalist, the young Eliezer
was careful to ensure that his mysterious answer made a bold prediction of future experience.
But my hypothesis made no retrospective predictions.
According to traditional science, retrospective predictions don't count.
So why bother making them to a Bayesian on the other hand?
If a hypothesis does not today have a favorable likelihood ratio over, I don't know, it raises
the question of why you today believe anything more complicated than I don't know.
That is a very, I mean, it, it doesn't sound like a good sound bite, but that's a really
good sound bite.
I think it's a good sound bite.
Uh, I remember it.
Sorry.
Oh, I was going to say it's a bit long for one, but yes, go ahead.
Sorry.
This is the problem with Skype.
It's much harder to, to do this next, next episode, we'll all be back in one room again.
Thank God.
Hey, get to see your new digs.
Hail's to the yes.
Uh, I was put in mind of, I can't remember the exact quote, but there was a part of methods
of rationality where Harry's asking Hermione, do you know the scientific method?
And she's like, of course I know the scientific method and you state a hypothesis, you do
a test, you weigh the results, and then you make a cardboard, I was like a cardboard display.
Yeah.
Just cracked me up because I was thinking of, uh, you know, science fairs and the like
very, very formulaic scientific method that children are taught, but, um, Eleazar would
probably be glad to know that, I mean, at least, um, you know, in the field of medicine
and specifically like pharmacodynamics, uh, they do higher Bayesian statisticians to crunch
a bunch of numbers on the feasibility of different study designs.
They do look at the past knowledge that you'd be building upon.
So I don't really know, um, and it would be interesting to find out what sequence of events
led up to people updating in this way.
Honestly, I think it's probably just capitalism, like inventing drugs that work is more profitable
than not inventing drugs that work.
Unfortunately, it hasn't failed to, or it hasn't, we haven't been able to stop companies
from like greedily waiting until patents expire and then taking the same molecule and adding
a methyl group that doesn't do anything and then relabeling it, something new and doing
all new branding stuff.
Yeah.
Lune stuff.
I mean, that's also a technique, right?
Yes.
I mean, it sounds like what you're saying is that at least in pharmacological chemistry,
what did you say it was called?
Yeah, you could just say like, that's a, well, at least in the field of big pharma, it sounds
like one rationalist technique is winning because it actually works.
Yes.
And do you know how long they've been doing this?
Because I know the sequences are like 12 years old now.
I don't know.
I only got into the field like last year.
Okay.
You mean your bootcamp didn't include a history of the field?
Oh, they did.
They had to take for...
Oh, no.
No, yeah, I told you about some of the history of the field.
Well, you forgot all the useless shit.
The bootcamp was, if you remember, like Slate, Start, Codex, Rest in Peace, doing a like
genuflection, but you can't see it.
There was the...
Oh, it was called My IRB Nightmare.
We can link to the probably Waybacked Machine version of that, but they're talking about...
It was Scott, like, kind of deciding, I want to do a research.
I'm a smart person.
I can do this.
And then running into all of the terrible, terrible, terrible, like regulations from the
federal level.
Oh, yeah.
Yeah.
The review board.
A lot of...
And all he really wanted to do was give a survey to some people, right?
Yeah, yeah.
But...
And that was unethical.
It was because my bootcamp crunched this into us as well.
The history of clinical trials is paved with blood, or paved, I don't know, painted.
I tried to do a metaphor and it didn't work, but yeah, there was lots of unethical trials
that were done in the past.
And now, in order to make sure this never, ever, ever, ever, ever happens again, we have
to put, like, 7,000 bureaucracies in charge of everything.
As long as there's no trials ever again, there won't be any unethical trials.
It's like the cruelty to elephants problem.
I did, like, a small-scale, I don't know, I guess, a psychology experiment when I was
an undergrad and had to get board approval for that.
Oh, you had to get an Airbnb?
Yeah, the only risk to patients or risk to subjects was, like, possible emotional distress
or something.
Yeah, I love the...
There's some trials that are just so minimally, I wanted to say minimally invasive, I don't
think that's the right term, but there's such little risk of danger, but you still have
to list everything that could possibly happen.
And then you're also required to list the alternatives to participating in this study,
which Scott pointed out in his post, the only alternative that I and, like, the woman that
was supervising him could really agree on was not participating in this study.
I've seen that one a bunch of times, too.
I mean, like, working with cancer, there's less of the, I mean, like, your alternatives
are, well, I could die referencing the name of the old man shrugging.
Well...
It's easy to get people to sign off on it.
Well, yeah.
That reminds me, this is a super apropos to lead us into today's topic, because he goes
on to say, like, he, I'm just giving a bit through just so he can work through it, but
when I think about how my younger self carefully followed the rules of traditional rationality
in the course of getting the answer wrong, it sheds light on the question of why people
who call themselves rationalists do not rule the world.
You need one hell hell of a lot of rationality before it does anything but lead you into
making new and interesting mistakes.
Yep.
Yeah, just before that, he said that he's lucky he was at least a traditional rationalist,
because that led him to dig himself back out of the hole, because with that he would have
been totally screwed, but as he said, traditional rationality still wasn't enough to get it
right.
It just led me into different mistakes than the ones I had explicitly forbidden.
Yeah, I thought that was the next article, but let's move on to the other one, because
they tie into each other.
Yeah, there's one more thing I wanted to pull out of this one, too, where he talks about
how, and this is actually why I didn't pursue, I mentioned I got my undergraduate degree
in psychology.
This is why I didn't pursue the field, because I wouldn't get to pick the problem and I'd
get to spend five years digging into something that probably wouldn't a thing.
And yeah, and he says that the way traditional rationality is designed, it would have been
acceptable for me to spend 30 years of my life, or 30 years on my silly idea, so long
as I succeeded in falsifying it eventually, and was honest with myself for what my theory
predicted and accepted the disproof when it arrived, etc.
This is enough to let the racket of science click forward, but it's a little harsh on
the people who waste 30 years of their lives.
Yeah, honestly, I wish that traditional rationality or whatever, you know, the paradigm at the
time was had allowed people to do that for 30 years just in good faith, because often
I think what happens is that people refuse to accept their results, so they would screw
around with the statistics or do unethical study design things that makes it look like,
oh, look, we did find evidence for telekinesis.
Looking at you Zimbardo.
It's yeah, no, absolutely, but it's also, I mean, you can kind of understand how it might
be really hard for someone to accept that they've spent their basically entire productive
adult life on something which turns out to be completely wrong.
My life is a waste.
I think that it's not a waste.
I mean, like, I think that there is, yeah, there's the worst case scenario is that you
did decide to pursue something silly and you were really stuck on it.
So ideally, like, science would incorporate the Bayesian priors, Bayesian thinking and
deciding what you're going to pursue.
But then also, you know, there was the whole, I feel like I keep bringing it up too, but
the replication crisis scare quotes, which I'm not scare quoting it because it wasn't
a thing, but just because of the really melodramatic title.
But if there was more prestige to be had in replicating and falsifying or adding evidence
to previously, like, established work, then that would be excellent.
I mean, it would give a lot of people.
Yeah, I think things are ratcheting in that direction.
I think I don't know how much money there is in that, but, you know, there are like our
attempts at journals that, like, I will publish the results no matter my findings, and then
they'll accept the grant money, do the experiment, because there's also like publication
bias, we only publish positive results.
And at least, you know, there are, there are moves in the last decade or so to better
that situation.
Yeah, it became like it was the scientific community was well aware of the fact that it
had this issue.
And I'm really happy to have in my lifetime seen them taking a lot of really positive
strides towards dealing with it.
But the whole system had been stacked against actually figuring out the truth previously.
It was like, if you're in academia, then you have to publish.
If you're someone that has to publish, then you want to publish positive results because
you won't get published if it's something negative.
So you got to screw your data or find like a new thing that no one's ever done before,
which good luck with that.
All the low hanging fruit has been picked already.
Yeah, most of the easy to find answers have been found.
$20 bill on the street, et cetera.
I want to say that, like, it's no, it's nothing to be ashamed of to spend 30 years
working on something just to end up proving that this one potential avenue
turned out to be incorrect.
You've still, like you said, ratcheted science forward and improved knowledge.
And that is very much the way I felt about things up until maybe a year ago.
But now, you know, I also realize that there is time pressure to get this stuff done.
If we want to secure aging or whatever it is, our goal is before our death.
We kind of want to avoid wasting 30 years of anyone's life because there's a limited
amount of people that have the ability and the inclination to do this sort of thing.
And they have a limited amount of time to do it in.
So not wasting time as much as possible is a huge benefit.
God, there was some other Slayster Codex article and I can't remember the name of this one.
Maybe one of you will, or I'm sure one of our listeners will.
Where was it now?
And I'm like sort of doubting myself about whether this was Slayster Codex or
somewhere on the strong, but the sounds like a scat ism talking about how many
years go into the training of every scientist, how each field becomes more
and more and more and more specialized as we gain more knowledge.
And then the amount of time it takes you to absorb all the knowledge of all the
previous generations working on it, like, yeah, like you've only got however many
productive years, like if you're, you know, getting your doctorate by the time
you're in your forties or whatever.
Yeah, we we got to fix this aging thing, man, so we can keep doing more better stuff.
For real?
It's it's such a waste every time someone dies.
Yeah. Fuck death.
But exactly.
Anyways, we should continue on to failing to learn from history.
I was just going to say that that was the second post that we sort of already
summarized, but didn't really mention the name of it's basically just a
continuation of the previous post.
And like, honestly, I pulled so many quotes from here and it's such a short
post that I think I pulled like 40% of it.
But I guess I'll all right, I'll jump forward.
He says that my younger self did not realize that solving a mystery should
make it feel less confusing.
I was trying to explain the mysterious phenomenon, not render it into a mundane
phenomenon.
Yeah, I when I read that, I was reminded of my own idiot child self
reading a bunch of Madeline the Engel books, which by the way, Madeline
the Engel is a great writer.
But one of the things she did was trying to reconcile Einstein's theories
with religion and that was a trap for little me.
So I also I remember I was actually telling Phoenix about like, remember
when you had to like cover your textbooks, or like you'd have to pay the
damage, so I would cover all my textbooks with just brown paper bags
because my family was poor.
And then I would write all over them.
And I had all these like books that had equations trying to prove various
stupid things using Einstein's theories.
And I didn't even know any math like I knew, you know, up until like a
middle school age math and probably a little bit like advanced knowledge of
like physics and biology, but I was just making a bunch of shit up, throwing
numbers around.
And I was like, look, I've proved, I don't know, telekinesis.
I keep some reason defaulting to telekinesis because it's a funny word.
But I was like showing my other fellow classmates and they're like, wow,
you're smart.
I was just like, yeah, I'm genius now.
But yeah, they're like, I actually really like that line where if you notice
you're still confused about something like that, the idea of noticing your
confusion, I think is a huge important concept that the rationalist community
or Eleazar in particular has really sort of crystallized.
Yeah, I like the idea of, you know, making something mundane.
If it still feels mysterious, you haven't really answered it.
And like he points out that that is, that's a reason some people don't
think science can solve things because they're taught about, I don't have the
exact quote here, but as children, they're taught about stars and biology and how
the planets work, and it all just seems so mundane because you really have the
answers, right?
Like, oh, okay, it's gravity.
The things traveling circles because they're both towards each other.
All right.
And he like, he says, these were all incredibly mysterious, wondrous things.
And now they feel mundane, but nobody lived through that conversion.
So when they find new, mysterious, wondrous things, they don't think of the
correct way to get it into science is to make it feel that mundane way.
I think, go ahead.
I don't know, like, I think our generation, the one after as well, are just like, I
know I always feel incredibly lucky to have been born when I was because I got
to watch the birth of the internet, cell phones, microprocessors, like getting
more and more complex and just the birth of like, really simple AI to like GPT
three, like, oh my God, we got to do an episode on that at some point.
Yeah.
Oh, I have, hmm, I have a couple of people in mind who would be good hosts if
they'd be willing to record their voices.
Excellent.
Then let us reach out to one.
Yes.
Yeah, I think the, the mundanity of science or like the explanation of the
universe, you know, you flip on a light and you're not amazed that the room is
illuminated.
Like that all just comes from, it's not that the average person knows how that
works, you know, the average person knows that they're closing a circuit and that
makes electricity go or something, right?
And that's about all I know.
But like the, even, even though it's unknown to me, it doesn't seem like a
compelling mystery because I know in my head that it is understood and that
makes it like somehow less interesting.
It's, and I think this is a common thing for, you know, people who have no
interest in science at all.
And they, they just get the sense of blandness about it.
And that's why, like, I really like the poetic writings of science from like
Carl Sagan and Richard Dawkins, as well as, I don't know, I've plugged this book
before, but a short history of nearly everything.
I'm forgetting the author's name right now.
Bryson.
It's, it, yes, Bill Bryson.
Is that it?
Yep.
I also recommend that one.
And it really, it really digs into the history of us learning stuff as a
species.
And it gives you some scope of, like, I think it'd be, you know, a better
scope might be like a long history of chemistry or something.
If there's a book like that, that would do a better job of doing this feeling.
But this does it in a lighter dose of trying to imagine what it was like not
knowing this stuff.
It's like, like, you know, where the hell do mountains come from?
It's so entertaining to read.
It sounds like such a stupid question to ask.
And yet it's a, how that sort of, how that very mundane phenomena was
understood, took a long time.
Tectonic theory is, you know, was, was not popular when your parents were in
school.
Um, it's, I think I mentioned a few episodes ago, I think it was this podcast
that, you know, the extinction of the dinosaurs by meteorite wasn't accepted
until the late eighties.
Did I tell you guys, I probably said this on the podcast before, but, uh, I
found a, I found a book of my dad's that had these illustrations of dinosaurs
that just looked incredibly derpy.
Like they were like inflatable, uh, and it like just had this one chapter about
dinosaurs and said that they like lived however many years ago.
Um, they were giant reptiles.
They, they grew to enormous proportions due to like a brief abundance of resources
on the earth after the flourishing of plants or something like that.
But then they quickly grew too large to be able to sustain themselves and died
out.
And I remember being a child, I was a dinosaur nut.
When I was a kid, I was one of those kids that had like one of every dinosaur toy.
And I could like ramble all the facts about like, do you know about
parasora loaf of snow windows with horn in the back of its head?
It's for, it might actually just be like for a mate display, but it might
be for amplifying the sound of their calls.
I don't care kid, who are you?
Go away, but like I read that and I was just in tears.
Like I was rolling on the floor laughing.
I was like, I tried to explain my dad why that was funny.
He's just like, oh, whatever.
My dad, by the way, who like still doesn't believe in global warming or science
based medicine.
So.
Well, that sucks.
One of the best things about living in this time is that my dad can grumble
about science all he wants.
But like every few months, there's some other cool technology that can be like,
hey dad, hey dad, look, my phone can talk back to me now.
Like whatever.
Science still doesn't exist.
Ghosts in the phone.
Can I read like sort of a longer poll?
Please.
All right, good.
You can read us out read out the rest of the rest of your polls.
If you want it.
So he goes, I thought the list of history was that astrologists and alchemists
and vitalists had an innate character flaw, a tendency towards
mysterianism, which led them to come up with mysterious explanations for
non-mysterious subjects.
But surely if a phenomenon really was very weird, a weird explanation might be in order.
It was only afterward when I began to see the mundane structure inside the mystery
that I realized whose shoes I was standing in.
Only then did I realize how reasonable vitalism had seemed at the time, how
surprising and embarrassing had been the universe's reply of, life is mundane
and does not need a weird explanation.
We read history, but we don't live it.
We don't experience it.
If only I had personally postulated astrological mysteries and then discovered
Newtonian mechanics, postulated alchemical mysteries and then discovered chemistry,
postulated vitalistic mysteries, and then discovered biology.
I would have thought of my mysterious answer and said to myself, no way.
Am I falling for that again?
Goodful.
That is, it's also worth disappointing everybody that, like he has that fine
tendency towards mysterianism with a lower case M that is in some small circles, a capital M.
I know that one of my first introductions to philosophy was a course of lectures by Colin McGinn.
And that's his like explanation for consciousness that it's so complicated that
there's no reason to assume that our weak monkey brains will ever understand it.
Oh dude, there's a lot of people like that around.
I run into them.
Yeah.
Fair bit.
Oh, I know, but he calls it mysterianism with a capital M.
Oh, oh, okay.
Interesting.
Yeah, like he just, he wholeheartedly embraces the mysterious answer.
I mean, it's, it's not a mysterious answer as in like, well, it's magic.
But it's a pointless answer and as in, well, it's impossible for us to get it.
But it's, it's like he doesn't understand that people thought that about all kinds of things.
And now we get them, right?
Did somebody say that about like, what was it?
You're thinking of life and, you know, being able to move your hand and stuff.
What was his name?
Kelvin.
Yeah, I'm thinking of probably Lord Kelvin, who just really liked to jerk off to how
fucking mysterious everything was.
Hey, man, that's everybody.
Mom was to everybody.
Yeah, no, I like, I don't know.
I think the thing that makes rationalist weird is, or I don't know.
I think when I was a kid, like in the single digits, I really liked the X-Files
because of the whole like, I want to believe in the mysteriousness of mysteries everywhere,
you know?
Oh, I was super into paranormal shit too, but like, I like bought all these books
and then I needed to find out if it was really true.
I mean, I did the same thing with religion.
And there was your downfall.
Yeah, but I mean, like, it was just, if something's like, everybody's talking
up how mysterious it is and how no one can know.
And I'm just like, but what do we know?
And then I better weigh all the evidence.
Yeah, that's probably why rationalists are weird.
You were too inclined to question things too early.
Well, I wanted to believe in all this stuff.
And now-
Yeah, your mistake was looking into it, right?
Assuming that what you wanted was to actually believe this, what it seems like
your brain ended up really wanting was to understand what was going on.
Yeah, so I could manipulate it.
Like if psychic powers existed, then like, why the fuck didn't I have them yet?
And how do I initiate that?
You know, if there's ghosts, then I need to find out where to find them and
how I can like harness their powers to have a ghost ray or something.
I think most people just aren't ambitious enough.
I agree.
Well, this actually ties us in neatly to what I wanted to talk about.
And this is to get around to occasional back and forth with a chain of emails I've had with,
or I think I've been answering all of them, but he's been emailing the
Bayesian Conspiracy account.
But that has been emailing-
What is the email address there?
Oh, the Bayesian, wait, what is the email address?
Bayesian Conspiracy podcast at gmail.com.
Excellent.
If you want a quick reply from anyone, that's not the best way to get a hold of us.
The best way to get a hold of us is probably to join our discord and ping us.
Or maybe ping us on Reddit, but all the emails are read and eventually responded to.
Even if it takes us two years to get around to doing your episode.
Yeah.
So anyway, I think we touched on it probably in some episodes here and there,
but I wanted to just dedicate some actual time to answering this because I felt like
it was a worthwhile topic.
Like the emails are too long to easily summarize.
So if I don't think I'm doing a misjustice to say that the thrust of it is,
it doesn't seem like there's empirical evidence to substantiate the claim that
being a proficient rationalist will equate with you winning quote unquote.
Like it seems like, you know, we aren't the apex of industry across the planet.
We aren't running nations.
We aren't all billionaires.
So like, why are we failing if we all think we understand stuff?
Part of the possible explanation that Matt throws out is that,
or rather that Matt delivers, he doesn't throw this out.
He suggests that the world might just be too random to incorporate into a model that works,
that you can whatever make predictions and manipulate.
Like if the world is just too unpredictable, you can't predict that.
So I mean, we could take it piece by piece, but part of my answer to that is that,
that is not a fact that's not known.
So, well, I don't know.
I'll throw out that and let you guys respond before that there is randomness and blank spots on our map.
Some things are unpredictable.
No one would have predicted three years ago that the stock market would have taken a huge dump
in April of 2020, right?
No one in 2017 was accounting for some global pandemic that would hit the economy in such a way
the first quarter of the 2020, right?
Well, I don't know.
Actually, can I stop you?
Yeah, three years ago, absolutely.
But for many years now, people have been saying,
it's only a matter of time before some sort of pandemic hits.
And specifically, the rationalist community was really good about being ahead of the ball
on the COVID thing and saying, hey, this COVID thing looks like it might be a serious issue
to the point where I know several rationalists actually started selling stock before it tanked,
including Eliezer, because it just looked like the market with this actually was a big thing.
The market should be a lot lower than it is, and they think it is going to be a big thing.
So let's get out ahead of this.
And we talked last episode about how The New York Times is doxing Scott Alexander.
The specific reason that the journalist was researching the rationalist community and Scott
Alexander is because the rationalist community was so good about the COVID thing as compared
to the rest of the population.
That was going to be a major focus of the article.
And so I think they actually have had, at least in the recent past, quite a bit of success.
Yeah. So I was putting out an example of the kind of thing I thought that Matt might be talking
about. Another example he uses was you might be able to find an internet group of dumb gamblers
that stumbled backwards into Bitcoin, but they aren't rationalists in the least.
Like they've got lucky.
But then that raises the question of why aren't there a lot of rationalist billionaires who
made a bunch of money on Bitcoin?
But I'm not sure if this came out after 2018 or not, but rationalists did do surprisingly well
in the Bitcoin market. That's surprisingly well.
I know. So I think this might have been in response to that SSC post about how well we did.
Or maybe this was right before that and it was perfectly timely.
Actually, there was an SSC post about why we didn't do better at communicating.
There was a Quern post from right before Bitcoin took off or was it Quern?
Somebody who's real mathy was like, hey guys, look at this Bitcoin thing.
This looks like it could be huge for all these reasons.
You should buy some stocks.
And I think a few people did, but word didn't get out to the general community.
And I think that post was Scott sort of saying like, why not?
If it could have all been billionaires instead of just the people that put a lot of funding
into Merian Seafar.
I know a lot of those organizations did get a big boost of money from
the people who made a lot of money in Bitcoin.
I met a couple people who made a lot of money in Bitcoin.
At one of the solstice events I went to and they were kind of talking about like,
yeah, so now I don't have to work for the rest of my life.
And I'm trying to figure out what to do with all this money.
And I'm just like, I wish I had your problems.
I'm so happy.
I mean, you know, it's possible to be like so happy for somebody and so jealous of them, right?
No, I was like, that's like an awesome.
I believe the post that you linked about basketballism does say that 3% of less wrong users
made over $100,000 on Bitcoin.
And that is a far, far greater percentage than the general population.
Yeah.
And so like, maybe I'll jump to one of his more recent emails just because this one, like,
well, there's one other thing in it.
I don't like, part of it is I'm just picking it apart and like nailing down the exam or like
ripping apart the examples.
That's not quite what I want to do.
I want to hit the broader subject of like,
why aren't rationalists winning?
Or if they are, why is it not obvious?
But like another example was, you know,
if I'm trying to paraphrase an email,
like you go to a job interview and, you know, rationally calculate a resume and interview
and your interview answers perfectly.
Unfortunately, some other guy for the job wasn't the same fraternity as the interviewer
and maybe just subconscious or maybe they just didn't like your haircut or something.
Rationality can't fix that.
So asserts Matt in 2018.
I sort of disagree.
Like if your goal is to get this job or if your goal is to get a specific job or something
like networking is a big part of that.
That's not a lost fact on the rest of us.
Like if you're taught, you know, if your frat bros are taught to network,
it's it's not a skill that is ignored in the community.
So like, I'll put it to you guys broadly.
Why aren't rationalists ruling the world?
Or is that like the wrong question to ask?
I think it's sort of in the middle there.
I do wonder or like I am a bit frustrated that we are not more accelerated than we currently are.
I do think that some of that has to do with the fact that like the communication thing
with Bitcoin, we are still small or still disparate.
I know that there's people gathering on in SF Bay.
But unfortunately, that was kind of due to founder effects and the fact that the tech
industry is there, but it's just like a suboptimal place to live.
No offense to my friends in the Bay.
I think they'll all agree actually.
But I don't know, like you still kind of have to almost be initiated into a secret society
to be part of the rationality community.
Like you have to find the right posts or you have to have the right friend.
Yeah, I want to go ahead.
I want to say part of it is that it is a very small movement still in terms of just
total numbers in America.
But and on top of that, it's a very young movement still.
I think most rationalists are in their 20s or 30s.
And a lot of this is like the question is why haven't they taken over the world?
Rationalism is a lot of it is about being able to meet your goals.
And not a lot of people have take over the world as one of their goals.
I mean, I wouldn't mind ruling the world, but it's not something I'm pursuing.
And I am unfortunately getting to an older age right now, which I am being reminded more and
more of every day.
But the fact is like I make only a little bit more than the national median.
And I am very content with my life.
I have more money than I know what to do with to the point where I'm probably going to retire
next year and just live off and just live off what I got and do what I want with my life.
And in the metrics that looks like Guy in his late 30s or early 40s now has almost no income
sucks to be him.
But on the other hand, I'm living my optimal life.
I'm comfortable and that's what I want.
Yeah, I think that that's a big part of my answer, too, is that I mean, there is at least
one rationalist in what is the the house somewhere on the East Coast.
I forget what her name is.
You know, I'm talking about the politician.
Yeah, yeah, I know who you mean though.
I forget who I don't even know what state she represents or whatever.
But you know, maybe it is her goal to take over the world via the presidency.
And if so, more power to her.
She seems to be on the way of doing that.
I think that the it's less about like, you know, same thing as we do every night pinky,
let's take over the world.
And it's more about that was a pinky in the brain joke for our younger listeners.
So like, you know, like Max Tegmark says that, you know, like the center for applied rationality
was instrumental in the birth of the future of life Institute that four of their five
cofounders are CIFAR alumni.
Um, like, so if, if your goal is trying to research and prevent existential risks,
it seems like at least one organization was born out of that.
And, and like, that seems like in the grand scheme, a larger goal than becoming president.
Right.
Yeah.
I mean, maybe if you're president, you could affect more change in that direction.
But your odds of becoming president, even if you, you know, again, with, with all the other
factors involved, um, might be, it might just be easier to start your own Institute and find
out how to save the world that way rather than become president and try and boss some people around.
Yeah.
I think a president is, first of all, uniquely on such president is not going to make huge
changes on the world because of all the other people vying for that power.
And I think rationalists are uniquely, um, situated to be terrible presidential candidates
because we don't do great with neurotypical general population.
But more to the point, that's not, that's, that might be a sweeping generalization.
And if so, that'd be a failure that we should, you know, win at.
So possibly, but I mean, more to the point, there are actual rationalists who are in the
process of, of to say, put it kind of tongue and cheeky, create God, which is going to be a much
bigger take over the world move than becoming a president.
Right.
Yeah.
I mean, if you're, if your goal is to radically shift the future of humanity, becoming president,
is one way to try and do some stuff, maybe, but then the next president will drip the solar
panels off the White House and shit on everything you ever did.
So like, there's not much, you know, that you can guarantee long lasting change when doing that.
But if you want to change the future light cone of the human species, you can create a
a recursively self-improving artificial intelligence that will change the world.
Right.
So yes, that was the Enios messaging saying that the person's name was Elizabeth Edwards.
And New Hampshire state representative.
Yeah, I met her. She's not still in office, though.
Oh, no.
Or at least last, I don't know, last time I talked to her was like, probably a couple of years ago
though. So I think she just needed some self-care time.
Because now she's moved into the shadow government that has more power anyway.
I hope.
Okay.
Hang on. Let me regenerate my thought there.
Yeah, what I was going to say was I like the direction of the organizations that
the rationalist community has helped like to found.
CIFAR is helping people learn these arts of rationality and helping them apply them instrumentally
to fixing problems that they have with their personal lives or with their careers.
80,000 hours is looking at like the top existential risks or the fields that are going to be like
that are maybe the most underserved or maybe the most likely to be really relevant in the
future and trying to direct young people or new graduates or people that are shifting careers
towards those. Mary is doing whatever Mary does.
Yeah, considering both our small numbers and our overall youthfulness,
I think the rationalists have a very outsized impact.
Yeah, I think, I don't know, there's also something to be said though for when you were
talking about rationalists being less good at, I don't know, doing politics or interfacing with
neurotypicals. That's also a thing. I mean, if the Slate Star Codex polls are representative,
which they might be a bit skewed, there might be like slightly different readership there, but
it seems like a lot of autistic people, a lot of systems thinkers, a lot of people with social
anxiety, a lot of like a certain demographic, let's say. I do remember, I believe it was the
guy that founded Dragon Army, his name is escaping me. Oh, Duncan, I'm not sure. Duncan Sabian at one
point I think said like, and it was sort of unfortunately phrased, but I understand what
he meant that like, we need more traditionally feminine women in rationality, which could be
quoted out of context terribly, but like what he meant was like community organizers, managers,
like people that are good at talking to others. I mean, and not just that, like,
demographic specifically, but what he's talking about is people who are good at these things.
And enjoy them. Yeah, that's true. I was like, all right, when I was doing social media management,
but I fucking hated it and couldn't wait to get out. Definitely. Yeah, I mean, I think the
overall thrust is that like, it's not everyone's goals to do these big sweeping things, that if
your goal is to be like, I want to just be able to commit to a workout regimen, like why do I suck
at being able to commit to like a basic goal? You know, like little things like that.
Understanding your failures of thinking can actually help you do that. There is a, you know,
everyone loves the New York Times. That was a joke because they're the whole Skylander thing.
But there was a New York Times article called the Happiness Code. That was, you know, in the whole
bullshit way that big newspaper slash magazines write their posts where there's a lot of like
gibber jabber for word count or something. Do you have to keep it gratitude journal?
I haven't read the whole thing. I was just going to mention that at the top, there was
like the, I don't know if that's in there or not. Like I said, it's some many thousands of words,
but you know, so maybe I'm not summarizing this correctly. But the point is that like,
yes, see, look, I'm fucking halfway into it. And they mentioned CFAR, which is what the
post was supposed to be about. Anyway, yeah, like there was an article in the New York Times called
the Happiness Code, where basically it's someone who did some interviews at CFAR and with some of
the founders, the CFAR is the Center for Applied Rationality, which basically took the like,
okay, we've got all these cool techniques. And you can either, you know, you can read this giant
book. Oh, would you believe it? Out of curiosity, did Phoenix ever attend a CFAR thing? Oh, Phoenix
Elliott is named in this article. All right, well, that's kind of cool. We'll be sure to tell them.
So like, have fun. I'm kind of distracted, but I'll push past it.
You know what? I wish I had them on to talk about their experience.
Yeah, that sounds great. Anyway, so well, we've rather than digging into this article, we'll
ask Phoenix because they're quoted in it. How fun is that? So the short version of those that,
like, the reason I brought this whole thing up is that these people didn't go to CFAR so they
could learn how to affect radical change on a global scale. They went there to figure out
enough about their own inner workings to solve some problems that they're trying to solve in
their own lives. And if that's your goal, that's your goal. And that's that's the way it is, like,
or that's the way, I mean, like, it doesn't seem like, so why, why doesn't Phoenix run the world
having taken a CFAR course? Well, presumably because they don't want to. They've got other
goals and other things they're working on first, right? I mean, I don't want to put words, words
in their mouth. That's my guess, primary goal, right? And I was trying to figure out what their
goals and values really are, which is actually really important. Most people go through life without
actually, like, analyzing that. I'm also sort of in the process of doing that right now where,
I mean, this is like, I don't know how off topic this is. But I've been talking about my, like,
job working on cancer research. And I have, like, with the help of rationalist techniques,
I have shifted careers, like, several times. And I keep thinking that, like,
I have, like, my eyes set on a goal. And I'm like, this is going to be my, like,
dream career, or this is definitely going to be really values aligned. And then when I get there,
I like, no, not yet. I really actually, this is like, going to be really stupid to say on air.
I have sort of my heart set now, like, on getting involved in aging research. I really want to do
that somehow. I'm not sure how yet. But hey, if anybody is listening, has any contacts in the
industry, or has any ideas about how I could get on that path, that's been on my mind a lot lately.
I don't feel like this is a stupid thing to say on here at all. That's awesome.
No, it's more just like the, I don't know, there's this weird, like, impetus, I think,
in Western cultures, or maybe a lot of cultures where it's like, you have to pretend that you
didn't try really hard, you're just like, Oh, yeah, whatever, you know, I got that degree,
it was no big deal. Yeah, fuck all that. So moving on to the most recent one, which actually
spurred me to finally get on and do this episode. So sorry, it took like two years, Matt. It wasn't
until you mentioned like, Hey, so I had an email in April, 2018. And I was like, Oh, shit, yeah,
we haven't really hit this directly. So like, part of it is, so like you had said that you've
only ever heard of us talk about positively bias tests, see whether rationality actually
works as a tool to run human life. Despite this bias, I still think you don't have any evidence
for it. Still, you should try to disprove that rationality isn't any way useful before you
bother adopting and learning the all these techniques. And I think there's little to no
correlation between success and rationality, past it based on for normal level non irrational
behavior. So like, I think I hope we've addressed at least part of that, that like, if you're not
seeing every head of industry say yes, I may I may capital R rationalist, it might be because
they're not trying to do that, or because the movement as a whole is at most what 15 years old.
So like a lot of them haven't had the 30 years it takes to get to the top of the corporate ladder
or something. But like, the main thing is that, like, you should be trying to disprove rational,
you should, I want to grab this quote, you should, you should be trying to disprove that
rationality isn't any way useful before you bother adopting and learning all these techniques.
I think there's two things to point out there, like one is that, like, the techniques, if you
find them valuable or worth learning whether or not it pans out, like, like, even if there's no,
no evidence whatsoever that this worked, if you found that it worked for you, great. Like, I, I
didn't do any primary research on the efficacy of meditation before getting mildly interested in it
and noticed a benefit from it. So I did it. So I still do once in a while, like, I, I don't know
if you need to have that rigorous of a time investment before you dig into literally anything
you want to try. And I guess the other thing is that like, it's curious, I would, I'm legit asking,
like, how would you disprove that the, the, the claim that rationality has positive impact on
people's lives? And granted, that is a, like, I mean, yeah, I think that's a pretty hard ask
because I, like, trying to prove a negative saying, Oh, no, it wasn't rationality. It was
really like the fact that, you know, you had a good breakfast every day for the last week or
something. How could you possibly roll out a rather variable? So like, if, like, I guess I'm,
I'm just torn because, like, part of it is tripping me up because, well, I guess, a, it's good to
keep in mind that, like, yes, we should look and see what the, the confirming and denying evidence
of this is. And yet, like, if this does work, I would be surprised. Like, so again, my claim that,
that if your goal is to in any way better your own life through introspection of your own mind of,
like, achieving your goals. And how, how would I set about what sort of evidence would I find
that that's not the case? I don't expect to find evidence for things that I think are really true.
Like, what is, what is the best evidence that the scientific method isn't the best way for finding
out about the world? Yeah, that's, that's a real question to you too. Like, I, so if something is
true, what is the best, like, where would you even find evidence that would suggest, Oh, no,
you know, there's actually these, these big gray areas where it doesn't work. Like, you might say,
well, the fact that we don't live on Mars yet or something, but that seems like a really weird
criticism of science. Because we're working on getting to Mars, right? I think definitely there's
only, I mean, the history of science has a pretty good track record in terms of, you know, there's
less infant mortality, or just basically you can just look at trends that impact
people's quality of life all across the board and see them going up and up. And it correlates really
strongly with, well, yeah, it's like being too skeptical to say that like, well, it correlates.
It's definitely to do with better sanitation, medicine, transportation, you know,
but that's a different topic necessarily than rationality. It's, yeah, I think I, you know,
I agree with a lot of the thought that it's way too early to tell that actually, like,
we can do it pretty good for ourselves considering how young the movement itself is.
And I also, though, think that it's not worth just dismissing out of hand how we could be better
or, like, whether or not this is the correct path. Definitely. I do think one of the
riches of rationality is always asking, what do I know? And how do I know it? Or what would it
look like if I was wrong? I would say that also, when I was thinking about this topic,
yeah, like rationality isn't even like well known enough to have had any empirical studies.
I think one thing you could do is pull a large number of rationalists, which,
unfortunately, Slayster Codex could have done. I'm not bitter. And just ask a bunch of questions
about, you know, like you can self report whether or not you think rationality is being a boon in
your life. I know that I've talked to enough people and this is, you know, we can bring our
anecdotes into it and then you can roll your eyes at anecdotes. But like, I know I personally
wouldn't have gotten anywhere near as far as I had if I hadn't been reading the sequences
inspired by rationalist fiction, et cetera. But I always kind of had that mindset. I was bringing
up like my weird childhood tendencies. I don't know, these people probably like, people in this
movement probably would have individually stayed on whatever track that they're on, but they might
not have had as much of a like unified push. I do think as a community, we're lacking in the
things that make communities community like we could definitely do better in that regard.
I right now I'm just trying to like start the first to Denver rationalist group house and
that's been harder than I thought it was going to be. Rationalists are kind of
loners. There's a lot of people that like it's just like herding cats. There's a lot of people
that you get a lot of them together. And I don't know, there's personality differences. There's
yeah, what were you going to say, Steve? Oh, no, I mean, I think that those part of those things
are true as well. I think like, you know, part of the, because it seems like a cop out to say,
well, it's too young and there's no, there's no studies done. So like, if that's the case,
then why would any of us believe this? And part of that is because of our own personal anecdotes
and those of people that we've spoken with. And like, at the end of the day, the plural of anecdotes
is data. And if you hear from 100 people that, Oh, yeah, this thing actually helped. And the
people that you otherwise trust to be sane, it seems worth looking into like the, I know that
CIFAR conducted a small study, I'm guessing like 2015 or 16, where they admitted 50 participants
to its workshop, but only actually admitted 25. And then they did like surveys of the other
25 who didn't come and the 25 who did. And the 25 who came to the workshop, it's a one week workshop
that costs like $3,900 back in the day. I'm not sure what they cost now. Did I say it was a five day
workshop? That's what I meant to say. And the study showed that there's a statistically significant
decrease in what psychologists referred to as neuroticism in the attendees. And they were,
there was also a less significant but still market increase in self efficacy, or the belief
in one's ability to accomplish goals. And so like, because the study was done four years ago,
means that they can't do longitudinal 40 year studies on these participants,
and they only had 25. So like, if you're, if you're starting from the point of there's no
reason to believe this, a, a, a trial of 50 participants won't really change your mind,
right? Like what we need is a 2000 person study where, or a 4,000 person study where 2000 actually
go to see if our workshops get rationality training and we follow their career trajectories
over the next 30 years. And the other 2000 go to fake workshops, and they don't actually learn
anything. And then we see other studies or see other life trajectories turn out. And then maybe
another 2000 people who don't go to any workshops so that, you know, we can get a base rate. But
like, it's, there's also like the, the sampling bias, like the kind of people who are willing to
volunteer or willing to volunteer. Yeah, their time and money to go. Actually, you know what,
I think that randomized trial that CIFAR did, I'll link to the thing where I'm reading a snippet
about it. It's in a vice article. I think that that was actually a randomized trial where they
like messaged people again, how do you find 50 random people? Well, I can say to you guys once
to come to a, come to a workshop. I mean, I thought people asked me that at the train station.
Yeah, they have to be part of the same demographic too, in order for it to have any, I mean,
you could very easily, you know, take 25 people who applied to CIFAR themselves versus 25 people
who are going to community college, but they're going to be different people already. That's
right. And so, and so part of the issue there is that like, you're already selecting for people
who are willing to spend $4,000 on bettering themselves. And so people who are willing to
do that may or may not even like, yeah, and able to. And so those, those people may have
done better in any case. What I'm trying to see here is whether or not they actually didn't charge
these 25 participants who attended, but I'm not sure. But like, an allegory for that is like,
when I went and saw my most recent, well, I guess, yeah, my second therapist ever,
I made an appointment to see this guy and like, I don't know, it was right before the world ended,
so it would have been like January. A few days before my first appointment, he called and said,
hey, are you still planning on attending your, your scheduled appointment? And I was like,
yes, that's why I made it. And I thought about it for the couple of days until I got there and
I asked him, I was like, so I imagine actually you called because you get a lot of people who
don't show up. And he's like, yeah. And I was like, do you think that's because like, the impetus
that they've made to say, I'm going to actually make steps to better myself, like is kind of all
the nudge they needed. And he says, I think that's exactly it. I'm paraphrasing, but that's, that's
the short version. And so like, people who are already like invested enough to try to better
themselves will probably find some way to get there. So like, I guess I'm getting at is that
proving this to statistical satisfaction sounds really, really hard. If anyone has any ideas,
or $100,000 and wants to let me pay somebody to figure this out, that'd be great.
I have like two, two thoughts on this subject.
Sorry, I've been rambling. No, no, it's okay. Like, the one of them is that,
yeah, this sort of data is just really hard to get in part, like, you can never completely trust
self reporting. And it's more complicated by the fact that people who stay around in the community
are people who find value and are helped by this sort of thing. So the people that it doesn't work
for just aren't going to be around to answer the survey and nearly the same numbers. You really
need something like a natural experiment sort of randomization event. Like I not too long ago,
I remember reading about a study about if school discipline actually helps life outcomes. And
like, it's just really freaking hard to tell because where there's more school discipline,
it's also usually the case that more school discipline is needed because it's just
a rougher neighborhood with more chaos. And so there's all these other kind of founding factors.
And like one time in the early 2000s, a school district's got redrawn in the middle of the school
year. And without anybody like moving, all of a sudden just some people that were in one neighborhood
started going to a different school, which happened to be a lot stricter. And people just
across the street from them went to this other school that was much more lax and due to this,
like, fluke of redistricting that happened when it wasn't supposed to, they were able to follow
life outcomes for people over like 10 years to see what difference it made for people who
had been in the same school previously, and we're still living in the same neighborhood and all
that. And that kind of thing is like really rare and requires a pretty large population to occasionally
get those rare hits, which I don't think we're going to get anytime soon. But I also kind of think,
like in one way, this is besides the point, because a lot of this is people doing what
what helps them in life. But in another way, I've been saying this a lot, and it's just been
dominating more and more of my thoughts over the past few years, that again, it comes down to culture.
And I think this this first got kicked off to me when the Secret to our Success book came out,
and we started reviewing that. And I've been building moral on along those lines. But I think
culture is incredibly important to life outcomes. And culture takes a long time to propagate to
the point where it's noticeable, like when Christianity first came out in the in the Roman
Empire. It was not, I mean, there were first of all a whole lot of different flavors of it. But
it was not at all clear that this was a better way to live life and do things than the Romans
currently had going. And yet several hundred years later, it had spread to the point where it
basically took over the empire. And yes, there were other extenuating circumstances, but culture
takes a whole lot of people over many generations to the point where like, you don't know that
border culture being taken out of the border warfare zone and brought into the American
colonial zone is going to result in the terrible culture of crime and honor several hundred years
down the line, whereas Puritan culture actually ends up with a relatively stable prosperous culture.
And I think like, in the end, that's what is is it's going to happen. Several generations from now
100 200 years, people will be like, huh, that rationality culture thing actually worked out
pretty darn well. Look at how good they're doing overall, how low their crime rates are and how
they tend to be tend to be satisfied with their lives. And it, it would work the same way as
Christianity, where just people in neighboring areas being like, those people apparently got
something going for them, let's let's convert over to their way of doing things, because it seems to
be working. And that's, that's kind of squishy. And there's no numbers and that sucks. But I don't
know how else culture can propagate. We don't have the benefit that previous cultures had of being
able to colonialize, colonize Christianity, took over the world, like by literally sending people
and ships and forcibly conquering peoples and forcibly converting them. There's other religions
that just really, I mean, you know, any ash, really aggressively proselytize. We don't do
either of those things. We sort of anti do that thing. We send really strong signals. We have
our ridiculous jargon. I was scared to join the community for a while, because I was like,
everyone's going to think I'm an idiot, and I don't belong here. And they're all going to be
so much smarter than me. And I think a lot of people had that sort of had or have that kind of
mindset. Even people in the community are still afraid of other people in the community who are
like more elite. Maybe we should have some kind of outreach. I mean, I was going to say, you did a
good job proselytizing a minute ago, Inya. I sure welcome to leave that. Have you heard of our lord
and savior, Thomas Bayes? Yeah. But like, yeah, I mean, it's, I want to make sure that I address
Matt's point and to be completely clear, like if I did a, if you feel like I'm dodging any points
you made, I'll, you know, write you back and we'll, we'll try and hit it better. And actually cover
what you're trying to say. But like, it seemed like in your initial email, you drew like a distinction
between like persistence and like, yeah, rationalism or persistence. And I don't think those are oars.
Persistence. I think that, yeah, so like he had said, consider what would work better in a random
world, rationalism or persistence. And so, I think, right. And I think that like, it definitely
takes both. And like, you can be persistent and you can persistently chase your stupid idea.
Like, what was Eliza's in the post you covered something about gravity influences neurons,
right? Exactly. So I mean, you could dumbly persist that, or, you know, you can dumbly and
persistently chase that for 30 years and be wrong. Or you can smartly chase that down for as long as
it takes to realize, Oh, this is a dumb question. Or like a dumb hypothesis, I'm not going to waste
the 30 years. Like, I guess, do we have anything to say about like, how one exercises rationality
in a random, in a world with admitted randomness and luck? Like, you know, I, and Matt pointed
that too, I credited in my joining the community and even hearing about it from being at a stoplight,
and hearing Julia Galef, also one of the founders and former president of the Center for Applied
Rationality, point out, or pick, what was it Harry Potter and Mother of Rationality as her
rationally speaking pick for that week. And like, I could so easily have not been on a stoplight and
just like miss the memo on that. You know, if I didn't pause when I got out of the car and played
through that episode or something, then like, who knows, right? I might not, I might never have
gotten here. So like, there's a level of, there's a huge level of luck involved in things. But I
think that's, that's going to be true, whether you're a rationalist or not. So then I guess the
question is, how do you account for the role of luck? My own intuition, as I'm saying that is
like, you try to constrain luck as much as possible. Like, you try to continually pursue sources
that have been fruitful in the past until they no longer bear fruit. Or, you know, like, if I
happened to hear about this one cool thing, because I was in a conversation with this person, well,
maybe I'll try to have more conversations with that person to hear about more cool things, right?
I wanted to say, I couldn't escape rationality. It's probably just due to, you know,
identify as an optimizer. I think a lot of people in this community can relate to that. But, you
know, as a kid, I was like, really serious about my beliefs or about what things I wanted. And I
find that some people aren't very serious about that. Like, there's so many people that believe in
ghosts because they think it's cool that ghosts exist. And they'll misidentify, like, a shadow,
or, oh, I felt a weird chill. And then this other coincidental thing happened. It's a ghost. And
that's cool and satisfying for them. For me, I was like, if there's a ghost, I'm going to go find
them. I'm going to get all the books, you know, like, I'll buy a multimeter. I don't know. No,
I didn't go that far. But that's because you concluded before that that ghosts weren't real.
Like, I was rationality adjacent before. I think what I was getting at as far as the luck
factor is that I might never have heard about the specific community. I think, you know, this was
what, 10 years ago? So like, Slate Star Codex would have come across my plate at some point,
I imagine, because I was already, like, in the, like, skeptic community, which is, I think,
maybe broader, but to me, like, way easier and less interesting. Still super, super valuable.
Don't get me wrong. It's just like, yeah, like, so if rationality is about helping you achieve
your goals, I would like, if that's the one, like, you know, bumper sticker for it, I would say
skepticism is about, like, maybe protecting your money against hucksters, or, like, yeah, consumer
protection, maybe is the best quick sell for it. Like, how to keep, you know, you how to keep
yourself safe from from people trying to separate you from your money for bad reasons.
And also just like consumer protection for most basic bullshit beliefs.
Yeah, epistemic protection, or something like that.
Right. And exactly. Yeah, that's, that would be my selling point. I think if I was,
if I was going to proselytize it with a bumper sticker, I would, I would use it or like on the,
you know, quote on the front of my book, I would say how to keep people from taking your money or
something, because that would be like a very sellable message. And is the only way you can do
that is by having a base, you know, the basic framework of the understanding of the world that
comes from the past few centuries of science that is ingrained in the skeptic community,
or in the skeptic mindset, you know, if you need a basic understanding of medicine and physics,
just so like you can avoid every bullshit treatment that everyone's trying to throw at you.
Just be a materialist, even if you don't dig real deep into physics or medicine, but you
know kind of, I think they even like somebody who was really busy or doesn't like have the,
you know, drive to study all this stuff, can also learn enough about materialism that they can
Oh yeah, I meant it like at the very rudimentary level. Like I was a friend who was messaging me
the other day because he's trying to figure out how to talk with his anti-facts friend. And
you know, his, I'll paraphrase and just say like, you know, it's okay to like just point to the
established authority of medical science. And it's, it's when you get so it's like, if you,
as, as a consumer are coming across something and it's perfectly consistent with your
understanding of medical science, then you don't, I don't really feel like I'm compelled to do a lot
of research to figure out if that works. Like if someone says, Hey, I like, I never heard of aspirin
and they're like, Hey, here's some aspirin, it'll help your headache because it's an anti-inflammatory.
I'd be like, Oh, great. If they said, Hey, here's some aspirin, it'll make your dick bigger.
Like I would, I would be surprised and I would investigate, right? Especially before I gave
them $200 for a pill. But I'd also say, Oh, great. Well, I would say no, thank you. Which might help.
Right. It's too easy not to make dick jokes. But that was, that was the conversation I was having
with my friend a couple of days ago. I didn't mean to cut anyone off. I just, it put me in
mind of that. That actually just put me off guard enough that I forgot what I was going to say.
That's hilarious though. Yay, I did it. Sorry.
Gosh, what was I going to say? I don't know. I do have. Yeah. Actually, I was just going to say,
like, I feel like we've kind of, we can talk about this as much as we want. We don't have numbers,
which like, is unfortunate. But I do think that we, what do we have?
No, sorry. Go on.
Well, yeah, we have basically the anecdotes of like everybody that I've met in the community,
at least saying that they feel that their quality of life was improved by being here.
And whether or not that's because they, I know, like you could track on people's careers. I think
Stephen or Annie, I just want to, you mentioned longitudinal studies that track people's careers,
how much money they've made. Like, but maybe someone's life goal is to be a housewife,
or like they just get a lot of fulfillment out of that or to volunteer. Or to, I know a guy who's
in the nationalist community who is a nomad, and he just like does odd jobs and makes enough money
to get by, but otherwise just travels and advises people. And he's this awesome, like, monk person.
And I think he's just living his best life. But um,
I mean, and if success is money, I mean, like my, what annual take home income has like tripled
since I got into the community. Granted, that's because I was delivering pizzas part-time when
I first heard about it. But when I decided to like, actually, you know, we, you know,
I talked a little bit about like, some of our random rationality techniques and one of my
main ones that was poorly articulated was like kind of just do the thing or at least
figure out how hard the thing is to do if you want to try something. So when I finally took
that advice to heart and got into and changed fields, I doubled my income. I did the opposite
though. I like was in a high paying career and I left it because I realized it wasn't fulfilling,
like, uh, the whole kind of learning what your values are thing. I'm still not making it.
Don't give it wrong. I'm also, I'm also happier in this field. But like that, that just illustrates
the point that like some people have different goals. And so like the goal isn't necessarily to
make seven figures. The goal might be to like, I want to be happier. I want to forge better
relationships. I want to, uh, commit to an exercise regimen or something, right? I don't mean to cut
you off. I'm enthusiastic. No, I, yeah, I'm totally like with you on that. That's sort of what I was
about to say where I was working for Disney as a video game designer for a while and I was miserable.
I was making great money, uh, working 11 hour days, sitting in front of a computer all day,
not interacting with anyone. And the career changes I made after that were things that
actually pushed me out of my comfort zone. Uh, they were all directed at just self-improvement
and exploration and curiosity generally, like working at the library taught me how to do social
interactions, uh, and how to be more assertive and a lot of things. And then like getting into a
science field was sort of just me proving to myself that I could get into a science field,
because I've had been told when I was a little kid that like science isn't for girls, which
gross, but, um, also I'm not a girl, which, haha. Take that. You got them on both counts. And like,
I also, I also don't want to shit on it on accounting, but of the three of us, you're the
one whose career is making a positive impact on the world. So, um, I, I'll go ahead and, you know,
I have my, if my, if my company's product disappeared tomorrow, the world would be no
worse off for it. I guess, you know, the people who make money off of it would lose that money,
but it's not like the kind of thing that I think will make a lasting impact on the
man. Well, hold on. See, I mean, I completely agree with that, you know, Jason's having the
most impact and all, but like people give your company money because your company gives them
something of value. Like you're making someone's life better, which is why they're giving you
money. And they, they're actually getting money out of it. The customers are like, it's, it's, uh,
referral marketing tracking is what my company does. And so like you're either getting money
or something else, but like, uh, the, I always go to example is like that little share button
at the bottom of Hulu. Um, you know, if Hulu was one of our customers, uh, then it might be where
like, you know, it doesn't matter, but the point is, is like, you don't get, you know, Hulu doesn't
send you five bucks. They said you two free, free weeks, which is the equivalent of seven and a
half dollars, right? Um, so, you know, saving some people a little money down the road, but that
said, like I'm not building AI yet, but you know, I'm, I'm new into the, into my career. So
I put more stuck in growth mindset. Obviously the people that are trying to mitigate AI risk,
that's the bigger concern, I think, but, uh, that is totally an aside, but
No, I'll just make AI first and then, you know, we'll solve the problem of the, of the fallout
afterwards. I mean, uh, I, that's supposed to be, as far as, no, I, sorry, I processed it late
because I was like on a thought train of some kind. Oh, I was just making it clear. So no one
adds me over it. You know, Steven, that's really a bad idea. Um, we, one more thing. I'll finish.
I think particularly if I'm thinking about, uh, effect of altruism and like 80,000 hours,
the fact that I think the rationalist community has identified
what they think are the key existential risks and also put a lot of work into, uh,
well, philosophy and ethics. I mean, those fields haven't really made a lot of progress since,
I don't know, they've been around the, uh, for quite a while and we've entered new territory with
the atheist skeptics movement, uh, kind of letting people for the first time be publicly free of
superstitious beliefs, but then there's sort of a void left there and people are trying to define
like what's good. I think, I mean, EA is pretty incredible. Um, when I thought about like the
simple, the simplicity of the concept of just like, you know, giving 10% of your earnings,
whatever that is, or whatever you can afford to give based on how much you make and what your
expenses are to the people that are literally the most in need or the cause that needs the most,
you know, just like multiplying your efforts there. Um, yeah, we forgot to mention that EA
was birthed out of the rationalism. I was, when I was trying to think of, when I was talking about
the organizations that I like, I was like, you know, the one with the charities and the, yeah,
give well and et cetera. Yeah. Uh, even if that's all the rationality community contributed,
like, and then we just all died out because a meteor struck the SF Bay or something. Like,
still that's assuming like these organizations continue to move forward. I think, uh, 80,000
hours, giving those resources to people who have to drive to either work to give or to work in one
of the key fields, like, you know, researching pandemics, uh, going into politics, uh, AI alignment
problem. Uh, that's all stuff that humanity really needed. And no one else is really like
pushing real hard on these things. I mean, religions are still saying the things religions have
always said, which is do quote unquote good things and don't, and, you know, stop the bad
quote unquote things, which are just super updated. Um, and you'll get to heaven or whatever your
reward is. I think only like Buddhism that I can think of doesn't have some kind of reward.
Uh, gosh, now I'm going on like a big, long tangent. I was going to finish up real quick.
No, you're good. I'm just trying to, trying to think of how I could like wrap up my thoughts
about this, which are, I guess, I think we're already doing pretty good for a very young
sentient species as compared to the many other sentient species out there. God,
I should just stop. I'm going to stop. I think I've made my point already.
As a very, as a very young community.
Yeah, let's, let's go with that one.
What about you? And Yash, did you have any wrap up thoughts on this subject?
No, no, I am, I'm good. I think we've hit just about everything. How about you?
Um, I mean, I, I want to make sure I do the question justice. And like, I feel like saying
we don't have the answer or like don't have the data yet is a cop out, but I,
I hope I've given a good explanation to why I feel like it's, uh,
just the circumstances we're in and that it at the same time doesn't make it unreasonable to
believe that there's something here. Um, and I don't think that the type of people who,
who, uh, need the data to join are going to actually join. Like this is something
you do because it feels like it is making your life better. And yes, we would all like to have
that data and it is an ideal and a goal of the community to have that eventually, but
that's not what personally motivates people. Yeah. I mean, that's a good point. Certainly
not at this stage. Like if it did work out to where, you know, CFR 3.0 can guarantee, you know,
guarantee with like 96% success that you will see a 50% increase in your income a year after
leaving the workshop or something, that'd be great. Um, but I mean, yeah, like right now it's,
it's mainly anecdata that, you know, I can give from my own personal testimony as to why I'm here
and that I've heard from other people. Um, and, you know, part of it's the community aspect of
it. Like the, the friends that I've made in the community are awesome. Um, I don't like,
I mean, I didn't make any friends in the skeptic community. I was never, maybe because there's
no in person things, um, although there wasn't here really in Denver until I started them. So
like maybe if I tried in Fort Collins, it could have happened, but, um, for a skeptic meetup,
but, oh, you know what? There was actually a skeptic meetup and it was super boring. I remember
someone was trying. I went to one. Uh, yeah, I think I kept saying I was going to go and then
never made it out. I went to one. It was like an upstairs part of a, of a coffee shop and some guy
just came in and he's like, so I heard this was like a skeptic scheme. I wanted to ask you guys
about like, you know, it was some ESP or some bullshit. Yeah. And it was like, okay. So we spent
the whole time talking with him about ESP. Um, I mean, it was, it was fun and it's kind of exactly
what you want. If you go to a skeptic meetup, you want to sit there and tell somebody why they're
wrong, but uh, that's never why I was into it though. Like, and I guess that's a, that's why
you're here and not there. Well, yeah, yeah, exactly. I mean, um, what do you get together and
talk about? Like is that I still am sad about the fact that the skeptics movement kind of
seems to, I don't know what happened. I think, uh, God, you know, let's not get into culture war
stuff, but culture wars happened. Uh, yeah. I have a brief culture note, the, uh, culture
worry side note that I can make before we segue into discussing any other like rationality techniques,
because J.C. missed that episode and I wanted to get your, your take. Um, if you feel like you're
up for it, but the, uh, we might be running kind of long this time, actually. Yeah. And we still
got like a couple things that I wanted to hit kind of fast before we finish.
Fair enough. Well, we'll, we'll, we'll just have like, whenever we feel like it, or we need to
fill some dead air, we'll throw in a rationality technique that we like. How's that sound?
I almost want to do like a part two of that episode because I have so many things.
Okay. Yeah. We'll make it a dedicated thing then. Um, anyway, I wanted to mention that,
uh, like five hours ago as of the posting of this, the New Yorker, uh, posted a, uh,
an article called Slate Star Codex and the Silicon Valley Wars against the media.
And, uh, it was about as good as the title makes it sound. Um, again, it does that wordy thing
where it has to like, just, I don't quite get that style of writing.
An AI probably has their own style of writing.
Maybe. Yeah. No, I think it has a human author, but like, uh, speaking of styles of writing,
this is just to kind of get the, illustrate the point. Like, has anyone ever read a LinkedIn
post? Uh, like you have you? Not really.
Okay. Well, so, uh, like, if you, if anyone has a LinkedIn, go there and just scroll to the top
of your feed and look for one that's not an ad and just look at the weird way everyone talks.
It's all algorithmic. I'm telling you, this is, but, but it's human, it's human algorithmic.
It isn't. It isn't even, I have a friend. He was a Grimsman at our wedding,
talks like a perfectly normal human in real life. I see his LinkedIn posts once in a while
and it's like, you know, so happy to be working with the, you know, this best, you know, the best
team that were really driven. The synergy here is awesome, et cetera, et cetera. And I'm like,
why are you talking like this? Oh, cause you're on LinkedIn, but it's so anyway,
I bring that up because that's how I feel about reading like every news website.
But the New Yorker maximizing for eyeballs and it's, it's algorithmic. Uh, it's about keywords.
There may or may not be human analysts that are coming up with this stuff, but I was in
the app store optimization and search engine optimization.
Like, uh, that was part of my job when I was doing the social media marketing for mentioned one.
Definitely, uh, this is, I don't know, like that. I almost want to do a whole episode about the
YouTube algorithm because it's gotten really terrifying. That does sound like another interesting
kind of worms. I just meant that I've read ones that are written by humans who I flesh and blood
know. And they would never write that title. Yeah, they just put on a, no, I mean, it is
their title. Like they wrote the whole thing. If this was the way that they were talking to you,
they would never, yeah, phrase it that way. It's because they're optimizing for keywords.
Exactly. I think unconsciously even, I think it's probably pretty intentional.
I think people just talk different in different mediums. Like I talk with my parents differently
than I talk with you guys. And I think there's probably a similar thing with LinkedIn. I
definitely talk with my boss different than I do with, uh, my friends. One more. Yeah. Like
there's Tumblr speak. There's Reddit speak. Um, like that's just the thing. Anyway, I brought
all that up because I hate reading articles from places like the New Yorker and New York times
and vice and all that stuff. And yet I found articles from all those things, uh, while doing
this. And then I came across the New Yorker one for the, I just wanted to plug really quick and
I'll put it in the show notes. That's why I brought it up. Um, more recording on what the, I already
forgot the date because it's always the ninth. It's, if I haven't mentioned yet, we're in the
middle of a plague. And, you know, so when you're listening to this five years in the future, this
is during the first year of lockdown when everyone was still adjusting. So, um, that's a scary thought.
Um, yeah, by year three, we'll have this down. Everything will feel about, feel like it's normal.
Oh, I really love how the headline says that it's, uh, the Silicon Valley war on the media
instead of the other way around because fuck you, you assholes. By love, I mean hate in this case,
where, where they, yeah, no, they're like, we're the media. So obviously Silicon Valley declared
war on us. Also the derision, like you're expected to read the words Silicon Valley with a rolled
eye and a snare. Are you? I think so. I mean, anytime I see Silicon Valley mentioned, uh,
I think in 10% of cases it's to praise some innovation and 90% of cases it's to
like give the middle finger to those, those people, you know, those tech boroughs, those, but us.
I don't know. I say Silicon Valley a lot and I just mean it to refer to the place.
You do. I don't know. I didn't, I didn't realize that there was this negative connotation.
Maybe, maybe that's just if you read the New Yorker. No, I think it's a lot of media outlets.
It's kind of like using the word rich. Yeah, it's not even somebody could be wealthy,
but like that's almost a slur. It reminds me of the extent to which people hate Elon Musk.
I mean, in his defense, he does a lot to help fuel that. It sucks. He's like,
like the Batman that we all want, but we're not getting and he like so could be. He's almost
our universe is Tony Stark. But I mean, like, he just does some weird shit. I mean, doing weird
shit isn't something that should make people hate you. We do weird shit all the time.
Yeah, but we're not famous. No, it's like the fact that, oh, he thinks he's so much smarter than all
of us. But I even saw somebody was shitting on Elon Musk for attempting to come up with some kind
of COVID intervention. I don't remember exactly what it, oh, it was, he tried to get his company
to donate a bunch of a ventilation machines to hospitals and they sent the wrong machine
to a hospital. But I think actually I looked into it and they did send the correct machine to like
a large number of hospitals and maybe one or some percentage got the wrong machine.
And I think it was fixed after the fact, but it was like, go home, Tony Stark, like,
you know, stop trying to, and the same thing about like Bill Gates and the malaria foundation.
Like, I see hate from, yeah, like anyone involved in the EA too, but like, God forbid that you try
to say that there's a better way to do charity than you giving to like your neighborhood baseball
team or whatever. I don't understand what kind of a monster tries to help humans.
I think it's anyone that puts their goals in a position of saying that they're good at something
or like, like, you know, trying to be the best at this thing, then all the haters have to rise
up and tear them down. And of course, anything that feeds into that is going to be maximally eyeball
grabbing. So they try to really like push for that in the media. It's there's so much negativity
bias in the media. I can confirm that of the media slant about Elon Musk's respirators. I literally
only heard about the hospital that got the wrong ones. But like by the weird shit, I mean, like,
you know, when the those Taiwanese kids were stuck in that cave, and he like tried to build
that sub or something, and then they I think they ended up not using it. And then he called
like the guy who rescued them on Twitter, a pedophile, I think out of nowhere. So like,
that's the weird thing I'm talking about. Yeah, everyone's going to focus on that though,
like rather than the fact that he tried to do something about it. Oh, no, I'm the one singing
it. Don't go wrong. I was singing his praises. It just it's just like, sometimes he makes he
gives the enemy too much ammunition. But we're getting hung up on Elon Musk, but I get I get
the point. Yeah, I mean, I guess I don't think that he should have to be a politician. No, but
I also don't think he should be running around calling probably not but that's called give a
pedophile on Twitter, but you've got a lot of followers, you know, this is exactly why most
people should never ever get on Twitter. Well, he's not doing any worse than the president. Fair.
That's you know, if you're sitting the bar there, then we're all doomed. I think we're all doomed.
Oh, geez. Actually, like, all righty, now she said he had something to something else to talk
about before we all get to him. Yeah. Yeah, sure. Let's go on to the Twitter one then.
I used to have a Twitter account. I made it like many years ago, basically never used it
after about a week because I was like, this is dumb. Twitter is terrible. I'm out. I logged back
into Twitter for the first time in years to post a note of support for aila. Aila is a
rationalist and is probably most well known to people by her own admission as being the person
who dropped acid, a large dose of acid every week for I don't even know how long months at least,
maybe I think it was two years, years. Okay, cool. And yeah, we talked about her when we
did our psychedelics episode. We did. I just didn't remember how, how long this went on.
A long time. Yes, apparently. Anyways, she no longer does the weekly acid, but this is not
what this is about. So I'm going to get to what it is about. Aila, Twittered or tweeted, I guess.
Okay, boomer.
She texted to the tweet.com confession. I lurk in Christian only communities online.
And when someone posts about doubting their faith or being in pain over what their faith
requires them to do, I PM them sympathy and affirm their doubts. And like, first of all,
that is awesome. I logged on to reply and say that that's awesome and to thank her for helping
both improve those people's lives in the long run and strengthening society as a whole, because
that is wonderful. And I, you know, I kind of wish I had the time and the energy to do that
sort of thing too. I wish I had the stomach to go on Christian forums at all. Yeah, I mean,
like just the fact that you're there and able to find these people out of all the other stuff
you're probably looking at. And the main reason I did this, I like wouldn't have done it if it was
just a tweet because, you know, fuck Twitter, I'm not getting on Twitter for anything. But
apparently there was a lot of backlash from a bunch of people, even within the rashless community,
being like, Oh, that's bad. Don't do that. And so I have to go on and say you, you to bomb,
keep doing what you're doing, because I don't know why people would be upset that someone would do
this. I might be wrong, but I was under the impression that a lot of people actually just
misunderstood the way she worded her post. Maybe it has something to do with Twitter and it's like
one sentence post. But I think they thought that she was encouraging them to stick with the faith.
No, I believe it's the exact opposite. No, I know that's I know she was doing the opposite. I think
some people misunderstood what direction she said that she was arguing in.
I think that she said like affirm their doubts. I don't think that that was the
misunderstanding. I think those understanding that people had because I have to believe because
you sent us the tweet. And so I read that and a handful of replies and I saw yours and Elias
Yudkowski, and he wasn't supportive, he had said, I can't support you on this.
So what I'm assuming that he thought, unless I'm totally failing to model him correctly,
which is entirely possible, like, I'm thinking that he thought, Oh, you go around and like
try and de-convert people or something, which is, to some extent, to some communities, maybe
admirable, if that's your thing. I don't I've never like, in the last, I don't know, decade,
I haven't really gotten up on doing that. That said, if someone confessed to me privately that
they are having doubts about their religion and like struggling to deal with the fact like,
what do I do if there's an afterlife or something? I feel like the nicest thing I could do would
be to reach out to them and say, Yeah, man, I went through the same thing. Here's how you,
here's how I got over it. Like, I'd love to help. That's how I read her tweet.
Yeah, exactly. That's how I read it. I just was under the impression again,
from the way some people were replying that it was literally just a misunderstanding of the
wording. That's probably not so important, though, because I think that the people who did seem to
have understood have read the wording correctly and still disagreed. I don't know what their beef
is, like maybe just this isn't a good use of your time or
From what I think they mostly were pattern matching to the fact that religious people will
often prey on people who are at their lowest point in their life. They just had a loved one die or
something terrible happened to them. And they pounce on them and say, you know, Jesus or Muhammad
or whoever can help you through this time and save you forever and you'll get to see your family
member again. Absolutely. Brown can talk to them right now. Yeah, exactly. And yes, yes, the psychic.
I hope not. The kid's dead. Luckily, I only ever learned about her from James Randi's.
My mom has her books. She was. Oh, she also has a deep pack troper books, some other bullshit.
Anyway, yeah, but this is this is absolutely not that because first of all, she's in Christian
forums where Christians are there to talk about religion. And these are people who are saying,
you know, hey, I have some doubts. And so she tells them, yeah, you know, I see that other
people in your forums are not addressing these doubts, you're right to have these doubts like
these are people here explicitly to talk about their faith with others. And she also mentioned
how did she phrase it? I have the tweet. And when someone posts about doubting their faith or
being in pain over what their faith requires them to do, I PM them sympathy and affirm their deaths.
I mean, PMing them sympathy is very much not the praying on someone, I think, unless like,
I don't know, since I haven't seen like, it would be interesting actually to see if she
has any screenshots of those posts, but that would probably also just be to be too privacy
violating indeed. But still, like, I just don't get the impression that this is somebody trying
to be like, haha, I can convert this person to my side. And if somebody is posting that they're
having feeling pain over doing something their religion requires them to do, it's probably
because their religion is acquiring them to cut off ties with their child because their child came
out as gay or something. This is a good thing that she's doing saying people, yes, I feel your pain.
This is because your religion is asking you to do bad things, like she's making people's lives
better. And by reducing religiosity in society, she's making society better overall. Like this is
how we get to the transhumanist future, right? We help people see things that are false. I think
generally, like you're doing a public service, if you expose someone to different viewpoints
than their own. I was raised Catholic and I was just totally like I never I didn't know what an
atheist was. I had I was just of the opinion as a child like sheltered and whatnot that everyone
believes in God and everyone does these things and it never occurred to me like even when I tried to
test God's existence by like jumping off a desk repeatedly and being like praying for God to like
let me fly for a second even if no one's watching just to prove that he existed. And then when it
didn't happen, I was like, God exists, but he's a dick. Not that God doesn't exist. That just wasn't
an idea that I could have yet. And then like, more of my deconversion actually came from
studying other faiths. I bought like a book about it was just a bunch of different religions
that interviewed people. Like, I think it was specifically a book for kids who were interested
in like religion and maybe wanting to change faith to I don't know. But I remember there was
interviews with a bunch of kids where they talked about like here's what my practice looks like
day to day and here's what I believe and why I think it's important. And that was another
realization of Oh, like, all these people feel the same way just as strongly about their faith,
which is incompatible with this other one. And then finally, actually, like my deconversion
came from just reading the Bible cover to cover. But like, yeah, I think that's a popular
deconversion tool. I don't know. That was something that occurred to me earlier, too,
that was just like, why don't you just tell them, like, have you read this cover to cover?
And really thought about it. But uh, I mean, there's a lot more foreskin talk than you would
guess, you know, having ever never opened the book so much bullshit that the Bible talks about
like, I remember slogging through the parts of the Old Testament that was just like, talking
about animal sacrifice, how to build alters, sacrifice, sacrifice, exactly how to build
alters, sacrifice an animal. And it was like the most like, boring detail about like,
it can't have one black hair on it, it must be pure, like, can't have had any brothers and it
needed to have the, you know, then you have to hold the head in this particular way and face this
direction spin around three times and hop on one foot and spit behind your left shoulder. And then
that's just like on and on and on and on. I was like, there's no way God or like any, any, like,
immortal being or whatever wrote this. Like this is so specific to that like
bronze age desert society that cared about things like goats.
And if you had been in a Christian forum at the time and said, Hey, you know, I'm having some
doubt about my faith, like with all this weird goat talk, would you have felt preyed upon and
violated if someone PM'd you like, Hey, yeah, you're, I think you're right to have those doubts.
I think even if like, I'm trying to imagine like from, from the other side,
because I would have felt like I'd finally found a kindred soul, someone who was actually willing
to talk about the thing that everyone else in my community is saying, shut up, you must not talk
about this. And, you know, it'd be nice to have someone there to be like, Oh, thank God, there's
another sane person here. Even if I didn't like, even if I wasn't convinced by their arguments,
it would be nice to have someone who acknowledges that these are issues and just be able to finally
speak my mind without feeling like I was about to get destroyed by my community. Yeah, like that,
even the whole like PMing them sympathy over their pain is the important part of that. Like,
I think that if I'm trying to like put myself back in my head that I'm, of course, like,
forums didn't exist. But when I was thinking about all this, if someone who was Muslim had
PMed me sympathy about my pain and then also said like, and here's like what I believe and why I
believe it, I, and like, you know, with epistemic honesty, I would have been like, thank you for
telling me that, like, maybe that doesn't change my opinion. But like, yeah, I don't know. I just,
I got to say as if you are when you're deep in a Christian community, and that is your identity,
and that is everyone you know, it is incredibly lonely to be like the only person in the universe
that has doubts. Yeah. And it really sucks. And like, one of the best things about getting online
when I was a kid was that I finally discovered there were other people like me out there. And
that was fucking huge. And so this, you know, this is this is just an unvarnished good in every
way. It's good for the person. It's good for society. I mean, this is it was doing God's work.
It's kind of funny coming on the tail end of us sort of, I felt a little bit bad
when we were talking, we weren't really talking shit on like the skeptic community. But I kind of
cringed a little bit after I said it's a stepping stone, because I don't want to I don't want to
say that the skeptic community or the atheist community is not as important as the rationalist
community or that they're like less enlightened or something like that. It's right. It is very
important we were talking about being able to falsify hypotheses. Like, a lot of the important
work that science has done is falsifying a lot of hypotheses. Even if like the answer ends up being,
I don't know, there's still a lot of things the answers, I don't know. And it's important to know
that to not just have a fake. Yeah, don't get me wrong. My, I think, I think skepticism does a
lot of the work for laying or at least for me did a lot of the work in laying the foundation for
me to be primed to be into rationality. And like my longest running monthly donation has been to
Skeptoid Media. We had Brian Dunning the host on twice. I think it's a fantastic endeavor. I have
nothing, like I said, nothing but good things to say about it. I mainly said it was it was a
rationality in easy mode, because I don't feel like there's a lot of positive work
like if you want to just be like in the loop on skepticism, like it's at least
maybe it was just really easy for me because there's you know, I was already super primed for it or
something. I but I could be completely untratable there. Like there's a lot of positive work that
they do as well. I mean, look at any big figures. I mean, Brian Dunning again, you know, he's without
fail, except I think he missed one Tuesday. In the last 13 or 14 years, he's put out a podcast
on random subjects that are lightning to random people are on on various things. And some of them
are for fun. Some of them are like super profound. But it's just about, hey, let's let's point our
Skeptical Eye at this at this little thing here. He also produces educational material for schools,
for teachers, movies. And that's just one guy. Like it's, it's, it's, yeah, don't if I if I was
heard earlier as dissing the skeptic community, I, I retract what I said and further issue that
clarification. Yeah, I love the skeptic community. It was really important for me, like especially
during the time period, when I got really into it, it was right after my two best friends died. And
I was like, working almost full time and also commuting to college and living at my parents'
house and pretty isolated. And it was just like, for a while, I just was really like only sort of
listening to skeptic podcasts, like watching Christopher Hitchens do debates on YouTube and
reading Richard Dawkins books. And it felt like, Oh, at least like, here's something that I can feel
pretty solid about in my life. Being able to like, I'm glad I found this one thing. Or like,
yeah, I don't know. We're going pretty late. Yeah, should we, can I do my one last thing?
No, please. Before we end up before we have updates out.
Go for it, man. All right. So this last thing is going to be sort of a follow up to last week.
I don't want to get into any of that conversation again, for the most part. But in the other podcast
that I'm on, The Mindkiller, we often talk about it's COVID-19 and how the CDC really fucked up
that result, or that whole thing. One of the things that I have come to learn over the past
several months is that, you know, how the lot of people specifically are president, but a lot of
people are saying, Well, you know, COVID is it's basically like just a bad flu season. It's like
two bad flu seasons, right? Because the CDC obviously like a flu season will kill 40 to 60
thousand people. So it's not that big a deal. And I mean, intuitively, that seems right ish,
if it is projected that COVID-19 would kill about twice as many people as a bad flu season.
That's not that big a deal. Like we have bad flu seasons all the time. Yeah, it sucks that people
die. But this is not a society shattering event. And it turns out that the CDC doesn't have exact
numbers on how many people die during the flu season. But it's almost certainly an order
magnitude less than what they're saying. What what the CDC does is like a lot of deaths of old
people and sick people that are possibly helped along by flu like symptoms, get attributed to
death from flu, specifically because if everybody got the flu shot every year,
that would really make a big deal for society. It would help with pretty much every metric.
Our GDP would go up because people would miss less work, people would be healthier in general,
there would be less deaths. And so they've been pushing for a long time, this many people die
every year from the flu, everybody get your flu shot. And like their intentions are good,
they are trying to save lives, they are trying to get people to get the flu vaccine, which everyone
should be doing anyway. But they use misinformation to make that point. And for decades, it didn't
matter that they used misinformation as long as it was pushing people to do the right thing.
But then a pandemic that is similar to COVID-19 appears, and all of a sudden people start using
their misleading numbers to say, look, it's not that much worse than the flu, and we get this
shit show. So that is one of the reasons I am so dedicated to epistemic rigor, because you don't know
when your little misrepresentations and bendings of the truth in order to get a really good result
is going to come around and bite you in the ass. And I just, I think it's important to
not be misleading even for a great cause, like preventing thousands of people per year of dying
of the flu. Or do you have a source for that you can share? You know, not offhand, but I will look
it up. Yeah, I must say, because the order of magnitude disparity between the reported number
to get people to go get flu shots, I mean, you know, the concept of like a noble lie
seems appropriate there. And if it gets the job done, it's hard to argue against it,
unless you're going to point out things like what just happened. And I think that's extremely
important. And I'm really surprised to hear that they might have been pushing false numbers.
I mean, I'm open to being proven wrong, but I'm sort of questioning how much of a lie
this was, if you're saying, for example, someone had like, yeah, a lot of elderly people or young
sick children that have a bunch of other maybe like, I mean, as oppressive disorders or whatever,
and then end up dying of flu, like symptoms are attributed to the flu. I mean, everybody dies
for multiple causes. So I wouldn't say that that's not a death that was caused by the flu. I mean,
maybe not that specific strain of the flu, but most people don't know all the science about the
different mutations and about herd immunity anyway. Yeah, I've heard, I've heard that argument against
like COVID deaths, too, like, oh, you know, that person also had some underlying lung condition.
And like, yeah, but COVID killed them. Right? Yeah, like they had an underlying, they had an
underlying lung condition, and they were living with it until they contracted COVID. And then
they got sick and died. I mean, so like, if I think we have to include all the deaths that come from
people who have this and die while they have it, right? It's not like, I don't know. I mean,
it's, yeah, I have another friend who died of cancer, but she actually died from an infection.
A lot of people who have cancer die of something else, because when you're treating cancer, you
have to wipe out their natural immune system with chemotherapy. And then they have to be in a sterile
environment and often something benign kills them. Same thing with people that are immunosuppressed
for other reasons, or already struggling with other conditions. If that flu risk hadn't been there,
because people had gotten the flu shot, then they might have survived.
Right. And that's the problem. Like the whole, they might have survived if they didn't get the
flu, but they don't really know for sure. And so they take the highest end number of that.
Like everyone who had the flu and died gets counted, even if the, you don't know how many of them
would have actually died. They aren't like direct flu deaths as unlike the COVID people,
which generally they would not have died if it was not for COVID.
I like want to talk about this more, but if coming right on the end of the episode,
maybe I'll record on a, yeah, we can table it for now. I also insisted that we record on a
weeknight so that I can get the stuff ahead of time for editing purposes and all this and that.
So we're all wipes from work stuff too. Are we good to call it here then?
Yeah.
We're going to thank a patron?
All right. Yes, of course. We're never too tired to thank a patron whose turn is it?
I'm looking at the list.
Is the person who, who started the CMO chain with you a patron?
We could.
I was looking at that on our list.
I don't think them anyway.
And not on our doc here.
Well, we can't thank a patron if he's not a patron.
Uh, well, no, no, I was going to, I mean, I, you guys jump, you already beat me to the punch
and take some of the oomph out of it makes it sound like it wasn't planned from the start.
Sure.
I didn't want to thank Matt for writing this and even while, you know, having some,
I guess, I don't know, whatever misgivings or, or concerns about some of the,
the claims or something in the community to still listen.
And he's been listening patiently waiting for us to get around to the subject since April 18th, 2018.
So thank you so much for sticking with us this long.
And I hope you at least got some clarity out of our answer, even though we couldn't cite,
oh no, check out these three awesome studies.
But I hope you did find this valuable and do let me know what you thought.
So thanks again.
And thanks also to Mark.
I'm going to butcher this.
Sorry.
Go be a your support keeps this podcast alive, keeps the lights on.
Let's chase by a headset so that we can record at a distance during the plague.
And it's, it means a lot.
So thank you so much.
And if it's go via or jovia, sorry if I butchered one of those as well.
At least one of those as well.
You're great.
Thank you.
I'm making, I'm making confetti hens and I'm aiming them at my computer screen.
But anyway, and, and you, you aren't just making us happy.
You are also making everyone else who listens to this podcast happy because we can keep
bringing it to them because of your support.
So a lot of people are thankful for your support right now.
That's a really good point.
Oh, I like that.
Yeah.
And I'm Matt, the original question asker.
I also wanted to kind of shout out to you for having those doubts.
I mean, even though it seemed like at points, I was probably like arguing against your
concerns.
It's a concern that I share too.
It's important for me to know whether or not I, you know, I'm doing the right things with
my life or have the right beliefs.
And I think that that's a really, like I said, a virtue of the rationalist community is always
questioning yourself.
Well put.
And I forgot to mention that actually that the question, I thought of that when I first
read his most recent emails, like you realize that questioning things is a rationalist virtue.
And yes, that's a really good point.
Thanks, Jason.
Yeah.
Let's call it a night.
All right.
Thank you, everybody.
It's not good to me.
Thanks, everybody.
We'll see you next fortnight.
Good night, everybody.
And one quick reminder.
Don't forget to nominate Woodlice Dreaming and the DragonCon Fan Awards,
if that is a thing you would like to do.
Thanks.
