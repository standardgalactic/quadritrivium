I'm comfortable and that's what I want.
Yeah, I think that that's a big part of my answer, too, is that I mean, there is at least
one rationalist in what is the the house somewhere on the East Coast.
I forget what her name is.
You know, I'm talking about the politician.
Yeah, yeah, I know who you mean though.
I forget who I don't even know what state she represents or whatever.
But you know, maybe it is her goal to take over the world via the presidency.
And if so, more power to her.
She seems to be on the way of doing that.
I think that the it's less about like, you know, same thing as we do every night pinky,
let's take over the world.
And it's more about that was a pinky in the brain joke for our younger listeners.
So like, you know, like Max Tegmark says that, you know, like the center for applied rationality
was instrumental in the birth of the future of life Institute that four of their five
cofounders are CIFAR alumni.
Um, like, so if, if your goal is trying to research and prevent existential risks,
it seems like at least one organization was born out of that.
And, and like, that seems like in the grand scheme, a larger goal than becoming president.
Right.
Yeah.
I mean, maybe if you're president, you could affect more change in that direction.
But your odds of becoming president, even if you, you know, again, with, with all the other
factors involved, um, might be, it might just be easier to start your own Institute and find
out how to save the world that way rather than become president and try and boss some people around.
Yeah.
I think a president is, first of all, uniquely on such president is not going to make huge
changes on the world because of all the other people vying for that power.
And I think rationalists are uniquely, um, situated to be terrible presidential candidates
because we don't do great with neurotypical general population.
But more to the point, that's not, that's, that might be a sweeping generalization.
And if so, that'd be a failure that we should, you know, win at.
So possibly, but I mean, more to the point, there are actual rationalists who are in the
process of, of to say, put it kind of tongue and cheeky, create God, which is going to be a much
bigger take over the world move than becoming a president.
Right.
Yeah.
I mean, if you're, if your goal is to radically shift the future of humanity, becoming president,
is one way to try and do some stuff, maybe, but then the next president will drip the solar
panels off the White House and shit on everything you ever did.
So like, there's not much, you know, that you can guarantee long lasting change when doing that.
But if you want to change the future light cone of the human species, you can create a
a recursively self-improving artificial intelligence that will change the world.
Right.
So yes, that was the Enios messaging saying that the person's name was Elizabeth Edwards.
And New Hampshire state representative.
Yeah, I met her. She's not still in office, though.
Oh, no.
Or at least last, I don't know, last time I talked to her was like, probably a couple of years ago
though. So I think she just needed some self-care time.
Because now she's moved into the shadow government that has more power anyway.
I hope.
Okay.
Hang on. Let me regenerate my thought there.
Yeah, what I was going to say was I like the direction of the organizations that
the rationalist community has helped like to found.
CIFAR is helping people learn these arts of rationality and helping them apply them instrumentally
to fixing problems that they have with their personal lives or with their careers.
80,000 hours is looking at like the top existential risks or the fields that are going to be like
that are maybe the most underserved or maybe the most likely to be really relevant in the
future and trying to direct young people or new graduates or people that are shifting careers
towards those. Mary is doing whatever Mary does.
Yeah, considering both our small numbers and our overall youthfulness,
I think the rationalists have a very outsized impact.
Yeah, I think, I don't know, there's also something to be said though for when you were
talking about rationalists being less good at, I don't know, doing politics or interfacing with
neurotypicals. That's also a thing. I mean, if the Slate Star Codex polls are representative,
which they might be a bit skewed, there might be like slightly different readership there, but
it seems like a lot of autistic people, a lot of systems thinkers, a lot of people with social
anxiety, a lot of like a certain demographic, let's say. I do remember, I believe it was the
guy that founded Dragon Army, his name is escaping me. Oh, Duncan, I'm not sure. Duncan Sabian at one
point I think said like, and it was sort of unfortunately phrased, but I understand what
he meant that like, we need more traditionally feminine women in rationality, which could be
quoted out of context terribly, but like what he meant was like community organizers, managers,
like people that are good at talking to others. I mean, and not just that, like,
demographic specifically, but what he's talking about is people who are good at these things.
And enjoy them. Yeah, that's true. I was like, all right, when I was doing social media management,
but I fucking hated it and couldn't wait to get out. Definitely. Yeah, I mean, I think the
overall thrust is that like, it's not everyone's goals to do these big sweeping things, that if
your goal is to be like, I want to just be able to commit to a workout regimen, like why do I suck
at being able to commit to like a basic goal? You know, like little things like that.
Understanding your failures of thinking can actually help you do that. There is a, you know,
everyone loves the New York Times. That was a joke because they're the whole Skylander thing.
But there was a New York Times article called the Happiness Code. That was, you know, in the whole
bullshit way that big newspaper slash magazines write their posts where there's a lot of like
gibber jabber for word count or something. Do you have to keep it gratitude journal?
I haven't read the whole thing. I was just going to mention that at the top, there was
like the, I don't know if that's in there or not. Like I said, it's some many thousands of words,
but you know, so maybe I'm not summarizing this correctly. But the point is that like,
yes, see, look, I'm fucking halfway into it. And they mentioned CFAR, which is what the
post was supposed to be about. Anyway, yeah, like there was an article in the New York Times called
the Happiness Code, where basically it's someone who did some interviews at CFAR and with some of
the founders, the CFAR is the Center for Applied Rationality, which basically took the like,
okay, we've got all these cool techniques. And you can either, you know, you can read this giant
book. Oh, would you believe it? Out of curiosity, did Phoenix ever attend a CFAR thing? Oh, Phoenix
Elliott is named in this article. All right, well, that's kind of cool. We'll be sure to tell them.
So like, have fun. I'm kind of distracted, but I'll push past it.
You know what? I wish I had them on to talk about their experience.
Yeah, that sounds great. Anyway, so well, we've rather than digging into this article, we'll
ask Phoenix because they're quoted in it. How fun is that? So the short version of those that,
like, the reason I brought this whole thing up is that these people didn't go to CFAR so they
could learn how to affect radical change on a global scale. They went there to figure out
enough about their own inner workings to solve some problems that they're trying to solve in
their own lives. And if that's your goal, that's your goal. And that's that's the way it is, like,
or that's the way, I mean, like, it doesn't seem like, so why, why doesn't Phoenix run the world
having taken a CFAR course? Well, presumably because they don't want to. They've got other
goals and other things they're working on first, right? I mean, I don't want to put words, words
in their mouth. That's my guess, primary goal, right? And I was trying to figure out what their
goals and values really are, which is actually really important. Most people go through life without
actually, like, analyzing that. I'm also sort of in the process of doing that right now where,
I mean, this is like, I don't know how off topic this is. But I've been talking about my, like,
job working on cancer research. And I have, like, with the help of rationalist techniques,
I have shifted careers, like, several times. And I keep thinking that, like,
I have, like, my eyes set on a goal. And I'm like, this is going to be my, like,
dream career, or this is definitely going to be really values aligned. And then when I get there,
I like, no, not yet. I really actually, this is like, going to be really stupid to say on air.
I have sort of my heart set now, like, on getting involved in aging research. I really want to do
that somehow. I'm not sure how yet. But hey, if anybody is listening, has any contacts in the
industry, or has any ideas about how I could get on that path, that's been on my mind a lot lately.
I don't feel like this is a stupid thing to say on here at all. That's awesome.
No, it's more just like the, I don't know, there's this weird, like, impetus, I think,
in Western cultures, or maybe a lot of cultures where it's like, you have to pretend that you
didn't try really hard, you're just like, Oh, yeah, whatever, you know, I got that degree,
it was no big deal. Yeah, fuck all that. So moving on to the most recent one, which actually
spurred me to finally get on and do this episode. So sorry, it took like two years, Matt. It wasn't
until you mentioned like, Hey, so I had an email in April, 2018. And I was like, Oh, shit, yeah,
we haven't really hit this directly. So like, part of it is, so like you had said that you've
only ever heard of us talk about positively bias tests, see whether rationality actually
works as a tool to run human life. Despite this bias, I still think you don't have any evidence
for it. Still, you should try to disprove that rationality isn't any way useful before you
bother adopting and learning the all these techniques. And I think there's little to no
correlation between success and rationality, past it based on for normal level non irrational
behavior. So like, I think I hope we've addressed at least part of that, that like, if you're not
seeing every head of industry say yes, I may I may capital R rationalist, it might be because
they're not trying to do that, or because the movement as a whole is at most what 15 years old.
So like a lot of them haven't had the 30 years it takes to get to the top of the corporate ladder
or something. But like, the main thing is that, like, you should be trying to disprove rational,
you should, I want to grab this quote, you should, you should be trying to disprove that
rationality isn't any way useful before you bother adopting and learning all these techniques.
I think there's two things to point out there, like one is that, like, the techniques, if you
find them valuable or worth learning whether or not it pans out, like, like, even if there's no,
no evidence whatsoever that this worked, if you found that it worked for you, great. Like, I, I
didn't do any primary research on the efficacy of meditation before getting mildly interested in it
and noticed a benefit from it. So I did it. So I still do once in a while, like, I, I don't know
if you need to have that rigorous of a time investment before you dig into literally anything
you want to try. And I guess the other thing is that like, it's curious, I would, I'm legit asking,
like, how would you disprove that the, the, the claim that rationality has positive impact on
people's lives? And granted, that is a, like, I mean, yeah, I think that's a pretty hard ask
because I, like, trying to prove a negative saying, Oh, no, it wasn't rationality. It was
really like the fact that, you know, you had a good breakfast every day for the last week or
something. How could you possibly roll out a rather variable? So like, if, like, I guess I'm,
I'm just torn because, like, part of it is tripping me up because, well, I guess, a, it's good to
keep in mind that, like, yes, we should look and see what the, the confirming and denying evidence
of this is. And yet, like, if this does work, I would be surprised. Like, so again, my claim that,
that if your goal is to in any way better your own life through introspection of your own mind of,
like, achieving your goals. And how, how would I set about what sort of evidence would I find
that that's not the case? I don't expect to find evidence for things that I think are really true.
Like, what is, what is the best evidence that the scientific method isn't the best way for finding
out about the world? Yeah, that's, that's a real question to you too. Like, I, so if something is
true, what is the best, like, where would you even find evidence that would suggest, Oh, no,
you know, there's actually these, these big gray areas where it doesn't work. Like, you might say,
well, the fact that we don't live on Mars yet or something, but that seems like a really weird
criticism of science. Because we're working on getting to Mars, right? I think definitely there's
only, I mean, the history of science has a pretty good track record in terms of, you know, there's
less infant mortality, or just basically you can just look at trends that impact
people's quality of life all across the board and see them going up and up. And it correlates really
strongly with, well, yeah, it's like being too skeptical to say that like, well, it correlates.
It's definitely to do with better sanitation, medicine, transportation, you know,
but that's a different topic necessarily than rationality. It's, yeah, I think I, you know,
I agree with a lot of the thought that it's way too early to tell that actually, like,
we can do it pretty good for ourselves considering how young the movement itself is.
And I also, though, think that it's not worth just dismissing out of hand how we could be better
or, like, whether or not this is the correct path. Definitely. I do think one of the
riches of rationality is always asking, what do I know? And how do I know it? Or what would it
look like if I was wrong? I would say that also, when I was thinking about this topic,
yeah, like rationality isn't even like well known enough to have had any empirical studies.
I think one thing you could do is pull a large number of rationalists, which,
unfortunately, Slayster Codex could have done. I'm not bitter. And just ask a bunch of questions
about, you know, like you can self report whether or not you think rationality is being a boon in
your life. I know that I've talked to enough people and this is, you know, we can bring our
anecdotes into it and then you can roll your eyes at anecdotes. But like, I know I personally
wouldn't have gotten anywhere near as far as I had if I hadn't been reading the sequences
inspired by rationalist fiction, et cetera. But I always kind of had that mindset. I was bringing
up like my weird childhood tendencies. I don't know, these people probably like, people in this
movement probably would have individually stayed on whatever track that they're on, but they might
not have had as much of a like unified push. I do think as a community, we're lacking in the
things that make communities community like we could definitely do better in that regard.
I right now I'm just trying to like start the first to Denver rationalist group house and
that's been harder than I thought it was going to be. Rationalists are kind of
loners. There's a lot of people that like it's just like herding cats. There's a lot of people
that you get a lot of them together. And I don't know, there's personality differences. There's
yeah, what were you going to say, Steve? Oh, no, I mean, I think that those part of those things
are true as well. I think like, you know, part of the, because it seems like a cop out to say,
well, it's too young and there's no, there's no studies done. So like, if that's the case,
then why would any of us believe this? And part of that is because of our own personal anecdotes
and those of people that we've spoken with. And like, at the end of the day, the plural of anecdotes
is data. And if you hear from 100 people that, Oh, yeah, this thing actually helped. And the
people that you otherwise trust to be sane, it seems worth looking into like the, I know that
CIFAR conducted a small study, I'm guessing like 2015 or 16, where they admitted 50 participants
to its workshop, but only actually admitted 25. And then they did like surveys of the other
