Welcome to the Bayesian Conspiracy. I'm Inyash Brotsky. I'm Stephen Zuber.
And today we have with us a special guest. Hi, I'm Alexander Wills. Hello,
Alexander. We are going to be talking to Alexander today because he piqued my
interest with something that I posted on Facebook and I really wanted to get him
in here and pick his brain on it. But before we get into that, we should, well,
even actually before we do the less wrong post, we should give a quick intro to
Alexander in case people did not hear the last episode that he was on.
Alexander Wills, you are very well known for having written The Metropolitan Man,
a bunch of other Rationalist fanfics, and who is currently writing the very popular
Worth the Candle original fiction. Yep. That's pretty much it. I live in Minnesota.
Stay at home dad. I was a software engineer for seven years or so before I did that.
Kind of burnt out on programming for a while, but that's as much of my life story as you
probably need. I was on programming checks out. Yeah. I was originally planning on waiting until
Worth the Candle was done before I started, but it just seems like that's a very, very bad plan
at this point that I should jump in sometime soon. What are you up to now and how far in
do you think you are? It is, it's at 1.3 million words, which is a lot. Yes.
I think it's in the home stretch. I'm closing more threads than I'm opening. So that's,
I don't know, it's really hard to say. And I kind of try to let myself have some freedom to
go do something weird with the story if I want to. Yeah. Part of my apprehension about reading
works in progress is that more than half the time that they're started, I've found that they just
end before getting to the ending that you're just abandoned. But like at this point, I am pretty
damn confident you're going all the way. So I think I'm going to jump in here real soon. Yeah.
And we have your email and can, you know, hassle you be like, what happens? Yeah. That's awesome.
You're closing it on wild bo length novel there. Oh yeah. Yeah. A worm was I think 1.6 million.
And I'll probably hit that before the end. Awesome. Almost, almost definitely, I think.
I wanted to mention too that Jace is just tardy. I'm not sure if they got something
came up or whatever, but we didn't just not invite him. It's just scheduling conflict,
I'm guessing. So, so if anyone's wondering, where's Jace, the voice of reason on the podcast,
well, he's busy. We will soldier on without him and hope that things don't get too far afield.
Yeah. Alrighty. So as normal, we should start with the less wrong posts. And today,
we had making history available. And what was last one? Stranger than history. I think we actually
forgot to announce this in last week's episode. So hopefully this isn't catching anyone too much
by surprise. But let's get into making history available. Stephen, do you want to start?
Yeah, I'm not sure if this introduces the concept or just where he mentions it again,
but this is the, he mentioned he opens with the fallacy of generalization from fictional evidence,
which is one of my favorites. It's always fun to kind of point these out whenever they happen in
the wild, like just with conversation with friends or something. And once you are aware
that people are actually doing this, I think you might notice that it happens surprisingly often.
I don't hear a lot of things involving Terminator necessarily, but which is what he brings up,
because that's, you know, especially in 2007 was the main focal point for AI in movies.
It's, yeah, I mean, I'm really bad at summarizing. We can just...
It's amazing how much more AI there has been in movies over the past, I guess, 13 years now.
Like Terminator at the time was my go-to example of what AI is. And now it's like not even in the
top five, I don't think. Yeah, it's gotten a lot more mainstream, especially more,
not necessarily realistic, but more nuanced takes on the idea in fiction, especially. But
when he talks about the, and it's not the point of the post necessarily, but the logical fallacy
of generalization from fictional evidence, a lot of what people do is that they hear a story and
they use that as like how they get a handle on a concept. And then that just kind of stays with
them, even if the like fictional example doesn't apply in the real world. Yeah, I love the term
to generalization from fictional evidence. And I think this is the first time it shows up in the
sequences. I'm not actually sure, because it's just become so ingrained in my vocabulary now,
I don't know when I first saw it. Yeah, same. I can't let this pass by just pointing out how
much better. I think a lot of cinema, especially does AI, like or cinema or TV or whatever.
It's not really spoilery. There's AI stuff involved in the towards the end of the TV series,
Silicon Valley, which is a delightful comedy series about computer nerds trying to start a
business. And like it was it was perfect. I think that it did really, really well. I even paused at
a certain part to explain to my wife, like just to throw a jargon at her, because I was like, Oh
my god, they're hinting at this thing. If you read Nick Bostrom's book, this would be the thing
they're talking about. And I think they hit it right on the head. So yeah, things have gotten
at least more, there's more variety to point to. But yeah, this post isn't just about introducing
that concept. It talks about, as the title might suggest, like, because some of us who are aware
of the fallacy of generalizing for fictional evidence, like, we have a propensity to not
consider historical evidence as real evidence. And I think that he has this like, line in there about
how like, what was it? Oh, in our ancestral environment, there were no movies. What you
saw with your own eyes was true. Is it any wonder that fictions we see in life like moving pictures
have too great an impact on us? Conversely, things that really happened, we encounter as ink on paper,
and they happened, but we never saw them happen. We don't remember them happening to us. And so
like, you know, I have memories from, you know, watching movies or playing video games, especially
where it kind of feels more like I'm doing these things. And none of that's none of that's real,
but it's more readily available to my, like, did this happen bucket in my brain than stuff that
I read on a page or heard someone talk about in a class, right? Yeah, that's a good point. I still
have like some visceral memories of playing Soma and the, you know, the experience at the end of
that game. And it just, it never actually happened to me, right? But, but it's still like, kind of
emotionally feels like it did that I went through that journey. Yeah. And that's, you know, to be
clear, this isn't to say that you can't take stuff from fiction, I think it'd be a complete
misnomer to pretend that, A, that's what this is saying or B, that that's true. Yeah. Like,
you can you can even draw real life lessons from from fiction. But the point is that you should
be more inclined than we typically are to take real life lessons from things that really happened
in our real in our Earth's real history. And he did say at one point that one of the reasons he
wrote methods of rationality, well, Harry Potter and the methods of rationality was because he
wanted to find some way to give the experience of being rational and making these discoveries. And
that that wasn't just ink on paper, like the sequences were that were more like a memory
and experience that people remember emotionally. And I think he did a pretty good job. But I'm
biased. Yeah, it's a lot of that that post he goes into, like, trying to get that feeling of
having been there from history, like, when you read about history, trying to actually put yourself
in the shoes of, you know, the people who can can seem very abstract, and who I guess we can
misunderstand fairly easily. Yeah, he said that like it happens right after in the last
episode, we talked about the his mysterious answer, he gave some serious question, and how if he had
lived through vitalism, he would have recognized that was what was happening. And he said he
reiterates that here that he'd only read about them books, but had it actually happened to him,
if he had experienced in the past, and lived through those scientific revolutions,
he would not have made that same mistake. And so this next part, like, I find a really interesting
insight into his mind, because he has this whole thing where he says, he should try to approximate
the thoughts of an Eliezer who had lived through history. He should think as if everything he
read history books has actually happened to him. He says, Why should I remember the Wright brothers
first flight? I was not there. But as a rationalist, could I dare to not remember when the event
actually happened? I had to overcome the false amnesia of being born at a particular time.
And he goes on to describe how he he starts trying to form these memories that never actually
happened to him. And it's really an interesting read. Yeah, go ahead. Sorry. No, I was just going
to kind of concur that it's interesting and fun. And I mean, all these are short, everyone should
just be reading these two. I want to go ahead and pull out to do new two more things near the bottom
that he he says he came to realize as he tried to picture himself actually living through all
these historical events, says the modern world became fragile to my eyes. It was not the first
modern world. He mentions this right after he just describes living in a stable Roman Empire and then
seeing it crumble and overrun by barbarians. So many mistakes made over and over and over again,
because I did not remember making them in every era I never lived. And to think people sometimes
wonder if overcoming bias is important. And then he admonishes everyone to remember things that
they didn't actually live through. He says, remember how you had always thought that slavery
was right and proper. And then you changed your mind. Don't imagine how you could have predicted
the change for that is amnesia. Remember that. In fact, you did not guess. Remember how century
after century, the world changed in ways you did not guess. Maybe then you will be less shocked by
what happens next. So yeah, I like it. And that transitions perfectly smoothly into stranger
than history, which is the second post. And this is the one that like, before we started recording,
I'd mentioned that like, if you knew nothing else about Eleazar Yudkowski, I think you could at
least get that he's a creative guy with a funny streak, just by reading like the first three
bullet points on this post. And so I'm going to go ahead and just read all three of them because I
can't not. So it opens by saying suppose I told you that I knew for a fact that the following
statements were true. One, if you paint yourself a certain exact color between green and blue and
green, it will reverse the force of gravity on you and cause you to fall upward. Two, in the future,
the sky will be filled by billions of floating black spheres. Each sphere will be larger than
all the zeppelins that have ever existed put together. If you offer a sphere money, it will
lower a male prostitute out of the sky on a bungee cord. Three, your grandchildren will think it's
not just foolish but evil to put thieves in jail instead of just spanking them. You'd think that's
crazy, right? And I like that the next three that he puts out to contrast these because
like, you can see the one to one correlation between them says now suppose it were the year 1901
and you had to choose between believing those statements I have just offered and believing
statements like the following. One, there's an absolute speed limit on how fast two objects
can seem to be traveling relative to each other, which is exactly the speed of light miles per hour.
If you hop on board a train going almost this fast and fire a gun out the window,
the fundamental units of length change around. So it looks to you like the bullet's speeding
ahead of you, but other people see something different. Oh, and time changes around too,
which is his, you know, correlation to the painting yourself an exact color will reverse
gravity. This is in the future, there will be a super connected global network of billions of
adding machines, each one which has more power than all the pre 1901 adding machines put together.
One of the primary uses of this network will be to transport moving pictures of lesbian sex
by pretending they're made out of numbers. Which I want to pause real quick to say,
remember in 2007 when the primary form of porn was lesbian sex? Boy, were we naive.
And then finally, your grandchildren will think that it is not just foolish,
but evil to say that someone should not be president of the United States,
because she is black. And I think this does a, yeah, like Steven said, it very well ties into
the previous post about pointing out just how weird the future can be, and how hard it is to
predict what's going to be happening. Because you, you haven't lived through all these
sort of crazy revolutionary statements in the past. So you aren't prepared for a world that's
going to change in such drastic ways. Like, I mean, if you were to compare any two of those statements,
it's hard to say which one is more ridiculous. Oh, yeah. And I mean, then you just generate
like actual future guesses that seem probable. And they sound equally insane, which is like
the hidden inference from this, right? You know, in the future, people will be able to
switch bodies depending on what they want to feel like looking like that day. And
at a whim, they can jump in and out of a matrix like simulation. That's something that I can see
actually happening in the future. But that sounds just as insane as painting myself green and flying,
right? I've always kind of assumed to get this slightly more fraught territory here
that in three worlds collide the fiction he wrote. There's this one chapter where
the protagonist mentioned that rape is legal now in the future. And there's a lot of implications
in my mind in the story that what he's referring to as rape is different from what we think of
as rape. But without getting into all that, I thought of this post the first time I read that.
And I was like, maybe he's doing this thing where he's just trying to
trying to make us understand how weirdly bizarre the future might be that we can read that.
And like we are all shocked and appalled. But perhaps in the future that could actually be
the truth, just the same way that we people 100 years from now, 100 years in the past,
would think that it is shocking to say that it is evil that someone shouldn't be president
if they're black. Yeah, I wonder, like, I can't remember if I mean, because I wasn't there. So
I should remember even though I wasn't because of amnesia. If if he invented the term weird
topia or if that was a TV tropes thing or some third source. But I think that's what
is going for there. Like he wanted to stress that, look, if the future utopia is exactly like
you think it would be, you're probably missing some if or rather, the future utopia probably
won't be just like you think it would be because the odds of you being exactly right on everything
are low. Yeah, your future shouldn't just be an extrapolation of the present based on like
trend lines that you can see coming. So that's never what the future is actually going to be like.
Yeah, I think Charles Strauss said that the future is like 90% totally mundane, normal stuff.
And like 9% 9% just extrapolation of trends and then like 1% total weird bug fuck stuff
that you cannot predict whatsoever. And that's kind of that's kind of his approach to
world building for the future is like if you're writing something that's like 20 years in the
future, there needs to be that that element of just strange things that aren't not necessarily
that aren't predictable, but that seem to people as though they came out of nowhere.
Yeah, yeah, that makes sense. I mean, I kind of feel like it's pointless to try to write a true
future in part because you know, it is so unpredictable, but also because we aren't
writing for future audiences. Like if you go back and read science fiction of the past,
it's pretty obvious that it's like written for the audience of the time and how
how they think what is happening right now is going to affect the future.
And I don't think there's anything wrong with that. Like I think that's kind of legitimately
the place of science fiction to be like, what is the future that we are careening towards if
other things don't change. And let's think about that for a while, despite the fact that we know
well, and very well that something crazy and drastic is going to change. But what can you do
about that? Yeah, it's not like your your audience is people of the future, they cannot buy your book.
Yeah, I think in some sense, the partly science fiction authors ruminate on it a lot just
because that's what they enjoy doing. Yeah, like making their predictions and stuff. It's a fun
thing to do. But it's also partly just to give a bit of to like invest a bit of the zeitgeist
into your work, and then also to add a little bit of realism by taking like current trends
and extrapolating them out and trying to create a world that people will understand. But that kind
of leaves you out on the weird, the like necessarily weird stuff that makes no sense to people from
like 30 years ago. I don't know, I could I could go on and science fiction at length, because man,
I love that topic. But I yeah, we don't we don't have time for all that today. Is there anything
more that either of you guys had about these two posts? I think I'm good. I think talking about
science fiction transitions semi smoothly into talking about the stranger than fiction stuff
that we're talking about here. Although that just sounded better than it actually ties in. So
strange stranger than real, maybe not even not quite whatever.
Before we get to that, I hate to fuck up your transition or segue rather sorry.
We should mention real loss from the start. We should mention the posts for next episode.
Of course. Next episode, we will be reading and talking about explain worship ignore and
science as curiosity stopper. Perfect. Cool. Alright, so I mentioned that this got started
