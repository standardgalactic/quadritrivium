bucks of it. You know, like to you that might not be worth the 50,000, the risk of losing all that
money, right? Because the odds are all small, but those are actually like, boundedly small,
like possible to think of numbers, right? You can say I assign a one in 10,000 chance to
any of these working or something, not a one in whatever, 10 to the negative 23rd probability,
right? Yeah. Well, it also brings up, you know, part of the problem is what if the thing that the AI
is actually to give up for these theoretical people isn't $5, it's the fate of the earth itself.
Right. Because just the earth is really infinitesimal compared to all these however many uncountable
number of people. So, you know, what's the sacrifice of one earth for a chance to save that many
people? Yeah, it says a mine that works strictly by Solominoff induction would not know how to
rationalize reasons that Pascal's mugging mattered less than earth's existence. How should an
akamabiding mind avoid being dominated by tiny probabilities of vast utilities? Yeah. Ah, so
there is a point. Yes. And the, I mean, one of the interesting things about the post is that
he doesn't have an answer. He's just like, so how do we fix this problem? Guys, anyone? Because
this is a problem. And then he says like, do I have an instinct to resist exploitation by
arguments anyone could make? Am I unsatisfied by any visualizations in which the dominant
mainline probability leads to a loss? Do I drop sufficiently small probabilities from
consideration entirely? Like he's trying to figure out what, how, why do I ignore this
probability? And how can I generalize that to an AI so it also makes what I consider the
correct decision without fucking over all the programming and ruining everything we've been
trying to do to make this AI work in the first place? Yeah, that is a fun question. It doesn't
on a good point like that. And I skim to the comments. That's funny, because there were some
negatively voted ones, which you don't see that often. I didn't pull any out. So, but if you're
curious, go read the comments. And he does ask at the very end, like, like you said, Stephen, is it
me that's wrong? Should I not be ignoring this tiny possibility? I mean, I, it's hard to know
how you could possibly operate your life that way. Right. Right. I mean, you couldn't. Yeah. I mean,
that's the thing I was trying to bring up about scope and sensitivity, like, or Charlie problems,
like, I think, like, if you can live your life that way, but like, I think it's the reason
that effective altruism is unpopular with like, people that are in the rationalist community,
because it feels cold and robotic. But it's like, all I have to do to get you just to be
Pascal's mugged is tell you that like, oh, your car doesn't really run on gas. It runs on destroying
souls of angels or something. And they, and they are a billion times as sentient as you are. And
it's actually a really bad thing. Like, that's, that's the level of absurdity that's involved
here. Right. It's not merely like, you know, if you're throwing money at charity to save lives,
you're actually saving lives of actual people that you could in theory meet. You know, I'm not,
I'm not making shit up to extort you to never drive your car or something, right? Like, when I
get my car, I don't do a 60 point inspection on it every time I started. And I don't even
open the hood to see if there's like an animal sleeping in the engine, right? Or like on top
of the engine where it's warm. Like, I should because I care about animals. I've seen pictures of
raccoons and cats and stuff under there that you can live your whole life. Like, I will almost
certainly live my whole life without an animal ever being under there, right? But there's a
non negligible chance. And that's not even approaching the infinitesimal probability of a
Pascal's mugging. Well, generally, the animal would get off the engine block before he heard it,
right? Or like, I mean, it could get caught in the belt or something and ripped apart. Yeah.
It could go could go south, you know, but but it almost so closely never happens that I don't
lose any sleep over it to the point where I don't spend three seconds or maybe 30 seconds checking
my car before I leave every day. Like, you can't live your life trying to protect yourself from
every possible something killing you. And that's every like real possibility, like that, you know,
actually happens. But so the mugging thing is is so ridiculously unlikely that how could you
possibly operate that way, right? You'd be forced to give everyone who asked you $10 or however
much, right? To sell to give them both your kidneys and sell your sell your family and, you
know, harvest their organs. Like, if you really believed any of this, you'd be in you'd just be
this this absurd. And there's a movie I'm sure where it was a yes man or something where like
they have to agree to say yes to everything for a day. Yeah. Yeah. Was that Jim Carrey? Yeah.
It sounds like Jim Carrey, because he also got cursed with not being able to lie for a day and
liar liar. That one was a really good one. Yeah. Yes, Jim Carrey was. Okay. I should see that.
But in any case, no one took advantage of him enough that data totally ruined his life because
it's like, Hey, you know, because they didn't know he had the curse. Yeah. Oh, yeah. I haven't I
haven't seen the movie, you know, if someone found out like, Hey, can I have all your money? And while
I'm at it, all your family's money and all their organs, like, what is he just supposed to say yes?
So that that would be you if you if you operated this way. So I just like, nah, fuck it. Not worried
about it. Somehow I'll just meh, I'll med that problem away. That's my level of coherence,
dismissal of it. I think we need to program a eyes with a math function. I mean, and that
math function could be say, could say anything that's, I don't know, under one in 10 billion
times, one, one in 10 billion odds or something, right? You could you could throw a hard number at
it. You should necessarily throw a hard number, maybe something that is theoretically impossible
to verify. Or like, yeah, if this guy is not giving you any evidence that he's a Dark Lord,
the Matrix, just I don't assume he's lying. I don't think we'll solve the problem of how to
train an AI safely to handle this problem. No, no, no. I think what they're doing at Miri is trying
to deconstruct sort of how we got our own values in the first place. Yeah. And it's impossible
to also think on math just way like further down. Much fuzzier. Yeah. And I think that
not just values, but also like the intuitions we have, again, we're not susceptible to Pascal's
muggings. The obvious thing that we have is that we're like a communal species, a social species.
So we put like higher weight on art, the things that we value, which are like tends to be, you
know, other people, we'd have to make an AI that's capable of like, altruism or empathy or
whatever the thing that humans have that make us care about that. I recently heard a cool argument
that really we can think of our minds extending to all the people around us as well, because we
store a lot of our knowledge in other people's brains. We don't necessarily know something.
We're like, hey, we're kind of one way or another thing or, you know, I don't necessarily need to
know how to do my plumbing because I know someone else who does know how to do plumbing. And yeah,
we would never have gone beyond the hunter gatherer stage if we weren't able to sort of
collectively store memory and pass it down through generations.
That's good shit. Speaking of storing memory and passing it down, should we go on to the next?
Totally. Okay. The next post is illusion of transparency. Why no one understands you.
Anyone want to jump on this or should I start it?
We always know what we mean by our words. So we expect others to know it too.
And that is basically the entirety of the post in a nutshell.
Yeah, it's funny because it's it's that sounds like obvious and almost to the point of like
tautological, right? Like I and I assume that you all know what I meant when I used that last
sentence, right? Yes, because I knew what I meant when I said it. And even if I stumbled
through it or mispronounced a word, I still know what I meant. And I assume that you do too.
This is this turns out to be an actual problem when when communicating anything.
And the they're he describes a fun experiment that's actually worth maybe touching on.
Several fun experiments. Yeah.
Yeah, I found the one with the the tape, the answering machine message, like the most fun
there. Because it had the funniest wrinkles in it to me. Okay. To me, that was the most suspect,
but go ahead and describe it real quick. Or should I or yeah, so June gives Mark a recommendation
for a restaurant. Mark goes there and has one of two experiences is either terrible and the
service was sucky or it was great and the service was great. He calls her and leaves a voicemail
message saying it was marvelous, just marvelous. Exactly. And depending on how they talk, you know,
I'm assuming you have to take this within the bounds of like the normal way of speaking,
right? If I I never use the word marvelous to describe something if I was describing a food
place to you. So you'd think I'm being funny, probably. Right. But if we usually talk to that
way, so I'm assuming that like you said marvelous, I would think you're being sarcastic because it's
not something you would say. Exactly. So let's just assume that pretend Steven's a theater nerd
that's super dramatic that's within the range that's within the range of how they usually
communicate. So if he had a good time, or rather, if you ask people, okay, Mark had a bad time,
he left this voicemail, how will June interpret it? Some high percentage, the majority of people
say, Oh, he'll, did I say good time the first time I said this? No, he had bad time. So if he
had a bad time, and he left this voicemail, and he asked people will June get that he is being
sarcastic? Most people think yes. And if you if you say he had a bad a good time, and he left
this voicemail, what will June get? She'll like, Oh, he'll think he's sincere. But it's the same
voicemail. Yeah, they play the same one. And they don't. And June doesn't know how Mark actually
had the experience, right? And what's funny too, is that if when they say he had a bad experience,
but he's lying to June and wants her to think it was a good experience, they assume that June
thinks that he had a good experience. And there's there's no reason to think there's, I think I
remember this at least twice before on the podcast. But if you YouTube key and peel text message,
Oh, that's a good one. It's brilliant. It's this exact problem. And I mean, it's a, you know,
obviously written to comedic effect. But like, there's there's no reason to think that she would
get the two layers that you're doing through the deception of trying to be funny and, you know,
whatever be sarcastic or be joking, right? So the idea that not only does Mark assume that
Jane will get the right message or not if he's trying to subvert the expectation, but the other
people also assume that that's the funny and insane part. Yeah. So we're much worse at this when
we're little. I find this really hilarious. Like, there's a test that you can do to see if a child
has learned theory of mind yet or not. And it's the one where you show the kid a video of this kid
has a ball, the kid puts the ball in a box, another kid comes and takes the ball out of the box.
And then the first kid comes back and you ask the child, like, what does, where does this
kid think the ball is? And because they saw the other kid take it out of the box, they're like,
Oh, he'll come back and he'll know that like, Jeffrey over there has it. If they don't have
theory of mind. But like, if they do, they'll be like, I realized that the fact that I know that
Jeffrey took the ball doesn't mean that Jimmy knows that Jeffrey took the ball. So he'll think it's
still in the box. And this is a very hard thing for children to do. But we're still not good at
it as adults. Like, that's, I sort of think it's interesting that there's one test that you can
do that shows that. But I've definitely met adults that are much better and worse at this.
And I don't know what really like causes you to be better or worse at it.
I didn't think that the answering machine test was like a great one, because I kind of figured
maybe the people thought that just Mark and June know each other and have their own thing. Like,
we don't use Marvelous. But maybe the people assumed that he would, or they just assumed
that Mark's a good liar when, you know, he was trying to be trying to lie to her about how it
was a good time. That was my thought too was like, of course, people thought if he was trying to fool
her, he would be more successful because they have a relationship. So he knows how to phrase
something so that she would be misinformed. That's valid. I think to me, what was fun was that people
without knowing how Mark actually, if you enjoyed the restaurant or not, they would assume that
Jane understood the exact same message the right way, right? If they know each other, he should be
able to somewhat be able to convey that, which is I think what people are going to do. That's why I
didn't like that example as much. That's totally fair. But they had two other examples, which were
much more interesting. Which one did you like? So I like the the goose hangs high one. I like that
one too. It's an old expression which no one uses anymore. Oh, is that a real expression? I don't
know. Apparently they were told that it's a real expression in the past. Okay. And I don't know
if it actually was or not. The goose hangs high is an excellent expression and we should bring it
back. Yes. Except first we have to find out which thing it means. Well, the subjects were told either
it means the future looks great or the future looks gloomy. And regardless of what they were told,
when they were asked, what do you think someone who just heard the goose hangs high
in a conversation would think it means, they generally always thought they would mean whatever
they were told. So if they were told the future looks gloomy and they were asked, hey, you know,
what do you think someone who just heard this session would say would think it means they're
like, oh, yeah, they probably think it means it's gloomy because like, obviously, everyone knows that.
And yeah, I'm the other way around, which was a much more interesting experience experimented my
opinion. Apparently, it does actually mean it's an old fashioned things are or will be very pleasant,
desirable or merry. Everything is looking up. Okay, so everybody on the podcast, let's bring it back.
The goose hangs high. It's hanging high, man.
Sounds vaguely sexual.
But see, for all you guys know, I inverted the definition I just found.
You son of a bitch.
You don't you don't actually know if I did that or not. I don't know.
So but the thing that that was the thing is that, you know, if that's the point of the
experiment here is that if you told people it meant one thing, they would just believe it and
think it's obvious to everyone else. Well, I wouldn't think it's obvious.
But well, I mean, I think you're not a dirty liar.
They thought they thought listeners would perceive the meaning presented as standard.
If you know something, then you just tend to think that it's obvious to others.
That's the illusion of transparency. Yeah.
But I mean, yeah, it's all it's just being bad at like the theory of mind thing.
The the really interesting examples at the end where it says two days before Germany's attack
on Poland in World War Two, Chamberlain sent a letter intended to make it clear that Britain
would fight if any invasion occurred. The letter phrased in polite diplomatese was
heard by Hitler as conciliatory and the tanks rolled in.
That's why you don't fuck around when you're writing letters about war.
And you include the words, I'm not fucking around.
This aggression will not stand, man.
Yeah, so that was basically it. Don't be don't be too quick to blame those
who misunderstood your perfectly clear sentences because they're never all that clear.
There was another experiment that wasn't in this post where people would tap a song that's in their
head, you know, whether it's a happy birthday or some other popular song.
I've tested this on people tapping happy birthday. Nobody can hear it.
But when it sounds insane from your own perspective, try it.
I know, right? It's great because and people would assume with
astonishingly high accuracy. I can't remember what it was. It was I want to say 70 plus percent,
maybe maybe 80 or 90. But the majority of people assumed that oh, I'm doing a popular song.
The person who's listening to me tap will totally know what song I'm doing.
I'm really confident. And they never did or almost never did.
And it's that's just the illusion of transparency.
Well, it's clear to me what I'm doing. How is it not clear to you?
Yeah, well, that is sort of a way that you can test this, I guess.
Yeah, it's a nice at home test it yourself.
And not just test it yourself, but make it really salient with
Yeah, I was just thinking about like everyone in the cases where I've tried to explain to
people that like I can't read your mind. And they're like, well, how could you not know?
And this would be a good example of bringing up like, OK, what song is this?
That's happy birthday. Because we prime to have your birthday.
I actually knew that one. But yeah, I was at Walmart and I was getting boxes for my upcoming move.
