Hello all, a note on this episode before we begin.
We recorded Robert McIntyre again, as promised, and as is tradition with this podcast, the
audio was once again really fucked up.
Stephen came through okay, but Rob's track is kinda crappy and my audio was almost incomprehensible.
We've done what we can to fix up Robert's audio, and I have re-recorded everything that
I said just now in a microphone and added it to the interview in post.
This means that my tone of voice might not quite match what was originally said, but
all the words are the same.
Also, I have a bit of a cold right now, so I don't sound that great either.
Like I said, this is a very special episode.
We've also put the listener feedback at the beginning of this because the audio for the
listener feedback was actually okay.
We apologize for how chopped this will all feel, and we hope that next time Robert's
on the podcast, there will be some different technical issues, rather than audio being
bad and or lost.
And also, of course, big thanks to our sound engineer, Kyle Moore.
Here we go.
First, we would like to thank our Patreon supporter, Philip Reynolds.
Is that Reynolds R?
No, that's Riemond.
I thought that was an RNN, but it's just an M. We'd like to thank our Patreon supporter,
Philip Riemond, for helping support us and bring this to you.
And you really, you people make it worthwhile because, you know, it's nice to know that
people care.
So thank you.
I second everything Enos just said.
That's fantastic.
We really appreciate it.
Speaking of supporters, that brings up one thing I wanted to dive into.
So this episode is going to be coming out on the 17th, which is, oh wait, no.
So this is going to be coming out on the 14th.
Is that right?
17th.
Yeah.
So this is going to be a few weeks after, but there was some concern last month in December,
which is now, when Patreon cut out some new fees that were going to fall into the donors
instead of the recipients.
And their idea was, hey, look, the recipients will get more of your money, and we'll be
getting a little more too.
And that really upset a lot of people.
And we had some people write in, specifically Roman and Nick wrote in to basically say,
hey look, sorry that, you know, which are our support, but we can't abide by Patreon
doing this.
Patreon said a letter last week saying that they, or I guess last week from now, a few
weeks ago from the release, that they are withdrawing that idea, because turns out everybody
hated it.
So they're not going to be rolling out that fee adjustment, which is great.
I appreciate everybody who, you know, under, or what am I trying to say?
I am completely understanding that people who, you know, don't want to be dropping extra
money and for every Patreon that they're doing.
So
Or even just the people who were against it, just on principle, you know?
Oh, absolutely.
Yeah.
And so there were some people asking if we were going to be setting up a PayPal or something
which I was going to do, but I think that since Patreon is turning out to have changed
their minds on this, that it's no longer worth it to set up a PayPal account for this
right now.
But I don't want to be coming down the bike too, because why not?
So can I just say that I was, I was literally surprised, like I had to update my model of
the world upon learning that Patreon was pulling back and decided not to do that anymore.
Because like, I've gotten so used to people just not giving a fuck, you know?
Oh, you guys hate that?
What tough shit.
Yeah.
So when, when everyone started complaining and writing and tweeting and I was like, well,
no one fucking cares anyway, they're just going to do what they want to do.
They have power and money and we don't matter.
And then like, they changed their policy and I was like, that is nuts.
It just pushes me slightly more in the libertarian direction when like, I see corporations actually
listening to people and changing things because I like, no fucking way the government would
pay attention to that kind of shit.
Right.
Well, I think part of it is that Patreon has competitors, right?
So it's, that is the, the one blessing of the free market, well, I guess not the one,
but it is a blessing of the free market in that, Hey, we've got competition.
We can't be unilaterally, we can't unilaterally be fucking our customers because they'll just
go somewhere else.
So yeah, that's pretty cool.
Speaking of being unilaterally fucked by big businesses, the FCC vote happened and didn't
work out or rather worked out the way everyone thought it was going to and net neutrality
is revoked.
I didn't do a lot more homework to do and I last talked about it, but I was, I was curious
if, you know, if you're learning that the fact that like the EFF and the ACLU and everybody
in organizations, organizations like that were worried about this, this vote, if that updated
your model at all of, from what you read.
Well, a little bit in that I, I was significantly less confident in my position afterwards, but
I went to the EFF AMA that you linked me and I didn't see them actually say all that much
of substance.
The fact that they're against it though does speak a lot to me because I trust that organization.
I think they do good work.
So I'm not as confident as I was before, but I still think that for the most part, this
is a large overreaction and I don't trust regulations necessarily to get things right.
And I would much rather see a large competitive market of ISPs and providers rather than the
government coming in and saying, Hey, here's your cool monopoly, but you have to follow
these rules because the rules, I think we'd all prefer that, but that's not really what's
happening.
Right?
Well, it's, it's, it's not not happening.
There's first of all, wireless keeps getting better.
And there's times where I go to my cell network instead of my internet when I want reliability,
which is the exact opposite of how things were five, 10 years ago.
So yeah, as the cell networks keep getting better, there's, there's, there's in most
of the, most of the populace has more than one option and they are starting to have to
change a little bit because of that.
So I think that there is some competition and that having less of the regulation would
make it easier for small people to get it.
Well, I'm curious about that too.
I wanted you to send me the stuff that you read because we talked about the last time
you said you read some stuff that persuaded you that way and I didn't get a chance to
look at it yet.
So I got to take a look.
Did I send you that?
I don't think so.
Okay.
I'll send it to you after we get off the, off the Skype here and yes, and I'll send it
to you because I was going to link it all in our episode when it goes just before it
goes up on Wednesday.
Anyway.
Cool.
That reminds me.
I am only about a half hour into it, but I will be checking the way tonight tomorrow.
But let's see, as far as other feedback, before we get to listen to feedback, can we do host
feedback?
Yeah.
Okay.
So I have, I have some feedback from our last episode with Jenkins from myself because
there was, there was a number of things that I was, I kind of wanted to say, but we didn't
have the time to say them and quite honestly, I hadn't really got my head around how I wanted
to say it at the moment.
When the episode first started, I didn't realize that it was going to be spirituality via drugs,
which I probably should have given that we know Jenkins and, but, but the one thing as
I was editing the episode that really stuck out to me as we were talking about this was
he said a few times things along the lines of, and here's, here's a direct quote because
I wrote it down, spirituality is not the goal of science.
And then someone brought up, I don't remember if it was you or him, but brought up Richard
Feynman as sort of the stereotype of the cold, unfeeling scientist.
And I wanted to say that I think my spirituality is different, which is why I don't quite
do the drugs connection with spirituality as much as other people seem to, because in
my opinion, I mean, spirituality is not the goal of science, maybe, but science is a big
part of my spirituality.
It is the wonder of exploring the world and seeing how it works and finding out all the
little things that make us go and how, how wondrous and amazing that is and how we as
humans can discover this stuff and not only use it to our advantage, but even like know
it and understand it.
Can a frog understand the sort of thing?
Can the process of a river cutting its way through a continent understand these things?
No, I mean, they're ruled by the physics, but the fact that we can comprehend them and
look on the universe and be part of the universe is really very beautiful to me.
And so my spirituality is very much science-based, which is I think part of the thing I was going
for with saying that when someone asked me how could you look at something and think it makes
itself instead of attributing it to God, and my reaction was like that is anti-spiritual,
that is just childish.
The comprehension of the physical forces that made this is to me a much more spiritual thing.
And I think Richard Feynman is actually a great example of that because if you ever see him talking,
oh my God, he's just got this joy for life and for his, his knowledge and his craft and
he loves explaining it and understanding things.
And there's just this energy that exudes from him when he's talking even about simple things
like the physics of how a train car goes down the rails and without, you know, rolling off them.
He's just so full of wonder and happiness and that is the sort of thing that I feel
when I look at the universe and so someday I want to do a sort of spirituality science
with spirituality episode, not anytime soon because we've just done two in recent succession,
but that is more where I get my, my wonder in the universe and my feeling of oneness with
all things rather than, I don't know, bullshit talking with other humans.
So I think, I think you and I totally agree.
And I'm not sure how well that came out in the episode, but it'll, I'll take trust
to your recollection of it open mind since you did the editing on it.
But yeah, he brought up Feynman as an example of a cold, unfeeling scientist.
Well, that, that seems to not dry with anything that I remember from Feynman either.
I don't necessarily as an example of it, but like as the stereotype that people
would think of a scientist being cold and unfeeling type.
Oh, well, they chose a bad stereotype then.
Yeah.
Yeah, no, I totally agree.
And I, I mean, I, to Jenkins's point, we haven't done the drugs that he's done.
So maybe if we did enough of, you know, DMT or something or a bag of mushrooms that we could,
we would totally change our minds and say, man, all that cool enlightenment and rush
we got from comprehending our place in the cosmos, that's nothing compared to this trip.
But I, I sort of, I sort of doubt that, at least from, you know, my pre doing that experience,
for sure, I think that Carl Sagan, that was like, you know, we are a way for the cosmos to know
itself. And, and, you know, there's the dull meaning of that, like, yeah, we're made a matter,
we can look at matter and comprehend it. But that the real rush and meaning to that is like,
you know, I guess just that sentence again, both different emphasis, right?
You know, we are, I mean, we could go on and on about it, but yes, I totally agree. And I think
that, you know, that Jenkins and I and you were talking about different things, maybe to Jenkins,
they're, they're inseparable. But yeah, to me, I think that, you know, it's cool to have a trip
on LSD and, and, you know, I feel like I had a valuable experience and I don't regret doing it.
And I even feel like I had some like interesting, you know, realizations
that my brain kind of awkwardly spent an afternoon trying to work on when I was tripping. But
certainly, I don't think that, at least for me, in my experience, that there's anything
that profound there, nothing like, you know, just, just reflecting on, you know, your shared history,
your shared ancestry, rather, with your houseplants, right? To think that it literally,
if you've lined up our parents going back in time, we'd have a same parent. That's insane. So
that's pretty cool. Or at least we'd have a shared species of parents.
Okay, so I'm glad I got that out. Thank you for doing that.
Okay, did you have any listener feedback it sounded like?
Real quick, right in here, or I'll cast a comment on episode 30 of specs and omelettes,
which was our discussion of the minuscule utalon, or negative utalon distribution across an unimaginably
large number of beings versus one being being tortured. Their take was that they prefer the
large, large number of beings suffering a small, bearable thing over one unbearable thing,
because you can bear unbearable things. And yeah, I,
oh right, did I say it wrong? Yes, you can, you can bear bearable things, but you can't bear unbearable
things. And so yeah, that's true. But I think the purpose of the thought experiment was more to
not so much like, weigh one ruined life over trillion, trillion, very minutely,
or disturbed lives. It was to get your, get you thinking about, you know, if that is an actual,
if say the dust spec was an actual negative utalon experience a large, among that large
of a group of beings, then how could you possibly weigh that against the maximum
number of negative utalons from one being? I think that they sort of missed the point.
Does that make any sense to you? No, that makes total sense to me. And that
basically is what the argument boils down to. The, the one unbearable thing is unbearable
versus the numbers are higher. And I don't, that's just, there's no, I don't know if there's a way
to resolve that. It's just a philosophical difference that some people do not care about the numbers
and other people do. Yeah, I agree. And it's, I mean, I'm still sort of pretty undecided on it.
Luckily, I'm not standing over a switch to make this decision. So,
well, I mean, it comes more of a question of how do you program your God? And if your
God thinks in numbers, that's an issue, right? Luckily, I'm not programming God either. So,
right. Metastable, who says that I said in one of our earlier episodes that Elon was an early
founder of Mary. But I think you got him confused with Peter Thiel. And yes, that is the case.
I meant Peter Thiel. And I did at that point confuse him with Elon because, you know,
my brain's stupid. And they're both cool Silicon Valley guys that I look up to. So it made a little
switch. I'm sure it's good. It's worth pointing out that there's conversation happening over at
subreddit r slash the Beijing conspiracy. If you like stuff to talk about between episodes here,
looks like on the drugs episode Jenkins expanded his, or I guess added some notes to the
conversation on the episode 49, the spirituality via drugs episode. So if you're interested in
seeing more of that from him, you're welcome to check that out there. Yeah, to provide, you know,
a balancing view to what I had just said earlier, it is good for Jenkins to be able to say his piece
as well. And that is on the subreddit, the spirituality via drugs episode, the first comment.
Oh, nice. I mentioned the baptizing the dead thing that the Mormons do. And
they had somebody, let's see, hanky USA, or honky you so I'm not sure how they say it. But
on that same episode, they, they have a lot to go on here, but they talked about some of the
dead people that are baptized and apparently Carl Siggins on the list. That's kind of funny.
Yeah, we had a number of people right in a number of ex Mormons right in to tell us
about Mormon afterlife. And for the most part, it sounds like basically everyone gets a heaven
or at least a sort of spirit prison where they're not actively tortured or anything. They just sort
of hang out until they get, they get some sort of saving things. The even, even like the worst
people on earth, like criminals and horrible people get a type of afterlife that's not really a
hell, they're just trapped in the company of other horrible people, whereas as opposed to being,
you know, actively tormented by God or anyone else, they just have to hang out with each other,
which kind of suck. And like the normal people just get sort of, you know, a nice place, but it
isn't like heaven, heaven, you know, and then like the really good people get ultimate awesome
bliss heavens and get to become gods of their own universes if they were like really cool.
They, the only real hell they have is this thing called the outer darkness in capital letters.
And that is where rebels against God go. So literally Satan, the other one-third of the
angels that rebelled with Satan and any people who were Mormons, but then left Mormonism
because they are in God's presence, but then they left. So they are, you know, basically
rebels against God and they get to go to the actual hell hell that's awful called the outer
darkness. And do they get to get saved? Because I'm pretty sure Carl Sagan was like an, you know,
an active campaigner against religion. And that sounds like an enemy of God.
I don't think he was a Mormon in life and then the church.
Yeah, no, but you said that it was for rebels of God or ex-Mormons.
Well, rebels against God are literally people who were Satan or those angels or people who were
Mormons and left. Okay, so that's the only three. It's not like, say, if you and I made our life
school to de-convert as many Mormons as possible, only the Mormons who got de-converted would go
to hell, not us. Right, exactly. Because we're actually in the presence of God and then rebelled,
whereas we were never blessed enough to be in the presence of God, so we couldn't rebel against him.
Cool. Which, I mean, I guess it sort of makes sense because it's not too
torturous for everyone else, but it has very strong penalties for being an apostate, which
most religions do. They generally hate people who were that religion and then left far more than
anyone else. So, okay, there we go. Perfect. I'm not seeing a whole lot of other feedback,
but I thought we were behind on some stuff. Anything jumping out at you?
No, that is about it. And since we took some time with host feedback, I think this is a
decent time to style. Works for me.
Hey, folks. This is Kyle, audio editor for the Bayesian conspiracy podcast. Due to the aforementioned
chopped-up nature of today's episode, we neglected to record an intro for our guest.
So we now present to you our interview with Robert McIntyre. Please enjoy.
All right. Well, in that case, welcome to the Bayesian Conspiracy. I'm Stephen Zuber.
I'm Minyash Brotsky. And I'm Robert McIntyre. Robert, thanks for coming back on.
It's a real pleasure. I don't know if Minyash mentioned last time something got garbled in
the audio when we were, I guess, between recording and saving the file. And it came through kind of
like, if you're shouting through a woodchipper the whole time. So at the very least, I think it would
be useful to cover some of the same stuff as last time. But before that, I wanted to hear about the
talk that you gave at the Future of Humanity Institute. That's the one. That was their vision
conference, I believe, a couple of weekends ago. And they invited a bunch of people over. The talk
that I was part of was, you know, kind of what the future of mind uploading was going to look like.
And we're going to discuss some interesting stuff. What was your take on what the future is going to
look like? They were trying to compare it to Hanson's book, Age of E.M. And I think one of the
main things there is he thinks that AI is not going to really happen before we get the uploading.
I don't see how you can't get some type of AI, especially if you, you know, have gotten to the
point where you're beginning to really understand how the brain works. It seems to me like if you
can upload a mouse, that gets you certainly some amazing tricks to do with our current neural networks,
which may lead to something that's got some fairly robust intelligence. So that's the main
conceit that he makes in that book. Probably because he's wanted to explore, you know, what would
happen in the absence of AI, like many science fiction books do. And AI makes it very hard to
predict because then you're trying to look past kind of the singularity, right?
And, but I do think that's somewhat unrealistic. So that was, that was the main thing I had.
I agree. I, we talked with Robin about his book Age of E.M. actually. What was, I think just in
general, what we talked about Age of E.M. And that seems to be one of the, I guess,
priors to the book, that if AI happens, it's too slow a takeoff for it to
subvert the Age of E.M. from happening for a couple of years. I think he's been a proponent
of slow takeoff for as far back as I've been following his stuff. Oh, speaking of AI takeoff,
have you guys seen the new, what was it? Not AlphaGo, but AlphaZero? AlphaGo Zero. Yeah,
I read about that on a post by Yudkowsky responding to some letter of criticism.
Okay. Yeah. It took it like, what, four hours to go from doesn't know the rules of the game to
superhuman playing? Well, that's superhuman better than Stockfish, which was our best,
was our best AI for playing chess. So not only did it go past all of the many hundreds of years
of human experience, you know, with masters teaching their students on how to play chess,
but then it also ended up being the best AI we were able to build to play chess as well.
I thought it, I thought it played go. That was for AlphaGo, but for AlphaZero, they used chess
for it. And there was like no outside influences at all on it. It was just given the rules of the
game. And basically that's it. And with just that, it played against itself until it figured out chess
and was able to break the game so that it would never lose. It's pretty good. It only took four
hours. It's insane. And first of all, not only how many hundreds of years of humans working to
perfect the game, but after that, decades of programmers making computer playing chess programs,
which were basically programmed with special knowledge, things like opening moves and gambits,
and what to do when this situation arises, looking forward, X number of moves in advance.
And then all of those decades of work and programming was just blown away by a learning
algorithm in four hours. It is, I think, as Eliezer said, an indication that his idea of
fast AI takeoff is more likely because once they figured out how to do the learning in a
good learning algorithm, it just demolished all previous work. So I'm not an AI programmer,
but isn't it a different sort of problem? Because you can program in the rules of chess,
now go forth and figure out how to kick ass at it. But can you program in the rules of the universe
and say go and figure out how to kick ass at that as easily? Not obviously as easily, but is that
even the same kind of problem? I don't know, but it's pretty impressive that you can blow past,
like we care about chess a lot and we spent hundreds of years trying to get good at it.
And this thing just blew past it from nothing to better than everything in four hours. It's
very impressive, I think. Oh, I totally agree. The main point being that it managed to self-improve
over just four hours, starting from scratch, rather than incrementing further from previous
efforts. The whole slow AI takeoff argument depends on an AI slowly incrementally learning at a rate
where we can see what's going on and maybe react. Whereas this kind of shows that once an AI learns
how to learn in the proper way, it can take off at an exponential rate far faster than we're able
to understand what's happening. And in the process, just cruises right past everything that we had
thought that we'd figured out over centuries and or decades. So I get like these mixed feelings
whenever I think about super AI, like impending. And, you know, I think the same feelings everyone
else gets, but talk to me to be stoked, but it's also super exciting, right? Right, it's terrifying.
Yeah, although chess is still a pretty circumscribed type of game, right? So,
just because it can blow it away that quickly, may or may not have a lot of bearing on what it can
do in general. But still, you know, I think there are a lot of other games that humans play that
are very important economically that, you know, you may very well see an AI go from totally not
competitive in those fields to better than not only anything we could do, but anything we could
work with a computer to do very rapidly. And that itself could be a big deal.
Yeah, well, Charles Strauss has explored this concept before in his books as well. But
a lot of our financial instruments, financial markets can be gamified and see viewed as a game.
And AI bent on learning those could, in theory, come up with the financial instruments that we
cannot even really understand what it's doing and throw the entire economy into complete chaos.
There you go. Yeah, it could be nuts.
And yeah, chess is really a limited arena. But I think it's a proof of concept that if you get
the learning algorithms right, they can really advance a lot faster than a lot of people have
been thought possible. I think you're right. It's, it's both exciting and daunting. We'll
see. We'll see how it goes. Fingers crossed. Hooray. So that's the thing. They're going to be,
when they go to like hit enter on these machines and start things going, they're going to be like
popping champagne and be like, all right, guys, we're all excited, or I think they're going to be
like just getting wasted and thinking hopefully this doesn't kill everybody. Well, I hope if
that's their actual fear, then they wouldn't press the button in the first place. Yeah, you're
probably right. I guess. Yeah, you gotta make that money, right? Yeah, I think the button
will be pressed by other people who are afraid that if they don't press it, other people will
beat them to it. And it can't be that bad, right? Well, that's, that's almost worse than the two
options I laid out. Because your two options are like either we get it right, or, you know,
or we have no idea, not like, not like we better hurry, right? Because, you know, what if the
Chinese get it before we do? And then the Chinese would have this huge advantage and maybe take
over the world. And we don't like that. We want hegemony. Back in the day, we had a little bit
more primitive morality, I think, where, you know, the king is good because he's so powerful, right?
And this concept of that you can be good and not powerful. And like, just because you're
powerful and can kill everyone doesn't necessarily mean that you're right or good or moral. I think
that's a thing we had to figure out over time that wasn't as obvious at the beginning. And I
think a lot of the people, so I've talked to, you know, that are actually working on AI still
have this notion, you know, where they think if the AI is is better at playing some of these games,
and it deserves to be able to take over everything. And there's this kind of fatalism that's part of
that. So anyways, yeah, not a fan of that, that thesis, I guess. Yeah, something that's just straight
up if might, you know, might makes right. If they can kick my ass, it deserves to be the boss of me,
right? Fuck that. I think there's a bit of an is on distinction here, because something that can
kick my ass will be the boss of me. But I don't think that's necessarily a good thing. So maybe
if I can stop it from coming into existence, I would like to do that. Agreed. Okay, well,
before I forget, I wanted to do a kind of quick recap of our last conversation. So talk about,
I think the small animal brain freezing award, I'm sure there's a better name for it,
preservation award. Sorry, I'm not running on all cylinders today, I should have mentioned that
at the beginning of the call. So, but I'm definitely good enough to talk, just not lead.
The small mammal brain preservation prize, and how, you know, this aldehyde stabilized
crowd preservation technique that I made, managed to win that prize. The large mammal prize is still
outstanding. But I've seen some of the early results for them, they're looking fairly good. So
I do hope that that will be one. And then we went into more talking about, you know, brain
preservation, mind uploading, you know, what that future sort of looks like, what you would probably
want in a brain preservation technology. Now we touched on some of our course stuff. And that
was most of the conversation, you know, some of the things I'm trying to do for next home, I guess.
So maybe this is a bit of a personal question, but I'm assuming that you would like have your
brain preserved using the process where it gets fixated first, the what was it called?
The aldehyde stabilized crowd preservation. Yeah, I'm assuming you'd prefer to have your
brain preserved using that method, right? Well, it's an interesting thing. I think that what we need
is a technique that's been validated to preserve the connectome. And in lieu of that validation,
it's really sort of a crapshoot as to what you're going to use to preserve yourself.
The aldehyde stabilized crowd preservation technique, I think would have very serious
problems being applied to someone postmortem, more than a couple of hours. And, you know,
that is the one thing that the current crowd preservation techniques probably have over it,
is that you can still kind of use them even like five hours afterwards. On the other hand,
those have not been demonstrated to preserve the connectome. So, you know, what are the
metrics of success that you want to use to judge your brain preservation protocol,
or to say that, you know, this preservation protocol is better than this other preservation
protocol? What Hayworth did for the brain preservation prize is he said, you know, the first
metric of success ought to be the ability to preserve the connectome. So, for every synapse in
the brain, can you trace that synapse back to an originating neuron, or can you not trace that?
Because what neuroscience tells us is that memories are stored in the connectome. And so,
if you're disrupting the connectome to the point where it's not recognizable or it's not traceable,
then it's likely you're not preserving memory. Now, maybe there's some other redundant mechanism
that's encoding memories, but it does seem like the connectome is a good place to start.
And so, under that metric, there is no human brain preservation technique currently in existence
that has been proven to preserve a connectome. So, why, first of all, doesn't it work
more than a couple hours after death? Well, because fixatives are being delivered through
perfusion. And if you are trying to do this couple hours after death, you're going to have a lot
of problem with blood coagulation. And the process of fixation makes that much worse. And so,
you're going to have an emboli, you know, blockages in the bloodstream that are going to cause a lot
of trouble with perfusion. With the cryo-optectin perfusion, although that's still, you know,
very difficult to use after death, at least the cryo-optectins don't actively coagulate blood.
In fact, they sort of do the opposite. They will help to expand your blood vessels and to shrink
your red blood cells to get things flowing again. And so, you know, I definitely think that as far
as it goes, it's easier to establish flow with the current techniques than it would be with
aldehyde-stabilized cryo-preservation. So, two follow-up questions then. The first one being that
if you were to die in ideal conditions, like at a hospital where you can unplug and know the time
of death, would you prefer the cryo-protectant or the fixative method? You know, right now,
it seems like it might be a better option. On the other hand, I really think that anything that's
going to be used on a human's got to be validated to preserve the connectome. But the cryo-protectant
method isn't validated either, right? Well, I think they should also be validated. It's kind
of surprising to me that it hasn't been done because there are people who donate their bodies to
science all day long, okay? And you could certainly have someone who has no expectation of future
revival and you have no fiduciary duty to preserve their brain. But nevertheless, they want to donate
their body to advanced science and you would pay to acquire their body post-mortem under similar
conditions as a normal Alcor patient. And you do your preservation technique and then you slice
their brain into a million slices and check very carefully at many different points to see how well
you did at preserving the brain. And I don't see why Alcor doesn't do that. Does Alcor have the
budget to do that sort of thing? Because I don't think they're running on a large margin. Well,
that's a personal principle now, isn't it? And nevertheless, that's the type of thing that
would expect from a robust, well-validated brain preservation technology. And really,
I would say Hayworth would agree or definitely say that that would be almost a requirement
before you were to use this on people, right? Yeah. Would it be reasonable to extrapolate from,
say, I guess, doing standard cryopreservation on a small mammal, like a rat or a rabbit or something,
and then looking at the connectome that way? Well, yeah, you could do that. But even those
studies aren't that conclusive, right? I mean, there's never been using just cryo-protectants
images that demonstrate good connectome preservation. That seems like such a huge example of
civilizational inadequacy to me, or maybe not the entire civilization, but at least our subculture
part of the civilization. Like no one has gone and founded some sort of startup to try to find
funding for these things and address these concerns. Well, fortunately, we have a startup
that's addressing these concerns at this very moment. And I have, in the last couple of months,
managed to raise quite a bit of funding for this. I actually just closed, this is a connectome.
Okay. So, you know, I just closed a pretty large funding round for connectome.
Yeah. So, connectome recently got into Y Combinator. Congrats. And we're in the January,
we're in the winter 2018 batch. And we're going to be working on developing a validated
brain preservation protocol. And we're working to preserve the first human connectome.
Holy shit, this is, you are the answer to my prayers.
I'm going to give it a good shot to try. And I think there's a good chance to
reboot some of the discussions that are being had around preservation,
more around neuroscience rather than around cryobiology. And, you know, towards that end,
we're working on actually preserving human connectomes in a research context,
which I have definite plans to do. Hopefully, within the next three months,
we'll have the first human connectome preserved. But we'll see.
I just want to clarify that my prayers are a very low bar. All I want is for someone to be
putting some money into looking into this thing. So, that is what I mean when I say you are the
answer to my prayers, that not that I expect you to actually preserve my brain or anything right
now, but just that someone is finally looking into actually doing this.
You know, the aldehyde sterilized cryopreservation
actually appeared in a book 30 years ago, Engines of Creation by Drexler. And almost
in exactly the way that it's done today, you know, glutaraldehyde for an initial stabilization,
ethylene glycol for cryo-protection. Yeah, there's a couple of minor issues when you actually try
to do it that you run into, but nothing too huge. And, you know, that works amazingly well at
preserving the connectome. Of course, that's at the expense of totally abolishing all biological
activity, because the glutaraldehyde is basically gluing all the proteins together. But on the
other hand, you're preserving that structure, which is stopped by neuroscience to encode memories
and personality. So to me, it makes sense as a trade-off. And, you know, I think that the next
thing that makes sense is kind of twofold. You've got this approach towards making this actually
scale up to humans and be a very robust procedure that's actually available. And two is really
demonstrating memory preservation, right? I've demonstrated I can preserve the connectome,
but what we all really care about is can we preserve memory? And so I think there's some
profitable experiments that could be done today that help us answer these questions
for memory preservation. And I think we ought to be doing them both.
I think that's really awesome. I mean, it's going to be reassuring to be able to put, you know,
good estimates of cryo-preservation working into double digits. Yeah, I'm with Ian Yash. This is
the kind of thing that, you know, I was just, I was talking with my girlfriend earlier today
that, you know, that the realization that we all had at some point growing up that like nobody
really knows what they're doing and adults are all just fucking around. But there's no such thing
as like, you know, well-rounded, understanding all the picture, I guess, smart controllers,
you know, like your doctors leave the room after you talk to them so they can go google
your symptoms, that kind of thing. And I had even said I'm still kind of letting that percolate
into the rest of my beliefs about everything. And yet I realized at the beginning of this
conversation that I didn't really do that when signing up for cryo-preservation. Like I just
kind of assumed, okay, well, and I guess in their defense and my defense, they were probably doing
the best that they could, right? Absolutely. No, I totally agree. Like they weren't,
they weren't trying to do better than what they could do, but they were doing what they could.
So there's at least that. But yeah, I'm all in favor of this getting leveled up considerably.
I'm probably the most pessimistic cryonist that's still actually bothered to sign up. I mean,
I did sign up for cryonics, but when I did that, I thought it was about a 1% chance of working,
even if I'm under ideal conditions. And that was barely worth it, honestly, for me to actually sign
up. And, you know, since then, I've even adjusted that a bit more downwards, just given that people
die in very inconvenient ways, which, you know, degrades even further. So practically, I think
it's like more of a 0.1% chance, which yeah, it's better than your other options. But it's still
not a very good option. And, you know, why not put some serious resources into making that more
like 90%, right? At which point, I think a lot more people are going to see the benefit for
preservation. And it's less of a long shot and more of a thing that is risky, but you can bank on it,
you know, if it was more likely that this could work than, for example, an experimental cancer
drug, right? I think you're going to see a lot of people wanting to be preserved and value it.
Oh, Stephen, did you realize that we have assisted suicide laws here in Colorado?
No. Did that go through? Huh? Yeah, I was just hearing on the radio about a study they did about
the people in Colorado who chose to go through with the assisted suicide. So here we will be able
to choose the time and location of our death if we know we're close to it. And therefore,
it'll be under ideal conditions, hopefully. Yeah, I do think that if you want to do
serious brain preservation, it's got to be an end of life type of option. And it's got to be scheduled
just like any other major medical intervention is generally scheduled. You know, you don't have a
doctor that says, well, I'll do a quadruple bypass on you, but, you know, let's wait until after you
die. And then let's try to get you real fast and, you know, and deal with it at that point.
Normally, you know, you're going to come into the doctor's office and get your surgery done.
And maybe not necessarily after you die, but we're going to wait until you have a
heart attack on the street and then rush you into the hospital real quick and do the surgery then.
And, you know, there's a place for emergency brain preservation as a service. And I think
that's a worthwhile thing to be researching. But it's not clear to me why that needs to be the
first step towards getting brain preservation available to people. I think that's what you
have when it's a mature science, you know. Yeah, that should be a last ditch effort,
just in case you didn't die in a nice controlled fashion the way that we would prefer.
So what is a serious brain preservation project look like, right? I mean, you've got
an independent validation of the technique. Okay. And so the technique should be done on animals
first and demonstrate that it can preserve connectome. And you need some consensus amongst,
you know, the people who, who ought to know, which is, you know, kind of Thomas is a neuroscientist
in general, people who are involved in kind of doing simulations of neural tissue right now that
here are the things that you need to do to preserve memory, or at least here are the things
you need to do to be likely to preserve memory, right? And then the technique itself should then
be validated, you know, after having been validated on animals, it should be validated on
donated human bodies, right, so that you can work out what the limits are for being able to preserve
a human brain, you know, how many minutes after death can you succeed, you know, what are the
pitfalls to procedure, you know, get a really good risk profile, preferably you've done this on
20 or 50 donated humans, right? And then at that point, it may make sense to have a preservation
that's offered strictly at like a single location, and using end of life kind of criteria
for individuals. And then each individual would be individually validated for preservation,
probably through a brain biopsy or another appropriate surrogate, and then independently
confirmed, sort of like the brain preservation price, you know, it was independently confirmed for
these animal preservations that the connectome is actually preserved. And then there ought to be
consequences for not preserving the connectome, right? If you say to someone, you know, what we're
selling you is connectome preservation, right? And then you fail to meet that level of standard,
it's actually a good thing from a business perspective that there'll be financial consequences
for that, as opposed to that it's just at a best efforts level of service. Because then, you know,
the incentives to improve it are not necessarily there. Right. So do you already have the funding
for these first stages? But we do. I don't want to go into too much details on the funding right
now for the company, but suffice it to say, we've actually managed to raise some appreciable amount
of money, even since last time we talked. And the plan right now is that we will preserve a human
connectome before the end of Y Combinator. And so our plans are in motion to do this. Man, that's
awesome. I'm just kind of absorbing that fact. That's really, really cool to put it very mildly.
I was hoping to get the money raised, you know, before the start of January,
and we managed to do that at this point. So we're ready to rock and roll.
Fucking awesome. How long will this take you, do you think?
You know, super optimistically, we did January.
Wait, what, in one month?
Yeah. I'm hoping to do it next month. You know, more realistically, I could see it going into February.
And then July is March. So, yeah, I've got a pretty tight schedule here.
Yeah. And, you know, this is one or two human brains that have been preserved.
And then we'll independently evaluate their preservation through grades like, you know,
at Princeton, at the BPF, at MIT, that sort of thing.
And I'm assuming that the ultimate goal is to have a proven and reliable
cryonic service to provide to customers once this is all over with?
You know, it's something where we are, I think that there's a place for a service like that.
And it's something that we're looking at. But I think that what's really important right now
is to determine, you know, whether you can preserve a human connect.
There's a lot of questions about that still, even with the animal work.
I mean, you know, I mean, I got the small mammal prize.
I don't have the large mammal prize yet. And so, you know, it really needs to be validated
on humans before you start talking about, you know, whether you could use it on humans.
But I do hope to have the answers to those questions answered sooner rather than later,
because I do think it's a very important option. And, you know, looking into the further future,
like 10 years from now, I really think that this ought to be considered a basic human right,
that if you want to be able to be preserved, then you should be able to do that, right?
I think that I love the idea, but that sounds optimistic to me. It's not even a,
it's debatable whether it's human right to receive medical care in general in some parts of the world,
including the United States, right? But I certainly like the idea. I had a quick question.
Was there any major anticipated hurdles between a small animal and a human-sized brain,
other than the size scaling up? Or is that in itself a much bigger hurdle than I'm guessing?
You know, I don't think so, but those are the details for all of this stuff. To give you an idea,
it took me seven months to get it to work on rabbits, you know, to perfect the chemistry and
the, you know, building the machines and such. And then to then scale that about 10 fold to a
pig brain. A rabbit brain is about 12 grams and a pig brain is 60 to 80 grams. So, you know,
it's about 10 times bigger or so. To build that, to design and build that machine took me five
hours. It took me one evening and it worked the first time. So I do hope that we can do another
factor of 10 and make this work for human brains. And I do think that one very important area of
research that's, you know, been neglected for far too long is, you know, what is the actual time
course over which the human connectome degrades? Nobody knows, believe it or not. You know, whether
the connectome starts degrading 30 minutes after death, an hour after death, two hours after death,
etc. There are certainly complications that arise when you're trying to do post-mortem brain
preservation, which is how our initial trial is going to go, that we're doing, you know,
fairly soon. And so I can see that throwing a wrench into the works. But we will see.
We will definitely see. I think that overall, it shouldn't be too challenging. But, you know,
the world has a way of making things much more difficult for you.
Yeah. Is there, in the ultimate goal of project, are you looking just to do the scientific research
on this sort of thing? Or are you looking to maybe one day be one of the early founders of
this sort of service and maybe also push on, like, the political front to make this be considered a
basic human right? There needs to be a foundation that deals with lobbying for the rights of digital
persons and persons that, you know, have been restored. There definitely needs to be work done
on outreach to explain why preserving yourself makes sense at both an individual level and at a
cultural level. I mean, I see this as being something that's important for preserving the
memory of humanity. Because every generation, you know, we kind of lose the knowledge and the
wisdom that was gained from a lifetime of existing, all right? Yeah, we're just fucking
treading water repeating the same mistakes over and over again. Well, and I think we keep doing
that because we keep forgetting a lot of the lessons that we learn. Yeah, as we lose the
people who learned them. Well, and it sucks though, because we get more powerful every generation from
technology, which doesn't accumulate, but we don't get more wise every generation. And that is not
good for the future. We really need to deal with this. And, you know, where there are people that
are alive today, where, you know, there's only maybe 12 people that speak various languages,
okay? And when they die, we lose that connection to our past. And that's, that's a real shame. It
would be much better if we could preserve that connection to our past. So, you know, this is a
very important, this is very important from a cultural level, and from an individual level,
you know, how great would it be to be able to talk to your great great grandmother, right?
And, you know, you can't do that. But we may be in a position in the very near future to be able
to offer that to future generations. So, it's very important. Somebody needs to be able to tell
that story. And, you know, we are, are definitely looking at what people want in preservation
right now. And I think you got to be very careful, though, about getting the science right, and
getting the preservation quality right, and being able to clearly convey what you can and
can't do, right? Even a perfect implementation of Valdehyde Stabilized Corral Preservation
for human brains is not going to be able to guarantee that it can preserve memory,
all right? It's going to be able to guarantee it can preserve your connectome, all right? And
there is still a debate as to whether that preserves memory, although I would say that,
that a lot of the core understanding of neuroscience is that it ought to preserve memory.
So, that's forever right now. So, in addition to, you know, getting this to work for humans,
I think there's got to be some serious research into proving or disproving this idea of memory
preservation, because it's not going to anybody any good if it doesn't actually preserve memories.
Great. You do? Yeah. Oh, okay, great, because it would just, it would be really sad if someone
went and did all this research and did the science, and then no one took it and ran with it and
provided it as an actual service. And I do understand that some people just want to do the
science, and that's what they have a passion for, and they don't want to go about trying to start a
new business. If you are willing to take up that mantle, that makes me much more hopeful for the
future. Well, I think doing this business to not help people, right? So, it would be, it would
make me very sad too if you just had the research done, it didn't end up actually doing anything
worthwhile. Well, you can always hope someone else takes it over. I believe that a lot of people in
the sciences do do that sort of thing, where they're like, hey, here's the research I did and the
things I found. Now, someone please take this and make it available and do cool stuff with it.
I don't think that really ever works. You got to actually make it work yourself if you want your
technology to win. Fucking heroic responsibility mindset right there.
Robert Edinger wrote The Prospect of Immortality in the 50s, and he was like, if we freeze people,
and maybe that'll preserve them, look at the massive advances that have been made in
cryobiology over the last couple of years, we're probably like 10 years out from reversible
cryopreservation, and probably the ability to undo whatever freezing damage we're doing now.
And he thought that was such a compelling idea that he just had to publish it, and there would be
massive worldwide government programs in five years to offer this to anybody who wanted it.
And the reality is nothing happened at all. And five years later, he finally decided, well,
let's try to start something to make it happen. And I think that's a much more realistic way
that technology happens. And really, if your thing is legit, why would you not go and make
a lot of money off of it? Right? Why do you want someone else to do that? That's a good point.
And if you're not going to do that, maybe that means your thing's not legit after all.
Yeah, I think it also takes a lot of business acumen to make something like that work because
I personally would not want to start a business because, God, the headache.
I'd be looking for the easy halfway point where I could just be like, hey, I'll call her, hey,
Clonix Institute. I found this other cool way to do it. You guys want to offer this as an option to
your new customers? Maybe they'd be pressured into that if they had a competitor that was offering
that. Right. Yeah. I think that'd be cool too, because they're already out working on sort of the
campaign stuff. A lot of people are very hesitant about using a preservation technique like this
because you are totally abolishing biological activity. The most realistic mechanism I can
personally see for extracting memories from a preserved brain would be destructive scanning
and emulation in a kind of emulation environment on a computer. And a lot of people don't like
the idea of that or they feel like that's not really a meaningful continuation of them.
And so for that reason, I think a lot of people are not necessarily going to want to go for something
like autohydestabilized prior preservation. Yeah, but if you're restored in a simulation,
you can always have that simulation hooked up to a cool cyborg body and interact with the real world
too. Well, you absolutely could. Or you could print a new brain. It's patterned off the blueprint
of the old brain and do that. And of course, you know, I say that kind of flippantly. I mean,
that's an amazingly advanced application of technology. On the other hand, you know, I could
see a pathway towards doing many of these things, but I don't see a pathway if you don't have that
blueprint. If you have that data that defines what your memories are, it's going to be very
difficult. The comparison here would be like, let's say you have a book and you want to preserve
that book, right? And so one of your options is you mix up a bunch of epoxy, and you're going to
pour it over that book. And the whole thing's going to turn into a solid block of plastic,
and you're going to glue the ink to the pages and the pages to themselves. And you have this
totally immobilized tube of just plastic, right? On the other hand, you can preserve the book by
just sort of, you know, putting it in a nice environment, right? Like a freezer.
Yeah, but then you're going to end up getting some holes in the pages, though, from, you know,
just decay. And the ink's going to fade a bit. But you'll be able to open that book, right,
and look at some of the pages, which are going to be very fragile. I would say that the bigger
those lacunas in that page become, right, these holes in the text, it rapidly goes from, you know,
oh, maybe we can figure out what this letter was, or maybe we can figure out what this word is to,
you'll never be able to figure out what that sentence is, right, or what that paragraph is.
You've really lost the information. And, you know, while it seems, at the face of it, that this
block of plastic is almost impossible to interrogate or do anything with, you could
certainly imagine going through it with an x-ray and then printing a new copy of that book.
And now you can completely read that story again. If I told you, hey, you know, we can give you,
there you have two options. I can give you the original Library of Alexandria on a thumb drive,
okay? Or we'll give you the ruins of Library of Alexandria, but, you know, only a quarter of
the books are intact at all, and even those are highly damaged. But they're the original books,
which one would you guys rather have? Sounds like a no-brainer.
Yeah, well, from a practical point of view, I might take the originals because I think those
would be worth a lot more on the market. And I think that possibly all the knowledge that was in
there originally has been recreated over the millennia and, you know, likely, please surpassed.
But I absolutely take your point.
Yeah, that's what I was going to say. That was my first impulse is you could sell the real books
for something. But I mean, for the spirit of the question.
Yeah, to address the spirit of your question, I would actually prefer to have all the information
on a thumb drive rather than only pieces of the information in their original form.
You know, it's interesting because the story is what matters. And the originals, you can
ascribe a lot of value to them. But what we really care about is hearing the voices of the past.
And the originals aren't good at giving us those voices of the past, but the thumb drive is.
Yeah, and we could recreate some of the original lost works of fiction and dramas and such that
are just completely lost if we had them on thumb drive.
I wish the Greeks and, you know, they have this concept of a libation to the gods where
if you have a drink, you're going to pour out part of that drink on the ground,
you know, for the gods. I wish they had the same thing for libraries, right, where they take their
books and they're going to, you know, pour wax on them and turn them into a block of wax and put
them in a lead box and toss the lead box into the sea. OK, because if they had done that,
we would have their stories again today. Yeah, it's just a shame that they didn't.
Yep. Wow. So that is that is a lot. Do you have like a timeline now for the broader picture,
broader strokes of things going forward into the future after this first step here?
I think that there's there's too many things we need to get this to work for humans,
because it would be good to solve all the logistical problems around human connector
and preservation. And beyond that, there is a big important question of does preserving the
connector and preserve memories? And if not, what additional structures in the brain do you need
to preserve to preserve memories for future digital emulation? And so attacking both problems,
I think, makes a lot of sense. One was more of a peer research question, one's more of a
of a peer engineering question. So I tend to do both. The human preservation is substantially
easier given our current resources. So we're going to we're going to work on that and demonstrate
you know, kind of a next phase of this brain preservation prize, demonstrating a preservation
of a human connectome. And then there's a couple of very interesting experiments
for memory preservation that I think are just around the horizon. And those are are approaching
memory preservation as kind of like a zero knowledge proof, where you do an experiment
that's designed to reveal whether the memories exist or not, because you wouldn't be able to
complete the experimental outcome without those memories existing. And it gets around some of
these problems of understanding exactly how memories are encoded, or even, you know, being
able to trace large amounts of brain tissue, which neither which we can do currently.
And so I think those are those are amazing experiments. And then also, you know, growing
a brain on a chip, as we're rapidly developing these technologies, I know there's one company
that's developing this technology. So you could have drones that can smell things.
And that's really cool. And it seems to you know, they're doing some major progress for it.
We're actually growing real cortical neurons on a on a chip. And there's actually probes,
electrical probes in the neurons cell bodies, you know, that are getting some millivolt signaling
from these neurons. And the neurons are kind of exposed to the air. So various things impinge
on them and cause them to fire in different ways. And it's actually, you know, learning from that
neural network that forms what the cells are. But you could, after many days of recording carefully
through this neural network, then preserve that network with your preservation technique, scan
it with an electron microscope. And if just from the data from the electron microscope, you can
emulate it and totally recreate the input output, you know, the transfer function of that neural
network. That's very compelling that your preservation technique is preserving the things
you need to replicate computation. The zero and all is pretty cool because you're able to answer
high level questions like was this mouse afraid of the thing or this other thing. And so those
test experiments are doable with today's technology. And they're important, they actually get you
answers to questions about memory preservation. And they allow you to compare one preservation
technique against another one. So those are the few things I think are going to be really cool
in the future. I should probably get going because both of my computers are about to die.
And I would love to be able to get to your audio. Did you have anything to wrap it up?
And I was going to dive into more of the memory stuff, but we'll have to save that for another
time. Yeah, I think you're right. It's worth preserving the memory of this conversation
on your computer rather than losing it forever. So I had some more too, but we can hit them up
next time. I was wondering if once this next phase of your project is done and you get some
results, would you be willing to come back to the show and talk about them some more?
Absolutely, but you got to show off some of the electron micrographs if I do that.
Yeah, no problem. We can put them up on the website. Deal.
Beautiful. All right, cool. Well, it's time to go and we'll let you go.
All right, thanks. Have a good day. Thanks a lot, Robert. That's great.
Alrighty, so thank you everybody for listening. And well, I hope you had a great Christmas and a
happy new year. And we'll see you all in two weeks. Excellent. Goodbye. All right, see you.
