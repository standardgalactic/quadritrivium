Welcome to the Basin Conspiracy, I'm Uniesh Brotsky, I'm Stephen Zuber, and I'm Alex.
And I'm David Youssef. And who are you guys on the Discord server?
Oh, I go by Bayes Theorem, spelled B-A-E-S.
And I change my moniker pretty regularly, but I believe right now you can find me as
King of the Summer Sun. Excellent, welcome. And David has actually been here before. You have
been the wizard on our crazy wizard episode. I don't know if crazy is the first term, but on our
wizard episode. And Alex, you were on the Colin Show. Yes, yes indeed. My whole thing is I'm the
organizer for the Kansas City Rationalist Meetup, as well as the Kansas City Effective Altruists
Meetup. A lot of overlap, but there are some people in the EA group that aren't in the Rationalist
Meetup. So you live in Kansas City. That's correct. For some reason, this whole time I
thought you were on the East Coast somewhere. Nope, Midwest. Okay, cool. So you guys hadn't
actually ever met in physical space before, had you? Yes, this is the first time we've
occupied the same time space. For some reason, I thought that you guys knew each other already.
I mean, not physically. There's no good words in our modern English language,
because my brain has been talking to all of you guys. I feel like, oh yeah, I was just talking
to them like a few days ago, but we haven't physically all been in a room ever together.
It's very strange. Right. Well, we are here now, and we are going to be talking about a
special project they are working on. But first, we are going to do the sequences as we always do.
As we sometimes do. We try to anyway. Luckily, these are a couple of quick ones, and they're fun.
They are fun. I like this one. Yeah. Well, I want to kick us off with Explain Worship Ignore then.
Sure. Sounds good. Explain Worship Ignore. Yeah, I remember reading this when I first
read the sequences, and it's not really a new revelation to me, but it's as many of the sequences
are. It's articulated in a way that I never thought of. And having this trichotomy, so to speak, is
something useful to look out for whenever I'm encountering the supposed end, the answer to
a curiosity I had. Yeah, and I think it does what a lot of the other posts do, which is like
distill down themes he's been hitting on for a while until like, all right, here's the thing I'm
talking about. Here's a nice, here's a nice single post you can reference rather than try and explain
the long-winded way of what I've been hinting at for the last two months of blog posts. So,
what is it that he's trying to explain in this one as a short summary? So, Explain Worship and
Ignore, at least the summary I got out of it, was every time you're faced with a phenomena,
you have a limited amount of brain energy, like you don't have infinite resources, and you have to
prioritize what you're going to do and how you're going to respond to it. And we really only have
three responses to phenomena. You can either get curious and say, well, is this worth putting
in time and effort and understanding? Can I ignore it? Is it not important at the moment? I don't
need to think about it. And then the idea that this article really pointed out to me that I had
not had before is that the third option is worship. And that's kind of terrifying. But the idea is when
you feel and you see something you don't understand, there's at least a somewhat human instinct to
wave it away by saying, oh, that's something beyond the comprehension of men. Therefore,
I just need to be in awe of it. The example he uses is an early man wondering where rain is from.
And some kid asks an elder, hey, where does rain come from after it rains? And the elders, like,
has never really encountered this before, because it just rains. No one gives a shit. It happens.
It has always been in the ignore category. Exactly. For their lifetimes, it's always
just been the ignore category. And now, for some reason, some punk kid is asking for an explanation.
So he gives an explanation, and the kid asks, but oh, but why that? Why are the spirits fighting
and crying up there? And the elder eventually goes to, because that is the way it is in the
grand universe. And this is how the cycle of life continues or something. And so defaulting to the
worship category for that. And it's not, it's not a bad thing to put something into the ignore
category. If it's genuinely not relevant, or you just don't have, you just don't have an answer,
you don't know how to get the answer. But it's important to recognize that you've put it into
the ignore category, and not the worship category. That way, when you do have the capacity to
investigate it, you don't blow it off and say, oh, well, that's just the way it is. You're just
trying to take the mystery out of it, and so on and so forth. He made the, he pointed out that the
explain is a answer that will always be reiterated, because there will always be deeper and deeper
explanations. Like, why does it rain? Oh, because of this. And why, well, why does, why do, why does
moisture condense on particles in the air because of this? And, well, how does that happen? Because
of atomic physics? Well, why do atoms happen? Well, because of electrons and protons. And you
always, you can always ask another why can explain deeper until eventually you reach the point where
we don't know yet scientists are working on that come back in a decade or two.
Right. Someone in the comments asked, well, why can't it just be an infinite recursion? And
you'd ask, you responded saying, well, maybe it is an infinite recursion. But then my question is,
why is it this infinite recursion, as opposed to another infinite recursion?
And I will say I've run into that, the ending on worship a number of times in my real life,
especially back in the day when I was more active in atheist argument stuff. But this happened
even just a year and a half ago to me when I was talking to someone who is says he's a theist and
signs onto one of the major religions Catholicism, I think. But in practices, functionally, an atheist,
right? Except he goes back to, well, you know, we don't know why or how the Big Bang happened. And
we don't have any sort of experience for how something can happen before time has begun or
without a cause or whatever. So that is that is what God is. God is whatever strange force happened
to make the Big Bang happen. And I was like, Okay, so you just got to the point where you
ran out of explains and there's your worship. So I'm confused. Does this person think that before
airplanes existed, and humans had the experience, they'd never had the experience of flying, that
would they have taken the position then that that was an impossibility and a like a reason for worship?
Oh, we haven't experienced it yet. Therefore, worship. I don't know, you'd have to ask him.
Seems dubious. It also kind of reminds me of the the Bayesian judo sequence where
you'd cast you encounters someone who is a theist, and they are poo pooing the idea of
artificial intelligence. And you'd cast he says, Okay, well, you just made a prediction, you think
that in your model of reality, artificial intelligence can't happen. Therefore, if and when
I make artificial intelligence, that means your your theism is incorrect. And the guy then
recurses in the conversation. And so if someone says the Big Bang is a mystery, and that is God,
what are they going to do when we if and when we explain the Big Bang?
And God drinks back the next thing. Yeah, I'm always surprised too, that someone
can have that as their like, their motivator for their religion, and still call themselves
like a Christian or a Catholic or whatever. And it's like, how does it follow from the
fact that we don't understand pre Big Bang, that like masturbating to sin and, you know,
gay people shouldn't get married or something? Is your religion doing any actual work for you?
Or are you just like a good old fashioned deist? Right? Because you realize that 500 years ago,
that it brings you at the stake as a heretic for saying things you are now if you're pretending
to be a Catholic. And I try to point out, I don't know why you're using a personal term like God.
And you even if you don't say it specifically, you think that he has like agency and personality.
Like, the Big Bang, the force that caused the Big Bang is probably something as impersonal as
what makes protons and electrons retract. And the deed was like, but you know, that's God,
man. That's just God. I'm not saying any of that. Like, no, you're not saying it, but you live like
it. You've decided to put this in the worship category for the rest of your life. And that's
fine. But you need to take the consequences of that, which means you can't make predictions.
You can't make predictions and your curiosity is forever stopped. I think this is the thing
is the curiosity stopper. Yeah, this is the thing that actually I disagree with in the article.
So he says that we might run into an explanation one day that is self referential, and therefore,
like, needs no further explanation. And that would be where he would choose to worship.
But Godel's incompleteness theorem, and we were mentioning this before the podcast started,
Godela Shabbat, but Godel's incompleteness theorem literally says that like, no matter how
intelligent you are, no matter how far you go in math, any closed system will always have
things that are outside of its understanding until you build a new system. So it's literally
impossible. Like it is infinitely recursive. Unless I'm really misunderstanding that proof,
but I'm pretty sure I'm not. I, I'm trying to get more context here, but I think he was being
facetious. Because he does talk about that later on in the comments. I've not read the comments,
I might be very much misinterpreting this. He says, I say must in the worship option,
it is irony. But if there is an infinite regress, I should find that highly curious,
and I would like to hear explained why it is allowed, and why this infinite regress exists
rather than some other one. So it sounds like he would still hit the explain button.
Okay, really like Alex's voice for Aliezer. He sounds kind of British with an American influence.
I'm like, huh? Yeah. Wow. It's not what he sounds like. But no, not at all. But it sounds very
authoritative. Yes, Professor Aliezer. Well, we, we are going to say we use the word curiosity
stopper, which leads us directly into the next post. And this one ties really closely with
that one. Were you going to say something else on this one though? Yes, I was going to say two
quick things. That the worship, he also ties back to worshiping is like a mysterious answer
mysterious question thing, where you are kind of you are making a value of your, your ignorance,
and how this is mysterious and great and feels really good. So that was the thing. The other
thing I was going to say is, you guys are all younger than me. And some of you fair, quite a
fair bit younger. I was wondering, do you understand? Do you get the the in joke to explain worship
ignore being the same thing as abort retry fail? I do not. No, sorry. Way, way back when computers
ran on DOS, well, when PCs ran on DOS, a common whenever the computer would try to execute an
operation and it failed, it couldn't, it couldn't do it. It would come up with a little dialogue box
that said abort retry fail. And if you aborted, it would stop doing what it was trying to do.
If you failed, the exact same thing happened. I don't know why there are two different options.
And if you retry retry, then it just tries to do it again, which in 100% of the cases in my
experience meant you just got the dialogue box again. Definition of insanity. But yeah,
and then that was ported over into the first Windows operating system as well, where whenever
there was a system error like that, you would get that pop up box. So I immediately as soon as I
saw explain worship ignore, I was like, Oh, it's a board retry fail. That's exactly what it is.
And with that context, and I think it matches to because like explain maps to retry because
you're always like searching further and further and further. I'm assuming ignore is fail because
you've just failed to try to explain things. And maybe worship is fail. Yeah, worship is fail.
If I had to guess why there's two different options, one would put a would send it to
some log somewhere saying this task failed, if you click failed, but if you just hit abort,
it's just like, fuck it. And it doesn't bother. I'm not actually sure, but that'd be my guess.
And what's funny is like, I can just imagine like the allegory of like, you know, tell your
computer to make you a sandwich and it goes in to get peanut butter. There's no peanut butter.
So just like, there's nothing I don't have. I don't have a way to handle no peanut butter.
Don't want to try again. Yeah, sure. Oh, fuck, there's still no peanut butter.
Like, so of course, it's going to just fail on the retry every time. Like the only time I see that
working is, you know, over web connections where it's like, Oh, yeah, there was a hiccup in the
connection. Now it's fine again. So maybe it was for really back in the day when you could like go
back and mess with vacuum tubes and then hit retry. Maybe.
What I like about this too is that independently, I think the phrase God of the gaps came up for
like the worship category here, where, Oh, I've got this gap in my understanding. Well,
that'll be why we touched on this, we just didn't give it the name. But that I think it was an
independent articulation of that same sort of thing that I liked. So yeah.
All right. Then we should move on to science as curiosity stopper.
I've got a good way to jump into this one. The first thing I thought of was when I also do a
Harry Potter podcast on method of rationality. And when Professor McGonagall turns into a cat,
he's like, how the fuck did that happen? And she's like magic. And he's like, that's not an
explanation. That is exactly what this is. We brought a caveman from, you know, 100,000 years
ago and put on a light switch and showed him the refrigerator that puts out clean water. And he
just, you know, he was also a scientifically curious caveman. And he'd be like, how's this
work? He'd be like, oh, science. And he's like, that, that doesn't tell me anything. That's not
an answer. Fuck you. The word science can often be used as a worship button as well. Honestly,
anything like magic science, if you don't actually understand the word, any word can be used to
just stop your curiosity. I mean, this sounds like scientism to me, like the,
the almost like, I fucking love science Facebook page. It's people who admire what science does.
And I don't blame them for that. But they don't want to do the work of understanding the process.
They just want to understand the end. And they don't even want to understand the end, really.
They just want to see the end results and be able to say like, Oh, someone gets it. Therefore,
it's good. Yeah. Science could have resulted in a lot of different discoveries and a different
kind of universe. But the beautiful part about science is not the things that has discovered.
It is the methodology of learning the rules of the world around you and finding out
where you are wrong and where how you can learn more. It's like a methods of rationality. Harry
says, if, if all, if everything failed and the all the laws of the universe were replaced,
I still exist. And that in my ability to find, figure out the world around me still exists.
And that is the beautiful part about science that a lot of people don't understand.
Agreed. The beauty of the natural world that we've discovered is just a bonus.
Right. Yeah, he says he finds it interesting that a lot of people stop being curious about
something. If it turns out that someone else knows the answer, which is what saying science
often means. Yeah. Like, why does the light switch turn on the light? Well, you know,
because of electricity. How does electricity work? I don't know science. Like, oh, okay.
I actually like something Scott Alexander once wrote. He, and someone else he knows,
they have a habit of whenever they don't actually understand something, they explicitly say,
that's magic. Just, just as a placeholder, because they know it's not just a few episodes
back. Oh, the sequences. Oh, great. Yeah. That's, it's a useful technique, especially as long as
you don't actually believe in magic. Right. But yeah, it's sitting right next to you.
You believe in placebo mancy that's different than, than, than the magic I'm thinking of.
I put on my robe and wizard hat. What? Yeah. It's a fun technique that I've used in the past.
I think so. I think a good way actually to deal with this, because like, I run into this all
the time. And I'm sure you guys do as well, where people clearly don't know the science they're
talking about and spreading is to let them give them examples of when the scientists don't know
what's going on, because then it helps them realize maybe someone out there doesn't know. I don't know
why that psychological thing is in their head. I find it's easier to tell people like, Oh, this
thing that you think is figured out by science, you're completely wrong. We're kind of guessing,
we're not even sure we're anywhere right. Then they get curious, because then they're like,
Oh, there really is a mystery. And I think, I think the sequences make a very good case
that that feeling of needing mystery is a trap, and that you should be looking outside of whatever
you conventionally think is mysterious. But it seems like a good way to do it. Like one of my
favorite stories is we had jet engines for a few years before we had the aerodynamics to explain
how they flew. So there were several years where there were Air Force pilots getting into machines
going at Mach three, and no one on earth could explain what was happening. It was essentially
like riding a magic bullet, like anyone on earth would have been like, in that similar situation
with things like anesthetics. Yeah. And so like helping with jet engines, it's basically throwing
shit out the back to make it go faster, right? It's the vortexes that were really confusing us
because we didn't understand how the movement of air behind the turbine was creating as much
thrust as it did. Like we knew it should work the same as a rocket, but we just didn't understand
how effective it was and why we would be getting issues at higher temperatures. Like we had to
discover that when you go at a certain speed, the metal heats up and stretches. And so you need
to build gaps into all your jet engines and stuff like that. Okay. Wow. Being a test pilot must
have been pretty dangerous then. It must have been absolutely radical to get into a machine
that no human on earth could explain to you. This is why I don't get the version one of anything.
Why I won't be waiting in line for Elon Musk's neural neural link version 1.0. That's why I'm
not getting the vaccine first. I'm getting it. I'm not an anti-vaxxer, but I'll wait for the second
round. I think the FDA is way too strict and we should be totally fine by the time it comes out.
Well, and vaccines are explored territory. So like it's different than, you know, the
the discovery and distribution of jet engines or neural links. I just figured, you know what,
I'll, the neural link, I'll get the 2.0 version, but you know, vaccines I've had since I was a kid.
So this is like the other ones I've got then close enough. But I hear what you're saying.
I'm not retiring until I have the vaccine because it'll be covered by my insurance and I want to
retire as early as possible. So getting that vaccine as soon as I can. Nice. Pretty good point.
Yeah. I like the last paragraph here where he says, the world around you is full of puzzles.
Prioritize if you must, but do not complain that cruel science has emptied the world of mystery.
Yeah, that kind of goes back to the idea of the beauty of science is not the things it has
discovered. It's if you are a proper scientist, there is no end to the curiosity to your curiosity.
There's no end to the mystery and wonder of the world around you.
To a real scientist, if you say the answer is science, that's a prompt for them to be like,
what field? Tell me who did this? It's not a conversation ender. It's the beginning.
Yeah. To a real scientist, the word science is a very unsatisfactory explanation.
I just wired up yesterday a couple, well, one more thing in my house. And I realized while I
was doing it that like, I know that the live wire goes to the power station where the electricity
in quotes comes from. But like the ground wire, where does that go? I assume it has to go back,
right? Nope. Not like the ground ground that grounds the house. Yeah, the other wire, the
non live one. The white wire, where does that go? Does that eventually loop back to the station
as well to complete the circuit? See, mystery is abound. It's just the way it has always been
any young. It's from the time before time. I feel like half our listeners are going to be like,
I can't believe he doesn't know this. What adult doesn't know this? But on the other hand, I'm just
like, the black one is the death. And the white one is okay. And you match black to white when you
hook things up. Or black to black and white to white when you hook things up. If anyone's going
to give you shit about that, I'll share some of that and saying that I couldn't have, I would have
killed myself trying to do anything like this. My knowledge of like, my lack of knowledge of
anything regarding electricity was really born when we met, got to know Chase, I don't know,
years ago, one of the meetups. And he's just like a Wikipedia on this stuff. And I'm like,
fuck, I don't know shit all about any of this. This is awesome. It was it was really enlightening. I
remember in the, like early advent of being able to text pictures to each other, we were visiting
my great grandparents. And my grandpa, you know, was a farmer, then postal worker. And he was,
you know, I showed him, I was like, Oh, yeah, this is a picture I took. And then Oh, yeah,
my someone sent me this picture just today. And he's like, I have no idea how that can possibly
work. And I'm like, you know what, I don't really either, because I was like 12. And even now it's
like, I still I understand how parts of it work. But it's still I don't understand enough of it
to be able to say build one from scratch or tell you how to build one from scratch.
You mean, making pictures out of ones and zeros? Well, that and and texting a picture to somebody
that part I get more than the just yeah, I mean, rendering a picture from someone. I mean,
I get parts of it. But you know,
there's a cool video. It starts out like it appears to be a explanation of Excel spreadsheets
and how you can make the different colors or the different cells, different shades, if you
it's common thing, like if a number is greater than 100 make the cell turn red so that it pops out
right away and the camp can be like, Oh, what happened over here? But it's a great video. It
starts out like that. But then he just zooms out. And he's like, Oh, he made a picture. And it's
it's basically I know about this guy. I read an article about him. He does Excel art. He's been
doing like pieces that are huge wall mounts and selling them for a few thousand dollars. I would
love to have an Excel piece of like a Monet because I can't think of anything more opposite to
impressionism than little boxes. And it's how all all electronic pictures work. Just every
single pixel is a number and the number represents a color value. It's a really good thing to excel
at. Nice puns are good transitions to the real episode. Terrible. We got to kick them off the
podcast. We've got to tell over discussing next episode. Right. Next episode, we will be talking
about the posts. Where was I absurdity heuristic absurdity bias, which is one post, and availability,
which is the other. All right. And while you're doing a third one, why is the future so absurd?
Okay. Awesome. Cool. All righty. Well, I suppose this if you guys had anything else you wanted to
go over. All right. So by the time this comes out, there'll be an episode. Yes. Thank you.
Like applause. There'll be an episode on well, I can make sure I plug the doof. Yeah. Whatever.
If you're if you give a buck a month to do if you can subscribe to their patron only feed,
which is mainly Matt Freeman, famous leader of the rationalist movement,
um, and his brother talking about random cool shit. And I think mine and Scott's on this one
will be the first one that isn't no, wait, maybe the second one that isn't Matt and Scott having
the Freeman bros conversations. So wait, I'm sorry, Matt, Matt and his brother Daniel. Um, yeah.
Anyway, check it out. Cool. So you guys are here. Well, I guess you're here from Kansas City,
and you're here from, I know the East Coast, New Jersey, I want to say Pennsylvania country.
Yes. Yes. I was going to get that right. But you, uh, well, you have some things from Kansas
City bring to us. Yeah. Yeah. So I suppose this starts, the story starts two, three years ago.
Evangelical Alex was running a Harry Potter tabletop set, a campaign, a D&D style.
And they actually have a source book for that? No, it's not official. Okay. There are a few
different varieties. But anyways, I was looking for plot ideas. So I did some research specifically
into the founders of Harry of Hogwarts. And I stumbled across HP more. Oh, yeah. That's what
started it. That's what started it. I mean, a classic backstory. So I read HP more. And then
got into the sequences because it's like, Hey, do you want to learn everything Harry knows? I'm
like, yeah, I want to know everything Harry knows. That sounds great. And I read the sequences over
the course of like three months. And it's among other things that single-handedly
deconverted me from evangelical Christianity. And then I was just a rationalist alone in Kansas City
with no one to talk to. Because I wasn't really active on the internet that much. I was very busy.
But eventually, I looked on Less Wrong, and I saw that there was a Slate Star Codex meetup.
It was one of the meetups everywhere thing. It was just a one-off kind of meetup. But I
got went there and it was so cathartic. It was so good to meet other people I could talk to
and about the content of the sequences and HP more. David, you had a thing about the first
time you walked into a Less Wrong meetup? Yeah. So the first time I actually went to a
rationalist meetup was in Denver here. I knew you guys were in Denver. My little brother lives here.
And I was like, Oh, at least check on meetup.com. Maybe I'll get lucky during the week I'm here.
And I was really like nervous and intimidated. But as soon as I walked into the room and saw
all of you guys and heard the conversation, I literally felt my shoulders drop and relax.
And I didn't realize how much tension I have, knowing that most of the people I talk to,
I have to assume they are not reasonable. I have to start with the assumption that things are not
going to be an easy communication. And that's just not true in this community. It really,
it felt like breathing for the first time really deeply in like months.
It's funny, I can't picture you being nervous.
I think I mentioned earlier, I had a really good analogy and it's escaping. Oh, yes. So when
you're talking with another rationalist and you meet another rationalist, you already know that
you share so much background knowledge that in any other relationship would take months of
really intimate discussions and a really solid amount of time together. And that you just get
for free with most people in the rationalist community. But it wasn't enough for me. I've
always been a very ambitious person. Everything I do, I go all the way. I go big, I go home,
I'm that kind of person. So I started to attend these late start codecs meetups. It was once a
month, hang out where they just kind of chatted over coffee kind of thing. I'm like, you know what,
I want to raise the standard water line of planet Earth. That's what I want to do.
So I gathered everyone together and I said, okay, who wants to just start an actual
rationalist meetup? Like, we're going to do this every week, we're going to have a dojo,
we're going to do community external facing community stuff. And I managed to get most of
them on board. So then I baby rationalist Alex, who has almost no training in the community,
was tasked with constructing a dojo. Because that's what I wanted to do. But I was the only one that
wanted to do it. So I had to do this myself. And the best thing I could find was something called
the hammer time sequence on less wrong written by someone who went through CIFAR and then wrote
30 days of material going over everything he learned. So we started off with that. And because
we're a bunch of rationalists, we went through it and we modified it so much, we what we had. Yeah.
Do you want to explain what the hammer time sequence is for the listeners who haven't had
the opportunity to listen to it yet? Well, it's if you're not familiar with CIFAR,
the Center for Applied Rationality, it is basically the most formal organization to come out of the
rationalist community. It is basically they basically put on these semi frequent workshops
where you it's like a two three day camp or a week long camp, something like that. Yeah,
they do have the some smaller ones. Yeah, the big one is like, I think two or three weeks,
two or three weeks. So that's almost like a mini boot camp. Yeah, yeah. But they have smaller ones
now too. Yeah. And so this they basically teach you various ways of overcoming bias in your planning,
like in your day to day life, applied rationalities in the name. So they they're interested in how
you apply rationality to accomplishing goals in your real life. So things like debugging yourself,
finding the problems in your in your physical space, overcoming biases and planning that kind
of thing. So that's the material that's in that was the material that inspired this hammer time
sequence, which we then used as the raw materials on which to practice dojo stuff. And basically
each week, we discussed one of the techniques, and we critiqued it, we used it, we talked about it.
And the next week, we would report back on how it affected our lives from the last from the
previous week. And that went on for a while, we eventually got to the end of the hammer time
sequence and did a post mortem on it, and realized there was so much material we had brought to the
table ourselves as a bunch of rationalists who have done our own rationality in our own lives.
We have a licensed therapist among in our midst, who was able to bring a lot of really good
frameworks to formal frameworks to the table. And we decided to start doing our own thing.
And it's very similar format, we talk about a technique, we talk about something epistemologically
related. Then I then Corona hit and done done done done. So we had to cancel our IRL meetups.
And I also around this time had started an effective altruism meetup. And that includes a
lot of people that are not explicitly in the rationalist community. So the main thing I wanted
to bring to the table here is, number one, there are lots of rationalists around the country that
don't have a meetup that they can go to they don't have people a community they can go to,
to feel this sense of catharsis that David and I and you guys get to experience whenever you
meet your local rationalists. And I wanted to first start off by giving them a word of encouragement.
The Bayesian conspiracy was a huge help to me during those times. And I was just a baby rationalist
that didn't know anyone around me. And number two, if you are able to access online forums of
some kind like Facebook, events, meetup.com, if you post that you are a rationalist looking for
the rationalists, you will very likely find someone. But if you do not, I started an effective
altruism group. And that has brought a lot of people into the rationality community that
were not previously in it. It's a similar mindset, similar mindset that tracks the same kind of people.
But it has a slightly larger circle. And if you're struggling creating an organization,
a community in your local area of rationalists, start an EA group. That is a great springboard
for bringing people in. And we basically have a book club each week, every month with EA. And
every time it's my turn to provide a reading, I usually provide the sequences of something.
And that and everyone loves it. It's great. And that has been a very positive experience for me.
So, all that being said, there were a few, the reason I did all this, and the reason I was so
passionate about this is because I do want to have a positive impact on the world. And the
rationality community has such potential to be that. It is everything that I consider,
the mind model of a group of people that changed humanity for the better very closely
matches the rationalist community. But there were a few problems that I've noticed. Number one,
rationalists are notorious for not working very well together. At the very least, they don't,
they dislike grouping together into organizations. As an issue with like the skeptic community too.
And the AES community, I think Richard Dawkins equated like coordinating this community to
herding cats. Right. Yeah. Right. A lot of anti-authoritarian communities are going to have
allergic reactions to groups that are trying to coordinate. Right. And that is the worst,
least rational part about us, because there's nothing more powerful on earth than groups
of humans cooperating together. We have almost nothing weaker than one guy screaming through
a megaphone. Yeah. And so, but that's a hard thing to get over when your entire life you've
been trained to like watch out for large groups because they're dangerous and they're stupid.
So, oh, one second, I'm about to transition straight to you. Thank you. So, I was listening
to the Bayesian conspiracy. You guys had David Yusuf on and he was absolutely railing against
this particular failure mode of the rationalist community. Yeah. I'm like, there's a guy I can
talk to about organizing and he won't have allergic reactions to this concept. So, I reached out to
him and I'm, I say, hey, do you want to start a virtual dojo? Because we can't do corona,
we can't do IRL dojos during the coronavirus. Do you want to have like a zoom one that we can
just open up to the Discord channel? And he's like, yeah, as a matter of fact, I've been talking to
Matt Freeman and I will hand it over to you to give you a backstory on all this. So, a few years ago,
when I first got to Denver, met you guys, I think it was after my because I've done another episode
after the magic one where I was in person and I know I've done one online, but I met Matt Freeman
and during our conversation, we realized we had a lot of the same frustrations. In fact, I believe
a few episodes ago, Steven, you were talking about emails you had been sharing with Matt about
how frustrating it is that a lot of the rationality stuff that we practice is not measured, is not
really, we don't know how effective it is, we don't know how well implemented it is.
I've got to clarify, I think we're talking about two different mats. Yeah, that was a different
mat that was about that episode. Oh, yeah. So, I didn't use the guy's last name because I don't
like to disclose full names on from emails. If it's public, then I'm fine reading whatever username.
This was not Matt Freeman. Matt knows the value of the community just fine and the value of its
teachings. You can just cut out all of that. Oh, no, leave it all in. It doesn't matter. It's just,
it's a mistake. No, because we were talking about that before and it didn't quite click that like,
oh, wait, he's maybe thinking of a different mat. Okay, yeah. Well, then I'm glad that someone
else is thinking about this. But the mat I was talking to is Matt Freeman. And for a few years
now, we've been discussing this very frustrating issue of one, we don't know, we both believe
that rationality has helped our lives immeasurably, but we don't know how to measure that. Like in a
practical way, we don't know how to advertise. And one of the things that's always bothered me is,
I think a lot of rationalists view soft skills like social skills as an annoyance to be learned
afterwards, not realizing that this puts them in a position where other people define us.
Like we as a community are so antithetical to the things we consider the dark arts like branding
even that we end up leaving ourselves vulnerable in a lot of ways that are pretty stupid in my
opinion. And so we had talked for years about how to approach this and we weren't sure we'd
shared discord messages and emails. And then Alex reaches out to me and Alex is like, Hey,
I would like to do a virtual dojo. And so I was like, Yeah, me and Matt have been talking about
this. So I included Alex in the conversation. We also include included Gray, who does the podcast
a podcast very different from our own and also uncultured swine. Thank you. And as well as the
only rationalist I knew in Lancaster, Pennsylvania for years, my one of my oldest friends, Errol,
who is a programmer with experience in nuclear submarines in the Navy. So as a group, we've
been trying to meet at least once or twice a week since the quarantine started online.
And we have been trying to figure out how to attack a lot of these problems in a coherent way.
Yeah. And some of the problems we noticed, just to give you kind of basic rundown of the problems
we're trying to solve. One, we mentioned the rationalists are pretty bad at coordination.
And also another thing, once you've done all the reading, once you've read HP more about the
sequences, you're left wondering, Well, what now? What do I do with this? And that's something that
the likes of CIFAR has tried to try to accomplish to varying success. There's also a big problem
where there's not a lot of interpersonal accountability and interpersonal development. So
CIFAR, for example, they have their workshops, which are a few days to a couple of weeks.
Then you go home and you go back to your life. And there's no reiterating all that. There's no
other person you can talk to in your in meat space saying, Hey, how are you doing? What did you do
last week that helped you with your growth as a rationalist? Or what about this project you've
been working on? They try to accomplish that. But it's from the people that I have known who
have gone to CIFAR. It doesn't really stick that much. There's not enough structure there.
Then there's also the question of there are rationalists who don't have people,
IRL, that they can speak to and have interpersonal accountability for. So there's this problem of
a scalable community, something you can have in your home or in your immediate community,
and also something that scales up to the nationwide community or the global community
of rationalists. You have various communities you can join, various discords, podcasts you
can listen to, you can go post unless wrong, but they're all disparate. They're not connected
in any coherent way. There's not consistency there. So that's another one of the problems.
Then David mentioned that we feel like rationality has helped us a lot. But all I can really do is
create a counterfactual model of my life and say, hey, yeah, this was pretty bad if I didn't have
rationality. And I can point to some big things like my finances are orders of magnitude better
since I discovered rationality, my epistemology is more coherent, my relationships are better,
but I can't really point to a single thing. It's mostly just raised the sanity waterline of my life.
And people often come back with either, well, you would have been that way anyway, because you're
just a naturally smart person, or they come back with any other self-help program would probably
have similar results. And that is a perfectly fair criticism. If rationality is just like any
other self-help, I want to know that. As a good rationalist, my question is, what do I think I
know? How do I think I know that? How can I test this? But we don't really have a good way to test
that, like actual scientifically. And there's also just the idea of motivation. Having other people
to hold you accountable is one thing, but also just having people to motivate you and provide
incentive structures for you. Like in martial arts, you have belt systems, and people reward you with
belts, and you get a whole test to yourself where everyone is watching you demonstrate your skills
and spar with others. And then they recognize your talent. And we don't really have that in the
rationality community. So those are some of the problems that we have noticed. And in order to
solve those problems, David, would you like to give us the quick and dirty on the actual
game? So we
want to create an online organization in space. And we want it to be a place where we teach and
help each other grow and learn and build a formal structure around it. The reason that
we wanted to make something as official as a guild, not a business, but a guild because
a guild implies apprenticeship, it implies growth through it. And that's what this community
really lacks. We're actually old enough as a community now where we have seniors and like
baby rationalists. That was not true five or eight years ago, like the community was still too young
at that point. But now we actually have people who not only have done the work, went through the
sequences and all of that, but have actually made criticisms, improvements. It's pretty incredible.
And the other thing is the art can never be focused on itself or it becomes recursive.
So we wanted to make rationality instrumental. And I want to, I've heard a really good phrase
about Christians evangelizing, preach the gospel every moment of every day. And if absolutely
necessary, use your words. And while I am not a Christian, I appreciate the idea of this that
if you are winning, if the thing you believe is real, you don't need to advertise, people will
come to you and say, what are you doing right? So in that vein, we have named our organization
the Guild of Servants, because we should use rationality to serve the world, to be bigger than
our own egos and bigger than the things that make us feel that we are special. We are special in the
sense that every individual has unique gifts. But until we work as a group and work together to make
ourselves better, we're always just going to be a second rate internet community instead of the
group of people who has the ability to change the world. I mean, we were correct about the
coronavirus as a community way before everyone else. And while not many of us made huge changes,
I think almost every rationalist I know was slightly better prepared for the coronavirus
than the entire population of this country and most of the government. And nobody listened to us.
We had no social clout. So when we started panicking for that first month, we were ignored
by our local friends and communities. What was nice was being able to have the
foresight to help the people I care about prep who don't read rationalist blogs. So I got to
tell my parents, be like, yeah, there's the 15 cases. This is probably definitely going to be huge.
You guys should be prepared for, and I didn't really anticipate because I didn't have a good,
god, what, seventh month model, eight month model of what this is supposed to look like?
15 year model. We're only in the first year of lockdown. We've got three more to go.
So please don't joke. But it was at least one small thing that, hey, I happen to be
in a social circle that informed me that this is probably going to be a pretty big deal.
I'm able to look at what they're saying makes sense to me. I'm going to act like this is a big
deal too. And thus I can, you know, I called my grandma, made sure she had everything that she
needed to hunker down for a bit. And she said the most badass thing. I might have said this in the
air or not before. I think next week she'll be turning 86 or 87. And she's like, oh yeah,
this reminds me of like when Polio was going around. But back then not everyone had a radio,
so not everyone really knew what was going on. And I'm like, that is the most gangster fucking
thing. That's the most like grandma way of saying, oh, I've seen some shit this thing.
Like now I've got TV and internet, I'll be fine. But you know, in her house without electricity as
a kid, you know, Polio was ravaging the nation. And not not everyone had a radio was really the
statement that like, oh, damn, okay, yeah, that that a super dates that statement. And also
really adds the like, the level of you'll be fineness that I'm getting from from what you're
saying. I mean, and think about that, like you were able to legitimately make the lives of the
people around you safer. I hope I was at least able to tell them stuff. Listen, maybe it was only 10
percent safer. But when things are this dangerous, that matters. Those add up. Those things really
do. And we were right. Like I was a little bit paranoid when I heard about the coronavirus
stuff. So I went out and I used a little bit more money than I thought and I got some extra canned
food. I was like, I can't hurt. And you know what, when the lockdown happened, my family did not need
to leave the house for the first two months, we had enough food that we just didn't even have to
leave the house. I don't know if that really made a huge difference, but it made our stress levels
go down. And yet we help our families. Why are there no rationalists consulting the government?
Maybe not this administration, but as a general theory, like why are there no
rationalist consulting groups working for the government? Why are there none helping big
corporations pivot as soon as they see this to start making masks and ventilators so they
can make the most profit? Like these are all things that could have happened and didn't.
Yeah, yeah. So you mentioned branding a moment ago, Stephen, and that is also another focus
that we have. So we don't call ourselves a rationality guild, as you may have noticed.
This is designed to be its own thing, but it is heavily inspired by the rationality community
with all the knowledge and power that we have as rationalists behind it. So every cause wants to
be a cult, happy death spirals. We created this with all of that in mind. Everyone should know
real quick that he's not saying every cause wants to be a cult as in we want to be a cult,
but that is a sequence. That is a sequence post. That is a warning. That is a warning that every
cause wants to be a cult. So you got to do certain failure modes of organizing. And we took all that
in mind and we balanced the scales of pros and cons. We decided that we would own our brand from
the very beginning. So that's a problem the rationality community has, is they don't own
their brand. People brand for us. They look at us as this weird online community. And because we
are so detached from our local communities, that they have more power over our brand than we do.
Which is hugely despairing. I mean, I was just talking while watching a conversation on the
internet with some people a few weeks ago. And at some point, one person has some asshole
use quotes from a Slate Star Codex post to make some jerk point or something.
And that's their only exposure. And it's part of me wants to be a dick right back at them being
like, Hey, you know, if the first time you get mugged, it's a black person doesn't mean all black
people are bad. But that's not really hitting the nail on the head. It's like, it does make a
general thing about like, let's not generalize across an entire group of people based on one
interaction. But this is a bit on the side from that part of the branding issue. But I was having
this conversation then one on one with somebody. And they're not in the community. And they were
trying to explain to me like how from the outside this looks bad. And like, and so I gave them kind
of my explanation, my, my prior thought on like, well, look, you know, if one person miswields
the tools or misunderstands an argument and uses it poorly to despair to disparage somebody else,
that a, there's not much we can do to stop that other than having a solid brand that we're behind
and then saying like, look, they're clearly not in this club. But, you know, if somebody, again,
find some, some, you know, Robin Hansen is, is, is, I think, delightfully thought provoking with
basically everything he writes. And if you write something that can come off to large audiences,
is like very offensive, because they're not one of the things you mentioned about like being able
to relax on rationalists is that we are capable of the many thousands of year old revered tradition
of being able to entertain an idea without believing it. What are you talking about? What
nonsense is this? We can take absurd hypotheticals, talk about them coherently, and to the point where
it's like, yep, it's perfect sense. And then just go on about our day without, you know,
implementing eugenics or something. Right. So like, it's, it's something that I find valuable
being able to consider ideas that I don't necessarily want to promulgate. But they,
they went off and they found like the top post from the month on r slash the mat, which is the
Sains late star codex subreddit. And it was the culture worth read. And the top comment was on
like disparities in IQs with cross races or something. And they're like, so from the outside,
if I'm curious about what the rationality thing is, like Google places to look at it,
I don't know why you would find the mot first. But right. But if you did, the thing that they
wanted to talk about the most that month was IQ differences across races. And I'm like, I don't
really know how to address that. Like if you read the comments, people are saying, why the
fuck do we care about this? And, you know, other other saying things that almost everyone can get
on board with. But it, I mean, I just think that the proper response to that is, this is not a
rational conversation to have, because there's like, literally decades of research data that
shows that while there are differences between cultures, race is like the least important way
to measure it. And so therefore, it's a waste of our time, like we shouldn't prioritize that
conversation, not that it's bad to have it, or that we should be incapable of considering it.
But like, it is just kind of silly. But then they would say, well, then why was this such a
commonly talked about? Why would why was this the most upvoted talked about thing on the thread?
Oh, I agree with this person, someone should have stepped into the thread and said, this is a waste
of our time. Yeah, that's what I believe the moderators messed up. Because, like, unless there
was new research, if there was a new paper that came out that significantly shifted previous
assessments, then I would be more reasonable. But otherwise, I agree with this person, if I
that was my first exposure to the community, I would be pretty unwell with that, especially
as an Arab American, like it would be pretty frightening. Yeah, so I think not too long ago,
some Vox journalist resurrected the whole Sam Harris is evil, because he interviewed the guy
that wrote the bell curve. And so that was a trending topic for a while. Actually, delightfully
enough, I was just going to bring that up because she one of the authors that that post was on his
podcast, the most recent episode, which at the time of this recording is episode 212, Catherine
Paige Hardin. And it was actually a really, really good episode. They they they talked about
really, and she's also in the field of like genetic research, and how genetics, you know,
not genetic determinism in so many words, but like longitudinal twin studies and stuff, the
stuff I take part in, but don't do. And oh, yeah, you're a twin. I'm a twin, yeah. Are you forgetting
that? Which is like my my lame fallback for like, I am helping the body of science going forward
by always answering the summons from the from the University or the Colorado,
what, Colorado University, or whatever, CU, Boulder's Department of Behavioral Genetics,
and going there and do stuff every few years when they call. In any case,
they had a very fruitful conversation on that. And it does come down to like,
this is this is something that we don't know a lot about. And at the end of the day,
it doesn't seem all that valuable to know. And if differences, this is just the IQ thing,
I don't want to get too bogged down in that. Because any individual person you meet can be
anywhere. Right. And well, I mean, the thing is, is like some groups of people are taller than
other groups of people. Right. And like, and I don't again, I don't want to get too bogged down
in this, but he makes the point that like, if we take a list of the top 50 things that we all
care about, and that we all want more for ourselves or something, it's a good bet that one of the
that many of those will have some basis near genetics, right? Whether it could just be longevity,
you know, some families come from, you know, lineages, people that all die in their 60s,
and others have ones that push to their 90s for, you know, going back three or four generations.
And so like, that's a genetic thing. It doesn't have to be single anti CRISPR person is going to
immediately turn around as soon as they find the way to CRISPR bigger penis genes.
Um, so I guess what, what I, what all this comes down to is if I was talking with this person,
and, uh, I could we talk to you guys and say, Hey, look, this person's asking me, why is the
Mott, what is a typically good bastion of sanity, spending so much time talking about something
so stupid and like, it's hard to not think of a facetious more off putting example of something
to discuss. If you're just poking your head into the room, and you overhear, uh, IQ school,
and you're like, Oh, okay, well, I'm going to close that door. They're fairly insane in there.
What do we do about that? So I think you kind of hit the nail on the head. We need to have a brand.
So when someone crosses that line, we can say, listen, that guy is not associated with us.
Our organization will have certain principles, courage, curiosity, honesty, and I believe there's
there's a big focus on knowing how we're perceived by others in the world. That is the,
that is one of the biggest motivations to make a separate organization because we want to be able
to get ahead of that conversation. And there are certain conversations that are great to have
and fun to have as rationalists. We like to entertain ideas. But at the end of the day,
there are, if we want to raise the sanity waterline of the world, we have to recognize where that
waterline currently is and how our community is going to have effect on that. What ripples are
going to be made, how we go about raising that waterline and talking about IQ stuff probably
isn't something you'll ever see us doing as a, as a, as a organization. I have two, well, one thing
and one question, I guess. The first thing is that rationalism is always going to have a problem
because there is a large movement that's been under foot for decades to basically roll back
the whole enlightenment. It's very postmodern, very, you know, everything is subjective and
has a huge amount of allies right now in academia. Well, some places in academia,
but it's, it's the very much, God, there's a great article on it that I'll post soon,
but it's very much a thing of everything is relative. Cultural relativism is a huge thing,
and rationality is directly opposed to that. Even worse, epistemological relativity.
Yeah, they're, they're like rationality and logic and dispassion are things that they have
identified as enemies and they attack frequently. Then you beat them. Right, right. No, I'm saying
right now, they are a large and strong group and we are not. So it's going to be a long uphill fight.
And so I understand why you want to like not include the word rationality and distance yourself
from that, because obviously, if you're starting out as a new organization, you don't want someone
that big to fight with off the start. But are you, are you not worried that by pulling from
the rationalist ranks and being kind of rationalism adjacent, you're going to be,
get the guilt by association thing that they like to do? So there is one way I know to defeat that,
which is building a reputation that is so strong that no one can attack it. And the reason we don't
have that reputation is because we are an insular community. One of the big parts about this
organization we want to start is we're going to be outward facing in the sense that
we're going to encourage people every time they do a series of classes with us to do a project
that affects their real physical community. My end goal is something like an Elk's Lodge
in every city, a group that everyone knows is a little bit weird, maybe a little mysterious,
but they have a reputation of being there for the community. They do volunteer work,
they go help. The very first one we're going to do is we're going to encourage everyone
to do as much good as they can within like a hundred miles of themselves
for the coronavirus. And obviously, if you're isolated and you need to do stuff online,
we're not unreasonable, we will accommodate. But if someone's going to make accusations like,
oh, you guys are a terrible group, you don't like, you're so selfish with your rationality,
we can be like, you can say that, but we just raised a hundred thousand dollars for children
who have the coronavirus. What did you do? That's the way you defeat that with actions that are
incontrovertibly good and saying that is what we dedicate ourselves to. And if you have a problem
with us after we've done that, your issue, you're the crazy bigot, not us. I like that answer so
much better than mine, which was like, I'm never going to convince those people. No, but I think
it's true, you're not going to convince those people. There are people that think effective
altruists are evil because they're, you know, concentrating on hearing malaria in Africa instead
of fighting classism here in America. Or extremely rare puppy disorder. Yeah, no, I've
literally heard people say effective altruists are a bunch of, you know, unemotional spurts
because they're focusing across the world when we need the money here in America to help people
with whatever. Well, and it's like, I mean, not to sound defeatist immediately, but like,
with that one, well, that's that sort of it. It's like, at that point, it's like, well, we just
have different values, like I value human life across the globe. And even to some extent into
the future, more apparently than you do, you know, the average homeless person in America
has it so much better than the bottom billion, where, you know, they have access to clean water,
they have access to typically enough food to not die, occasionally shelter, and like, and
emergency medical treatment. I think, I think like, don't get wrong, this is a problem. We
shouldn't have homeless people in America. This is a wealthy country. It's insane. But as far as
like, what can I do as a person with a budget of $10,000? Well, I can, with $10,000, I could
probably turn two lives around, right? Maybe get them an apartment, get, you know, try and get things
going. And if I'm looking for homeless people in the US, if I was able to send, you know,
anti diuretic capital capsules to Africa at the cost of eight cents each. And even at the cost of
distributing those and all the logistics involved, you know, people in the world die of diarrhea.
Do you guys know that? Like, that's what I'd say to these people. And like, that's insane, right?
This, this is a problem. I think those people have a point. I think they have at least one
real point, which is by not caring about what the local community sees around you,
of what your actions are, you are not advertising rationality or effective altruism. If your money
is going to someplace in Africa, you are helping those people's lives. There's no bad in that.
But you're not going to your actions aren't going to show up in your local community,
you're not going to attract more effective altruists doing that or more rationalists to
raise the San Diego waterline. You're going to make yourself feel better, and you'll make the
world a measurably better place. But I think there is a tradeoff, and it's painful to say,
but I think there is a tradeoff in efficiency of good versus converting more people.
Like, and I'm okay with that. I don't want to say that I don't want to be like this negative Nancy,
you will never fix everything. Everything is terrible, because I don't believe that I just
want to point out that some people will always hate you no matter what, like as, as Jesus said,
that they will hate you because you're good, or as the modern day Jesus said, they hate us for our
freedoms. They hate us because they ain't us. There will always, there will always be those
haters. So we'll never be all the way there. We got to be okay with some people. But I think
you're right that it's the advertising to your local community is super important,
especially since people in Africa can't help us. And people here in our local community can
sometimes destroy us. And that's bad, I'd rather not be destroyed. Sometimes you have to be less
effective with some of your money in order to build up allies and defenses in your local
community, which is where you can be killed. And the concern about branding isn't just to convince
the people that would always hate you anyways, it's to reduce the power they have over you
in the local community. There's a lot of people out there who are somewhat on the fence to varying
degrees. And if the the your enemies have more power over your branding than you do,
they will be the ones that convince the people on the fence, not you. So the goal is to shift the
power dynamics to have power over your branding. So when people do attack you, the ones that may
never be convinced, they won't have as much effect on the people around you and local community.
And it'll make them look stupid when they're like, you're attacking these people who have
done wonderful things to our community. Why are you doing that? Like they're the asshole.
What I imagine would be a beautiful example in the future is imagine if we have classes and
next Earth Day, we say, do as much as you can to clean your local environment, send us pictures,
measure it like trash, reduce trees planted, whatever you want. And then, you know, every
little city and like town in America that has a few rationalists sees these weirdos going out and
cleaning up litter, planting trees, planting flowers. I guarantee you, at least a few people
will be like, Oh, what are you doing? Why are you doing this? And we're going to gamify it as well.
So one of the nice things about this organization is we've been talking to Matt and he's actually
working on some software to accelerate learning that might be a concurrent and part of the process.
And we actually have a few of our classes already designed and ready to go so that when this
organization starts, you can immediately gain value out of it.
Yeah. And of course, all of this is still in the testing phase. We're going to have a three month
period where it's we're not like collecting guild dues or anything like that. It's just all everyone
we're going to have a select few people invited to see test out the material, give us feedback.
And the after this three month period, we're going to regroup, do a postmortem, get critique,
and then decide if there's any restructuring that needs to happen. So everything so far is
subject to revision as anything in rationality is always subject to revision if based on new evidence.
One thing I like too about the approach of trying to, again, not convince the anti epistemology
folks, but like whatever you're on a forum and there's some discussion going on. It's just like
Socrates and just like every other, you know, rational rationalization that we gave ourselves
from many of us did when we were going through our religious deconversion and arguing with people
online. I'm not doing it to convince the person I'm arguing with, I'm doing it to help give the
audience information. And so, you know, if all they're hearing is the vehement one side and all
they and all they see is the insane shit they bring to the table, they're like, Oh, okay. Yeah,
this is clearly not for me. You can come back and, you know, with something helpful. You know,
what I've been using sort of as a like, as a common template is the positive things that the
rationality movement has done so far, things like popularizing effective altruism,
things like the Future for Humanity Institute, cryonics. There are like tangible organizations
and movements for a better society that I've already sprung up. And so, you know, I then again,
the most vehement detractors never ask like what good has your community done? They don't think
that's a possible consideration, right? So again, this isn't really, in my mind, still much for
them. It is for the audience, right? My goal is to create a reputation and an organization so solid
because you're right, there will always be haters. I want to be, we want to use every bit of our
rationality, every bit of wisdom, every bit of self help and cultural knowledge we can,
so that when those haters come, they have no legs to stand on. That's the goal, not that they will
like us. But I'm going to force them to show everyone in the argument that they are frivolous
and that they have nothing to stand on there. That's the only real way. And if you do that often
enough, the haters will shrink, they'll never go away. But I think the percentages can drop quite
a bit. It's really, really hard to hate the group that's giving kids masks to prevent them from dying.
Like it's not impossible, but it's pretty hard. Do you want to talk about it?
Have like a sort of Elk's Lodge slash Dojo slash church thing on a corner with a big billboard that
says, you know, 1000 trees planted this month, the Guild of Servants, please enter and be willing
to serve to make the world a better place. And then yeah, like whatever we did in the last month
to make the world's like good, raised money for charity or whatnot.
Once the vaccines are available, you know, 10,000 vaccines given out to the needy.
Yeah, yeah, stuff like that. And the people inside of this Guild are helping each other.
They have groups that support each other to learn how to do more effective community service.
And also they know how to communicate things like epistemology to the people around them.
They know how not to make social faux pas that cause problems with reputation.
They know how to how to brand themselves so they don't don't seem as weird.
So that actually leads into some of the classes we're going to be offering for the first three
months. Do you want to start with the character sheet? Yeah, yeah. Hold on real quick. Is there
since I don't really know anything about this yet. Is this actually a creative organization?
Is there a website? Is there some sort of? So we are working on that. We don't want to put too
much effort into things for the alpha test because we don't know what's going to change.
So this is still in the testing phase? Still in the testing phase. We'll be doing this for
three months. And just to kind of give you a recap of what this physically looks like,
it's going to be an online organization primarily. So it's geographically neutral for people who
don't have a physical community. But it is designed to be a place for the community,
for the rationality community to actually gather around. We want to be able to teach each other
how to be more effective humans and rationalists. We're going to have weekly courses where
there's a class of some kind on how to make the world a better place, how to have better
epistemology, so on and so forth. The idea is to provide social support and motivation to each
individual. So you're going to have a cell, a group that of usually three to five other people
approximately. That's your group. You are the ones that go to classes. You can earn points
as a group, which these points can be used very similarly to Hogwarts House points.
Coral points is honestly a better description. Because House points don't do anything.
Yes, we actually do useful things. The points are actually going to have real world effects,
but more on that in a moment. So you're going to have this group of people preferably in real life,
but if you don't have people in your local community that are rationalists, you have a small
group of people that you can talk to and get support from. So it's also going to be a way for
us to signal boost our accomplishments in the local community, at the same time be a testing
ground to see if we can actually perform great accomplishments as rationalists. Because if we
can't actually do anything with rationality, then this whole venture is not as important as it might
be. So also, again, this is part of reclaiming our identity and brand as people who think clearly
and know how to impact the world around us. And that's the general gist of the organization.
So as far as weekly, the actual classes themselves are concerned. We have three modules, which will
be broken up into multiple classes a piece. The first module will be something that I dub
the character sheet. It came out of my local dojo, and I have tweaked it so much. But it's
basically introspection tool inspired by CIFAR's bug list, where you compile a list of all the
problems in your life. The version that I created allows you to also prioritize those
and provides various helpful tools for finding those bugs. Along with David, we have modified
that to be a much more thorough introspection to see where you're emotionally
failing in life and how to spin that into a positive thing, something to aspire to. Therefore,
it's not called a bug list. It is called a character sheet. It is a list of all the features
that you are trying to attain in your life. Very similar. It's inspired by RPG character sheets.
I won't spoil the details. You'll have to take the class to find out, but
it is quite delightful, and has helped me a lot. Probably the best tool I have used as a
rationalist since we've joined the community. Since that sounds so appealing, I'm desperate
to get my hands on it. Is it available? It will be available. We'll be giving some
information about the alpha testing here shortly. Okay, good. I didn't want to raise my hand and
politely demand that I be included, but I desperately wanted to be.
So that is going to be our first module. The second module is one that Gray and I have been talking
about, inspired by Sheldini and a conversation I had during the winter solstice in New York City,
which is a lot of rationalists become vulnerable to the dark arts because we hate a lot of
manipulation and sales tactics so much we never even bother to learn them, and that leaves us naive.
It does. I've seen a lot of rationalists who are way smarter than me fall for tricks that,
in my brother's words, makes them look like a jabroni. These are naive failures that I'm
kind of shocked by. So we're going to create a module called Defense Against Dark Arts,
where people will have this pump. I've done sales for 10 years and Gray, with his own background,
I won't speak for him, but has had his own experiences dealing with these things.
And between the two of us, we've come up with a series of classes to help you notice when someone
is engaging in behaviors that are red flags that you need to watch out for and how to defend yourself
socially and emotionally from people like that in those situations.
I remember Robert Sheldini's book is one of my favorite go-tos for recommending people
and even just buying them copies because they're ridiculously cheap. There was an anecdote that
Julia Galev gave many years ago on the Rationally Speaking podcast about how, at a mall or something,
someone had one of those expensive hair straighteners and I was like, oh, let me demo
this for you. It's great. And then, sure, why not? And then at the end, it's like, okay, well,
they're like, I forget how much, 150 bucks or something. And she's like, oh, no, thanks. Well,
I just did this for you. It's like, yep, I don't owe you anything. You volunteer to do this. And
that's an awkward thing to say, but that is the appropriate response to a technique like this
being wielded against you. And then a few months later, I bumped into somebody who went to one of
these mall, got roped into one of these mall kiosk stands and came home with an expensive
hair straightener. And I'm like, if only you had read Siltini's book, you would know that
you're not being an asshole by saying, no, thanks, I'm not taking, I'm not going to give you money
in exchange for the service that you provided up front that wasn't supposed to be part of this.
That you volunteered. Right. Yeah. So there's that one. And then there's the fashion module. So
I have a module, the last module we will have in the alpha phase is I've worked
in clothing stores for years. I really like fashion. And I think many rationalists don't
take it seriously. They don't take it seriously, because if they think it's an inconvenience and
a clothing is just there to prevent them from being arrested or cold. And that is this picture
and I don't like it. I don't like this idea, because in my opinion, fashion is communication.
My opinion is that you have layers of communication in person. And the first one is fashion,
then it's body language, then it's voice tone, and then it's the words you say as people get
closer to you, physically, that that's the layers they interact with. We are really good as a
community at knowing the right words. In fact, this community is unusually good at being
linguistically talented. But I think every other layer needs improvement. And so my contribution
is thinking about how to develop your personal brand. Not I like to dress a little bit outrageously
and gather attention, but that's me. That's my own personal brand. And it helps create an identity
for me that is useful and practical in a lot of rationalist ways. Like, when I show up,
people know what I am about from 50 feet away when they see me in a rose suit.
Like, I clearly describe who I am, and it's a filtering mechanism. I don't have to talk to
the people who don't want to deal with that. And you're right, the body language also is a thing,
like seeing you the way you walked up to the group in that rose suit, like also communicated,
hey, this is a, this is what you're going to get time to swagger. But um, yeah, so I'm going to be
creating a fashion module where at very minimum, we will get rid of the worst fashion habits that
you have. And oftentimes that's enough to make a big improvement. And just learning how to shop
for a t-shirt made a huge difference in my life. Yeah, knowing about fit, like knowing how much
of a difference fit makes, and how you can wear a $5 white t-shirt from Kmart. And if it fits you
well, oh, Kmart might be out of business. This is a silly reference. But if it fits you well,
it's going to look like a million bucks. But if you spent $200 on like a nice fitted button
down shirt, and it's baggy on you, you're going to look like you're wearing your dad's clothing.
And I am very lucky that I have at least a few female friends who are going to be helping consult.
So this will be a all genders, or gender neutral class as well. And I will offer a little teaser,
which is we are working on, I'm working on another module, I've talked about this on the discord
about building social networks and making them what making wide and deep social networks in any
city you're in in about six months. So if you're interested in such a class, you should support
the guild for the first three months, it seems like it would be on your it would be in your interest.
Well, what's fun is that, like on the meta level,
but then I want to a specific point here is I'll try and make both one,
high up, you guys are doing the awesome thing of looking at something that exists that you
that you see room for improvement for and asking how can we do better, which is fucking tight,
just got to call that out. At the the lower level thing of the fashion thing, that's that's been
coming around to me in like the last years. So like, my wife, in addition to being just like
gorgeous is also has this ability to buy herself things that like we can't leave the house that
are getting complimented, which is awesome. And then there's me in my three year old Costco jeans
with holes in them, and my target shirt, shit also with holes in it. Like I have some nice clothes.
And I like it's, you know, on the most part, like I yeah, but let me finish my thought, which
I guess on couple notes one, we're barely leaving the house now, so it doesn't matter.
But the other thing is like, it's partly like, on the one hand, I like dressing in a way that,
you know, like nice guy from worm, your eyes totally pass over me when you look at me in a
crowd. And so like, I'm on the train to work, I don't want people to like stop and notice,
part of me would like that maybe, but the other part of me just likes to be completely ignored.
But also I could optimize for that strategy too, I guess, right?
Yeah, to dress in such a way that you are noticed when you want to be.
Yeah. And, you know, the other thing, but I do love dressing nicely, you know, you're wearing
a button down shirt, David, and you look great in it. And I liked to wear my target shirt because
it was the one at the front of the line in the rack in my closet this morning. And actually,
last night when I threw on the floor, so I got a good dressed in the dark.
But I like dressing up a lot. It sounds like a silly thing to mention, but it's not.
When I dress nice, I feel nice, you know? It's a way of like, you know, why do I shower?
Like, it's not just because I smell if I don't, it's so I feel like as good as I want to look,
right? Yeah. So, Stephen, I was lucky enough to stay with you last time I was in Denver,
and I met Rachel. And so, I've been on her Facebook and I agree, she has a great look.
Now, here's the question I want to ask you. Do you think Rachel could make a look if I gave
her $20 and put her in a thrift store and she would come out with a look that you would say,
yes, that is her style? I am ill-equipped to answer that question, but not unusually ill-equipped.
Her parents don't buy her clothes. Like, her fashion sense is impenetrable to all of us
in such that, like, you know, what I'm getting at is maybe, I don't know.
So, my opinion is this, we confuse expensive clothing and nice clothing for fashion.
Oh, her fashion isn't all that expensive. Exactly. She has an aesthetic. And once she
knows what her aesthetic is, she's able to cultivate it. And the truth is, this is a very
natural process. Developing an aesthetic is something artists do, fashion designers, it's a
thing you can learn and teach other people. But it is work. It is not a natural thing. Humans
don't come built in with an aesthetic normally. We come in with a way to protect our nethers from
the cold and bugs. And police. Yeah. And now, yeah, just wearing enough clothes to not have
people throw garbage at us and call the cops. Yeah. So, what this class will be aimed at doing
is helping people develop that aesthetic for themselves. Because my opinion is fashion is
so horrible, we have to get rid of it every six months. Style is forever. I think that's a Mark
Twain quote. But we, that's what I would like with that module. And I think that if you look at the
modules we have as the first three, what you're seeing is kind of the thrust of where we're going.
We also have plans with Matt about doing a possible class on practical Bayesian analysis
in the field where you would mix like math that you did with poker practices so you can do odds
live. Yeah. Being able to do calculations in real time, even just knowing how to perform a
back of a napkin Bayesian analysis analysis of a situation is super helpful. And not many people
know how to do that. That sounds really valuable too. I mean, there's something to be said for
just having the intuition of it. And that can be helpful. You know, like if I take my car in and
it's making a clunky noise, I'm not going to check the windshield liper fluid, right? Like,
that's not the problem. Probably wouldn't bother checking the battery first, right? You come in,
it's just, it's a differential diagnosis, right? And so that in itself is sort of a
Bayesian exercise. But yeah, being able to do the math for it would be would be helpful to
just say, am I, I mean, Jesus, at my job, half of it is just like, all right, what the fuck is
wrong with this thing? And being able to do some quick odds and being able to be able to concentrate
my uncertainty, so I don't spend my first half day investigating this problem, looking at the wrong
thing reliably, I can reliably find the right thing to look at the first time half the time,
that'd be awesome, right? Yeah. So these classes are basically each of us as rationalists who are
passionate about how the community looks to the outside, and the potential for the rationality
community to raise the sanity waterline. These are things we think are some of the highest order
of magnitude changes that rationalists can could make in their lives towards towards these ends.
So given all that, do you guys have any questions for us? I have one.
I'm trying to couch this so it doesn't sound like a criticism. No.
So I'd like, I'd like and I hate the name, community of servants, oh, guild of servants.
So first of all, I'd like the fact that it seems to be very outward facing, it is there for the
other people to look at us and be like, oh, they're servants, they're here to help the community,
this is great. And that's exactly what we want. On the other hand, like, as soon as I heard that,
if someone were to ask me, do you want to join a guild of servants, I'd be like, fuck you, I'm not
anyone's servant. I live my own life. And, and I really want to be a part of this. And you really
pick the name. And I think, honestly, I think objectively, it's probably a good name. But like,
what do you say to people like me who have been spending their lives trying to get past the
feeling that we, well, you know, as someone who came from, from a Christian cult that our lives
are to be used for other people, and we're trying to get over that, seek freedom and become slave
to your desires, seek discipline and you shall find your liberty by refusing to be a servant to
anything. You are just like, what is that one of the 12 virtues is if you allow yourself to be carried
by your, what you want, you will be enslaved to your whims. You're not a servant to the world,
you're a servant to truth. And if you can't become a servant to truth, you have no right to call
yourself a rationalist. We serve the truth first, we serve the world second, and we serve ourselves
third. Okay, that's pretty fucking awesome. I like that we serve the truth thing. Yeah.
This is why David's going to be head of marketing. Hell yeah, I am our HR person.
And I have found that having a, a, a life without the times I'm happiest in life tends to be when
I'm doing things with and for other people, when like, Oh God, the Corona months have been awful.
But like, I'm just alone and doing things for myself and not seeing other people. And it's
miserable. You have no sense of meaning in life anymore. Right. Yeah. And yeah, when, when finding
something bigger than yourself is such an important thing. It's, it's why we have religion. It's why
we have all these various philosophies that people served to their dying breath, because there's
this overwhelming need to do something that's bigger than yourself. And that one of the most
important things that's bigger than ourselves is the continuation of the human species, the well
being of the human species, the advancement of the enlightenment, and all those things, their
servant can mean a variety of things. And one of those definitions is seeking it all your days,
pursuing it, and making it a priority in your life.
I'd want about like these sort of community facing activities that will, that you can point to and
say, look at this good we did. I do like, I mean, any palpable thing where someone can walk down
the street and notice what you did, you know, picking up garbage is an obvious thing. I don't
know what it's like in Kansas City or nowhere in Pennsylvania. But like there, I can't walk
to say for that passing garbage on the street and it drives me nuts. And so it'd be cool, you know,
to have that cleaned up. But any, any group of humdrum motivated people can clean up garbage.
What makes us cool? What makes the stuff we're doing cool? What should we be doing that like,
oh man, I should get in with them. So here's the way I think it's, the way we have it structured,
is these are competitions between cells. And so you are encouraged to use every
rationalist trick you have. And remember, cheating is just what losers call technique
to win. If you're, if your goal is to dump all my trash, you can spend your points to
sabotage other teams. In harmless ways. Trash on my lawn, though, that means I have
extra bags of trash to get points with. I don't even have to go very far. Look at all this trash
I cleaned up. What I would like is if this is a problem, if you see trash in Denver, yeah, any
group of humdrum people could do some cleaning and they probably would earn some goodwill.
Like they'd probably get a few people interested. I would love it if maybe the group of Denver
rationalists talked with the city council, worked in a 3D printing shop and then designed
rumbas that clipped to the sides of the curb and cleaned the streets forever. And then the
problem is solved forever. That's what I think rationalists can do. The first person comes around
and kicks the rumba for shits of giggles. Then you should design your rumbas to be a modular
and you're not very rational if you're not planning for kicks. Or to have it violently
explode when kicks. One of the things we would be measuring is the long-term impact you have on
your community and how the community responded to the things that you did. So part of that is
not just for using this particular example of cleaning up trash. What did you do to prevent
trash from happening again in the future? What systemic problems did you work towards fixing
and in order to be more effective at what you're doing? That actually makes this hard.
When I try to answer that question, I like immediately draw a blank, which means I have
to work at it, which is awesome. Which means you have to go and problem solve. You have to go
you have to go figure out what is causing this in the first place.
And maybe you and your cell will have a brainstorming session and then you guys might
pre-mortem a bunch of the ideas and you use the rationalist techniques you've heard and then you
think about the classes you have and you think, okay, we did the module for defense against
dark arts and we've noticed that this person in the city council is a real problem. How can we
work around them? Instead of bashing our heads against the wall or getting frustrated and saying,
humans are just so frustrating, blah, blah, blah, blah, blah. No, we're going to use our modules
to work around that and accomplish things. We're going to look good while doing it so
they can't just brush us off as just another group of humdrum lay people. And right now too,
I think that is largely, if not the default response, a default response for a lot of people,
which is, and people just suck, we're never going to be able to do anything about that.
And like, that's basically quitter talk. Like, we live on a planet with people.
And then until you guys have your own planet and you get to move, you know, and it's,
then it's, you know, whatever, rationalists, which are better than people. I say in quotes,
like, this is the world we have. And so you don't get just to throw your hands up and say, well,
people suck. And therefore, it's not worth doing stuff, which I think is a common attitude.
Adaptation executors and the system of incentives determines what adaptations they
execute. So if we can change the system of incentives, make things better.
I was an evangelical Christian. And I just by reading some material from the rationalist community,
I did a complete 180 in my quality of life, my relationships, my epistemology. Imagine having
a cell of people, a group that holds me personally accountable and teaches me and helps me and guides
me and shows me how to live a more rational life. That's perhaps massive effects. I can't even,
I can't even conceive of what, of how good that could be for some people. So if, if anyone was
a hopeless case, that was me. And it required very little from the rationalist community to,
to turn me around. It required it merely existing and you finding it. Yeah. Yeah. Imagine what's
something like an active rationalist community that knows how to brand themselves and how to
teach others in a empathetic and effective way. I also find it, in my opinion, the thing that
really crushes me the most is I think the people who would most benefit from rationality are the
people who are least likely to find it when they need it. Like, I think we can all, I think everyone
who's listening to this podcast and everyone in this room can think of at least one person in their
life who is smart, who is capable, who could understand this and whose life could be improved
by these things. But because they were either in the wrong social circle, or just quite honestly,
their interests weren't the same as ours. They never ran into it when it would have mattered,
when it could have made a real impact on them. I am not, I honestly don't think I would have
found this community if it wasn't for my friend Errol reading HPMOR and then recommending it to
me, because none of my interests aligned. Like, I would have been in any other situation exactly
the kind of dark arts master that everyone hates. I would have been some kind of lawyer
politician salesman. It would have been evil. So this community, by dumb luck, saved me from a
very terrible path. And I'm just wondering how many other people out there, because we don't
advertise well, because we're not out there, who were on that borderline are falling the wrong way.
Like, I want to make rationality so popular and simplified that you can start teaching it to,
like, middle schoolers, and that everyone can just start absorbing it into their life. You're
not going to raise the sanity waterline by making geniuses smarter. You're going to raise the sanity
waterline by finding the people in your community who are at the lowest, and then lifting them up,
even if it's just one little step. I would caveat with, you'd said they could have found
rationality when it would have made a difference. You know, barring deathbed exceptions. I feel like
it's almost never too late to get better, right? I believe in theory that is true, but I think that
there are some people for whom making that transition after they've invested so much in their current
identity would break them. Like, it's the reason people don't leave the Westboro Baptist Church,
because for every person who does, they always tell like, Oh, is the worst thing that ever happened
to me, it destroyed my entire worldview and social life for years until I was like able to form other
connections. The deeper your roots are, the worse it sucks when you uproot them all. Yeah.
Okay. Yeah. I guess I was thinking of somebody whose life could could use some
on track finding, not that they're entrenched in the wrong cult or something yet. That's,
that's a different problem. But even then too, we still watch the right cult. We are a secret
society. Thank you. Colts are desperate. Secret societies are selective. And in fact,
that is an important facet. One, one still wants to be able to just listening to this podcast can't
join up. You got to be invited. One still wants to be able to, you know, encourage. We want the
number of people leaving the Westboro Baptist Church to go up, right? And especially if it went
up, I don't know, they're not, they're not that big of a group anymore. It's like 30 people. Yeah,
I think at the peak, it was like 80 or something. But, you know, if fuck it, five of them, if five
of them left next week, they have a social circle already, right? They got all five, they got all
of each other. But then what do they talk about? They're shared pain. The only experience they
have in common, which is the thing they're trying to leave behind. And the ones that they're doing
going forward, I'm just saying like, at the very least, if, if more people were leaving these
bad toxic groups, you know, like there was that guy, I forget his name, I think Christian might
have been his first name, reformed neo Nazi. And instead of just like being a reformed neo Nazi by
himself and having better himself, he heads up groups of people helping to get people out of
this, you know, doing Nazi tattoo removal and stuff like that, deep, like deep programming and
depropagandizing people. Yeah. And like, that's awesome. And so, you know, it, I guess what I'm
getting at is that I don't want to be, it's weird that I'm defeatist and other notes, not on this
one, that it's never too late to get better, right? Which I don't think is a statement that
you're challenging so much. It's just that it might be harder and then you might, you might bear
less fruit. As an Asian, the probabilities that you will change are never zero, but they do get
pretty damn low. You know, if you're 75, and you're leaving a cult that has been life consuming,
you know, you're, I don't know, still part of me wants to focus on the remaining years that you
have that are now better, right? Of course, if they're all going to be terribly worse because
you're now shunned, I guess I see what you're saying. But yeah, I'm still advocating for the
fact that I think the pool of people that won't be helped by raising their sanity a bit is extremely
small. I'm willing to agree with that. Yeah. So yeah, I don't think we disagree that much.
Sometimes you just have to leave like Darth Vader, it was this last few minutes of life,
and yet he still had to leave his cult and be like, no, they've gone too far.
Not that people who aren't rationalists are Darth Vader, but they kind of are.
And I know we will teach you to defend yourself from them.
And as we know, it's safe to generalize from fictional evidence. Yes.
But as I caveat in the last episode, this isn't fictional evidence. This is, you know,
generalizing a lesson. It's not saying next time you're confronted by Emperor Palpatine,
this is what will happen. So yeah, on as a general invitation, it is an application
process. That way we have the ability to invite everyone we want while still also maintaining
a end goal of a small enough group of people that we can still manage and grade and such.
So it's going to take place on Wednesdays at 7.30 p.m. Central Standard Time.
The location will be on the internet for now. How long is the meeting?
Two hours approximately. Maybe, yeah, depending on the on the on the exact class.
First half will usually be a lecture. Section half will be you working with your cell to discuss
either the previous assignment or the next assignment. So in order to apply, in order,
if you really want to get in on this and see what it's like and provide feedback and critique,
you want to send an email to guildofservants at gmail.com with your name and a short response
explaining your hopes for the course, introducing who you are and how you receive this invitation.
1,000 characters or less. We know you rationalists. We know how much you write.
Characters or words.
Characters. Characters, okay. Yeah. Poetry, man. Get real good at saying things real fast.
That's going to be like one to two paragraphs. Perfect.
We don't have that much time. Yeah. So yeah, when when when you send that email,
you will, if you are accepted, you will receive a formal invitation with all the details.
And then you'll begin joining the three month alpha test of the guild of servants.
And you can start sending those in the day this podcast comes out. And two weeks after that,
uh, we will have reviewed and the people who have been invited will have received responses
and the classes will start. And so all they need to send is their name and what they hope to get
out of the community, not the other courses, the course. Yeah. Okay. Cool. Awesome. I'm drafting
my my paragraphs in my head right now. So in the future, it's going to, I'm guessing going to be
mainly a zoom thing, at least until the corona thing wears off. Very likely. Yeah. And
how many people are you hoping or expecting planning on having this initial wave?
We are going to not accept any more than 30 people. We cannot handle more than 30 people
and give the quality of experience that we want. And I'm assuming that it's going,
is it going to be one big zoom of 30 people or they're going to be like multiple branches?
It would be a, it would be one, one big group where you listen to the lecture for the, for the
lecture portion. And then you would do something akin to zoom breakout sessions where you discuss
the content with your cellmate, the instructor, cellmate. And the instructor can go, go between
the rooms answering questions, giving advice, that kind of thing. I know that, um, rebellions and,
and other revolutionary activities were generally broken up into cells too. What did they call
each other? Cause we could use, borrow a term from that rather than cellmate. Yes. Selly was the
colloquialism I heard from people sharing rooms in prison, but we probably want to use that.
We want, we want whatever you called your fellow cellmates in a, in a revolutionary
Comrade. Comrade. A bit too, a bit too common. Yes. We'll think on that. We'll think on that.
That'll be our project between now and when we launch the thing. Cool. Cool. Indeed. And that's
really what we have as far as what we're bringing. And we hope that the people who are listening to
this podcast who are interested take the time and ask themselves, what do they want from the
rationalist community? Even if it's not what we're doing, I would rather have 20 other groups
competing with us. Cause then one of us will succeed at doing the right thing and making
us a big group, but obviously we're the best cause we're first. You're going to get the opportunity
to lay out some founder effects. Well, what I like is that this is again, finding,
you know, optimizing everything is what, you know, if we had bumper stickers, that's what one of them
would say. And, uh, you know, optimizing what does rationality do isn't really a question that has
occurred to me that explicitly before, um, which is awesome. And like, I remember we had a,
the pleasure of meeting Robin Hansen for dinner when he was here for Sam Harris's podcast a
couple of years ago. And it was many people from the local rationalist meetup and he asked
like a couple of times like, what do you guys do? What does your meetup do? And I was like, well,
we, you know, enjoy the community norms of the rationality community. And like, what kind of
answer are you expecting? Cause he asked twice. He's like, well, you know, a lot of meetups I
go to, they're like working on some Bitcoin thing, or they're all building an app or whatever. And
like, well, we don't really have anything like that. We're just hanging out and enjoying the,
you know, good conversation. Um, that's incredibly, incredibly valuable.
Well, yeah, but, uh, I like this answer more, a lot more. Like what are you guys doing? Well,
we're actually fucking doing something. And you guys are doing that. I think that's
outstanding. And I don't have, uh, the vocabulary to articulate other than saying how awesome it is
again. Um, really, really how cool I think that is. So I love my ego getting stroked. Don't stop.
I'm almost there. I'm really looking forward to having one of those signs on the side of the
highway that says this next mile is maintained by the community of servants, guild of servants,
guild of servants, right? Yeah. Cause the end goal is to also be able to have physical locations
and the guild of servants as a nationwide, global wide organization can give them the
resources. They can network them. They can provide course material and that allows us to
basically plant rationality communities. And if we get big enough, we can have a guild of pope.
That's a, uh, that's a failure mode, but
damn it. They're going, my plans for being guild pope. That does bring up the important
question. Will there be hats? Every cool club for the pope, every cool club has hats. My grandpa
was a, in the shiners. Yeah. So we actually have a, we have a strict rule for our meetings,
which is every time we have a meeting, all of us have to wear silly hats and
the reason why is you don't want to take yourself too seriously. It's so easy when you have these
big goals and these big aspirations to get caught up in yourself. And it's really hard to take
yourself too seriously when you have a gesture hat on and you're jingling every time you nod your
head. My favorite is a Santa Claus hat that is green. Oh, that's a good one. I only own one hat,
so I'll have to find some silly ones. It's, I think it's TBD, whether we'll require the,
the students to do it, but I'm leaning towards that. It looks stupid, so I'll still wear it,
and I think it's still counts, but it's not a gesture hat. Gotcha. All right. Well, this is
awesome. Do you guys have anything else you want to add? No, I guess website, TBD and all that
stuff. Yeah, website, TBD, formal stuff like that is all, is all TBD. By the time this episode
comes out, we will probably have a website and we will send it to you so you can put in the show
notes. Okay. Perfect. I mean, if then the first wave is an invitation on the alpha test, you probably
don't need a website yet. We might at least have a landing page to do that, people too,
with basic information and basic communication platforms. I could have a discord.
An email address were to apply. Yeah. This one's awesome. Yeah. I don't have anything else to add.
No, I am super excited. Yeah, I'm pretty stoked. I don't get, I mean, this is something that I
feel like I can benefit a lot from. And I have an optimistic, you know, vision for 10 years from
now of how much this could grow and how much stuff it could do. And hopefully being part of the alpha,
part of that test will be bragging rights for me in 10 years. Like I was there helping get this off
the ground by being an early contributor. Definitely. I admit, I kind of feel like we were just treading
water the past couple of years. Like it's been great and it's been a lot of fun. But I'm like,
we aren't doing anything new. Yeah. I would describe the last few years as when you plant bamboo,
it doesn't grow for the first few years. All it's doing is it's growing down. The roots are
growing down and it's becoming more solid. That's what the community has been doing the last few
years. We've been building connections. We've been talking, we've been doing discords. We've been
creating podcasts and networks of communication. We've built the root network. And it's really
just someone has to pull the trigger and start shooting up. And I honestly, I'm not sure if I'm
the most qualified person for it, but I might be the stupidest person who's also brave enough to do
it. And with wisdom like Alex and Matt and Gray and Errol bringing, it's very easy for us to do
amazing things. I think most qualified is a highly overrated qualification. The most important thing,
in my opinion, has always been just the willingness to do it. If someone's actually out there doing
the thing, that is, you're 99% of the way there because most people just don't do the thing.
100% agree. If you're waiting for the best person to do it, they'll never show up.
It's just the person who will do it. And man, it would be cool in 15 years if the legacy of this
podcast is that it helped bring together the people who started the Goal of Servants. I think
that'd be a pretty sick legacy anyway. Indeed. This podcast has helped bring a lot of people
together. You guys should be very proud of yourselves. I mentioned this on the live episode,
but this podcast is what kept me going before I was able to start a local community.
Shit. That's awesome. Yeah. If this podcast didn't exist, there's a good chance I would have fizzled
out. Well, damn. Like I said, if all that comes out of it is that it helps birth, not all that
comes out of it, but if this is one of the seeds that helped birth an actual move to shoot up,
like David was saying, then I think that's awesome. Indeed. Cool, man. This was great.
I want to hear all about this. Like I said, there will be three months of trial period.
Everyone else is as stoked as I am hearing about this.
Stace, maintain this little excitement for the next quarter year, and then there'll be
whatever, Discord websites and community and all that stuff. I'm assuming it'll be a month of
getting applications and going through them before you guys actually start anything.
Correct. Between now and when we start, probably about a month, approximately.
Awesome. Well, thanks so much, guys. Of course. Thank you for letting us on. We appreciate you
guys so much. You're awesome. Dude, you guys are awesome. You are doing a thing, and that is huge.
I'm very excited for what this can be. All right. Well, shall we thank our Patreon as we wrap up?
Oh, yeah. Someone else is also doing a thing. Yeah. Someone who is helping to keep this network
going that keeps people from fizzling out. Oscar Capraro, I hope I'm pronouncing that right,
is our patron that we are thinking today. You have helped keep Alex in the community
and going so that now he can do this thing for all of us. Oscar, you are awesome. All our patrons,
you are awesome. We thank you all. Thank you, Oscar. Yeah. You keep this going.
Seconded. I don't have much else to say other than, you know, I said it all better.
It doesn't mean I don't feel the same way. If you would like to also help provide this
fallback network thing for people to listen to, you can donate to us at patreon.com.
Under the Bayesian Conspiracy, we have our website, TheBayesianConspiracy.com.
You can hit us up on the Discord, which is linked there. And there's a subreddit. You can email us
personally, again, linked at the website. There's lots of ways to get in contact and to talk with
other rachelists. So do all that, rate and review the podcast, maybe. Yeah. If you're suffering alone
in, you know, a single bubble of sanity that is just you and you want a community,
online avenues exist. And then, you know, if you want to start a meet space one when
IRL things become safe again, then again, my advice is, and this isn't, I'm not an expert at
starting local communities, but it's always just do it. You know, put it on meetup.com,
go to a coffee shop. And if you're by yourself for the first two or three meetings,
whatever, maybe find a way to market it if it takes several meetings or whatever. But people
will come. People show up and then you could start conversations and it's great. And if anyone ever
needs logistical advice, feel free to reach out to me. I'm available all the time.
How can they reach you? My email address is fine. Alex.headkey at gmail.com. That's A-L-E-X.
H-E-D-S-N-Delta-T-S-N-Tango-K-E at gmail.com. Awesome. And Bayes Theorem on the Discord.
And Bayes Theorem on the Discord. And we'll also put that in the show notes and on the website.
If you're okay having your website. That's totally fine. Okay, cool.
All right. Thank you everyone for joining us and we'll be back in two weeks. Bye. Bye.
you
