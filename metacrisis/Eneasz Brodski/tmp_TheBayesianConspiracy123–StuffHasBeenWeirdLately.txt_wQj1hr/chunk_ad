How could we possibly test it?
That's a very creative answer, like to approach that problem.
And that's why I really liked the field enough to go to go to school
and learn more about it, that that kind of creative problem approach.
There's a few ways that they tried to test, like just to really make sure
that this bias was happening to where.
It was in the previous one, too.
It was this is to make sure that people weren't just
misunderstanding the word probability.
They were... That was why they were... This is really long.
Yeah, it really is.
He makes a similar example.
They did the same thing with doctors judging what symptoms are likely.
Yeah, to present.
Well, they did the best part to make sure that people weren't just
misunderstanding what was meant by probability.
And then they said, well, it might have just been
that people were thinking B to mean only B and not A.
And so that was the one with the doctors where they worded the instructions.
The probability they will be among the conditions experienced by the patient.
And then an explicit reminder, the patient could experience
more than one of these conditions.
Yeah, and they still still ran into the conjunction fallacy.
But then also found the probability
rank and representative rank exceeded 95 percent when they did the secondary test.
Yeah, I still wish that they had gotten into like...
I think without... Oh, sorry, go ahead.
Why?
It's not some hypotheses of why our brains might be wired like this.
Maybe it is just that we think of everything as like people and having a story
the way like sort of animism works.
Or even if you're thinking about a dye or dice, awkward plurals in English.
You're still kind of thinking about, well, the red guy and the green guy.
I don't know.
It hasn't been six in a while.
It's bound to be six one of these times is the kind is like a super natural way
to think that a super natural but wrong way to think about dye, right?
You could see why you might think that about some things in nature, though.
Yeah, I mean, for sure.
I think that it's I don't know it doesn't get into into here much.
But without treading into the waters of evolutionary psychology,
I think that that's about as far as we can get.
I think it's
understandable how our brains didn't evolve to do math.
And so it evolved to say, well, how reasonable does that sound?
And reasonableness doesn't necessarily relate to mathematics in our abish brains, right?
Yeah, I mean, we did kind of evolve to be like human pattern matches.
Since I think we were primarily like our own worst enemy.
I mean, we're social manipulators and as well, or that still makes it seem bad.
I'm trying not to put a value judgment in there.
Like we evolved mostly to understand and work well with one another
because we're social species.
There's a lot of PPP in our human experience.
And yeah, the like second half, though, of the sequence is just
Eleazar actually uses the phrase like hammering it down or
he says nailing it down.
But why do I keep hammering on this?
Well, it's because this fallacy, the conjunction fallacy, he says,
was probably the single most most questioned biased ever introduced,
which means it now ranks among the best replicated.
Yeah, I like that.
He says he continues saying questioning in science calls forth answers
and links that over to the proper use of doubt sequence post.
Yeah, which is a great thing about science.
How you this is how you summon answers by questioning things.
It is almost an eldritch ritual.
I emphasize this because it seems when I talk about biases,
especially to audiences not previously familiar with the field,
a lot of people want to be charitable to the experimental subjects,
but it's not only experimental subjects who deserve charity.
He says scientists can also be un-stupid.
Someone else has already thought of your alternative interpretation.
Someone else may have already devised an experiment to test it.
Maybe more than one.
And I wonder if it's when you read these kind of studies,
psychological studies, it often feels like you're trying to trick people.
And that's why I like these like these subjects didn't know what was going on.
And the scientists tricked them and like I've got to defend them.
Yeah, I don't know.
I've encountered that attitude before and that's weird.
We're like, I will study show this.
It's like, well, the people probably were doing this, this and this in the study.
You know, they didn't realize that the researchers were going to blah, blah, blah.
I'm just, you know, like, I think you're misunderstanding the point of this.
Yeah. So I mean, on the one hand, I totally agree with him, especially.
Well, OK, so real quick, he also says like a blank map is not a blank territory.
If you don't know whether someone has tested it, that doesn't mean no one has tested it.
And and so all this, all the sequences were written before the replication crisis,
which it kind of makes the whole thing a little it puts in a different light
because yes, he's he is correct.
And lots of these things have been multiple times tested and and verified.
But there's also a number of things which weren't and were just accepted as common wisdom.
And when the replication crisis hit and people started trying to replicate the stuff,
they fell apart.
And I think a lot of people nowadays are a bit more more wary about things
because specifically because of that, things that they were told were
where rock solid turned out not to be so much.
Yeah, well, I think it's like, sorry, I was just going to say,
we'll have to get a psychologist on at some point who knows all the modern stuff.
I've got somebody in mind if they're interested to talk about like.
So you use the word fall apart.
I think more like things are shown to have holes in them.
Like, I don't know how much of the edifice of our last century of knowledge,
especially like in social psych, completely fell to pieces.
Like whether or not you can get somebody to sit in a room filling with smoke
because of, you know, bystander effect or whatever.
That there might be reasons explaining what was going wrong with how that experiment
was done in the whatever decade it took place in.
But bystander effect is still probably definitely a real thing with or without
that experiment and we can devise better ones that have demonstrated the same thing.
But like that one in particular doesn't replicate or has problems with it.
Right. Yeah.
Well, like the conjunction fall scene specifically, he says it's one of the most
question biases ever and which is why it has so much replications
and so much proof behind it.
But there were lots of other things that like it turned out were just
researchers literally manipulating people.
Like in the case of the what was it the Stanford Prison Experiment?
Right. Yeah.
There were there were some that were just like really bad methodology
from the very beginning where someone was just trying to make a point
and didn't care what kind of trickery they had to do to make it.
Yeah. It's I think it's worth noting that.
I remember like this period of the rationality community.
A lot of people were talking about this and I think in the scientific community too,
although I wasn't part of that at the time, but like people.
You see Eleazar being like science is great because we can replicate this stuff
and like we can know things about the world because that, you know, like.
There are facts about the way the universe is that we can test and we can retest.
And what like actually caused the replication crisis was more of the publisher
parish sort of model that we pursue science through where there's no
prestige really to be had for replicating studies.
Grant Money is going to people discovering new things and negative results
never get published. Yeah.
Yeah, they aren't sexy, but it's still like it's still human biases
that are causing us to get the wrong results, which is why I, you know,
I'm not sure what point I'm trying to make here.
I guess I'm just I well, I got this.
I like the way he expressed the frustration at the end here.
He says it does become a little frustrating sometimes to know about this
overwhelming mountain of evidence that from thousands of experiments,
but other people have no clue that it exists.
After all, if there are other experiments supporting the result,
why haven't they heard of them?
It's a small tribe.
Surely they would have heard by the same token.
I have to make a conscious effort to remember that other people don't know
about the evidence and they aren't deliberately ignoring it in order to annoy me,
which is why it gets a little frustrating sometimes.
We just aren't built for worlds of six billion people.
Very big tribe.
But at the very end, he does say, I'm not saying, of course,
that people should stop asking questions.
If you stop asking questions, you'll never find out about the mountains
of experimental evidence.
Faith is not understanding only belief in a password.
So yeah, don't stop asking.
Keep looking.
Try to replicate and disconfirm and shit.
Yeah, good faith.
Yes.
Not because you don't like where the evidence is going or something.
Yeah.
The the whole ending, the whole second half of this sequence post
kind of reminded me also of Alexander's Scott Alexander's post.
Yes, we've noticed the skulls where he talks about the researchers
saying, yes, we are aware of these things that people keep pointing out to us.
Yeah.
But yeah, that was that.
It was something else to say about this.
No, it's fun.
I always I always enjoy this stuff.
And there's plenty to read about like with the history of this field of research.
And I mean, I guess you can I was going to try to recommend a book,
but I can't remember quite the title of one of my favorites that I read
that wasn't recommended to me from anything in the rationalist sphere.
It was just like I came across it in a library and it was like great 20th
or great experience of the 20th century or something.
And this woman tried to go through and like like in her own
investigation, trying to replicate as many as possible.
And none of them I can't remember anything related to conjunction fallacy in there,
but it was just fun.
Like I find the the 1900s to be like the most one of those fruitful,
probably the most I don't know, whatever, fruitful decade or centuries
of social psychological research, right?
I think it was in the early 1900s when like they first tried to test
like how many words can a small child remember or something?
Like just basic shit about people.
And we went all the way from that to all right.
Well, now we've got some basic idea of how people work.
Oh, how do they not work?
And that stuff started to come up at like 1950s and later and it was really cool.
And so there are a few book links at the end of this,
but they're all kind of in a diverse key, but no doubt they link to other books
and their own citations and essays.
So there's lots to look into here, look, lots to look into here
if you find the stuff interesting.
Yeah, there's kind of an interesting conversation in the comments as well
about the disparity between psychologists suggesting that people
should trust their instincts, but then also like being aware of biases.
