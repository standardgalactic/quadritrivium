Well, right. That's one of the differences between this and the type of deterrence.
If you think about deterrence, if deterrence says you're going to cause somebody not to,
for example, take your property, you're going to punish them, and the punish them as a cost
that they have a reason to avoid. Now, that works to a certain extent up to the point
where they can take your property without getting caught, in which case you have no deterrence
value. But what if you can get them to not want to take your property? One of the things
about people, if they don't want to do something, then they don't need somebody looking over
their shoulder to catch them if they should do it. They simply don't want to do it. So
if you can create an aversion in people to taking property such that I wouldn't take
that for a million dollars, I just don't want to take things from other people, take things
that aren't mine, then your property is safe even when you have no deterrence, even when
there's nobody watching over their shoulder. I guess the people steal because they want
your stuff. This is sort of raising the question for me of how you let me lay out the problem
that I'm thinking and the solution that I'm halfway developed to do. So the problem, I
guess, would be how to decide which desires to try and foster other people or how to weigh
desires against each other to say this is the one that you should have, you shouldn't have
this one as much. And I guess one way of solving the problem would be saying, okay, look, if
you want this, it's going to hurt you in all these other ways. It's going to inhibit your
future ability to satisfy your desires, or it's going to conflict all these number of
desires. So really just want the ones that are the most consistent with each other and
with everyone else. Maybe not with yet. Maybe not with everyone else.
Yeah, how do you decide which desires should be increased and which should be decreased?
Well, you simply look at the ones that tend to fulfill other desires. You go for honesty
because everybody needs to have true beliefs in order to fulfill their desires. You go for,
you don't want them taking your property without your consent, because then you wouldn't be
able to plan and do you know good to work on something because your property would be
disappearing. You definitely have a reason to cause other people to have an aversion to
causing you pain simply because you don't like pain. So what you do is you look at the
things that you want and you look at how different desires will make it either easier
or harder for you to get what you want. And those are the desires you have reason to promote
in others. And they're the same desires that they have reason to promote in you. And it
comes up to your fairly basic set of moral principles. You know, don't lie, don't break
promises, be kind to others, help them when they're in need. Don't take things without consent,
that type of stuff. What about in situations like colonial America where there's 100 white people
who want free labor and one black person who doesn't want to be enslaved? How do why do his
desires outweigh the desires of the 100 white people?
There you're getting into the idea that what's right as well but fulfills the most desires. But
that's not the case. Remember, we're evaluating desires. Now, who has, does anybody have any good
reason? I mean, everybody has a good reason to cause other people to have an aversion to slavery.
Because if people don't have an aversion to slavery, then you're at risk of being the slave. So the
desire for slavery itself is a bad desire when one that everybody has reason to condemn as it
turns out. Well, it's only a scary desire insofar as you have any realistic risk of becoming a slave.
Yeah, what if you instill the desire not to instill, not to enslave people with the same skin
color as you in a place where you are a majority, then you could get the benefits of free labor
without having to worry about being enslaved yourself. Well, if you could...
I'm not trying, we're not trying to stump you and be like, ah, gotcha. I'm really just trying to,
like the way that I assess different world theories is I try to see how they tackle real
world problems, right? So this isn't, if it sounds like we're just trying to drill you into a part.
Oh, no.
This is what we're trying to do.
No, this is a standard problem. And if you go to my blog, I actually have a blog post called
The 1000 Satists Objection, which is what this is. What if a thousand people wished to torture
one person, then would desirism say that that's a good desire? And so, you know, it is a common
problem. But when you're talking about the moral desires, you're talking about desires that are
to be universal across everybody. And the way to look at it, like the The 1000 Satists
example, is do you have any reason to be surrounded by sadists? Do you have any reason to be surrounded
by people who are willing to enslave others? Now, you can say, what about, we're going to give
everybody a desire to enslave only this particular people with a particular color skin. How are you
going to do that? And once they have, if they have no aversion to slavery, if they're sitting there
thinking, okay, I can go ahead and enslave this person, identify, enslave more people, I get more
labor. Now, you're going to create a situation where they're going to try to enslave more people,
and that puts you and your descendants at risk. There's also an issue in that it's difficult to
make specific desires. Desires aren't like rules. You can make rules that are really complex. They
have lots of exceptions. But when you're using praise and condemnation to molded desires,
you're not going to be able to mold desires that are incredibly complex. Like you can give somebody
an aversion to slavery. But how do you give them an aversion to slavery of people of a particular
color skin? I think, as humans, we do very naturally break down people into in groups and
out groups, though. And it's very easy to have distinctions between the in groups and out groups,
so that it can be even someone like people who can't pronounce a word a certain way are now the
out group. And all the moral rules that apply to the in group do not apply to the out group.
I think one of the major advances that we've made over the past few centuries is the expanding of
the in group to include more and more people. Until now, it seems that, at least in the Western
world, to include all human beings. But I don't think it's necessarily that difficult to decrease
the size of the in group, if you wanted to, so that people will feel discussed in aversion
towards people of certain ethnicities or religions. And they don't have trouble making separate moral
rules within and the out group. It is incredibly easy. In fact, there's been experiments,
what they've done is they've taken random people and invited them into a room and simply given them
two different colored tags, tags and green tags. And after just a couple of hours of mixing with
each other, it's them about their level of trust that they would say that people of the same color
tag are more honest. They would trust somebody of the same color tag to watch over their children.
And this is just, these are strangers. And the only difference is the tag color. And so, yes,
it is incredibly easy. But in virtue of the fact that it's incredibly easy, it also creates a great
deal of hardship. If it's hardships, it's the fact that the violence and the discrimination
that people have to endure, all of that is what gives us reason to work against these
common psychological dispositions and to get something that actually treats people according
to their actual worth, how useful they are. And to put these things aside, the very fact that
they're destructive is the reason to work against them. Okay, so you're arguing that having lots
of this separate in-group and out-groups like that will cause a lot of conflict between various
groups and that a society that eliminates this sort of intergroup conflict will be stronger
and dominate ones that are very fractious? Well, that's true. I'm a bit uncomfortable with the
dominate ones that are fractious because I don't know what you're meaning by dominate there.
But yes, we do have reason to get rid of this conflict and look at human history. Just about
every horrible thing that's happened in human history has happened because of this
tendency to form in-groups and out-groups, whether you're talking about the Thirty Years
War or the Holocaust or the Mongol invasions, and it's all caused by this disposition to
form in-groups and out-groups. And the fact of all that we have reason to avoid all of those
hardships are the reasons to fight against this disposition to form these in-groups and out-groups.
I want to change gears a little bit, but only predicated on the possibility. Have you read
the Harry Potter book series? Pardon? I'm sorry, have you read the Harry Potter book series?
I haven't read books, I know the movies. I can't remember if this was in the movies or not. In
the fourth book, and probably the movie, there was a house elf that was... I kind of bring the
problem of desirism to like creative and artificial minds, like using house elves as a go-to example.
Right. The house elves basically want to be servants, and so like if they want it,
you want a servant, it sounds like everybody wins. There was a part in the fourth book where
one house elf is trying... They also have a desire to self-harm if they aren't good servants,
and when at one point one was stopped from self-harming, and she was distressed about it,
and it's hard for me... I think I'm still trying to be together with desirism enough,
because to me, it makes sense, like, look, I'm going to stop you from hurting yourself,
I'm going to try and teach you why it's wrong to hurt yourself, but she was distressed about it.
The house elf wanted to hurt herself for being a bad house elf, and, you know, letting her do
that would have satisfied her desire to do it. I guess, are there good and bad desirers, especially,
I guess, trying to think of something as convoluted as created minds?
I only heard part of that, that you're cutting off. Could you repeat just the very end of it?
In Harry Potter, the house elves had a desire to self-harm if they weren't good servants,
and then at some point in the book, one of them is having that desire to self-harm
supported by one of the humans in the book, and she's distressed by not being able to self-harm,
but it seems to me that that's not a great desire to have, but she wants it,
and she really wants it for other house elves, presumably, so I guess,
is there a way to say that, no, this desire is bad?
Well, a desire is bad if it thwarts other desires. If it thwarts other desires,
then you have a reason to get rid of it. Now, you talk about the house elf wanting to harm
themselves, but what is the harm? The harm itself is necessarily thwarting another desire,
so he has a desire to thwart other desires, and that desire to thwart other desires is a desire
he has reason to be rid of, and that just is the same thing as calling it bad.
I think in the context of the book, I think they self-harmed as sort of like a program's way to
make sure they were even better servants. It's like they wanted to hurt themselves because
they wanted to be good servants, and if they needed to punish themselves to do it, that's what
they did, so they weren't really challenging their own desires, and if this is too far-fetched to
be worth considering, that's totally fine. It is necessarily countering their own desires,
because otherwise it wouldn't be harmed. Can you be harmed by something that you'd like?
Oh, I see. Yeah, I guess it hurt. They were punishing themselves, though.
Right, but in punishing themselves, they were creating a situation that they had an aversion to,
that they had a reason to avoid, otherwise it wouldn't be punishment.
Gotcha. Okay, that makes sense. Yeah, another good example might be a crazy religious fundamentalist
whipping themselves in repentance or something. They're only doing it because they feel bad,
and they want not to whip themselves, but they're doing it because they feel they have to.
Right, yeah. They have a reason to get rid of that desire, too. If it's any desire that thwarts
other desires is one that you have reason to get rid of, and the reason comes exactly from
those desires that are being thwarted by it. One of the things I really liked about
desirism is that it has a category of moral negligence, which some ethical theories don't,
whereas it is the fact that you can condemn people and punish them for not doing something
that a good person would want to do. Right, that was one of the objections that I first
heard of when I started talking about this theory. There was a philosopher in the 1900s by the name
of James Martino, who his theory was that the value of an action is determined by the value
of the desire from which it springs. What I call motives, he called springs of action.
And one of the objections brought against him by Henry Sidgwick was that this doesn't account for
negligence, because negligence doesn't come from a bad desire. The drunk driver who just wants to
get home doesn't have a bad desire, he just has a desire to get home. So how can you condemn that
under this type of theory? And the answer is that you can condemn people for having the absence of
a good desire. The negligent person, the drunk driver, isn't properly concerned with the well
being of other people that we have reason to cause people to have. So we have reason to condemn
the drunk driver and anybody else whose carelessness puts other people at risk. We have a reason to
demand that they take more concern to avoid harming other people. I think this is particularly
of relevance today, these days, because I consider a lot of these
not necessarily news sites, but places that put forward claims that are ridiculous and wrong,
and they simply don't care that they're wrong. And I think that they are harming society in
general for putting forward these claims as if they were true and not even caring to check if
they are correct or not. I condemn them as being morally negligent and on the scale of evil for
not caring that they should be telling the truth. Actually, I would put them as something
beyond negligent. They're being dishonest, so we have a reason to cause people to have a
version to lying, and apparently it hasn't worked with them because they are lying.
But in lying, they are making it... Well, the way that desirism views lying is lying
is a type of a parasitical action. Think about it as putting a... If I had a way of controlling
your actions so that instead of doing what you wanted, you did what fulfilled my desires,
if I had a remote control or something that I can put into your head, then I would be using you
for my own ends. And that's exactly what a lie does. What a lie does is it puts something in your
brain that will cause you to act in ways that for your desires, for your interest and fulfill mine
in its place. And we definitely have reason to condemn that type of action, but we have reason
to condemn lying, and that's what they're doing. I think it extends further that it extends through
the people who just don't care if what they're publishing is true or not. They're like, well,
this sounds good, and this supports my narrative, so I will spread it without bothering at all to
check if there's any truth behind what they're publishing. The people who honestly believe,
for example, now that it's not relevant anymore, that Obama was born in Kenya and would spread
that, they I think are at least somewhat morally culpable for not caring enough to check if that
was true. Right. That is something that I call epistemic negligence, and it is something that
we have reason to condemn because it spreads all sorts of false beliefs that do actual harms,
and we do have reason to give people an aversion to doing that. The invention of social media,
I think, has made that particular vice much more damaging than it has been in the past when the
only people you could talk to are your neighbors. But yeah, a lot of the things, there is an obligation
to check whatever it is you find on Facebook or what gets forward to you in an email before you
pass it on to 100 other people. It is negligence. I kind of feel like religion had a role in
encouraging epistemic negligence from the very beginning. Yeah, that is one of the charges I
think you can bring up. Well, not religion, it's say religion is an extremely broad term and
encompasses a great many things, but the idea of faith, the idea that you could accept certain
propositions and completely ignore any type of evidence for or against it, that's a problem. Now,
some religions don't put that much stock in faith, although many of them do. But faith itself is
something that I think can be condemned as an epistemic negligent way of approaching truth.
I agree. I'm not a huge fan of faith either. I like the idea that epistemic negligence seems to
talk a lot. We were talking once about, not on this podcast, but previously we talked about
a Clifford, William Clifford wrote that essay on what it was called. It was the parable of the
boat captain. Right. Yeah, and that the boat captain has a duty to not be epistemic negligent.
Another world example might be like 60s to faculty. Right. They might have suspected,
but they're not going to look into it. That might prove them wrong. They're going to say,
well, no, we're not going to look at this particular claim. Right. Or you could look at the energy
companies today with respect to global warming. I mean, I'm certain that some of those executives
are simply convinced themselves that greenhouse gas emissions can't harm the planet. But still,
they're producing a product, which it is going to cause a great deal of harm. It's going to kill
people. And so that gives them an obligation to look through this evidence objectively and determine
whether or not these claims are true. And if they can't be objective, then their next best option
is to find a panel who that can be objective and to ask them to render a decision for them.
