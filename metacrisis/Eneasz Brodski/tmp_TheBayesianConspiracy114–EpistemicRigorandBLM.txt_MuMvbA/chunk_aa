Welcome to the Bayesian Conspiracy, I'm Eniasz Brodsky, I'm Stephen Zuber, I'm Jay Stiggy,
and we have an interesting conversation today, but before we do that, we're going to do less wrong posts like we always do, right guys?
Just like always.
Like we helped do last time.
Yes, it was good times having Wes on last time, wish I could have been here.
It was. Speaking of good times, I listened to the Mind Killers episodes, I finally got caught up on the backlog, including the most recent one, and that was a lot of fun.
Thank you.
Is your mind currently dead?
Yes, but for other reasons.
Okay, good enough.
Alright.
So, we have some sequences.
Yes, our first sequence today is called positive bias, look into the dark.
I just want to make sure that is the one we're on, because I missed last week, but then you didn't do last weeks?
I think we're doing a positive bias and say no to complexity.
Okay, good.
And we can just skip positive bias, because everyone here has read Harry Potter and the Methods of Rationality, and if they listened to the companion podcast, we want more.
We covered this in, I think, chapter eight, which I think went by the same name.
I think we can do it again, though, because...
I'm just kidding.
Okay.
We're all rationalists already, we don't need these sequences.
Yeah, we're all already perfectly sane.
And, I mean, people who are coming back listening to archives afterwards are not necessarily listening to things in the same order, so maybe they're going to get to the we want more after they're done with this or whatever.
I was confused because these are in the opposite order on less wrong dot com.
Oh, really?
Yeah, saying no to complexity comes before positive bias.
I think that they kind of, I don't know, doesn't matter what order they're in, kind of, but not really.
Now, particularly, positive bias was posted on the 27th of August, 2007, and complexity was 28th.
So, in chronological order, this is correct.
So, let's start with positive.
Excellent.
Steven, you have told us what this is about already, so would you like to kick us off?
Oh, sure.
So, positive bias is essentially where, in a sentence, it's where you try to confirm my hypothesis rather than falsify it.
And this is distinct from confirmation bias, because that's more like seeking out sources to fit with the preexisting position.
And this is more of like, all right, I've got this idea.
Now I'm going to try to test to see if this idea is true rather than see if this idea is false.
And what is the example he gave us that was later immortalized by Hermione Granger?
The 246 task.
Did they call it petals around the rose in the story?
No, that was the one I used and we want more because Brian had already read the chapter before I gave it to him.
Which I stole from a, I might have been a Alexander Wales 2 chapter fanfic.
That was the really good one that wrecked me.
Harry Potter and the Philosopher's Zombie.
That one.
Hey, does anyone else want to be destroyed? Read that story.
No more emotions.
Speaking of being destroyed by stories, I just finished the first Last of Us video game today.
We did talk about that like four or five years ago on the podcast.
So everyone who wants to go find it, it was I think on our episode on like utilitarianism or something.
So anyway, the 246 task is essentially where, what was it?
Peter Watson, not Watson.
Basically the premise is I have a condition that the integers 246 passes the condition and I want you to guess other numbers to see if it passes or fails.
And then when you've done enough experiments, tell me what you think the condition is.
Yeah, I think they gave them, I don't know if they gave them three or if that's just what they had as students guesses in the article.
I want to say I think they got three chances that no, no, no, it says you can test as many triplets as you like.
Okay.
Yeah, and the one in the article is one student's guessing.
So they do 462, which returns a no.
468 returns a yes.
And 101214 returns a yes.
And I like this.
At this point, the student wrote down their best guess at the rule.
What do you think the rule is?
Would you want to test another triplet?
And if so, what would it be?
Take a minute before continuing.
Now, this isn't fair because we already all know the answer.
I think if you've been reading the sequences, even if you don't know the answer, there should be something about Eleazar's tone there, at least to me, that was like, haha, how you're trying to get me right now.
There's some trick here.
I'll let Stephen reveal it.
Oh, well, I guess before I give the answer, it was, I think the replication of that study shows that there's a success rate on the first guess of about 20%.
Which means that 80% of people think they've got it and they haven't.
So the actual, the rule is the three numbers must be in ascending order.
And it's that simple.
People would make these convoluted rules or they would, you know, like again, 468, oh, increases by two each time.
101214 also increases by two each time.
Okay, the rule is it has to increase by two each time.
And that's not it.
So it's, it can be as long as they're in ascending order, that was the rule for this task.
So it's a fun little test.
And if you get a chance to test out on your friends or coworkers, it's a great way to make friends and enemies.
Yes, and enemies.
But the point is that the person who wrote down 468 and then 10122, it didn't occur to them to, it occurred to them to keep testing things that would confirm,
but never testing one that would disconfirm by saying, for example, 4610, because that would disconfirm their guess that it always goes up by two.
And they never asked something like that.
That's the generalizable lesson is if you have a hypothesis, try to see what wouldn't happen and test for that.
Yeah.
Right.
Yep.
Yeah, I liked that.
It's further on in the article, but there was a really good line that I want.
Yeah, here it is.
We ought to think about both positive and negative examples, which automatically pops into your head.
You have to learn wordlessly to zag instead of zig.
You have to learn to flinch toward the zero instead of away from it.
And that's hard.
Like it's rationality is not easy because it does mention this is like, I got this wrong.
Or I think he says that he got it wrong when he tried it.
Yes, he did.
That was in the next.
Yeah.
It's like, so like, it's not like, it's not about being stupid or smart.
It's about you have these instincts that you have to have some kind of heuristic to check for you.
You're checking yourself constantly.
I know that people are reliably wrong in this way.
I know that I'm a person.
It's hard to do though.
And that the subtitle of this post, it's called positive bias, look into the dark.
And the reason he calls it look into the dark is because looking for examples that prove you wrong
kind of like feels bad.
It's not natural.
That's why he says look into the dark, like look for things that would prove you wrong
or that would prove your hypothesis wrong at any rate to find out whether the hypothesis is actually correct or not.
Yeah, I think this is a small scale example of what ended up leading to the replication crisis.
We're the same thing with, you know, scientists still want to get a yes.
Sort of how we're, I guess, trained in school.
The whole idea is that this all rolls into guessing the teacher's password and so forth where we're kind of taught to be conformist.
We're kind of taught to try to get a yes.
I feel like it's almost kind of antisocial to look for a no.
Yeah, that's a good point with the replication crisis.
If you're always just looking for ways to confirm your data, that's much easier.
But if you look for things that might disconfirm it, it's work that, you know, you don't want to do because then it disconfirms your idea.
Well, it's hard to get more funding when you say, yes, I showed there's nothing here.
Another main thing.
And this is like a nice neutral, non-emotionally charged way to test this sort of general principle.
But it gets like the look into the dark part where it's actually scary where you have to flinch towards the scary thought rather than away from it.
Is when, you know, if you're considering something of emotional salience to you and, you know, what would make my important belief that I have?
You know, this is just a hypothesis about some number game, right?
But if you have like this important belief about especially something political or whatever, trying to, like even the idea of looking for numbers or looking for contradictory evidence just feels uncomfortable and wrong for, I think everybody, or at least most people.
Not, I think, you know, if I were to count myself among them, even rationalists like testing to see if my, you know, emotionally salient political belief is true or false, or especially to see if it's false.
There's like a bit of a fear reaction there.
And so it's important to just face that and try to be less wrong about stuff.
Hey, that's the name of the show.
I remember this was actually like a college professor I had.
It was an art teacher.
So maybe this gets more of a free pass, but he was talking about something about like the mysteriousness of nature.
And I like being smart.
I said something about like, I knew the biology of how the thing he was describing works.
So I said it and he's like, you said just always trying to quantify things.
Oh my God.
And I was just like, yeah, that actually that's what we're, that's exactly the did you not, do you not know the scientific method?
Do you not realize this is the name of the game?
This is how the world works.
It's like that it ruins the beauty here destroying the rainbow by running it through a prison or something.
Whatever that poet thought.
I actually know what he thought of just being intentionally obtuse about it.
It's because Keats was a sour grapes nerd.
And if you want the real awesomeness of it, check out Unweaving the Rainbow.
That's going to be my fifth plug for that book on this show so far.
And yeah, plus one.
Should we go on to the next post then?
Why don't you lead us in on this one?
This one's kind of fun.
All right.
This one is say not complexity.
So as far as I can tell from this one, it's basically he's saying, look,
just saying something needs complexity is very much like saying something is an emergent behavior.
He says he was talking with someone he was working with on how to create an AI that could discover how to solve a Rubik's Cube.
And several times in the discussion, the other person said, well, I think the AI needs complexity to do X and complexity to do Y.
And Eleazar said, don't, don't say complexity.
Or I believe his words were, yeah, don't say complexity.
All right.
I'm imagining him leaning forward and placing one finger on this other guy's lips and going, don't say complexity.
Leaning really close.
Oh my God, creepy.
And the guy asked him why not?
He says it should never be a goal in itself.
You may need to use a particular algorithm that adds some complexity, but complexity for the sake of complexity just makes it harder.
Can I bring up the next thing, though, because he put in a little parentheses after that one.
I was thinking of all the people who had heard advocating that the internet would wake up and become an AI when it became sufficiently complex.
I was called out by that because that used to be one of my pet theories when I was in high school.
I didn't necessarily say because complexity, but I think that was what I was thinking about, though, that surely when it gains more functions,
it just needs to be bigger and more complex like a brain.
It's got neurons like a brain, right?
And then it'll become a brain.
That was totally a thing in high school for me, too.
It is a compelling idea until you look at it that way.
He pointed out that what you're doing when you're saying things like complexity or emergence is just skipping over the mysterious part.
And that's not helpful at all.
You need to pay closer attention to that.
And is this the one we said?
Yeah, this is the one where they introduced magic.
So as a workaround for this because there were some issues that they couldn't tackle everything all at once.
They had to lay out some things and they developed this convention that whenever they ran into something that they didn't understand,
they would use the word magic as an X magically does Y to remind themselves that there was an unsolved problem here.
And they had to come back to it.
And that was, you know, they were like, if you use the word complexity or emergence that can hide the issue.
But if you say magic, then it's really obvious that there is something missing here that you need to go back to later.
I like that it reminds me of a writing technique where if you have a placeholder when you're writing a first draft to make sure that you see it, use the swear word there.
I forget if a friend of mine made that up or I might have even made that up.
But when you're going back and editing, you can't not see it.
But yeah, it's that kind of thing that like, wow, that doesn't belong.
Do you remember what Mark Twain said about very and fucking?
Which?
Okay, so I think it was Mark Twain, but this may be suffering from the whole, you know, all quotes eventually get attributed to famous people.
He said that you should remove, everywhere in your document when you're writing, you should replace the word vary with the word fucking.
Because afterwards, your editor will go back and remove the word fucking from everything and your manuscript will be better.
That might have been actually where I got that idea from.
