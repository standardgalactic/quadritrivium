Welcome to The Basin's Conspiracy, I'm Eni Ashbrotsky.
And I'm Stephen Zuber, and today we have a guest, Chase, and we're going to be talking
about digital rights.
Do you want to tell us what that subject is?
Hello, I'm Chase, and yeah, I'm here to talk about digital rights.
So, well, firstly, to be painful, I'm not even sure I'm a fan of the term digital rights,
to me it's really just your standard rights, just as they exist when you happen to be in
front of a computer or a phone or any other digital device.
That does seem to make it almost sound like a lesser right, it's like these aren't your
normal rights, these are your special digital rights.
Yeah, exactly.
It's kind of like the way the homophobic people were like, well, these gays want special
rights.
I'm like, no, we just want the same rights you have.
Exactly.
Digital rights are the same thing, they're just your rights.
So what are these digital rights?
Or what are these rights that extend to the digital domain?
Fundamentally, it's all the same rights.
We, the right to a freedom of speech, the right to some privacy, personal space, personal
privacy, and man, that's about it for digital rights.
So why should I be worried about my digital rights?
Don't I have the right to freedom of speech?
You do in the real world, but when it gets to digital, it gets real gray really quick.
Facebook is a fantastic example of this.
When you post things on Facebook, Facebook has an internal algorithm that determines who
sees them and when they see them and how many of your friends see them.
And this is rated by a lot of things, mostly by what Facebook thinks your friends want
to see, which may not be what you're saying, which isn't fantastic on its own, but also
certain topics that Facebook just avoids.
They don't want talked about on their site, so even if you post about it, they just
blanket block it from anyone seeing.
They don't notify you, and it's not a direct blocking of freedom of speech, but it's a
subtle undermining of it, and it can be very problematic.
That's one example.
I mean, I see what you're saying, and I dislike that as well, but since it's their platform,
do they have some right to do that if they've determined that that is what their customers
want and what will serve their corporate not getting sued and or losing customers' interests?
They're absolutely allowed to do it.
They're legally fine to do it, but...
But they shouldn't be.
I don't want to say ethically.
I guess it is, but ethically, they shouldn't be because they are in ways interfering with
your freedom of speech.
And...
Now, if they didn't have those blanket prohibitions on certain topics, which I agree is bullshit,
and instead just weighted stories based on what your friends want to see, wouldn't that
be okay?
Because then they're providing a service to the people who use Facebook.
I used to, back when this was actually an option, and I had less than five bazillion
friends, I just had my feed set up chronologically.
I would see things as they came in and scroll through it until I caught up with the last
thing, and obviously I can't do that anymore.
But that privileges people who just spam Facebook constantly.
And I don't want to reward people who spam Facebook constantly with crap.
I want to see the stuff that's actually interesting to me.
And if Facebook knows what that is, I am very happy that they promote things like Robin
Wiblin stuff to the beginning of my feed.
And it is in their interest to do so, and I'm sure they will continue to do it.
The reason it can be a problem is it, to me, it's one of the big causes of sensory bubbling
information.
What am I looking for here?
Accessibility?
No.
Polarization in society?
Yeah.
The term I don't think is exactly sensory bubbling, but it's your news bubble, your information
source bubble.
Sure.
Is there a term?
I've heard the term info bubble.
Echo chamber is good, info bubble?
Yeah.
All right.
Sorry.
Where were we?
What did you last ask?
I asked, isn't that a useful service to cut out the boring crap and give me the stuff
I actually want to see?
Yeah.
Yes.
It's a very useful service, and it is in Facebook's interest to do it, but it very
much leads to a sensor bubbling phenomena, a news bubbling.
It gives you your own echo chamber.
It limits your exposure to all disagreeing opinions, alternate perspectives, and that
can be a very dangerous thing.
Personally, I think some of those effects have already manifested on Facebook.
If you have seen any of your friends kind of lean their political leanings ever more
radical, but specifically while on Facebook, I think that some of the reasons, some of
the reason we see stuff like that and how it can cause issues.
There is some things I see on Facebook that I don't get from people when I see them face
to face, but I always just attribute that to internet balls.
Yeah.
Of course.
It's always easier in text.
We talked about this earlier, and my counterpoint to that, and I know you had a pretty good
argument against it, but my counterpoint to that was people always naturally filter
themselves anyway, that when I was much more active in online communities, I would go to
an atheist forum and just talk with other atheists about atheist things.
Every now and then, if a Christian showed up, we would either rip into him if he was
an asshole, or sometimes have decent moderate debates, but it was very much a social bubble
and very insulated, and we knew that, and we were okay with it, is what we wanted.
I think you just kind of hit on what makes it different, is you knew it.
You were aware of it when you were there.
It's easy to recognize, or at least easier to recognize as a social bubble, as kind of
outside of how the rest of the world talks, how the rest of the world thinks, and it's
more a conscious choice instead of it being decided by some skeezy algorithm in some corporate
headquarters, what you should talk and think about.
I don't know why you got a diss on the algorithm, man.
This is a perfectly nice algorithm with a wife and two algorithm children.
I think it's related.
There's been concerns on Reddit that there's non-user-controlled manipulation of front-page
content.
I think what you're describing is the difference between going to r slash atheism versus your
front page being filtered without you being able to adjust that.
Then you're getting a skewed view of the world without knowing it.
Exactly.
The overall concern there is that if you're going, first of all, don't use Facebook for
news, but if for some reason you are, people might be going in anticipating that they're
getting a somewhat balanced or proportional view, and they're probably not, right?
I'm going to make a confession that I get most of my news from Facebook because the
actual news that I was at my parents just a week ago and they turned on the evening
news, this is depressing.
This is awful bullshit.
I do not want this poured into my eyeballs every single fucking evening.
When I do hear about things, it's generally because enough of my friends are talking about
them that it has made its way to me.
I get most of mine from either news alerts on my phone or from the NPR five-minute flash
briefing from the digital assistant that if I say its name, it'll activate.
That updates every hour.
A couple days a day, I can be like, hey, what's my flash briefing?
That updates every hour?
Every hour or two, I think.
I'll start checking it more often.
It's kind of cool.
Then that way, if there's something that I find interesting, I can dive into that.
Yeah, you're right.
Sitting and just watching the news, that sounds like a nightmare.
I guess moving away from Facebook and Reddit, there were some other really interesting examples
of how a consumer's right to either possess information or own information that they've
stored digitally or manipulate information or other stuff digitally.
I totally want to get back to that because that is super interesting, but I don't want
to move off Facebook just yet because what other option do we have for mass communication
with our friends?
I mean, the whole point of a social network is that more people are on it, the more useful
it is.
So, pretty much you're stuck with the best one or the largest one.
Well, yes, and optimally, there would be a...
Do we just have to put pressure on Facebook through legal or social means to not be dicks?
Is that our only choice?
The solution, I actually don't know what the solution is.
The solution is to spend as much time as you can with companies that aren't doing this.
If there's any alternative you know, if there's any other company, any other way you know
to do this, whether it be even just a group messaging app to keep in contact with people,
there are a few very small open source projects that easily accomplish most of Facebook's useful
side, but as you said, it really matters what network your friends are on.
If they're not there, it's not of tremendous value, but the more we can push to these alternatives
that are ethically correct or more ethically correct, I think the better things will be
in the future for literally everyone.
And I think just the fact that those exist makes things a little better?
Yeah, absolutely.
And that's what we really have to be careful of is those do exist for now.
If you want to have a personal secure communication with someone, you still can.
It's a lot of work and it's harder than...
It's a lot harder than you might believe to have a truly secure conversation with someone,
but you still can today.
And depending on how net neutrality rulings go and how ridiculously large Facebook continues
to grow, it's not unreasonable to think that at some point you might not have the freedom
to do that.
And the sooner we can head that off, the better all of computers will be for the future.
I personally, when Amazon came out with their eReader, the Kindle, and Barnes & Noble came
without, there's the nook.
Even though the Amazon had a little bit more usability and breadth of scope, I went with
the nook because it doesn't have the terrible DRM on their stuff.
All everything you got for the nook was DRM free.
It's kind of disappointing in that the nook has more or less been outcompeted.
They're not really supporting it as much anymore, but you can still buy all the eBooks you want
off Barnes & Noble without the DRM.
And I think the fact that that did exist as an option, even though only like 5%, 10% of
the marketplace may be used it, is part of the thing that helped push Amazon into getting
rid of their awful DRM.
And I am glad to have helped support the cause for a little bit.
Exactly.
And I still use the nook because I mean, it's just as good.
That's a great example of just leaning towards the freer, better platform and how that can
affect these big scary corporations.
But I do worry, as you said, that if the nook goes away entirely and or Barnes & Noble
goes out of business or something, what is the check on Amazon at that point?
Exactly.
Yeah.
Why wouldn't they go back to their crazy?
And that all falls under DMCA law, which is a huge complicated monstrosity that if we
have time, maybe we'll cover in the end, but it's one of the big things that interferes
with your own digital rights and your access to your own software, to your own hardware
and to truly, it's one of the things that really limits you from truly owning and controlling
your own machines.
It basically strips away what rights you have to your own stuff.
It says that the things you have are not actually yours is, God, I hate the DCMA or
DMCA.
Yeah.
Yeah.
Digital Millennium Copyright Act.
Right.
It's passed back in the 90s and has been interfering with everything in computer since then.
This is the one that we talked about a few episodes ago that makes it so that companies
can make it illegal for people to change their own oil.
Yeah, absolutely.
It interferes with everything because of the way additionally copyright law works.
You can put DMCA on, say, most anyone here has a computer, I mean, computer, a phone.
If they are listening to this without a computer, I am very impressed.
It means someone has gone to the trouble of putting it on tape and handing it to them.
All right.
All right.
Everyone has a computer.
There are certain parts of that computer that you bought and you own and you have in your
possession right now that you can't look at legally.
In fact, most of it, the entire operating system, the word processor, possibly even
the web browser you're listening to this on if you're not on Firefox or Chrome, most
of Chrome is open source, that are illegal for you to look at too hard, for you to investigate
too hard, just for you to look into it is against DMCA law.
Even though you possess it, you own it, and even more so, there's even hardware inside
of a computer you own.
There are certain chips that run mysterious black box code that you aren't allowed to
look at because of DMCA law, even though you bought it.
The thing that really irritates me more than anything else is that you don't own it anymore.
You don't own your stuff.
You have paid money for the things and you're in physical possession of the things, but
legally the ownership belongs to someone else and you are this person that they are
daining to allow its use for a limited period of time, which they could yank away at any
time if they wanted to.
Exactly.
There's a famous quote from Richard Stallman that says, either you own your software or
your software owns you.
Richard Stallman is a big advocate of open source software.
It's a very transparent way to build software so that you know what's in it, so that you
can't have either state actors or big corporate actors controlling how your software works
and what it does instead of you controlling how it works and what it does.
Exactly.
I use Ublock for my primary ad blocker.
What I like about that is that it's open source and I haven't gone and looked at the code
myself, but the idea is that other paranoid and savvy internet users can and if there
was something fishy about it, they would say, hey, look at this and that's not the kind
of access privilege that most people have to most of their software.
That's terrifying.
I wanted to get to clarification on something really quick.
You said word processors have occasionally black box code areas.
All of them except for a few very open source projects.
What on earth would they need that for unless it was to explicitly for something nefarious?
Well, even wider, let's say all of Windows specifically sends back every single keystroke
mass movement and occasionally contents of screen to Microsoft ostensibly lets them
debug and help improve the operating system for the future, but it's one of those things
that can be very dangerous if that power were to be abused.
I had no idea it sends that much data back to Microsoft.
It was a fairly big scam when Windows 10 came out.
It's new in Windows 8 or Windows 10.
They've started doing that and it's obviously not all of them, but it can happen whenever
it wants to and they have a legal right to that.
And they do.
That's the type of product you have purchased and there are alternatives to that.
There are open source operating systems that don't do this.
The Linux project is Linux.
It's a huge computational framework that most servers on the internet run because it's
actually secure, secure against not just Microsoft, but even against state level actors.
You can trust it not to be reporting to them because it is entirely open source code.
It's improved by the community.
It's watchdog.
No, it's, what's the term I'm looking for?
Audited.
It's audited by the community and if there was anything fishy in it, more than likely
someone would catch it or more than likely someone would have fixed it because that's
the other advantage of open source is it's transparent.
Almost anyone can post improvements.
If you see something wrong with it, if you see a security vulnerability, anyone in the
world, they can submit the code to improve it themselves, which would be in their interest
if they're running this open source code, which most anyone on the internet is.
So it's a very good way to do things.
You sent me a fascinating article about the importance of transparency in code.
It was the pacemaker article where a woman with a pacemaker likes to go jogging and at
one point she was going up a flight of stairs when all of a sudden she basically couldn't
breathe.
She started blacking out.
It was like her entire body shut down on her and they rushed her to a hospital.
Eventually they figured out what the problem was is that her pacemaker went above a certain
threshold of heart rate.
I forgot what it was like 120 or 150 and it reset back down to 60 beats per minute, which
is not nearly enough to support her body with the level of activity she was at.
She was an engineer.
She started really looking into this pacemaker and all the code that runs it and so forth
and found out that not only could she not see the code and not update it, but it had
a wireless update capabilities so that the creator or the owner of the pacemaker, the
company, could push updates to it without her knowledge and without telling her what
the updates did.
And she had, first of all, a huge problem with that because she wants to know what the
code inside of her body responsible for her living is doing.
But also, this is now a vector of attack.
If something can be wirelessly updated, it's not just the original owner that can update
it.
It's anyone with enough hacking skill to get into it.
And she did not like the fact that anyone could hack into her heart.
And that's a fantastic example.
There's someone literally walking around with an implant keeping alive and she doesn't
own it.
Someone else owns it.
Someone else has complete control over it and they can do whatever they want with it.
And that's absolutely ridiculous.
There were stories a couple of years ago about stuff like that, about pacemaker security
vulnerabilities and pacemaker hacking.
And all of that's possible because the only people who know how this works are big medical
corporation and whoever is sketchy enough to look into how to hack these things.
So let's say this woman wanted to shut down other people's pacemakers, she might be one
of the only people who can, which is dangerous.
And if she wanted to legally turn off the ability for her pacemaker to be hacked, she
can't do that.
No, that would be against the law.
She can't alter anything inside her body without breaking the law.
And that is very dangerous.
And that even brings us as we progress and as our phones, almost extensions of our minds
as they are now, but as more and more of that capability can become potentially integrated,
potentially implanted in the future, it becomes very dangerous when a part of you isn't under
your control.
Yeah, like you're wearing a smart watch right now, where some years away from not having
to put a, being able to attach it without a wristband, right?
When that happens, I mean, the biometric data that your Fitbit stores isn't yours, I think
you can look at some of it through your apps or whatever, but you don't get to keep that
information secure if you don't want to.
Yeah, you don't get to decide where it goes.
Someone else can access it, it could be subpoenaed by a court, it could be distributed by Fitbit
to its advertising partners, you have no idea where it goes.
And even more so, a lot of the time what happens with this data is a lot of people end up with
it who are not in your original target audience.
So you say, sure, Fitbit can have that.
Yeah, well, Fitbit shares it with a couple of advertising partners, shares it with your
little toy app on your phone that gives you rewards for how much you walk.
And they share it.
And eventually one of those people in that huge tree has a data breach.
It just happens.
It's just everyone at some point, and then who knows who ends up with it?
It was, was it Etna?
One of the major health insurance companies recently got hacked and lost records, not
lost, but the records were copied for like 112 million people, something like that.
If you've been on the internet for any length of time, it is almost 100% certain that your
data is in the hands of people that you did not expect to have it, and who don't legally
have it, but have it nonetheless.
Even if you're on the internet, your data is probably in the hands of people that you
didn't expect to have it because you clicked yes when you signed up for a website or something.
Yeah.
Which, I mean, there's a whole other bag of worms that I...
Can we do anything about ULAs to make them not be fucking evil?
That's sort of what I was going to try and get at, right?
On the one hand, the corporation or whatever, the software that you're downloading that
says explicitly in its ULAs, if someone dies or becomes injured or if your company takes
a loss as a direct result of a failure in the software, that's not our fault.
That sentence can show up in there on page 117 out of 250.
And to be clear, they don't give you ironclad legal immunity.
You can still take them to court, and the courts will say, well, despite the fact that
it says this in the ULA, we find that unconscionable, and you are responsible for this person's
death, but it makes it a lot harder.
You have to go through a lot more process and pay a lot more, and the outcome's uncertain.
It's true.
I mean, there are protections.
You can't just declare yourself immune from negligence.
Even if you're on the highway, and there's one of those trucks with a one foot by six
inch sign that says, stay 250 feet back, we're not responsible for rock chips.
First of all, you have to be 30 feet away from this truck to see that.
But even if rocks start flying off and breaking your windshield, that's still on them.
They can't just declare themselves free from that responsibility.
But they can say they can, and that might turn some people off, or it might give them
some one level of resistance in court, right?
Well, we told them they couldn't drive behind us.
They should have just looked.
And just to clarify, Yula is short for end user license agreement, which is the thing
that you nowadays have to click that you read, even though you didn't, and that you're okay
with before you use almost any piece of software that exists.
And to answer your question for what we can do about it, what you can do about it is help
build these alternatives, help build alternatives that don't have big, scary, terrible Yulas
on them, and use them whenever possible.
The more competition there is, the more people who care about this, the more companies are
going to have to listen to, this is the right way to do this.
And if they don't, hopefully these alternative projects can be large enough to be usable.
Many of them are today, you know, Linux and OpenOffice, and that whole branch are huge
projects run by probably more than 50% of the computers in the world.
I mean, all of Android is a Linux branch.
Oh, I did not realize that.
And at its core, it's an open, secure operating system, but Android has a whole layer of all
of Google's shmoo on it.
And because of the way free software works, actually, by doing that, Google has to update
the true open source project Android is based off of.
It's called the Android open source project, which is a very nice, very secure, not corporate
controlled and not as data leaking operating system.
You can run on many phones today if you want to avoid that kind of scary Yula corporate
controlling freedom infringing behavior.
And the more people do that, the more pressure it puts on other companies to
behave.
So some of the some of the terminology being thrown around sounds kind of like fear
mongering and either can we explain why that isn't fear mongering?
But in fact, this is as terrifying as it sounds.
Or can we just say like for the average user, just to play devil's advocate a little bit,
I like being able to go to Amazon and seeing on the front page there.
Oh, look, an author like has a new book out.
I'm not sure whether or even if I bought the previous author's book on Amazon or
where maybe I like to unface book or something who knows the perceptions that
even if they do have all this information, they're just using it to try and target ads,
which I'm like the only person I've met who's kind of OK with that.
No, I love that fact that I will sometimes hear about a band that I like and that isn't
very popular coming to my town.
Right.
I'm like, this is I would pay for the service.
I'm glad I get it for free.
Yeah.
And that's kind of actually what you were saying earlier, Inyash, which is the this is
providing a service.
It is helpful and that that's one of the big that's how these companies that's
how they defend themselves.
That's what they say they're doing.
And in the large part, yes, they are.
It is a very handy service.
But to me, they're not nearly as transparent as they should be about this.
This should be big red text first when you come on, which is we're we're collecting
all sorts of things about you in very subtle ways, very technical ways.
You know, we can track what websites you go to from here, what you do before you
come here, all sorts of things and they don't.
They don't really share that.
They don't consumers don't really know that.
And people might change the behavior if they did.
It surprised me.
It's already changed my behavior a little bit when you told me the quote,
unquote, private conversation I'm having with someone in Facebook Messenger is
seen not only by me and the person I'm talking to, but Facebook and their system
for determining what words I'm going to type next or something.
Sure.
And all their advertising partners are going to use that to help target
advertisements at me like by personal conversation, which is feels weird.
I don't mind them doing that for things.
I post on Facebook, my wall itself, but the things I'm talking about with
other people being scanned as well starts to feel weird.
Yeah.
And most of those personal chats, as far as I know, aren't, I don't think
are shared with advertisers yet, but Facebook certainly keeps track of all of
them.
They use it for all sorts of learning algorithms on what they do.
That's actually all outlined in their privacy policy.
If you read the page, God knows what, but it's not only that in these
personal conversations, you also have, well, the keyboard on your phone is
reporting back to Google.
It's analytics.
If you have an, if you have an Android or Apple, if you have an Apple on top
of that, the operating system on your phone is keeping track of these.
And that might be controlled by Google.
So now Google and Facebook have it.
And if you go even a step further, which not too long ago would have, would
have been called a conspiracy theory as of when did the songs first do
his big leaks 2014?
It's been a few years now.
I don't remember exactly when.
I feel like it's longer ago than that, but who knows.
Yeah.
It's not super important.
So what would have been called conspiracy theories up until quite recently
is that literally the government has access to this.
The, there were big reveals on, you know, the whole NSA, phone tapping, the
metadata collection, the interference with computers as they are.
And that's the thing that happens.
And not only does it happen, it's incredibly widespread.
It is actually extremely difficult to have a truly secure conversation
with anyone nowadays to a ridiculous degree.
There was a time, and I think this was known even before the Assange
WikiLeaks thing.
That was Snowden.
Sorry.
Or well, Snowden worked with Assange though.
Yeah, I know, but I'm sorry.
The government for a long time actually forced chip manufacturers to put code
in their firmware that what reported back to them or did something with your
data, that was actually an even worse example.
So one of the, the arguments, like we were just saying, if you want to have
a secure conversation, all right, don't use Facebook Messenger.
Don't use your Android phone controlled by Google.
Use the hardware you own and that you bought and that doesn't go through
any corporation that you're privately emailing directly to another person.
It doesn't go through anyone's server, but yours and theirs.
And you say, yeah, sure, that should be completely secure.
And it's still not because there was a, what's called the equation group malware.
It's the NSA's, although arguably the CIA's, no one really knows.
It did a whole lot of things.
It was ostensibly built to help counter Iranian nuclear threats, but at some
point it ended up on 30 something percent of all computers in the world.
And what it would do is if it saw you encrypting something so you could send
it securely to someone else without it being read by any intermediate parties,
it would weaken that encryption.
It would see the encryption key go to the heart of your computer and subtly rewrite it.
And that's on your computer that you bought that doesn't go through any
server, no ULAs, no nothing that should be a secure communication that still isn't.
It was literally on the hardware itself.
Yeah, it was it was on a chip came in coming out of the plant that way.
And which is I heard one of the reasons that many governments now
consider it part of national security policy to be able to create their own
hardware in the country.
Absolutely.
One of the only because you can't trust hardware that you get from the U.S.
One of the only secure computers you can buy today is sold by Richard
Stallman at the Free Software Foundation.
It's a early 2000s think pad.
It's one of the only laptops that doesn't have a huge block of mysterious code
running in a chip you have no control over and aren't allowed to look at.
Lest we come off suddenly conspiracy theorists will link to all this stuff
on the episode description just because this.
Well, my first time being exposed to this, I'm just like, this sounds like
it sounds like you should be wearing a tin foil hat.
This can't be real.
No, but this is well known now.
It was it was it was reported on at NPR and various news media outlets when it became known.
And even more recently, as of as of this recording, just a few days ago,
WikiLeaks has posted a bunch of as of yet technically unverified leaks about
CIA internal operations that detail CIA's extensive research into
interfering with automotive computers into interfering with hardware
manufacturer for personal computers and a huge set of spying tools to interfere
with what should be secure communications in you and another party.
So what is it that they do?
What do you mean?
Well, the new one that just came out on WikiLeaks, I'm not sure I can answer that.
OK, I'm not sure I know enough detail.
It just came out just a few days ago and I haven't read all of it, but the newest
one was a set of tools, a set of data collecting tools, mostly.
So four places like Facebook that either have this publicly or privately shared
or for Google, a set of tools that can let them scour everything accessible
to compile as much information about a single person as you can.
So you say, oh, it's not bad, Fitbit has this, it's not bad.
Facebook has this part, it's not bad that my Alexa has this part of my history.
But you start mushing that all together and you can come up with a lot of
information about a person they may not have meant to share.
And a lot of the more recent tools are that, but that even stacks with
the additional information they have from what should be secure computers.
I've got a fun tie in since you name dropped the Amazon Home Assistant,
the one in the corner activated and was listening.
I remember reading something a few weeks ago, maybe a few months
where it was either an actual terrorist or suspected one.
Somebody was trying to get the as much conversation as they could from Amazon
that was stored on their Amazon Home Assistant, the Echo, I don't want to
say its other name because it will start talking in the background.
And they were, as far as I could see, unable to.
So like Amazon just really didn't store much.
Like so when you say, when you use the activation word, it'll store what you
say after that until it starts processing what you said.
And then it won't save anything else.
At least that anyone could find in this one thing.
Yes.
So firstly, there are certain things, there are many things that could be
captured because the keyword isn't just Amazon Home.
As you guys know, you have one.
There are a couple of things I can wake it up.
A fair number of words that can wake it up accidentally.
Home is one of them.
Is it?
Right.
What about, um, um, assassinating the president?
Well, ostensibly, according to Amazon that you let know.
But as crazy as it sounds, we don't know if that's the only thing
running on that.
You don't have the right to look into it and make sure the only softer
running on it is Amazon's.
For all you know, anyone's could be.
It could be a compromise system by a kid down the street or by a foreign state.
And there's really no way to know because you don't have control over it.
You have to trust that Amazon kept it secure and that it's in their interest to do that.
And Amazon might not even know.
And it might not, they might not have a real strong incentive to work
really hard to secure this because no one cares.
No one raises an issue about this.
So it's more than just, just Amazon having it for sure.
And that's, it is something to think about.
And I know that we've talked about this before, but just because it might be on
someone else's mind, it might just be, might not just be me.
What is, as long as I'm not talking about doing anything illegal, why do I,
what, why would I want to have a private conversation?
I mean, that sounds like a stupid question, except let's say if I was like, well,
you know what, I'm okay with something looking over all my, my Facebook
conversations, just to see if there's any keywords that pop up and, you know,
maybe not saving everything else.
Maybe who knows, because I'm concerned about my national security.
And because, so I'm willing to sign that away.
And because they're not doing anything bad to me right now, I'm kind of fine with
that. I think that's the, the steelman position for this really is national security.
Right.
There's no one's coming out and saying, yeah, we're doing it because we're, you
know, they're not mustache twirling, you know, super villains.
If we can catch one terrorist, it makes it worth violating all these rights.
Totally, totally correct.
Well, I think that's more or less their articulation, maybe some, some
keywords in or out of there, right?
What is the comeback to that?
So like, I'm not, I'm not doing anything illegal.
Why do I care if Facebook creates my, my messenger conversations?
Hmm.
Did I accidentally win?
No, I'm kidding.
The risk always is, uh, it's the same reason a police require a warrant for a
wiretap or police require a warrant to come into your home and investigate what
you're doing.
They're fundamental freedom of speech and freedom to have a functional
democracy reasons why this has to be this way.
And those same, those same needs continue into the digital domain.
The same needs to a reasonable level of privacy.
I actually really wish I could articulate those offhand, but.
It does seem like privacy is a thing that most people just want instinctively.
I hear a lot of celebrities are unhappy about the fact that, uh, they don't have
very much privacy in their lives, even though if they aren't doing anything
illegal, why should they care, right?
But it does feel like the same kind of thing where if there's a cop standing
in your house at all times watching to make sure you aren't breaking any laws.
Someone could say, well, if you aren't breaking any laws, what's the big deal?
Got nothing to hide.
But on the other hand, just having someone there constantly with the threat
of violence in case you fuck something up can be extremely stressful.
And I would assume, you know, even bad for your health.
I completely agree with you guys.
I just wanted to get that conversation.
No, I think that's a really good question.
And I wish I could better come up with the term for why that's so dangerous to
have that police officer always standing in your living room.
I mean, it would make things safer.
You would never assault someone while that police officer is always there.
Yeah.
So like celebrities, you know, or anybody has has the rights to, um, like it's
illegal, I think in most states to try and take pictures to someone's window if
they're inside their house.
You know, if their front door is open, if they're on their lawn, that's where
like paparazzi pictures come out of famous people or something.
But the idea that I'm at home, this is my space.
I'm going to do what I want here.
And I don't want to worry about looking bad if, you know, whatever, whatever it
is, right? Whether I'm doing anything illegal or not, I just don't want to
have to look glamorous in case someone posted this picture online.
I should be allowed to say, no, that's, you guys can't have that picture.
But as far as like making things safer, you know, we talked about before some
parts of the United States, like certain intersections, especially, but my
understanding is that in large parts of the United Kingdom, there's like surveillance
cameras all over the place.
And they're, they're not at least the ones that people see aren't like hidden
secret ones.
They're just like, you know, on street lamps or whatever.
I mean, they might act as a bit of a deterrent because people will say, oh,
by mug this person, that camera will see me.
But they also act as a way to corroborate your story.
It's kind of why people like police body cams, right?
So that in that way there's, there's uncontestable accountability saying, no,
no, look at 313, I was mugged by this ATM, you can check the camera.
I guess what I'm getting at is that sort of ties into people don't have this
expectation of privacy when they leave their house, right?
Right. And that's an example of laws that made a lot of sense in the past and
don't make quite as much sense now because it makes a lot of sense.
Sure, you're outside your house, you're, you have no expectation of privacy.
We are allowed to watch you, you know, track you, see what you're doing.
And that makes enough sense, except as technology evolves and as things change,
we end up with a situation where instead of just being able to look at you or
being one person, be able to see what you're doing, we can now aggregate all
of the video data of everything you did in that entire day down to the minute.
And hopefully that will only be used to do good for the citizens.
But at some point, you are trusting a branch of your government with all
of this information about you and you start aggregating this from not just
webcam, but from all of this information they have illegal and legal access to.
And it becomes, it becomes a dangerous amount of information.
It's one of those, what's that well-quoted stab?
I'm not sure if it's true, but that the average person commits a felony a day.
And that under perfect observation, you could put anyone in jail and you living
in a state, you know, living under laws like that is very dangerous.
You can put anyone away you want to at any time without them having committed
a specific crime, without them having committed any more crime than the
neighbor, you can put them away because you just have the ability to look it up.
Yeah.
Because everything's because everyone's against some law.
It's, I don't remember exactly which reporter it was, but there's reported
that followed cops around for a while and apparently the cops in this particular
precinct have a game called, they call it the 10 minute game.
Anytime someone is riding around with them to see what they do, they tell them,
pick out any car at random you want at any time and within 10 minutes, I'll be
able to pull them over for something.
And it's never failed.
Apparently they, someone just points out a car, the cop follows him for 10 minutes
and eventually something happens.
They're like, you're pulled over and that, I mean, that's, you can do that same
thing.
There's so many laws out there.
Everyone is breaking something at some point.
At that point, I start to really get worried about our legal system because it
means that basically the only reason you're not in jail is because you haven't
pissed off the right people.
Exactly.
And that's, that's not the right way to run things.
Yeah.
In that case, the, in a society like that, your only point of defense is not to
come to the attention of the powerful.
Don't do anything that would piss off someone.
And I think we all agree.
We don't want to live in that society.
No, it's not safe to rock the boat even a little.
Uh, I think the other, the main comeback about, you know, unsecure communication,
whether it's, if, whether you're doing anything nefarious or not, there's no
such thing as like a backdoor that only the trustworthy agent has access to.
So even if, even if we lived in a, in a world where we just, we had a national
security agency that we were all just all behind, we said, Hey, there, we know
that the super trust worthy, no one in that, that industry has done anything bad.
And even if it's like the mythological version of Jesus himself in charge of it.
Right.
Um, and this isn't, I'm not making a jab at the NSA, but you could just say that
even if you're on board with everything they're doing, there's no such thing
technologically as giving only them a backdoor to your stuff.
Once you weaken it like that, you, you fundamentally compromise its security to
anybody who has the time and money and effort to go in and, and figure it out.
So like people will put like sticky notes on their cameras and their computers.
Um, not everybody, but some people will include a carry a phone in their pocket.
Right.
And then carry a phone in their pocket with a microphone and everything.
Right.
So like, I'm not super worried about some NSA agent looking at me and my, you
know, watching me read on my computer, right?
But if I wasn't in a different circumstance and maybe if I was trying to avoid
a stalker or, you know, if I was a celebrity that I didn't want people
looking, you know, that's basically being stalked all the time.
Right.
So it's not just the NSA person looking at your computer.
It's anybody.
Once the backdoor is open, it's not just like one person can look in.
You don't even have to worry about doing something illegal.
It's just about kind of wanting to be able to mind your own business and have
people stay out of your business for a while.
Yeah.
Yeah.
And, and today we still have options to do that.
It is still possible to communicate securely, but that if we were, if we
don't watch it carefully, we may lose that.
And is that because of the DMCA?
Well, no, no, I mean, to some degree, yes.
It's one of the things that makes it easier to enforce, but it's just because
of the way communications move today.
As everyone moves up to Facebook and off of their own personal computers that
you control, it becomes harder and harder to do.
You moved and or I do move to more and more computation is done in the cloud.
Exactly.
Exactly.
I feel like I hit all the points I was thinking of.
Yeah.
And, and just to, just to counter just a little bit further, a good example would
be depending, it depends a lot on who has access to this data.
So if it's all logged by your perfect NSA, even if we assume as a magical way to
do it without invalidating the security of all software, how long is it before
you're in a trial for who knows a speeding ticket, a something really minimal
and someone can pull up a recording you said four years ago in your home about
hey, wouldn't it be funny if Donald Trump's hair caught fire and he died of it?
And bam, you've now broken a whole other set of laws.
Like it's very important who has access to this.
That reminds me, you did bring us something really interesting.
Last time we talked about this, which was if I'm arrested for something, say, say
if I'm being charged with murder, the police can go to my, whatever my cell
provider and figure out where I was at all times for as far back as they think
is necessary, but it's apparently you said it was either way harder or impossible
for like my defense lawyer to do the same thing.
Yeah, because one of a lot of police agencies not only can go subpoena
that from the wireless provider, which may or may not have it, but a lot of them
now recently have been deploying their own.
Basically, it's a hacking device.
It's a fake cell tower that your phone can connect to as it drives by that they
own and they say, oh, look, this cell phone's right here.
And because of the way the 911 system works, your phone will report its
location to that fake cell tower immediately.
And they have access to that because it's their device and you and your
defense lawyer very much don't.
That's weird that I mean, Stingray system, right?
Stingray system.
And that's horrifying.
Just recently, they require a warrant for that up until now.
They don't even that's when it first came to my attention was when I heard
that warrants are now required for this.
I was like, oh, this was a thing before a warrant.
And so that's interesting.
Like with no probable cause, you could be put under that level of investigation.
And what, what, what to me really blew my mind is that the prosecution can go
get this information pretty much really easily.
I guess now they need a warrant, but I mean, that's not super hard to get
depending on what the warrants for.
But if that information could exonerate me, I can't get that from my lawyer.
I mean, no, that's insane because if that information's out there and it's
from my stuff, I mean, this is like, this is what really drives me.
Uh, like this really drives this issue home for me.
This whole umbrella of, of digital rights is that if my phone can tell me,
yeah, at 3.30 last night, Steven was in fact at home watching Netflix and
playing, you know, clash of clans on his phone, we can see everything from where
he's at. Therefore, he couldn't have committed this murder in, you know,
two cities over, uh, but that, that blows my mind.
Like, why, why isn't that information easily easy to find for my defense?
I mentioned this, uh, earlier when we were talking, the, the one that I find
really crazy is the, uh, again, it's a pacemaker one, the one where a guy is
being charged for, uh, insurance fraud for burning down his own house to collect
the insurance. There's recording of him calling 911 saying, oh, my house is on
fire, blah, blah, blah, and they're all worried about putting on a pretty good
show about it. Police went and accessed the data from his pacemaker and they
saw that his heart rate at the time was not very elevated.
It was basically a resting heart rate.
And they said, look, there is no way someone who's actually panicked about a
fire happening has a heart rate that low.
He is probably not even in the house at this point.
So, uh, they're using that as part of their prosecution, that he very
obviously was not actually in panicked or fear for his life.
And if you were to try to do that the other way around, you aren't going to
get your pacemaker data from the company that holds it.
You don't have the power to subpoena them and get that and see, be like, look,
you say I was murdering someone at 2am last night, but here is the data
from my pacemaker that shows I have a resting heart rate and I was probably
asleep at that moment.
I certainly was not stabbing the shit out of some dude.
So that the fact that they have access to that information and they will use
it to prosecute you, but you do not get access to it to defend yourself is
something that very much bothers me.
It's, that's pretty mind blowing.
I mean, again, this whole thing of like they have access to it.
I know who they are, like that we're talking about, but this is, this is
probably the most tinfoil hat conversation that I've, that I, that I can
fully get behind.
Well, I was actually going to ask, I'm not entirely sure the laws on medical
data, whether you can subpoena that and a prosecutor can or can't.
I'm not entirely sure how that works.
Okay.
Um,
You think they may have been going past their legal reach and it might get
thrown out?
No, no, I think they can.
I'm just not sure if you can't, I'm not sure if that's the case.
I haven't actually looked up the specific case.
I'd be really curious to see it though.
I mean, this also could just show that the guy knows how to keep
his cool under pressure.
Right.
Yeah.
So, I mean, maybe he's just super Zen and he's like, all right, well,
panicking won't help.
Right.
So I'm, and I mean, also your heart, it would be elevated if you're faking
a fire too, right?
Or if you're faking, if you're faking, uh, an accidental fire.
I know.
And I guess back to the point you were making is he should have access to that
without any question.
He shouldn't have to go hire a lawyer and file legal documents with a medical
company providing this.
It's his, he owns it.
It's in his body.
It's madness that that's the only way he has to access his own data.
And I think really the, the, the home driving point for this too was that as we,
we alluded to earlier with, you know, smartwatches and other, other things.
I mean, phones are, are definitely there.
But the second phones stop being external and something, some parts of the phone,
you know, whether it's an implanted Fitbit or, you know, a pacemaker is a very
early version of this where we're well on the way to getting, you know,
technology in our bodies, in our brains.
And if, if there isn't some reform between now and then you can get a software
push to your brain chip that does God knows what, right?
How long is it going to be until you don't actually own your own body?
Yeah.
Yeah.
Someone, some corporation has legal rights to it and you have to abide by
whatever they decide.
Yeah.
That's terrifying.
The most invasive thing that I can think of as far as brain stuff is they can
treat Parkinson's with like a deep implant that does, I think it activates dopamine.
Yeah.
The deep brain stimulation, low voltage things.
Exactly.
I don't remember what it's called, but it's out of my, I'm just not finding the word.
I don't know if that's even the kind of thing that has remote update capability or not.
It's wouldn't want it to.
Well, I wouldn't want it to either.
But I mean, it's one thing to acknowledge that if, for whatever reason,
there's a better version, for example, that first woman with the heart of the
pacemaker, the idea that for whatever idiot reason it has a governor at 120 beats a
minute or 150, whatever it is, and then it just tanks to 60, that sounds like a bug.
And it probably was a bug.
Yeah.
So like the idea that they could fix that without having to crack my chest open
sounds great, right?
But I should be fully in the loop.
And the idea that, that kind of reasoning and privacy on behalf of the
product owner, not you could work for something like a brain implant is kind of
terrifying.
I mean, you remember how much people, I don't know if you remember, but I remember
how much some people I know freaked out when Windows pushed the Windows 10 update
onto their computers and they didn't want it.
They wanted their old Windows still.
Like how much worse is it when a company pushes their update into your chest when
you didn't want it?
Or worse, Microsoft, for whatever corporate interest, whatever corporate reason
that's not yours, they could decide, oh, we're done with Windows off.
Like then it's not in their interest to do so.
But the fact that they legally can is worrying and it should be.
So we are round and close on when we should be ramping up ish.
Did you want to talk about the DMCA a bit?
I think we've covered it fairly well.
Okay.
Yeah, it's dangerous.
The only thing I wanted to bring up is fantastic organization that's really
helping get this legal ground pushed into the modern age is the electronic
frontier, Frontier Foundation.
Their charity that fights a lot of big legal cases.
They fight patent trolls.
They fought a case not too long ago.
That allowed podcasts to be recorded and distributed, which was someone with a
media company was there was actually, yeah, they were trying to, uh, they
claiming that they had their right on the concept of, of what a podcast even
does recording content and then giving it to people broadly, uh, then it was
fought because, uh, someone managed to find back like in the 80s, a group that
had made just a cassette tape recording of, of the sort of like a podcast
explaining set tape and they would record, you know, lots of copies of it and
then pass them out to their friends and various subscribers across the city or
the state and the EFF was like, see precedent.
This company was not the first one to do it.
It was this small group in Kansas or wherever.
And yeah, but the fact that for a little while it was the very concept of a
podcast was in jeopardy, something that is so simple and fundamental and not
something a corporation can like claim they invented, you know, uh, was madness.
My favorite example of patent rolls and I can't remember which two corporations
were having a, a peeing contest about this, but it was, uh, who owns the tablet.
And there was some back and forth and correct me if I'm wrong.
Um, but my understanding was that, uh, in 2001, a space Odyssey, there's a
tablet on like one of the computer chairs or something.
And they're like, concept existed before, before either of us.
I, apparently on Apple products, you can't get swipe on your keyboard or just
wipe your finger around.
I certainly don't have a swipe.
I don't know if I can't get it, but probably not.
Yeah.
If somebody owns that.
And, but that's fair.
Like that, that's a recent development that someone built and patented and did.
And that's fair enough.
We're not talking about someone trying to patent the idea of an online
shopping cart, which is a famous patent for all that tried to shut down
basically every vendor on the entire internet.
Anyone who couldn't pay the huge legal fees to fight it was just, well,
well, too bad.
Give us half your money.
Yeah.
I love the EFF.
I heart them.
They're doing God's work.
And they're one of the charities that I donate to annually.
I think that's, yeah, I think that about summarizes it.
I did have a question.
You guys mentioned DRM a few times.
What does that stand for?
And what exactly is that?
It stands for digital rights management.
And that is how companies get to say that I own this block of information.
And I will try to lock it down in any way that I can.
There's a famous XKCD comic about it where you buy something and it has DRM on it.
And then eventually you want to transfer it to somewhere or you want to use it
on a different device or something and you can't because the DRM blocks you
from doing that.
So then you have to go and pirate a copy.
And so now you have a pirated copy of the thing you purchased legally and
you're a felon or you can just pirate it anyway.
And you have broken the same laws and you have the same product, but you
haven't paid the money for it.
So it's basically a way to punish people who have legally bought a product.
Yeah, the DMCA is a subset of DRM.
OK, yeah, actually, I remember back in the day when I still bought DVDs, I
would I had to use a piece of illegal software to burn it onto my computer so
I could put it on my mobile device or DRM is what makes it so that if you buy
a book or back when they were using DRM on their stuff, if you buy an
electronic book from Amazon, you can only read it on an Amazon created device
or an Amazon licensed device.
If you leave the country and they notice that because your device
pings their servers all the time and you go someplace where they have not
allowed you to read the thing, they will delete it off your phone.
Oh, that was that case that you mentioned before.
Yeah.
Yeah, they will just take stuff off your thing.
So what is I mean, OK.
And it makes it really hard to access your things sometimes.
A lot of DRM is just shitty.
And we haven't even gotten into, especially in future tech, you know,
you talk about consciousness expanding phones and how much you offload onto them.
And then it starts to get even worse when you're, you know, a significant
portion of how you think where you store a lot of your data isn't under your
control. It just it just gets so much worse, so much faster.
You mean, you don't have to remember nearly as much as you used to anymore.
You just have to be able to find it again on the internet.
The Google is like outsourcing of your brain now is a repository of lots of
information. Well, a lot of that, I mean, is done, I guess, even more literally
than that, too. I mean, I don't know how many I have a thousand or so pictures
on my phone, right? And so that that and then that way it's kind of a record.
It's a much more detailed record than what I could remember myself.
So I'm sort of outsourcing that memory, right?
So I can go back and get it later with more reliability.
For a kind of visceral example of what we're talking about, imagine if every
time you crossed, you crossed a border, you got on a plane.
Every time you're pulled over by a police officer, who's like, all right,
let me see all of your phone. I want to see every picture you took.
I want to see every where you've been.
I want to see every text you've sent.
Every sex you've received in the last 48 hours, in the last all of recorded
digital history. And you can see even today, just the way we use phones now,
how bad that would be. And it will only get worse as we use them for more and more
things. Yeah. Well, I mean, you don't have to email your phone, links to your
Facebook, links to everything that is you.
Yeah, exactly. And you don't have to be a criminal.
It's not want to copy able to see your sex, right?
So or your dirty pictures you're sharing with somebody or even the business
documents that you have sent back and forth through email.
That's true. Most business documents nowadays are sent through email.
All my legal proceedings are going back and forth through email right now.
That's just, I mean, the alternative is mailing it, which I mean, arguably is
even way less secure, right?
Yeah. But if people were, if it was, if someone was opening all of your mail,
copying it, putting it in a secure database somewhere else, resealing and
sending back to you without telling you, you'd be like, that's absolute madness.
And the fact that that's somehow accepted once it goes digital is just ridiculous.
That's a really good analogy to bring it home.
And the same questions could have been brought up.
You know, why do you care if the government's looking at the mail you're sending out?
It's like, because it's my shit. Well, yeah.
So like the, and we have this mental image that, you know, countries and
times where that happened, those are not desirable places to live, right?
So, and yet we live in those places now, if I'm sending an email.
You were saying something about not wanting to concentrate power into a
single entity, that kind of the point of democracy is to keep power diffused.
Yeah. And that's, that brings us even deeper in disinfoil hat territory,
where you end up with that whole late-stage capitalism, ultra powerful
corporation. What's the, what sci-fi author built an amazing world out of that?
Neil Stephenson. An amazing world out of ridiculous, capitalistic,
cyber dystopia. Oh, are you talking about Snow Crash?
Among others, but everything in that universe.
Yeah. Yeah. And, you know, it was kind of awesome.
Snow, the world in Snow Crash was awesome.
The story was horrible, just so bad, but the world is amazing.
Wouldn't it be kind of neat to be able to move to a gated neighborhood that had
different laws from the neighborhood, the next one over so you could choose what
laws you wanted to live under? Yes.
But at what cost? I haven't read the books, but I'm assuming that there's some
monkey paw side effect here to where it's the the ultra far out liberalism.
Fire starts and three firetrucks are there in seconds because they each own
their own satellite that watches for fires.
Right. And they all walk up to the clipboard and bid.
All right. I'll put it out for 10 grand.
I'll put it out for five.
And that's, that's not a terribly efficient way to run a government.
We're well into just talking about fun books now.
Yeah. Anything else you guys want to talk about?
I feel like we we covered a bit of this.
We talked about ways to combat some of this, some of these problems.
I think I've got a question for you to the EFF.
That's great. And the other company, the other place you were talking about was
FSSF. Yeah. The FSSF.
Well, the FSSF built a lot of the free software we use today.
They're big advocates for it.
But the biggest thing is just be aware of this.
Be aware of what information they're collecting, voice your opinions, tell
tell companies you don't want this done and choose the companies
that do with the least.
If you can get Linux up on a computer, so you can at least have one,
you know, safer place to safer place to have stuff.
But these are all just, you know, the more options we keep,
the more likely we'll still be able to keep them into the future,
because we still have these options now and we might not always.
Would you guys like to help me with some listener feedback?
Sure, let's do it.
Chase, does that work with the guest?
You weigh in for fun.
Yeah. OK. Yeah.
You're on your own opinions.
And now, listener feedback with special guest, our Chase Barkley guest or I
feel so honored.
So this is from Gad B.
Bay, maybe Gad B.
B on the Reddit in defense of Aristotle.
It occurred to me that you might have not have checked the claim that
Aristotle didn't check his claim about women having fewer teeth.
So I looked into it some more.
My first finding is that Aristotle accidentally or not might be correct.
The mean number of teeth is slightly lower in women due to a higher
prevalence of hypodandia in women of European descent.
It also came across this essay on Aristotle and it links to an
essay called Rescuing Aristotle, which makes the good point that when
Aristotle made his claim about women having fewer teeth, he said,
it is well known that women have fewer teeth due to observations
that people have made like he was basing his claim on actual
historical observations at the time.
And also the average number of teeth people had back before dentistry
was probably highly variable in a lot of his writing.
It's pointed out that he is fairly up on empiricism, even if he
doesn't personally do it and the author of the essay made a great
point saying asking the reader personally, if the reader is male,
do you have a significant other in your life?
So let's Steven, do you have a significant other in your life that is female?
Yes.
Have you ever counted the teeth in her head?
No.
Do you think she has as many teeth as you do?
I do, but now I'm going to.
So when you said that someone actually checked and that there
could be some truth to that, I had to suppress laughter.
That I mean, that's hilarious.
And if that's true, it's only possible in the modern world to do.
Well, I mean, but it could be that if he did check if this was a quirk
of like Europeans 2000 years ago, if that's true, that's hilarious
because I always use that as my example of him not being a good empiricist.
Yeah, but no, I mean, I will counterteeth when I get home.
I think it's a good example of people being kind of hypocritical
because I have also quoted that and yet of the various people
that I have been intimate with, I have never counted their teeth.
And I simply accept that the professionals in our society,
the dentists and the educated people have counted teeth and know these things
and have transferred this information to me correctly.
And so I'm basically going on the exact same assumption
that Aristotle was going on.
Shit, the professionals in his time knew what they were talking about.
That's amazing.
OK, well, thank you for pointing that out.
And I will look into that and see how that looks today.
We have from Googleplex Byte, also on the subreddit.
Free speech isn't necessarily the optimal means of achieving the benefits
it supports a spouse.
As an ordoliberalist, I feel a system of competitive speech would be superior,
which like was kind of mind blowing me that there is a competitive speech system.
Ordoliberal theory holds that the state must create a proper legal
environment for the economy and maintain a healthy level of competition
through measures that adhere to market principles.
Similarly, it holds that the state should not just create a system
that allows a free exchange of information in the form of free speech,
but creates an environment for competitive speech.
The belief is that an optimal competitive market for information
would be the best means of providing perfect information.
This is relevant to the stance of balancing free speech against hate speech
as another tenant of an optimally competitive market is having no negative
externalities, which is a damn good point.
Hate speech has some negative externalities, right?
So in a competitive market for information, hate speech would be
information with negative externalities.
Thus, it would be the duty of the state to eliminate it or to offset
those externalities through a Pagovian tax.
And Pagovian tax for people who aren't familiar with the term is a tax on
things that have negative externalities to account for that and pay
back the people who are harmed by it.
I mean, that sounds like, especially given the context of today's
conversation, like a very slippery slope, criticizing the executive branch
or the government could have negative externalities and make me
will be less patriotic, less people sign up for the military, etc., etc.
So we're going to tax you every time that you say, I don't like the
current administration, we're going to send you a bill for a thousand dollars.
I mean, I'm obviously straw manning, but that sounds like a not implausible.
That sounds like free speech for the really rich.
Yeah.
The idea of taxing or otherwise disincentivizing speech with bad externalities
seems to have its own bad externalities.
Yeah.
And I think then there would be very costly legal battles going back
and forth constantly as to what creates negative externalities and what doesn't
and how much, how bad the negative externalities are.
Keep in mind that those negative externalities are already punished,
just not financially.
Yeah.
If I go outside and I say, I hate insert race here, somebody's going to call me a
fucking asshole, someone else isn't going to give me a job, someone else is
going to possibly hit me in the face.
I think in the context of the episode.
Right.
So, I mean, they're already violent, but I support the nonviolent disincentives
to being an asshole, right?
I suppose it depends on your society.
There's some societies were saying, I hate race blank will actually get you
praise and positive rewards, but in that society, I don't think, I don't know if
the government would be against you either, if you said that.
I mean, I guess it comes down to forging a decent society and the fact that we
don't necessarily trust a distant, large, powerful government to do it for us.
Yeah, I think that that's sort of the takeaway, at least from my perspective
as well, right?
So yeah, it was a very neat thought.
And I kind of like it because I'm a fan of markets and obviously a fan of
governments doing things to correct for massive market failures, like negative
externalities, but it seems like that would be very ripe for abuse for anyone
who wanted to stifle speech.
That's what I'm wondering is that the externalities of controlling all of
that or punishing it systematically seems like would have enough downsides to
make it not worth it.
It's possible that it could work, but I think that it would be a bigger shift
to get all the way there from where we are now than just to basically do what
we're doing now.
Uh, also on the whole punting Nazis thing, not without incident says, it's
not clear to me when violence is appropriate or necessary avenue for social
change.
Can everything be achieved non-violently?
It doesn't seem to be what we've seen historically with many positive changes
requiring at least the threat of violence, which I think I touched on as well
during that episode about, uh, how I feel like the Black Panther movement made a
big difference for the civil rights.
And it does seem to be the case that there does have to be a threat of violence
to change things, which is really unfortunate and sad.
And I don't want to be on board with violence because of that, but I don't
know, how do you feel about this?
Okay, Stephen.
No, can you paraphrase exactly what the that it seems like just demanding
things non-violently often doesn't work.
And there has to be some threat of violence as well.
Oh yeah.
That's that sort of change.
That's sort of where we came down on in the feedback episode, right?
That, you know, the example, I liked the one with the Trail of Tears example, or
like Japanese internment camps in the forties.
I mean, at some level just saying, I disagree with this, isn't enough.
And I think people are going to have to draw their own lines to when they're
ready to pick up a weapon and go, you know, go violently defend with their beliefs.
I'm not really, I'm not equipped for myself to even anticipate where I draw
that line, certainly where I would say you should draw the line here too, right?
I guess the main thing we're saying is that this line is the place where the
line is being drawn currently at it is okay to punch anyone who identify as a
Nazi is a bad line.
And we're trying to push against that.
We're saying put your line a little bit further down the road.
This is not a good place for it.
This is leading to too much wanton violence.
Yeah, that's, that's where I would come down now.
I mean, obviously the comeback we kind of already talked about, which is this is
just nipping it before it, you know, gets worse, right?
But I, I mean, if you're going to start punching people for slippery slopes, I mean,
that, that's also a kind of scary dystopia, right?
Yeah.
Not without incident goes on to say, I think the idea of
guilt by association is really important here, or maybe it's collective guilt.
I want to be clear that I would never advocate punching someone that just voted
for a policy I don't like.
On the other hand, I do believe in collective guilt in the sense that entire
groups of people, even those who weren't alive or voted against something can still
benefit from horrifically violent action.
IE reparations are a good idea.
This seems relevant because one problem you pointed in violent action is
assigning guilt and also assessing influence.
If someone is a literal Nazi, but essentially powerless, what good does
resisting them do?
In these cases, ignoring really does seem to be the best course of action.
When it comes to politicians or judges, as you referenced in this episode, things
are a bit trickier since they have some power, but the individual share of any
action the government takes is fairly minimal.
Obviously, a dictator is the other extreme and direct action against them would make
sense.
Again, I don't think it's an easy line to draw.
I have an interesting personal situation when it comes to benefiting from a
collective guilt of benefiting from horrific violence.
So he makes the case of reparations, which I don't want to get into because I
don't have a well-formed opinion on that.
That's a whole can of worms.
I don't want to touch it until I've thought more.
But in my specific example, my grandmother was in an area of Poland on my
mother's side that basically had been overpopulated.
Over the centuries, the land there had become more and more densely crowded.
And when my mom, when my grandmother inherited her land, there was just
barely enough land there for them to eke out a living and to feed themselves.
She was freaking out the entire time because there was literally not enough
land to divide among her children.
And we are talking like literally a peasant economy.
Her option was to give all her land to one child and he could live and
survive and the rest would starve or split it up equally between the children,
which is what the social norm was in their society.
And then all of them would slowly starve as they can't make enough food to
keep living forever.
And this was like a major source of war.
She would go to bed every night thinking, what the fuck?
How are my children going to live?
What's going to happen?
And then World War II comes around and a large chunk of land to her left is depopulated.
The Russian government comes in and says, Hey, you people over here, you're
going over to this area of Poland where there's plenty of land and where all
the Jews and Germans and other people that used to be there are dead now.
Their land is yours.
And she's like, Oh, thank God, no one starves.
So I am alive today in part because of the fact that she was gifted land from
the government due to the horrific violence of World War II.
And I don't know what to do about that.
Like I live in America now.
My mom is alive because of this thing happened.
But who do I owe money to?
Like what I see how I benefited.
I'm glad I'm alive, but I was born in 1980.
I should I send a check to some family in Europe that their grandfather was killed?
I don't know.
I don't know what this whole, I don't like the collective guilt thing because it
doesn't seem fair to me personally, I guess.
I also, yeah, I never liked the idea that you're responsible for what your ancestors did.
Like, how could I be blamed?
I wasn't even alive.
Like if I'm benefiting from it, I'm wary of those arguments, right?
So, like, I mean, I have an ancestor who lost a thumb in fighting for the north in
the Civil War and probably damaged his livelihood.
And I mean, so did someone cut him a big check or, you know, his descendants
because now his family wasn't as wealthy as they might have otherwise have been?
Like that sounds like a bullshit thing to say.
I mean, that I guess it's never really been cleared to me how to divvy those things up.
And so I've never, the other thing too, they're just like, you're responsible for
what your great grandfather did.
It's like, no, fuck that.
How can you be responsible if you weren't born?
It could be that there's an argument there.
If there is, be nice and send it my way.
I mean, it feels like collective punishment is kind of one of those things
that leads to genocide, right?
Yeah, when we had Alonso Fyfan earlier, one of his strongest arguments is that
the difference between a civilized society and a barbaric society, one of the
major differences is that a civilized society assigns guilt to who is guilty
and spends resources and a lot of effort into making sure that the guilty are punished
and the innocent are not.
And collective guilt is just a way of punishing the innocent.
It's a way of saying, well, I don't want to find out exactly which Arab was
responsible for blowing up my tower.
So I will punish all the people in this region.
Yeah, that sounds like a decent analogy.
I mean, I think people will just come back and say, well, we're, we are
punishing the guilty, we're just expanding our definition of guilty.
But that's, that sounds like bullshit to me, right?
So what else we got?
Okay.
Ooh, interesting one from Peregrine Tuch, which I still don't know if that's
your parents name, when we were talking about effective altruism, he says,
coming from Germany, a country with a relatively high tax rate, I give about
50% of my gross income to things like tax, public health insurance, public
social securities, public retirement, et cetera.
I personally do give a little, and in terms of EA, probably to the wrong causes.
However, the question I really had is, wouldn't it be better that we who care
would pitch in our money and effort to change the way that society as a whole
works, like the way that the government allocates resources when half of his
resources are going to the government?
I can touch that really quick.
Go for it.
In that it seems a lot easier for you personally to save a life or a bunch
throughout your lifetime, than it would be for you personally to change how the
government allocates its, its charity budget, right?
Or how the world runs.
So I mean, part of it is just what can you do?
You can, it's also not mutually exclusive.
You can do the third option, which is do both.
You can vote for candidates who advocate for more of a, you know, global
civilization slash tech care or whatever.
Um, and you can, you can also donate to, to causes that through at least some,
hopefully diligent looking into you find whether or not, and I'm not sure if this
came across super well in the episode that I think that people who are advocates
of effective altruism have things that they say that we should care about and
that these are the appropriate causes you should care about.
Like for example, the future of humanity.
And I, I tend to buy all those arguments, but that's not to say that that's the
only way to be an effective altruist.
You know, if what you really care about is curing, let's say it's
curing breast cancer, you know, it's, it's a limited scope, but that's your,
that's going to be your hobby horse.
And I'm, that's not a pejorative.
I'm just mean that that's going to be what you are going to focus on.
You can give it to whatever that really shitty foundation with all those pink
ribbons, um, common foundation.
Thank you.
Yes.
Where something like a nickel to your dollar goes to actual research and the
rest goes to awareness and branding and pink water bottles and shit, or, or you
can give to a better charity, which I should have been able to name one
off the top of my head, but I can't.
But the idea is that not, not so much that you care about the right things.
I think that's what some people would argue, but that whatever it is you do
care about, you're actually doing it, you're actually caring about it in a
way that makes you better at, makes you a more effective altruist, right?
I think that is the core and the most important point.
Although I will say that I think breast cancer in general is vastly
overexposed and overfunded and, uh, we would do much better as a society to
start looking at other things now, rather than hammering away on this one
thing that already has tons of things pouring into it and, and doesn't.
Yeah, that's it.
Well, I mean, it's big money.
That's why it's still so popular because so much money is going to branding
and all that stuff.
And everyone loves boobies.
I mean that too.
I think that's maybe why there's, why there's pink ribbons for breast cancer
and there's not a ribbon for colon cancer, but like lung cancer, you know,
people I think care less about because often you, like victims are blamed
because you know, a lot of them smoked or something.
I think that really the takeaway is just be the best altruist you can be while
focusing on the causes you care about.
You know, if you care about the environment, find what specifically you think
you can do to make an impact there, right?
So yeah, I think I know that there's been a lot of debate in EA communities about
whether systemic change is a good use of resources or not.
And the, the side that I tend to come down on is that for every $1 trying
to pull in one direction, saying that this is a good idea, let's pull society
this way, there's going to be a dollar pulling in the opposite direction saying,
no, let's move society in, in towards this instead.
And to me, it feels like a very big zero sum game where a lot of money is being
burned on both sides, getting nothing accomplished and just keeping the status
quo, which is one of the reasons I personally think that systemic change
on the government level is not very efficient.
But I mean, I don't know, on the other hand, if you didn't spend that money,
then would only the opposition spend money and pull things their way instead?
Sometimes it's worth it just to pull away from an undesirable outcome, right?
But the cool thing about that is that has the question of whether or not
donating to just two causes that are advocating or working for systemic
change is successful.
That is an empirical question.
You know, information will come down on that question one way or another,
and then we'll know what to do.
And if it does turn out that that's the best way to do it, real,
effective altruists will start donating to that instead.
Yeah, but a lot of people seem to say, within the effective altruist community,
let's not fight against each other on these social issues and instead focus
on things where we know that we won't be fighting against each other with money
and all going together at the same thing.
Like no one is, no one is for keeping malaria around.
So that makes it so at least you aren't burning money fighting each other.
Let me ask a question you guys may well want to add it out.
It's off, it's only tangentially relevant to this question.
I've been looking for a framework, a way to calculate with even a modicum
of reliability to apply future weight values, I want to say Bayesian values,
specifically on things in the future and future returns that are longer term.
Like the example we were fighting about, which is irrelevant, is all right,
we can assassinate the heads of these big, these big oil companies or however,
however happens, we can shut down this huge, big oil company, right?
And we can say, all right, five minutes that save no lives.
We were at negative and sure, 10 years, we might get back to positive,
but we have to rate those 10 year future so much lower than we're rating
these lives now because it's not certain.
Is there a real, is there a simple non textbook requiring answer to that,
to weighting future, I don't know, lives are a difficult one.
Let's not say lives, but to weighting future money to now money.
Like it always comes back to the economic argument.
And I don't know, you probably don't want this in user feedback, but no,
no, no, no, that's a great question.
If anyone out there has an idea, please email us or post something and let us know.
I personally do not.
I think a lot of it depends on how stable your situation is.
If your government looks to be on the verge of collapse, then obviously
you should be spending a lot more right now to get the most use you can out
of your money while it's still worth something.
Whereas if you think the situation will be very stable
and you trust society to to honor the money you have in the bank as actual money,
then you can think on a much larger time scale.
Yeah, I guess that that always my big question with effective altruism is how
big can I reasonably put my time scale?
You know, there's a big difference between saving lives today
and potential lives in the future.
And the way to weight that is really difficult and sounds like the best thing
you can do is the weight apply much, much lower weights to future lives
and fix the ones you 100 percent can.
I think the Bayesian way to do that is just to take however many lives
you anticipate you might save, multiply it by whatever percentage
that might encompasses and then go with the solution.
Yeah, so I think I don't think it's that hard of a question.
Like and that's why I think that many effective altruists care about things
like the future of humanity or, you know, safe AI or whatever it is
that will keep humanity from dying out.
So like say the really dumb example is like that's like giving all of your money
to breast cancer awareness and spending none on food, right?
Like if you knew that we're 10 years off from a big meteor strike,
you used to donate really you just do whatever you can to keep that
meteor from hitting Earth and because even if like maybe if it was
had a 50 percent chance of hitting Earth, you know, even then you should still
do everything you can because the one and two chance that life has wiped out
then all of the causes you care about no longer are are being so I guess it is
really just about getting running some really detailed math to figure out
that real chance of it in the future happening.
If there's a 50 percent chance of it hitting Earth,
you should probably donate 50 percent of your money.
Well, I mean, that's probably like the biggest threat that we can that
that's possibly happening, right?
But I mean, it really depends on how likely it is that the future will get here.
If you think there's a good chance humanity will still be around in 100 years,
200 years, then yeah, invest in things that will make a difference 100 or 200 years out.
If you don't think that humanity will be here in 100,000 years,
then don't bother with things that will make a big difference that far out.
Although I can't imagine anything that would make a big difference that far out.
You know, you and I both making investments to a distant future right now.
We're both son of a cryonics on the on the small percent chance
that that we arrive in a desirable future.
We're both think that's worth like a hundred thousand dollars now.
A hundred years out.
There are a lot of things I can think that could have effects.
A hundred years out. Most medical research.
A hundred thousand. Oh, I'm sorry.
No, like even cryonics, I expect to pay off way before a hundred thousand or else not at all.
Yeah, no, I agree.
But like that's the idea is that you take whatever your expected outcome is,
which is really for me approaching infinity, you know, or not even infinity,
but you could say it approaches a hundred trillion,
whereas the average hundred year lifespan and, you know, can go up to like five thousand.
And so just the idea that you could live a better life and a longer life.
If awoken, what was the word we liked back then?
If you're revived from chronic preservation in a desirable future,
the expected positive outcome is huge.
And so it's worth, you know, whatever twenty seven dollars a month right now for me, right?
And for people who don't expect to make it to the age of 30,
it makes a lot of sense to go ahead and just drink and smoke
and take part in fun but dangerous activities
because you're not going to live long enough
to have to deal with lung cancer and liver failure anyway.
Who's expecting not to make it to 30?
I know a lot of people, not personally,
but I know of people in inner cities who don't figure that they'll make it to 30.
Oh, that sucks.
Yeah, they're like or someone who maybe lives in a war torn area.
It just there's a good chance I won't live that long.
So fuck it.
And I don't know what specifically you're talking about,
but it seems to me like, well, I could spend all my money on boozer cigarettes
or I could spend all my money on a good pair of shoes
and just walk out of wherever the shitty area is, right?
Yeah, well, my my brother was in the military
and one of the jokes in the military is I should quit smoking
because these things will kill you.
Because when you're in an actual active duty zone,
like my brother was in Afghanistan,
that seems like the most far away stupid thing to worry about.
That's a fair point.
But I mean, he's not in there anymore and he had to quit smoking,
which is a pain in the ass and a lot of people don't.
Yeah.
So maybe he should have been a little bit more future minded at that time.
Yeah.
And I mean, there's all kinds of ovens and outs there,
but I feel like we're getting now a little far abroad.
But that is a good point that I mean,
if you're weighing against long term outcomes or your long term prospects are lower.
Certainly, if you're in Afghanistan too,
the suspended suspended animation Incorporated can't fly out
and take you back to Michigan and freeze you, right?
So really nothing you do like is going to have the that outcome
that we're talking about with cronics.
So and for a less extreme example,
I I have always believed I live in a very stable society
and with decent prospects for the future.
So I've spent a lot of my effort into investing in future things.
And recently I lost about $40,000.
And it really I feel like I should have spent more money in the past,
because at least then I would have gotten the use out of it.
I didn't realize I was in as a precarious situation as I was.
And if I was more correctly balanced,
I would have had a bigger discount value for the future.
I would not have valued the future income as much
and I would have spent my money and got use out of it at the time.
I mean, this is a situation where I would have been better off
spending money in the past rather than
saving up for the future because of what happened.
True. But probabilistically, that might not have been the case, right?
This could have been like a one in four outcome
where still you were better off investing
because you had a better chance of it working out.
That's true. And the dice just came up the wrong way.
Yeah. Yeah.
So I don't know if that's really want to generalize.
Yeah. But it does suck.
And it did really clarify in my mind
that there is a good reason to have some discount for the future
because the future isn't 100 percent certain.
And if the future is anything less than absolutely 100 percent certain,
there should be some discount for future results.
Yeah. I mean, Chronix is not my best bet for living forever, right?
What I'm hoping for is that technologies like life extension
technologies will take off before I die
and I could take advantage of those technologies.
So the more baskets your eggs are, the better.
And it is a weird thing to advocate for,
to have a non-zero future discount
because I remember reading somewhere that even a one percent discount rate
means that all lives after further than 200 years out
are worth essentially zero to you, which mathematically,
I suppose is the case.
But I think I personally wouldn't put it at everything
past 200 years out is worth a zero.
So I guess I don't have a perfectly linear discount function either.
I think that's fair.
Any other feedback we want to touch on?
I want to take this opportunity to say that audio editing
and mixing is done by our sound engineer Kyle Moore,
so mad props to him.
And also to let our Patreon subscribers know
that there is another little bonus mini content up on Patreon.
It's just 10 minutes of us talking about our personal lives and crap.
Let's joking around this time, but you know,
still a little extra bonus.
There was one little comment that I liked
from a Ropus777 on the subreddit.
You're linked to a product at neptunic.com.
That's like a shark suit.
And this was in response to the Max Harms episode
where we talked about fiction.
And I griped about how bad people are in zombie movies.
And it's like this, this shark proof suit.
And then you said that would be perfect for zombie apocalypse.
I'm like, you're exactly right.
That is what I would want.
Unfortunately, I have no idea how much they cost.
You have to email the person for cost,
which tells me it's probably a fortune.
So otherwise they would just list it.
But there's an actual photo of a shark chomping down on a dude's arm.
The dude's just like, yep, come at me, bro.
Yeah, good luck.
If good luck for a zombie to get through all that.
So I think that's pretty cool.
Anyway, fun little light thing to end on there for now.
Cool. Thanks for listening.
We will be back in two weeks.
Great. Thanks.
Bye.
Bye.
She's got to say bye too.
Bye.
I'm going in blind.
Fuck it.
Let's do this.
