I'm like, that is distracting right now.
Cupcake.
That's distracting.
That's another question for you.
Please, grandma.
How big your eyes are.
If we all have different perceptions of reality, how do we get close to what exists in the
territory?
You're skipping ahead slightly.
Sorry.
It's okay, but I can go ahead and skip to that if you would like.
The part of rationality is the process of making sure that reality changes your beliefs,
that your beliefs are entangled with reality, and you're not trying to force your beliefs
onto reality.
You are letting them be manhandled and mauled and destroyed in any way that reality needs
to destroy them so that reality is affecting what you believe.
This includes things like knowing what standards apply to evidence and just being familiar
with the scientific method in general, accepting critiques that if you hear a critique of your
position from someone else, you don't dismiss it out of hand because it's not what you believe.
You take it into consideration and especially if they have good evidence for their side.
A litany I really like is what is true is already so and acknowledging it doesn't make
it worse.
So if you really, really don't want to go to the doctor because that mole is, you don't
want to know that it's cancer, the thing is it either is or isn't cancer already.
And if you find out that it's cancer, that doesn't make anything worse in reality.
All it does is make your map more accurate.
So never shy away from knowledge that may hurt because it can only help you.
And in my opinion, these are the sorts of things that people who have a like internal
desire, like a real need to know the actual truth will come to eventually when I, I got
to thank my parents for their religious upbringing because in my religion, it was very big about
the religion is the truth and the truth is really important and we must spread the truth
to people.
And so I was deeply ingrained with this love and desire to have the truth all the time.
And eventually you start asking yourself things like, how do I know that what I think is the
truth is actually the truth, you know, the fundamental question of rationality?
How do I know what I know?
Why do I believe what I believe?
And anyone who cares enough about the truth will eventually ask themselves that question.
And then they will, in my opinion anyway, then they will start seeking out methods to
verify what they believe.
And they will eventually stumble across the scientific method or, or rationality or other
similar methods of finding out what is true based on empirical research.
So that that's a big part of it is to make sure your map accurately flex the territory
by using these tools.
Now an important part of this, I actually had this earlier, but this works out really
well.
An important part of having a good map is being able to update your beliefs when you do run
into this, when you do run into new evidence, which is where Bayes comes in.
And I believe we mentioned in the last episode, a link to a good, intuitive, easy explanation
of Bayes theorem.
It's still not the easiest thing in the world, but it is the concept that it's how to integrate
new evidence that you find into your current beliefs to update them in a direction that
puts you closer to what reality actually is, puts your map closer to the territory.
And one example that I got, which I really like is that Mormons are told that when they
read the Book of Mormon, Mormon, they will know that it is the truth because they will
get this warm, glowy feeling in their heart.
And the question, the Bayesian question of that is, what is the, if you do read the Book
of Mormon, what is the likelihood that you will get a warm, glowy feeling in your heart
if there is a God versus what is the likelihood of getting the warm feeling, glowy feeling
in your heart if there is no God?
If there's still a lot of things that could cause the warm, glowy feeling upon reading
that are not to the God, then that's not very good evidence.
If you know, if it's written very poetically and it is inspiring to you and there's cultural
baggage behind it and you've been told this will make you feel warm and glowy, there's
psychologically a good possibility you will feel warm and glowy even if there is no God
in our universe.
So it's not great evidence.
Can I interject there?
Sure.
I've read, I tried to read part of the Book of Mormon because I picked it up from a hotel
and I can't, I personally can never, cannot imagine feeling warm and glowy while reading
it or even being able to get past the first page.
Thank you.
I was going to say something similar.
I have a copy out there and I was going to mention how it's written in terrible, like
fake sounding 17th century English and you know, it was written 150 years after people
talked or anything like that, but according to you non-believers.
Well, so the other thing to keep in mind is that I think that there are other examples
of introductory bays and what you mentioned was more akin to I think the conjunction fallacy,
right?
So you feel, well, it's basically a formalization of extraordinary claims need extraordinary
evidence.
Yeah.
Okay.
Fair enough.
It's not time for conjunction fallacy yet.
Yeah.
And this goes back to the actually the UFO theory that I think two episodes ago, not the UFO
theory, but my UFO experience a few episodes ago, one of the things that I thought when
I saw that light and had this overwhelming feeling that aliens were coming to get me
is, is there other things that can explain this feeling as well or better than aliens
actually coming?
I suppose nothing would explain it better than aliens actually coming.
But are there other explanations as well?
And yes, there were lots of other explanations.
Therefore simply that feeling and that light was really shitty evidence that aliens were
actually behind me.
So it's important to keep in mind that something did explain it better than aliens actually
being it because it turned out not to be that.
Right.
So whatever turned out to be actually did explain it better.
Yeah.
Yeah.
And then if you do have the alien hypothesis, there's all these other questions like why
are they visiting Podunk me in, you know, a suburb of Denver as opposed to going to
the president?
Why are they even landing on our planet as opposed to using it for whatever they need?
Yeah.
Yeah.
It's a stupid hypothesis.
It's a large hypothesis.
Yeah.
Isn't sufficiently answered by saying, well, they wanted my cattle or to ruin my crops
or something.
Whatever does the aliens have to do?
Yeah.
So you have degrees of belief in your map.
You update your map based on evidence.
You make sure that you have good evidence and you know what constitutes good evidence.
Next on the list here is it puts a rationality puts a lot of emphasis on knowing what flaws
you have in thinking or knowing what flaws are common and correcting for them.
The analogy for this is the analogy that I like anyway is that if you have a camera
and you look through, you know, you look through the camera through the lens and there's a
spot where there's a building that's like really wonky.
It's like the lines are everywhere and you're like, wow, that is a crazy ass building over
there.
And you just assume there's this weird building in your field of vision.
But eventually you may come to the conclusion that it's not a weird building.
There's a chip in your lens right at that spot.
And it's something that you don't know at first, but you can find the chips in the
lens that you look through if you put enough effort into it.
And once you know there's a chip there, you can adjust for that.
Cupcake?
Yes.
Cupcake?
Are you talking about biases?
I actually am.
Yes.
Oh.
And I thought how to overcome those biases.
Excellent.
Yes.
So you know, if you can, you look at it from other angles as well, or you ask other people
what they see, or you simply know that there is a flaw there.
And so whatever is behind that flaw cannot be trusted as entirely reliable.
And I think a wonderful, very top timely example of that is politics.
Humans have very ingrained emotional reasons to take sides in politics and to defend their
sides very strongly regardless of how true they may be.
So the classic term is politics is the mind killer.
Whenever politics gets brought into the discussion, you have to be aware that you may not be seeing
things clearly.
Emotion is likely to rule because of evolutionary reasons.
So be very careful at that point.
Apply your tools more than you would in other cases because it is a mind field for thinking.
Be very vigilant in that field.
One way to help overcome that is if you happen to be a friend with anyone who's historically
savvy, you can discuss whatever current topic that you're having a deliberation about in
the context of, you know, whatever, 1700 France.
And then that way that it puts some distance between you and the topic rather than it being
part of your identity like people's current politics are.
It also often helps to have friends who you know are smart and you respect that are on
the opposite side of you.
I do have a few Republican friends and that's that's the whole getting a picture of the
same area from a different camera.
It's you know, you can see if they can explain it well and you can listen to them long enough
to get their explanation.
You can see some other parts of reality that you would not have seen otherwise.
If you haven't had a conversation with somebody that you disagree with politically that you
acknowledge as otherwise smart, you owe it to yourself.
It's those are some of the most rewarding discussions I've ever had are with people
that are on the other side of political topics than I am.
And if you can both keep calm and and share your ideas and defend them, the consensus
from these people and myself when we come away from these conversations is that we both
feel better and smarter.
So talk and learn and grow.
It's great.
The one one example that I like a lot is orchestra recruiting.
Is it recruiting hiring?
When people hire players for an orchestra out when, you know, someone else retires and position
opens up, they used to just watch them play and then decide from that.
But the theory is that they want whoever plays the best.
And they came to realize that there are some biases biases in their choosing, which they
weren't.
I mean, as much as they were like, no, I'm not sexist, I'm not racist.
As much as they were confident they were making decisions just based on what they were listening
to, the hiring data didn't necessarily bear that out.
So they blinded themselves by putting up a screen, which helped things a bit, but they
found that they also had to put down padded carpeting to go behind the screen.
Because if they heard someone in heels walking to it, the hiring rate would go down just
because they heard heels.
It was an unconscious bias, not these people were sexist.
But once they put in the padded carpeting and the blinds, women started getting hired
at a much higher rate than they had been previously.
And that's a good way of when something's brought to your attention, you can take steps
to mitigate it.
Yes.
And if you rewrite your unconscious beliefs, since that's probably impossible, just taking
outward steps to fix it is a great way to adjust for solving that problem.
And I thought that that's a great example.
It is also, in my opinion, an example of where stated preferences diverge from actual preferences.
