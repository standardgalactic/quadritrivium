or carry a massive social taboo that you buy into and taking the time to deconstruct that
and and figure out what the actual what the truth is.
A lot of these are incest.
That's more of a should statement than a factual statement.
But as a rationalist, I can change my mind about should statements to be a better person,
a kinder person and a more accepting person.
I think should statements are just as important because a lot of it is what we want to know
is what we should do, right?
And what the way things actually are greatly impacts that.
But that's one of the reasons we're figuring out what things are so that we know what we should
and shouldn't condemn or promote.
Absolutely.
So that's a good example of finding a good place if you want to get some practice.
I think if you've already lost your religion or if that's not something that you want to start
first with or ever.
I'm not going to say you have to be an atheist, but find something that you find just repellent
bestiality as long as we're on the sex scene.
I'm still working on that one.
I'm still working on that one.
That's tough.
My general consensus on it now is as long as you're not hurting the animal,
at the very least you could probably do something better with your time.
But I'm not going to go out there and tell people.
I'm not really going to comment on it, but I will say I wanted to say the biggest thing
that I changed my mind on away from the sex thing, at least away from the animal and sibling
fucking the biggest thing I changed my mind on.
And it was fairly early in my introduction into the rationalist community was death.
I lost my religion at some point in my I don't know if I ever really had it.
We touched on this earlier in a previous episode, but there were a few years where I
went through and I'm like, I'm going to die and the world's going to be, you know, my god.
And, you know, I found some solace in the whole Mark Twain quote about, you know, like,
oh yeah, but you were dead for millions of years before you were alive and, you know,
be back there.
It's like, I won't be freaked out, but like, I still don't want to be there.
I'm glad that I'm not in that pre-birth state.
I don't want to return to that when I die.
And in one of my favorite books called Unweaving the Rainbow by Richard Dawkins,
he has this great poetic analysis of what it's like to live and die.
And he talks about how we're going to die and that makes us the lucky ones because the number
of potential people so vastly outnumbered the number of actual people and the fact that you're
alive right now is so statistically improbable that it's like a miracle.
Get out there and enjoy it.
I found a lot of solace in that and it is.
But then I, so this is kind of the opposite.
This is related to looking at a yuck reaction, looking at something that terrifies the hell
out of you.
So when I finally got around to re-examining that, I said, no, Dawkins, that's great.
And if this was 100 years ago, I'd be on board with that.
But I can't resign to just die if there's any way around it.
So after some deliberation, I signed up for cryonics.
I make an effort to, I mean, I just never like, I guess, what am I trying to say?
You changed how you lived your life.
A bit, yeah.
In accordance to a change in your opinion.
Yeah, I think so.
I fully hope to live to be as long, as old as I want.
Let's put it that way.
So yeah.
So you did some soul searching.
You looked at evidence.
You looked at other thoughts about death and dying that were out there.
And you changed your mind and that's an okay thing to do.
For sure.
And I think that's the, you know, and if I change it back, that's great too.
But this is one topic where there is some, there's not a strong consensus.
I think that in the rationalist community, at least that I've seen, maybe there's some,
some data on Scott's blog, but that's something that I feel like not a lot, not enough people.
They're, I mean, they're, if we were talking about death, there isn't a strong consensus,
but they're, it's still much more, we're still much more anti-death than the general population.
Oh, yeah, for sure.
Then higher than the base rate, but I've been, while I'm imagining it's something like 80%
utilitarian, I'm not sure what percentage are, are anti-deathists.
All right, we both said something.
What did you put something?
You were talking about how there are a lot of people who are very interested in longevity.
And I think in the rationality movement, and I think that goes along with people who are
interested in superintelligence and artificial intelligence.
Those are also more, more common concerns within the rationalist movement too.
Transhumanism in general.
Yeah.
And transhumanism is basically the thesis that it's okay to have aspirations beyond
what biology gave you as far as for your own physical well-being.
And I did explain this to my grandma once.
Yeah.
I said, grandma, we're both wearing glasses.
Neither of us are content with what nature gave us.
Now, I think that's kind of a cheap shot for transhumanism because it's not,
or it's a cheap, it's a cheap point rather.
It's a good point.
It is, but it's not the same as like brain augmentation or, you know, synth body upload,
whatever, right?
So it, it, but it generated, it illustrates the general concept.
It does.
Cheap and easy are different things.
Yeah.
Fair enough.
Yeah.
So what's something you've changed your mind on?
Wait, before we do that, did you have anything else on your list?
Unrelated, but I was going to give another example of, of Bayesian updating.
There's, there's the traditional example that I really like.
And if you also have any of this.
What's the traditional example?
Well, if any of the, the talk of Bayesian probability or probability theory in general
is fun to you, check out Leonard Mladenov's book, The Drunkard's Walk,
How Randomness Effects Our Lives.
That's my book pitch for the day.
The, one of the, one of the classic examples for just illustrating what Bayesian updating
is to somebody is say you're approached by a mathematician pushing a stroller with
two swaddled babies in it and you can't tell what sex they are.
And you ask, is at least one of your children a girl?
And the mathematician says, yes.
So then you can ask yourself, what is the probability that they're both girls?
And the point to illustrate here is that before asking that question,
the probability that both of those babies are girls is one in four.
Because you have boy boy, boy girl, girl boy and girl girl as the four options.
After confirming that one of them is a girl, you knock off that boy boy option.
So now you're not the chances that they're both girls is one in three.
In other words, you've been given more information so you can update your probabilities.
Exactly. And there's, there's an exact amount to which you should update your, your belief
by based off of the, just the number of possibilities that there were.
So that's, that's one of my favorite examples because it illustrates updating
and it's really simple fractions.
So one of the ones I like that's just very simple and that I don't know
a decent percentage of people don't get is if you flip a coin 10 times
and the first nine times it comes up heads, what is the probability that it's going to
come up tails on the 10th flip? 50 50.
Right. But a lot of people will say it's a much greater probability that it will,
that it will come up tails because it's come up so many times it's due for it to be tails.
And that, you know, it's incorrect because you have more information now.
But if you would have asked before the flip started, what are the chances that you'd get
nine heads in one tail, you'd say extremely low.
But if you've already flipped the coin nine times, the two options that are left are heads
or tails. So it's a 50 50 shot.
Well, that said, with nine out of 10, it'd be less strange to me.
But if it was 999 times out of 1,000, I would say we have an unfair coin.
Right. Yes.
And so then then you can use your your Bayesian updating to say, look,
the fact that it had had so many times, it is not one in two.
I'm willing to bet more than I would bet whatever I'm willing to bet.
Yeah, that you're cheating.
Yeah, or that or that for whatever reason.
It's going to be heads.
Exactly.
So.
So, yeah.
Yeah, but I like that one because it's a demonstration of the fact that probability
is in your probability is in the mind, not in the reality.
Probability is an aspect of the map, not of the territory.
Like if you roll the dice and you cover it with a cup and you ask someone what is the
chance that it's a six, whatever it actually is, it's 100% of what it is.
Right.
In the reality, it's either 100% of six or 0% of six.
But what the probability is that it's a six is one out of six,
because you don't know what it is.
So you have to give equal probability to all options.
Right.
So then that's exactly as probability exists in the mind, not in the territory.
It is six or not in your prior estimate.
So when people talk about Bayesian statistics, they'll often use the word prior.
That's just the the word that they use for initial estimate.
You know, if I pull out a quarter and say heads or tails,
your initial estimate is going to be 5050 after 1000 throws.
And it's if we're getting some weird results, you can then your new estimate,
your posterior probability is going to be your updated estimate.
Excellent.
Any fun things you've changed your mind on?
We never asked.
You gave the the incest example.
That's why we never ask Katrina what she would say to her grandmother.
Oh, I'm so sorry.
Yeah.
Well, again, yeah, she's covered some great things that one should say to one's grandmother,
I love the map and territory.
That's a it's really good getting into what reality is the idea that we believe in an objective
reality one that exists no matter what's going on in your head.
And so you covered a lot of great points.
I think I might in addition tell my grandma that rationality, the rationality movement
is about living your life as a scientist and applying what you do as a scientist and and
how you look at data and how you look at evidence to everything.
I'm curious, being curious and wanting, you know, wanting to learn and wanting to know.
And this doesn't mean getting a PhD and running a lab experiment.
I like Carl Sagan had a great quote.
Whenever you check your belief against reality, you're doing science.
And by that by that standard, I completely agree that anytime that it's not enough just to have
your little belief in your head and just leave it there unchecked and believe in it strongly.
If you can test it, go out and look and see if you're right.
And if you're not, you should want to change your mind.
That's that's another key component to rationality is not just having a map territory
distinction and having mental models, but wanting those models to be accurate.
Katrina, as your grandfather, I'm worried about this rationality thing.
Why don't you believe in things like love anymore?
Why do you think it's so irrational to feel emotions?
You really do just have the one old guy voice.
I don't at all.
I just want my emotions.
I want my emotions to be more in line with reality and what I see as, you know,
as reality in the best course forward.
But doesn't Spock always say that emotions are highly illogical?
I think actually you're bringing up a really good point, Grandpa.
