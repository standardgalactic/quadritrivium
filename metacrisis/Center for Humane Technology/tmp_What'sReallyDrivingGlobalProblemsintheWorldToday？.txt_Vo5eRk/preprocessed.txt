Welcome to Your Undivided Attention. Today, I am so honored and happy to have my friend
Daniel Schmacktenberger as our guest who works on the topics of existential risk and what
are the underlying drivers of all of the major problems or many of the major problems that
are really facing us today as a civilization, be it climate change, breakdown of truth,
social media, our information systems. Those of you who've been following Your Undivided
Attention will hear this as a very different kind of episode. We almost think of it as a meta
episode about the underlying drivers of many of the topics that we have covered on Your Undivided
Attention thus far. So if you think about the topics that we've covered, whether you've seen
the social dilemma or you followed our interviews previously on topics like attention span shortening
or addiction or information overwhelm and distraction, the fall of trust in society, more
polarization, breakdown of truth, our inability to solve problems like climate change, well this
is really about an interconnected set of problems and the kind of core generator functions that
are leading to all of these things to happen at once. And so I really encourage you to listen to
this all the way through and I think that we're going to get into some very deep and important
knowledge that will hopefully be orienting for all of us. One of my favorite quotes is by Charles
Kettering who said that a problem not fully understood is unsolvable and a problem that is
fully understood is half solved. And what I hope we talk about with Daniel is what about the framework
that we are using to address or try to meet the various problems that we have has been inadequate
and what is the problem-solving framework that we're going to need to deal with the existential
crises that face us. So Daniel, welcome to Your Undivided Attention. Thank you Tristan. I've been
looking forward to us dialoguing about these things publicly for a while. Well you and me both
and for those who don't know Daniel and I have been friends for a very long time and his work has
been highly influential to me and many people in my circles. So Daniel, maybe we should just start
with what is the metacrisis and why are these problems seemingly not getting solved whether it's
the SDGs, climate change, or anything that we really care about right now. I think a lot of
people have the general sense that there is an increasing number of possibly catastrophic issues
and that as new categories of tech, tech that allows major cyber attacks on infrastructure,
tech that allows weaponized drone attacks on infrastructure, biotechnologies, artificial
intelligence and moving towards AGI, that there are new catastrophic risks with all of those
categories of tech and that those tech are creating larger jumps in power faster than any
types of jumps of tech including the development of the nuclear bomb in the past by many orders
of magnitude. So there's a general sense that whether we're talking about future pandemic
related issues or whether we're talking about climate change or climate change as a forcing
function for human migration that then causes resource wars and political instability or
the fragility of the highly interconnected globalized world where a problem in one part
of the world can create supply chain issues that create problems all around the world,
there's a sense that there's an increasing number of catastrophic risks and that they're
increasing faster than we are solving them and that when you mention like with the UN
while progress has been made in certain defined areas of the sustainable development goals
and progress was made back when they were called the millennium development goals
we're very far from anything like a comprehensive solution to any of them we're not even on track
for something that is converging towards a comprehensive solution and if we look at kind of
the core initial mandate of the united nations in terms of thinking about how to recognizing after
world war two that nations take government alone wouldn't prevent world war and now that world
war was no longer viable because the amount of technology we had made it a war that no one could
win we still haven't succeeded at nuclear disarmament we did some very limited nuclear
disarmament success while doing nuclear arms races at the same time and we went from two
countries with nukes to more countries with better nukes and that's simultaneous to that every new
type of tech that has emerged has created an arms race we haven't been able to prevent any of those
and the major tragedy of the commons issues like climate change and overfishing and dead zones
in the oceans and microplastics in the oceans and biodiversity loss we haven't been able to solve
those either and so rather than just think about this as like an overwhelming number of totally
separate issues the question of why are the patterns of human behavior as we increase our
total technological capacity why are they increasing catastrophic risk and why are we not solving them
well are there underlying patterns that we could think of as as you mentioned generator functions
of the catastrophic risk generator functions of our inability to solve them that if we were to
identify those and work at that level we could solve all of the expressions or symptoms and if
we don't work at that level we might not be able to solve any of them and again people have been
thinking about this for a long time kind of notice these issues they notice that you try to solve a
like the first one I noticed when I was a kid was trying to solve an elephant poaching
issue in one particular region of Africa that didn't address the poverty of the people that
had no mechanism other than black market on poaching didn't address people's mindset towards
animals didn't address a macro economy that created poverty at scale so when the laws were put in
place and the fences were put in place to protect those elephants in that area better the poachers
moved to poaching other animals particularly in that that situation rhinos and gorillas that
were both more endangered than the elephants had been so you moved a problem from one area to another
and actually a more sensitive area and we see this with well can we solve hunger by bringing
commercial agriculture to parts of the world that don't have it so that the people don't either not
have food or we have to ship them food but if it's commercial agriculture based on the kind of
unsustainable environmentally unsustainable agricultural processes that lead to huge amounts
of nitrogen runoff going into river deltas that are causing dead zones in the ocean
that can actually collapse the biosphere's capacity to support life faster than we're
solving for a short-term issue that's important and driving even worse long-term issues we see
that many of the reasons people who oppose climate change solutions in the west oppose them is because
not because they have even really deeply engaged in the underlying science and say
the climate change isn't real that will oftentimes be what's said but because the solution itself
seems like it'll cause problems to other areas that they're paying attention to that seem even
more critical to them so if the solution involves some kind of carbon tax or something that would
decrease GDP for the countries that agree to it and some other countries don't agree to it and
let's say in this particular case the model that many people have is western countries agree to
it their GDP growth decreases China doesn't agree to it and there's already a very very close
neck-and-neck fight for who controls power in the 21st century are we ceding the world to
Chinese control that many people would think it has less civil liberties and is more authoritarian
in its nature and so or some people's answer to climate change is what we just have to use
less energy but when you understand the energy correlates directly to GDP and when GDP goes down
it affects poverty people in extreme poverty first and worst and wars increase because
people who have desire to get more end up going zero sum on each other and only when it's very
positive some does that not happen you see all these intricate theory of trade-off so we can't see
that the problem is climate change everybody knows problems you know the problem of climate change
seems like a big thing but you've got to look at climate change plus the macroeconomic issues that
would affect the poorest people and that would increase the chance of war and the geopolitical
dynamics between the west and China whatever and the enforcement dynamics of international
agreement when you start to recognize that the problem is that suite of things together in a
way it seems well that's too hard we can't even begin to focus on it I would say that that's actually
easier because trying to solve climate change on its own is actually impossible because if
you're trying to solve something that is going to externalize harm to some other thing maybe the
other thing that you maybe you solve that thing but you find out that you're in a worse position
so I would say that it's impossible to actually improve the world that way or half the world that
is paying attention to that other thing disagrees with you so vehemently that all the energy goes
into infighting and whatever some part of the world is trying to organize to do the other part of
the world is doing everything they can to resist from happening then all the creative energy just
burns up as heat and we don't actually accomplish anything so I would say that the way we're trying
to solve the problems is actually mostly impossible it either solves it in a very narrow way while
externalizing harm and causing worse problems or it makes it impossible to solve it all because it
drives polarization and so going to the level at which the problems interconnect where that which
everybody cares about is being factored and where you're not externalizing other problems well it
seems more complex is actually possible impossible is easier than impossible and so it's not just
that there's a lot of issues right there are a lot of issues and just that the issues are both
more consequential at greater scope and moving faster than previous issues because of the nature
of exponentiating technology that's part of it it's not just that the problems are all interconnected
it's also that they do have underlying drivers that have to be addressed otherwise a symptomatic
only approach doesn't work the first underlying driver that when people look at it they generally see
is they see things like structural perverse incentive built into macroeconomics that
the elephant dead is worth more than the elephant alive is and so is the rhino and so is the and
so how do you have a situation where that's the nature of incentive where you're incentivizing
an activity and then trying to bind it or keep it from happening and the same would be true with
overfishing as long as live fish are worth nothing and dead fish are worth more and you have there's
something fundamentally perverse about the nature of the economic incentive and the same is true that
when war goes when we have war and there's more military manufacturing GDP goes up and when there's
more addiction and people are buying the supply of their addiction GDP goes up and when there are
more sick people paying for health care cost GDP goes up so it's obviously a perverse kind of metric
so anytime someone can fiscally advantage themselves or a corporation can
in a way that either directly causes harm or indirectly externalizes harm
we have to fundamentally solve that if there's something like 70 trillion dollars a day of
activity happening that is a decentralized system of incentive that is incenting people to do things
that are directly or indirectly causing harm there's really nothing we can do with some
billions of dollars of non-profit or state or whatever money that is going to solve that thing
so we have to say well what changes at the level of macroeconomics need to happen where the incentive
of individuals and the incentive of corporations and the incentive of nations is more well aligned
with the well-being and the incentive of others and so we're less fundamentally rival risk in the
nature of our incentive so we can see that underneath heaps of the problems structures of macroeconomic
incentive are there that's the kind of maybe the first one that most people see we can go deeper
to seeing that even as an expression because whether it's a economic incentive for a corporation
or whether it's a power incentive a political power incentive or a political party or for a country
they're both instantiations of rival risk type dynamics that end up driving arms races because
if you win at a rival risk dynamic the other side reverse engineers your tech figures out how to make
better versions comes back which creates an exponentiation in warfare and eventually exponential
warfare becomes self-terminating on a finite planet exponential externalities also become
self-terminating so if we want to say what are the underlying generator functions of catastrophic risk
first maybe just to make clear the catastrophic risk landscape is this all right if we do a brief
aside on that yeah let's do it and then we're I think what we do let's do that and then let's
recap just what these structures are so people are tracking each of these components because
you've already mentioned a few different things I mean the first thing is just many listeners
might hear what you're sharing as an overwhelming set of problems and I think it's just to recap
it's important people understand that it's overwhelming if you're not using a problem
solving framework that allows you to see the interconnected nature of those problems because
if you solve them with the limited tools we have now let's just solve the social media problem by
pulling one lever and changing one business model of one company or banning TikTok but then
you get 20 other TikToks that come and sit in its place with the same perverse incentive of addiction
the same rival risk dynamic competing for human attention we're going to end up perpetuating
those problems and so just to sort of maybe recap some of that for listeners and I think maybe let
you continue with the other generator function let's just make sure that people really get
those frameworks I think it's really important yeah I mean in the case that you in
Center for Humane Technology have brought so much attention to with regard to the attention
harvesting and directing economy it's it's fair to say that it's probably was not Facebook or
Google's goal to create the type of effects that they had those were unintended externalities
they were second order effects but they were trying to solve problems right like let's solve
the problem if we're Google of organizing the world's information and making better search
that seems like a pretty good thing to do and let's solve the problem of making it freely
available to everybody that seems like a pretty good thing to do and with the ad model we can
make it freely available to everyone and let's recognize that only if we get a lot of data will
our machine learning get better and so we need to actually get everybody on this thing so we
definitely have to make it free and you know then we get this kind of recursive process well then
the nature of the ad model doing time on site optimization and I'm stuff I'm not going to get
into because you've addressed it so well ends up appealing to people's existing biases rather
than correcting their bias appealing to their tribal in-group identities rather than correcting
them and appealing to limbic hijacks rather than helping people transcend them and as a result you
end up actually breaking the social solidarity and epistemic capacity necessary for democracy so
it's like oh let's let's solve the search problem that seems like a nice thing the side effect is
we're going to destroy democracy and open societies in the process and all those other things like
those are examples of solving a problem in a way that is externalizing harm causing other problems
that are oftentimes worse and so we the the let's just focus on the opportunities
and just to say typically this this will get accounted for as oh this is just an
unintended consequence but there's some other generator functions I think we should outline I
mean if if YouTube and Google didn't personalize search results and what video to show you next
and the other guy did on tiktok starts personalizing they're caught in a race to the bottom of whoever
personalizes more for the best limbic hijack and so just to sort of connect some of those
those themes together for for listeners so you mentioned race to the bottom and obviously
cht has discussed this before and this is a key uh piece of the game theoretic challenge and global
coordination and the two primary ways it expresses itself is arms races and tragedy of the comments
and the tragedy of the comment scenario is if we don't overfish that area virgin ocean
but we can't control that someone else doesn't because how do we do enforcement if they're
also a nuclear country that's a tricky thing right how do you do do enforcement on nuclear
countries equipped countries so us not doing it doesn't mean that the fish don't all get taken
it just means that they grow their populations and their GDP faster which they will use rival
wristly so we might as well do it in fact we might as well race to do it faster than they do
that's the those are the tragedy of the comments type issues the arms race version is if we can't
ensure that they don't build a AI weapons or they don't build surveillance tech and they get
increased near-term power from doing so we just have to race to get there before them
that's the arms race type thing it just happens to be that while that makes sense for each agent
on their own in the short term it creates a global dynamics for the whole in the long term
that self-terminate because you can't run exponential externality on a finite planet
that's the tragedy of the commons one and you can't run exponential arms races and exponential
conflict on a finite planet so the thing that has always made sense which is just keep winning at
the arms races has had a world where we've had lots of wars increasing in their scale and lots
of environmental damage we started desertification thousands of years ago it's just there's been
a long slow exponential curve that really started to pick up with the industrial revolution and is
now really verticalizing with the digital revolution and the cumulative harm of that kind of thing
becomes impossible now so basically with the environmental destruction with the wars and
with the kind of class subjugation things that civilizations have in the past it pretty much
anyone would say we have not been the best stewards of power and technology is increasing our power
exponential tech means tech that makes better versions of itself so you get an exponent on
the curve you get a and we're now in a process where that's a very very rapid computation
gives the ability to design better systems of computation and computation in ai applied to
biological big data and protein folding gives the ability to do that on biotech and on and on right
so we could say the central question of our time is if we've been poor stewards of power for a long
time and that's always caused problems but the problems now become existential they become
catastrophic we can't keep doing that how do we become adequately good stewards of exponential
power in time right how how do we develop the good decision-making processes the wisdom necessary
to be able to be stewards of that much power I think that's a fair way to talk about the central
thing now if it's okay the thread we were about to get to I think is a good one which was the
history of catastrophic risk coming up to now is that before world war two catastrophic risk was
actually a real part of people's experience it was just always local but an individual kingdom
might face existential risk in a war where they would lose and so the people faced those kinds
of reality and in fact one thing that we can see when you read books like the collapse of
complex societies by Joseph Tainter and just any study of history is that all the great
civilizations don't still exist which means that one of the first things we can say about
civilizations is that they die they have a they have a finite lifespan on them one of the interesting
things we can find is that they usually die from self-induced causes they either over consume the
resources and then stop being able to meet the needs of the people through unremovable
environmental dynamics and that's old or they have increasing border conflicts that lead to enmity
that has more you know arms race activity coming back at them or they have increasing
institutional decay of their internal coordination processes that leads to inability to operate
quickly in those types of things so we can say that it's the fundamentally most all civilizations
collapse in a way that is based on generally self-terminating dynamics and we see that even
when they were overtaken by armies oftentimes they were armies that were smaller than ones they had
defended against successfully at earlier peaks in their adaptive capacity okay so catastrophic risk
has been a real thing it's just been local and it wasn't till world war two that we had enough
technological power that catastrophic risk became a global possibility for the first time ever
and this is a really important thing to get because the world before world war two in the
world after was different and kind so fundamentally and this is why when you study history so much
of what you're studying is history of warfare of neighboring kingdoms and neighboring empires fighting
and uh because the wars were fundamentally winnable at least for some right they weren't
winnable for all the people who died but at least for some and with world war two and the development
of the bomb became the beginning of wars that were no longer winnable and the that if we employed
our full tech and continued the arms race even beyond the existing tech it's a war that where
win lose becomes omni lose lose at that particular level of power and so that created the need to
do something that humanity had never done which was that the major superpowers didn't war the whole
history of the world they the history of the thing we call civilization they always did and so
we made an entire world system a globalized world system that was with the aim of preventing world
war three so we could have non-kinetic wars and we did right the increasingly you can see from
world war two to now a movement to unconventional warfare narrative and information warfare economic
diplomatic warfare those types of things resource warfare and you could if you were going to have
a physical kinetic where it had to be a proxy war but to have a proxy war that also required
narrative warfare to be able to create a justification for it but also to be able to prevent the war so
so the post-world war two Bretton Woods mutually assured destruction united nations world was a
solution to be able to steward that level of tech without destroying ourselves and it really was a
reorganization of the world it was a whole new advent of social technologies or social systems
just like the US was new social technologies or social systems coming out of the industrial revolution
the industrial revolution ended up giving rise to kind of nation-state democracies the nuclear
revolution in this way kind of gave rise to this ideal intergovernmental world and it was predicated
on a few things mutually assured destruction was critical globalization and economic trade was
critical that we if the computer that we're talking on and the phone that we talk on is made
over six continents and no countries can make them on our own we don't want to blow them up and
ruin their infrastructure because we depend upon it so let's create radical economic interdependence
so we have more economic incentive to cooperate makes sense and let's grow the materials economy
so fast through this globalization that the world gets to be very positive GDP and gets to be very
positive some so that everybody can have more without having to take each other stuff that was
kind of like the basis of that whole world system and we can see that we've had wars but they've
been proxy wars they and cold wars they haven't been major superpower wars and they've been
unconventional ones but we haven't had a kinetic world war three we have had increase of prosperity
of certain kinds 75 years give or take now we're at a point where that radically positive some
economy that required an exponential growth of not of the economy which means of the
materials economy and it's a linear materials economy that unrenewably takes resources from
the earth faster than they can reproduce themselves and turns them into waste faster than they can
process themselves has led to the planetary boundaries issue where it's not just climate
change or overfishing or dead zones in the ocean or microplastics or species extinction
or peak phosphorus it's a hundred things right like there's all these planetary boundaries so we
can't keep doing exponential linear materials economy like that that thing has come to an end
because now that drives its own set of catastrophic risks we see that the radical interconnection
of the world was good in terms of will not bomb each other but it also created very high fragility
because what it meant is a failure anywhere could cascade to failures everywhere because of that
much dependence so we can see with the easy example yeah we had what was a local issue
to an area of china but because of how interconnected the world is with travel it became a global
issue at the pandemic level and it also became an issue where to shut down the the transmission
of virus we shut down travel which also meant shut down supply chains which meant so many things
right and very fundamental things that weren't obvious to people at first like
that country's agriculture depends upon the shipment of pesticides that they don't have
stored and so we got these swarms of locusts because of not having the pesticides which damaged
the food supply and shipments of fertilizer and shipments of seed so we end up seeing a drive
of the food insecurity of extreme poverty at a scale of death threat that is larger than the
covid death threat was as a second order effect of our problem we were trying to solve the problem
of don't spread covid and the solution had these massive second third order effects that are still
playing out right and that was a relatively benign pandemic a relatively benign catastrophe compared
to a lot of scenarios we can model out so we can say okay well we like the benefit of interconnectivity
so we're not invested in bombing each other but we need more anti fragility in the system
and then the mutually assured destruction thing doesn't work anymore because we don't have two
countries with one catastrophe weapon that's really really hard to make and easy to monitor
because it's there's not that many places that have uranium it's hard to enrich it you can monitor
by satellites we have lots of countries with nukes but we also have lots of new catastrophe
weapons that are not hard to make that are not easy to monitor that don't even take nation states
to make them so if you have many many actors of different kinds with many different types of
catastrophe weapons how do you do mutually assured destruction it's you can't do it the same way
and so what we find is that the set of solutions post world war two that kept us from blowing
ourselves up with our new power lasted for a while but those those set of solutions have ended
and they have now created their own set of new problems so there's kind of the catastrophic risk
world before world war two the catastrophic risk world from world war two till now
and then the new thing so the new thing says we have to have solutions that deal with the
planetary boundary issues that deal with global fragility issues and that deal with the exponential
tech issues both in terms of the way exponential tech can be intentionally used to cause harm i.e
exponential tech empowered warfare and unintentionally i.e exponential tech empowered externalities
and even just totally unanticipated types of mistakes the facebook google type problem
multiplied by agi and things like that and so when we talk about what the catastrophic risk
landscape is like that's the landscape the metacrisis is how do we solve all of that and
recognizing that our problem solving mechanisms haven't even been able to solve the problems
we've had for the last many years let alone prevent these things and so the central orienting
question it's like the un s 17 sustainable development goals there's really one that
must supersede them all which is develop the capacity for global coordination that can solve
global problems if you get that one you get all the other ones if you don't get that one you don't
get any of the other ones and so we can talk about how do we do that but that becomes the
central imperative for the world at this time so you're saying a whole whole bunch of things and
one thing that comes to mind here if i'm just reading back some of the things you've shared
the development of the let's call one of the first exponential technologies which is the nuclear bomb
led to a new social system which was sort of the post breton woods world of trying to stabilize
that one exponential technology in the world in a way that would not be catastrophic and even there
we weren't able to sort of make it all work and i think people should have maybe a list of some of
the other exponential technologies because i want to make sure that phrase is defined for listeners
and there's a lot of different ways that we've now not just created more exponential technologies
but more decentralized exponential technologies and i think people should see facebook and google
as exponential attention mapping or information driving technologies that are shaping the global
information flows or the wiring diagram of the sort of global societal brain at scales that are
exponential it's sort of a nuclear nuclear scale you know rewiring of the human civilization we
couldn't do that with newspapers we couldn't do that with the printing press not at the scale
speed etc that we have now so do you want to give maybe some more examples of exponential technologies
because i think that's going to lead to we're going to need a new kinds of social systems to
manage this different landscape of not just one exponential nuclear bomb but a landscape yeah
indulge me as i tell a story first that leads into it because it'll be a relevant framework
obviously the bomb was central to world war two and the world system that came afterwards and what
motivated our activity getting into it but it was not the only tech it was one new technology
that was part of a suite of new technologies that could all be developed because of kind of the
level science had gotten to and basically like physics and chemistry had gotten to the point
that we could work on a nuclear bomb we could start to work on computation we could get things
like the v2 rocket and rockets and a whole host of applied chemistry and one way of thinking about
what world war two was it's not the only way of thinking about it but it's useful frame and i think
it's a fair frame is that there were a few competing social ideologies at the time primarily kind of
uh german fascism fascism socialism whatever you want to call it uh soviet communism and
western liberalism something like that um and that this new suite of technologies whoever kind
of developed it and was able to implement it at scale first would win uh that social ideology
would win because it's just so much more powerful if you have nukes and they have guns you're going
to win right and uh germans were actually ahead of both the us and the soviets because of some
things that they did to invest in education um and and tech development and but that led both
the soviets and the us to really working to catch up as fast as they can and uh when the us finally
figured it out which we were actually a little bit slow to right einstein actually wrote a letter
the einstein solar letter that went to the us government saying now the science really does
say that this thing could happen and the germans could get it and you should focus on it and at
first they didn't take them up on it wasn't till the private sector actually uh non-profit supported
advanced it further that then the manhattan project uh was engaged in but then it was engaged in when
they recognized the seriousness that there was an actual eminent existential risk to the nation and
and the whole western ideology and whatever then it was an unlimited budget right it was a let's
find all the smartest people in the world and let's bring them here and let's organize however
we need to to make this thing happen and let's do it for all of the new areas of tech we're going
to get the enigma machine and crack the enigma code we're going to get a v2 rocket we're going to
figure out how to reverse engineer that and advance rocketry we're going to do everything needed to
make a nuclear bomb and then more advanced ones it was the biggest jump in technology ever in the
history of the world in recorded history as we know it and it wasn't actually done by the market
right it was done by the state that's a very important thing this idea that
markets innovate and states don't innovate is just historically not true here though
these this was state funds and state controlled operation in the same way that the
apollo project coming out of it was and a technological jump of that kind
hasn't happened since so it's an important important thing to understand but um
um we can say though this is not a totally fair thing to say we can say that the us came out dominant
in that technological race the us and the ussr both had a lot of capacity so that was the cold war
and then finally the us came out and so the world post-world war two system was a us led system
right the breton the un was in the us the breton wood system was pegged to the us dollar um
um what i would say is that so it wasn't one type of tech it was the recognition that science had
got to a place where there's going to be a whole suite of new tech and the new tech meant more
power and whoever had the power would determine the next phase of the world and if we didn't
like the social ideologies that we're going to be guiding it of course we can also think of it as
who wanted to win at the game of power but from the the philosophical argument if we didn't
like the social ideologies then we had to have another social ideology get it what i would say
is that there is an emerging suite of technologies now that is
much more powerful in the total level of jump technological jump than the world war two suite
was in fact orders of magnitude more and only those who are developing and employing exponential
tech will have much of a say in the direction of the future because just from a real politic
point of view that's where the power is and if you don't have the power you won't be able to oppose it
and so what do we mean by exponential tech there's a couple different ways of thinking about it
just exponentially more powerful is a very simplistic way and in that definition nuclear
is exponential tech but what we typically mean with exponential tech is tech that makes
it possible to make better versions of itself so that there is like a compounding interest
kind of curve the the tech makes it easier to make a better version which makes it easier to
make a better version and so we see that starting with computation really in a fundamental way
because computation allows us to advance models of computation how do we make better computational
substrates how do we get more transistors in a chip how do we make better arrangements of
chip so we get GPUs and those types of things and so in this new suite of technology the center of
it is computation the very very center of that is AI is kind of a self-learning computation
on large fields of data the other kind of software advances like advances in various
meaningful advances in cryptography and big data and the ability to get data from sensors and
you know sensor processing image recognition all like that is a part of that central suite
and the application of that to the directing of attention and the directing of behavior by
directing attention which you focused on very centrally then the next phase is the application
of the tech the application of computation to increasing computational substrate so this
is now the software advancing the hardware that can advance the total level of software and you
see the recursion so that's not just continuously better chips it's also quantum computing photo
computing dna computing those other types of things and the other types of hardware that need
to be part of that thing ie sensor tech in particular so that you can keep getting more
data going into that system that can do big data machine learning on it then it's the application
of that computation in and AI specifically to physical tech so to nanotech material sciences
biotech and even things like modeling how to do better nuclear and you know robotics and automation
and so when you start thinking about better computational substrates running better software
with more total data going in with better sensors in better robots you start getting the sense of
what that whole suite of things looks like um so that's that's the suite of things that I would
say is what we would kind of call exponential tech and the the the reason why the term exponential
is important is we we don't think exponentially well our intuitions are bad for it because we
think about how much progress was made over the last five years we imagine there will be a similar
amount over the next five years and that's not the way exponential curves work right and so it's
very hard for us our intuition was calibrated on the past and it's going to be miscalibrated
for forecasting the total rate of change and the magnitude of change
so to link this for one much more narrow aspect for our listeners who are familiar with social
media and the social dilemma and you're talking about sort of self-compounding systems that improve
recursively like that um if i'm tiktok or if i'm facebook and i have i use data to figure out what's
the thing to show you and that's going to keep you here for longest since going to bypass your
prefrontal cortex and go straight to your limbic system your lizard brain um well the better it gets
at doing that and succeeding at that the more data it has to make a better prediction the next time
but then a new user comes along who it's never seen before but hey they're clicking on exactly the
same pattern of anorexia videos that we've seen these other two million users have that turn out
to be teenage girls and it just happens to know that this other set of videos that are more anorexia
videos are also going to work really really well so there's sort of a self-compounding loop that's
learning not just from one person and getting a better sort of version of hijacking your nervous
system but learning across individuals and so now you get a new person coming in from some
developing countries never used tiktok before and they're just like barely walking in for the front
door the very first time you know it's sort of like when coca-cola goes to southeast Asia for
the first time and you get diabetes 10 years later because you refined all the techniques of
marketing so effectively but now happening at scales that are automated with computation so what
you're talking about is the impact of computation and learning on top of learning data on top of data
and then cross-referencing lookalike models and all of this kind of thing you could apply to the
domain at least that social dilemma uh watchers and people who are familiar with our work uh might
be able to tie into yeah the more people you have in the system and the more data per person
that you're able to harvest the more stuff you have for the machine learning to figure out patterns
on which also means that the machine learning can provide things that the users want more
even if it's manufactured want right even if it's manufactured demand which means that then more
users will come and put more data in and it can specifically figure out how to manufacture the
types of behavior that increase data collection and so you do get this recursive process on how
many people how much data how good are the machine learning algorithms you know that kind of thing
and this is one of the reasons that we see these natural monopoly formations within these categories
of tech and this is another reason that's important to understand like uh these types of self-reinforcing
dynamics and things like network effects like Metcalf's law didn't exist when the Scottish
Enlightenment was coming up with its ideas of capitalism and market and the healthy competition
and markets and why that creates checks and balances on power they didn't exist uh Adam Smith
did not get to think about those things and so when you have a situation where the value of the
network is proportional to the square of the you know people coming into the network then you're
incented to keep it free up front maximize addiction drive behavior into the system and then once you
get to the um kind of uh breakaway point on the return of that thing it becomes nearly impossible
for anyone else to come in and overtake that thing so you get a power law distribution in each
vertical you get one online market that is bigger than all the other online markets one video player
that's bigger than all the other video players one search one social network one and that's not
because of a government monopoly that's because of this kind of natural tech monopoly this also
means that when we created the laws around monopolies they don't apply to this thing and yet
this this thing still has the same spirit of power concentration and unchecked power that our
ideas of monopoly had but it's able to grow much faster than law is able to figure out how to deal
with it or faster than economic theory can change itself right and so one of the things that we see
is that our social technologies like law like governance like economics are actually being
obsolete by the development of totally new types of behavior and mechanics that weren't part of the
world they were trying to solve problems for right and so the Scottish Enlightenment was the
development of new ideas of how to problem solve the problems of its time the uh the constitution
was trying to figure out how to solve the problems of its time I would say they were good thinking
right they were good work the Bretton Woods world was none of them are adequate to solve
these problems because these are these problems are different in kind and even where they're just
an extension of magnitude when you get enough change in magnitude sometimes it becomes a
difference in kind like as you're getting more and more information to process once you get
past what humans can process infosingularity type issues okay well now it's a difference
in magnitude that becomes a difference in kind which means you need a fundamentally different
approach so I would say this is where it's important to recognize that those social technologies
that we loved so much because they seem so much better than all the other options we had at the
time like markets and like democracy these are not terminal goods in and of themselves
the terminal goods were things like human liberty and justice and checks and balances on power and
opportunity and distribution of opportunity and things like that these were the best
social technologies possible at the time the new technologies both kill those things they don't
work anymore right you can't have the social technology of the fourth estate that was necessary
for democracy which is why founding fathers said things like if I could have perfect newspapers
and a broken government or perfect government broken newspapers I take the newspapers because
if you have an educated populace it all understands what's going on they can make a new form of
government if you have people that have no idea what's going on how could they possibly make good
choices if their sense making is totally broken so we had this idea that the fourth estate was a
prerequisite to a participatory governance but that was based on a very narrow limited capacity
for print right and again it was the technology of the Gutenberg press that was one of the things
that actually ended feudalism and so the founding fathers were employing that new tech both because
it upended the previous tech and it made this new thing possible same with guns that they needed
guns and second amendment to make this new thing possible um but once we get to a internet world
where you don't have centralized broadcast you have decentralized and then there's so much stuff
that you can never possibly find at all in search of whoever coordinates the search the content
aggregators which is the facebook the youtube whatever are doing it with the types of business
models we have the fourth estate is just dead forever that old version there's no way to recreate
that version so does that either means democracy is dead forever or anything like a well-informed
citizenry that could participate in its governance in any form or you have to say what is a post
internet post social media post info singularity fourth estate that creates an adequately educated
citizenry that's thinking about the way that our social technologies our social systems have to
upgrade themselves in the presence of the tech that obsoleted the way they did work but we can
also see and we can give examples of this how the new tech also makes possible new things that
weren't possible before so we can do something better than industrial era democracy or industrial
era markets which is why I say they aren't a terminal good they're a way to deliver certain
human values that really matter and the new technology that obsoletes those can actually also be
facilitative in designing systems that also serve those values but it's not a given that it does
that has to become the kind of central orienting mission so so now just to make sure we're linking
this back to the start of this conversation we started this conversation by saying the way
that we are going about solving problems let's say using the legacy systems of law making in a
congress or using the legacy systems of a town hall to vote on a proposition or trying to you
know pass laws as fast as social media as rewiring society the lines don't match and so what you're
saying is that and just for listeners because I know that you use the phrase social technology but
I think you're really sort of talking about a social systems ways of organizing you know democracy
or technology in the most fundamental sense of the word of something humans design to facilitate
certain kinds of activity or outcomes so like language is a technology or democracy is a technology
so social systems social systems yeah and so if the kind of old world approach of you know
some people might be hearing this and say to themselves now hold on a second so we have all
these institutions we have all these structures we live in a democracy and we live in a system that
that you know is working the way it does it has its courts it has its attorney generals it has its
litigation procedures it has its law making bodies if you're saying that we can't use those
things because they're not adequate or they won't help us solve those problems we need to have new
social systems um maybe you could give us some hope about why that might be feasible and instead
of feeling uh impossible because this is actually precedent in in our history when new new technologies
show up and then new social systems emerge to make room for those technologies functioning well
because you you kind of briefly touched on them but I think it's important to give listeners a
few concrete examples yeah there's a number of kind of good academics and disciplines of
academics that look at the history of evolutions and physical technology and the corresponding
evolutions in thought and culture and social systems um Marvin Harris the cultural materialism
did a kind of major opus work here where he specifically looked at how changes in social
systems and cultures followed changes in technology there are other bodies of work that
will look at the social systems as primary or the cultures as primary and we can say they're
interfecting um but uh but for instance you know the vast majority of human history was tribal was
you know however much 200 000 years of humans in these small kind of Dunbar number uh villages
there was a social technology social systems that mediated that that had to do with how the
tribal circles worked and um and the nature of how resources were shared right it was a very
different kind of economic system a very different kind of judicial system a different
educational system it had all those things it had a way of education meaning intergenerational
knowledge transfer of the entire knowledge set that was needed for the tribe to continue operating
the development of certain technologies particularly the plow but baskets and a few other things
um absolutely did that thing because all of a sudden it made possible big amounts of surplus
that made reason for much larger populations to emerge those larger populations were going to
win in conflict against the smaller populations and so you can see that then the emergence of new
social technology to facilitate large groups of people empire types uh civilization technology
emerged you can see and that there were a few other shifts in technology that evolved the types
of empires that were there and then you know the next one that people talk about a lot is the
industrial revolution from the printing press specifically and then steam engine the gun powder
revolution was part of it that kind of ended feudalism and began the nation state world
and so you can see like what is the thing that the founding fathers in the us were doing well
they weren't trying to keep winning at feudalism right there there was a game that had been
happening for a long time and they were saying like nowhere we're all people who are in of the
type of people who could do well at that system and rather than do that we recognize that there are
are fundamentally things wrong with this system and fundamentally new possibilities that hadn't
been previously recognized so we're going to actually try to design a fundamentally different
system that we think a more perfect union that makes life liberty in the pursuit of happiness
better for everybody and increases productive capacity and things like that so that was fundamentally
an advance in social technology or social systems that both utilized new physical technology
and was enabled by it right um in the current situation there are groups that are advancing
the exponential technologies and what that means whatever social systems that they're
employing are the social systems of the future if we don't change it and that's what I want to get
to in a moment but like who is working to invent to implement any of the new emerging
tech for better social systems that are aligned with social systems we want
you've had uh Audrey Tang on the show do you want to just briefly describe an example of
what she and what they have done there because if people aren't aware of it that's a pretty
prime example of for this particular iteration sure well um so just and maybe just to go back
briefly um because you gave this example in one of our earlier conversations that um you know that
the printing press could have been used by the the feudal lords for consciously reinforcing
feudalism but instead this and actually this new technology the printing press gives way
to new ways of organizing society and we can actually have things like a fourth estate or
newspapers or you know things like that um it was happened what you're both happen yeah right
but then then the new thing theoretically has to win out over over the old thing
um at least the one that we want that holds the values that the society wants correct so um I think
a lot of people can hear our conversation we've had this riff before actually following our last
episode after my senate testimony speaking about a frame that that you you have offered and know
well which is that we can notice that digital authoritarian societies right now like china
are consciously using exponential technologies to make stronger more effective digital clothes
and authoritarian societies and in contrast digital open societies democracies like the
united states are not consciously using technology to make stronger healthier open societies
instead they've sort of surrendered uh what they are to uh private technology multinational
corporations pursuing self-interest to shareholders and are are profiting from the degradation and
dysfunction of democracies and so um when we say all this and we talk about um how do we build the
kind of next social system and audrey tang and in her work I think people get chipped up in thinking
that what we really mean is we have to make some kind of 21st century digital democracy in fact
I probably said those words but what we're really talking about here is some new concept that preserves
the principles of what we meant by a democracy yes um but instantiated with the new technologies
you know our version of the new printing press which is um you know networked information environments
and um you know all of the new capacities that we have in 21st century with um you know mobility
where everyone's connected to everywhere and everything all at once so what is that system
that new social system that leverages the current technology and makes a stronger healthier open
society and I think audrey tang's work I mean I would probably send listeners back to listen
to that episode I think it's one of our most listened to and most popular episodes for a
reason because in Taiwan she's essentially built an entire civic technology ecosystem
in which people are really participating in the governance of their society oh we need masks we
need um better air quality sensors we need to fix these potholes um there are processes by which
every time you're frustrated by something you actually get invited into a civic design process
where whether it's the potholes or the masks you can actually participate in having a better
system uh you're complaining about the tax system and filing your taxes and maybe it's
an inefficient form or something like that you get brought into a design process of what would
make it better and so the system is participatory but not in that kind of 18th century way of hey
there's a physical wooden townhouse and we're going to walk into it and we're going to hang out there
for three hours and I'm going to yell and scream about issues that are more local within you know
10 15 miles of where we are because we were existing in a world before automobiles
we're now talking about how do you do an open society social system
but in a world with all of the new technologies that are not just here today but emerging and
so do you want to talk a little bit about what the prince how will we even navigate that challenge
and why is some new social system like that um necessary for dealing with these problems that
you've sort of laid out at the beginning because I'm sure people would like to feel less anxiety
about those things uh uh hanging around for longer
yeah I think I think what Taiwan has been doing and what uh
Audrey Tang in the digital ministry position in particular has been leading
is probably the best example certainly one of the best examples in the world of this kind of
process and thinking and does it apply in the or could it apply in the exact same way to the U.S.
no of course not like we we know that uh because of the relatively small geography and
high speed train transportation you can get across Taiwan in an hour and a half
and so when you're mentioning the small scale of local government at the beginning of the U.S.
where you come to the town hall in a way they have that right like it's 23 million people
but there is an older shared culture there is all there also happens to be an existential
threat just right off their border that is you know big enough that they can't just chill and
not focus on it they have everyone has to be civically engaged with some civic identity and
like that uh they didn't start making their culture in the industrial era and then have to
upgrade it right like they started later um where they're we're able to start at a higher level of
the tech stack um so there's a number of reasons why it's different so we're not going to naively
say what you do in a tiny country that is culturally and ethnically homogeneous uh
and has a higher GDP and education per capita and whatever is the same thing you would do
but we can certainly take a lot of the examples and say how would they apply differently in different
contexts so the thing we said earlier that this suite of exponential technologies is so much more
powerful than all of the previous types of power that only those who are developing and deploying
them will be really steering the direction of the future and that there are ways of employing them
that do cause catastrophic risk uh and the catastrophic risk is of two primary kinds right
conflict theory mediated and you can't you just can't do warfare with this level of technology
and this interconnected a world and make it through well not all catastrophic risk means
existential doesn't all mean nuclear war and nuclear winter and we've killed all the mammals on
earth it it might just mean we break global supply chains kill lots of people and regress humanity
and the quality of the biosphere pretty significantly so i'm i'm not just focused on existential risk
i'm interested in you know kind of catastrophic risk at scale in in general and we can see that
exponential tech applied as in conflict theory and in mistake right as externalities in the cumulative
effect could you define conflict theory and mistake theory for people who who are not familiar with
those terms yeah there's a very nice discussion on the less wrong forum if people are interested
to go deeper and is this question of how much of the problems in the world are the result of
conflict theory versus mistake theory meaning conflict theory is we knew we either wanted
to cause that problem that harm to whomever as in a knowingly wanted to win at a war and or at least
we knew we were going to cause that problem and didn't care because it was attached to something
we wanted right conflict theory or mistake theory we didn't know we didn't want to cause it and we
really didn't know and it was just unintended unanticipatable consequence and it's fair to say
that there's both right there's plenty of both one thing that is worth knowing is that if i
if i'm trying to do something that is actually motivated by conflict theory it benefits me to
pretend that it was mistake theory benefits me to pretend that i had no idea and then afterwards
say oh it was an unintended unanticipatable consequence it was too complex people can't
predict stuff like that and so the reality of mistake theory ends up being a source of plausible
deniability for conflict theory and but they're but they're both things and we have to overcome
both meaning we have to have choice making processes in our new system of coordination and
like this sounds like maybe hippy stuff until you take seriously the change of context so we
have to have problems of choice making that consider the whole that sounds like unrealizable
hippy stuff until you realize but we're making choices that affect the whole at a level that
can even individually be catastrophic and is definitely catastrophic cumulatively so if we
aren't factoring it then the human experiment self-terminates and maybe that's the answer to
the great filter hypothesis right uh and so are well yeah i think people don't have an intuitive
grasp of um what it means that each of us are walking around with the power of gods to influence
huge enormous consequences i mean i give a few examples every time you enact with the global
supply chain and hit buy on amazon you invisibly enacted you know shipping and planes and petroleum
and middle wars in the middle east there's a whole bunch of things that were sort of tied into when
you are posting something on social media and have more than a million followers you're influencing
a global information ecology and if you're angry and biased about one side or the other of the
pandemic is real or it's not real or something like that you're externalizing more bias into
the commons of how keep the rest of the world understands things so we're walking around with
increasing powers but i don't think the increasing power that we've granted is as intuitive
for for for some folks did you explain some more examples of that there's both cumulative effect
and like cumulative long term and fairly singular short term and cumulative long term i mean you go
back to early us settlers coming into the us moving west and they're being buffalo everywhere
and there had been buffalo everywhere for a very long time and then there's no buffalo in whole
areas that were forested with old growth forest became deforested and it was like no it's impossible
we could never get rid of all the buffalo like i we could never cut down all the trees but the
cumulative effect of lots of people thinking that way we're individually i have no incentive to
leave the buffalo alive and i do have an incentive for my family individually to kill it but everybody
thinking that way and increasing our um desire for how much we consume per capita our technology
that allows us to consume more per capita and developing more capital more total people well
then you start getting environmental destruction and species extinction at scale and that's a
long time ago right like that's much lower tech and much less people and it's distributed action
it's a cumulative it's a cumulative effect issue and obviously we see that with
with nobody's intending to fill the ocean with microplastics but everybody's buying
shit that is filling the oceans with microplastics and so everyone is participating with systems
where the system as a whole is sociopathic the system is self terminating the system
doesn't exist without all the agents interacting with it all the agents feel like their behavior is
so small that that justifies everybody doing that thing right so that's what we mean by cumulative
kind of catastrophic risk but it's also true that whoever made that thermite bomb and hooked it to
a drone and hit the ukrainian munitions factory a couple years ago that caused a billion dollars in
damage exploded the munitions factory the effect of a bomb as big as a the the largest non-nuclear
bomb the u.s arsenal has and it's an air bomb this is a home that was a homemade little bomb in a
drone right and so and crisper gene drives are cheap and easy and it doesn't take that much
advanced knowledge to start working with them and so that that starts to look like
individuals and small groups with real catastrophic ability not long-term and
cumulatively the increase in our tech gives us both issues via globalization and the overall
system you get these cumulative long-term effects and with the exponential attack creating
decentralized catastrophic capabilities one of the core questions we have to answer is how do we
make a world that is anti fragile in the presence of those kind of catastrophic capabilities that
are easy to produce and thus decentralizable so uh how do we do that what are the social
systems that we need to employ to bind some of these bad effects in ways that that the natural
inclinations of self-interested actors will drive things in that direction just to link this to the
social media space for people if i know that i can get a little bit more attention and a little
bit more likes and clicks and follows and shares and so on if i exaggerate the truth by five percent
just to use a little bit more of an extreme adjective you know i know that that in the
long run would be bad if everybody did that but for me right now i can win a few hits and i can
get more influence and i'm an instagram influencer and i'm making ten thousand dollars a month and
if i don't do it i'm noticing everyone else's do it and if i don't use the filter everyone
else is using the filter and so everyone ends up in this sort of another race to the bottom
sort of situation that has that kind of cumulative degradation or cumulative derangement where
there's increasing distance between what is true and what people believe because we've all been
subtly exaggerating it to make our point and gain influence and so on and so just to give another
example maybe for listeners in in kind of the space that they're more familiar with
but going back i mean the whole premise of this is as we gain more exponential technologies that
have more capacity and more hands so instead of having just the u.s and russia having this you have
whether as you mentioned chris projean drives or some of the drone things that are out there
more and more people have access to these things how can we bind those kinds of forces
and what are the social systems that we need to make that happen yeah i want to go back as you're
describing this i was thinking about how many people who um listen to your show who maybe work
in technology who might have uh they work in technology because they see the positive things
technology can do and have more of a kind of techno optimist point of view and this
overall conversation might sound very techno pessimist and like did we not read pinker and
watch hans rossling and you know those types of things and um so i want to speak to that briefly
first this is a meta point but it's worth saying right now particularly in on this podcast and in
the kind of post truth post or fake fact world where then so much of the emphasis has gone into
we need fact checkers and we need real facts um obviously it's possible to have an epistemic
error or even intentional error in the process of generating a fact is is there corruption in the
institutions and that kind of thing but let's even say that wasn't an issue and the things that go
through the right epistemic process as facts are facts can you lie with facts totally can you
can you mislead with facts yeah because nobody's going to make their choice on one fact they make
their choice based on a situational assessment based on a narrative based on a gestalt of a
whole thing that's lots of different facts well which facts do i include which facts do i not
include and do am i decontextualizing the fact so uh the quality of life has gone up so much
because we average person lived on less than a dollar a day in the us in 1815 and now they live
on this many dollars a day which inflation adjusted means higher quality of life yeah but in 1815 most
of their needs didn't come through dollars they grew their own vegetables they hunted they so i'm
decontextualizing the facts to compare something that's really apples and oranges so even if the
fact is quote unquote true the decontextualization and recontextualization makes it seem like it
means something different than it means and the same with the cherry picking of facts and i can
very easily say oh there's a lower percentage of people in extreme poverty but i might also be
changing the definitions of extreme poverty i can also rather than focus on percentage say well
there's more total people in poverty than there were total people in the world before the industrial
revolution so like so there's the ability to decontextualize and recontextualize facts there's
the ability to cherry pick facts and there's the ability to lake off frame facts and put particular
kinds of sentiment and moral valence on it and so am i talking about them as illegal aliens or
undocumented workers and i get a very different kind of sentiment so talking about it as a
pre-owned car or a used car everyone loves a pre-owned car no one wants a used car and so these
very simple semantic frames contextual frames cherry picking of the things means that i can
make a narrative where all the facts went through the most rigorous fact checker and yet the narrative
as a whole is misleading and so fact checking is necessary but it is not sufficient for a good
epistemic in good sense making and not only is it not sufficient it's even weaponizable
this is a very important thing to understand because if you are not pursuing that you're
if you're not recognizing that you might be believing nonsense thinking that you're using
epistemic rigor okay so the techno pessimists and the techno optimists both cherry pick and they both
lake off frame and this is true with all the difference in almost every political ideology
the woke in the anti-woke the um the pro socialist pro capitalist you'll notice that the way they do
their arguments the systemic racism is really really terrible no there's not that bad the systemic
racism they both have stats but this is actually you can almost think of it as statistical warfare
as a tool of narrative warfare and um so this is where a higher level of earnestness rather than
a particular vested interest or bias a higher willingness to look at biases a higher level of
rigor you know ends up being critical to actually overcome any of these things so can i cherry pick
stats that make it look like everything's getting better totally those things are true and nobody
wants to go back to a world before novocaine when you have to do dentistry and nobody wants to go
back to a world before penicillin when basic bacterial infections go around and like there's
totally good stuff that has emerged um and are there all kinds of uh ubiquitous mental illnesses
and chronic complex disease that didn't exist before and um increase in the total number
of addictive type behaviors within populations and um and a radical increase in the catastrophic
risk landscape a negative effect to environmental metrics so things are getting better and things
are getting worse at the same time it's important to understand that depending upon what you pick
it's just that the things that are getting worse are heading towards tipping points that make the
whole thing no longer viable and so that we're not denying that there are things that are getting
better we're saying that for the game to continue at all right to have it be an infinite game that
gets to keep continuing there are certain things that have to not happen and you can't have the
things that are getting worse keep getting worse at the curve that they are and have the things
that are getting better be able to continue at all so i just want to say that so naive techno
optimism can actually make you a part of the problem because then you do things like develop
a solution to a narrowly defined problem and externalize harm to other areas because you
weren't taking seriously enough not doing that but techno pessimism also makes you a part of the
problem or at least not a part of the solution because because the world is the future is not
going to be determined by Luddites it's not going to be determined by people who aren't developing
the tools of power so if you aren't actually looking at how do we develop a high tech world
that is also a fundamentally desirable in terms of a high nature and high touch world then you
really aren't thinking about it in a way that ends up mattering and so we are techno optimist but
not naive techno optimist we go through the totally cynical phase of man tech is a serious
issue and then you go to a post cynical phase of if i want to be techno optimist and not be silly
what does it take to imagine a world where humans have that much power and we are good stewards of
it meaning that we actually tend to each other well and we don't create a dystopic world that has
exponential wealth inequality in an underclass that nobody in the upper class would want to trade
places with and that doesn't cause catastrophic risk right now the amount of power of exponential
tech makes two attractors most likely catastrophic risk of some kind or social systems that are
that do not preserve the values that we care most about that are the ones that are currently most
working to develop and deploy that technology and to just give a very brief recap of the frame that
Tristan you gave on it earlier as you mentioned
China is not leaving a hundred percent of its technology development to the market to develop
however it wants even if it harms the nation state they are happy to bind technology companies
that are getting too large and in ways that would damage the nation state as we saw with
ant corporation and and they are doing a lot of very central centralized innovation
as well associated with long-term planning long-term planning is a key thing in the US
term limits make long-term planning very hard as does a highly rival risk to party system that is
willing to damage the nation as a whole to drive party wins so in that system
almost all the energy just goes into trying to win right you spend at least a couple years
but even the years before that are fundraising creating alliances to just try to win then
you're not going to invest in anything heavily that has return times longer than four years because
it won't get you reelected so no real long-term planning and then whatever you do do in those
four years will get undone systematically in the next four years for the most part all right
all right that system of governance will just fail comprehensively in relationship to a more
to a to a system that doesn't have that much internal infighting and that has the capacity
to do long-term planning and there's a million examples we can look at but just when did high
speed trains start they started you know we saw them emerge in Europe we saw them emerge in Japan
and in China we've seen China now start to export them all around the world and the US still doesn't
have any high speed trains and it's like what happened why and we can see that the US innovated
in fundamental tech in the Manhattan project kind of through the Apollo project but then it started
to privatize almost everything to the market the market started to develop in ways that really
were not advancing the technology in a way that increased the coherence of the nation and the
fundamental civic values and ideas of the nation even the world war two thing we can see we increased
our military capacities radically but that didn't mean we actually really advanced the ideas of
democracy or those values of do we make a better system to educate the people and inform them and
help them participate in their governance do we make better governance this is why the US military
is so powerful but the US government is so kind of inept and which is why nobody wants to fight a
war with the US a kinetic war but it's very easy right now to engage in supporting narrative warfare
where you turn the left and the right against each other increasingly and where you do long-term
planning where the US can't do long-term planning of those kinds and so we can see
that the government of the US and not just the US but like we can see that open societies are not
innovating in how to be better open societies for the most part more effective ones where they're
using the new tech to make better open societies that's happening in the market sector the market
is making exponentially more powerful companies a company's not a democracy it's not a participatory
governance structure in general it's a kind of very top-down autocratic type system and so we see
that there's more authoritarian nation states that are intentionally doing long-term planning
of the development and deployment of exponential tech to make better nation states of that kind
and we can't even blame them when they look at I mean China had the benefit of getting to see
both where the USA failed and where the USSR failed and try to make something they didn't
fail in either of those ways and there's some things that are very smart about those approaches
so we see though exponentially empowered more autocratic type structures and the emergence of
one natural monopoly per tech sector and then the interaction of those that kind of becomes like
oligarchic feudalism tech feudalism neither of those have the types of jurisprudence
or public accountability or whatever that we're really interested in so the two attractors right
now is the emergence of social systems that are deploying the exponential tech that will probably
not preserve the social values that we're interested in and not be maximally desirable
civilizations probably pretty dystopic ones or not even guiding it well enough to prevent catastrophic
risk and catastrophic risk those are the two major types of attractors we want a new attractor which
is how do we utilize the new exponential technologies the whole suite of them to build new systems of
collective intelligence new better systems of social technology how do you make a fourth
estate that can really adequately educate everyone in a post Facebook world well does
the same way that we're trying to optimize control patterns of human behavior for market
purposes to get them to buy certain things and to direct their attention could that be used
educationally of course it could if it was being developed for that purpose and the AI tech that
can take a bunch of faces and make a new face that is merged out of those could it take semantic
fields of people's propositions and values and create a proposition that is kind of the
semantic center of the space and then could we use we can't all fit into a town hall but can we
engage in digital spaces where we can have better processes of proposing refinements to the propositions
of course we can could we use blockchain and other types of uncorruptible ledgers to solve
corruption which is something that universally everybody thinks is a good idea should all
government money be on a blockchain the movement of it so you have provenance so you can see where
the money is actually going and if someone wants to be a private contractor they have to agree that
the accounting system as if they want government money goes on the blockchain so we can see the
entire provenance of the taxpayer money so that they're really you can't have representation if
there isn't transparency of how it happens so there's a whole bunch of when you start to think
about attention directing technology and what its pedagogical applications could be when you start
to think about AI and how it could actually help proposition development and parsing huge amounts
of information to make a better epistemic commons when you start to think about blockchain and could
we actually resolve corruption using uncorruptible ledgers and making the provenance of physical
supply chains and information and money all flow across those totally new possibilities start to
emerge that never emerged before that were never possible before but if it doesn't become our
central design imperative to develop those that those are not the highest marketed opportunities
for those right now the highest market opportunity for blockchain is speculative tokens that have no
real utility and for AI is things that actually drive ads and purchasing and you know on and on
and for attention tech it is the same thing so you've sold me on the idea that we have
two dystopian attractors that we don't want and the third attractor that we're trying to develop
here is some kind of open society that is consciously using all the modern technologies
towards the values that we care about can you give some concrete examples of what it would look like
to use you know AI and attention driving tech and click driving tech and blockchains and all
these things but in a way that would make a stronger healthier open society yeah totally
so let's say we take the attention tech that you've looked at so much that when it is applied
for a commercial application is seeking to gather data to both maximize time on site and maximize
engagement with certain kinds of ads and whatever that's obviously the ability to direct human
behavior and and direct human feeling and thought in a way that is both emerged out of capitalism
and has become almost a new macroeconomic structure more powerful than capitalism because even more
powerful than being able to incent people's behavior with money is being able to direct what
they think and feel to where the thing that they think of as their own intrinsic motive has actually
been influenced or captured so if we if we wanted to apply that type of technology and we figured
out how to make the kind of transparency that made institutions that were trustworthy enough
that we could trust them with this and already we have institutions that have it that we have
no basis to trust with it could that same tech be used educationally to be able to personalize
education to the learning style of a kid or to an adult to their particular areas of interest
and to be able to not use the ability to control them for game-theoretic purposes but use the
ability to influence them to even help them learn what makes their own center their locus of action
more internalized right we could teach people with that kind of tech how to notice their own
bias how to notice their own emotional behaviors how to notice groupthink type dynamics how to
understand propaganda media literacy so could we actually use those tools to increase people's
immune system against bad actors use of those tools totally could we use them pedagogically in
general to be able to identify rather than manufacturing desires in people or appealing
to the lowest angels of their nature because addiction is profitable can you appeal to the
highest angels in people's nature but that are aligned with intrinsic incentives and be able
to create customized educational programs that are based on what each person is actually innately
intrinsically motivated by but that are their higher innate motivators everybody can have a
reward circuit that is based on you know chocolate cake and sloth but the immediate spike that comes
from the chocolate cake ends up then having a crash and increased weight and inflammation
and whatever where the baseline of their happiness goes down over time even though every time they
eat the chocolate cake they get a spike the exercise reward circuit is maybe not that fun maybe even
kind of painful and dreadful in the moment but then creates a higher baseline of energy and capacity
and endurance and self-esteem and you start to actually have the process become more fun you
get a new reward circuit and the baseline goes up so of course i can appeal to the lower reward
circuit and say hey i'm just giving people what they want yeah but if you have a billion dollar
or a trillion dollar organization that is preying upon them and you discuss this very well all the
time the vulnerabilities that make people's life worse to then have the plausible deniability to
say yeah but they wanted it yeah but it was a manufactured demand and a vulnerability where's
the no bless oblige where's the obligation of having that much power to actually be a good
steward of power a steward of that for other people where if there are reward circuits that
decrease the quality of their life reward circuits that increase it that we're trying to appeal to
one rather than the other could we do that yeah totally we could could we have an education system
as a result that was identifying innate aptitudes innate interests of everyone and facilitating
their development so not only did they become good at something but they became increasingly
more intrinsically motivated fascinated and passionate by life which also meant continuously
better at the thing well in a world of increasing technological automation coming up both robotic
and AI automation where so many of the jobs are about to be obsolete
our economy and our education system have to radically change to deal with that because
the core of like one of the core things an economy has been trying to do forever was
deal with the need that a society had for a labor force and that there were these jobs that
society needed to get done that nobody would really want to do so either the state has to force them
to do it or you have to make it to where the people also need the jobs so there's a cemetery and so
kind of the market forces them to do it well when you technologically automate those jobs and it
happens to be that the things that are the most wrote are the least fun for people and the easiest
to program machines to do and so if you keep the same economy where if people don't produce
they don't have any basic needs met then people want those crappy jobs right but if you make it
to where they have other opportunities then of course having those jobs be automated is fine
but what does it mean to really be able to have other better opportunities so
if one of the fundamental like axioms of our all of our economic theories is that we need to figure
out how to incent a labor force to do things that nobody wants to do an emerging technological
automation starts to debase that that means we have to rethink economics from scratch because
we don't have to do that thing anymore so maybe if now the jobs don't need the people can we remake
a new economic system where the people don't need the jobs can we start to create commonwealth
resources that everyone has access to where people's access does not isn't based on possession that
automatically limits everyone else's access if you get around transportation wise with a car
based on owning that car where the vast majority of the life of the car it's just sitting not being
used for you to have access to the car you have to have possession of it which means that it's a
mostly underutilized asset i don't have access to the thing that you possess now what we see with
uber of course is a situation where your access is not mediated by your possession so now turn that
into electric self-driving cars and now make the entire thing on a blockchain so you disintermediate
even the central business make it a commonwealth resource and everyone has access to transportation
as a commonwealth resource it'll take a 20th of the number of cars to meet the same level of
convenience during peak demand time so much less environmental harm it'll actually be more
convenient because i don't have to be engaged in driving the thing and there's less traffic because
the coordination and better maintenance and there isn't a desire for an incentive for designed
an obsolescence in that system you can see a situation where okay can we make it to where the
wealth augmenting capacity of that technologic automation goes back into a commonwealth because
we don't have to have the same axioms of needing to incent the people oh yeah but if you don't
incent the people there'll all be lazy welfare people nonsense einstein didn't do what he did
based on economic incentive and neither did mozart and neither did gondian and none of the people
that we are most inspired by through history were doing that and what kids will who will spend so
much time doing where they ask questions about why this why this why this and building forts and
whatever is intrinsic motive it's just we don't facilitate the things that they're interested
in we try to force them to be interested in things they aren't interested in that's what ends up
breaking their interest in life and then they just want a hyper normal stimuli and play video
games whatever what if you had a system that was facilitating their interest the entire time now you
have a situation where you can start to decrease the total amount of extrinsic incentive in the
system as a whole use the technology to the automation to decrease the need for extrinsic
incentive and make an educational system and culture that's about optimizing intrinsic incentive
because if my needs are already met getting stuff there's no and everybody's needs are met
through access to commonwealth resources there's no real status conferred that there's only status
conferred by what i create so now there is a any status is bound to a kind of creative imperative
that's an example we can look at blockchain tech even more near term and say
but just to come back to this technological automation thing so obviously it makes possible
changing economics and changing education but also what is the role of humans in a post AI
robotic automation world because that is coming very very soon and what is the future of education
where you don't have to prepare people to be things that you can just program computers to be
well the role of education has to be based on what is the role of people in that world
that is such a deep redesign of civilization because the tech is changing the possibility set
that deeply so at the heart of this are kind of deep existential questions of what is a meaningful
human life and then what is a good civilization that increases the possibility space of that
for everybody and how do we design that thing we come back to blockchain and we say well blockchain
is an uncorruptible ledger well one thing that the left and right and everybody agrees on is
that we the corruption happens and it's bad for the society as a whole we don't like it we just
disagree on who does it is it possible that that tech could make possible decreasing corruption
as a whole actually decreases the possibility set for corruption yeah in order to do corruption
i have to be able to hide that i did it right i either have to to break enforcement or break
accounting and mostly it's break accounting and so what if all government spending was on a blockchain
and doesn't have to be a blockchain it has to be an uncorruptible ledger of some kind
hollow chain is a good example there that is pioneering another way of doing it but
uncorruptible ledger of some kind where you actually see where all taxpayer money goes
and you see how it was utilized the entire thing can have independent auditing agencies and the
public can transparently be engaged in the auditing of it and if the government is going
to privately contract a corporation the corporation agrees that if they want that government money
the blockchain has accounting has to extend into the corporation so there can't be
you know very very bloated corruption everybody got to see that when Elon made SpaceX all of a
sudden he was making rockets for like a hundreds to a thousands of the price that Lockheed or
Boeing were who had just had these almost monopolistic government contracts for a long time well if the
taxpayer money is going to the government is going to an external private contractor who's
making the things for a hundred to a thousand times more than it costs we get this false dichotomy
sold to us that either we have to pay more taxes to have better national security or if we want to
cut taxes we're going to have less national security what about just having less gruesome bloat
because you have better accounting and we make the rockets for a hundredth of the price and we
have better national security and better social services and less taxes well that's oh everyone
would vote for that right who wouldn't vote for that thing well that wasn't possible before
uncorruptible ledgers now that uncorruptible ledger also means you can have provenance on
supply chains to make the supply chains closed loop so that you can see that all the new stuff is
being made from old stuff and you can see where all the pollution is going and you can see who
did it which means you can now internalize the externalities rigorously and nobody can
destroy those emails or burn those files right what if the changes in law and the
decision-making processes also followed a blockchain process where there was a
provenance on the input of information well that would also be a very meaningful thing to be able
to follow so this is an example of like can we actually structurally remove the capacity for
corruption by technology that makes corruption much much much harder that forces types of
transparency on auditability what if also you're able to record history you're able to record the
events that are occurring in a blockchain that's uncorruptible where you can't change history later
so you actually get the possibility of real justice and real history and multiple different
simultaneous timelines that are happening that's humongous in terms of what it does what if you can
have an open data platform and an open science platform where someone doesn't get to cherry
pick which data they include in their peer reviewed paper later we get to see all of the data that
was happening we solve the oracle issues that are associated and then if we find out that a
particular piece of science was wrong later we can see downstream everything that used that output
as an input and automatically flag what things need to change that's so powerful like the least
interesting example of blockchain is currency creation these are actual like
the capacity for the right types of accounting means the right type of choice making right
let's take ai well with ai we can make super terrible deep fakes and destroy the epistemic
commons you know using that and other things like that but we can see the way that the ai makes the
deep fake by being able to take enough different images of the person's face and movements that it
can generate new ones we can see where it can generate totally new faces averaging faces together
somebody sent me some new work that they were just doing on this the other day i found very
interesting they said we're going to take a very similar type of tech and apply it to semantic
fields where we can take everybody's sentiment on a topic and actually generate a proposition that
is at the semantic center or take everybody's sentiment and abstract from it the values that
they care about and create values taxonomies and say we should come up with a proposition that meets
all these values then can you have digital processes where you can't fit everybody into a
into a town hall but everybody who wants to can participate in a digital space that rather than
vote yes or no on a proposition that was made by a special interest group where we didn't have a say
in the proposition or even the values it was seeking to serve so it was made in a very narrow
way that like we mentioned earlier benefits one thing and harms something else which is why
almost every proposition gets about half of the vote and inherently polarizes the population
well people are so dumb and so rival risk the process of voting with bad propositions and
and bad representation process is inherently polarizing and downgrading to people so what if
there's a process by which there's a decision that wants to be made you start by identifying
what are the values everybody cares about and then we say the first proposition that meets all these
values well becomes the thing that we vote on and then instead of just a direct vote do we
engage types of qualified and liquid democracy together where you have to show that you understand
the basics of that topic to be able to vote on it but the education is free and you can keep
retesting and the basics don't show leaning one way the other just shows you understand the stated
pros and cons so that massive populism doesn't happen but if you don't want to come to understand
it you can cede your vote to someone else who has passed that thing these are that type of liquid
democracy that type of qualified educated democracy where it doesn't have to be educated
across everything it can be per issue and where you're not just voting on a thing you're helping
craft the propositions these completely change the possibility space of social technology and we
could go on and on in terms of examples but these are ways that the same type of new emergent physical
tech that can destroy the epistemic commons and create autocracies and create catastrophic risks
could also be used to realize a much more pro-topic world so I love so many of those examples and I
especially on the blockchain and corruption one because I think as you said something that the
left and the right can both agree on is that our systems are not really functional and there's
definitely corruption and defection going on and just to add to your example imagine if citizens
could even earn money by spotting inefficiencies or corruption in that in that transparent ledger
so that we actually have a system that is actually profiting by getting more and more efficient
over time and actually better serving the needs of the people and having less and less corruption
and so there's actually more trust and faith and that's actually a kind of digital society
that when you look at let's say the closed China's digital authoritarian society and you look at this
open one that's actually operating more for the people with more transparency with more
efficiencies you get more SpaceX Elon Musk type cheap ways of sending rockets to the moon and
becoming a multi-planetary civilization as opposed to more bloat and more mega monopolies defense
contractors that are not taking us to where we need to go that's just an inspiring vision and I just
I hope people listen to what you shared and kind of go back because there's a lot of different
aspects there I think the question on many people's mind right now is going to be
how do we get from where we are to the world that you're talking about what are the steps that are
in between obviously I don't know nobody knows there's gonna like which projects emerge and
first and start really making success that there's a lot of different possible paths
I can say some of the things that could happen and some of the things that I think need to happen
so we take all the catastrophic risks that exponential tech makes possible and the dystopic
attractors and we say okay so we need to solve all those problems but we're not doing really good
at solving those problems right now so our problem solving processes need upgraded and
that means new institutions and when we say institution we usually think of a pretty centralized
thing and with things like decentralized governance emerging the institution might be a decentralized
one but it's individual people aren't going to solve all of that right so it's new
institutions centralized and decentralized that have the right capacities to solve these types
of problems need to come about all right well who develops those institutions and who empowers them
and this is where the democratic idea of the power of government coming from the consent of the
governed is one of the key ideas to what we would think of as the values of an open society let's
say that there's a small number of people who think we understand these problems we understand the
solutions it must happen everybody else doesn't get it so we're going to make this thing happen
and because we have the power we can just kind of implement it by force and so that becomes
its own dystopia right and implement it by force might be well the people think they need to be
free so we'll implement it by attention hijacking them so that they participate with it or don't
even realize that it's happening and they just keep doing whatever's next the cultural element
why we talk about the need for a new cultural enlightenment is of course when we look at
like the founding of the US we can see all that was super wrong with it right I mean just to mention
like how when Churchill said democracy was the worst form of government ever saved for all the
other forms there's when when Socrates talked about in in the republic when Plato was discussing it
why democracy was a dreadful idea the arguments are good arguments right like do you want
do you want people who understand seafaring to man the boat or just the general population who
knows nothing about it to man the boat well that's not a very good idea do you want the general
population that knows nothing about it to build the nasa rocket or do you want people that know
what they're doing well why would we think people who have no idea what they're doing are going to
be good at figuring out how a civilization should be run what should our nuclear first strike
policy should be how should we deal with the stability of the energy grid against Carrington
events and so what does it take to have a population educated enough and yet then if we say okay
but then the other problem is if we say the people are too uneducated and maybe too irrational
and rivalrous to be able to hold that power so it needs to be held by some how do we ensure
non-corruption and who is a trustworthy authority to be able to hold that power and not have vested
interest mess it up and so this is why I think it was a Jefferson quote of the ultimate depository
of the power must be the people and if we think the people too uneducated and unenlightened to be
able to hold that power we must do everything we can to seek to educate and enlighten them not
think that there is any other safe depository and so even with that we take the the U.S. formation
and you've got some founders who had read most of the books of the time right read most of the
books of philosophy knew the history of the Magna Carta and the Treaty of the Forest and all these
kinds of things thought and talked deeply spent many years were willing to die fighting a revolutionary
war were not going along with winning at the current system but really trying to do a fundamentally
different thing to develop a new system not everybody who was participating in the U.S.
was doing that thing they weren't all doing systems architecture right but they were all
basically saying we agree to this kind of systems architecture and we want to learn
how to participate with it adequately we'll read a newspaper we will do a jury duty we'll come to
the town hall that kind of thing so in Taiwan's example I think their population is 23 million
people and their online citizen engagement platform has something like five million people
engaging that's pretty awesome right that's not everybody and and no one should be forced to be
engaging and one of the critical things when we think deeper about is it a democracy is it a
republic is it a is it a epistocracy is it a we want to think about the values not the previous
frames for them and the values exist in dialectics and we need to be able to hold those together of
course we want individual liberty but we don't want individual liberty that gets to harm other
people and other things so we want also you know law justice collective integrity how do you
relate those things one of the core things is the relationship between rights and responsibilities
so there if I have rights and I don't have responsibilities there ends up being like tyranny
and entitlement if I and we can see that that's kind of rampant the entitlement thing if I have
responsibilities and I don't have any attendant rights at servitude neither of those involve
the healthy just society so if I want the right to drive a car the responsibility to do the driver's
education and actually learn how to drive a car safely is important and we can see that some
countries have less car accidents than others associated with better drivers education um
and so increasing the responsibility is a good thing we can see that some countries have way
less gun violence than others even factoring a similar per capita amount of guns based on more
training associated with guns and mental health and things like that so if I have a right to bear
arms do I also have a responsibility to be part of a well organized militia train with them and
be willing to actually sacrifice myself to protect the whole or sign up for a thing to do that do I
have to be a reservist of some kind those are the right responsibility if I want the right to vote
is there a responsibility to be educated about the issue yes yes now does that make it very unequal
no because the capacity to get educated has to be something that the society invests in making
possible for everyone and of course we would all be silly to not be dubious factoring the previous
history of these things but this is what we then have to insist upon because do we want people who
really don't understand the issues but think they do voting now that's a dreadful system
but do we want people who know something to have no avenue or who care do we want people who know
something to have no avenue to input that into the system or people who care to have no opportunity
to learn no that's also dreadful so how do we make the on ramps to learning available for everyone
not enforced but we're actually incentivizing can we use those same kind of social media behavior
and sending technologies to increase everyone's desire for more rights and attendant responsibilities
so that there's actually a gradient of civic virtue and civic engagement yeah we could totally do that
um so this is where the cultural enlightenment layer is of course not everyone is going to
be working on how do we develop AI and blockchain for these purposes but they can certainly be saying
I am going to make sure that my representatives are talking about these issues I want all the
presidential candidates to be talking about these issues I'm going to pay attention to and support
candidates who really do in earnest ways I'm going to invest in companies that are doing those
things I'm going to divest from companies that are doing the other things there is a cultural
enlightenment that is needed to be able to create the demand and the support for where those projects
that are earnestly working on and have the capability start to emerge
so you've painted a compelling vision of some of the ways that a open society could consciously
employ some of these technologies to revisit and re-fulfill some of the original values
for which they were intended how much of this how does this work with the existing institutions
that we have how much is this going to rely on transforming the existing digital leviathans
into something new how much is going to depend on blockchain projects how much is this going to
depend on existing institutions would be the the brookings institution or the new york times
can you speak to the role of new and future institutions in making this transition possible
yeah it's interesting when we look at institutions that emerged to try to solve some social or
environmental problems or nonprofits in particular and some government branches that are associated
with that there's this kind of structural perverse incentive that if i am an organization
which means i'm people in an organization that have some that have job security and some actual
power and access and whatever because of this position and my job is to solve a problem if
i fully solve the problem i would obsolete my job and obsolete myself so then there's this
kind of perverse incentive to continue managing the problem continue manufacturing the narrative
that we're needed to manage the problem continue manufacturing the narrative that the problem is
really hard and is hard to solve and so we got to keep you know doing this thing and so one of the
fundamental dispositions of systems is that they want to keep existing and so and yet they might no
longer be fit for purpose they might even be antithetical to the purpose we have to be very
careful about this um with regard to the new institutions we need to what degree could existing
institutions reform themselves to a degree does it need to be new ones it's kind of up to them
like it's kind of up to the the depth of realization of the need and the sincerity and then the
coordination capacity of people in current institutions how much role they could play
we can see the way that going into world war two coming out of the depression the us up regulated
its coordination capacity so profoundly so could we have a manhattan project like level
organization by organization i mean uh in the capacity to organize not a singular thing
that was oriented to how do we instantiate the next model of civilization how do we
instantiate the next model of social systems and social technologies what is the future of
education what's the future of economics what's the future of uh the fourth estate of law etc
that are that fulfill the values that are meaningful and are antifragile in the presence
of the current technologies and that can actually compete with the other applications of those
technologies towards things that serve different values and or aren't antifragile um i would love
to see the us make that a central imperative manhattan project level to be able to do that
not just how do we create a more powerful military but how do we create a more powerful
a healthier fundamentally a healthier society that up regulates and engages collective intelligence
in its own problem solving and innovation better i would like to see lots of countries do that i
think there are countries that uh did not yet transition to democracy are interested in it and
completely bypass the industrial era democracies and go directly to better systems i think networks
of small countries you see what taiwan is doing estonia is trying to do some interesting things
i think networks of small countries could start sharing best practices and sharing resources so
they don't all have to develop the stuff from scratch which could start to lead to coalitions
of countries like the e u saying let's do some fundamentally better things i think it will happen
also not at the level of nation states where like decentralized groups blockchain type groups say all
right let's really earnestly take on what these primary problems are and work on developing
these solutions in these capacities uh for the tech companies to do so would be very hard because
while it could be
still profitable long term it would not be profit maximizing short term relative to the
current thing they're doing as we said winning at the current game and building a new game are
different things and winning at a current game that self terminating is a very short sighted thing
to want to keep doing so if facebook or google or whatever were to cut its ad model it would
have a hard time being able to meet its fiduciary responsibility to shareholders a different way
but could it in conjunction with a uh participatory government regulatory process that wanted to help
change its fiduciary responsibility um where it's became more of a social utility start to
actually redirect its technology and redirect its decision making process yeah it could that would
be super interesting um so i would like to see that as we mentioned earlier i'd like to see the
un recognize that the level of progress that it has made at the sustainable development goals
nuclear deproliferation and other types of international things like economic equality
globally writ large and uh preventing arms races and tragedy of the commons that well it hasn't
done nothing what it's doing is not converge it's it's not adequate it's not converging on
eventually solving the problem set it needs not just more of that approach it needs a different
approach and so to say okay well clearly we don't know how to facilitate coordination of global
problems well enough so let's have a the superseding focus be innovation towards better methods of
global coordination that becomes our new number one goal because we know we only get all the other
goals if we get that and you can see that during world war two when we had to crack the enigma
machine and figure out computation and whatever we got touring we got von Neumann we got all of the
smartest people from countries all around the world engaged in solving those problems i would
like to see the us the un i would like to see other countries and i'd like to see private sector
taking seriously the actual problemscape we have and innovating not for just short-term advantage
or narrow in-group advantage but for long-term advantage of the whole how do we since we have
global effect how do we build global coordination adequate to what is needed to me that has to
become the central zeitgeist and and whatever groups figure out how to do it effectively will
be the groups that can direct the future muted sorry and i know that this is the work that you
are working towards with the conciliants project do you want to talk just about how you are working
towards that with with your work and how we're collaborating yeah i mean we're with the very
very beginning the conciliants project has a site update is not even a beta yet just because we
in just starting wanted to um you know work on building stuff in association with thinking
but uh this talk is very central this conversation you and i are having is very central to the aims
of the conciliants project which is we're wanting to inspire inform and help direct a innovation
zeitgeist where the many different problems of the world start to get seen in terms of having
interconnectivity and underlying drivers and that the forcing function of the power of exponential
tech is taken seriously that says in order to become good stewards of that requires
evolutions of both our social systems and our culture the wisdom to be able to guide that power
a recoupling right of wisdom and power in that adequate to what is needed so how do we innovate
in culture the development of people and how do we innovate in the social systems the advancement
of our coordination both employing the exponential tech and being able to rightly guide it and so
we have a really great team of people that are doing research and writing basically the
types of things we're talking about here in more depth explaining what is the role of
the various social systems like what is the role of education to any society help understand
fundamentally what that is understand why there is a particularly higher educational threshold
for open societies where people need to participate not just in the market but in governance
understand how that has been disrupted by the emerging tech and will be disrupted further by
things like technological automation and then envision what is the future of education adequate
to an open society in a world that has the technology that's emerging and we don't necessarily
know what the answer is but we know examples and we know criteria so then it's like innovate in
this area and make sure you factor these criteria and the same thing with the fourth estate the
same thing with law the same thing with economics and so the goal is not how do we take some small
group of people to build the future it's how do we help get what the criteria of a viable future
must be and if people disagree awesome publicly disagree and have the conversation now but if
we get to put out those design constraints someone says no we think it's other ones at least now
the center of culture starts to be thinking about the most pressing issues in fundamental ways and
how to think about them appropriately and how to approach them appropriately so fundamentally our
goal is supporting an increased cultural understanding of the nature of the problems that
we face a clearer understanding rather than just there's lots of problems and it's overwhelming
and it's a bummer and so either some very narrow action on some very narrow part of it makes sense
which is most of activism or just nihilism we want to be able to say actually because there are
underlying drivers there is actually a possibility to resolve these things it does require the fullness
of our capacity applied to it and with the fullness of our capacity so it's not a given but with the
fullness of our capacity applied to it there is actually a path forward and so we're writing these
papers that basically would be kind of like a a meta curriculum for people who want to be
engaged in designing the future and some of them have to do with current public culture and how to
be able to change patterns of public culture that leads to better conversation better sense making
better meaning making and choice making so that there's an on ramp into higher quality conversations
meaning higher quality process of conversation and then some of them are things like what are the
design criteria of the future social systems and how could how could we build those things then
not everybody will read those some people who have the ability to help start building them will
but we hope that other people will take that and translate it on podcasts and into animations and
in whatever other forms of media so that those topics start to become increasingly present in
people's awareness then of course the next part is what groups start emerging wanting to address
those and what can we do to help facilitate good solutions in those groups and this is where you
know you and I I've learned a lot from you about the the social media issues in particular and how
central they are to the breakdown of sense making because obviously without good shared sense making
there is no possibility for emergent order you either just get chaos or you have to have imposed
order if you want emergent order that means emergent good choice making that means emergent
good sense making and so you know we we've learned a lot and discussed these things for a long time
and obviously also not just you and I there's a whole network of people that we're connected to
that had been thinking deeply about these things that we continue to try to think about what adequate
solutions could look like and I think what CHT did with the social dilemma took one really critical
part of this meta crisis into popular attention maybe in a more powerful way than I have seen
done otherwise because as big a deal is getting climate change and public attention is it's not
clear that climate change is something that is making that is driving the underlying basis of
all the problems but a breakdown in sense making and the control of patterns of human behavior that
kind of downgrade people like oh wow that really does make all these other things worse so I see
that as a as a very powerful and personal on ramp for those who are interested to be able to come
into this deeper conversation and some some of them it'll simply help them be like okay
now I know what I was intuitively feeling somebody's put it into words and I at least
feel more oriented and that's the extent because they don't necessarily have the ability to build
new blockchain systems or whatever it is and they should be doing the nursing or education
or whatever really other important social value they're doing some people will be able to say
this actually really resonates I can translate this to other audiences
and get more people engaged and some people say I can actually start innovating and working with
this stuff and all of those are good yeah I I agree and I think what we've essentially been
outlining here and you sort of hit it at the end is going back to the the Charles Kettering quote
which I learned from you and I've learned so many things from you over the years
which is that a problem not fully understood is unsolvable and a problem that is fully
understood is half solved and I just want to maybe leave our listeners with that which is
I think people can look at the long litany of problems and feel overwhelmed or get to despair
and a hurry I think is your phrase for it and I think that when you understand the core generator
functions for what is driving so many of these problems to happen simultaneously there's a
different and more empowering relationship to that and you've actually offered a vision for how
technology can be consciously employed these new technologies can be consciously employed
in ways that should feel inspiring and exciting I mean I want that transparent blockchain on a
budget for every country in the world and we can see examples like Estonia and Taiwan moving in
this direction already and we can see Taiwan building some of the technologies you mentioned to
identify propositions of shared values between citizens who want to vote collectively on something
that previously would have driven up more polarization so we're seeing this this thing
emerging and I think what we need is to sort of have this be seen as a necessary upgrade to
let me do that again I think we need to see this as not just an upgrade but but the the kind of
cultural enlightenment that you speak of that so many different actors are in a sense already
working on you know we used to have this phrase that everyone is on the same team they just don't
know it yet and once you understand the I think degree to which we are in trouble if we do not
get our heads around this and and identify the kind of core generator functions that we need to
be addressing once we all see that I'll just speak to my own experience when I first encountered
your work and I encountered the kind of core drivers that that drive so much of the danger that
we are headed towards I immediately I was kind of already in this direction already but I reoriented
my whole life to say how do we be in service if this not happening and and of creating a better
world that actually meets and addresses these problems and I know so many other people whose
work and whose lives and whose daily missions and purpose have been redirected by I think hearing
some of the core frames that you offer and who I hope and who are you know many of whom are already
working on active projects to deal with this and those who are not are supporting in other ways
and I just hope that our audience takes this as an inspiration for how can we in the face of
stark and difficult realities as part of this process gain the kind of cultural
strength to to face these things head on and to orient our lives accordingly because I have
while you know bearing periods of time hit probably low you know low grade despair myself
I actually feel more inspired than ever the amount of things in the number of people who
are waking up to these challenges and I'll just say that that I think when you face these challenges
alone and you feel like you're the only one seeing them or you have a weird feeling in your stomach
it can feel debilitating and when you realize the number of people who are also putting their
heads up to say how can we change this that's what feels hopeful and that's where I derive
my optimism so Daniel thank you so much for for coming on it's an honor to have you your work has
touched the lives and work of so many people who may not always say so publicly but I know that you
had also a huge hand in inspiring some of the themes that emerge in the social dilemma which
has impacted so many people as well so thank you so much really wonderful that we get to have this
conversation thanks just on absolutely
you
