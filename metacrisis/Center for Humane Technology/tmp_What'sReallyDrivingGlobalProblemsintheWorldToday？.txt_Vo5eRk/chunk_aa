Welcome to Your Undivided Attention. Today, I am so honored and happy to have my friend
Daniel Schmacktenberger as our guest who works on the topics of existential risk and what
are the underlying drivers of all of the major problems or many of the major problems that
are really facing us today as a civilization, be it climate change, breakdown of truth,
social media, our information systems. Those of you who've been following Your Undivided
Attention will hear this as a very different kind of episode. We almost think of it as a meta
episode about the underlying drivers of many of the topics that we have covered on Your Undivided
Attention thus far. So if you think about the topics that we've covered, whether you've seen
the social dilemma or you followed our interviews previously on topics like attention span shortening
or addiction or information overwhelm and distraction, the fall of trust in society, more
polarization, breakdown of truth, our inability to solve problems like climate change, well this
is really about an interconnected set of problems and the kind of core generator functions that
are leading to all of these things to happen at once. And so I really encourage you to listen to
this all the way through and I think that we're going to get into some very deep and important
knowledge that will hopefully be orienting for all of us. One of my favorite quotes is by Charles
Kettering who said that a problem not fully understood is unsolvable and a problem that is
fully understood is half solved. And what I hope we talk about with Daniel is what about the framework
that we are using to address or try to meet the various problems that we have has been inadequate
and what is the problem-solving framework that we're going to need to deal with the existential
crises that face us. So Daniel, welcome to Your Undivided Attention. Thank you Tristan. I've been
looking forward to us dialoguing about these things publicly for a while. Well you and me both
and for those who don't know Daniel and I have been friends for a very long time and his work has
been highly influential to me and many people in my circles. So Daniel, maybe we should just start
with what is the metacrisis and why are these problems seemingly not getting solved whether it's
the SDGs, climate change, or anything that we really care about right now. I think a lot of
people have the general sense that there is an increasing number of possibly catastrophic issues
and that as new categories of tech, tech that allows major cyber attacks on infrastructure,
tech that allows weaponized drone attacks on infrastructure, biotechnologies, artificial
intelligence and moving towards AGI, that there are new catastrophic risks with all of those
categories of tech and that those tech are creating larger jumps in power faster than any
types of jumps of tech including the development of the nuclear bomb in the past by many orders
of magnitude. So there's a general sense that whether we're talking about future pandemic
related issues or whether we're talking about climate change or climate change as a forcing
function for human migration that then causes resource wars and political instability or
the fragility of the highly interconnected globalized world where a problem in one part
of the world can create supply chain issues that create problems all around the world,
there's a sense that there's an increasing number of catastrophic risks and that they're
increasing faster than we are solving them and that when you mention like with the UN
while progress has been made in certain defined areas of the sustainable development goals
and progress was made back when they were called the millennium development goals
we're very far from anything like a comprehensive solution to any of them we're not even on track
for something that is converging towards a comprehensive solution and if we look at kind of
the core initial mandate of the united nations in terms of thinking about how to recognizing after
world war two that nations take government alone wouldn't prevent world war and now that world
war was no longer viable because the amount of technology we had made it a war that no one could
win we still haven't succeeded at nuclear disarmament we did some very limited nuclear
disarmament success while doing nuclear arms races at the same time and we went from two
countries with nukes to more countries with better nukes and that's simultaneous to that every new
type of tech that has emerged has created an arms race we haven't been able to prevent any of those
and the major tragedy of the commons issues like climate change and overfishing and dead zones
in the oceans and microplastics in the oceans and biodiversity loss we haven't been able to solve
those either and so rather than just think about this as like an overwhelming number of totally
separate issues the question of why are the patterns of human behavior as we increase our
total technological capacity why are they increasing catastrophic risk and why are we not solving them
well are there underlying patterns that we could think of as as you mentioned generator functions
of the catastrophic risk generator functions of our inability to solve them that if we were to
identify those and work at that level we could solve all of the expressions or symptoms and if
we don't work at that level we might not be able to solve any of them and again people have been
thinking about this for a long time kind of notice these issues they notice that you try to solve a
like the first one I noticed when I was a kid was trying to solve an elephant poaching
issue in one particular region of Africa that didn't address the poverty of the people that
had no mechanism other than black market on poaching didn't address people's mindset towards
animals didn't address a macro economy that created poverty at scale so when the laws were put in
place and the fences were put in place to protect those elephants in that area better the poachers
moved to poaching other animals particularly in that that situation rhinos and gorillas that
were both more endangered than the elephants had been so you moved a problem from one area to another
and actually a more sensitive area and we see this with well can we solve hunger by bringing
commercial agriculture to parts of the world that don't have it so that the people don't either not
have food or we have to ship them food but if it's commercial agriculture based on the kind of
unsustainable environmentally unsustainable agricultural processes that lead to huge amounts
of nitrogen runoff going into river deltas that are causing dead zones in the ocean
that can actually collapse the biosphere's capacity to support life faster than we're
solving for a short-term issue that's important and driving even worse long-term issues we see
that many of the reasons people who oppose climate change solutions in the west oppose them is because
not because they have even really deeply engaged in the underlying science and say
the climate change isn't real that will oftentimes be what's said but because the solution itself
seems like it'll cause problems to other areas that they're paying attention to that seem even
more critical to them so if the solution involves some kind of carbon tax or something that would
decrease GDP for the countries that agree to it and some other countries don't agree to it and
let's say in this particular case the model that many people have is western countries agree to
it their GDP growth decreases China doesn't agree to it and there's already a very very close
neck-and-neck fight for who controls power in the 21st century are we ceding the world to
Chinese control that many people would think it has less civil liberties and is more authoritarian
in its nature and so or some people's answer to climate change is what we just have to use
less energy but when you understand the energy correlates directly to GDP and when GDP goes down
it affects poverty people in extreme poverty first and worst and wars increase because
people who have desire to get more end up going zero sum on each other and only when it's very
positive some does that not happen you see all these intricate theory of trade-off so we can't see
that the problem is climate change everybody knows problems you know the problem of climate change
seems like a big thing but you've got to look at climate change plus the macroeconomic issues that
would affect the poorest people and that would increase the chance of war and the geopolitical
dynamics between the west and China whatever and the enforcement dynamics of international
agreement when you start to recognize that the problem is that suite of things together in a
way it seems well that's too hard we can't even begin to focus on it I would say that that's actually
easier because trying to solve climate change on its own is actually impossible because if
you're trying to solve something that is going to externalize harm to some other thing maybe the
other thing that you maybe you solve that thing but you find out that you're in a worse position
so I would say that it's impossible to actually improve the world that way or half the world that
is paying attention to that other thing disagrees with you so vehemently that all the energy goes
into infighting and whatever some part of the world is trying to organize to do the other part of
the world is doing everything they can to resist from happening then all the creative energy just
burns up as heat and we don't actually accomplish anything so I would say that the way we're trying
to solve the problems is actually mostly impossible it either solves it in a very narrow way while
externalizing harm and causing worse problems or it makes it impossible to solve it all because it
drives polarization and so going to the level at which the problems interconnect where that which
everybody cares about is being factored and where you're not externalizing other problems well it
seems more complex is actually possible impossible is easier than impossible and so it's not just
that there's a lot of issues right there are a lot of issues and just that the issues are both
more consequential at greater scope and moving faster than previous issues because of the nature
of exponentiating technology that's part of it it's not just that the problems are all interconnected
it's also that they do have underlying drivers that have to be addressed otherwise a symptomatic
only approach doesn't work the first underlying driver that when people look at it they generally see
is they see things like structural perverse incentive built into macroeconomics that
the elephant dead is worth more than the elephant alive is and so is the rhino and so is the and
so how do you have a situation where that's the nature of incentive where you're incentivizing
an activity and then trying to bind it or keep it from happening and the same would be true with
overfishing as long as live fish are worth nothing and dead fish are worth more and you have there's
something fundamentally perverse about the nature of the economic incentive and the same is true that
when war goes when we have war and there's more military manufacturing GDP goes up and when there's
more addiction and people are buying the supply of their addiction GDP goes up and when there are
more sick people paying for health care cost GDP goes up so it's obviously a perverse kind of metric
so anytime someone can fiscally advantage themselves or a corporation can
in a way that either directly causes harm or indirectly externalizes harm
we have to fundamentally solve that if there's something like 70 trillion dollars a day of
activity happening that is a decentralized system of incentive that is incenting people to do things
that are directly or indirectly causing harm there's really nothing we can do with some
billions of dollars of non-profit or state or whatever money that is going to solve that thing
so we have to say well what changes at the level of macroeconomics need to happen where the incentive
of individuals and the incentive of corporations and the incentive of nations is more well aligned
with the well-being and the incentive of others and so we're less fundamentally rival risk in the
nature of our incentive so we can see that underneath heaps of the problems structures of macroeconomic
incentive are there that's the kind of maybe the first one that most people see we can go deeper
to seeing that even as an expression because whether it's a economic incentive for a corporation
or whether it's a power incentive a political power incentive or a political party or for a country
they're both instantiations of rival risk type dynamics that end up driving arms races because
if you win at a rival risk dynamic the other side reverse engineers your tech figures out how to make
better versions comes back which creates an exponentiation in warfare and eventually exponential
warfare becomes self-terminating on a finite planet exponential externalities also become
self-terminating so if we want to say what are the underlying generator functions of catastrophic risk
first maybe just to make clear the catastrophic risk landscape is this all right if we do a brief
aside on that yeah let's do it and then we're I think what we do let's do that and then let's
recap just what these structures are so people are tracking each of these components because
you've already mentioned a few different things I mean the first thing is just many listeners
might hear what you're sharing as an overwhelming set of problems and I think it's just to recap
it's important people understand that it's overwhelming if you're not using a problem
solving framework that allows you to see the interconnected nature of those problems because
if you solve them with the limited tools we have now let's just solve the social media problem by
pulling one lever and changing one business model of one company or banning TikTok but then
you get 20 other TikToks that come and sit in its place with the same perverse incentive of addiction
the same rival risk dynamic competing for human attention we're going to end up perpetuating
those problems and so just to sort of maybe recap some of that for listeners and I think maybe let
you continue with the other generator function let's just make sure that people really get
those frameworks I think it's really important yeah I mean in the case that you in
Center for Humane Technology have brought so much attention to with regard to the attention
harvesting and directing economy it's it's fair to say that it's probably was not Facebook or
Google's goal to create the type of effects that they had those were unintended externalities
they were second order effects but they were trying to solve problems right like let's solve
the problem if we're Google of organizing the world's information and making better search
that seems like a pretty good thing to do and let's solve the problem of making it freely
available to everybody that seems like a pretty good thing to do and with the ad model we can
make it freely available to everyone and let's recognize that only if we get a lot of data will
our machine learning get better and so we need to actually get everybody on this thing so we
definitely have to make it free and you know then we get this kind of recursive process well then
the nature of the ad model doing time on site optimization and I'm stuff I'm not going to get
into because you've addressed it so well ends up appealing to people's existing biases rather
than correcting their bias appealing to their tribal in-group identities rather than correcting
them and appealing to limbic hijacks rather than helping people transcend them and as a result you
end up actually breaking the social solidarity and epistemic capacity necessary for democracy so
it's like oh let's let's solve the search problem that seems like a nice thing the side effect is
we're going to destroy democracy and open societies in the process and all those other things like
those are examples of solving a problem in a way that is externalizing harm causing other problems
that are oftentimes worse and so we the the let's just focus on the opportunities
and just to say typically this this will get accounted for as oh this is just an
unintended consequence but there's some other generator functions I think we should outline I
mean if if YouTube and Google didn't personalize search results and what video to show you next
and the other guy did on tiktok starts personalizing they're caught in a race to the bottom of whoever
personalizes more for the best limbic hijack and so just to sort of connect some of those
those themes together for for listeners so you mentioned race to the bottom and obviously
cht has discussed this before and this is a key uh piece of the game theoretic challenge and global
coordination and the two primary ways it expresses itself is arms races and tragedy of the comments
and the tragedy of the comment scenario is if we don't overfish that area virgin ocean
but we can't control that someone else doesn't because how do we do enforcement if they're
also a nuclear country that's a tricky thing right how do you do do enforcement on nuclear
countries equipped countries so us not doing it doesn't mean that the fish don't all get taken
it just means that they grow their populations and their GDP faster which they will use rival
wristly so we might as well do it in fact we might as well race to do it faster than they do
that's the those are the tragedy of the comments type issues the arms race version is if we can't
ensure that they don't build a AI weapons or they don't build surveillance tech and they get
increased near-term power from doing so we just have to race to get there before them
that's the arms race type thing it just happens to be that while that makes sense for each agent
on their own in the short term it creates a global dynamics for the whole in the long term
that self-terminate because you can't run exponential externality on a finite planet
that's the tragedy of the commons one and you can't run exponential arms races and exponential
conflict on a finite planet so the thing that has always made sense which is just keep winning at
the arms races has had a world where we've had lots of wars increasing in their scale and lots
of environmental damage we started desertification thousands of years ago it's just there's been
a long slow exponential curve that really started to pick up with the industrial revolution and is
now really verticalizing with the digital revolution and the cumulative harm of that kind of thing
becomes impossible now so basically with the environmental destruction with the wars and
with the kind of class subjugation things that civilizations have in the past it pretty much
