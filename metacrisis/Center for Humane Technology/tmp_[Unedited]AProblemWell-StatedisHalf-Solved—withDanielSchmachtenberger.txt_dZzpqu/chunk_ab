So we have to say, well, what changes at the level of macroeconomics need to happen
where the incentive of individuals and the incentive of corporations and the incentive of nations
is more well aligned with the well-being and the incentive of others.
And so we're less fundamentally rivalrous in the nature of our incentive.
So we can see that underneath heaps of the problems, structures of macroeconomic incentive are there.
That's kind of maybe the first one that most people see.
We can go deeper to seeing that even as an expression,
because whether it's a economic incentive for a corporation or whether it's a power incentive,
a political power incentive or a political party or for a country,
they're both instantiations of rivalrous-type dynamics that end up driving arms races,
because if you win at a rivalrous dynamic, the other side reverse-engineers your tech,
figures out how to make better versions, comes back, which creates an exponentiation in warfare
and eventually exponential warfare becomes self-terminating on a finite planet.
Exponential externalities also become self-terminating.
So if we want to say, what are the underlying generator functions of catastrophic risk?
First, maybe just to make clear, the catastrophic risk landscape.
Is this all right if we do a brief aside on that?
Yeah, let's do it.
I think what we should do, let's do that, and then let's recap just what these structures are.
People are tracking each of these components, because you've already mentioned a few different things.
The first thing is just many listeners might hear what you're sharing as an overwhelming set of problems,
and I think it's just to recap.
It's important people understand that it's overwhelming if you're not using a problem-solving framework
that allows you to see the interconnected nature of those problems,
because if you solve them with the limited tools we have now,
let's just solve the social media problem by pulling one lever and changing one business model of one company,
or banning TikTok, but then you get 20 other TikToks that come and sit in its place with the same perverse incentive of addiction,
the same rival risk dynamic competing for human attention.
We're going to end up perpetuating those problems.
And so just to sort of maybe recap some of that for listeners,
and I think maybe let you continue with the other generator function.
Let's just make sure that people really get those frameworks.
I think it's really important.
Yeah, I mean, in the case that you in Center for Humane Technology have brought so much attention to,
with regard to the attention harvesting and directing economy,
it's fair to say that it probably was not Facebook or Google's goal to create the type of effects that they had.
Those were unintended externalities.
They were second order effects.
But they were trying to solve problems, right?
Like, let's solve the problem if we're Google of organizing the world's information and making better search.
That seems like a pretty good thing to do.
And let's solve the problem of making it freely available to everybody.
That seems like a pretty good thing to do.
And with the AdModel, we can make it freely available to everyone.
And let's recognize that only if we get a lot of data will our machine learning get better.
And so we need to actually get everybody on this thing.
So we definitely have to make it free.
And then we get this kind of recursive process.
Well, then the nature of the AdModel, doing time on site optimization and stuff I'm not going to get into because you've addressed it so well,
ends up appealing to people's existing biases rather than correcting their bias,
appealing to their tribal in-group identities rather than correcting them,
and appealing to limbic hijacks rather than helping people transcend them.
And as a result, you end up actually breaking the social solidarity and epistemic capacity necessary for democracy.
So it's like, oh, let's solve the search problem.
That seems like a nice thing.
The side effect is we're going to destroy democracy and open societies in the process and all those other things.
Like, those are examples of solving a problem in a way that is externalizing harm,
causing other problems that are oftentimes worse.
And so let's just focus on the opportunity.
And just to say, typically, this will get accounted for as, oh, this is just an unintended consequence.
But there's some other generator functions I think we should outline.
I mean, if YouTube and Google didn't personalize search results and what video to show you next,
and the other guy did on TikTok starts personalizing, they're caught in a race to the bottom of whoever personalizes more for the best limbic hijack.
And so just to sort of connect some of those things together for listeners.
So you mentioned race to the bottom, and obviously CHT has discussed this before,
and this is a key piece of the game theoretic challenge and global coordination.
And the two primary ways it expresses itself is arms races and tragedy of the commons.
And the tragedy of the commons scenario is if we don't overfish that area of virgin ocean,
but we can't control that someone else doesn't, because how do we do enforcement if they're also a nuclear country?
That's a tricky thing, right? How do you do enforcement on nuclear countries, equipped countries?
So us not doing it doesn't mean that the fish don't all get taken.
It just means that they grow their populations and their GDP faster, which they will use rivalrously.
So we might as well do it. In fact, we might as well race to do it faster than they do.
Those are the tragedy of the commons type issues.
The arms race version is if we can't ensure that they don't build AI weapons or they don't build surveillance tech
and they get increased near-term power from doing so, we just have to race to get there before them.
That's the arms race type thing.
It just happens to be that while that makes sense for each agent on their own in the short term,
it creates global dynamics for the whole and the long term that self-terminate,
because you can't run exponential externality on a finite planet.
That's the tragedy of the commons one, and you can't run exponential arms races and exponential conflict on a finite planet.
So the thing that has always made sense, which is just keep winning at the arms races,
has had a world where we've had lots of wars increasing in their scale and lots of environmental damage.
We started desertification thousands of years ago.
It's just has been a long, slow, exponential curve that really started to pick up with the industrial revolution
and is now really verticalizing with the digital revolution and the cumulative harm of that kind of thing becomes impossible now.
So basically, with the environmental destruction, with the wars and with the class subjugation things that civilization has had in the past,
pretty much anyone would say we have not been the best stewards of power, and technology is increasing our power.
Exponential tech means tech that makes better versions of itself, so you get an exponent on the curve.
We're now in a process where that's a very, very rapid.
Computation gives the ability to design better systems of computation.
Computation and AI applied to biological big data and protein folding gives the ability to do that on biotech and on and on, right?
So we could say the central question of our time is if we've been poor stewards of power for a long time and that's always caused problems,
but the problems now become existential, they become catastrophic, we can't keep doing that.
How do we become adequately good stewards of exponential power in time, right?
How do we develop the good decision-making processes, the wisdom necessary to be able to be stewards of that much power?
I think that's a fair way to talk about the central thing.
If it's okay, the thread we were about to get to, I think, is a good one, which was the history of catastrophic risk coming up to now,
is that before World War II, catastrophic risk was actually a real part of people's experience.
It was just always local, but an individual kingdom might face existential risk in a war where they would lose.
And so the people faced those kinds of reality, and in fact, one thing that we can see when you read books like The Collapse of Complex Societies by Joseph Tainter
and any study of history is that all the great civilizations don't still exist, which means that one of the first things we can say about civilizations is that they die.
They have a finite lifespan on them.
One of the interesting things we can find is that they usually die from self-induced causes.
They either over-consume the resources and then stop being able to meet the needs of the people through unrenewable environmental dynamics, and that's old.
Or they have increasing border conflicts that lead to enmity, that has more arms race activity coming back at them,
or they have increasing institutional decay of their internal coordination processes that leads to inability to operate quickly in those types of things.
So we can say that it's the fundamentally most all civilizations collapse in a way that is based on generally self-terminating dynamics.
And we see that even when they were overtaken by armies, oftentimes they were armies that were smaller than ones they had defended against successfully at earlier peaks in their adaptive capacity.
Okay, so catastrophic risk has been a real thing. It's just been local.
And it wasn't until World War II that we had enough technological power that catastrophic risk became a global possibility for the first time ever.
And this is a really important thing to get because the world before World War II and the world after was different and kind so fundamentally.
And this is why when you study history, so much of what you're studying is history of warfare, of neighboring kingdoms and neighboring empires fighting.
And because the wars were fundamentally winnable, at least for some, right? They weren't winnable for all the people who died, but at least for some.
And with World War II and the development of the bomb became the beginning of wars that were no longer winnable.
And that if we employed our full tech and continued the arms race even beyond the existing tech, it's a war where when lose becomes omni-lose-lose at that particular level of power.
And so that created the need to do something that humanity had never done, which was that the major superpowers didn't war.
The whole history of the world, the history of the thing we call civilization, they always did.
And so we made an entire world system, a globalized world system that was with the aim of preventing World War III.
So we could have non-kinetic wars, and we did, right? Increasingly you can see from World War II to now a movement to unconventional warfare,
narrative and information warfare, economic, diplomatic warfare, those types of things, resource warfare.
And you could, if you were going to have a physical kinetic war, it had to be a proxy war.
But to have a proxy war, that also required narrative warfare to be able to create a justification for it.
But also to be able to prevent the war, so the post-World War II Bretton Woods Mutually Assured Destruction United Nations World
was a solution to be able to steward that level of tech without destroying ourselves.
And it really was a reorganization of the world. It was a whole new advent of social technologies or social systems,
just like the U.S. was new social technologies or social systems coming out of the Industrial Revolution.
The Industrial Revolution ended up giving rise to kind of nation-state democracies.
The nuclear revolution in this way kind of gave rise to this I.G.O. intergovernmental world.
And it was predicated on a few things. Mutually Assured Destruction was critical.
Globalization and economic trade was critical that we, if the computer that we're talking on and the phone that we talk on
is made over six continents and no countries can make them on our own, we don't want to blow them up and ruin their infrastructure
because we depend upon it. So let's create radical economic interdependence so we have more economic incentive to cooperate.
Makes sense. And let's grow the materials economy so fast through this globalization
that the world gets to be very positive GDP and gets to be very positive sum
so that everybody can have more without having to take each other's stuff.
That was kind of like the basis of that whole world system.
And we can see that we've had wars, but they've been proxy wars and cold wars.
They haven't been major superpower wars and they've been unconventional ones.
But we haven't had a kinetic World War III. We have had increase of prosperity of certain kinds.
75 years give or take. Now we're at a point where that radically positive sum economy
that required an exponential growth of the economy, which means of the materials economy,
and it's a linear materials economy that unrenewably takes resources from the earth faster than they can reproduce themselves
and turns them into waste faster than they can process themselves, has led to the planetary boundaries issue
where it's not just climate change or overfishing or dead zones in the ocean or microplastics or species extinction
or peak phosphorus. It's a hundred things, right?
There's all these planetary boundaries so we can't keep doing exponential linear materials economy.
That thing has come to an end because now that drives its own set of catastrophic risks.
We see that the radical interconnection of the world was good in terms of will not bomb each other
but it also created very high fragility because what it meant is a failure anywhere could cascade to failures everywhere
because of that much dependence. So we can see with COVID we had what was a local issue to an area of China
but because of how interconnected the world is with travel it became a global issue at the pandemic level
and it also became an issue where to shut down the transmission of the virus we shut down travel
which also meant shut down supply chains which meant so many things, right?
And very fundamental things that weren't obvious to people at first like that countries agriculture depends upon the shipment of pesticides that they don't have stored
and so we got these swarms of locusts because of not having the pesticides which damaged the food supply
and shipments of fertilizer and shipments of seed so we end up seeing a drive of food insecurity of extreme poverty
at a scale of death threat that is larger than the COVID death threat was.
As a second order effect of our problem we were trying to solve the problem of don't spread COVID
and the solution had these massive second third order effects that are still playing out, right?
And that was a relatively benign pandemic a relatively benign catastrophe compared to a lot of scenarios we can model out
so we can say okay well we like the benefit of interconnectivity so we're not invested in bombing each other
but we need more anti-fragility in the system.
And then the mutually assured destruction thing doesn't work anymore because we don't have two countries with one catastrophe weapon
that's really really hard to make and easy to monitor because there's not that many places that have uranium
it's hard to enrich it you can monitor by satellites.
We have lots of countries with nukes but we also have lots of new catastrophe weapons that are not hard to make
that are not easy to monitor that don't even take nation states to make them.
So if you have many many actors of different kinds with many different types of catastrophe weapons
how do you do mutually assured destruction?
You can't do it the same way.
And so what we find is that the set of solutions post World War II that kept us from blowing ourselves up with our new power
lasted for a while but those set of solutions have ended and they have now created their own set of new problems.
So there's kind of the catastrophic risk world before World War II
the catastrophic risk world from World War II till now and then the new thing.
So the new thing says we have to have solutions that deal with the planetary boundary issues
that deal with global fragility issues and that deal with the exponential tech issues
both in terms of the way exponential tech can be intentionally used to cause harm
i.e. exponential tech empowered warfare and unintentionally
i.e. exponential tech empowered externalities and even just totally unanticipated types of mistakes
the Facebook Google type problem multiplied by AGI and things like that.
And so when we talk about what the catastrophic risk landscape is like that's the landscape
the metacrisis is how do we solve all of that and recognizing that our problem solving mechanisms
haven't even been able to solve the problems we've had for the last many years let alone prevent these things
and so the central orienting question it's like the UNS-17 Sustainable Development Goals
there's really one that must supersede them all which is develop the capacity for global coordination
that can solve global problems. If you get that one you get all the other ones
if you don't get that one you don't get any of the other ones and so we can talk about how do we do that
but that becomes the central imperative for the world at this time.
So you're saying a whole bunch of things and one thing that comes to mind here
if I'm just reading back some of the things you've shared
the development of the let's call it one of the first exponential technologies which is the nuclear bomb
led to a new social system which was sort of the post Bretton Woods world of trying to stabilize
that one exponential technology in the world in a way that would not be catastrophic
and even there we weren't able to sort of make it all work
and I think people should have maybe a list of some of the other exponential technologies
because I want to make sure that phrase is defined for listeners and there's a lot of different ways
that we've now not just created more exponential technologies but more decentralized exponential technologies
and I think people should see Facebook and Google as exponential attention mapping
or information driving technologies that are shaping the global information flows
