what they are to
private technology
corporations pursuing self-interest
to shareholders and are
profiting from the degradation
and dysfunction of democracies
and so
when we say all this and we talk about
how do we build the kind of next social system
and Audrey Tang and her work
I think people
get tripped up in thinking that what we really mean
is we have to make some kind of 21st century
digital democracy in fact I probably said those words
but what we're really talking about here
is some new concept that preserves
the principles of what we meant by
a democracy
but instantiated with the new technologies
our version of the new printing press
which is networked
information environments and
all of the new capacities that we have in the 21st century
with
mobility where everyone's connected to everywhere
and everything all at once
so what is that system
that leverages the current technology
and makes a stronger healthier open society
and I think Audrey Tang's work
I mean I would probably send listeners back
to listen to that episode I think it's one of our
most listened to and most popular episodes for a reason
because in Taiwan
she's essentially built an entire
civic technology ecosystem
in which people are really participating
in the governance of their society
we need masks, we need
better air quality sensors, we need to fix these
potholes, there are processes
by which every time you're frustrated by something
you actually get invited into a civic design process
where whether it's the potholes or the masks
you can actually participate in having a better
system
complaining about the tax system and filing your taxes
and maybe it's an inefficient form
or something like that you get brought into a design process
of what would make it better
and so the system is participatory but not in that
kind of 18th century way of hey there's a
physical wooden townhouse and we're going to walk into it
and we're going to hang out there for three hours
and we're going to yell and scream about issues that are more local
within 10, 15 miles
of where we are because we were existing in a world before automobiles
we're now talking about how do you do
an open society social system
but in a world with all of the new technologies
that are not just here today but emerging
and so do you want to talk a little bit
about what
how we even navigate that challenge
and why is some new social system like that
necessary
for dealing with these problems that you've
sort of laid out at the beginning
because I'm sure people would like to feel
less anxiety about those things
hanging around for longer
yeah I think
I think what
Taiwan has been doing
and what Audrey Tang
in the digital ministry position
in particular has been leading
is probably the best example
certainly one of the best examples in the world of this kind of
process in thinking
and
does it apply in the
or could it apply in the exact same way to the US
no of course not like we know that
because
of the relatively small geography
and
high-speed train transportation
you can get across Taiwan in an hour and a half
and so when you're mentioning the small scale
of local government at the beginning of the US
where you come to the town hall in a way they have
that right like it's 23 million people
but there is
an older shared culture
there is all there also happens
to be an existential threat just right
off their border that is
you know big enough that they can't
just chill and not focus on it
everyone has to be civically engaged
with some civic identity and like that
they didn't start making
their culture in the industrial era and then have to
upgrade it right like they started
later
where they're we're able to start at a higher
level of the tech stack
so there's a number of reasons why it's different
so we're not going to naively say what you do
in a tiny country that is culturally
and ethnically homogeneous
and has a higher GDP
education per capita and whatever is the same thing
you would do but we can certainly take a lot
of the examples and say how would
they apply differently in different
contexts
so
the thing we said earlier
that this suite of
exponential technologies is so much more powerful
than all of the previous types
of power that only
those who are
developing and deploying
them will be
really steering the direction of the future
and
that there are ways of employing them
that do cause
catastrophic risk
and
the catastrophic risk is of two primary
kinds right conflict theory mediated
and
you can't
you just can't do warfare
with this level of technology
and this interconnected a world
and make it through well
not all catastrophic risk means existential
doesn't all mean nuclear
war and nuclear winter and we've killed
all the mammals on earth it might
just mean we break global supply chains
kill lots of people and regress
humanity and the quality of the biosphere
pretty significantly so
I'm not
just focused on existential risk I'm interested
in kind of catastrophic risk
at scale in general
and we can see that exponential tech
applied
as
in conflict theory and in
mistake
as externalities and the cumulative effects
could you define
conflict theory and mistake theory for people
who are not familiar with those terms
yeah there's
a very nice
discussion on the less wrong forum
if people are interested to go deeper
and it's this question of
how much of the problems in the world
are the result of
conflict theory versus mistake theory
meaning conflict theory is
we knew we either wanted to cause
that problem that harm to whomever
as in a knowingly wanted to win
at a war and
or at least we knew we were
going to cause that problem and didn't care because
it was attached to something we wanted
right conflict theory or mistake
theory we didn't know we didn't want to cause
it and we really didn't know and it was just
unintended unanticipatable consequence
and it's fair to say that there's
both right there's plenty of both
one
thing that is worth knowing is that
if I
if I'm trying to do something that is
actually motivated by conflict theory
it benefits me to pretend that it was mistake
theory benefits me to pretend that I had no idea
and then afterwards say oh it was
an unintended unanticipatable consequence
it was too complex people can't predict stuff
like that and so
the reality
of mistake theory
ends up being a source of plausible
deniability for conflict theory
and
