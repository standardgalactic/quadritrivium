Hi, everyone. It's Tristan, and this is your Undivided Attention.
Up next, we have our unedited conversation with Daniel Schmacktenberger.
And because it's unedited, it's longer and not corrected for fact-checking purposes,
but you can find our shorter, edited version wherever you found this one.
Listen to both versions, and then come to our podcast club with Daniel and me,
and hopefully you, on July 9th. Details are in the show notes.
And with that, here we go.
Welcome to your Undivided Attention.
Today, I am so honored and happy to have my friend, Daniel Schmacktenberger,
as our guest, who works on the topics of existential risk
and what are the underlying drivers of all of the major problems,
or many of the major problems, that are really facing us today as a civilization,
be it climate change, breakdown of truth, social media, our information systems.
Those of you who've been following your Undivided Attention will hear this
as a very different kind of episode.
We almost think of it as a meta-episode about the underlying drivers
of many of the topics that we have covered on your Undivided Attention thus far.
So if you think about the topics that we've covered,
whether you've seen the social dilemma or you followed our interviews previously
on topics like attention span shortening or addiction or information overwhelm and distraction,
the fall of trust in society, more polarization, breakdown of truth,
our inability to solve problems like climate change,
well, this is really about an interconnected set of problems
and the kind of core generator functions that are leading to all of these things to happen at once.
And so I really encourage you to listen to this all the way through,
and I think that we're going to get into some very deep and important knowledge
that will hopefully be orienting for all of us.
One of my favorite quotes is by Charles Kettering,
who said that a problem not fully understood is unsolvable
and a problem that is fully understood is half-solved.
And what I hope we talk about with Daniel is what about the framework that we are using
to address or try to meet the various problems that we have has been inadequate
and what is the problem-solving framework that we're going to need
to deal with the existential crises that face us.
So Daniel, welcome to Your Undivided Detention.
Thank you, Tristan.
I've been looking forward to us dialoguing about these things publicly for a while.
Well, you and me both.
And for those who don't know, Daniel and I have been friends for a very long time,
and his work has been highly influential to me and many people in my circles.
So Daniel, maybe we should just start with what is the metacrisis
and why are these problems seemingly not getting solved,
whether it's the SDGs, climate change, or anything that we really care about right now?
I think a lot of people have the general sense that there is an increasing number
of possibly catastrophic issues and that as new categories of tech,
tech that allows major cyber attacks on infrastructure,
tech that allows weaponized drone attacks on infrastructure,
biotechnologies, artificial intelligence and moving towards AGI,
that there are new catastrophic risks with all of those categories of tech
and that those tech are creating larger jumps in power faster than any types of jumps of tech,
including the development of the nuclear bomb in the past by many orders of magnitude.
So there's a general sense that whether we're talking about future pandemic related issues
or whether we're talking about climate change or climate change as a forcing function
for human migration that then causes resource wars and political instability
or the fragility of the highly interconnected globalized world
where a problem in one part of the world can create supply chain issues
that create problems all around the world,
there's a sense that there's an increasing number of catastrophic risks
and that they're increasing faster than we are solving them.
And that when you mention like with the UN,
while progress has been made in certain defined areas of the sustainable development goals
and progress was made back when they were called the Millennium Development Goals,
we're very far from anything like a comprehensive solution to any of them.
We're not even on track for something that is converging towards a comprehensive solution.
And if we look at kind of the core initial mandate of the United Nations
in terms of thinking about how to recognizing after World War II
that nations take government alone wouldn't prevent World War
and now that World War was no longer viable
because the amount of technology we had made it a war that no one could win,
we still haven't succeeded at nuclear disarmament.
We did some very limited nuclear disarmament success while doing nuclear arms races at the same time
and we went from two countries with nukes to more countries with better nukes.
And that's simultaneous to that.
Every new type of tech that has emerged has created an arms race.
We haven't been able to prevent any of those.
And the major tragedy of the commons issues like climate change and overfishing
and dead zones in the oceans and microplastics in the oceans and biodiversity loss,
we haven't been able to solve those either.
And so rather than just think about this as like an overwhelming number of totally separate issues,
the question of why are the patterns of human behavior
as we increase our total technological capacity,
why are they increasing catastrophic risk and why are we not solving them well?
Are there underlying patterns that we could think of as,
as you mentioned, generator functions of the catastrophic risk,
generator functions of our inability to solve them,
that if we were to identify those and work at that level,
we could solve all of the expressions or symptoms.
And if we don't work at that level, we might not be able to solve any of them.
And again, people have been thinking about this for a long time,
kind of notice these issues.
They notice that you try to solve a,
like the first one I noticed when I was a kid
was trying to solve an elephant poaching issue in one particular region of Africa
that didn't address the poverty of the people that had no mechanism other than black market on poaching,
didn't address people's mindset towards animals,
didn't address a macroeconomy that created poverty at scale.
So when the laws were put in place and the fences were put in place
to protect those elephants in that area better,
the poachers moved to poaching other animals,
particularly in that situation rhinos and gorillas
that were both more endangered than the elephants had been.
So you moved a problem from one area to another and actually a more sensitive area.
And we see this with, well, can we solve hunger
by bringing commercial agriculture to parts of the world that don't have it
so that the people don't either not have food or we have to ship them food,
but if it's commercial agriculture based on the kind of unsustainable,
environmentally unsustainable agricultural processes
that lead to huge amounts of nitrogen runoff going into river deltas
that are causing dead zones in the ocean
that can actually collapse the biosphere's capacity to support life faster
than we're solving for a short-term issue that's important
and driving even worse long-term issues.
We see that many of the reasons people who oppose climate change solutions
in the West oppose them is because,
not because they have even really deeply engaged in the underlying science
and say the climate change isn't real,
that will oftentimes be what's said,
but because the solution itself seems like it'll cause problems
to other areas that they're paying attention to that seem even more critical to them.
So if the solution involves some kind of carbon tax
or something that would decrease GDP for the countries that agree to it
and some other countries don't agree to it,
and let's say in this particular case,
the model that many people have is western countries agree to it,
their GDP growth decreases, China doesn't agree to it,
and there's already a very, very close neck-in-neck fight
for who controls power in the 21st century.
Are we seeding the world to Chinese control
that many people would think it has less civil liberties
and is more authoritarian in its nature?
Or some people's answer to climate change is what we just have to use less energy,
but when you understand that energy correlates directly to GDP
and when GDP goes down, it affects poverty,
people in extreme poverty first and worst,
and wars increase because people who have desire to get more
end up going zero sum on each other,
and only when it's very positive sum does that not happen.
You see all these intricate theory of trade-off,
so we can't see that the problem is climate change.
Everybody knows the problem of climate change seems like a big thing,
but you've got to look at climate change plus the macroeconomic issues
that would affect the poorest people
and that would increase the chance of war
and the geopolitical dynamics between the West and China,
and the enforcement dynamics of international agreement.
When you start to recognize that the problem is that suite of things together,
in a way it seems, well, that's too hard, we can't even begin to focus on it.
I would say that that's actually easier
because trying to solve climate change on its own is actually impossible,
because if you're trying to solve something
that is going to externalize harm to some other thing,
maybe you solve that thing,
but you find out that you're in a worse position,
so I would say that it's impossible to actually improve the world that way,
or half the world that is paying attention to that other thing disagrees with you
so vehemently that all the energy goes into infighting
and whatever some part of the world is trying to organize to do,
the other part of the world is doing everything they can to resist from happening,
then all the creative energy just burns up as heat
and we don't actually accomplish anything.
So I would say that the way we're trying to solve the problems is actually mostly impossible.
It either solves it in a very narrow way
while externalizing harm and causing worse problems,
or it makes it impossible to solve it all because it drives polarization.
And so going to the level at which the problems interconnect
where that which everybody cares about is being factored
and where you're not externalizing other problems
while it seems more complex is actually possible.
Impossible is easier than impossible.
And so it's not just that there's a lot of issues, right?
There are a lot of issues,
and just that the issues are both more consequential at greater scope
and moving faster than previous issues
because of the nature of exponentiating technology.
That's part of it.
It's not just that the problems are all interconnected.
It's also that they do have underlying drivers that have to be addressed,
otherwise a symptomatic only approach doesn't work.
The first underlying driver that when people look at it they generally see
is they see things like structural perverse incentive built into macroeconomics,
that the elephant dead is worth more than the elephant alive is,
and so is the rhino, and so is the...
And so how do you have a situation where that's the nature of incentive,
where you're incentivizing an activity and then trying to bind it,
or keep it from happening?
And the same would be true with overfishing,
as long as live fish are worth nothing and dead fish are worth more.
There's something fundamentally perverse about the nature of the economic incentive.
And the same is true that when we have war and there's more military manufacturing, GDP goes up.
And when there's more addiction and people are buying the supply of their addiction, GDP goes up.
And when there are more sick people paying for health care, cost GDP goes up.
So it's obviously a perverse kind of metric.
So anytime someone can fiscally advantage themselves or a corporation can
in a way that either directly causes harm or indirectly externalizes harm,
we have to fundamentally solve that.
If there's something like 70 trillion dollars a day of activity happening
that is a decentralized system of incentive,
that is incenting people to do things that are directly or indirectly causing harm,
there's really nothing we can do with some billions of dollars of nonprofit or state
or whatever money that is going to solve that thing.
