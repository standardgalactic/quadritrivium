Hey everyone, it's Tristan, and this is a bonus episode of Your Undivided
Attention, the podcast from the Center for Humane Technology. As you may have
heard, last week the Wall Street Journal released the Facebook Files, a huge
investigation of the extent to which Facebook's problems are known inside
the company, all the way up to Mark Zuckerberg. To respond to the story, I was
invited by pollster Frank Luntz to talk about this on his weekly webinar,
together with my friend Daniel Schmockenberger. Daniel is a founding member
of the Consilience Project, which is aimed at improving public sense-making
and dialogue. And you may remember him from Your Undivided Attention episode 36.
A problem well stated is a problem half solved. Frank Luntz is a political and
communications consultant, pollster, and pundit who deeply understands the hopes
and fears of Americans. So without further ado, here's my conversation hosted by
Frank Luntz with Daniel Schmockenberger about the Wall Street Journal's
Facebook Files.
As people get brought into the Zoom, I don't know if I've ever done a Fridays
with Frank that was more appropriate and more timely because of all that has
happened in the last seven days. Tristan Harris, congratulations on winning two
Emmy Awards. You're the first personal friend I have. That is actually a
multiple Emmy Award winner. Good for you. You should feel very proud. And you're
already getting a comment from one of the people who is listening in. And Daniel,
what you are trying to achieve with a more constructive, a more open, a more
useful dialogue and the teaching of civility and decency and how we
communicate in the public square is something that we should all emulate. I
am a proponent of technology. I am a supporter of it. We're going to hear a
lot of criticism today because of the problems. I do want to open up saying
that I believe in it, believe in what it has done for us. And in fact, I'm going
to do something I've never done, one of these Fridays with Frank, which is I'm
actually going to show some data that we've not shown publicly until now.
We've been looking at technology. Now people react to it. This is important. We
asked the question in the opposite way that most people do. How would your life
be different if you didn't have all that technology, the stuff that we use every
day, Google, Amazon, YouTube? And the public action by almost two to one say
that the quality of your life would be better without that technology. However,
they wanted to know whether technology has made their life easier or more
difficult. And overwhelmingly, they say that technology has made it much easier
to keep in touch with people as well as issues that are important to you. Another
example, it's given people more choices. It's actually made their lives easier to
consume because you get more services and more products. And again, numbers are
overwhelming. In terms of making shopping hassle free, 63% easier, only 6%
harder. We got more for these. Saving money in the things you buy, overwhelmingly
easier. One more. Has it made it easier or harder to get involved in politics by
47 to 10? They say it's made it easier. Again, I go back to that very first
statistic I showed you. Not easier, but better. The public has an issue with
that. So let me go to you, Tristan. And again, congratulations on your success.
We've talked about this. You and I've known each other for a year and a half.
Our meeting, our was a chance encounter by a friend of mine who said, I must sit
down with you. And I admit that I was going to not show up. I was going to
cancel the meeting. And probably in the year 2020, you're the single most
important person I met. You look at that data. You know how much people need and
want and value technology. But you also know the consequences. What have you
learned in the last seven days? The Wall Street Journal has been pummeling
Facebook and really shining a bright light on social media. What have you
learned over the last week that would be helpful for all the people who are on
this Zoom? Thank you, Frank. And yeah, really pleasure to be here with both
you and Daniel. So for those who don't know, over the last seven days, last
five days, I think the Wall Street Journal has released a new series called
the Facebook Files. This looks like it's the largest event. I would say they
call this the largest event since Cambridge Analytica in terms of revealing
research that the company has been aware of harms across the balance sheets of
teenage mental health increases in teen suicide, body image issues for teenagers,
the radicalization of political parties. There's evidence of the way that Facebook
changed its ranking systems that then caused political parties to actually
tell Facebook, we know that you changed your algorithm and we switched it to we
know because we have to publish now 80% negative content about our opponents to
even get any attention the way that we used to. We know that publishers had to
learn to publish more negative content to get any attention. I just really
recommend that people check out the Facebook Files because it's really the
first time that there's evidence of so many of the things, Frank, that you and
I, because we've done one or two of these before, have been saying for a long
time and that what we said in the social limit, yeah, for those who don't know the
social limit, just also won a couple Emmy Awards came out a year ago, we're
coming up on the one year, we just passed the one year anniversary. And really what
the social dilemma is about, to answer your question, Frank, is it's not about
technology, it's about these certain kind of incentive systems that are built into
technology. So if you take a look at Facebook, TikTok, Snapchat, YouTube, what
do they have in common? They seem like they're different products, like one is a
video broadcasting site, that's YouTube, the other is a social networking tweet
site, Twitter. So they seem like different categories, but their business
models are all optimizing for the same thing, which is whatever gets people's
attention. And so I think that is the generator function of all the harms
because in the same way that a values blind economy that's counting GDP, war is
good for GDP, prostitution and drugs are good for GDP, human trafficking is good
for GDP. In the same way, things that are good for attention that are not things
that we want, well, body image issues that had had kids basically, you know,
infinite looking at anorexia videos, that's really good for keeping time
spent up. Addiction is really good for keeping time spent up. Negativity and
outrage and things that go viral that are, as we said in the social dilemma, fake
news spread six times faster than true news, because the speaker who can say
anything that they want to unconstrained, meaning they can lie is going to do
better than a person who has to wait and say, well, what's actually true, but
the unconstrained actor is going to win. So for your slides, Frank, the thing
here is not that it's about technology being good or bad. It's about the kind
of technology and incentives that we bind to the technology and the business
model of maximizing engagement. Well, we found out in the Wall Street Journal
articles, and I could run through some of the things that we found. But
basically, Facebook knew, for example, that they were increasing some of the
negativity in society. And they had research showing that they knew that.
But Zuckerberg didn't want to change the ranking algorithms of Facebook if it
was going to hurt engagement. And now you could say he's just greedy or he
just wants the profits or he just needs to keep his share price up. He also is
bound because he set up a set of incentives. All of his employees, all
those people at Facebook, most of them are incentivized by how much they can
get engagement up. So all throughout the company, imagine you have a bonus
structure where everyone's salaries and paychecks come in through maximizing
engagement. But then you find out that, let's say 50% of that engagement is
causing genocides in Ethiopia, is causing body image issues in kids. You can't
say we need to have our engagement because now all your employees are going
to leave because they won't be able to get their benefits. You've actually gone
against the own incentive structure for your own employees.
So I want to know what it is causing. And I'm going to add a little bit of
pressure on you, which is that we have two members of the Judiciary Committee.
By the way, I'm in Belfast. I'm actually here in Conflict Capital of the Globe.
And that's why I'm so happy, Daniel, that you're involved. But I'm just
telling you, I've got one more for you. You've got two members of the Judiciary
Committee say that fast five times. They have to deal with this. What should
they know? If I gave you 30 seconds, what should they know that you know
about what's happening?
Well, I think Daniel, in a moment, I think we'll help elevate the conversation
to what kind of changes needed because, unfortunately, while I wish that there
was, you know, a couple of laws or bills that we could pass to get to some
better state, the challenge is that this is based, this is now baked into the
the infrastructure that we use is now the fabric of our democracy and
virality. The thing that is causing some of this, I think of this, everyone's
now familiar with the idea of a lab leak in Wuhan, the Wuhan Institute of
Viralogy that was doing potentially gain of function research on what viruses
can go viral. Well, people now know what are not is the idea of something that
can go viral and how many people does it infect? The purpose of Facebook is to
be the Zuckerberg Institute of Viralogy. The purpose is to create and allow for
things to go viral across the world and be spread to millions of people and to
literally take the R not to be as high as possible. We want it to infect as
many people and spread to as many people because that makes engagement go up.
And that's the core thing. So you say, what's the law that we can pass? What's
the issue that we can change? It's not going to be as simple as that. I think
we have to change the nature. We can't have it be the Zuckerberg Institute of
Viralogy. It has to turn into something safer. So I will warn you that there is a
Facebook executive that's on this conversation. So don't be surprised by
challenging Harry Clark, who is one of the best minds in communication, public
relations. He's asking as part of the Q and A one more. And this is one of both
Why not just boycott Facebook? Why is that a strategy you're considering?
And I don't want to, I don't want to sandbag you. Someone from Facebook is
going to hear this. Why not boycott Facebook? He wants to know.
Well, I mean, if people could boycott Facebook and there was meaningful
alternatives that were not the same problem in TikTok is basically has the
same problem. YouTube has many of the same problems. Snapchat has different, but
some of the same problems. So boycotting and then going, there's nowhere safe to
go. That's that's one of the issues. And the second issue is that you can't really
boycott it when your life depends on it. So one of the problems that's actually in
the article about teenage girls is that you can't actually say it's not an
individual choice to say, I don't want to use these things because I'm going to
ostracize myself. And if all my friends are still on it, you'd have to get the
entire world to boycott it together and move to something else because it's
fundamentally been baked into our lives. Small businesses have to use it to
advertise. How else are they going to reach their users and their and their
customers? They have owned the capacity to reach people. If we want this video to
reach as many people as possible, we probably want to post it on not some
random tiny video site. No one's going to click on, but you want to post it on
the one that gets as many views and likes, etc. So you're going to post it on
Facebook and you're going to post it on YouTube. So they have a monopoly on
reach, which makes it very hard for people to boycott it and say, let's go
somewhere else.
Daniel, you, even though you're involved in this issue, I look at you as being
essential to to public discourse, because you're looking at it, you're looking
for solutions. You're looking for results. You're one of the strongest thought
leaders in how we talk to each other now in society. I'll ask you the question I
asked Tristan, would you recommend a boycott knowing that there's a Facebook
person on this conversation? And do you have any solutions to the problems that
Tristan has raised?
I think it's kind of like what Tristan said that there's a monopoly, but not a
monopoly in terms of a government contract monopoly, but in terms of a
network dynamic monopoly. Network dynamics create natural monopolies where one, as
you get increasing returns on the more people that are in a network, then you
fundamentally have to engage with that thing because there's something like
exclusive value offered there. If somebody decides they're not going to sell on
Amazon and they have a small business, they just can't compete with the ones
that are doing that. Or similarly, if they're advertising on Facebook. So one
of the things is when we built the laws around monopoly and antitrust, network
dynamics didn't exist yet. Those were built before internet and those dynamics.
So we actually have to take the emergence of the internet and the emergence
of network dynamics and Metcalf law and say we actually have to rethink that
monopoly didn't just mean a crony capitalist government contracting. It
means
Can you, for those of us who only went to the University of Pennsylvania, can
you dumb it down just a little bit so we understand what you're talking about?
Nobody wants to use 20 different social networks and have to remember all the
logins and find some friends in one place and some friends in another place,
just like they don't want to use 20 different kinds of currencies. So if
there's a currency that everyone accepts, that currency kind of gets a
monopoly value. If there is a network that everybody's on and you can see your
friends from high school and your family and the news and all the things you're
interested in with one login, like those stats you showed, people said it was
easier and made their life worse. Like everyone who has conveniences where
they don't exercise and don't do the things that actually strengthen them
or read or study, there's a lot of things that make life easier and worse.
And so where something has a network dynamic where the more people that
engage with it, the more value it has because now everybody's producing
content, everyone I want to find is on there. The AI will curate all the
content to show me exactly what I want to see, but which part of me wants to
see? Well, the AI is going to optimize based on my behavior and how long I
spend on site and how many things I like and comment on and share. And it
happens that the things that appeal to my existing biases and increase my
