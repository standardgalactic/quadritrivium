sense of certainty in an uncertain world and the things that scare me and
kind of create emotional responses that make me less clear about the fact I
don't want to be on Facebook and go do other stuff with my life. And the
things that reinforce tribal identity maximize time on site and engagement.
So it's one of those things where you can manufacture demand from the supply
side and then say, we're just giving people what they want, but you're
appealing to the weakest, lowest angels of people's nature and then doing
so with radical asymmetries of power.
So Richard Dreyfus, who's always been a friend of these Fridays with
Frank and he's just his brain is incredible. Is there proof that social
media is leading to incivility, leading to anger? We may think it, but Daniel,
is there proof of this?
Well, this is what you were talking to Tristan about regarding what the Wall
Street Journal has been showing this week. And they're obviously previous cases
and it's this week and what will be continuing as more information comes out
is stuff that Tristan and Jaron Laney are have been saying would happen for
nine years because the business model guarantees it. Now there is increasing
proof in the form of hard internal documents and disclosure.
But for anyone who's been kind of paying attention, the business model of
maximizing people's time on site and maximizing engagement combined with the
technology of behavioral modification AIs was bound to be antithetical to
democracy and antithetical to health. So Tristan can give the proof, but for the
people who've been paying attention, it's kind of like saying, is there proof
that deforestation is happening? And as soon as you're looking at the financial
incentive to cut down the trees in an area where the trees alive are worth
less than the trees dead, you're kind of like, it's going to happen.
Right. And the same way that a tree is worth more dead than alive and a whale
is worth more dead than alive. In this case, our attention, it's easily more
sought with outrage. It will be, that will be the profitable model. Us being
happy or civil, talking to each other off screens and not on screen is not
profitable for any of the social media companies, specifically some of the data.
And again, I recommend people check. I think it's the third article that the
Wall Street Journal released. They talk about actually due to some of my own
work, Facebook changed its core metric. It used to be maximizing for time spent.
I was part of a movement called time well spent. That was my first TED talk.
Facebook decided actually Mark Zuckerberg wrote in his January 2018 post his
yearly goal, his new goal for the year was to take Facebook in the direction of
time well spent, not time spent. He took my words. Then he said, we're going to
change the way we measure success at Facebook. We're going to use something
called meaningful social interactions, MSI. And this Wall Street Journal
article, I recommend everybody reads it, showed how meaningful social
interactions they were trying to give, they assigned different points. So for
example, you've got one point, if you for a post would get one point if it had
a like, it got five points if it got a reaction or a reshare without any text.
It got 15 points for what they call a non-significant comment. And then it
got 30 points for significant comments and significant reshares. What that
really meant was the more long comment threads and article created, which is
to say more arguments, the more those things got boosted to the top. So
whenever there was an argument, it was like, Hey, let's put that at the front
and center for everyone's feet and then do that in a decentralized way for the
entire world all at once for 2 billion people. And when you basically highlight
divisiveness and disagreement and instability, which is the thing, frankly,
that you're trying to find one thing you and I were just at the milk and
conference. And there's a lot of people who are funding things like, Hey, how
do we do American one room? How do we fund with hundreds of millions of
dollars of depolarization for the country? And let's have people together
physically in rooms talking to each other. That's great. But how's that going
to compare to the four hours a day? People spend seeing in civility every
single day. And if 90% of people became civil, but only 10% are left that are
in civil, then what does Twitter and Facebook show you? Well, they only show
you that all the bad faith in civil people. So that keeps just completely
blasting over and plastering your whole feed. And so it continues to look like
the world is in civil, even if many people are starting to get better. We
cannot have that system with democracy period. Open societies cannot allow
this situation to be. And Daniel, I'd love for you to speak about that because
I think it's the reason why I wanted to have Daniel here, Frank, is I think
this isn't just about less toxic social media. How do we just reign in? Let's
take the reins and if we just move at five degrees this way, we would suddenly
have a better democracy plus Facebook. We have to look at a deeper problem
statement there to get to where we want to go. Okay, so I'm going to ask both
of you and you can go another order. Solve it. By the way, we've got a lot
of parents on this, and I'm going to ask you in a moment to scare the living
hell out of them. Give me your most frightening conclusion based on all
the research you've done on young people. But before I do, we're adults, do
either of you have an actual solution that you're going to be presenting to
Congress? Either of you. Daniel, do you want to try to describe? I can say
some things that would be directionally right. So we read all the documents
around the founding of this country and know that the idea of universal public
education and a adequate fourth estate were considered prerequisite
institutions for democracy to function. The people had to be educated and they
had to have access to the information to participate in governance. There's a very
deep question. Hold on one second. Those people who are watching because you're
actually, we're 25 minutes into this and I can see the number of participants is
actually rowing. I'm going to focus on kids in about five minutes. So if you
guys want to send out an email, want to send out a text to people saying tune in.
In about five minutes we're going to specifically focus on what social
media is doing to your children. So I suggest you stay on this. Daniel, please
continue. So you can actually see how the critical role of the fourth estate
following the printing press and it's been well analyzed the role that the
printing press had in the formation of democracy. We don't need a small educated
nobility who rules everybody because everyone can have access to textbooks
and newspaper. They can be educated and we can come to a town hall and participate
in our own governance. But this was based on the idea that we could get
something like fair and independent news and all read the same thing and then be
able to have an educated discussion about it. So when you have an internet where
there's radically more information than anyone could begin to parse, what
information you see ends up being determined by curation processes. I'm not
going to see all the videos. I'm not going to see all the news. I'm not going to
see all the posts. And so it's not like we respond as rational actors to the best
information. We respond to whatever YouTube's algorithms and Facebook's
algorithms put in front of me and they put it in front of me based on a business
model that's maximizing time on site based on engagement. And it happens to
be that that which appeals to my existing biases and emotions maximizes time on
site. So someone on the far right and the far left when they're looking at their
newsfeed and how they're coming to understand the world might see nothing
in common. And so, and yet it's representing the world to them. So you
have to say if democracy doesn't exist without a fourth of state and people
having a shared sense of what base reality is, and the internet, and
specifically, network curation based internet has destroyed the fourth
estate irrevocably. How do you remake a democracy post internet network age?
Because people can't do shared choice making if they don't have a basis for
shared sense making of what's going on.
Yes. And so that question, then how do you do it? It's the right question, but
I'm pushing you now. How do you do it?
Well, you can see that China decided, well, let's control our internet to not
have radically divisive ideas that end up making people against being good
citizens. And you can see that there's an effectiveness in that, but it's
antithetical to the idea of an open society. So you either keep an open
society with these type of network dynamics, and it just becomes
increasingly chaotic and fails. Or you try to apply the China model, those are
the only two things currently as the possibilities. And what we want is how
do you have something like open speech, but with this degree of radical
amplification possibility that doesn't become total chaos. And you have to
look at what is the incentive for the amplification. If there is a tool that
can curate it and make stuff radically more amplified, what is the incentive
guiding it? And so let's say, for instance, if Facebook is the most powerful
behavioral modification machine in the history of the world that can gather
micro targeted information on people and then specifically put information in
front of them to control their behavior for advertisers. But the people who it's
gathering information about and influencing are not the customer. But it's
gathering privileged information about people to then sell it to the customer
who is the advertiser. This should be a break of a fiduciary contract where
you're not allowed to gather privileged information about someone and then use
it against them. If the user was the customer, rather than the advertiser
being the customer. And as a result, the optimization algorithm was not to sell
people ads or to maximize time to sell them ads, but was to find the metrics
that actually correspond to people's real quality of life. And the AIs were
oriented to that, we might start to get somewhere. But that's the beginning of a
radically different business model. An ad based business model with AI controlled
behavioral mechanics will break democracies. They don't go together.
I trust down. I know you agree with this, but can you explain it to someone who
only went to pen? Daniel, half of Congress is not going to understand this. They
still call the tape recorder a machine or sorry, a microphone speaking the
speaking the machine. No, it's actually a microphone. They don't even know what
the internet is. Just on go ahead. Well, I think the thing that Daniel saying is
that an advertising supported. Imagine Frank, I put a brain plan in you and I
actually talked to the guys at Neuralink once about this, right? Imagine Neuralink,
Elon Musk's Neuralink project. I'm going to put a brain implant in your brain. It's
going to shape the thoughts. I'm going to give you thinking superpowers, but let's
imagine that brain implant in your brain. It's going to intimately shape every
thought that you have from the moment you wake up to the moment you go to bed and
your dreams, that someone attached the advertising business model to that Neuralink
brain implant. So now you start having thoughts that you didn't even intend to
have and it's actually in control. We would just say immediately when I say it
that way, it should be clear. Maybe we can have brain implants, but we certainly
would never allow brain implants with an advertising based business model. What
Daniel is saying is that we cannot have democracy and the primary brain implant
of that democracy be an advertising based business model. But when Daniel says
fiduciary, what he's referring to is a brain implant that would have your best
interest at heart, just like a doctor, theoretically, is supposed to have your
best interest at heart. And a psychotherapist, you're going to tell the
psychotherapist all this privilege, deep information that's deep in your psyche.
They have to have your best interest at heart. What we're saying is such a deep
change that we have to have technology that's humane with our best interests at
heart. Now, the reason that's such an uncomfortable conversation is that I
believe Facebook stock price has not moved that much this week, despite the
fact of these, these awful revelations. And it's worth about a trillion dollars
in that trillion dollar valuation comes from the advertising based business
model. So it's as if we had an entire industry of psychotherapy that was
based on a manipulative business model that was worth a trillion dollars. But
now we have to switch to what does it look like to be in the interests of
people. And the question is that's that's a very dramatic economic change. So I
think it's more that our brain wants to shy away from that because it's so
uncomfortable that we'd have to make a change as deep as that. That's one of
the big things that has to change.
I want you guys to know that one of the comments is maybe we need more people
like you in Congress, that it's not your fault that you're speaking the truth.
It's their fault for not understanding it. And actually, that's not such a bad
idea. Let me ask you, I wanted to speak to what you said earlier about what
people in Congress would understand. If because of who the people in government
are or the structure of government, if it cannot understand the nature of the
issues it's supposed to regulate, and particularly as technology is evolving
rapidly faster than the people who are in there are able to understand the
consequences of, then it will just break. Right. If the regulatory apparatus can't
understand the effects of what it needs to regulate, it will just break. And
this is the key thing that we're talking about is we're right now talking about
the case of social media tech following a business model. But we could also be
talking about CRISPR and tabletop CRISPR emerging, where we're getting very,
very close to cheap ability to make bio weapons for everybody. And with regard
to AI and generative text AI, we're getting very, very close to the ability
to make content in your voice, saying anything that anyone can do and flood
the internet with more information that passes the Turing test. And and so and
Elon said this, he said, if we wait to regulate AI and the other technologies
that operate this quickly AI specifically, who's talking about till after the
effects have been seen for as long as we did with cigarettes or DDT, it's way too
late. The effects will have been irreversible. So when we say exponential
tech, what we mean is exponentially faster to scale exponentially larger
effects that can happen from exponentially smaller groups of people. It
doesn't take state actors like it did to make nukes to make AI weapons, bio
weapons, CRISPR weapons. And so the big question becomes in the presence of the
