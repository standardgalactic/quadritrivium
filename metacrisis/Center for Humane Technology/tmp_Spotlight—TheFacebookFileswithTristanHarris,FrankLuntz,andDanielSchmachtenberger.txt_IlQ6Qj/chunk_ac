speed and scale of emerging technologies, our processes of governance are just
inadequate. They're too slow. They are too divided. And this is why China has done
a good job of saying, no, we actually have to control these technologies,
otherwise they'll break the country. How do we do it? But it's in a particular
direction. If we want something like an open society in the presence of
exponential tech, how do we make a regulatory apparatus capable of
regulating what it needs to in time and ahead of time that is aligned with the
civil values of an open society? That's the central question of our time. I
believe I want a simple number, a number. Daniel, what percent of Congress house
in the Senate is really intellectually not ready to tackle this issue? What
percent? I don't know. I don't know them enough. What would you guess? I would
trust your guess over mine on this. Okay, Tristan, you've been testifying. So you
are not letting you out of this. What percent don't really shouldn't be
regulating this that they do not know? I think it's very understandable why
people are skeptical of Congress to regulate this effectively when they
hear senators ask Mark Zuckerberg questions like, how do you make money? And
he responds famously, Senator, we sell ads. If I was Zuckerberg, I would have
paid for that moment to happen. And maybe I did because it generates the
impression forever in people's minds. It sticks, Frank, in your language, into
the minds of the public that government cannot regulate this, right? So I've
created the outcome that I want. And someone I noticed in the chat was
talking about do social media companies own the numbers of Congress? Well,
let's say that this narrative gets really strong. Well, it's a trillion dollar
market cap corporation. It's not very hard to start buying off any of the
numbers of Congress that get critical. And a couple will make some public
statements. But what's really what we're trying to do here and what Daniel's
really saying is that this is existential for our society continuing to
work. This will break our society. We've been saying that for eight years. The
social lemma says that it's clearer than ever. January 6, I had text messages
from people, Joe Rogan saying, Oh, my God, I thought the social lemma, you know,
it's so eerie, all this stuff is coming true. You know, when I remember in the
film, people may remember the guy who invented Facebook's business model, Tim
Kendall, he was asked on camera, you know, what are you worried about is the
consequence of this. And he was, I think he was recorded saying this in 2019 or
2018. And he said civil war. And I remember that I think Netflix wanted that to
not be in the film because it sounded like it was too aggressive a statement to
make. It sounded like that wasn't where we were. That was before the pandemic.
And when people saw January 6 and they see the results and people should read
this Wall Street Journal article about the outrage economy and how it how it
drove up basically more insanity, it makes perfect sense. And the point Daniel's
trying to say is that we were trying to ask the question, if we don't want to
beat China by becoming China, then we have to develop an open society
alternative to exponential technology that does not result in catastrophe and
chaos. And we're spending some time in Washington DC. And part of the reason,
Frank, I wanted to do this with your audience, because I know you have a
lot of listeners that are in DC and that are curious to get to this point is
that, you know, we're trying to see who resonates with this and wants to have a
serious conversation about the more comprehensive change that's needed.
But I'm being asked again and again, both in people who are texting me,
emailing me in this comment right here, everybody says, we got to do something,
but I don't trust Washington to do it.
What's the answer? They don't, the direct language. I don't want Washington
making the decision for me or my children, what we're going to see.
Well,
I can speak to this as one of the things we've seen during COVID is the
breakdown of the sense of a shared, trustable authority or institution.
And when it comes to news media, and even when it comes to scientists and
public intellectuals weighing in on the science, there's just radical
polarization of what would be a trusted authority.
And so, yeah, people rightly don't trust Washington, but they would also
rightly not trust private companies that have interests that are exactly
opposite of their own and radical asymmetries of data manipulation capability.
So the question becomes, when you have technology that is this asymmetrically
powerful, who could you trust to govern it, given humanity's track record with
power? And yet, like whoever had the
cannons in the past is nothing like who has the AIs and all the world's
information, the behavioral dynamics on your children.
And so as we follow an exponential curve of power,
there's this core governance question of we've never done all that good a job of
being great stewards of power, and now we have radically
increasing exponential power. How do we govern it?
And the whole thing when we don't trust Washington is Washington was never
supposed to be a thing separate from of foreign by the people governance.
It was supposed to be that the state was given the ability to regulate
predatory market interests while still allowing healthy market interests
to ensure the values of the people that were encoded into law
could be implemented with a monopoly of violence.
But the state could only check the market if the people checked the state.
And that like everything you can read by the founding fathers
and the Declaration and the Constitution was all about the people's ability to
oversight and check the state and be engaged in governance.
When the people stop checking the government, the government gets captured
by the market and you get short-termism, crony capitalism, regulatory capture,
those types of things. So ultimately there is a cultural revolution
that has to happen of people who get committed to actually being able to
make sense of reality together and make effective choices together
and participate with the remaking of 21st century governance, 21st century
democracy, republic, open society, whatever you want to call it,
and the creation of institutions that actually can be trusted because of the
right types of checks and balances on power and oversight process
with this technology. Okay, I'm going to read it from Eric Schwartz.
Due to forceful regulation, banks are obligated to know their customers and
there's no room for anonymity. Why shouldn't social media be governed
the same way if there was no anonymity and the platforms were obliged to know
how to access all participants? Would that help?
Either of you. I'll just respond to something there. We've been saying
also for about five years, just like banking has, know your customer
laws and so on, KYC, there is eventually especially going to need to be
that with social media and online publishing because of
what Daniel was talking about with GPT-3. So for those who don't know
when you say GPT-3 or deepfakes, people have heard about this term, right? They
just quickly say what this was. Daniel and I were actually just with one of the
top AI research people in the entire world
and they were saying how much this field has progressed. You can basically say
write me a novel in the voice of James Joyce
about the topic of democracy or something like that
and it would write you a 100-page book. I could say, hey, write me a
article about why the COVID vaccine is dangerous and with
lots of charts and graphs and actually criticize with the names of
the logical fallacies that people are using that
that makes them wrong about the vaccine and why they actually shouldn't
trust it and it'll actually generate like a 100-page
research paper with charts and graphs that it'll take biostatitions like a
year to actually parse out what's right or what's wrong about that.
That capacity to instantly flood the internet with information and by the
way for those who don't believe me, do a google search for open AI
and I don't know what they call this video. They can actually do
programming so you can actually tell this GPT-3 AI.
Hey, write me a computer program, a game, where there's a moving asteroid. Whenever
I hit the letter, the left and right arrows, it goes back and forth,
make the asteroid bigger. I say all that and it writes the entire code of the
video game for me. I'm just saying a natural language
what I want. So in the next election, Frank, we're moving to a world and this
is not sci-fi so people might hear this as
alarmism or moral panic and people who believe that this is moral panic
like listen to the fact that we were saying these things eight years ago and
all of them have come true. We're about to hit a world
where in the next election, midterm elections, for those who don't remember
in 2016, there is this popping up of these fake local news websites, the Denver
Post, the Cincinnati Herald, I don't know the names of the
fake ones, you can basically make them up. GPT-3, you can also say spin up a
local news website with the fonts and everything and the big sections at the
top. It'll generate the entire website and it looks perfect, it looks totally
indistinguishable, then generate lots of articles about why the other side is
untrustworthy and he beat his dog and whatever and it'll actually just
generate thousands of these websites. We're getting so close to that being
possible and the reason I'm saying this is to
answer Eric Schwartz's question about why we need to know our customers, why we
need verified identity because if we don't have the sense that someone who
generated this comment or this post or this text is a human
being that's traceable to some kind of ID,
we're not going to have a working open society. So table stakes going into the
future is we're going to have to have some kind of zero knowledge proof
identity and people who are following this closely know that that's one of the
big changes that's going to need to make.
When we talk about Congress regulating these issues, we're often talking about
looking backwards in time at the at the historical issues. How do we deal with
these common threads on Facebook or like the stuff from like four years ago
issues? We're missing the fact that what Daniel's
saying is the first derivative of how technology is constantly changing
and generating new issues, second and third order effects,
faster than any of our governance processes keeping up. So what we really
need is a new kind of governance process. We need a Manhattan project
for governing exponential technologies that move faster and I would actually say
similar to the Einstein-Sillard letter that was written to FDR in 1939 that said
if we don't do this and open society values don't have nuclear bombs,
if Nazism gets the nuclear bomb or if Communism gets the nuclear bomb,
they will run the future because whoever wields the power of exponential technologies
will run the world and we're at another choice point today
where we have to have open societies consciously employ the technology and
bind to the predatory negative aspects. Otherwise we're seeing what China is
doing and they're moving much faster. Okay well I don't want us to become China
and there have been several comments about that that just because China is doing it
doesn't make it right. They don't value freedom, they don't value democracy,
they don't value the things that we insist on. Agreed and that's why that's
why what Daniel was saying is actually, go ahead Daniel, sorry.
Like to connect what Tristan is saying to the question that you asked about rigorous identity.
So obviously being able to know was this a human that produced it or was this an AI
would be pretty valuable. But even just is this the human that it seems like it is
or is this a fake account sock puppet that is part of a state actor propaganda farm?
That's pretty valuable because we've forensically find those types of
bought farms and fake actor farms all the time. And what they can do is use
Facebook split testing algorithm to see what is stickiest for certain populations and
continue to modify the content they produce even without AI to push vulnerable populations.
Now the AI just gets to take that exponentially. So obviously rigorous identity would be valuable
but then this question that comes back again it's like saying regulation be valuable.
Who do we trust to have the rigorous identity associated with all of someone's online
behaviors, including through changes in government that will never forget that
where now some despotic government comes in in the future or someone that I didn't vote for
or didn't like but now that is an unerasable memory. So we get to see on either sides here
we're like okay we actually want anonymity because we don't trust anybody. On the other side
the anonymity makes it to where there's no possibility for justice or knowing what is
true or not true. This is a hard issue and it corresponds to it's pretty hard as Tristan was
mentioning about the the war for the arms race for nukes. It's pretty hard to make nukes enriching
uranium is difficult the precision engineering that was needed for the rockets was hard. It's not hard
to make drone weapons anymore home based drones with homemade bombs on them. It's not hard to
take papers that are written about the cutting edge of AI and reverse engineering and make
crypto cyber weapons and AI type weapons. The thing about exponential tech is that
the idea of decentralizing tech we have this kind of romantic Silicon Valley idea of this
means democratized power for everyone but it also means catastrophe weapons for everyone
and when you have catastrophe weapons for everybody and it's non-state actors and there's
no way to even be able to visualize it you can't have mutually assured destruction you can't create
equilibrium. So then the the only other answer so far has been okay well either catastrophe
weapons for everyone if you want something like freedom or ubiquitous surveillance.
Ubiquitous surveillance is a good answer if we know what everyone's doing in their basement nobody
can do work on AI weapons. Those two answers are both so terrible we need a better answer.
So in the presence of decentralizing exponential power how do you not have ubiquitous surveillance
and not have centralized access to that personalized data and yet still have something
that can create anti fragility in the presence of that much power that even small actor groups
could engage with. There are some answers that are neither just allow the chaos to continue
