One of the core things is the relationship between rights and responsibilities. So
if I have rights and I don't have responsibilities, there ends up being like tyranny and entitlement.
If I have responsibilities and I don't have any attendant rights at servitude,
neither of those involve a healthy just society. So if I want the right to drive a car, the
responsibility to do the driver's education and actually learn how to drive a car safely is
important. And we can see that some countries have less car accidents than others associated
with better driver's education. And so increasing the responsibility is a good thing. We can see
that some countries have way less gun violence than others, even factoring a similar per capita
amount of guns based on more training associated with guns and mental health and things like that.
So if I have a right to bear arms, do I also have a responsibility to be part of a well-organized
militia, train with them and be willing to actually sacrifice myself to protect the whole,
or sign up for a thing to do that? Do I have to be a reservist of some kind?
Those are the right responsibilities. If I want the right to vote, is there a responsibility to
be educated about the issue? Yes. Yes. Now, does that make it very unequal? No, because the capacity
to get educated has to be something that the society invests in making possible for everyone.
And of course, we would all be silly to not be dubious factoring the previous history of these
things. We should be very dubious given the historical use of education to suppress the Black
Vote. But Daniel's saying we should design systems to enable people to be maximally informed
and maximally participate in their own governance. So how do we make the on-ramps to learning available
for everyone not enforced, but we're actually incentivizing? Can we use those same kind of
social media behavior and sending technologies to increase everyone's desire for more rights
and attendant responsibilities so that there's actually a gradient of civic virtue and civic
engagement? Yeah, we could totally do that. So this new attractor is nothing short of a kind of
new cultural enlightenment, which sounds ambitious, I know. Our last enlightenment was a shift from
superstition myth and a rationality to logic, science and rationality. And in pursuit of new
ideals like liberty, tolerance and representative government, a new cultural enlightenment would
be a shift from a culture that manages risk through oppression, or that doesn't manage risk at all
because it's fallen into chaos, to a culture that has the emergent wisdom to manage exponential
technologies, a cultural enlightenment that is supported by humane technology. How do we utilize
the new exponential technologies, the whole suite of them, to build new systems of collective
intelligence, new better systems of social technology? How do you make a fourth estate that
can really adequately educate everyone in a post Facebook world? So let's say we take the
attention tech that you've looked at so much that when it is applied for a commercial application is
seeking to gather data to both maximize time on site and maximize engagement with certain kinds
of ads and whatever. That's obviously the ability to direct human behavior and direct human feeling
and thought. Could that same tech be used educationally to be able to personalize education to the
learning style of a kid or to an adult to their particular areas of interest and to be able to
not use the ability to control them for game theoretic purposes, but use the ability to influence
them to even help them learn what makes their own center, their locus of action more internalized,
right? We could teach people with that kind of tech how to notice their own bias, how to notice
their own emotional behaviors, how to notice groupthink type dynamics, how to understand
propaganda and media literacy. So could we actually use those tools to increase people's
immune system against bad actors use of those tools? Totally. Could we use them pedagogically
in general to be able to identify rather than manufacturing desires in people or appealing
to the lowest angels of their nature because addiction is profitable? Can you appeal to the
highest angels in people's nature but that are aligned with intrinsic incentives and be able to
create customized educational programs that are based on what each person is actually innately
intrinsically motivated by but that are their higher innate motivators? Could we do that? Yeah,
totally we could. Could we have an education system as a result that was identifying innate
aptitudes, innate interests of everyone and facilitating that their developments are not
only did they become good at something, but they became increasingly more intrinsically
motivated, fascinated and passionate by life, which also meant continuously better at the thing.
Well, in a world of increasing technological automation coming up, both robotic and AI
automation, where so many of the jobs are about to be obsolete, our economy and our education
system have to radically change to deal with that because one of the core things an economy has been
trying to do forever was deal with the need that a society had for a labor force. And there were
these jobs that society needed to get done that nobody would really want to do. So either the
state has to force them to do it or you have to make it where the people also need the job. So
there's a cemetery and so kind of the market forces them to do it. So if one of the fundamental
like axioms of all of our economic theories is that we need to figure out how to incent a labor
force to do things that nobody wants to do, an emerging technological automation starts to debase
that. That means we have to rethink economics from scratch because we don't have to do that thing
anymore. So maybe if now the jobs don't need the people, can we remake a new economic system where
the people don't need the jobs? What is the role of humans in a post AI robotic automation world?
Because that is coming very, very soon. And what is the future of education where you don't have to
prepare people to be things that you can just program computers to be? Well, the role of education
has to be based on what is the role of people in that world. That is such a deep redesign of
civilization because the tech is changing the possibility set that deeply. So at the heart
of this are kind of deep existential questions of what is a meaningful human life and then what
is good civilization that increases the possibility space of that for everybody and how do we design
that thing? So what Daniel is saying and as previous guest Yvonne Harari pointed out is that
the new technology forces us to reimagine our previous social systems within the context of
personalized AI that can tune educational experiences. What is the new education? Within the
context of automation of most tasks, what is work? Within the context of a post Facebook digital age,
what is the fourth stage? China is answering these questions. But for the purpose of a digital closed
society, but Daniel is encouraging us to answer these questions for the purpose of a digital open
society with examples like what Audrey Tang in Taiwan and others are already doing.
But before we go on, let's take a step back and have some humility here.
We don't know all the answers about how this is all going to work. But what we do know is that
the question of what would make social media slightly less bad or less harmful is not adequate
to answering the question of existential risks caused by the three generator functions that
Daniel has outlined. Humane technology must be supporting the capacity of culture to have the
wisdom to steward exponential tech amidst rival risk dynamics. And in that spirit, how might we
use technology in a way that enables people to meaningfully participate in their own governance
and to have that culture become the new attractor that can manage global existential risk?
What if all government spending was on a blockchain and doesn't have to be a blockchain,
it has to be an uncruptible ledger of some kind. Holochain is a good example that is pioneering
another way of doing it, but uncruptible ledger of some kind, where you actually see where all
taxpayer money goes and you see how it was utilized, the entire thing can have independent
auditing agencies and the public can transparently be engaged in the auditing of it.
And if the government is going to privately contract a corporation, the corporation
agrees that if they want that government money, the blockchain has accounting has to extend into
the corporation. So there can't be, you know, very, very bloated corruption. Everybody got to see
that when Elon made SpaceX, all of a sudden, he was making rockets for like 100s of the price
that Lockheed or Boeing were, who had just had these almost monopolistic government contracts
for a long time. Well, if the taxpayer money is going to the government is going to an external
private contractor who's making the things for 100 to 1000 times more than it costs,
we get this false dichotomy sold to us that either we have to pay more taxes to have better
national security, or if we want to cut taxes, we're gonna have less national security. What
about just having less gruesome bloat, because you have better accounting, and we have better
national security and better social services and less taxes? Everyone would vote for that, right?
Who wouldn't vote for that thing? Well, that wasn't possible before uncorruptible ledgers.
Now that uncorruptible ledger also means you can have provenance on supply chains to make the
supply chains closed loop so that you can see that all the new stuff is being made from old stuff,
and you can see where all the pollution is going, and you can see who did it, which means you can
now internalize the externalities rigorously, and nobody can destroy those emails or burn those files.
What if the changes in law and the decision making processes also followed a blockchain
process where there was a provenance on the input of information? Well, that would also be a very
meaningful thing to be able to follow. So this is an example of like, can we actually structurally
remove the capacity for corruption by technology that makes corruption much, much, much harder,
that forces types of transparency on auditability? What if also you're able to record history?
You're able to record the events that are occurring in a blockchain that's uncorruptible,
where you can't change history later. So you actually get the possibility of real
justice and real history and multiple different simultaneous timelines that are happening.
That's humongous in terms of what it does. What if you can have an open data platform,
and an open science platform, where someone doesn't get to cherry pick which data they
include in their peer reviewed paper later, we get to see all of the data that was happening.
We solve the oracle issues that are associated. And then if we find out that a particular piece
of science was wrong later, we can see downstream everything that used that output as an input
and automatically flag what things need to change. That's so powerful.
Let's take AI. With AI, we can make super terrible deep fakes and destroy the epistemic
commons using that and other things like that. But we can see the way that the AI makes the
deep fake by being able to take enough different images of the person's face and movements that
it can generate new ones. We can see where it can generate totally new faces, averaging faces
together. Somebody sent me some new work that they were just doing on this the other day,
I found very interesting. They said, we're going to take a very similar type of tech and apply it
to semantic fields, where we can take everybody's sentiment on a topic and actually generate a
proposition that is at the semantic center. Then can you have digital processes where you can't
fit everybody into a town hall, but everybody who wants to can participate in a digital space
that rather than vote yes or no on a proposition that was made by a special interest group,
where we didn't have a say in the proposition or even the values it was seeking to serve,
you start by identifying what are the values everybody cares about and then we say the first
proposition that meets all these values well becomes the thing that we vote on. These completely
change the possibility space of social technology and we could go on and on in terms of examples,
but these are ways that the same type of new emergent physical tech that can destroy the
epistemic commons and create autocracies and create catastrophic risks could also be used
to realize a much more pro-topic world. So I love so many of those examples and I especially on the
blockchain and corruption one because I think something that the left and the right can both
agree on is that our systems are not really functional and there's definitely corruption
and defection going on and just to add to your example imagine if citizens could even earn
money by spotting inefficiencies or corruption in that transparent ledger so that we actually have
a system that is actually profiting by getting more and more efficient over time and actually
better serving the needs of the people and having less and less corruption and so there's
actually more trust and faith and that's actually a kind of digital society that when you look at
let's say the closed China's digital authoritarian society and you look at this open one that's
actually operating more for the people with more transparency with more efficiencies that's just an
inspiring vision. What's also very inspiring is what Daniel's building the conciliants project.
This conversation you and I are having is very central to the aims of the conciliants project
which is we're wanting to inspire and form and help direct a innovation zeitgeist
where the many different problems of the world start to get seen in terms of having
interconnectivity and underlying drivers and so we have a really great team of people that are
doing research and writing basically the types of things we're talking about here in more depth
explaining what is the role of the various social systems like what is the role of education to any
society help understand fundamentally what that is understand why there is a particularly higher
educational threshold for open societies where people need to participate not just in the market
but in governance understand how that has been disrupted by the emerging tech and will be
disrupted further by things like technological automation and then envision what is the future
of education adequate to an open society in a world that has the technology that's emerging
and the same thing with the fourth estate the same thing with law the same thing with economics
and so the goal is not how do we take some small group of people to build the future it's how do we
help get what the criteria of a viable future must be and if people disagree awesome publicly
disagree and have the conversation now but if we get to put out those design constraints someone
says no we think it's other ones at least now the culture starts to be thinking about the most pressing
issues in fundamental ways and how to think about them appropriately and how to approach them
appropriately so fundamentally our goal is supporting an increased cultural understanding
of the nature of the problems that we face a clearer understanding rather than just there's
lots of problems and it's overwhelming and it's a bummer and so either some very narrow action
on some very narrow part of it makes sense or just nihilism we want to be able to say actually
because there are underlying drivers there is actually a possibility to resolve these things
it does require the fullness of our capacity applied to it and with the fullness of our capacity so
it's not a given but with the fullness of our capacity applied to it there is actually a path
forward i think what cht did with the social dilemma took one really critical part of this
metacrisis into popular attention maybe in a more powerful way than i have seen done otherwise
because as big a deal as getting climate change and public attention is it's not clear that climate
change is something that is making that is driving the underlying basis of all the problems but a
breakdown in sense making and a control of patterns of human behavior that kind of downgrade people
like oh wow that really does make all these other things worse so i see that as a very powerful
and personal on ramp for those who are interested to be able to come into this deeper conversation
and some people say i can actually start innovating and working with this stuff
yeah i think what we've essentially been outlining here is the charles kettering quote which i learned
from you and i've learned so many things from you over the years which is that a problem not
fully understood is unsolvable and a problem that is fully understood is half solved and i just want
to maybe leave our listeners with that which is i think people can look at the long litany of problems
and feel overwhelmed or get to despair in a hurry i think is your phrase for it and i think that when
you understand the core generator functions for what is driving so many of these problems to
happen simultaneously there's a different and more empowering relationship to that and you've
actually offered a vision for how technology can be consciously employed these new technologies
can be consciously employed in ways that should feel inspiring and exciting i mean i want that
transparent blockchain on a budget for every country in the world and we can see examples like
estonia and taiwan moving in this direction already and we can see taiwan building some of the
technologies you mentioned to identify propositions of shared values between citizens who want to vote
collectively on something that previously would have driven up more polarization i think we need
to see this as not just an upgrade but the kind of cultural enlightenment that you speak of that
so many different actors are in a sense already working on we used to have this phrase that
everyone is on the same team they just don't know yet i'll just speak to my own experience when i
first encountered your work and i encountered the kind of core drivers that that drive so much of
the danger that we are headed towards i immediately i was kind of already in this direction already
but i reoriented my whole life to say how do we be in service of this not happening and and of
creating a better world that actually meets and addresses these problems and i just hope that
our audience takes this as an inspiration for how can we in the face of stark and difficult realities
