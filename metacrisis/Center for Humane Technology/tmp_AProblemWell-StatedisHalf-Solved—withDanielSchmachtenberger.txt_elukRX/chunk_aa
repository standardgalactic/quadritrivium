Inventor and engineer Charles Kettering once said,
a problem well stated is a problem half solved, while a problem not well stated is unsolvable.
Here on Your Undivided Detention, we explore various different problems,
addiction, disinformation, polarization, climate change, and more.
But what if many of these problems are actually symptoms of the same meta-problem,
or meta-crisis? And what if a key leverage point for intervening in this meta-crisis
is evolving our collective capacity to solve problems? What if stating the problem in this way,
as a problem with our problem solving, makes it, as Charles Kettering said, half solved?
Your Undivided Detention is back, and we just turned two years old.
And here with us to explore how we might, let's say, solve the problem with problem solving
is my dear friend and mentor Daniel Schmocktenberger. Daniel is focused on the ways of improving the
health and development of individuals and society for the purpose of creating a more virtuous
relationship between the two. He's a founding member of the Consilience Project,
aimed at improving public sense-making and dialogue. And with Daniel's episode,
we're going to be doing something a little different. We're releasing two versions of the
episode. An edited version, along with an unedited version. And I highly encourage you to listen
to both, so that you can learn some new frames that we're going to start using on this show.
And then come to our podcast club. Daniel and I will actually be in dialogue with each other,
and with you. The podcast club will be on Friday, July 9th. Details are in the show notes. And with
that, here we go. So Daniel, welcome to your undivided attention. Thank you, Tristan. I've
been looking forward to us dialoguing about these things publicly for a while. So Daniel,
maybe we should just start with, what is the metacrisis? And why are these problems seemingly
not getting solved, whether it's climate change or anything that we really care about right now?
I think a lot of people have the general sense that there is an increasing number of
possibly catastrophic issues, whether we're talking about future pandemic related issues,
or whether we're talking about climate change or climate change as a forcing function for human
migration that then causes resource wars and political instability, or the fragility of the
highly interconnected globalized world where a problem in one part of the world can create
supply chain issues that create problems all around the world. There's a sense that there's an
increasing number of catastrophic risks and that they're increasing faster than we are solving them.
And like with the UN, while progress has been made in certain defined areas of the sustainable
development goals, and progress was made back when they were called the millennium development goals,
we're very far from anything like a comprehensive solution to any of them. We're not even on track
for something that is converging towards a comprehensive solution. We still haven't succeeded
at nuclear disarmament. We did some very limited nuclear disarmament success while doing nuclear
arms races at the same time, and we went from two countries with nukes to more countries
with better nukes, the major tragedy of the commons issues like climate change and overfishing
and dead zones in the oceans and microplastics in the oceans and biodiversity loss. We haven't
been able to solve those either. And so rather than just think about this as like an overwhelming
number of totally separate issues, the question of why are the patterns of human behavior,
as we increase our total technological capacity, why are they increasing catastrophic risk and
why are we not solving them well? Are there underlying patterns that we could think of as
generator functions of the catastrophic risk, generator functions of our inability to solve
them, that if we were to identify those and work at that level, we could solve all of the
expressions or symptoms. And if we don't work at that level, we might not be able to solve any of them.
The first one I noticed when I was a kid was trying to solve an elephant poaching
issue in one particular region of Africa that didn't address the poverty of the people that
had no mechanism other than black market on poaching, didn't address people's mindset towards
animals, didn't address a macro economy that created poverty at scale. So when the laws were
put in place and the fences were put in place to protect those elephants in that area better,
the poachers moved to poaching other animals, particularly in that situation, rhinos and
gorillas that were both more endangered than the elephants had been. So you moved a problem
from one area to another and actually a more sensitive area. And we see this with, well,
can we solve hunger by bringing commercial agriculture to parts of the world that don't
have it so that the people don't either not have food or we have to ship them food. But if it's
commercial agriculture based on the kind of unsustainable, environmentally unsustainable
agricultural processes that lead to huge amounts of nitrogen runoff going into river deltas that
are causing dead zones in the ocean that can actually collapse the biosphere's capacity
to support life faster, then we're solving for a short term issue that's important and driving
even worse long term issues. You get the idea. Over and over again, the way that we solve short
term problems may create other problems on balance sheets that we don't discover until later.
This is similar to the problem of Facebook's fact checking program.
Fact checking seems like a solution to the problem of fake news, but it actually can cause
more polarization because in a world that's already been divided by Facebook's personalization
rabbit holes, showing people fact checks can actually just drive up more polarization and
disagreement. In the case that you in Center for Humane Technology have brought so much attention
to with regard to the attention harvesting and directing economy, it's fair to say that
it's probably was not Facebook or Google's goal to create the type of effects that they had. Those
were unintended externalities. They were second order effects, but they were trying to solve
problems. Like let's solve the problem if we're Google of organizing the world's information
and making better search. That seems like a pretty good thing to do. And let's recognize that
only if we get a lot of data will our machine learning get better. And so we need to actually
get everybody on this thing. So we definitely have to make it free. Well, then the nature of
the ad model doing time on site optimization ends up appealing to people's existing biases rather
than correcting their bias, appealing to their tribal in group identities rather than correcting
them and appealing to limbic hijacks rather than helping people transcend them. And as a result,
you end up actually breaking the social solidarity and epistemic capacity necessary for democracy.
So let's define a few terms here. When Daniel talks about limbic hijack, he's referring to the way
technology is hijacking our limbic system or our paleolithic emotions and brains in order to drive
clicks and behavior. And when he says epistemic capacity, he's referring to and this is something
that's really important that we're going to keep using on your divided attention. He's referring to
epistemology, which means how we know what we know. So instead of talking just about fighting fake news,
we can talk about better epistemology, better sense making for how we know what we know.
And Daniel's concerned about how the social media platforms are breaking the epistemic
capacity necessary for democracy. It's like, oh, let's let's solve the search problem. That
seems like a nice thing. The side effect is we're going to destroy democracy and open societies in
the process. And all those other things like those are examples of solving a problem in a way that
is externalizing harm, causing other problems that are oftentimes worse. So I would say that the way
we're trying to solve the problems is actually mostly impossible. It either solves it in a very
narrow way while externalizing harm and causing worse problems or it makes it impossible to
solve it all because it drives polarization. And so going to the level at which the problems
interconnect where that which everybody cares about is being factored and where you're not
externalizing other problems, well, it seems more complex is actually possible.
And what makes it possible is understanding the underlying drivers, the generator functions
of existential risk, of which Daniel says there are three.
The first generator function of existential risk is rival risk dynamics. And it expresses itself
in two primary ways. And the two primary ways it expresses itself is arms races and tragedy of
the commons. And the tragedy of the common scenario is if we don't overfish that area of virgin
ocean, but we can't control that someone else doesn't because how do we do enforcement if
they're also a nuclear country? That's a tricky thing, right? How do you do do enforcement on
nuclear countries, equipped countries? So us not doing it doesn't mean that the fish don't all get
taken. It just means that they grow their populations and their GDP faster, which they will use
rival risk. So we might as well do it. In fact, we might as well race to do it faster than they
do. Those are the tragedy of the commons type issues. The arms race version is if we can't
ensure that they don't build AI weapons or they don't build surveillance tech and they get increased
near term power from doing so, we just have to race to get there before them. That's the arms race
type thing. It just happens to be that while that makes sense for each agent on their own in the
short term, it creates global dynamics for the whole in the long term that self terminate. Because
you can't run exponential externality on a finite planet. That's the tragedy of the commons one.
And you can't run exponential arms races and exponential conflict on a finite planet.
So that's the first generator function of existential risk, which is rival risk dynamics.
And we see rival risk dynamics everywhere over and over again on your undivided attention.
If I don't go after the attention of those preteen social media users and you do, then you'll win
and I'll lose. If I don't seize the dopamine reward system to build the addiction into my app
and you do, then you'll win and I'll lose. And if I don't use negative campaign ads to win an
election to make you hate the other side, then you'll win and I'll lose. These rival risk dynamics
bring us to the second generator function of existential risk, which is the subsuming of our
substrate. These are the substrates or the environments that make human civilization
possible in the first place. Environmental degradation from overfishing, attention degradation
from apps that are competing for our attention, or social trust degradation from politicians
competing to make us outraged. And the rival risk dynamics of runaway capitalism erode the
substrate that all of our civilization depends on. And the third generator function of existential
risk is exponential technology or technology that grows and improves exponentially. So you can think
of that like the rivalry between two people with stone clubs to the rivalry between two people with
semi-automated weapons to two actors with nuclear bombs that can blow up the whole world instantaneously.
Think about a rivalry between two advertisers who are putting up a single billboard in the city
that can influence about a hundred people to a rivalry between two agents using Facebook's global
ability to influence three billion people with millions of A.B. tests and precision guided
micro-targeting. The greater the exponential power and technology, the more exponential risk is created.
So these are the three generator functions of existential risk. Rival risk dynamics,
the subsuming of the substrate or playing field, and exponentially growing power and technology.
Daniel says that any civilization that doesn't address these three generator functions
will inexorably self-terminate. Not great news.
So let's take a step back. How did we get here? How did we get to this level of unmanaged global
existential risk? Before World War II, catastrophic risk was actually a real part of
people's experience. It was just always local. But an individual kingdom might face existential risk
in a war where they would lose. So catastrophic risk has been a real thing. It's just been local.
And it wasn't until World War II that we had enough technological power that catastrophic
risk became a global possibility for the first time ever. And this is a really important thing to
get because the world before World War II and the world after was different and kind so fundamentally
because the wars were fundamentally winnable, at least for some, right? They weren't winnable for
all the people who died, but at least for some. And with World War II and the development of the
bomb became the beginning of wars that were no longer winnable and that if we employed our full
tech and continued the arms race even beyond the existing tech, it's a war that where wind
lose becomes omni lose lose at that particular level of power. And so that created the need
to do something that humanity had never done, which was that the major superpowers didn't war.
The whole history of the world, the history of the thing we call civilization, they always did.
And so we made an entire world system, a globalized world system with the aim of
preventing World War III. So the post-World War II Bretton Woods Mutually Assured Destruction
United Nations World was a solution to be able to steward that level of tech without destroying
ourselves. And it really was a reorganization of the world. And it was predicated on a few things.
Mutually Assured Destruction was critical. Globalization and economic trade was critical that
if the computer that we're talking on and the phone that we talk on is made over six
continents and no countries can make them on our own, we don't want to blow them up and ruin
their infrastructure because we depend upon it. So let's create radical economic interdependence
so we have more economic incentive to cooperate. That was kind of like the basis of that whole
world system. And we can see that we've had wars, but they've been proxy wars and cold wars,
they haven't been major superpower wars, and they've been unconventional ones. But we haven't had
a kinetic World War III. Now we're at a point where that radically positive sum economy that
required an exponential growth of the economy, which means of the materials economy, and it's
a linear materials economy that unrenewably takes resources from the earth faster than they can
reproduce themselves and turns them into waste faster than they can process themselves, has led
to the planetary boundaries issue, where it's not just climate change or overfishing or dead
zones in the ocean, or microplastics or species extinction or peak phosphorus, it's a hundred
things, right? Like there's all these planetary boundaries, so we can't keep doing exponential
linear materials economy. And then the mutually assured destruction thing doesn't work anymore
because we don't have two countries with one catastrophe weapon. It's really, really hard
to make and easy to monitor because it's not that many places that have uranium, it's hard to
enrich it, you can monitor by satellites. We have lots of countries with nukes, but we also have
lots of new catastrophe weapons that are not hard to make, that are not easy to monitor,
that don't even take nation states to make them. So if you have many, many actors of different kinds
with many different types of catastrophe weapons, how do you do mutually assured destruction?
You can't do it the same way. And so what we find is that the set of solutions post World War II
that kept us from blowing ourselves up with our new power lasted for a while,
but those set of solutions have ended. And they have now created their own set of new problems.
So there is catastrophic risk before World War II, which was locally existential,
and then there is catastrophic risk from World War II to now, which was globally existential,
but managed by what Daniel might call the Bretton Woods order, which includes the Bretton
Woods agreements, the United Nations and mutually assured destruction. But in Daniel's eyes,
the Bretton Woods order is no longer up to the task.
The UNS-17 Sustainable Development Goals, there's really one that must supersede them all,
which is develop the capacity for global coordination that can solve global problems.
If you get that one, you get all the other ones. If you don't get that one,
you don't get any of the other ones. That becomes the central imperative for the world at this time.
So in the vacuum of what Daniel sees as a failure of our institutions to do global
coordination well, what are we left with? How are we responding to these unmanaged existential
risks caused by exponential technology? Daniel sees too bad attractors that we're currently
getting pulled towards, and those attractors are oppression and chaos.
Oppression looks like China's digital authoritarianism model,
ruled by the state from above. So we're going to have quantum computing, AI,
godlike technology that psychologically influences billions of people,
but it's managed by the state and limits the freedom of citizens. Or we can have chaos,
instantiated by the West's democratic dysfunction, where exponential technologies
aren't really managed at all because social media has deranged our society to be maximally
addicted, distracted, outraged, polarized, and misinformed until people don't know what's
true at all. So how do we manage global existential risk without devolving into oppression or chaos?
What could a new attractor be? I think it was a Jefferson quote of the ultimate
depository of the power must be the people. And if we think the people too uneducated,
not enlightened, to be able to hold that power, we must do everything we can to seek to educate
and enlighten them, not to think that there is any other safe depository.
