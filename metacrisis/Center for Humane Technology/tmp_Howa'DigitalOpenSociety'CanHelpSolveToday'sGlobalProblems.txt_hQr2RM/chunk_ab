for how we fulfill them. We're not doing a very good job of that. We're leaving the innovation
in the tech to the private sector. The private sector is doing it the way that's making
exponentially more powerful companies, but not an exponentially better system of governance or
healthier nation states or healthier open society. And as a result, you see things like Facebook and
Google that are becoming more powerful than nation states, but simultaneously actually degrading the
integrity of the nation state when more people are more certain and outraged about more extremely
different things. Can you run a democracy in that place? No. Tristan is using the term open society
coming from Popper, Popper doing philosophy of science saying the only way we can do this is if
we can all make sense of the world together, we can apply the philosophy of science, we can apply
dialectical thinking and reasoning and communication to make sense of the world together so that we
can come to shared sense-making, so we can come to shared choice-making. If we don't have shared
sense-making, can we do shared choice-making? No, because we think that the other people are crazy,
their ideas of reality are not just done and wrong but bad. And we have to go into culture war as a
sublimated form of actual war to stop them because they want to ruin the environment or they want
to ruin our civil liberties or they want to whatever it is. And so we can see that the digital
technologies that have proliferated that give me what will maximize time on site by appealing to my
existing biases, group identities, limbic hijacks, means that we're more certain about the vaccine
and about masks and about COVID's origins and about climate change than we were before,
more extremely opposingly, where the other people are both wrong and bad and where the whole thing
feels consequential. Can you run anything like a democracy in that place? No, absolutely not.
When all the energy goes into infighting and you have some other situation that doesn't have
a bipartisan voting system with short-term limits and Facebook doing that, let's say here, China,
being more prescient to say, let's control our internet to have it not do that thing. Let's not
create a bipartisan system that will necessarily add to the polarization. Then all the energy doesn't
get wasted as heat in terms of infighting and they can do long-term planning, like that's just
going to win. It's better designed, honestly, whether we like it or not. It's better designed
functionally. We can see that the tech that equals power has been evolving. We have been,
not only not innovating our social technology, but we have been having our social technology get
debased by the way it's been outsourced to the private sector. The private sector is becoming
a new social technology, which is a few companies that have outsized influence over the whole world
but don't have formal jurisprudence of accountability to, of or by the people type,
openness of their choice-making. That's the emergence of a new type of feudalism. We see
authoritarian nation-state autocracy exponential tech. We see feudalism exponential tech.
We see oomph in societies just eroding. Those are the two strange attractors we're talking about.
And so catastrophes, like just global catastrophic breakdown of civilization,
isn't most people's model of how we should go if we can avoid it. And avoiding it through
control systems that control for that happening, but that also excessively control personal freedoms
is also not most people's model. So how do you maximize personal freedoms and the type of
liberty and sovereignty and diversity that we care about while having enough coherent order
that we don't end up having those types of chaotic destruction and breakdown catastrophe?
Those are the questions we're exploring. Great. Yeah. And you did a beautiful job of
yeah, articulating those two attractors in the episode. So let's actually try to talk about
some examples. And thank you for, these are squishy terms. And it's like, it's this, it's a,
yeah, it is a nebulous thing to be talking about. I don't think we can claim that some country is
a digital open society and some other country is a digital closed society. But keeping that in mind
that these are squishy terms, what do you see as examples of what we might think of as a digital
open society, whether it's a specific, whether it's a specific actually just technology and how
it could be used to enable something that we would call a digital open society, or whether it's
a specific initiative that a country is already putting into practice. And that's for either of you.
Daniel, you want to go for that one?
They were already mentioned that there are some examples of the level of nation states
working in this direction. I think the one that has made the most traction that I'm aware of and
that I think many of us are aware of is the work in Taiwan and specifically, you know, Audrey
Tain's work with digital democracy and that whole crew. And the Consilience Project just wrote a
paper on how that transition worked that ConsilienceProject.org. It's a good paper to check
out. Tristan has also done interviews with Audrey Tain that are worth checking out. And it was pretty
cool because, you know, it was actually a protest movement that rather than just being against started
to like come up with solutions of how to do a better thing, build them independently, people
about to see it was possible as opposed to not possible. And then that kind of forced adoption.
And then the government said, sure, well, we'll go ahead and go along with that.
Of course, what worked in Taiwan wouldn't work in the US in the exact same way or in Russia or the
UK. Like they have very different situations in terms of the scope of geography. People in
Taiwan can all get to where each other are within an hour and a half. They have a shared culture.
They have a higher level of base education. They have an eminent existential threat just on their
border. They built themselves much later than we did. So they already had a more advanced tech stack
as their basis. There's a bunch of things about it that are different. So we're not looking to try
to copy. We're looking at principles and seeing how those principles could be applied in different
instantiations. But what they're looking at is things like, hey, rather than just instantly vote
on a thing, do we even know how people feel about it? Do we even know what they care about?
Like, why do we wait till we have a proposition and then people vote on it? And then nobody even
knew about the problem before that or nobody cared about it. And now all the way that they're
caring about it is advertising their hearing from somewhere. Well, where are they hearing about it
from? They're hearing about it from some special interest groups that made the proposition and
some other special interest groups fighting the proposition who are now educating everyone
through propaganda. And so, and nobody ever found out like, what is all the stuff that people care
about first? So can we make a thing where we can find out what people care about to even have an
idea of what a proposition that was good might be? What are all the interconnected things? So
they're working on innovating stuff like that. So it's not fair to call that democracy because
the way we have understood democracy, and we have these terms like, is it a representative
democracy? Is it a direct democracy in new terms? Like, is it a liberal democracy? Or is it a
republic? Is it a constitutional republic? Which is why we want to throw all those into
the hopper of a broader idea. And so, open society is one vague kind of term to say,
is there a society that has openness of information flows and communication flows as much as possible
so that the people can be engaged in governance sharing the same information?
We could even better, we could call it participatory governance. Are there some
methods where the people have possibilities to engage in the choices that will affect their
life in meaningful and effective ways? We could talk about it as systems of collaboration at scale
or coordination. How do we coordinate the activity of all of these people in a way that
isn't forcing or manipulating people to do stuff? Well, if we're not manipulating people,
then people are going to do stuff based on what they want and what they understand. So is there
a way to help share the sense making and share the values where what people want empathizes with
what other people want and where they have shared information so we actually can coordinate
in an emergent way, an emergent order rather than imposed order or just chaos.
So we can talk about systems of collective intelligence. How do we increase the intelligence
of the whole so that we're not just more individual intelligence but also more shared
intelligence so that where we have decisions that affect each other and we do have decisions that
affect each other? Are we all going to build our own roads? No, we're not all going to build our
own roads. Well, I'm not killing all the fish. I'm not cutting down all the trees. I'm just taking
these ones that I want. But at that level, everybody doing that actually does kill all the
fish and cut down all the trees. Is there a way we do we need some kind of forest stewardship? Do
we need some kind of fish stewardship? Do we need some like this is a place where the rights of the
individual and the duty and the responsibility of the individual to the collective that they're a
part of have to be paired? So how do we even think about the values like rights and responsibilities,
right freedoms and duties in a paired way? And how do we create systems where as people want more
responsibility, they want more rights to be able to influence the system, there's greater
responsibilities they're willing to take on to implement those things. Meaning, if I want to
have more say in the thing, maybe there's more education that I do. So I actually know what
I'm talking about. If I if I want to have a say and with the US nuclear first strike policy is
going to be or what the nature of energy policy is going to be, like, does it make any sense?
And this was socrates is critiques of democracy, you know, does it make any sense to have a lot
of totally uneducated people weighing in on technical topics as a good system of intelligence,
like nobody would want a democracy designing their spaceship. They would want some kind of
meritocracy of people that actually understood aeronautics and rocketry and whatever. So how
much of our world is actually spaceship is technical shit, where and yet that becomes very easy to
then be the slippery slope into we are the elite that should rule everyone. So how do so? Okay,
well, we don't really want to trust our life to a bunch of people who have no idea what they're
talking about, but are certain because they're dumb enough about the topic, they don't even know
how much they don't know. On the other side, the guys who say trust us, we really know that there's
very good reason to be concerned about that. So there's failure modes in both ways. How would we
know what people know? How would we know how important the knowledge is to weighing in on a
topic? How would we create visibility dynamics, right? These are these are really key questions.
And how we answer them in the age of AI that can parse huge semantic fields and process a lot of
that how we answer it in the age of uncorruptible ledgers where we can ensure the provenance of
information so that no information is being corrupted or hidden where it's coming from.
We can answer this differently. So there's been a lot of social theory on this since the Scottish
Enlightenment since modernity since whatever. But it's fundamentally different in its axioms
now where we have to actually re go back and say Adam Smith didn't do the end of the thinking
on the thing, right? Or Jefferson didn't do the end of the thinking on the thing or Marx didn't.
Everybody had to figure out how to make most people laborers, how to make most people basically
workers because a society needed a lot of stuff done. So you had to figure out an economic system
that motivated people to spend their life doing stuff that they would have no intrinsic motive
to do. So a huge amount of capitalism is saying rather than the state force them, let's have the
market force them. Robotic automation is about to obsolete most of that and not that long.
So if you make it to where people don't have to do all the labor jobs is that change the nature
of how intrinsic versus extrinsic incentive work, what is possible with economics, what's possible
with education. So these are places where there's like, there's fundamental changes in the axioms
of what is possible and what has to happen. And this is where the social theory itself
can and has to be revisited and upgrade. Yeah. And you asked the question in a beautiful way
in the episode you say, you know, if the jobs don't need the people, can we design a society in
which the people don't need the jobs? Tristan, before we open up to Q&A, I just want to give you
a chance to also, yeah, offer an example that to you helps illustrate what you're thinking of when
you think of a digital open society and possibly, I know you've mentioned this. Actually, I don't
know where it came from, but this moving from broadcasting to broad listening, or at least
we have the capacity to broadcast, what it would it look like to have the capacity to broad listen.
So that's, if that sparks anything. You're muted.
There we go. For those who are coming into this conversation, especially if they just randomly
saw Lincoln on Twitter and jumped in and said, wait, I saw the social limit. Why are we talking
about all of this stuff? What I wanted to maybe also contextualize in our discussion about
digital open societies, many people might expect this conversation to be about, okay, I saw this
problem with social media. I saw this problem of, you know, the Facebook platforms and how do we
fix them? I think the premise is that having slightly less toxic social media doesn't deal
with the problems that Daniel's outlining of the increasing exponential Godlike powers that we have
and the kind of current trajectory of heading into either collapse via kind of chaotic, you know,
techno capitalism goes off the rails. And we get the Huxley and dystopia of we're an addicted,
distracted, outraged polarized society that doesn't even know what's true. That society wielding
increasingly Godlike powers, whether it's we're doing nuclear planning and figuring out what to
put the power plants for, you know, dealing with climate change that people don't even know. And
we're just voting on it with less and less, you know, mindfulness and expertise or wisdom.
That society fails and the oppressive society is not the one that we want to live in. And so
part of this, the reason that we wanted to do this conversation today was to upgrade people,
upgrade kind of the frame of what we're trying to get after here is not slightly less bad Facebook
or slightly less bad TikTok, which is still going to be incentivizing, you know, the
addicted, distracted, outraged, polarized sort of version of a society that doesn't have the
wisdom to wield the Godlike powers that Daniel's talking about. So just wanted to kind of weave
together a little bit, you know, why we're having this conversation and I think why we need to kind
of kind of put a put a little goal statement around this perimeter where we're headed towards.
And also to say when you talk about examples or response to what Daniel's saying,
you know, there's a vast space of people who are working on public interest technology or civic
governance tech, or, you know, includes, you know, the public interest work by Ford Foundation,
Amityar, Augustine Justice League, we have Eli Pariser's new public, which is working on new
digital infrastructure and identifying what are the design patterns of things like what Audrey
Tang is doing, systems like Polis, I know that people are putting some things into the chat
of other kind of democratic governance processes. Daniel mentioned in the episode that we did
together about people who are using GPT-3 and instead of finding the intersection of all these
different faces to generate a new face, taking a lot of people's political opinions and finding this
sort of higher dimensional point of overlap where actually people agree and on a new proposition,
but we actually haven't talked about it ourselves yet. So these are examples of if I don't want to do
chaos, which is the kind of take our hand off the steering wheel and social media drives us off
the rails or oppression where you have, you know, one top-down authoritarian government deciding
everything and limiting freedom, we need to have some other models. I agree that Audrey Tang is
kind of the best thing that we have. When it comes to privacy-preserving data sharing, I point
people to things like open mind, M-I-N-E-D. When it comes to open science, Daniel talked about
actually how do we do open science and have public data sets? And then when there's actually a
change where you realize there's an error in that scientific study, everything downstream gets updated.
Old friend of mine, Victoria Stoddon actually helped drive a lot of that work and there's a
huge field in making more computational open science. We have things like Lumeo, which are
doing sort of shared decision-making for communities. How do we do more bottom-up governance and
decision-making? We have things like quadratic voting from the Ethereum community from Vitalik
Buterin and Glenn Weil, where we're actually saying, if I'm going to say this is the thing
that we want, I'm going to have to put more skin in the game on a quadratic curve if I really
want to endorse that that's the thing we need to do. When I talk about all these things, I don't
want people to think that this is the perfect answer and that we're saying that we're taking a big
rubber stamp and we're putting a humane tech or digital open society stamp on these six technology
systems. It's more that there's a lot of people who are already orienting their work around this
and we kind of want to say these are all going in a direction of answering the question of how
do we not fall into oppression and chaos? There's honestly so much more to talk about in such a
short period of time. I am curious also what big questions people have coming from the episode
because I think that's going to be most helpful for people rather than the few of us talking
actually without knowing what biggest questions people have. Yeah, great. Thank you Tristan and
thank you Daniel and yeah fantastic fantastic food for thought. So yeah we can let's open it up to
