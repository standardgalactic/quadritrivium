Thank you so much for joining us today.
My name is David J. I'm the head of mobilization at the Center for Humane Technology and I'm
really excited to invite you to a very special for us edition of today's podcast club. For those
of you joining us for the first time, the podcast club, you can think of it sort of like a book club
for the podcast, your undivided attention, where we have more in-depth conversations with guests,
take questions from you all in the audience, and then invite you to connect with one another
around the really deep ideas that are getting talked about here at the Center for Humane
Technology, because ultimately the way things change isn't just us articulating powerful ideas,
it's you all building trust, building relationships, and building the power to change the world.
So with that, I'm going to start us off the way that we normally do with one minute of silence,
even though our bodies are here on this shared call. A lot of us are holding big complicated
things in our world and I found that taking a minute to ground ourselves before we fill
up with the really rich ideas we're going to be talking about here will yield a lot of benefits.
So you will take one minute, you'll hear a sound coming from my mic when we're done,
and then we will dive into our conversation.
Okay, so I am extremely excited to introduce our guest, Daniel Smokneburger.
I guess Daniel Smokneburger and Tristan Harris will be in conversation today,
continuing the great conversation you've had with the podcast. I'm also extremely excited to
introduce Stephanie Lep, the producer of Your Undivided Attention, and a first time kind of
guest in our podcast club. Stephanie, you have been going so deep into the really rich ideas
being explored today. We knew that you were the perfect person to be facilitating this discussion.
So I'm going to be bowing out and leaving the conversation in your very capable hands.
Oh, Stephanie, you're on mute.
Ah, thank you, Tristan. Thank you, David. I was just saying I'm loving these emojis.
I have no idea where they're coming from, but they're very sweet.
All right. Well, hello, Your Undivided Attention podcast club.
Yeah, I am honored to join the Center for Humane Technology and honored to have as my inaugural
episode feature two brilliant people who I also can call friends. Tristan is an old friend,
and Daniel, I think I can call you a new friend. And so here is how our time together is going
to unfold. So I'm going to briefly introduce Daniel and then briefly introduce the topic
that Daniel and Tristan will be talking about and then ask them some questions about that
topic. And then we will open it up to all of you first with some Q&A. So please throw your
questions into the chat as we go so we can get them up on the screen in the Q&A. And then we'll
have some breakout groups for further more intimate discussion. And then we will come back together
and close. And so with that, welcome, Daniel. Thank you, Stephanie. Can you hear me all right?
Yes. Yeah. So by way of introduction, these emojis are very sweet, but they're totally
dividing my attention. I don't know. I don't know how to make them stop. Maybe that's something
David J. can do. Yeah, they are kind of dividing my attention as well, I would say.
So yeah, by way of introduction, Danish Machenberger is focused on ways of improving the
health and development of individuals and society for the purpose of creating a more
virtuous relationship between individuals and society. Sounds like a very worthy focus.
He is a founding member of the Consilience Project, which is aimed at improving public
sense making and dialogue. And Daniel is a prolific and generous thinker and writer and
speaker. And if you follow his work, you already know that. And if you don't, you can find links
to his work on our website on the webpage for our episode with him. And so the topic that
Daniel and Tristan are going to be exploring together, kind of springboarding from our episode,
is this notion of a digital open society. So on the one hand, we see some societies using
exponential technology in order to... We just lost Stephanie. There she comes.
Stephanie, you just left for a second and lost connection, but centralized power, I think.
Centralized power, yes. And enhanced surveillance. So think China, think Singapore. So we might think
of that model roughly as, let's say, a digital closed society. On the other hand, we see other
countries using technology to enable, you know, interactive democracy and citizen agency and
transparency and accountability. And so consider Taiwan, consider Estonian. So we might think of
that model as a digital open society. And so what we'd love to explore today, with Daniel and
Tristan and all of you, is how this notion of a digital open society might be a helpful frame
for thinking about how societies can use technology in order to address, you know,
addiction, polarization, breakdown in shared sensemaking, the climate crisis, like the
interrelated problems that we care about, i.e., the meta crisis. And so with that, I'm going to
pose this first question to you, Tristan. And that is, you know, understanding that, you know,
digital open society is an evolving frame and that many people and organizations,
including folks who are here with us today, are already working on that without necessarily
calling it that. How would you articulate what a digital open society is and how it differs from
a digital closed society? Yeah. Well, I think, you know, as we get into that topic,
obviously, the best way for people, if you haven't listened to this already, is to go back
and listen to the, you know, long unended conversation that Daniel and I had, trying to
really explore why such a digital open society is so needed or important. Because I want to
say here that we're not coming to the table thinking that we have the perfect utopian model.
We've already figured it out. This is exactly the spec for what a digital open society is.
We're also not just randomly pointing to a new North Star. We're trying to answer a current
trajectory, which I is rapidly heading towards the oppression or chaos direction that Daniel
mentioned. And I wanted to start today by reading a quote that I've actually referred to many times,
including on the Joe Rogan podcast that actually, first and for my work, in fact, I'll say that
when my first presentation went viral at Google about the attention economy and sort of raising
the alarms and that presentation was the one that was featured in the film, The Social Dilemma,
the most powerful and useful thing that came back from someone at Google
was listing a quote from Neil Postman's book, Amusing Ourselves to Death. And when she opens
that book with a quote about teetering between Orwell and Huxley, for those who don't know,
Orwell was the Orwellian 1984 vision of a dystopia and Huxley was the brave new world dystopia.
And people know the Orwell one. They don't know the Huxley ones. I'm just going to briefly read
that quote and then actually want to let Daniel do most of the speaking here and kind of elaborating
on what we mean by a digital open society. And what Neil Postman wrote was, what Orwell feared
were those who would ban books. What Huxley feared was that there would be no reason to ban a book,
for there would be no one who wanted to read one. Orwell feared those who would deprive us of
information. Huxley feared those who would give us so much information that we would be reduced to
passivity and egoism. Orwell feared that the truth would be concealed from us. Huxley feared that
the truth would be drowned in a sea of irrelevance. Orwell feared we would become a captive culture,
while Huxley feared we would become a trivial culture. And as Huxley remarked in Brave New World,
the civil libertarians and rationalists who were ever on the alert to oppose tyranny or oppression,
they failed to take into account man's almost infinite appetite for distractions,
including maybe some of the emojis that are on the screen right now.
And in 1984 Orwell added, people are controlled by inflicting pain. In Brave New World, they are
controlled by inflicting pleasure. In short, Orwell feared that what we fear will ruin us,
and Huxley feared that what we desire will ruin us. And so I wanted to bring this up because
Daniel, I think what I would love to have you speak to just a little bit is
we're not just randomly trying to say, hey, there's this thing called an open society and we should
try to build that digital 21st century thing. What is the default outcome that we're heading
towards? You mentioned the attractors of chaos and oppression, which are Huxley and Orwell.
Why is that just maybe just elaborate a little bit on why we're heading to those
two out? Because if we do nothing, we take our hand off the steering wheel.
Yeah, I want to hear feedback. Is that better? Oh,
I want to just acknowledge there were some comments that said I don't know if it's fair to
consider Singapore a closed society. There are some people who would say it's not fair to consider
China a closed society. There are some people who would say the idea that the US is an open
society when as much of the budget goes into black projects or gray projects and TSSCI
compartmentalization is not a fair consideration or that there is or has ever been an open society
actually. So these terms are very squishy, and we can get in trouble quickly. And then what do we
mean by digital? Is the whole key that we're using digital technology? No, we need to rebuild our
energy infrastructure. That's not a purely digital technology. That's the domain of atoms. We need
to rebuild manufacturing. We need to rebuild the physical materials economy so that everything
isn't made from raw resources that are depleting the world unrenowably on one side and turning
into pollution on the other side. So when we say digital, it really represents the center of the new
tech stack, but that the center of the new tech stack means the entire new tech stack. So what
we're talking about is that our physical technologies are going through a step function.
When our physical technologies go through a step function, our total power and how we behave
because technology ends up eliciting patterns of human behavior. If you have a tractor and you
don't use it and other people are using plows, then your people are just going to do much less
well. So the existence of the tractor codes the pattern of behavior of using the thing because
it's so much more adaptive, which means that the agrarian religions and mythos that have to do with
plow type cultures are going to change to industrial ideologies. So basically every time the
technology stack changes fundamentally, the social technologies, how do we coordinate have to change
correspondingly. So there is a, the industrial revolution was a major change and starting with
the printing press, feudalism, a lot of the basis of how that worked kind of got debased and we got
nation states. And so the movement into an internet world and computation applied to everything.
This is why we can say digital is it's not just computation and then the rest of the non-computation
world. It's that we can apply computation and then advanced tools of computation, meaning
machine learning on big data sets and like that, we can apply that to biology and protein
folding and drug development. We can apply it to nanotech and material sciences and balancing
energy grid. So that's not purely digital, but it's the basically computation at the center of a
new tech stack, AI at the very center of that, the technological substrate that mediates computation,
where the computation, the software can make the hardware that supports it better,
better transistor density, quantum computers, often photo computers, those types of things.
And then also the rest of the hardware stack, like the Internet of Things sensors and the rest of
the physical kind of infrastructure hardware. And then that applied to material sciences, biology,
everything else. And the reason we talk about the technology as exponential is it's tech
that helps us make better tech. So there's a compounding return, like gaining interest on
interest, right? Better computers allow you to model to be able to make better computers.
And so I'm just wanting to clarify, because if we take the terms literally, we'll get misguided,
right? Like they're pointing to a whole field of things. So when we say a digital open society,
what we mean is there is an emerging new suite of technologies that are,
you know, when we figure out calculus, and we can plot a ballistic curve. And we've got some
people who are aiming cannons by plotting a ballistic curve, and other ones who are doing a
pendulum dousing, like one of those is just going to win really, really clearly. The gunpowder
revolution and those who have guns versus those who don't. So who has more power just ends up
winning the game of determining what the world is in a kind of real politic assessment.
When you have a jump of power that has an exponent exponent in it, those who are developing and
deploying exponential technologies will just have more of a say in determining the future than anyone
who's not developing and deploying them. So at the center of the exponential stack, we can say
is digital technology. So we use digital as a shorthand to say, what are the new societies that
can utilize these powers? Because if they don't, they just won't matter. Not because they shouldn't,
but because in the in the nature of what we'll get selected for, if the thing doesn't actually,
if it doesn't actually do a better job at the current game of competing for power and being
able to organize people and do productivity, it's just not going to matter. So how do we utilize all
these technologies? And how do we utilize them to make a world we actually want as opposed to not
want? Because the increased technological power can just mess the world up. And there's a lot of
catastrophic risk associated with runaway AI with even the mild examples we already see that Tristan
talks about that is definitely not like a full blown paperclip maximizer or some kind of runaway AGI,
but is, whoa, we just kind of broke democracy and broke public solidarity in the epistemic
commons and drove kind of addiction and limbic hijacks across the whole population with a pretty
narrow AI, just optimizing an ad revenue model on a couple websites. Now we start to multiply that
by growing AI and the AI empowering autonomous weapons and all the other things. And we realized
that the way humans have navigated power so far has not been all that wise. We have used our power
to destroy environments, we've used our power to destroy other civilizations and win the game of
empire. So if you multiply that by exponential power, exponential externalities don't keep
working and exponential warfare doesn't keep working. So the exponential tech not guided more
wisely than we have used tech in the past looks like either exponential warfare or exponential
externality, those both look like catastrophic risk in a world where we have full globalization,
we have so much interdependence on the supply chains that we all depend upon these computers
that we're talking through and the whole internet infrastructure and the servers and the satellites
that we're talking through. And all of these are produced on vast supply chains across six
continents where problems anywhere can actually mess up those supply chains everywhere. So we have
a situation where you can't have localized failures that don't start to create cascade
dynamics in a way that wasn't true in the Roman Empire, the British Empire or any previous time
in history. We're also running up against planetary boundaries, not just with climate
change and overfishing, but a hundred different planetary boundaries where you can't just keep
doing exponential growth through extraction. We're also running up to where even smaller
groups can cause whether the smaller group is a militant group or a small group like a startup
called Facebook can cause much larger effect on the whole world through the exponential
technology that's involved. And so we are at a point where catastrophic risk as a function of
the total amount of tech we have plus how interconnected the planet is plus how the cumulative
effect of hitting planetary boundaries means the world has high fragility. And so catastrophic risk
is one attractor. If we keep going with exponential tech in the current way, we keep getting
increasing probabilities of catastrophic risk across more different catastrophic risk categories.
The only way to avoid that is to have societies that can't can avoid it that can anticipate and
control keep those things from happening. And that requires quite a lot of information and
quite a lot of control. And most of those end up being societies that don't look like the nicest
place to live, according to the values of most people for most people. So that looks like models
that are maybe stable in the presence of exponential tech in, but they are stable in a way that
many would consider dystopic. And this is when we're talking about, you know, the system of
the constitutional republic we have in the United States, the system of governance,
was a like early industrial revolution, not even like post Henry Ford, like an early industrial
revolution, yeoman farmer level society that assumed very small little local populations
that could all get into a town hall and largely know each other that didn't have major catastrophic
risks that didn't have to have as many places where the people all had to work together because
they weren't affecting each other because of not having, you know, integrated tech stacks and things
like that. So you can see that we have we've innovated in our military, but we haven't been
innovating in our fundamental system of governance. How do we have government that is
up for by the people and support of life, liberty and the pursuit of happiness based on ideals that
everyone has created equal and has inalienable rights, like even as many problems as those ideas
had in our bad instantiations of them from the beginning, if any of those values, even modified
versions of them seem valuable, there's some fundamental innovation that should be happening
for how we fulfill them. We're not doing a very good job of that. We're leaving the innovation
in the tech to the private sector. The private sector is doing it the way that's making
exponentially more powerful companies, but not an exponentially better system of governance or
healthier nation states or healthier open society. And as a result, you see things like Facebook and
Google that are becoming more powerful than nation states, but simultaneously actually degrading the
integrity of the nation state when more people are more certain and outraged about more extremely
different things. Can you run a democracy in that place? No. Tristan is using the term open society
coming from Popper, Popper doing philosophy of science saying the only way we can do this is if
we can all make sense of the world together, we can apply the philosophy of science, we can apply
dialectical thinking and reasoning and communication to make sense of the world together so that we
can come to shared sense-making, so we can come to shared choice-making. If we don't have shared
sense-making, can we do shared choice-making? No, because we think that the other people are crazy,
their ideas of reality are not just done and wrong but bad. And we have to go into culture war as a
sublimated form of actual war to stop them because they want to ruin the environment or they want
to ruin our civil liberties or they want to whatever it is. And so we can see that the digital
technologies that have proliferated that give me what will maximize time on site by appealing to my
existing biases, group identities, limbic hijacks, means that we're more certain about the vaccine
and about masks and about COVID's origins and about climate change than we were before,
more extremely opposingly, where the other people are both wrong and bad and where the whole thing
feels consequential. Can you run anything like a democracy in that place? No, absolutely not.
When all the energy goes into infighting and you have some other situation that doesn't have
a bipartisan voting system with short-term limits and Facebook doing that, let's say here, China,
being more prescient to say, let's control our internet to have it not do that thing. Let's not
create a bipartisan system that will necessarily add to the polarization. Then all the energy doesn't
get wasted as heat in terms of infighting and they can do long-term planning, like that's just
going to win. It's better designed, honestly, whether we like it or not. It's better designed
functionally. We can see that the tech that equals power has been evolving. We have been,
not only not innovating our social technology, but we have been having our social technology get
debased by the way it's been outsourced to the private sector. The private sector is becoming
a new social technology, which is a few companies that have outsized influence over the whole world
but don't have formal jurisprudence of accountability to, of or by the people type,
openness of their choice-making. That's the emergence of a new type of feudalism. We see
authoritarian nation-state autocracy exponential tech. We see feudalism exponential tech.
We see oomph in societies just eroding. Those are the two strange attractors we're talking about.
And so catastrophes, like just global catastrophic breakdown of civilization,
isn't most people's model of how we should go if we can avoid it. And avoiding it through
control systems that control for that happening, but that also excessively control personal freedoms
is also not most people's model. So how do you maximize personal freedoms and the type of
liberty and sovereignty and diversity that we care about while having enough coherent order
that we don't end up having those types of chaotic destruction and breakdown catastrophe?
Those are the questions we're exploring. Great. Yeah. And you did a beautiful job of
yeah, articulating those two attractors in the episode. So let's actually try to talk about
some examples. And thank you for, these are squishy terms. And it's like, it's this, it's a,
yeah, it is a nebulous thing to be talking about. I don't think we can claim that some country is
a digital open society and some other country is a digital closed society. But keeping that in mind
that these are squishy terms, what do you see as examples of what we might think of as a digital
open society, whether it's a specific, whether it's a specific actually just technology and how
it could be used to enable something that we would call a digital open society, or whether it's
a specific initiative that a country is already putting into practice. And that's for either of you.
Daniel, you want to go for that one?
They were already mentioned that there are some examples of the level of nation states
working in this direction. I think the one that has made the most traction that I'm aware of and
that I think many of us are aware of is the work in Taiwan and specifically, you know, Audrey
Tain's work with digital democracy and that whole crew. And the Consilience Project just wrote a
paper on how that transition worked that ConsilienceProject.org. It's a good paper to check
out. Tristan has also done interviews with Audrey Tain that are worth checking out. And it was pretty
cool because, you know, it was actually a protest movement that rather than just being against started
to like come up with solutions of how to do a better thing, build them independently, people
about to see it was possible as opposed to not possible. And then that kind of forced adoption.
And then the government said, sure, well, we'll go ahead and go along with that.
Of course, what worked in Taiwan wouldn't work in the US in the exact same way or in Russia or the
UK. Like they have very different situations in terms of the scope of geography. People in
Taiwan can all get to where each other are within an hour and a half. They have a shared culture.
They have a higher level of base education. They have an eminent existential threat just on their
border. They built themselves much later than we did. So they already had a more advanced tech stack
as their basis. There's a bunch of things about it that are different. So we're not looking to try
to copy. We're looking at principles and seeing how those principles could be applied in different
instantiations. But what they're looking at is things like, hey, rather than just instantly vote
on a thing, do we even know how people feel about it? Do we even know what they care about?
Like, why do we wait till we have a proposition and then people vote on it? And then nobody even
knew about the problem before that or nobody cared about it. And now all the way that they're
caring about it is advertising their hearing from somewhere. Well, where are they hearing about it
from? They're hearing about it from some special interest groups that made the proposition and
some other special interest groups fighting the proposition who are now educating everyone
through propaganda. And so, and nobody ever found out like, what is all the stuff that people care
about first? So can we make a thing where we can find out what people care about to even have an
idea of what a proposition that was good might be? What are all the interconnected things? So
they're working on innovating stuff like that. So it's not fair to call that democracy because
the way we have understood democracy, and we have these terms like, is it a representative
democracy? Is it a direct democracy in new terms? Like, is it a liberal democracy? Or is it a
republic? Is it a constitutional republic? Which is why we want to throw all those into
the hopper of a broader idea. And so, open society is one vague kind of term to say,
is there a society that has openness of information flows and communication flows as much as possible
so that the people can be engaged in governance sharing the same information?
We could even better, we could call it participatory governance. Are there some
methods where the people have possibilities to engage in the choices that will affect their
life in meaningful and effective ways? We could talk about it as systems of collaboration at scale
or coordination. How do we coordinate the activity of all of these people in a way that
isn't forcing or manipulating people to do stuff? Well, if we're not manipulating people,
then people are going to do stuff based on what they want and what they understand. So is there
a way to help share the sense making and share the values where what people want empathizes with
what other people want and where they have shared information so we actually can coordinate
in an emergent way, an emergent order rather than imposed order or just chaos.
So we can talk about systems of collective intelligence. How do we increase the intelligence
of the whole so that we're not just more individual intelligence but also more shared
intelligence so that where we have decisions that affect each other and we do have decisions that
affect each other? Are we all going to build our own roads? No, we're not all going to build our
own roads. Well, I'm not killing all the fish. I'm not cutting down all the trees. I'm just taking
these ones that I want. But at that level, everybody doing that actually does kill all the
fish and cut down all the trees. Is there a way we do we need some kind of forest stewardship? Do
we need some kind of fish stewardship? Do we need some like this is a place where the rights of the
individual and the duty and the responsibility of the individual to the collective that they're a
part of have to be paired? So how do we even think about the values like rights and responsibilities,
right freedoms and duties in a paired way? And how do we create systems where as people want more
responsibility, they want more rights to be able to influence the system, there's greater
responsibilities they're willing to take on to implement those things. Meaning, if I want to
have more say in the thing, maybe there's more education that I do. So I actually know what
I'm talking about. If I if I want to have a say and with the US nuclear first strike policy is
going to be or what the nature of energy policy is going to be, like, does it make any sense?
And this was socrates is critiques of democracy, you know, does it make any sense to have a lot
of totally uneducated people weighing in on technical topics as a good system of intelligence,
like nobody would want a democracy designing their spaceship. They would want some kind of
meritocracy of people that actually understood aeronautics and rocketry and whatever. So how
much of our world is actually spaceship is technical shit, where and yet that becomes very easy to
then be the slippery slope into we are the elite that should rule everyone. So how do so? Okay,
well, we don't really want to trust our life to a bunch of people who have no idea what they're
talking about, but are certain because they're dumb enough about the topic, they don't even know
how much they don't know. On the other side, the guys who say trust us, we really know that there's
very good reason to be concerned about that. So there's failure modes in both ways. How would we
know what people know? How would we know how important the knowledge is to weighing in on a
topic? How would we create visibility dynamics, right? These are these are really key questions.
And how we answer them in the age of AI that can parse huge semantic fields and process a lot of
that how we answer it in the age of uncorruptible ledgers where we can ensure the provenance of
information so that no information is being corrupted or hidden where it's coming from.
We can answer this differently. So there's been a lot of social theory on this since the Scottish
Enlightenment since modernity since whatever. But it's fundamentally different in its axioms
now where we have to actually re go back and say Adam Smith didn't do the end of the thinking
on the thing, right? Or Jefferson didn't do the end of the thinking on the thing or Marx didn't.
Everybody had to figure out how to make most people laborers, how to make most people basically
workers because a society needed a lot of stuff done. So you had to figure out an economic system
that motivated people to spend their life doing stuff that they would have no intrinsic motive
to do. So a huge amount of capitalism is saying rather than the state force them, let's have the
market force them. Robotic automation is about to obsolete most of that and not that long.
So if you make it to where people don't have to do all the labor jobs is that change the nature
of how intrinsic versus extrinsic incentive work, what is possible with economics, what's possible
with education. So these are places where there's like, there's fundamental changes in the axioms
of what is possible and what has to happen. And this is where the social theory itself
can and has to be revisited and upgrade. Yeah. And you asked the question in a beautiful way
in the episode you say, you know, if the jobs don't need the people, can we design a society in
which the people don't need the jobs? Tristan, before we open up to Q&A, I just want to give you
a chance to also, yeah, offer an example that to you helps illustrate what you're thinking of when
you think of a digital open society and possibly, I know you've mentioned this. Actually, I don't
know where it came from, but this moving from broadcasting to broad listening, or at least
we have the capacity to broadcast, what it would it look like to have the capacity to broad listen.
So that's, if that sparks anything. You're muted.
There we go. For those who are coming into this conversation, especially if they just randomly
saw Lincoln on Twitter and jumped in and said, wait, I saw the social limit. Why are we talking
about all of this stuff? What I wanted to maybe also contextualize in our discussion about
digital open societies, many people might expect this conversation to be about, okay, I saw this
problem with social media. I saw this problem of, you know, the Facebook platforms and how do we
fix them? I think the premise is that having slightly less toxic social media doesn't deal
with the problems that Daniel's outlining of the increasing exponential Godlike powers that we have
and the kind of current trajectory of heading into either collapse via kind of chaotic, you know,
techno capitalism goes off the rails. And we get the Huxley and dystopia of we're an addicted,
distracted, outraged polarized society that doesn't even know what's true. That society wielding
increasingly Godlike powers, whether it's we're doing nuclear planning and figuring out what to
put the power plants for, you know, dealing with climate change that people don't even know. And
we're just voting on it with less and less, you know, mindfulness and expertise or wisdom.
That society fails and the oppressive society is not the one that we want to live in. And so
part of this, the reason that we wanted to do this conversation today was to upgrade people,
upgrade kind of the frame of what we're trying to get after here is not slightly less bad Facebook
or slightly less bad TikTok, which is still going to be incentivizing, you know, the
addicted, distracted, outraged, polarized sort of version of a society that doesn't have the
wisdom to wield the Godlike powers that Daniel's talking about. So just wanted to kind of weave
together a little bit, you know, why we're having this conversation and I think why we need to kind
of kind of put a put a little goal statement around this perimeter where we're headed towards.
And also to say when you talk about examples or response to what Daniel's saying,
you know, there's a vast space of people who are working on public interest technology or civic
governance tech, or, you know, includes, you know, the public interest work by Ford Foundation,
Amityar, Augustine Justice League, we have Eli Pariser's new public, which is working on new
digital infrastructure and identifying what are the design patterns of things like what Audrey
Tang is doing, systems like Polis, I know that people are putting some things into the chat
of other kind of democratic governance processes. Daniel mentioned in the episode that we did
together about people who are using GPT-3 and instead of finding the intersection of all these
different faces to generate a new face, taking a lot of people's political opinions and finding this
sort of higher dimensional point of overlap where actually people agree and on a new proposition,
but we actually haven't talked about it ourselves yet. So these are examples of if I don't want to do
chaos, which is the kind of take our hand off the steering wheel and social media drives us off
the rails or oppression where you have, you know, one top-down authoritarian government deciding
everything and limiting freedom, we need to have some other models. I agree that Audrey Tang is
kind of the best thing that we have. When it comes to privacy-preserving data sharing, I point
people to things like open mind, M-I-N-E-D. When it comes to open science, Daniel talked about
actually how do we do open science and have public data sets? And then when there's actually a
change where you realize there's an error in that scientific study, everything downstream gets updated.
Old friend of mine, Victoria Stoddon actually helped drive a lot of that work and there's a
huge field in making more computational open science. We have things like Lumeo, which are
doing sort of shared decision-making for communities. How do we do more bottom-up governance and
decision-making? We have things like quadratic voting from the Ethereum community from Vitalik
Buterin and Glenn Weil, where we're actually saying, if I'm going to say this is the thing
that we want, I'm going to have to put more skin in the game on a quadratic curve if I really
want to endorse that that's the thing we need to do. When I talk about all these things, I don't
want people to think that this is the perfect answer and that we're saying that we're taking a big
rubber stamp and we're putting a humane tech or digital open society stamp on these six technology
systems. It's more that there's a lot of people who are already orienting their work around this
and we kind of want to say these are all going in a direction of answering the question of how
do we not fall into oppression and chaos? There's honestly so much more to talk about in such a
short period of time. I am curious also what big questions people have coming from the episode
because I think that's going to be most helpful for people rather than the few of us talking
actually without knowing what biggest questions people have. Yeah, great. Thank you Tristan and
thank you Daniel and yeah fantastic fantastic food for thought. So yeah we can let's open it up to
questions. All right, well if I could just say things like that and it would just happen.
Okay so this is from Max Peacock in Canada. So how can the next generation of entrepreneurs
redesign social media to better assist collective sense-making? What might future business models
look like? Tristan, that might be a yeah for you to run with that. Well we can we can both do it.
I mean clearly we're going to go with the advertising business model. It tends to produce the best
sense-making at scale, has the best effects on society, also funds you know the creation of
really good future sense-making and so I think that we need to actually rethink the incentives
at such a fundamental level. I've been trying to learn more about how different countries are
doing this. I think social media that's powered more by payments or micro payments where there's
more of a peer-to-peer incentive system and money flows that are flowing in the direction of what we
later endorse. I think one of the things we have to fundamentally do is decouple the click
from value. We've actually joked in the past that if there were to be a book on this topic,
the title of the book might be the click, the mistake that turned the world upside down,
which is to say that the click, which is basically just a pairing to the lower parts of our limbic
system, that signal, think about what are the signals that enter into a social media environment?
If we're just mining for what did people click on, that signal by itself as the primary input for
how would we re-rank the deck chairs in the Titanic with just clicks? Well all the deck chairs in the
Titanic, if they're clicks, it's just not going to be a good signal. How do we do more retrospective
reviews? One of the things that actually Facebook did in its research was asking people on retrospect
of the things that they saw, what would they say was quote unquote good for the world and they
actually created a new news feed that people looked back on the things that they clicked on
and said the things that they thought not just that they were happy about that made them happy
or something like that, like a skateboarding video that I liked in the moment that I actually
really liked later I didn't regret. That's one way to kind of deepen the signal of value,
but a different one is what would actually be good for others and they found a direct conflict
actually between what was engaging for Facebook and what was bad for the world and so they actually
ended up continuing to show people things that were bad for the world because that was most
engaging for Facebook. So I would just say that we need better research and actually Daniel,
I know one of the things you've talked about in terms of new metrics for what would make
more healthy social media is a new metric for how would you measure the well-being of a society
and I think you have a really interesting metric that maybe you can talk a little bit.
Yeah, that model that you're referencing take a minute to discuss.
But the question the way it's framed how would an entrepreneur work on this?
Probably what they mean by entrepreneur has the assumption of within the for-profit sector
within capitalism so assuming those constraints and that's actually a really key thing to assume
because the social media is a method of incentivizing patterns of allocation of human
attention at massive scale and so then what the platform is incentivized to do is going to be
determining how it develops kind of incentive tech and as we know Facebook and Google both have
more users than China and the US have people combined right and much more total time interacting
with them than we are interacting with our governments these are extraordinarily powerful and
someone was asking a question something like but isn't the click of social validation isn't that
stuff that we want there are higher and lower angels of our nature and we can appeal to either
and when we have trillion-dollar organizations appealing to the lower angels of our nature
it's just a bad direction right like we all know that we can be in environments where based on who
were around we're more likely to gain weight get out of shape drink more whatever it is especially
where we have those susceptibilities we know that we can be in another environment that makes it
easier to stop drinking to get healthier based on do I live with three triathletes or do I live
with other people who have my worst habits you know so so yeah it's easy to have the drug dealer
provide drugs to young kids who are upset and then get them addicted and then say I'm just providing
what they want right this is voluntaryism I'm just providing the supply it's their authentic
demand but yeah it's demand after in the same way that hostess is doing voluntaryism it's just
providing what people want except it's providing what the weakest most addicted vulnerable part of
them wants that actually makes their life comprehensively worse makes them hate themselves
and what other parts of them totally don't want but that they don't have good control over so if we
have as much asymmetric power as a mcdonald's or a hostess or even more a facebook or a google
and I'm in parts conflict which part of me do I hope it's appealing to
for my own growth and well-being and then the well-being of a society based on people that
either have the worst parts of themselves or the better parts of themselves being the basis of the
business model and so just the idea people wanted is neglecting manufactured demand and pretending
that the homo economicus is a real thing and we just make rational decisions based on a coherent
self and all the information and that we aren't making decisions based on addictive tendencies
biologic tendencies status hijacked dynamics very easy to make someone really want something they
never wanted or even knew existed before and that actually comprehensively makes the quality
of their life worse overall and so and then have the plausible deniability to say well
I was just providing them what they want yeah after ensuring that they wanted it using highly
effective manipulative asymmetric supply side tools so so then we have to say is capitalism
itself of adequate incentive system for us to answer these questions this is the entrepreneur
question or if your goal is profit maximization and profit is an extractive metric how much
more did I take out fiscally from the system than I put into it and I actually have let's say
as an entrepreneur I'm going to try to get venture capital and the venture capital wants a
raise to raise to raise to exit plan this means I'm going to move into a model of fiduciary
responsibility to shareholder profit maximization this means that those who make the choices would
actually be breaking the law to not maximize profit maximize profit means that whatever the
profit metric is I have to maximize it are there any activities that another person can make that
I can profit from where their life is best by me maximizing it if I have really significant influence
over them no because healthy life is mostly about balance for something that is good for them in one
dose is really bad for them in another dose and so can I make a profit without maximizing it sure
when I'm doing something good if I maximize it like can we have a food company that makes money
but that doesn't make the maximum money that making the maximally addictive stuff would
so this is where we have to say can a company that has fiduciary responsibility to shareholder
profit maximization does it even have the governance possible to do healthy social media no does not
you can operate within capitalism but you can't do profit maximization so the governance of it
has to be different to begin with the incentive structure which might mean you aren't taking
venture capital it's some other thing do we even need to assume that it's private sector doing this
or could you have co-ops right where in the same way that linkedin or wikipedia or whatever is not
operating from just a for-profit model could and blockchain is an example of communities looking
at this could we have a system where instead of the value of the network being owned by someone
who's extracting profit the value of the network is owned by the community of everyone who's
participating so there is no extractive metric the whole benefit of the network flows back into
the network yeah technologically we can do stuff like that it requires innovation and there are
no examples that are good enough yet in the same way that when the founding fathers were thinking
about the us the question well who's done constitutional republics adequately so far
there's just like no we're innovating we're trying to do something that has not yet been done
and so there are no systems that of governance that are adequate to the technological power
and complexity of what we need to govern there's good work being done in parts of it but there is
not a holistic consideration set that is adequate that's what people need to be inspired to engage
in and they have to question the axioms like is this something a state should fund is this
something a co-op should fund is this something that doesn't have to have individual ownership in
the same way at all because partial attribution through things like decentralized ledgers can
make a totally different model than we had before and actually have the value of the thing flow back
to the network if it's going to be a company could it be a company that has b-corp laws or
not for-profit where the profit flows back in so there isn't an extractive metric even if there
is a revenue model those are really key questions to be asking because otherwise the axioms or the
assumptions you're bringing in are probably a major part of what made the design flaws in the
first place yep so okay so for all the entrepreneurs out there right it's not just the thing you build
it's building it in a way that changes the entire playing field it's on which you're operating good
luck with that just kidding uh that's what we're here to help us all envision um
you know one last thing because i know we're gonna switch into breakouts in q and a and
in just a little bit but there's one of the a first call out uh zebras unite which is an
organization that does funding um and really concern with the funding models of new technology
and um this comes after the naming and nomenclature that silicon valleys usually after the unicorns how
do you hit a billion dollars in a few years and that's all we're funding is those unicorns and we
need zebras which are something that's more balanced and manfred max knief is a chilean economist um
someone uh many people in our community look up to and came up with this notion of synergistic
satisfies talks about you know trees don't grow indefinitely into the sky you know trees grow
and then they stop growing and they continue to develop and have deeper roots and if you've listened
in the conversation that daniel and i had we talked actually in that episode and also with the
uval harari episode on your individed attention about a human development oriented um uh tech
ecosystem i also want to call out vel van heren is on this chat right now and working on something
called potential how do we have human development oriented technology where the goal and incentive
is not to maximize no thank you sorry um sorry and someone popped in um uh and we had um human
development oriented uh technology and i think that's that's a place where you don't want anything
to be maximizing growth indefinitely um and daniel's talked about this many times and so
Daniel i wanted to tee up with one one thing that just to make sure we're not hitting people with
i think the the thing that people hear when you talk in these terms of this unprecedented nature
of what we're talking about that it hasn't happened before can leave people into feeling like this
isn't possible do you want to talk a little bit about the times in history where something
unprecedented is actually the very precedent that we're talking about the very thing that has
happened um i know you have some wait i mean your your tnl the conversation we've had before
which is like when i do a long history analysis the big questions in science and philosophy
mostly have to do with the emergence of new things that didn't exist before like aviagenesis
the beginning of life our best models are that you had an earth that had no life for a pretty
long time a billion years or so and then life emerged and you could say that in 12 billion
years of universe existing in a billion years of the earth existing it had explored the search
base and life just wasn't a thing right like that that that wasn't a thing and and then it was and
then it actually becomes the most interesting uh characteristic and then similarly you have like
a billion years where the life is only single cellular before it becomes multi cellular and
then the multicellularity explodes and then the same thing until like it's nervous systems and
central nervous systems all the way back to you know a very long period of time before
classicality even emerged from purely quantum dynamics and so when i look at the long arc of
universe evolution is the emergence of fundamentally unprecedented stuff right like stuff that is and
i don't mean biologic evolution i mean the broader case of the increasing ordered complexity of
universe and we see this throughout like literally all of physics cosmology biology the emergence of
ordered solar systems and galaxies out of what was much more just chaotic early mass and structures so
and then when we look at human societies you've got depending upon your model
150 to 300 000 years of homo sapiens never getting bigger than small tribes like
going to all the continents exploring all the spaces doing all the things never getting
bigger than small tribes like it would seem that the search space of possible ways of human
organizing had been played out and there was no precedent at all that we would get these
larger things and then Sumeria and other early civilizations and we start going to instead of
150 people 100 000 and a million people very quickly like why did that not happen for hundreds of
thousands of years before and then you know we can look at each of those steps and again it's like
the world the world was all like very dominated post empire by conquest big empires trying to
get more space and conquer the other ones you like watch those visual maps of the history of
empires and it's really impressive so the the largest empire is always war physically war
world war two comes along we get nukes we can't physically war because everybody will die
that's an unprecedented thing in the history of the world the major empires now can't war
they're like what do we do with that well we'll do globalization and mutual sure destruction and
stuff that we never did before like totally new stuff so i would say it's like it is the precedent
of universe to keep doing unprecedented stuff and this is why all of you know Einstein's comments
about the importance of intuition and imagination and kind of creative thinking being as important as
intellect it's why there were all these early nonsense ideas about that humans could never
go faster than the speed of sound or some thoughts of like couldn't even go faster than the speed
of a running horse and it's amazing how easy it is to have the search space of possibility
because there's a lot of stuff that is unknown but we don't even know that we don't know it's in
the unknown unknown so we can't imagine it as possible so we constrain our imagination to the
space of existing possibilities the people who do that will definitely not be innovators like
so you're just not going to innovate new stuff if you use history as the precedent of what can be
done you need to be well informed by history so that you aren't being dumb and trying to innovate
in spaces where the solutions don't exist it has to account for what is already known has to account
for those types of patterns but also has to fundamentally look into novelty sweet well that
is a hopeful hopeful thought the that the precedent the precedent is in and of itself just
unprecedentedness um let's let's maybe so i should have actually mentioned this for folks so that
folks know so we're actually gonna gonna break out into breakout groups that are on 315 so let's
let's take one or two more questions uh from the crowd okay so what is the grand and by the way
i'm reading this for the folks who are just listening what is the grand narrative in you've
all know a harari's words the story that will cohere people together in this cultural renaissance
what is its central value what should we call it what do communities built around it look like
Daniel i want to tee you up to answer this question because one of my proudest moments
was getting to organize a dinner between you and you've all about a year and a half ago and would
love to hear what here we have to I'll tell you the first thing that arises for me is any
answer to this question will definitely be wrong it'll be wrong and the fact that someone answered
it isn't itself wrong at the level of the how independent of what the what is
um we've got the new narrative we're the ones who see we're the ones who know we've got the
new narrative you guys need to catch up and kind of get with it that's not actually the way the way
forward there is a narrative it's unifying everybody's going to buy into it if you don't buy
into it you're there's something wrong with you or we have to do something about you like we know
that story throughout history we know the great religions doing it we know the kind of um patriotic
identities doing it so I don't think um somebody figuring out the grand narrative and trying to
utilize the tools of propaganda to get everybody on board is actually it that's one of the self
destruct things happening because as soon as you realize the power of that then various people
compete for who has the better narrative and now you have narrative warfare and then you find out
that just like with facebook and hostess or mcdonald's the narratives that succeed more are the ones
that appeal to people's fear and their in-group identity and out-group fear and that kind of
stuff and so now the narrative warfare becomes a race to the bottom rather than a race to the top
and that's the world we're in the the narrative of the left is so obviously the right one and the
narrative of the right is obviously the right one to the people that already have certain kinds of
susceptibilities and it requires straw manning the other side and requires making false equivalencies
on your side and the same with previous communist capitalist or you know liberal soviet or whatever
it is kinds of stories so I'm much more interested in people having trans narrative capacity the
ability to live in someone else's narrative see the world through that eyes feel it and feel the
meaningfulness of it be like yeah I can actually like I would love to see someone who has very
traditional values who could feel into an lgbtq activist and be like wow I can actually feel how
oppressive the world that I feel is right feels to them I can feel how much they can't find themselves
in it I can feel how much their desire for self-expression and freedom and authenticity is like
feels like the most profoundly meaningful thing I there's stuff in there that is real that I want
for them and I can see that I'd like for that that activist to be able to feel into the other
side and be like wow they're holding something that I held as oppressive as sacred they're holding
it as the willingness to sacrifice some things for other things and a maturity and a responsibility
that's willing to do that aligned with a higher sense of what is meaningful and sacred that they're
feel loyalty to they have the sense of loyalty that is different like I want people to be able
to inhabit different values different perspectives and different narratives and so it's not here's
the one narrative to unify them all it's each of the narratives will be partial it'll have it'll
a specific narrative will draw on cultural backgrounds the the new cultural renaissance
won't be the same for Islam and China and India and African nations in the west that would make no
sense it has to draw on their history their values their identity now any cultural enlightenment
to be an enlightenment has to have certain things in common all the dialectics where there are values
that seem to be an opposition but that all matter where if you hold them as an opposition you hold
one as partial you try to make this one win so now the other side is either oppressed or has to
fight back and you stand more all the values have to be held together in synthesis and you have to
realize that there is a continuous tension of managing synthesis so is it about the rights of
the individual or is it about the responsibilities of the individual to the collective if you have if
you think of it as an or you failed at this thing it's not a cultural enlightenment yet there is a
pairing of rights and responsibilities there's a pairing of freedoms and duties there is a
there's a pairing of we are we do are we saying that the society is made by individuals who are
individual agents and actors so we want to maximize individual freedom and agency so the people because
the more agentic the people are the better the society will be or are we saying that actually
individuals are conditioned by the environments they're born into if you're born into Darfur
versus versus born into Finland you're gonna have a very different life statistically it's
straightforwardly clear based on health care of nutrition and education and the things you're
exposed to and the amount of violence you're exposed to so if the individuals are actually
conditioned by the collective don't we want to make prioritize making a collective that itself is
actually conditioned best individuals well of course the truth is that the individuals are
influencing the whole the whole is influencing the individuals that the health of the body is
based on the health of its cells but also unhealth at the level of the body as a whole makes it
harder for individual cells within that system to be healthy there's a recursive relationship
between top down and bottom up dynamics in connected systems so for a cultural enlightenment
to actually be a cultural enlightenment whether it is going to be a uniquely Islamic one or a
uniquely Indian one or uniquely Western one it has to have a virtuous relationship between
the development of the individual their freedom liberty and their agency and the development
of the groups that they're part of and their integrity and coherence where the integrity
and coherence of this of the group is supporting the individual the agency of the individual
supporting the group and a virtuous cycle between them and you can fail on either side right and
it's a chaos or oppression type failure on either side so to be a cultural enlightenment to be a
narrative worth having at all it has to be at the level of the synthesis of the partial values
now could we do that a lot of different ways like are there going to be a lot of different
aesthetics and cultural versions of that and do we want that do we want the richness of that
absolutely so does that mean that we want people who can actually inhabit the different aesthetics
and it's like can I appreciate really beautiful Victorian architecture yeah can I appreciate
really beautiful Moroccan architecture yeah can I appreciate really beautiful Balinese art like
if it's done well and like that's just I can't say anything's more beautiful that's
fucking beautiful right um and so do I want all of art to be one thing no do I want all of culture
to be one thing no do I want that it is all aligned with life thriving and not just for that
little group but for everything because all the groups affect each other so much because of the
level of our tech and our globalization yes so uh we don't want a narrative we want trans narrative
capacity and we want that all the narratives are good for the group and the group's relationship
with the rest of the world not just the rest of the human world but also the rest of the living
and that they operate at the level of dialectic and then we actually want maximum diversity of them
that has richness and people that are oriented to move across them amen Tristan do you want to
speak to that or should we take one last question before we go to break it um let a million flowers
bloom yeah maybe we could just do one last last last question and uh all right so Magnus
Helled in Sweden is asking in a world where people hate change if they do not understand
why and where we're going how do we thread and yarn the change we need at the speed we need
and I think this might have been what the person who previously asked the question that
you know you've all in a story for humanity one one way to see that is kind of my reaction to
what you're sharing Daniel is obviously to say this is the master's story is basically creating
the oppression attractor so to reinforce that that narrative um and yet I think what this next
question is getting at is let's say you have a society that doesn't understand say the timelines
for certain climate uh and related sort of second or third order effects of climate
effects if a society is living inside of um impacting those global effects but not recognizing
it maybe what are the ways that we kind of deal with that or relate to that and that doesn't have
to be one master's story but a certain sense of what we're inhabiting a situation awareness and
this is all built into the things that we've talked about uh already on the podcast but maybe
you want to respond to some of that and then we can hand it over I don't think people hate
change um I don't think anybody hates change I actually think that everyone hopes for a future
that is in some ways better than the one they have which is necessarily change I think that
almost everyone feels good when they feel growth happening I think people get passionate when
they're voting even if they're voting for something they think is aligned with traditions
is because they want to change things or they they want to believe that a certain kind of
change happening I think people have a hard time with change that they think is going to go
badly or that they don't understand or that creates a sense of increased uncertainty or that
threatens something that is really important to them or that they feel they'll be responsible to
in a way that they they can't be um I think there is a dialectic between stability and growth
that matters where we could maximize the rate of growth including through processes that actually
mess up the quality of life now uh we could optimize quality of life now in a way that
doesn't increase the quality of life over time right more kind of hedonistic Dionysian on one side
or excessive uh logos telos with no aliveness on the other side I think for a long time
philosophy has thoughtful people have acknowledged how do we increase the quality of life now and
the growth rate of the quality of life over time is an important thing um I think
I think nobody when they started using Facebook thought that they were going to change the world
or the world was changing or that they were being asked to change their values would change they just
liked tagging photos they liked being tagged in photos it was a very simple feature they liked
seeing their friends it didn't feel like change it felt like it felt like people's faces and then
connected to people now it happened to be that because it met some need that people care about
there was massive adoption and then because of the architectures of it it was actually
changing the world in very significant ways so I think honestly there will be some people who
are really oriented to think about how to design new systems and not everybody most people
like someone who's oriented to be a musician or who's oriented to do nursing or to figure
out mathematical problems might not be thinking about social systems all that much um and that's
great that's fine they will engage with systems that meet that seem like it meets their needs better
so a lot of what happens at scale will happen through some people
building things that actually are effective and then the effectiveness creating a strange
attractor where you go from fast adopters to medium and other adopters and have scaling coefficients
there's a lot more we could say about that but I think it's time
great Tristan do you want to say anything else before we break out
um no I just want to um thank everybody for coming for coming for coming and listening
to this conversation and I know that many people who are in the chat are actually working on many
of these issues the point of this next section is so that many of you can connect with each other
I know people feel when they look at these issues or watch the social dilemma or you know overall
think about them it can feel really overwhelming and I hope that this space you know that David
and Stephanie are creating and hosting as we continue to do these sessions helps bring some
solidarity and some sense of what can happen as we as we navigate so just want to really
thank everyone for coming all the people that are doing this work every day and look forward to
you all getting to connect with each other and thank you so much Daniel for for coming and
elaborating on the conversation we got to have on that podcast and it was one of our most listened
to episodes to date it was really fun to be here I'm glad that Stephanie has joined the team and
I look forward to hear what uh people who are here I've seen some things about that
because we're going to share this thread and find a discord and I look forward to hear what comes
from it all right sweet well I'm going to call uh David in in order to explain how the breakouts
work and uh Daniel if you if you want to stick around if you can't stick around that would be
great and then after the breakouts we'll all we'll all come back together and close so over to you
David thank you so much um thank you for uh Daniel and Tristan for the fantastic conversation I have
went and did disable emojis on the back end but I'm I feel your excitement in spirit even
without them um and thanks to everyone sharing phenomenal resources doing great work in the
chat um now is the part of podcast club where you all will get to connect with one another
and uh there when we pause the session in just a moment you'll see a series of tables the tables
have labels on them that are sort of soft suggestions we want people working on humane tech startups
to be able to meet one another people interested in particular topics to be able to meet one another
but consider them a a gathering point not a um not a criteria to be met uh and you can either
connect in those tables stay in chat um and uh or connect one-on-one in the speed networking
section um you also in the side of your screen will be able to private message anyone if you
run into um I strongly encourage you to share contact information if there's someone you find
yourself gelling with and want to follow up with um and my uh last request is just that you when you
get to your tables um please make sure that everyone at the table has just at least uh 45
seconds to introduce themselves share a little bit of what brings them to this conversation
before you dive into what I'm sure are um a lot of thoughts that are brewing after the discussion
today thank you all um again so much for coming uh we will move into this breakout uh I'll be
moving around the tables to check in um we won't have a formal close so feel uh while the event
runs technically for another 15 minutes feel free to stay in conversation for as long as you'd like
and thank you all once again
