So, before we jump in in our intro, our guest Daniel, I just wanted to do a few housekeeping items.
We're going to spend about 60 minutes up here, and then we're going to release you to the bar.
At 60 minutes, you can either go to the bar or have some Q&A.
We'll be up here for as long as needed to get through the questions.
Just a quick note, for those of you who want to get a drink, the sponsors have all the drink tickets.
So, go talk to the sponsors and get as many drink tickets as you want.
That's our way of supporting the sponsors, making sure that they get people going to talk to them.
We couldn't put on the hit summit without the sponsors, so thank you so much to them.
So, I want to just quickly intro Daniel, and then we'll jump into the conversation.
So, Daniel is the founder of the Consilience Project, which is aimed at improving public sense-making and collective intelligence.
He's a social philosopher focused on making sense of the state of civilisation and how to prevent the many catastrophic risks we currently face with the solutions that are not dystopic.
So, these are concepts we're going to cover in the conversation, but he sees some of the feedback glutes between societal elements and the individual.
So, a lot of his work and analysis is actually thinking about the future of healthcare.
I came across Daniel, I went down a little bit of a rabbit hole.
I was reading about money and the role that money and currency plays in the economies and just the global system.
And came up on these ideas around how modern economies are incentivised to grow forever basically.
And if you tend that to the end of time, eventually you run up against planetary boundaries and cause a bunch of problems.
So, I found when I came across Daniel that he had one of the clearest thinking about many of the issues that are catastrophic risks that face humanity.
And as I'll talk in my talk tomorrow, some of those are related to healthcare.
And so, I wanted to have Daniel here, both to share some of his thoughts generally.
Because I think it's really important as a community that we broaden our knowledge base and continue to look outside of our industry.
But also because I think he has a lot of really interesting ideas about healthcare.
So, Daniel, thank you so much for being here with us today. I appreciate it.
So, what I'd like to do is I'd like to get to a conversation of some of the structural flaws in your assessment of the healthcare system.
And also vision of where we could be long term.
But before we did that, I wanted just to get some of your big picture thoughts on some of the catastrophic risks that are facing humanity.
As well as what you kind of refer to as the metacrisis.
And I'd love just to kind of hear you articulate those ideas.
Yeah, I will mostly try to face you so that I'm not squinting in the sunlight.
People might think that it's kind of a strange thing at a medical conference largely focused on changing the kind of business model of medicine to be talking about climate change and AI risk and escalation pathways to large scale war and other environmental risks.
I was quite happy to talk more just about future of medicine, but you said you wanted to kind of expose people to this thinking.
And obviously, while people here are doctors or various positions in healthcare, they're also citizens and humans on a planet that really is facing these very kind of eminent risks.
So, I'm happy to go over that.
Civilizational collapse, like full blown civilizational collapse, is actually a topic as old as civilization.
We can see pretty easily that the early hominids that we could consider humans other than homo sapiens don't exist anymore.
So full blown extinction of those species happened.
Happened for reasons that most people believe homo sapiens had something to do with.
So that's kind of an important point.
But then also when you study the history of empire, whether we're talking about the Mayan or the Aztec or the Roman Empire or Byzantine or Egyptian,
it's pretty easy to see that none of them still exist.
They all went through civilizational collapse and there's really good academic research.
The canonical work is by Joseph Tainter called the collapse of complex societies that identifies that most of those societies failed
or they ended up collapsing after hundreds or thousands of years of thriving from self induced causes.
It wasn't mostly volcanoes and weather events and it wasn't mostly just that some other empire got more powerful.
Oftentimes even if they fell militarily to another empire, it was an empire or a war smaller than ones they had successfully defeated previously
because they had already passed their peak of organizational capacity and when they were actually in their prime,
they started having more internal infighting and corruption that led to institutional decay, worse governance,
and then they couldn't handle the issues they had been able to previously handle.
Also many of them failed for environmental overshoot reasons, using up trees and topsoil unrenowably and then not being able to support their populations.
So the first thing, we don't think about civilizational collapse very often if it's not the field that people work in,
but every previous human civilization did collapse mostly for self induced causes.
So we actually don't know how to make civilizations that don't collapse, that's kind of an interesting point.
And then the difference between today and the previous ones is this is the first time we have a truly global civilization.
We can't think of a US or a Chinese civilization given that the goods and services that we depend upon take six continent supply chains
and pretty much no country can make the things that they depend upon, so there is truly an interconnected global system
that is going through the same type of decay situations leading to catastrophic risks that the previous ones did on very short term.
Maybe just give an example, like for example putting into your computer what are the requirements for that
and that's no single civilization, no single country can actually assemble a modern computer or almost any other advanced tech that we've got.
You just said it, I think this is streaming over the internet which is obviously satellite and server farm mediated
and if you think about the semiconductor manufacturing and the chip manufacturing and the entire supply chains that make that up,
they do take six continents to make, they do take many many countries to make,
and so the fundamental infrastructure we take for granted without which we wouldn't be able to keep living is truly globalized
and so that creates fragilities where failures anywhere can create cascading issues everywhere.
We saw this recently with a local issue happening in the part of the world called Wuhan, China
and the net results being global impact pretty rapidly, not just in health care but then to try to shut down the spread of the virus.
There was shutdowns of supply chains that stopped the flow of fertilizer and pesticides that created crop failure
that damaged the food supply for hundreds of millions of people.
The ripple effects of that are still cascading and many other effects like that.
So even though civilizational collapse is a kind of ancient topic,
the first time we had a technology where we could induce it quickly at a global scale was World War II and the bomb.
The bomb was obviously the first truly existential capacity where humans could make a handful of dumb moves
and inhabitability writ large for the planet and that was really a turning point
because the entire history of the world up till that point anytime we developed a new technology
there was a race to implement it as fast as possible for the competitive advantage.
Now we had a technology where we had to make an entire world system that ensured we never used it
and the world system from World War II till now that has kind of prevented a kinetic nuclear World War III
for the most part is ending right about now and it has driven hundreds of catastrophic risks that are imminent in very short term.
I can kind of give a brief overview of that.
So to prevent World War III kinetically against between major superpowers
which is a big deal when you look at the whole history of the world the major empires never didn't war
that was always kind of the defining feature.
When you say maybe just kinetic war just a quick summary.
Actual war with weapons as opposed to information wars or narrative wars
or economic wars or supply chain wars or other forms of competition
there's obviously a blurry line between politics and warfare
but to prevent and we've had proxy wars since then
but you couldn't have the major nuclear superpowers go into a full blown kinetic war
and so there were a few major parts of how we achieved that.
One was mutually assured destruction and mutually assured destruction worked
when the only catastrophic weapon was nukes because nukes are extremely hard to make.
Uranium enrichment is difficult, cyclotrons that make uranium can be seen from space
it's pretty easy to monitor who has them so you can prevent lots of countries from getting it
and so you can create this kind of forced equilibrium called mutually assured destruction.
Obviously since mutually assured destruction until now we have not succeeded at nuclear disarmament
we have been in an arms race towards faster and faster nukes, hypersonic nukes
because whoever had the fastest ones could win first strike.
More countries have got them and more other countries are connected to countries that have got them
that could influence them with cyber weapons and other things like that.
And then you have the arms race between America trying to build systems to intercept the nukes
and so then the Russians build Poseidon to go under sea and nuke
so they can nuke things really quickly and you just have that continual arms race
to the point where now we're more nukes than we were when we started with nuclear non-proliferation.
Right and of course when you have very good ability for cyber and information attacks
that can make it look like the other guy launched and you're in mutually assured destruction
that's a very sketchy scenario, we're in that scenario.
But it's also important to understand that there are now many, many nuclear level catastrophe weapons
and that unlike nukes are not hard to build.
This is something to understand about the biotech as a great example
we obviously just experience the effect of a pandemic of a not terribly lethal virus.
If you look at the rate of development of biotechnology both synthetic biology plus things like
crisper genetic engineering and how the rate of that advancement is making the genetic engineering capacities
to do those things much, much cheaper and more decentralized
we're currently three to five years away from tabletop crisper being pretty inexpensive and ubiquitous
which means the ability to engineer pandemic bioweapons is available to a single person in their basement
in a way that's pretty much unmonitourable.
And unlike nukes that are very again hard to make and control
here all I need is the information of the sequence, the DNA or RNA sequence
so if we even have open publishing in science
somebody figures something out at a university with an ethical review board
it gets published, anyone else who doesn't have the ethical review board
who now has access to that information with non-high tech,
I mean with non-hard to create technologies
has the ability to produce catastrophic tech
and obviously they can use that intentionally as weapons
they can also use it unintentionally to try to do good stuff but have accidents
protecting biosecurity is actually amazingly hard
and trying to use a biotechnology for a positive purpose
but not being able to factor all the second order effects
we started adding lead to gasoline to stop engine knocking
and the effects of all the lead that went into the environment
took about a billion IQ points off the planet cumulatively
before we dealt with the regulation and increased violence about 4x across the population
and the inventor, the video you shared the other day
the inventor of lead gasoline killed more people than any other human
in civilisation or something like that
something like that
and so this is an example of you build something for one
hopefully positive purpose but it has lots of other purposes
many of which end up being negative, we call this externalities
the more powerful the tech gets the faster the externalities are
and obviously 4 out of 5 doctors chose camel cigarettes
and DDT was better living through chemistry for everybody
and it wasn't until we saw how many people that killed
and how many pollinators that killed that we regulated it
we regulate way after the fact
with things like self replicating biotechnologies and AIs
we don't get to do that
if we wait till after the fact it'll be too late
so coming back, mutually assured destruction works
when you have one catastrophe weapon, two superpowers that have it
it's really hard to make and easy to monitor
now we have dozens of catastrophe weapons
many dozens of actors including non-state actors who can have it
exponentially more actors that are unmonitourable in the very near future
and so often times we talk about how good decentralisation
and democratisation of everything is
and the way that exponential tech allows what the largest corporations can do
to be available to anyone
but the democratisation of catastrophic capabilities
actually not a totally good story
and so if you want to solve the catastrophe weapons for everyone model
how do you do it if you can do it with
build the things with non-exotic materials in the basement
drones are another example
people can take commercial drones
and get advanced AI swarming algorithms for free on GitHub
they were developed by the very top thinkers in the world
at places like MIT but then they're free on GitHub
download them, put very simple kinds of explosives
and take out critical infrastructure targets
that can be radically catastrophic
what would be one example of a simple infrastructure target
that's rapidly catastrophic
better not to talk about
okay, good point
so
not that hard to figure out if you want to think about it for a while
okay, now I understand, good point
but I will say if you want to think about another category of catastrophic tech
we apply fairly simple AI models to supply chain optimisation
supply chain optimisation seems like a good thing for the environment
because it decreases inefficiencies
but if I can use AI to optimise flows through a supply chain
can I reverse it and find what the most critical
what the few, the least number of targets that if I were to take out
would damage the whole supply chain the most
sure
pretty much anything I can optimise with AI I can reverse
it's the same tech
and so it's kind of important to get that we'll look at
AI for protein folding in medicine to solve some issues
and we'll look at CRISPR and immuno-oncology to try to solve cancer
and remove oncogenes
once you develop that tech for that purpose
you can use it for any other purpose
and you can do a lot of things with CRISPR other than immuno-oncology
and a lot of things with AI in protein folding
other than the positive applications
one of the things I found that was a little bit shocking to me
when we were chatting a couple of days ago
was this idea that we're
as close as three or four years from reaching the
event horizon where there's a point and no return
of AI reaching escape velocity
that was sort of a little bit of a
in my head I've always thought maybe it's a few decades out
but how do you kind of think about that
can you maybe provide some examples
as to how you come to that conclusion
yeah near term AI let me close the loop
on this other thing I was saying about the
World War 2 solution why it's over I'll try to be faster
so mutually assured destruction doesn't work
when you have many catastrophe weapons
and many non-monitourable actors
the only solution that really anyone
is trying to propose to that is
well we have if people can develop catastrophe weapons
in their basement we have to know what people are doing
in their basement that requires ubiquitous surveillance
and there are some major nation-states working on that
that obviously starts to look
that's a lot of power to be concentrated
that's very hard to have checks and balances
on that kind of power so if you don't want
decentralized catastrophic power
then you create some centralized checking force
that becomes an unchecked power so either have catastrophes
on one hand or dystopias on the other
this is roughly what we call the metacrisis
the metacrisis is that we don't have
climate change risk or AI risk
or biotech risk or escalation to war
collapse of supply chains we have all of them
and that the cumulative effects
of industrial tech over a few hundred years
unrenewably removing resources
from the plan on one side including on the other
has hit planetary boundaries across many axes
and the evolution of exponential tech has created
many many catastrophic possibilities
it's easy to benefit one of them
making another one worse so we can try
to sequester more CO2 to address climate change
by planting more CO2 sequestering crops
in certain areas but if we do that
with nitrogen fertilizers that increase
the rate of nitrogen effluent to cause
dead zones in the oceans we can catalyze
oceans dying even faster
most of the solutions or we say
to solve climate change let's try to
create real taxes on carbon
to incentivize other energy sources
if every country doesn't agree to it
whichever countries do are
so economically disadvantaged in the short term
relative to the ones that don't they kind of
lose geopolitically and as a result you get
things like global autocracy dominating
so we have situations where almost
each of the catastrophic issues
the simple solutions are totally wrong
they make other catastrophes worse
and the way of approaching all of the catastrophes
usually looks like dystopias
so in our work we're looking
for a third attractor the future of civilization
that is neither catastrophic risk
or dystopias which means there must be
civilization systems that can check
the power of exponential
tech and a global civilization
but have that system have checks and balances
on itself and that's a really
non-obvious tricky thing to do
if we just identify briefly
the other couple aspects of the World War 2 system
that drove this thing was the
global monetary system that created
the reserve
currency and all those types of things
the Bretton Woods system
the idea was let's ensure
exponential growth of GDP
because the way you prevent wars
by making it to where everybody can have more stuff
without taking each other's stuff
how does everybody have more stuff without taking
each other's stuff
well you have to take it from somewhere
it looks like unrenowably taking it from the environment
and if you try to run an exponential
financial system attached to a
linear materials economy that destroys
the environment on both sides on a finite planet
you hit planetary boundaries pretty quickly
and so just quickly touch on linear materials economy
linear materials economy means
that we get stuff from somewhere
that looks like
taking fish out of the ocean faster
than they can replicate
taking trees down faster than they can replicate
taking food out of the soil faster
than the top soil can replicate
taking mining materials out faster
than they can be remade
so you get depletion on one side
and turning it into pollution and trash on the other
faster than it can be processed
so you get environmental issues on both sides
and so obviously with just something like energy
we get climate change and mercury
and the atmosphere and a bunch of things
from the burning of hydrocarbon on one side
and mountaintop removal, mining and oil spills
and wars over oil and whatever on the other side
it's worth noting that all those issues
associated with say
hydrocarbon energy and particularly
oil based transportation
for internal combustion
that are truly global
existential risks
are the unintended consequence
of creating automobiles
which was trying to solve a very real problem
of transportation and the difficulty of horses
and horse husbandry for drawing carriages
and how nice it would be to have a carriage
that didn't require horses
and so we solved that problem
and then the side effects of the way we solved it
is global climate change,
wars over oil, oil spills
and an entire geopolitical unstable situation
so this is one of the underlying issues
is that we solve problems in very narrow ways
that externalize problems that end up being worse
we do this in medicine
and we do this in our healthcare systems
to try to make a medical system
where whatever kind of piece of
regulatory apparatus or incentive is put in place
often times causes much worse problems
so one of the underlying things that we need to address
is how we define the problems themselves
has to be much more interconnected
so that we don't externalize problems somewhere else
in the process
so obviously we have to also change
our global monetary system
to not require exponential growth on a linear supply chain
and that's a huge deal
this is not an obvious thing
but we don't have all that long
so basically the solutions
to how to prevent nuclear war
ended up driving the environmental risks
and the growth of the technologies
that now portend lots of catastrophic risks
so we have each year there are more total
catastrophic risks with higher probability
you were asking about AI
the obviously post nuclear
we got digital revolution
and computers were kind of the beginning
of exponential tech
meaning technology that makes better versions of itself
so you get an exponential curve
and
the very centre of it
of computation is AI
and so technologies that are on
kind of exponential growth curves
are the things that can create the biggest effects
the quickest we all see that like
almost global proliferation
of smartphones in just over a decade
compared to a couple millennia
for global proliferation of a cloud
and how radically
that changes global behaviour and culture and everything
actually I love your analogy
you give with the invention of the plough
and how that kind of changed society
just profoundly over many generations
could you just kind of cover that story
because I think it's a really interesting kind of analogue
or do we not have time for that
I can do a quick version
I think many people
kind of have the sense that
either technology is just kind of net good
because technology is trying to solve a problem
and if it didn't solve some problem
that enriched human life
it wouldn't proliferate
markets wouldn't advance it
so the fact that it's solving problems
it betters human life in some way means technology is net good
that's kind of certainly the idea
that the industrial revolution ran on
then when people start to see
well the same technology that can give us to the moon
is pretty similar to the technology
that makes nuclear weapons and the same
computational system that can
or AI system that can do protein folding
for cancer stuff can also do it for bioweapons
then it's like okay well technology is not good or bad
it's just this inert thing
and it's the value systems with which we use it
that are good or bad
neither of those are
right
technology affects human value systems
inexorably in ways that we have to understand
for the design of it
specifically technology only
catches on if it confers advantage
in some way if using it creates some
advantage which ends up meaning power
which means that if some group
uses a technology that confers power
and another group doesn't that other group will probably
lose when it comes to an economic war
a political war a kinetic war
and so the first thing is that any technology
that confers a lot of advantage becomes
obligate you use it or you are not part
of defining the future the next thing
is that
to get the advantage of it you have to use
it which is a different set of behaviors and it also
obsolete some previous set of behaviors so
technology changes patterns
of human behavior and doing
that means that it also changes the basis
of what we are experiencing like the sensory
experience of the world and as a result
human value systems and cultures
and there is
such an important topic because
when we are building the tech that is in turn
building our minds and we are not thinking
about it you get things like facebook
having this effect of kind of radically
destroying democracies and creating polarization
or whatever as an unintended
effect of like a messaging app
so the plough is a very great example
when the plough was
first implemented
a number of things that historians
of technology have looked at is that
whenever the plough was implemented in an area
they didn't have the plough before they were hunter-gatherers
or they did small scale horticulture
using a kind of human used digging stick
to go from a digging stick to an ox drawn
or a horse drawn plough
required obviously yoking
an ox or a horse and then beating it all day long
that was something that hunter-gatherers never did
so pretty much every hunter-gatherer
society was animistic
they talked about the spirit of the buffalo
the spirit of the water the spirit of all those things
so they had some idea of the cycle of life
and man's relationship to it
as soon as the plough conferred so much
advantage because it did mean you could create
a lot more caloric surplus
which means that your tribe could make it through
famines and grow
which meant whoever used it was going to win over
when it came to tribal warfare and making it through famines
you kind of had to rationalise
beating an ox all day long
so animism had to go away there's no spirit of the ox
they're just done animals that are here
man's dominion over so the change
of human value systems followed
literally a change in tooling
and then things like the plough created massive surplus
were there had not been massive surplus before
because it allowed us to get much more grain product
a massive surplus meant that some people
could have a lot more ownership than others
and started to get radical wealth inequality
you also started to get much faster
growth of populations
you also got pretty much the end
of female gods in most cultures
because previously
in hunter-gatherer cultures you had male
and female gods associated with the fact
that men and women were both supplying food
stuff or the stuff of life and involved
in that mythos obviously we moved from hunter-gatherer
mythos to agrarian mythos but now men
were both doing the hunting and the ploughing
because the upper body strength needed
and so the thing that is called the patriarchy
followed a tool there's a thousand
more examples of now you have inheritance
because of the amount of surplus
and because of inheritance institutions on marriage
change so literally like
economics, religion
core spiritual ideas, ideals
about nature, male, female
all changed with a tool
and so it's a
it's a very important topic
as we see the
exponential rate of technology development
and that it doesn't just produce physical externalities
like leaded gasoline
having an effect on human brains that made us
both dumber and more violent at scale
but it also has these psychosocial effects
OK and so
one of the things
that we think a lot about
at Hint is the sort of
this idea that within
the health care system there's just perverse incentives
kind of everywhere right
and I think one of the things
I've found quite interesting is sort of listening
to you talk about kind of the alignment and this alignment problem
and maybe just
before we sort of parlay into health care
can you just share
some of your thinking in terms of
how you think about the alignment problem
and perhaps how it may relate
to kind of health care
Yeah so the term
perverse incentive in economics
means anytime that some
agent whether it's a country
a company or a person
somebody in a company has some incentive
to do something
that is going to harm some other agent of the commons
so there is a alignment gap
between the well-being of everybody
and the incentives of everybody
it's very hard
to prevent people from doing things that you're
simultaneously incentivising them to do
which also means disincentivising them not to do
and so
we try to create a system of law
that prevents people from doing things where they have
economic incentive but it causes enough harm
we think is problematic but then of course
if there is
a
aspect of the market
that law is preventing from doing a thing
that would be profitable
one of the most significant things
the market can do to advantage itself
is to try to change regulation
and so thus lobbying gets entered
and campaign finance support
and the whole host of incentives
that come in and you get regulatory capture
perverse incentive is a very deep topic
because you can say
it's possible to have a for-profit military
industrial complex
as one of the most profitable
sectors of the global economy
and have enduring peace
if there were solutions for enduring peace
that were able to de-necessitise most of that
that would actually collapse the global economy
like is there some problem in the incentive landscape
obviously there is
and we see this with things like the perverse incentive
in for-profit prisons
healthcare as a heap of examples like this
and the reasons why
global GDP is not a good measure
of the health of the world
because GDP
goes up during war in military spending
GDP goes up with more sick people
and more healthcare spending
it goes up with addiction and purchasing associated with addiction
so
the reason that I responded when you reached out
and the reason that I'm here is because
you said that you were
looking at how to address
perverse incentive in healthcare
and that you felt like was kind of the
central and highest leverage area
and that underneath all of the
problems in the metacrisis
there's perverse incentive driving
AI to go much faster and less safely
than it should
driving biotechnologies to go faster and less safely
and it's not just economic perverse incentive
it can be things like a military perverse incentive
where it's like
it's pretty understandable
hey they're going to develop this weapon so we have to develop it first
otherwise
and so because we can't be sure
that they aren't going to develop it
we all have to race to develop it as fast as possible
even though most likely we all die from it
so that's a
perverse incentive where what is good for me
in the short term and what is good for everybody
in the long term are exactly opposite
but if I try to do the thing that's good for everybody
in the long term I'll probably lose in the short term
so I guess I mean there's a lot of
um
you know
when I sort of listen to you I
get pretty nervous about our future
so how do you
are you all
um
so are you
you know is there
you know how do we get through this
what is it that you're working on
and how do we sort of start to think through the solutions
and maybe paint a picture for that
I didn't answer your
short term AI question
oh yeah let's jump into the short term AI question
I'm fascinated like
three years are we in trouble if we don't
make some big changes
as we say AI and actually maybe also
address how
some sectors that are
say developing AI for good purpose
actually maybe
partially responsible for the acceleration
of the AI that could be used for the wrong reason
so
we could easily
read the books about how society
is getting better and better whether we're talking about
Pinker or Diamandis or Hans
Rossling's work and
heaps of statistics on
things that are getting better and it's true
like nobody wants to go back to a pre-novacane world
or a pre-antibiotic
world or a
but they cherry pick the
stats to focus on the things that are getting better
and not the things that are either getting worse
or moving closer to catastrophic worse
and other people focus on those
things that are both true simultaneously
and this is kind of a complicated thing to hold
did antibiotics
solve a whole lot of
easy mortality
totally
that's awesome
did inappropriate
and overuse of antibiotics as opposed to a more
nuanced approach to the human relationship
of the global kind of micro organism
community create
really nasty
antibiotic resistant bacteria
increasingly accelerating
and
effects on the human microbiome that have
effects on genetic transcription
and all kinds of health issues
that's also true
you might say you're being a perfectionist
every tech is going to have some costs
we can actually do a better job
of identifying
all of the interconnected things rather than
this kind of single element
reductionism and being able to develop tech
that has more positive externalities
negative externalities
if we talk about AI
of course AI can be advanced
for a very positive purpose and medicine
is one of the very best purposes and also
both AI and biotech are advancing
largely for purposes in medicine
image recognition on medical files
and then big data
on medical information for AI
pattern recognition to be able to start
to identify early
disease indicators
that's awesome everybody here wants that
but
it's
those types of applications
where the both
kind of public support and regulatory
support and money going into the
development in the for profit and academic
world
create the advancement of the technology
that can then just so easily
be repurposed for any kind of purpose
and
so if you want to ask like
what are some of the near term risks
if we see the extreme polarization
that happened around the fundamental beliefs
about COVID
like did it come from a lab
did it not come from a lab is it even a virus
or is it an exosome is it real or is it
not real should we
wear masks or not vaccines
hydroxychloroquine whatever it was like
the most foundational just
assessment of base reality
had almost completely polarized
perceptions on almost everything
and we can look at the media landscape
and talk about this and there were obviously
forces driving polarization
before the internet but
social media in particular
radically accelerated these as a result
of a particular type of AI application
so
if you haven't watched the social dilemma as a
documentary that covers this it's a really good one
to watch the very brief
gist is I can't see
all of the news that's out there it's billions
of new pages uploaded to Google every day
and so I go to Facebook or whatever
my kind of social media feed is
I'm going to scroll it's
curating from all of the information
on the internet a subset of things to put
in front of me and the things that I see end up
affecting the because I'm not perceiving
the world directly I'm perceiving media meaning an
intermediated world or an intermediated
perception of the world and
the AI gathers data
about me gathers data about my mouse hovering
patterns my click patterns my friend network
and all those types of things and it empirically
optimizes for making me spend the most
time on site and engage with the content the most
it happens to be the things
that scare me piss me off and appeal to my bias
make me spend more time on site most of the
time than the things that challenge my bias
and make me do complex hard thinking
so it ends up optimizing for click
baby titles and over certainty
and over sanctimony and villainization
of the other guy but it does it
for everybody's existing bias set
so whatever your current views are
you're likely to feel more righteous more
certain more sanctimony is more villainizing about
those things simultaneously and this is a true
for climate change and true
for social justice and racial
inequality and every possible thing you can get
so this is a
the opposite of a fourth estate which
was supposed to be a prerequisite of democracy
that we all had the same information to do
collective decision making this is actually making
sure that everyone has maximally
polarized information a polarized
electorate
elects a polarized representative class
that creates gridlock that can't do shit and
when that is in geopolitical competition
with China that doesn't have that issue
doesn't have term limits etc
we'll just lose it long term planning
and so
that's already an example of a simple
AI a content
curation AI
that is destroying democracy the social
contract the epistemic commons at scale
and just quickly epistemic commons
our ability to collectively make sense
of the world we live in
in the fourth estate basically the news
news the idea
of the US
and most modern democracies is that
the democratic system depended on
two prerequisite institutions which was
public education and a independent
news or fourth estate
because you have to have an educated and informed
citizenry to do collective choice making
if we didn't all have collective sense
making about what's actually going on
collective choice making has no possibility
and the quality
of public education
and of
media relative to the actual
problems we face and the complexity means
we obviously don't have anything like democracy
we have a simulation of one at best
and a rapidly failing version of that
so that's already AI causing catastrophic risk
now if you want to talk about the scary scenarios
that seem scary
it's things that look like scary things
like autonomous weapons
and if you want to just get a brief
sense of what that looks like
go to YouTube watch a short video called Slaughterbox
and you'll get a brief intro to
what swarming autonomous weapons
in the very near term look like
this is being radically advanced
in a arms race
but
faster than that
the
Facebook algorithm
and the Google algorithm whatever are
basically curating content that humans made
AI is now also creating content
that people can't tell wasn't made by people
meaning it passes the Turing test
GPT-3
technology that's already publicly available
that I don't need to program
I just speak into it with natural language
I say GPT-3
make me a
argument about
why all COVID vaccines are dangerous
using
real statistical analysis
do
real data sets and real statistical analysis
that shows that
and it will instantly
present that
and it can do it at a speed that biostatisticians
can't begin to actually address debunking
and I can also say
given your personalised data
make one that will maximally compel you to X
and so the speed at which
that technology
is becoming ubiquitous
is like a three year time horizon
so if we can make maximally
compelling content of any kind
that
floods the internet where nobody
has the ability to tell what is real
or not on anything
then in the inability
to make sense of the world
despotic leadership and things like that take over
so that's roughly where I said
a irreversibility on a short
number of years timeline
so it's not in three years the two minute it shows up
it's just that if we don't figure out
how to put
in some controls or start to figure out
ways to almost like
mediate the tech
into a situation where it's almost like irreversible
and so maybe a question
for you on that is
how do you sort of tend to think about
on the solution side
of this equation
what's driving your thinking
what are the tactical
things that we can start to think about now
that actually move us
towards not being all in a lot
of trouble in say three to ten years
so if we
think about
AI and biotech as two of the categories
of exponential tech that are making the fastest
rate of change synthetic
bio is actually advancing much faster
than Moore's law currently
that means
that exponential growth of technology means
exponentially more impact
exponentially faster
with exponentially less
money and exponentially smaller number of people involved
and exponentially
dumber people because the social media
is making us all basically
go to one extreme
the complexity of the world
is hard to understand already
and being able to appeal to the lower angels
of our nature of tribalism and etc
as opposed to really try to handle complexity
and nuance is an easy thing to do
so underneath
the reason that we're letting
AI move as fast as it is
and we're letting biotech move as fast as it is
and that's why the risk landscape
is a type
of perverse incentive
we call the multi polar trap
meaning you have many different
players many different agents
that are all incented
to go as fast as possible to the thing
that is likely to create the worst case scenario
for everyone because if they don't
and someone else does first they lose in the near term
this is the case with the tragedy of the commons
meaning if I don't
go fish all the fish to try to
the fisheries restore but somebody else is going to
if I can't ensure they're not going to
then me not doing it doesn't leave the fish
the fish are still going to go
it just means that my rival is going to be able to grow
his population and economy faster
so not only will I not leave them
I have to race to get him faster than he does
and so this is the
a multi polar trap in the environment
and that's happening with climate change
and dead zones and oceans and all those things
it's the arms race
if I can't ensure that the other guy
doesn't have to work to develop the weapon
and the counter weapon faster
even though that means increased likelihood
of everybody dying from those weapons
and the worst case is actually the market case
whoever gets first mover advantage
will have so much advantage
and specifically in the world of network dynamics
where you'll have one Facebook
bigger than all other social media
one Google bigger than all other search
one Amazon bigger than all other
online stores
that's mediated by the fact that
those networks get
have something called Metcalflaw
they get much more value as they get more users
so once they get a certain percentage of users
they get a kind of takeaway dynamic
where they'll have a natural monopoly
so in a world with natural monopolies
because of networks and in a world with first mover advantage
nobody has the incentive
to really think about the risk landscape
go slowly and carefully
everyone has the
advantage to do the famous silicon valley
adage move fast and break things
but you don't want to break things
when it's breaking the whole world
basically
so far break things has always been able
to be socialize the losses
the government will deal with it
the environment whatever while privatizing the gains
and that's been the orientation
and if anyone wants to go slow
to think about how to do this thing
in a non-terrible way
someone else still moves forward fastest
and the terrible thing still happens
then even the people who want to be ethical
say fuck I've got to go as fast as I can to do the thing
so at least I then have the ability
to do the right thing later
so you end up having everybody racing on AI
even who know the issues
I'm a good guy I'm going to control the AI
so I can stop all the bad guys getting AI
and then ultimately you end up with
AI taking over everything
and it's a really hard problem
if you're like okay
we can kind of see if people are making nukes
because you can see uranium enrichment
from space but you really can't see that
even if we make an international agreement
they agree that they're not
have to assume they are and they're lying to us
so we're going to do it as well
and we're going to lie to them
and we're going to spy on them
and so either we don't make the international agreement at all
because everyone knows it's unenforceable
or we all make the international agreement
and I'll break it
and so that multi-polar trap
that's a legitimately hard thing
and this is why you start to feel the intractability
of it what can I do
so one of the things
we obviously have to do
that is deeper than climate change
or AI or bio risk or anything
is solve that kind of underlying issue
solve multi-polar traps
more categorically
so
our research organization
and a handful of other organizations are launching a project
the orienting questions project
where we're basically saying
more than the sustainable development goals of the UN
the
things that humanity should orient around
as it's kind of primary planning
and problem solving
are these underlying dynamics
that give rise to all the problems and catastrophic risks
and basically the questions
of how to progressively find better solutions
and the first one we're starting with
is progressively
better solutions to multi-polar traps
and I can give you examples of partial answers
there's a company
that we're in conversation with
that has the largest private satellite network in the world
for imaging
they have a very high resolution
real-time imaging of the entire surface of the world every day
it's getting better and better
and moving towards basically like
real-time video of the surface of the world
and who's that company?
Planet Labs
and they're very interested in the application
for these types of things
now if we see
areas of
a bunch of plastic in the ocean
or dead zones in the ocean
high quality imaging
can we trace back where it came from
to actually be able to identify attribution
and as a result the transparency
even though
this country couldn't go monitor the other country
because it wouldn't get the permission
the satellites actually don't need permission
they're in international space and they have the
allowance to do that
means anything that is visible on the surface of the earth can be monitored
and now we have the ability to say
because of transparency
we can actually do a better job of creating
and keeping international agreement
can we see the movement of
military activities
and logging and all kinds of things that way
and fishing boats, yeah
so forced transparency is an example
and you'd say well but what about the deep underground military bases?
Why don't we transition to
an example of a multi-polar trap in healthcare
and maybe talk about ways to solve that
so I think one example
of a multi-polar trap is
you've got the insurance carriers on one side
and their incentive is to
effectively to and continue to increase
the total cost of care
because their profits are
effectively a fixed percentage
at scale on top of that
so their incentive
is to kind of deny claims while
we're possible while pushing
the cost of healthcare up
on the provider side
in a fee-for-service model the incentive is to drive
as much role in as possible
so that you can submit as many claims
and drive as much revenue as possible
and you end up in this sort of arms race
where both sides
in order to win both sides
need to continue sort of on that
game until you end up in a situation
not too dissimilar to what we're
in today so would that be an example
in healthcare or did I get the idea of a multi-polar trap wrong?
That's not exactly a multi-polar trap
the multi-polar trap would be more like
say
competing providers
or competing pharmaceuticals
where if any of them figure out
how to lessen the regulation of clinical trials
then all of them are oriented
to do a similar thing
so it's more specific within a domain
but what you're talking about is the same type of thing
it's a
where you have individual perverse incentives
in relationship with each other creating attractors
that are not the global optimum for anybody
and obviously
you're picking this one because
you built a business and a conference
to address this one in particular
which I think is really cool
Do you want to speak about that?
Well actually one of the things I'd like to do is
I'd love to
maybe jump into
how you
tend to think about what healthcare
could be long term
so if we could fast forward
to very long term
because I get it
you are quite good at thinking about
where we end up very long term
I think if we can get to that then
and what the world may look like
if you sort of tend out a long way
then we can maybe start talking a little bit
about what are
things in the short term that could maybe impact
that long term view
So obviously thinking about
all of the sectors, future of economics
future of governance, future of defence
future of judicial system
future of medicine and healthcare and education
are part of this type of analysis
have been interested in
I don't know
if you can send that
interview ZDogg and I did
because we discussed that quite a bit
so I won't talk about those parts
I'll talk about some other parts that I think are
The ZDogg interview I thought was really awesome
so I recommend going and listening to it
if you found this interesting
I'll actually give an example
of the very positive applications
of both
AI and biotechnology
to the future of medicine
what that portends for the role of the doctor
and the GP in primary care in particular
and how I think the direct payer model
kind of fits in very nicely
I was thinking about this last night
on the way here after you and I talked about the direct payer model
One of the trends that we can see
over the next few years and few decades
is increasing technological
automation of
most jobs
pretty much
anything that is proceduralisable
being able to make a robot
or an AI that can do better
or at least competently enough to displace much of the job
like that thing is happening
will happen
and we can see that in medicine too
we can already see that
machines like the Da Vinci
are going to replace
surgeons for a lot of very technical things
and obviously
the ability to take
like
the evolution of diagnostics
to be able to run a lot more
biomarkers a lot more cheaply
so that you get really kind of big data on an individual
mass spec is getting cheaper
and home devices
like continuous glucose monitoring
are getting better and better to become like telemedicine type things
so you take the intersection of those
and you get something like
really high quality at home metabolomics
where you can take urine or saliva
run an entire metabolome
and be able to upload that to a cloud
people can't make sense of that
like the total amount of data
is unprocessable
can big data both to
monitor the individual over time
but also to monitor all people to notice
all these people who got this kind of cancer had these
as the earliest markers way before
any cancer indicator we currently had
is a lot of
diagnostics going to become
the intersection of much better
diagnostic technologies
plus big data and
processing plus AI totally
and
obviously even things like image recognition
on much larger databases than a doctor
can hold in their mind
so then the role of the doctor in the future
will become largely
what are the things the AI does not do well
that are still the things that the doctor does well
and the interface between the patient
and the technologies
and so
there will still be a role for a surgeon
in relationship with the surgical
AIs
but it's a different role
and the same thing with diagnostics
so I see that a huge part
of what the doctor becomes
is related to
deep human connection
which is the thing the AI is not going to do as well
and
being able to really
take enough time with the patient
and ask enough questions to be able to find out
what is being started after
a micro head injury
that might have created a subclinical TBI
that doesn't show up on a
MRI but maybe would show up on a spec scan
or if it happened after
some mold in their house that again
they didn't notice as an acute thing
but all the things that can be
delayed causation, chronic causes of things
emotional dynamics, whatever
for the doctor to ask enough questions
to really get a sense of those things
you had on your website the example of this doctor
giving the TED talk
Dr Robb
where he
had the time
to say hey if she broke her foot and doing this thing
does she have a bone density issue
as simple a thing as that is to think about
you need a little bit of time
to be able to think about your patients
to put those things together so I think
the increasing
high quality connection
relationship with the patient
and
the specialization things actually will become
increasingly
automated
I think that is a trend that will probably happen
and probably should happen and so then
I really like the idea of a direct payer
starting with primary care model
that is increasing the amount of time
the doctors and the patients are able
to spin together and trying to emphasize
the patient working with
a primary care provider that can pay attention
to them, track them, care about them more
I think that's very much aligned with
some of the key technological advances
in the future of medicine
so basically
I think
by the way I didn't tell him to say that
but basically restoring
the patient-physician relationship
restoring the integrity
of that primary care
almost like the spirit of primary care
restoring that
and reconnecting the patient to the doctor
as AI comes online
as kind of exponential tech
kicks in further and further within healthcare
the sort of the last
thing
that will be automated, maybe never
it's hard to tell
if we get general intelligence then
anything's impossible but up until
that point the last thing that will
be replaced is that primary care
relationship and actually if anything
in order to ensure that that is
a successful sort of
non-dystopic future
we need to basically restore the integrity
of that primary care relationship now
such that we can
move forward into the future and then leverage
these technologies in such a way that makes
sense for everyone involved so
I agree
There's something that I found really inspiring
several years ago
I was invited to this conference called
Heart-Based Medicine
and
it was mostly traditional medical doctors
there not like
naturopaths and herbalists or whatever
but they were contemplating what the future of medicine
should be that created
the doctor-patient
healing relationship at the centre of medicine
if they're going to rethink it
and there were some breakout groups where everyone
got to think about what is the future of medicine
that they would most like to see happen
and the thing that the most people said
and I was really inspired by this is that
they would like to see hospitals that are more like temples
or sacred spaces of some kind
with a particular denomination
but the idea that this is a space
where people are going to die
and this is a space where people are going to be
born and this is a space where people are going to be
near death and watch their family members
and those experiences and have
really hard conversations around
you have to make these deep life shifts that
involve addiction in your early trauma or you'll die
like there's no space
that addresses
the sacred things of life more potently
and that everything that
decreases the potency of that sacred connection
should be removed
and I
I also hold that
being as
central as the technological
and you know better
institutional advances
in medicine.
So just to repeat that
everything that decreases
the sacred connection between
the healer or the physician
should be removed.
I actually think that would be good
maybe a good opportunity to
would you be open if we take some Q&A
from the audience?
So we've got some mic runners
for those of you who want to go get a drink
feel free to do so.
We're going to stay up here and continue the conversation
and we'd love to have any audience questions
and if you don't have any I've got a bunch more
so you know don't
worry about that.
Thank you so much this was
incredibly interesting.
I found your sort of vision
for where healthcare goes next
to be quite fascinating
just the only big question
and I'm sure you think about this question all the time
is how do you
marry this world
where we have all this multimodal data
on our patients and we're able to use AI
with
people in research constantly talk
about which is the curse of dimensionality
and what is the role of the
physician in helping fight
that problem?
Say the last part again how do you balance
the big battle? Curse of dimensionality
so all this multimodal data
and does the physician
have a role
in helping because that's at least
dogma in the AI world that there is
an oracle that can help with this
and there are a lot of thoughts on that.
So there's a
problem called the infosingularity
that we're already in a situation
where there is more information
relevant to inform most decisions
than any human can competently process
and so if you look at
how many peer reviewed published
journal articles in any topic there are
no expert can actually keep up with all of them
which means no one is actually an expert
in anything
and to try to be an expert in anything
it has to be increasingly narrow domains
expert meaning knows
the extent of human knowledge in that
space and
so insofar as there are
consequential decisions to make
and there is a lot of relevant info
we don't necessarily want people making it
who don't have the info so the idea there is
okay we need AIs to make the decision
of that info so there's
there are a lot of people who are proposing
cybernated systems of governance
AI governance of various kinds
to try to make benevolent
super intelligent AIs that
run shit
I think the dystopic scenarios
there are almost certain
and that we don't need
the AI to make
the decision to be a decision informing system
that is able to take all that
multidimensional data and process it
into something that the human can keep up with
and so it is informing
human intelligence and groups of human intelligence
human collective intelligence
this is true for how we make democracy work
as well as how we make any specialty profession work
is that
I don't want to
search on google or google
scholar and get websites
I want to see
bespoke presentation
of the summary of all of the world's
information relevant to the particular situation
I'm looking at this is where
that same type of AI technology
like GPT-3 that can make compelling
deep fakes can also do this
like literally today can also
can already start to do this if we're programming it
where rather than
have to look through
hundreds of research articles
many of which we'll find out later
or wrong the ability to be able
to look at those together identify
where there is
information that looks like it is conflicting
versus self-reinforcing be able to give confidence margins
and then be able to
um
give the actual decision informing
meaning which is usually a second or third derivative
of the total amount of data
so it's
it's true that humans cannot
keep up with all the information it's not true
that we need to know all the information we need
to know the patterns of the information that are
important to informing decisions
and so we can have a symbiotic intelligence
of better
trained human intelligence
with better systems
of human collective intelligence
i.e. better than peer review
and democracy systems by which
shared intelligence can operate better
which we could get into augmented
by computer intelligence
and so what we're looking for
is AIs as decision informing
more than decision making systems
that are able to take that massive dimensionality
and show you the patterns
at the risk of
sounding overly pessimistic
that has been the theme so
do you think
that we
that it's too late
to develop
this model where the sacredness
of the healer
and the patient
can be restored
because so much damage has been done
that the majority of
users of health care
don't put any value
on having a relationship
that
building a model that would
that would
honour that sacredness that it's too late
because too much damage has been done
definitely not
thank you
obviously
when you're trying to pioneer
something very different you're going to appeal
to fast adopters first
and the fast adopters might be
a tiny percentage of the population
but if the thing is much more
effective then other people who
wouldn't have been fast adopters but see it
now have an on ramp into something
so
I wouldn't look at population
wide implementation
it's like before you do scale
you've got to get product market fifth
and then you start figuring out the way that scale occurs
you don't need
a lot of people
I mean let's talk about
a hundredth of a percent
of the population
engaging in a system of medicine
where
diseases are being found earlier and being
prevented where
they actually
feel like their doctor remembers
them, cares about them, they want to go
they feel like they
are making
growth in their own care of themselves
as a person by going
and then
those people both because they're
getting less diseases and having whatever
talking to other people of course then brings
the next group of people in
so prototyping
fundamental prototyping major changes
never happens wide scale
first it happens
small enough scale to do proof of
concept and then catch on and it's totally
not too late for that
I also agree
I mean
the way I tend to think about it is that
you're not going to change
a system
by trying to change the whole
system all at once
and I think
that's why we started this company
is to support this community because we see that this
is the kernel
that's like the seed with which
the kind of pearl can form around
and that you can take that
and scale that
and feel like we're still in that
pre-scale mode
of making sure that the kernel of what we're doing
is sound
but I think we're getting close to the point
where enough people are starting
to take notice of these types
of models that eliminate all the
bad stuff and bring in all the good stuff
I think there's enough people
that are seeing this
that I think you'll start to see a tipping point
and that's when we can start to think about scale
and so yeah
I'm actually incredibly optimistic about the future
as it relates to healthcare
I just think that we need
to keep charging
so
any other questions
so we've got, I think
a gentleman right here
and then up front
then we've got one up front, Dino is up front
yeah thank you, great discussion
before you
got the discussion of around
healthcare
can you hear me?
great discussion
before you got to the discussion around
healthcare
in the current healthcare
you discussed the global
the different issues that are more global in nature
now
this is really a unique
mostly a US
unique to the US
that we are discussing about
the patient
the healer
patient interaction
problem
would you say that it's unique
to the US
in the context that we are talking about
or is there a
or what influence does
the global
community have in this
with the increasing
globalization
increasing interaction
among the different
societies
do you first see
what influence do you
first see
in the improvement of our
patient
healer interaction
I don't know
country wide statistics
on
satisfaction levels patients
have with the feeling of care
of their doctors
to be able to rank them
I don't have
a clear sense of that
there are obviously
pretty significant differences
based on
the wealth of a country based on
social services available
things like that
but there is also a lot of global standardization
and we saw that
so potent leader in COVID
because of course
let's say that we take a major nation
like the United States and it decides
that its approach is something like a
mandatory vaccine
or at least a
requirement of it for travel
or things like that if it decides that
then anyone else that wants to have a travel relationship
with the US is now going to have to do
a similar thing which means
that even though there was not a
international regulatory body
market type dynamics in that
meaning that whoever
the leaders are
those processes now
become widespread and that I think has been
true in many areas of medicine
in terms of this
question about
the quality of the human contact
I would guess that somewhere
like Bhutan probably has
a much better version of that
that doesn't mean their system of medicine
as a whole is better
in general I think that's a part of medicine
that was often better previously
and while medicine advanced
and got better technologically
I think one of the biggest
externalities has actually been the patient
doctor healing connection
for
all the reasons that you guys know
I think the positive side
of this question of
the global influence is that
if a
good enough prototype happens
anywhere I think it does have the ability
to influence and scale everywhere
We've got a question up the front
for Dino
and keep it quick Dino
no long run on questions
You know that's not going to happen
I don't want to sound like
a therapeutic nihilist
and I don't know how to
ask this question
without sounding like one
but you know
background in clinical epidemiology
so when I look at the numbers I find
a problem with the idea
of the social determinants of health
Social what? Social determinants
of health which posit that 90%
of health outcomes
or maybe well-being
or welfare broadly
are not related to medical care
90% is related to access to health care
and I would posit
9 of those points are primary care
and only one from specialty
so the question becomes
do we have a problem
with resource allocation
that they're going to this
technological and industrial foundation
of medical care
as it has evolved
and is not focusing on other
larger metacrisis
maybe even meaning crisis kinds of issues
that are going to end up
be more positive for the rest of us long term
Maybe actually Daniel
maybe address the kind of how medicine
one of the questions I had
I think it's maybe related to this
is how kind of medicine has to
involve addressing other sectors
so I think you know like manufacturing
and agriculture and things like that
so I think that could be maybe a good combo
One of the things
for me is
the benefits of this particular model
you all are working with here is
how many more things
can be done through telemedicine
because of the financial system
and so I think the ability
for things like continuous blue coast
monitoring and better and better
biometric systems at home
and things like metabolomics
and image recognition
being able to make
preventative medicine and early diagnostic medicine
way better, cheaper, more ubiquitous
like I think that's extremely
interesting and exciting and the idea
that the primary care physician
could have
access to those
computational diagnostic tools
and a telemedicine process
so that things that someone doesn't want to go
to the doctor for but they would actually
hop on a quick phone call or
FaceTime and increasingly
the doctor can actually
just say yes upload my daily metabolomics
or glucose monitor or whatever it is
here so that the moment
I see a pattern the doctor can actually reach
out to the patient and give them input
what that portends for
general health promotion, preventative medicine
I think is amazing
the problem of
that everybody's focused on their problem
and they will try
and their problem seems
so catastrophic
that they'll put all of the resources
into that without looking at resource allocation
writ large and all of the other problems
like that's a governance issue
it is a
holisticness of perspective
and so
talking about how many of the determinants
of health issues are outside of just
medicine and access to medicine
so
my perception is that the future of medicine
and healthcare has to involve
the future of
civilization design writ large
and all the things that end up affecting human health
so when we
the lead example is a great example
and obviously we've banned
lead and gasoline except still for
piston planes and a few things
but there's
there's something like
50 million chemicals
in the chemical database
human generated chemicals
the VOCs
and the paint in here
those same type of petrochemicals
can be found in the snow in the top of Mount Everest
and most of them are
either endocrine disruptors
neurotoxins or carcinogens
we can find them in human mother breast milk
do we need to be designing paint
differently with regard to the VOCs
involved do we need to be doing industrial manufacturing
of all things that out gas differently
totally
if we think about
so
I personally think the topic of
subclinical toxicity
subclinical pathogenicity
and subclinical deficiency are huge
topics that functional medicine
pays attention to and I think
the rest of medicine
will start to pay more attention to
obviously there's a level of vitamin C
that is so low that we would diagnose
it as
deficient meaning you have scurvy
but there's a big range
between I don't have scurvy
what is the optimal level of vitamin C
in a human body
and I think that range
when people are at the lower end of the range
it is still considered you don't have a nutrient deficiency
in the formal sense
I think those types of things make a huge difference
so
when we look at an agricultural system
where you remove all of the trace
minerals from the soil
and then you just put back NPK fertilizer
and then continue to remove all the trace minerals
and you see things like
the low chromium and vanadium levels
in agricultural soils
and then increase type 2 diabetes
when chromium and vanadium have key roles
in insulin sensitivity and you see
that the
decrease in selenium in soils
and the increase in heart disease had
similar correspondences like
can we and that's
just at the level of like
top soil management and agriculture
of the productive food stuff
not even getting into of course animal husbandry
and the way more serious issues there
or then turning it into hostess or McDonald's
so
can I have a world where
the
economics make
commercials for McDonald's
and easy access and availability
to that starting in childhood
and have optimized health
for the whole civilization
not really so like the future
of the food system and the agricultural system
and regulation around that
and the future of manufacturing
I think those are all
examples of really critical things
to the future of health care
to be dealing with the underlying cause
of
not acute disease but
the onsets
of early aging and chronic
complex disease
yeah I don't know if that
addresses the question
those were a couple thoughts came to mind
Any other questions
is one of the back there
gentlemen right at the back
Happy to talk to you at a break
Hey, while that mic's been
is that mic working? Can we just have this
we'll have Mark's question because he's going there
Mark, you're next. Are you able to hear me now?
Yep, we can hear you
and speak up nice and loud for us
so I'm the founder of
a health care AI company
so
after your talk I'm at least happy
that I'm not the founder of a horse drawn plow company
my question for you
is we're trying to be very
intentional about the way we're building
what we build
oversight committees, feedback cycles
but it is difficult
a lot of people even academics push us
to do more complicated things
that are easily explainable to clinicians
Have you seen a framework
have you seen an international policy
an international standard that you like
that builds in that feedback cycle
in an ethical way that's
maintainable so we're not speeding up
bad decision making
No
Dan
That doesn't mean that you can't
in knowing that
do various kinds
of advocacy to try to help increase
that happening
if you want to understand
the issues of AI safety
and the acceleration of AI causing risks
you can read Superintelligence
by Nick Bostrom it's a good book
but specifically
Yudkowsky just wrote a new article
Eli Aizio Yudkowsky
Eli Aizio Yudkowsky is maybe the
top AGI risk expert in the world
and just published a new one a couple days ago
on the current state of
scenarios of AGI risk
I would say it's the best
current overview there is
and then what you can see is
the various categories of tech
development that contribute to those scenarios
I can tell you a few of the things
that don't yet exist but need to
and they sound
Oh, it's not true
Do I see any countries that are working on it
China
is
I would say
from what I can see
paying attention to the
existential risks, exponential technology
portends and trying to find solutions
because they have
more
top-down capability
and so you can see that
the social dilemma came out
and
we could see everything from
teen suicide and body dysmorphia
to breakdowns of the family
unit to increasing polarization
and everything from
January 6 and whatever
we can see all those issues and just no competence at all
to do anything about it because
the few tech companies
that are doing that also make up
most of why our stock market works
Following that
China did something very different
they actually made sure
that Tiktok only
showed
educational and patriotic material for minors
that there was a limit on the amount
of video gaming time
they stopped live streaming like they did massive
pertalments of the harmful aspects
now this is very concerning to people
who think about civil liberties
and doesn't that seem like a very
um
patriarchal top-down
kind of control system
that's true
on the other side
what are the harms of letting it continue
and this is why we say catastrophes and dystopias are the two twin attractors
that you have to avoid
but
when you look at ant group or whatever
the government actually regulating
market and general technological development
I would say China is probably doing that
better than anyone I can think of
associated with their ability for long term
planning and we know why we did
term limits here which was to not
have you know despotic rule
long term but one of the problems of term limits
means nobody ever tries
to do anything that has more than a four year
return horizon and mostly three year return
horizon which means long term planning is mostly non-existent
and especially since you know whatever you do
will be undone in the next
administration
and you just can't
do things that have long term effects
without the ability for long term planning
and continue to be a viable civilization
especially in the presence of anybody who can do long term planning
these are really deep governance changes
that have to occur
so one thing I can say that has to change
about regulation is so far
the nature of the relationship between the state
and the US has been
the market can advance new technologies
bring them to market pretty unregulated
in terms of new things right because
it has to work with an existing regulation
and if that thing causes
some social harm
then it's up to whatever
groups to try to lobby to address that social harm
and then of course the for profit lobbying
will work in its own interest and eventually
maybe the social harm will be seen
as severe enough that cigarettes
won't be allowed to be sold to minors after how many
lung cancers or whatever else
or DDT will finally get banned
to then be replaced by another thing that is just
as lethal but we just don't have long term trials
on how bad it is yet and then we sell it to Mexico
and buy the produce back or whatever things like that
so
we have to move to a situation where
the new technologies
have to actually get
regulatory approval before going to market
and we don't
like this idea because we don't trust our government
which is why we have to fix that
because if you either
you say
we don't trust our government so there shouldn't be one
or fuck we actually
a market does not solve these issues well enough
there are perverse incentives
we do need something like a state and rule of law
so we have to figure out methods for addressing
the corruption
and trustworthiness because of course the idea
is that the market will do a lot of things
well in terms of innovation distribution
of resources in a decentral way
but it also has incentive for a lot of fucked up stuff
and so since we don't want all the trees cut down
we'll make national parks and we'll have
rule of law backed up by a monopoly of violence
which is what the police force is
that will back up nobody logging the national parks
the state is supposed to be
what can implement
rule of law which is the collective value
systems of the people right which is why you need
a educated citizenry
that can vote on
the jurisprudence the basis of what becomes law
that monopoly of
violence is supposed to support
to check the predatory aspects
of the market allow the productive ones
and check the predatory ones but that only works
if the people are checking the state
in a of four and by the people
government system if the people can no
longer check the state because of the complexity
of it and because of every
topic being a national security issue
and things like that then of course that entire system
breaks down and rather than the state check the market
the market captures the state
and the people whatever
and so there are really fundamental
changes that have to occur to that entire
apparatus so that it
and the question of what would it take
to create trustworthy institutions
given that climate
change is pretty complicated and
a risk is pretty complicated and grid security
and medicine are pretty complicated individuals
can't make all those senses on their own
to just like buyer be aware be the only
answer for everything so we need institutions
that can process that complexity we have to
trust them right now there's pretty much
no universally trusted institutions
the left right polarization is so
severe and things like that so the question
of what would it take to create trustworthy
institutions in a population capable
of doing the epistemology
and sense making to determine the trustworthiness
of them it's a big
set of topics we have to do that there are
no answers without doing that that are at all
competent
and so assuming
the ability to make a state that is at all trustworthy
then with
new categories of tech that can produce
externalities
that are truly catastrophic
at rapid scale
you cannot release them into the market wait
for the catastrophe and then regulate afterwards
because it will be too late you actually have to be able
to do the externality
assessment up front
to be able to ensure that the version of the
technology that's going to market is actually
okay to go to market and then
you have to ongoing
be monitoring for early indicators
it's going in the wrong direction to be able to change
that regulation that is a very
very big change
that the speed and potency of exponential
tech absolutely requires
mark we had a question for mark
can you hear me
can you hear me
can you hear me
my question for you
have you ever been to a conference with
no AV issues Daniel
pretty common
okay can you hear me
great
question for you is when I think about
healthcare and AI
specifically do you see
a tension between the value
that it can provide
and yet its ability
to explain how it got to that value
so
I would think that
in its most valuable form
when AI is using
you know going across different information
that's out there it could identify
something that it's actually hard
to explain in the example of
the healer patient to the healer
why this could be the right decision
and the
if you take it
along that lines
the maximum value from it
it will be that much harder to explain
and so where is the role there
and if I was just to extend that a little bit
that was a healthcare example
but if you put it in a sphere
where time is of the essence
like in defense or something like that
the governance piece
that you mentioned while valuable
it actually seems like
it doesn't quite fit
and something else has to be figured out
there, thanks
I'm sorry I can only barely hear you
what I'm hearing is
if the AI can identify patterns
that they won't be able to explain the causation of
how do we deal with that
how do we deal with that
because
the most valuable
the value from AI might be
when it gets to the point where it can't explain patterns
and then the secondary is
outside of healthcare
that would seem to be exacerbated
when speed of decision making
based on the results is of essence
right
there are super tricky issues here
this is where we're talking about the infosingularity
that we want to
not
have the decisions limited
to what an individual doctor
or a small group of doctors know
because there's some new stuff being published today
and there's some red that might be useful
and there's stuff that's published in other languages
that none of them have read
so we want to be able to have access to all that
simultaneously
we don't want a system that is saying what to do
because of what's in a magical black box
that nobody can understand
and so what we're interested in pioneering
is a kind of symbiotic intelligence
between
human, individual and collective intelligence
and artificial intelligence
it's neither a artificial intelligence
decision making system
nor is it a
purely human
run system
I don't believe we want to disintermediate
humans in deciding most things
there's of course cybernated things
like you start
the system notices a particular seismic reading
and automatically pulls the train over
there are certain types of things where once we have
already engaged
in a decision making process around
that's the right thing to do
is simply automate that process
where speed really matters
but where we're deciding things
that have not already been decided
even though speed matters
the accuracy and quality
of the decision process really matters
then we want to be able to
have the computational systems
provide information
that the people who are making the decisions
maybe didn't have access to
and not just provide information
but provide the processing of that information
on the topic of
but then the people are ultimately
still responsible for making the decision
that's where the
as far as like malpractice
and adjudication and all those issues go
the technological system does not
actually become the responsible party
the people who are the responsible party
now the people who are developing
and implementing the technological systems
have responsibility for the effect of the systems
which is
different than the people who are using the system
who have responsibility for the choices they make
so where the responsibility goes is important
the AIs that can process big data
are not that different
from the AIs that can also be personalized
tutors so when we talk about
the future of healthcare
I think doctors
move towards a much more human connection
high touch orientation
I think this is also
very true for the future of education
is that
there will be AI tutors that are
incredible and yet we still need
human tutors
teachers interfacing
between the kid and the AI because the AI
does not actually have a relationship
a teacherly authority
relationship of care and love
with the student so but let's say
for instance GPT-3
is already at the place where I can not
just say you know make me
an article that says such and such I can say
make it in the voice of
you know this particular author give them
all of the writing of that author and it can actually
copy the voice of that author
now you imagine
the deep fake technology of
being able to generate
animations and
videos in real time
and so we already have chatbots
where I can talk to the chatbot
and it talks back to me that I can't tell
isn't
a person in many domains that's getting
better very rapidly that chatbot will move
from text chat to a video
to somebody I'm talking to
you can go to thisfacesnotreal.com
and see a bunch of faces that look totally
real none of whom are real they're all AI
generated faces and some recent studies
actually show that
without knowing not only did the humans
not know which ones were AI generated in real
in general they trusted the AI generated
ones more which was
interesting
but
let's say that I can go into
the metaverse through whatever mechanism
and I can go to the academy
and
have a conversation with Socrates
and it has all of
Socrates' thinking
and biographical information programmed
in so I have a chatbot of Socrates
that is trying to answer in ways
that are logically and semantically
congruent with the answers he would have given
or anybody right
I could go and ask
Van Neumann and Kurt Gerdel and Einstein
to all sit around the table with me and talk about formal logic
that will happen
and that's
so mind-blowingly amazing
for the future of education
that every kid could get something
where the AI is actually
personalising, modelling their theory of mind
so not only communicating in English versus Mandarin
but at their level of education
so it is doing personalised
trans media
bespoke education for them based on
their questions of this type
like that's amazing but it's also super dangerous
because that
Van Neumann
or that Socrates is going to say stuff
that is not exactly what the actual one probably
would have said and there is a difference between
the type of intelligence that is creating
that symbol manipulation AI
and the type of intelligence that we have
so now imagine the role of the teacher
in the future understanding those
AI as well and understanding the topics
and understanding pedagogy
so the student just went in and had this
conversation with Van Neumann on formal logic
and then I'm talking with the student saying
what do you think the AI Van Neumann said
that is different than what the actual
Van Neumann might have said and why
based on what is the difference
between how this artificial intelligence
system works and how you think
human organic intelligence works
now of course not only does the kid have
that amazing kind of
AI tutoring capability but it also then gets
to think about the difference between different types
of intelligence and different types
of theory of mind and when that happens
the recursion when you start thinking about
intelligence recursively
intelligence has a kind of exponential growth
curve so what this portends
for the future of human learning intelligence
is so amazing so imagine
now that you have that kind of tutoring
ability also in medicine where that AI
that identified a causal relationship
that it can't show you very easily
just from the way that it learned it
because it learned it through some
very complex topological assessment
it can translate
into a set of causal mechanisms
that you can't understand
and so we're looking
at both in this situation
the AI being a pattern
identifying tool
as well as a educational tool
So we've
actually come to time so thank
you all for sticking around
with us and asking questions and thank you Daniel
and I really hope my next conversation
with you isn't with a deep fake
so thank you so much for being with us
Thank you
