was this idea that we're
as close as three or four years from reaching the
event horizon where there's a point and no return
of AI reaching escape velocity
that was sort of a little bit of a
in my head I've always thought maybe it's a few decades out
but how do you kind of think about that
can you maybe provide some examples
as to how you come to that conclusion
yeah near term AI let me close the loop
on this other thing I was saying about the
World War 2 solution why it's over I'll try to be faster
so mutually assured destruction doesn't work
when you have many catastrophe weapons
and many non-monitourable actors
the only solution that really anyone
is trying to propose to that is
well we have if people can develop catastrophe weapons
in their basement we have to know what people are doing
in their basement that requires ubiquitous surveillance
and there are some major nation-states working on that
that obviously starts to look
that's a lot of power to be concentrated
that's very hard to have checks and balances
on that kind of power so if you don't want
decentralized catastrophic power
then you create some centralized checking force
that becomes an unchecked power so either have catastrophes
on one hand or dystopias on the other
this is roughly what we call the metacrisis
the metacrisis is that we don't have
climate change risk or AI risk
or biotech risk or escalation to war
collapse of supply chains we have all of them
and that the cumulative effects
of industrial tech over a few hundred years
unrenewably removing resources
from the plan on one side including on the other
has hit planetary boundaries across many axes
and the evolution of exponential tech has created
many many catastrophic possibilities
it's easy to benefit one of them
making another one worse so we can try
to sequester more CO2 to address climate change
by planting more CO2 sequestering crops
in certain areas but if we do that
with nitrogen fertilizers that increase
the rate of nitrogen effluent to cause
dead zones in the oceans we can catalyze
oceans dying even faster
most of the solutions or we say
to solve climate change let's try to
create real taxes on carbon
to incentivize other energy sources
if every country doesn't agree to it
whichever countries do are
so economically disadvantaged in the short term
relative to the ones that don't they kind of
lose geopolitically and as a result you get
things like global autocracy dominating
so we have situations where almost
each of the catastrophic issues
the simple solutions are totally wrong
they make other catastrophes worse
and the way of approaching all of the catastrophes
usually looks like dystopias
so in our work we're looking
for a third attractor the future of civilization
that is neither catastrophic risk
or dystopias which means there must be
civilization systems that can check
the power of exponential
tech and a global civilization
but have that system have checks and balances
on itself and that's a really
non-obvious tricky thing to do
if we just identify briefly
the other couple aspects of the World War 2 system
that drove this thing was the
global monetary system that created
the reserve
currency and all those types of things
the Bretton Woods system
the idea was let's ensure
exponential growth of GDP
because the way you prevent wars
by making it to where everybody can have more stuff
without taking each other's stuff
how does everybody have more stuff without taking
each other's stuff
well you have to take it from somewhere
it looks like unrenowably taking it from the environment
and if you try to run an exponential
financial system attached to a
linear materials economy that destroys
the environment on both sides on a finite planet
you hit planetary boundaries pretty quickly
and so just quickly touch on linear materials economy
linear materials economy means
that we get stuff from somewhere
that looks like
taking fish out of the ocean faster
than they can replicate
taking trees down faster than they can replicate
taking food out of the soil faster
than the top soil can replicate
taking mining materials out faster
than they can be remade
so you get depletion on one side
and turning it into pollution and trash on the other
faster than it can be processed
so you get environmental issues on both sides
and so obviously with just something like energy
we get climate change and mercury
and the atmosphere and a bunch of things
from the burning of hydrocarbon on one side
and mountaintop removal, mining and oil spills
and wars over oil and whatever on the other side
it's worth noting that all those issues
associated with say
hydrocarbon energy and particularly
oil based transportation
for internal combustion
that are truly global
existential risks
are the unintended consequence
of creating automobiles
which was trying to solve a very real problem
of transportation and the difficulty of horses
and horse husbandry for drawing carriages
and how nice it would be to have a carriage
that didn't require horses
and so we solved that problem
and then the side effects of the way we solved it
is global climate change,
wars over oil, oil spills
and an entire geopolitical unstable situation
so this is one of the underlying issues
is that we solve problems in very narrow ways
that externalize problems that end up being worse
we do this in medicine
and we do this in our healthcare systems
to try to make a medical system
where whatever kind of piece of
regulatory apparatus or incentive is put in place
often times causes much worse problems
so one of the underlying things that we need to address
is how we define the problems themselves
has to be much more interconnected
so that we don't externalize problems somewhere else
in the process
so obviously we have to also change
our global monetary system
to not require exponential growth on a linear supply chain
and that's a huge deal
this is not an obvious thing
but we don't have all that long
so basically the solutions
to how to prevent nuclear war
ended up driving the environmental risks
and the growth of the technologies
that now portend lots of catastrophic risks
so we have each year there are more total
catastrophic risks with higher probability
you were asking about AI
the obviously post nuclear
we got digital revolution
and computers were kind of the beginning
of exponential tech
meaning technology that makes better versions of itself
so you get an exponential curve
and
the very centre of it
of computation is AI
and so technologies that are on
kind of exponential growth curves
are the things that can create the biggest effects
the quickest we all see that like
almost global proliferation
of smartphones in just over a decade
compared to a couple millennia
for global proliferation of a cloud
and how radically
that changes global behaviour and culture and everything
actually I love your analogy
you give with the invention of the plough
and how that kind of changed society
just profoundly over many generations
could you just kind of cover that story
because I think it's a really interesting kind of analogue
or do we not have time for that
I can do a quick version
I think many people
kind of have the sense that
either technology is just kind of net good
because technology is trying to solve a problem
and if it didn't solve some problem
that enriched human life
it wouldn't proliferate
markets wouldn't advance it
