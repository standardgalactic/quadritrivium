So, before we jump in in our intro, our guest Daniel, I just wanted to do a few housekeeping items.
We're going to spend about 60 minutes up here, and then we're going to release you to the bar.
At 60 minutes, you can either go to the bar or have some Q&A.
We'll be up here for as long as needed to get through the questions.
Just a quick note, for those of you who want to get a drink, the sponsors have all the drink tickets.
So, go talk to the sponsors and get as many drink tickets as you want.
That's our way of supporting the sponsors, making sure that they get people going to talk to them.
We couldn't put on the hit summit without the sponsors, so thank you so much to them.
So, I want to just quickly intro Daniel, and then we'll jump into the conversation.
So, Daniel is the founder of the Consilience Project, which is aimed at improving public sense-making and collective intelligence.
He's a social philosopher focused on making sense of the state of civilisation and how to prevent the many catastrophic risks we currently face with the solutions that are not dystopic.
So, these are concepts we're going to cover in the conversation, but he sees some of the feedback glutes between societal elements and the individual.
So, a lot of his work and analysis is actually thinking about the future of healthcare.
I came across Daniel, I went down a little bit of a rabbit hole.
I was reading about money and the role that money and currency plays in the economies and just the global system.
And came up on these ideas around how modern economies are incentivised to grow forever basically.
And if you tend that to the end of time, eventually you run up against planetary boundaries and cause a bunch of problems.
So, I found when I came across Daniel that he had one of the clearest thinking about many of the issues that are catastrophic risks that face humanity.
And as I'll talk in my talk tomorrow, some of those are related to healthcare.
And so, I wanted to have Daniel here, both to share some of his thoughts generally.
Because I think it's really important as a community that we broaden our knowledge base and continue to look outside of our industry.
But also because I think he has a lot of really interesting ideas about healthcare.
So, Daniel, thank you so much for being here with us today. I appreciate it.
So, what I'd like to do is I'd like to get to a conversation of some of the structural flaws in your assessment of the healthcare system.
And also vision of where we could be long term.
But before we did that, I wanted just to get some of your big picture thoughts on some of the catastrophic risks that are facing humanity.
As well as what you kind of refer to as the metacrisis.
And I'd love just to kind of hear you articulate those ideas.
Yeah, I will mostly try to face you so that I'm not squinting in the sunlight.
People might think that it's kind of a strange thing at a medical conference largely focused on changing the kind of business model of medicine to be talking about climate change and AI risk and escalation pathways to large scale war and other environmental risks.
I was quite happy to talk more just about future of medicine, but you said you wanted to kind of expose people to this thinking.
And obviously, while people here are doctors or various positions in healthcare, they're also citizens and humans on a planet that really is facing these very kind of eminent risks.
So, I'm happy to go over that.
Civilizational collapse, like full blown civilizational collapse, is actually a topic as old as civilization.
We can see pretty easily that the early hominids that we could consider humans other than homo sapiens don't exist anymore.
So full blown extinction of those species happened.
Happened for reasons that most people believe homo sapiens had something to do with.
So that's kind of an important point.
But then also when you study the history of empire, whether we're talking about the Mayan or the Aztec or the Roman Empire or Byzantine or Egyptian,
it's pretty easy to see that none of them still exist.
They all went through civilizational collapse and there's really good academic research.
The canonical work is by Joseph Tainter called the collapse of complex societies that identifies that most of those societies failed
or they ended up collapsing after hundreds or thousands of years of thriving from self induced causes.
It wasn't mostly volcanoes and weather events and it wasn't mostly just that some other empire got more powerful.
Oftentimes even if they fell militarily to another empire, it was an empire or a war smaller than ones they had successfully defeated previously
because they had already passed their peak of organizational capacity and when they were actually in their prime,
they started having more internal infighting and corruption that led to institutional decay, worse governance,
and then they couldn't handle the issues they had been able to previously handle.
Also many of them failed for environmental overshoot reasons, using up trees and topsoil unrenowably and then not being able to support their populations.
So the first thing, we don't think about civilizational collapse very often if it's not the field that people work in,
but every previous human civilization did collapse mostly for self induced causes.
So we actually don't know how to make civilizations that don't collapse, that's kind of an interesting point.
And then the difference between today and the previous ones is this is the first time we have a truly global civilization.
We can't think of a US or a Chinese civilization given that the goods and services that we depend upon take six continent supply chains
and pretty much no country can make the things that they depend upon, so there is truly an interconnected global system
that is going through the same type of decay situations leading to catastrophic risks that the previous ones did on very short term.
Maybe just give an example, like for example putting into your computer what are the requirements for that
and that's no single civilization, no single country can actually assemble a modern computer or almost any other advanced tech that we've got.
You just said it, I think this is streaming over the internet which is obviously satellite and server farm mediated
and if you think about the semiconductor manufacturing and the chip manufacturing and the entire supply chains that make that up,
they do take six continents to make, they do take many many countries to make,
and so the fundamental infrastructure we take for granted without which we wouldn't be able to keep living is truly globalized
and so that creates fragilities where failures anywhere can create cascading issues everywhere.
We saw this recently with a local issue happening in the part of the world called Wuhan, China
and the net results being global impact pretty rapidly, not just in health care but then to try to shut down the spread of the virus.
There was shutdowns of supply chains that stopped the flow of fertilizer and pesticides that created crop failure
that damaged the food supply for hundreds of millions of people.
The ripple effects of that are still cascading and many other effects like that.
So even though civilizational collapse is a kind of ancient topic,
the first time we had a technology where we could induce it quickly at a global scale was World War II and the bomb.
The bomb was obviously the first truly existential capacity where humans could make a handful of dumb moves
and inhabitability writ large for the planet and that was really a turning point
because the entire history of the world up till that point anytime we developed a new technology
there was a race to implement it as fast as possible for the competitive advantage.
Now we had a technology where we had to make an entire world system that ensured we never used it
and the world system from World War II till now that has kind of prevented a kinetic nuclear World War III
for the most part is ending right about now and it has driven hundreds of catastrophic risks that are imminent in very short term.
I can kind of give a brief overview of that.
So to prevent World War III kinetically against between major superpowers
which is a big deal when you look at the whole history of the world the major empires never didn't war
that was always kind of the defining feature.
When you say maybe just kinetic war just a quick summary.
Actual war with weapons as opposed to information wars or narrative wars
or economic wars or supply chain wars or other forms of competition
there's obviously a blurry line between politics and warfare
but to prevent and we've had proxy wars since then
but you couldn't have the major nuclear superpowers go into a full blown kinetic war
and so there were a few major parts of how we achieved that.
One was mutually assured destruction and mutually assured destruction worked
when the only catastrophic weapon was nukes because nukes are extremely hard to make.
Uranium enrichment is difficult, cyclotrons that make uranium can be seen from space
it's pretty easy to monitor who has them so you can prevent lots of countries from getting it
and so you can create this kind of forced equilibrium called mutually assured destruction.
Obviously since mutually assured destruction until now we have not succeeded at nuclear disarmament
we have been in an arms race towards faster and faster nukes, hypersonic nukes
because whoever had the fastest ones could win first strike.
More countries have got them and more other countries are connected to countries that have got them
that could influence them with cyber weapons and other things like that.
And then you have the arms race between America trying to build systems to intercept the nukes
and so then the Russians build Poseidon to go under sea and nuke
so they can nuke things really quickly and you just have that continual arms race
to the point where now we're more nukes than we were when we started with nuclear non-proliferation.
Right and of course when you have very good ability for cyber and information attacks
that can make it look like the other guy launched and you're in mutually assured destruction
that's a very sketchy scenario, we're in that scenario.
But it's also important to understand that there are now many, many nuclear level catastrophe weapons
and that unlike nukes are not hard to build.
This is something to understand about the biotech as a great example
we obviously just experience the effect of a pandemic of a not terribly lethal virus.
If you look at the rate of development of biotechnology both synthetic biology plus things like
crisper genetic engineering and how the rate of that advancement is making the genetic engineering capacities
to do those things much, much cheaper and more decentralized
we're currently three to five years away from tabletop crisper being pretty inexpensive and ubiquitous
which means the ability to engineer pandemic bioweapons is available to a single person in their basement
in a way that's pretty much unmonitourable.
And unlike nukes that are very again hard to make and control
here all I need is the information of the sequence, the DNA or RNA sequence
so if we even have open publishing in science
somebody figures something out at a university with an ethical review board
it gets published, anyone else who doesn't have the ethical review board
who now has access to that information with non-high tech,
I mean with non-hard to create technologies
has the ability to produce catastrophic tech
and obviously they can use that intentionally as weapons
they can also use it unintentionally to try to do good stuff but have accidents
protecting biosecurity is actually amazingly hard
and trying to use a biotechnology for a positive purpose
but not being able to factor all the second order effects
we started adding lead to gasoline to stop engine knocking
and the effects of all the lead that went into the environment
took about a billion IQ points off the planet cumulatively
before we dealt with the regulation and increased violence about 4x across the population
and the inventor, the video you shared the other day
the inventor of lead gasoline killed more people than any other human
in civilisation or something like that
something like that
and so this is an example of you build something for one
hopefully positive purpose but it has lots of other purposes
many of which end up being negative, we call this externalities
the more powerful the tech gets the faster the externalities are
and obviously 4 out of 5 doctors chose camel cigarettes
and DDT was better living through chemistry for everybody
and it wasn't until we saw how many people that killed
and how many pollinators that killed that we regulated it
we regulate way after the fact
with things like self replicating biotechnologies and AIs
we don't get to do that
if we wait till after the fact it'll be too late
so coming back, mutually assured destruction works
when you have one catastrophe weapon, two superpowers that have it
it's really hard to make and easy to monitor
now we have dozens of catastrophe weapons
many dozens of actors including non-state actors who can have it
exponentially more actors that are unmonitourable in the very near future
and so often times we talk about how good decentralisation
and democratisation of everything is
and the way that exponential tech allows what the largest corporations can do
to be available to anyone
but the democratisation of catastrophic capabilities
actually not a totally good story
and so if you want to solve the catastrophe weapons for everyone model
how do you do it if you can do it with
build the things with non-exotic materials in the basement
drones are another example
people can take commercial drones
and get advanced AI swarming algorithms for free on GitHub
they were developed by the very top thinkers in the world
at places like MIT but then they're free on GitHub
download them, put very simple kinds of explosives
and take out critical infrastructure targets
that can be radically catastrophic
what would be one example of a simple infrastructure target
that's rapidly catastrophic
better not to talk about
okay, good point
so
not that hard to figure out if you want to think about it for a while
okay, now I understand, good point
but I will say if you want to think about another category of catastrophic tech
we apply fairly simple AI models to supply chain optimisation
supply chain optimisation seems like a good thing for the environment
because it decreases inefficiencies
but if I can use AI to optimise flows through a supply chain
can I reverse it and find what the most critical
what the few, the least number of targets that if I were to take out
would damage the whole supply chain the most
sure
pretty much anything I can optimise with AI I can reverse
it's the same tech
and so it's kind of important to get that we'll look at
AI for protein folding in medicine to solve some issues
and we'll look at CRISPR and immuno-oncology to try to solve cancer
and remove oncogenes
once you develop that tech for that purpose
you can use it for any other purpose
and you can do a lot of things with CRISPR other than immuno-oncology
and a lot of things with AI in protein folding
other than the positive applications
one of the things I found that was a little bit shocking to me
when we were chatting a couple of days ago
