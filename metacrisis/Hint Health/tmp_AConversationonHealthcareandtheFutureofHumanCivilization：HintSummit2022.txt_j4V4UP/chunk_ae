that's already an example of a simple
AI a content
curation AI
that is destroying democracy the social
contract the epistemic commons at scale
and just quickly epistemic commons
our ability to collectively make sense
of the world we live in
in the fourth estate basically the news
news the idea
of the US
and most modern democracies is that
the democratic system depended on
two prerequisite institutions which was
public education and a independent
news or fourth estate
because you have to have an educated and informed
citizenry to do collective choice making
if we didn't all have collective sense
making about what's actually going on
collective choice making has no possibility
and the quality
of public education
and of
media relative to the actual
problems we face and the complexity means
we obviously don't have anything like democracy
we have a simulation of one at best
and a rapidly failing version of that
so that's already AI causing catastrophic risk
now if you want to talk about the scary scenarios
that seem scary
it's things that look like scary things
like autonomous weapons
and if you want to just get a brief
sense of what that looks like
go to YouTube watch a short video called Slaughterbox
and you'll get a brief intro to
what swarming autonomous weapons
in the very near term look like
this is being radically advanced
in a arms race
but
faster than that
the
Facebook algorithm
and the Google algorithm whatever are
basically curating content that humans made
AI is now also creating content
that people can't tell wasn't made by people
meaning it passes the Turing test
GPT-3
technology that's already publicly available
that I don't need to program
I just speak into it with natural language
I say GPT-3
make me a
argument about
why all COVID vaccines are dangerous
using
real statistical analysis
do
real data sets and real statistical analysis
that shows that
and it will instantly
present that
and it can do it at a speed that biostatisticians
can't begin to actually address debunking
and I can also say
given your personalised data
make one that will maximally compel you to X
and so the speed at which
that technology
is becoming ubiquitous
is like a three year time horizon
so if we can make maximally
compelling content of any kind
that
floods the internet where nobody
has the ability to tell what is real
or not on anything
then in the inability
to make sense of the world
despotic leadership and things like that take over
so that's roughly where I said
a irreversibility on a short
number of years timeline
so it's not in three years the two minute it shows up
it's just that if we don't figure out
how to put
in some controls or start to figure out
ways to almost like
mediate the tech
into a situation where it's almost like irreversible
and so maybe a question
for you on that is
how do you sort of tend to think about
on the solution side
of this equation
what's driving your thinking
what are the tactical
things that we can start to think about now
that actually move us
towards not being all in a lot
of trouble in say three to ten years
so if we
think about
AI and biotech as two of the categories
of exponential tech that are making the fastest
rate of change synthetic
bio is actually advancing much faster
than Moore's law currently
that means
that exponential growth of technology means
exponentially more impact
exponentially faster
with exponentially less
money and exponentially smaller number of people involved
and exponentially
dumber people because the social media
is making us all basically
go to one extreme
the complexity of the world
is hard to understand already
and being able to appeal to the lower angels
of our nature of tribalism and etc
as opposed to really try to handle complexity
and nuance is an easy thing to do
so underneath
the reason that we're letting
AI move as fast as it is
and we're letting biotech move as fast as it is
and that's why the risk landscape
is a type
of perverse incentive
we call the multi polar trap
meaning you have many different
players many different agents
that are all incented
to go as fast as possible to the thing
that is likely to create the worst case scenario
for everyone because if they don't
and someone else does first they lose in the near term
this is the case with the tragedy of the commons
meaning if I don't
go fish all the fish to try to
the fisheries restore but somebody else is going to
if I can't ensure they're not going to
then me not doing it doesn't leave the fish
the fish are still going to go
it just means that my rival is going to be able to grow
his population and economy faster
so not only will I not leave them
I have to race to get him faster than he does
and so this is the
a multi polar trap in the environment
and that's happening with climate change
and dead zones and oceans and all those things
it's the arms race
if I can't ensure that the other guy
doesn't have to work to develop the weapon
and the counter weapon faster
even though that means increased likelihood
of everybody dying from those weapons
and the worst case is actually the market case
whoever gets first mover advantage
will have so much advantage
and specifically in the world of network dynamics
where you'll have one Facebook
bigger than all other social media
one Google bigger than all other search
one Amazon bigger than all other
online stores
that's mediated by the fact that
those networks get
have something called Metcalflaw
they get much more value as they get more users
so once they get a certain percentage of users
they get a kind of takeaway dynamic
where they'll have a natural monopoly
so in a world with natural monopolies
because of networks and in a world with first mover advantage
nobody has the incentive
to really think about the risk landscape
go slowly and carefully
everyone has the
advantage to do the famous silicon valley
adage move fast and break things
but you don't want to break things
when it's breaking the whole world
basically
so far break things has always been able
to be socialize the losses
the government will deal with it
the environment whatever while privatizing the gains
and that's been the orientation
and if anyone wants to go slow
to think about how to do this thing
in a non-terrible way
someone else still moves forward fastest
