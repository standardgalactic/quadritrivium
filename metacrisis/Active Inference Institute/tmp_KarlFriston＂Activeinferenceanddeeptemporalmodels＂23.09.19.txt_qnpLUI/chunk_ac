that I feel familiar with.
So that's the basic story in terms of
what is this functional of beliefs that we want to optimise
and this is a horrible slide if you don't do that
but again, please ignore the equations
I just wanted to show you how easy it is
to take away from these equations
and end up with a formism
that people have been working with for centuries
or at least decades and decades
so if you are a mathematician or a physicist
you will now recognise why this quantity is called free energy
it's basically an expected negative lot probability here
which is called an entropy
and then this quantity about putting together is the energy
so it's basically the difference between an energy and an entropy
so it's the energy that's going to do the work
and it's free energy
but just by shifting these things around
or grouping them together in a different way
we can interpret it in terms of opacity and accuracy
as we've just described
so all I'm saying here is there are different ways of interpreting these quantities
depending upon the words that you use
the constructs that you know are taught
and you use in conversation with your colleagues
they're all equally mild
another nice example of just switching things around
here I'm taking this over here
this over here
means there's another interpretation
of splitting this uncertainty
minimising the capacity of good policies
or expected energy here
we can actually carve it or decompose it into another pair of quantities
called epistemic value and expected value
so let me show you how that works
precisely let me show you
how people have already been using these constructs
these quantities in their work before
if we just focus on these two terms here
what this Christ wants to do
is essentially the expected difference
between beliefs about what's going on out there
if I had some observation in the future
relative to the beliefs about states of the world
without those observations
so what that means is
this corresponds to the salience of the policy or the action
it tells me the amount of uncertainty I am reducing
or the amount of information I have gained
but if I looked over there
that's a good sort of thing over here
so this quantity has been used a lot in visual neuroscience
found in visual searches and salience maps
in terms of the best place to go and sample the world from
it's the place that minimises your uncertainty
or that's invited to your information gain
that has salience, epistemic afforens
it's also mathematically exactly the same
as the mutual information
or the mutual predictability
or the shared variance
between the causes, states of the world
and the consequences, the outcomes that are generated by those states
so effectively what we're trying to do
is to help heat our world
either visually with eye movements
or literally with our skin sectors
by filling for example the layout
of a new hotel room in the dark
testing hypotheses to feed your way around
or sampling it to leave
those sensations that tell you
no, this is a table, not a bed
but you have to have those hypotheses in mind
in order to reach your uncertainty
and the hypotheses that you are entertaining
and in doing that you are increasing the mutual information
between what you feel and what caused those feelings
so that's a very important aspect
of this uncertainty reducing imperative
this free energy functional of beliefs
let's make things a bit simpler
so now I'm doing what I promised before
I'm going to get back to the value of the function
but if you remember before I said
the difference between the value of the function
and the free energy functional
isn't one is belief based
and the other is not
I can actually convert the belief based scheme
into a value based scheme
by removing uncertainty
so the first sort of uncertainty that you're going to be
is basically ambiguity
I can assume that our creatures out there
that can see every hidden state of the world
there's no sensory noise
there are no hidden states of the world
and what I see and my sensory organs
my observations, my mountains
are the things that are observed
and our essence become bones
and the bones become essence
and what we are left with
is just the divergence of the difference
between the predicted and preferred outcomes
these are just our risks again
so this is risk sensitive control in economics
also known as KL control
because this is a KL or Kulbaki but
divergence
sorry not for control theory
but it's KL control economics
this sensitive control
what it tells us is that this
risk sensitive control
is basically what is left
if we remove that ambiguity
let's make the final move
and actually take away ambiguity
so now not only
sorry let's make the final move
and take away the risk
having taken away the ambiguity
so by taking away the risk
what I'm saying is that I am equally uncertain
what will happen if I do that in the future
and if I take that away
we end up with just this term here
so I'll remove this now
and now I'm just left with this
so what if this one's just expected utility
so this is what economists use
to score the probability
of choosing this policy
and put that policy
in the absence of differential uncertainty
both in terms of ambiguity
but also in terms of risk
and there's a deep history
to the effect of the utility
and the expected value
both in economics and in behaviourism
and in the enforcement layer
based on exactly the same idea
and some reward or function
that can ignore uncertainty
and then you will see the policy
of action selection
being completely described
by this value function
so the purpose of that
was really to illustrate
how in general
belief-based formulation
of the thing that we are trying to optimise
mainly maximising evidence
basing model evidence from models of the world
or minimising our uncertainty
through active palpation of that world
are generalisations
of things that we have all been working with
for possible action
but you only get to these special cases
if you remove uncertainty
so the belief aspect
is now to the point that we talk about value functions
just to make it very clear
for those people who haven't come across
information gain
or epistemic value before
I just want to give you an intuitive example
of what it means to reduce
to choose actions
that dissolve uncertainty
even before you know what's going to happen
so imagine you are driving a car
and you are looking around
in the narrow time
and you now have a choice
you are stopped at a traffic light
and there is a filter on this traffic light
that could be pointing right or left
and you can choose to have a look over here
or you can choose to look exactly at the sign
now if you are wondering about driving
you are going to have a 50-50
belief posterior belief
or prior belief before looking over here
that the sign is pointing to the left
or to the right
and if you look over here
then you are not going to change that posterior belief
so it doesn't matter whether the sign is pointing to the right
or to the left
looking over here
won't resolve any uncertainty
you will have a 50-50 posterior belief
