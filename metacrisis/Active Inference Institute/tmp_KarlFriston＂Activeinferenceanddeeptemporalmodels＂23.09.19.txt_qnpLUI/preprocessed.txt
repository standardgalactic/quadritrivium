I spent the morning at Kremlin and its museums, and I've never seen so many of them.
I've never seen so many beautiful things in my life in one day before.
So to thank you, I'm going to show you my most beautiful formula, the Mathematical Equation.
I'm going to spend the next two hours deep on stratigraphy.
I'm joking. I have been told that not everybody here is a mathematician.
So I will be showing you my favourite equations, but I'm using them as pictures to remind me
what to say and just to rehearse the formal structure of the arguments.
This lecture is really an invitation for us to think about what the brain is doing,
and I'm going to take the perspective that the brain is optimising something.
The question is, what is it optimising?
So I'm going to ask you to stand back from psychology, or she learning, or education, or artificial intelligence,
and just ask the simple questions.
What is it that we want to achieve? What quantity do we want to optimise?
And then you have to offer an answer, which is indeed borrowed from statistical physics,
and it has a very different meaning and interpretation for us.
And so what I want to do is to walk through the interpretations and the meanings
from a psychological cognitive and sentiment perspective.
Further to that, if we understand the mathematical principles of higher grade function,
and indeed just the sections and action, then it should be possible to shine a new light
on message passing in the brain, on the neuronal dynamics, on the anatomy of the brain,
the function of the anatomy, or the computation of the anatomy.
So much of my lecture will be trying to rehearse the general idea in some abstract terms,
illustrating how far one can take the formal principles in understanding the empirical brain responses
that a lot of us measure.
Say, for example, if we achieve an electromagnetic brain response,
it's not indeed just our choices and our decisions and our behaviour.
So the agenda is ambitious, so I'm going to address a very deep and bigger question.
What do our brains do?
And provide a potential answer, but use the answer to illustrate to you
how far one can get in simulating the understanding, quite high level or sophisticated behaviour.
So I want to eventually end with an example of reading and language understanding
and its brain response currents.
So that's where we're going to try and go.
If I take too long, you're going to stop me, and then we'll have a conversation
which is usually the best part of these lectures.
There's a question for that.
So I'm not going to talk for more than an hour, thankfully,
and then I look forward to having a conversation about some of these discussions.
Now, have you all read this?
I will be asking questions.
This is what I'm going to be talking about.
I go to introduce the question at hand
and then provide this answer in terms of something called active inference,
closely related to things like active learning, machine learning,
or active vision in the visual sciences.
This is putting perception in an inactive context
that we are actively perceiving and we are in charge
of the way that we palpate or sample the world
in order to optimise our perceptual synthesis.
I'm going to show you that mathematically that's just the same
as gathering evidence for one's own existence.
And I'll explain that connection in about five or six months.
All of this self-evidencing, this active perception, this active inference
rests upon predicting worlds actively,
having a model of how the world works
and how the world supplies our sensory organs,
the sensations, the situation of cerebral outcomes.
And that's known as a generative model,
a model that generates sensory consequences
from the causes out there which we want to understand.
So I'm going to spend some time illustrating the kinds of generative models
that we use to simulate behaviours,
general studies, or in economic games,
and the resulting or ensuing belief-outdating
that we can then look at as if we were
electro-physiologists of red ladders.
And that's from the principles to the process theory.
So making a distinction between the principles of optimisation
that we're talking about, active inference and self-evidencing.
And the neuronal processes that are occurring in your head at the moment
that we can measure as neuroscientists and cognitive neuroscientists.
I'll briefly rehearse some empirical predictions.
I'll go through this quite quickly,
because I want to get to the end with this,
some of the most advanced applications of these ideas
to understand the functional architectures of the brain.
And that seems some deep generative models
that have a deep hierarchical structure,
both in terms of abstraction, but also in terms of time.
Exactly the sort of models you would need to generate language.
And I'm going to turn that on its head and say,
these are the models that we use to understand language.
And I'm going to present some very simple simulations of reading
and show that they produce the same electrophysical responses
that we use in classical paradigms,
like we just match negativity or P300 paradigm.
So let me just start very abstractly and very simply.
Imagine you are an owl.
You are a bird of prey and you're hungry.
So what are you going to do?
Boris, what are you going to do?
Search, perfect.
In that one simple answer to search,
there is a whole range of hindricks about what we architect at times.
So here's the owl searching and there's the unhappy prey
who is about to be eaten by the searching owl.
So clearly, if I'm hungry, the first thing I'm going to do
is to resolve my uncertainty about where the prey exists,
where here the mouse exists.
And it's that notion of searching,
resolving uncertainty that underwrites everything
that I'm going to talk about for the next 50 minutes.
It's important because there are two ways you can write down,
and here are the first and the foremost,
but I repeat, please do not worry about the maths,
they're just here to remind me about different ways of thinking
about things that you can write down in computer code
or in deep mathematics things.
There are two ways you can write down the objective for living,
for the owl, for you, or for me.
First of all, we could write down an expression
for things that we do, controlled variables in engineering,
which we'll call a view of this point in time,
as maximising the value of some states of the world
if I did that thing.
And then what I would be able to do
is to create a policy pie that for any given current state,
if I apply this action, I will move to the next state,
and then I will maximise the value of being in that next state.
So this is the notion of a value function of states
giving rise to a state action policy.
It requires you to believe in and commit to it
and believe in the idea that for every state
there is a label which tells you how valuable that state is
and then all you have to do is to choose the action
that takes you from this state to the most valuable state.
But that's not going to work to explain searching.
For the simple reason that searching is all about
reducing uncertainty, then we know immediately
because uncertainty is an attribute of a belief,
it's not an attribute of a thing,
it's an attribute of a belief about something,
then the function that we need to optimise
has to be a function of a belief.
And if the belief is about something,
then that's a function of a function of something.
And mathematically that's called a functional.
So what we actually need of the alternative way of doing this
is that our best action at this point in time
maximises a functional of beliefs about states
and their ends, states in the world,
if I did this action here.
And I'm going to describe this belief in terms of probability
and posterior probability distribution over different states.
Again, don't worry about the maths, just remember
that Q is a probability belief
and that gives a very different sort of optimisation state.
So we've moved from a value function of states of the world
to a function of beliefs about things of the world.
Furthermore, the notion of searching tells you
that something else is very important.
It means that it matters whether I search for my frame
and then I eat it, or I can't eat it and then search it.
So time and order really does matter,
which means that you can't just write down an object of function.
As a functional of beliefs, you have to define a policy
which is a sequence of actions in a particular order.
So now what we have is a notion that there is a best policy
that entails or prescribes a sequence of actions
in a particular order.
In machine learning or control theatres,
there's sequential conceptization.
For us, all it means is we know that the best kind of policy
of the system, pie and star again,
maximises the sum of this functional,
and I'll say that this is a free-action functional,
of beliefs to give them that particular policy,
and that if I don't write policy,
I can select the right action.
So these two contrasting ways of writing down formally
what things, what living things do,
emerge in many different guises, in many different contexts.
So the notion that you can explain behaviour
in terms of optimality value function
rests on optimality principle,
and from this you'll find lots of examples,
optimal control theory, dynamic programming,
deep reinforcement learning,
utility theory in economics,
apples induction, and so on and so forth.
Some of these you may have heard of,
some of which you've done,
but they're all having caught this commitment
to a value function that can describe
everything we do in terms of optimisation.
The other approach, which is the approach
that we are going to pursue,
is based upon a principalities action.
So action here is just basically a time integral,
or a time average of an energy,
and I've just said F cos a free energy.
So this path is an action,
and we're going to maximise that action
so that we choose the optimum action.
And this is a free energy principle,
also known as active inference.
From this we will hopefully get along
artificial curiosity and intrinsic motivation
in robotics emerges.
We can also cast this in terms of basic decision theory
that I mentioned before.
This is an aspect of sequential policy optimisation.
Now I'm deliberately sort of
contrasting classical value function
with free energy functions.
So how do I find these approaches
that are belief based, and these are not?
But I'll actually show that they come out together again.
So this becomes this
when we remove those certainties.
I'll try to start working back to expected details
of theory in a few slides.
But for the moment, let's just focus
on what this quantity is.
And I'm going to give you one answer,
and I'm not going to motivate you.
There is a deep backstory here
from statistical physics and basic mechanics.
But I'm not going to worry about that.
I'm just going to tell you what it is,
and then hopefully convince you
it is a super objective function
by a series of examples
that will come up in this lecture.
So here's the basic idea.
This quantity is known as a variational...
...quantity.
It's the information theoretic quantity.
Quite closely related to something invented here
in complexity or multilinear complexity.
It's also known as an attendance low boundary machine learning.
In statistics, it's known as the log model evidence.
It's also known as partial likelihood.
You can forget about all these different names.
The reason I'm listing that's all we can know
is it's a very, very important quantity
which you see in many of every field.
The fact that it's called basic model evidence
has given me a license
to describe this optimization self evidence.
I will see why that works in a moment.
From a statistician's point of view,
this native physical free energy here,
this native evidence or log evidence
or evidence low bound elbow machine learning,
is just the probability
of getting these observations own.
At this point in time,
given a model of how these outcomes were generated,
and I am going to leave that long.
From a statistician's point of view,
you can always write this quantity,
this evidence as complexity,
this native evidence as complexity minus accuracy
or log evidence as accuracy minus complexity.
What that means is,
we're going to consider the brain
as a statistical organ,
an organ that's trying to make inferences
just in exactly the same way that you, the scientists,
try to make inferences about
differences between one group and another group
using a statistical analysis of covariance.
The brain is doing exactly the same thing
with its sentient data.
It's trying to test different hypotheses,
different beliefs about how those sentient data
were caused,
and it's doing so by maximizing
the native model of evidence,
which means that it is trying to find
the simplest, minimally complex explanation
that provides an accurate account
of the sentient data.
And that's going to be very important
in the contextualization, it's going to be very important.
So it's not just finding an accurate account of data,
it has to be parsimonious and simple
in the sense of a computer laser.
So this variation of the energy
is just the mathematical expression
of this mixture of complexity and accuracy,
and we imagine that the brain just organizes,
learns, infers, passes the message,
it's all in the service of minimizing
this complexity minus accuracy
or maximizing accuracy, minimizing complexity.
And if that were the end,
then that would be perfectly synchronized
and form an accounted perception.
But what we're interested in here
is how the brain covers back
and actively samples the data
that it could use to infer
a critical structure in the outside world.
And that's the reason we're still here.
So we've already said that we have to
define the problem in terms of
sequences of actions or policies.
And what we're going to say
is that we're going to select those policies
that maximize the expected free energy
after performing that sequence of behaviors.
So what that means is we're going to effectively
choose policies that minimize complexity,
expected following an action,
and minimize accuracy,
sorry, maximize accuracy following an action.
But notice now the outcomes
are now random variables.
They haven't yet occurred.
They are in the future.
So now we have to take an average over that,
things that could happen in the future.
So now we're talking about the average complexity,
and that turns out to be risk.
Risk, and this is where the accuracy
reminds me to provide the formal definition.
So risk is really the needs about
what will happen if I pursue this policy,
compared to what a priori I prefer not to have.
So I'll say that again.
Risk is the divergence or the difference
between what I think will happen if I do this
and what I prefer a priori to having.
So here my client believes about
the sorts of outcomes that I encounter
define the sorts of outcomes
that I expect to experience.
I've been rich, happy, warm,
having my temperature within the physiological range.
These are the things that make me
and they're good to me and they're happy to me.
They are my a priori,
my prior beliefs about the outcomes
that I will attain if I pursue this policy.
And the goodness of the policy
corresponds to the minimal reducing the difference
between what I think is going to happen
and my priori preferences.
That must be that sort of risk.
Let's see another instance of that for me.
Economic perspective at the moment.
At the same time,
I'm going to maximize my expected accuracy.
So what would that look like?
What does the expected accuracy look like
if I haven't actually got the observations that happened?
What it means is
I am going to deliberately choose policies
that make the sensory data as unambiguous as possible.
So if it's like I walk into a dark room,
I'm going to turn the light off
because that's a policy
which means that I can unambiguously see what's going on out there
so to reduce the uncertainty about what it calls
if there are sensory pressures.
There's a table in front of me
that's a light over there
that I will not be able to see in an ambiguous sensory context
if the lights don't work off.
So this is a little bit like the joke
about the man who was drunk
and he's searching for the keys
and he's searching for his keys out at the lamphouse
or the streetlight.
So that's the thing.
What do you do?
I am searching for my keys.
Did you drop them there?
No, I dropped them over there.
So why are you searching here?
Because I can't see over there.
That's a clinically based optimal response.
And it reflects about that we were part of the drive
for our good policies
and those which minimise our rigidity
or maximize expected agency.
And then once we found the good policy
or some of the action from that
the actual change in states in the world
down there beyond our sensory market blanket
and that will supply new observations
of what we do, our perceptual synthesis again
and finally, simplest academic explanation of what's going on
use our beliefs about states of the world
to a rollout simulator
another future of another policy
to set the policy that minimises the risk of non-rigidity
to set the action and so the perception action
or the action perception cycle continues
on and on and on
all in the service of minimising risk and rigidity
minimising expected surprise
or negative free energy
which is just uncertainty
in physicists also called empathy
but you can remember this as putting these two things together
it's just minimising uncertainty about the future
where that uncertainty includes preferences
that I feel familiar with.
So that's the basic story in terms of
what is this functional of beliefs that we want to optimise
and this is a horrible slide if you don't do that
but again, please ignore the equations
I just wanted to show you how easy it is
to take away from these equations
and end up with a formism
that people have been working with for centuries
or at least decades and decades
so if you are a mathematician or a physicist
you will now recognise why this quantity is called free energy
it's basically an expected negative lot probability here
which is called an entropy
and then this quantity about putting together is the energy
so it's basically the difference between an energy and an entropy
so it's the energy that's going to do the work
and it's free energy
but just by shifting these things around
or grouping them together in a different way
we can interpret it in terms of opacity and accuracy
as we've just described
so all I'm saying here is there are different ways of interpreting these quantities
depending upon the words that you use
the constructs that you know are taught
and you use in conversation with your colleagues
they're all equally mild
another nice example of just switching things around
here I'm taking this over here
this over here
means there's another interpretation
of splitting this uncertainty
minimising the capacity of good policies
or expected energy here
we can actually carve it or decompose it into another pair of quantities
called epistemic value and expected value
so let me show you how that works
precisely let me show you
how people have already been using these constructs
these quantities in their work before
if we just focus on these two terms here
what this Christ wants to do
is essentially the expected difference
between beliefs about what's going on out there
if I had some observation in the future
relative to the beliefs about states of the world
without those observations
so what that means is
this corresponds to the salience of the policy or the action
it tells me the amount of uncertainty I am reducing
or the amount of information I have gained
but if I looked over there
that's a good sort of thing over here
so this quantity has been used a lot in visual neuroscience
found in visual searches and salience maps
in terms of the best place to go and sample the world from
it's the place that minimises your uncertainty
or that's invited to your information gain
that has salience, epistemic afforens
it's also mathematically exactly the same
as the mutual information
or the mutual predictability
or the shared variance
between the causes, states of the world
and the consequences, the outcomes that are generated by those states
so effectively what we're trying to do
is to help heat our world
either visually with eye movements
or literally with our skin sectors
by filling for example the layout
of a new hotel room in the dark
testing hypotheses to feed your way around
or sampling it to leave
those sensations that tell you
no, this is a table, not a bed
but you have to have those hypotheses in mind
in order to reach your uncertainty
and the hypotheses that you are entertaining
and in doing that you are increasing the mutual information
between what you feel and what caused those feelings
so that's a very important aspect
of this uncertainty reducing imperative
this free energy functional of beliefs
let's make things a bit simpler
so now I'm doing what I promised before
I'm going to get back to the value of the function
but if you remember before I said
the difference between the value of the function
and the free energy functional
isn't one is belief based
and the other is not
I can actually convert the belief based scheme
into a value based scheme
by removing uncertainty
so the first sort of uncertainty that you're going to be
is basically ambiguity
I can assume that our creatures out there
that can see every hidden state of the world
there's no sensory noise
there are no hidden states of the world
and what I see and my sensory organs
my observations, my mountains
are the things that are observed
and our essence become bones
and the bones become essence
and what we are left with
is just the divergence of the difference
between the predicted and preferred outcomes
these are just our risks again
so this is risk sensitive control in economics
also known as KL control
because this is a KL or Kulbaki but
divergence
sorry not for control theory
but it's KL control economics
this sensitive control
what it tells us is that this
risk sensitive control
is basically what is left
if we remove that ambiguity
let's make the final move
and actually take away ambiguity
so now not only
sorry let's make the final move
and take away the risk
having taken away the ambiguity
so by taking away the risk
what I'm saying is that I am equally uncertain
what will happen if I do that in the future
and if I take that away
we end up with just this term here
so I'll remove this now
and now I'm just left with this
so what if this one's just expected utility
so this is what economists use
to score the probability
of choosing this policy
and put that policy
in the absence of differential uncertainty
both in terms of ambiguity
but also in terms of risk
and there's a deep history
to the effect of the utility
and the expected value
both in economics and in behaviourism
and in the enforcement layer
based on exactly the same idea
and some reward or function
that can ignore uncertainty
and then you will see the policy
of action selection
being completely described
by this value function
so the purpose of that
was really to illustrate
how in general
belief-based formulation
of the thing that we are trying to optimise
mainly maximising evidence
basing model evidence from models of the world
or minimising our uncertainty
through active palpation of that world
are generalisations
of things that we have all been working with
for possible action
but you only get to these special cases
if you remove uncertainty
so the belief aspect
is now to the point that we talk about value functions
just to make it very clear
for those people who haven't come across
information gain
or epistemic value before
I just want to give you an intuitive example
of what it means to reduce
to choose actions
that dissolve uncertainty
even before you know what's going to happen
so imagine you are driving a car
and you are looking around
in the narrow time
and you now have a choice
you are stopped at a traffic light
and there is a filter on this traffic light
that could be pointing right or left
and you can choose to have a look over here
or you can choose to look exactly at the sign
now if you are wondering about driving
you are going to have a 50-50
belief posterior belief
or prior belief before looking over here
that the sign is pointing to the left
or to the right
and if you look over here
then you are not going to change that posterior belief
so it doesn't matter whether the sign is pointing to the right
or to the left
looking over here
won't resolve any uncertainty
you will have a 50-50 posterior belief
whether the sign is pointing this direction
or in that direction
so this is an example of a policy
that has no epistemic value at all
contrast that
with the situation where you are looking directly
at the sign resolving an ambiguity
and getting very precise sensory information
so now if the sign is pointing in this direction
then you will be 100% certain it is pointing this direction
if the sign is pointing in this direction
then you will be 100% certain it is pointing in that direction
and you know that
and then that before you even made a high movement
so that is basically what this
k-r divergence
this epistemic affordance
this salience
this information gain means
you can if you know the way the world works
and you know and have a journey of what are the consequences
of your act of sampling of that world
you can work out in advance
what the best move is to make to reduce your uncertainty
and that is mostly what I am going to say from now on
rests upon
a fundamental imperative, an epistemic imperative
that is certain to reducing self-imperity
so that is all the hard work done
now I am just going to see some pretty examples
and simulations to show what it looks like
in simulations
and hopefully convince you that you have seen
a lot of this phenomenology
in papers indeed possibly
in your own research
I should say
you know I made a joke about the mathematics
and the formula before
but perhaps I should
excuse why we use the mathematics so much
there is a simple reason
if you really want to understand something
as Richard Feynman used to say
you have to be able to build one
and to be able to build a little creature
that does the paradigms that we ask about subjects
or our experimental animals to do
you need to be able to write down the software
and you need to be able to write down
the mathematical formula
upon which the software are generated
so that is our motivation
really to create little in silico
in silicon regions
that we can expose to the same experimental paradigms
or lesions
as real creatures
and then see what this belief I've dated
this active infant self-emphasizing looks like
and then we can see the same kind
of empirical phenomenology
in real creatures
so that's the excuse or the motivation for it
but it does require you
to commit to very particular
and well specified models
that are used by creatures
living systems
when explaining their paradigm or their world
a very general one
again please ignore the equations
we're going to walk you through with the graphics
on the model
is called a Markov decision process
so with this single and same model
we have modeled an entire range
of different kinds of behavior
ranging from
waiting games
to foraging in a team
that's what the bats will do
through to reading
we'll see exactly that later
through to active curiosity
and problem solving
so many different kinds of paradigms
can be modeled with this one very general
generative model
so I'm just going to briefly take you through
to give you one worked example
just to give you a feel for the simplicity
in which you work
you want to use these kinds of models
to simulate your paradigms
so the idea is
we need to generate outcomes
things that can be a creature
or something like me
would be able to observe
sea, air, field
and these outcomes
we're going to say are going to be generated
by hidden states of the world
they are hidden because they are
not directly observable
we can't observe our sensations
we can't see them
directly because of their sensations
so they're often infertile
either latent or hidden states
and they have
a narrative, they have dynamics
there are successions
and transitions of hidden states
so if I'm in a particular hidden state
at this point in time
I will be statistically at this point
at the next point in time
and so on and so forth
in the need of hidden states
each one of these states generating an outcome
must time ticks them off
and the mapping between
the hidden states and the outcome
is just a white bit of nothing
it's the probability of getting this outcome
here in this particular state of the world
that's usually left by a hand matrix
now clearly
the way that the world unfolds
these hidden states
depends upon how I act upon
the hidden states
the hidden states of where my eye is pointing
determines
what I actually see
so we imagine that some states of the world
depend upon
policies
in other words the transitions between
this state of the world and the next state of the world
at the next time point
encoded by a probability transition matrix
beaten
is a function of policy
we've just said that policies
are determined by
our prior preferences
by states
and eventually then the prior preferences
by C
and they will have
some precision
some confidence associated
with that
I won't talk about that very much
but it is interesting because it looks
very much like
don't be the sponsors of the brain
and I'll show you a brief example
of that later
and finally I just have to specify
beliefs about the initial states
or probabilities of the initial states
and a few hyper parameters
that statistically parameterize it
and with that model
I can go all the way to anything
within reason
so toy model of all that
anything
furthermore
if I make some simplifying assumptions
about my beliefs about all the unknowns
the key unknowns of course being
the hidden states of the world
generating outcomes
and crucially the positives
so these are the two things I need
to
infer
four good beliefs about my minimizing
that
by optimizing that free energy
or that evidence you're about
I'm also going to
think about optimizing the confidence
of my policies
the important thing here
notice
that we're casting behavior
here
in terms of forming beliefs about
what I couldn't do
and then just selecting action
from the most likely
or the policy that I think I'm as likely
to be pursuing the model
there's sometimes known as planning
as inference
so it's casting action
as a process of inference
so you actually
if you subscribe
to this formulation
the choice
on the selection of what to do next
is an active inference
it's inferring this is the most likely thing
something like equal to
in this belief state
so I'm going to be trying to involve that kind
of uncertainty over the work towards those
more preferences
and you can write all of these
particular generalizations
and as prize
in this project of logic
if you
then just
apply something
this is called a new field approximation
this prioritizes beliefs
with
normal forms of reverse distributions
you can then just go
and get some of the shelf
mathematics
to describe the belief argument
and the message passing
that having that
sort of general model
even assuming you as a brain
from my perspective
even if you're not a mathematician
that must be from your point of view
possibly not from your perspective
but from my perspective
the results are remarkably simple
and more importantly
not very very similar
to the dynamics
of belief update
in simplified versions
of pregnancy
so remember before I said we will just
three things we don't know in this model
state of the world
policies apply
and the position of confidence
placed with those policies
and it turns out that the
solutions
that optimize that free energy
functional
can be expressed
here as a non-linear function
of linear mixtures
of beliefs about the past
of the future and observations
now and this starts
very much like a very simple neural network
model
a sigmoin firing activation function
operating upon linear mixtures
of activities elsewhere
in the brain
a very very simple expression
that now starts to
provide a metaphor
for neural responses
and belief updating
as encoded by neural fireworks
here an expectation
about being in a state
one state or another state
notice also this implies
expectations
about the past and the future
so written into this
gender model
is an elemental form of memory
and perspective
post-diction and prediction
of the future
so there's a sense of time
and progression implicit
in this update
if we look at
policy selection
it's simply a softmax function
of this expected free energy
of goodness for policy
and this is a passive softmax
response rule
used in economics
and much of reinforcement learning
interesting with the confidence
here
looks as though it's updated according
to something that's very similar to a reward prediction
which takes us off
in a very different direction
in the direction of dopamine and the relationship
of reward predictions
but I want to move on to
optimising the parameters of this model itself
and again
it's very nice because
with the update rules and solutions
that optimise this free energy function
nothing exactly like
heavy learning
so you have these functions
that have associated term here
can't see this here
because this is the deep one
but if we were looking at the A1 and CB
I would come from the states
carrying together as a product
a decay term here
and which is accumulated by building
a connection sense
and then decay again as a function of time
and then finally we have
our action selection here
with very simple rules
you can start to engineer
or propose a very
crude
or coarse function of that
observations come in say
visual cortex
they are used to update
beliefs about states of the world
so they have a countless of time
and these beliefs are then used
to evaluate the goodness
of a policy in terms of expected free energy
and risk and ambiguity
and you can code it again
the front part of the race
of basal ganglia
cortoformatic
looms
where the confidence in these policies
may be mediated by safety
in the ventric technical area
and then they generate the next action
that changes the world
gives you the next observation
and so the cycle continues
the very crude
but relatively simple understanding
of the potential massively that you get to
so here's
I'll close down with two examples
one a very simple example of origin
in a maze
and then we come to
a proof of certain many of our advances
in deep
generative models of this sort
that have been used to construct things like
language comprehension and reading
so this is an example
I don't need to
go through it in detail
in brief
all we have is a little rat
in our house
in a teammate
and it lights rewards
and it's got two moons
it can make two moons
and it doesn't know whether the reward is on the right
or on the left
what it also knows though
is that there is an instructional
key at the bottom of the maze
that tells it
whether the reward is on the left
or the right
so it presents an interesting choice for us
it can go
to one arm
and once it goes to one of the two rewarding arms
it has to stay there
which means that it can go there
and get two rewards
on 50% of the time
or it can go there and get nothing
on 50% of the time
or it can go down here
to find out where the reward is
and then get
50% probability
the reward will be a half the time
so the expected value
is exactly the same
but
by going to the instructional key
the epistemic key
it can immediately reduce
the epistemic part
which means that
if this maze
was minimising
it was optimising
it's expected
so it should go
if we simulate those equations
on the previous slide
when the journal took off
which I've written down here
for this parallel
it should go
and get the epistemic key
and then go and get it to reward
and indeed that's what it does
so it starts off
what I'm showing here
is behaviour
of over 32 trials
where the reward was
on the left or the right
and the policy of the terms
the outcome
the amount of reward it got
and beliefs about
whether the reward is on the right or the left
in terms of the addition states
what I've done here
is after switching the reward
after the first couple
of presentations
I then left the reward
on the left hand side
I want to see what's going to happen
so initially
as we might anticipate
the mouse goes
and finds the epistemic key
there's always this uncertainty about what to do
and then indulges
in its risk
of those behaviour
so then chooses the pragmatic
preferred option
by going straight to get the reward
and as happy as it could be
however
as time goes on
it now learns that
in fact the reward is over there
all the time
so now the epistemic value
of that instructional key
gets less and less and less
it's resulting in less and less uncertainty
because it's increasing in certain
that the reward
is on the left hand side
changing on this experience
with head on learning
learning about these initial states
that are heavy and sparse
so at what point
it changes its preferred policy
and chants to a pragmatic
exploitative policy
so it's a natural progression
from
exploration
to exploitation
but it's purely
a reflection
of the fact that we are using the belief
based function
because the goodness
of the thing to choose
depends upon my beliefs
and my uncertainty
whether I need to get right back to certainty
or as a search
it depends upon the need of a search
and of course
they are very familiar with the fact
that there is no need to search
as they are strained for
that expected value
and to engage in exploitative behaviour
this slide just summarises
at the same point that I've been making
so
basically learning
underwrites confident
policy selection
and that confidence is reflected
in this precision parameter
which is said to not like don't really
add it in deeply and stimulate
time-to-time updates
of this parameter here
as long as it's exactly like don't really
we can also look at simulations
of need-to-peak updates
of the experiment in the trial
so it's seen that it sees this
making value
because since it sees anything
it has to iterate these equations
in order to
find the days optimal
solution
and that looks a lot like
an adventure-related potential
in that journal of physiological research
and interestingly what happens is
it was less belief updating
when it's more familiar
and confident about the environment
to get an attenuation
of these responses
but an increase in the confidence
because it knows exactly what's going to happen
and
what it expects to happen
it does indeed happen
and how it goes and it stronts
its knowledge about where the reward
is
so using that different example
you can tell all sorts of stories
you can tell a story
about the representation of the future
and the past
so this is the beginning of the trial
the first one, the second move
and of course as these beliefs are updated
what are beliefs about
what future consequences of action
now become memories
of our past
so there's an interesting shift
of time and table frames of reference
that means that things are
what's a prediction
that becomes very interesting
accumulating beliefs from trial to trial
it also allows you
to think about
the approach responses
to the things that you would ultimately choose
as opposed to things that you are
not going to choose
and there's a nice
literature in the empirical
papers
showing exactly this form of saltation
divergence as time progresses
in terms of selective responses
shown by these
expectation encoded
simulated
neural populations
that mirror
or reflects exactly
the empirical results
we can even plot
these responses as a function
of where the house is
and what emerges from this
kind of architecture
are place levels
that sometimes are very
unartiguous
for example, the two rewarding locations
sometimes are a bit more
unartiguous
we can also perform simulated
on-board experiments
especially negativity experiments
so
these are the same results that I showed you before
but I'll now tell you
a different story about them using
a different language as if I were
an electric physiologist
doing on-board paradigms
so what I can do
is to believe updating
when this is from our scenes
the same stimulus
when it's familiar with it
and when it's not familiar with it
it does the same
response, selects the same policy
so the only thing that's different
between the perception and the actual
is its beliefs
that it has accumulated
through experience
and if I associate this with a standard
stimulus and this with a normal
stimulus
we can comparably update and take
the difference and indeed we can
reproduce the phenomenology
of the next batch of negativity
do the same thing
with those simulated
main responses and show
a classical phenomena
in single unit electric physiology
in dopamine
cells, namely a transfer
of phasing responses
from the rewarding
queue, the ad-condition
stimulus to the structural
epistemic queue which you can think of
here as the conditioned students
so again
nothing's changed here
other than I've told a slightly different
story about the results
that emerge from this little simulated
right and all of that lend
a degree of constant validity
as overall thesis
that everything is in
the service of self-evidencing
maximizing evidence
and I don't model the world
and selecting actions
that minimise uncertainty
namely this phenomena of negativity
so I'm going to finish now
with a very quick run-through
of exactly the same
technology and ideas that
apply to slightly more sophisticated
generated models
of a sort that people might use
to understand language
and generate language
in this graphic
not because it's educational
but because
we spent a long time drawing it
and again that was a joke
it's a nice graphic because
once you bring
down formally
what you think
is a thriving message
passing belief updating and behaviour
you can now
extend that formalism
by generalising it
to
hierarchical structures
and when you do that
you start to see
lots of emerging behaviours
that now look a lot more like
the kind of behaviours that psychologists
study in human beings
so what we've done here
is taken our standard
little MDP model
space-kicking program
time-on, time-to-generating
metrics paid
and our can here
have the transitions
carried by the B-metrics
the 10 problems of policies pie
that are informed
by the expected theology
gene equivalence of those policies
what we've done is put another one of these
on top
crucially
it operated
at a slower time scale
so
when it comes from
the process
of the higher hierarchical level
now
cause things that don't change
on a faster time scale
there are lots of things we could have chosen
we could have chosen
the likelihood of major seats
or we could have chosen
the likelihood of a particular policy
we've actually chosen here just the initial set
but it means that
the outcomes from the genetic models
are in-plane
for the duration
of the same transitions at the lower level
and you can imagine
putting a faster level below this
a faster and a faster one
so you're writing in
you're baking in
to your genetic model
not only a high model
depth or abstraction
but also
a deep diachronic
one time depth
or abstraction
of temporal scalars
over time
and of course that's what we need to understand language
I will have a representation
of a sentence or a phrase
at one level
and that's the same sentence of phrase
from the beginning of the first phony
to the end of the last phony
it's the same object
but on a faster time scale
that this current word
will change
the word from the beginning
of the words
first time frequency died
phony possibly to the last one
and as we pinker
lower and lower and lower
we now generate faster and faster dynamics
using this kind of model
so you may be asking
and that's all that this equation says
they're just a hierarchy generalization
of the first copy
used in the rat
into this deep diachronic structure
this is exactly the same model
and the reason I show this
and the reason I like this model
is you can generate this
graph
automatically from this graph
and this graph is known as a factor graph
they may not mean very much
to psychologists
but if you're a computer scientist
and you want to
design the message passing in the most efficient way
this is the design
so
what we're saying here
or what this figure
says
if you can write down the form
of your geratin model
you have automatically
written down
the message passing graph
and at some level
a brain must be using
in terms of connections
and passing messages over
these connections
for those of you who are interested
factor graphs are interesting
because they place the variables
on the edges
and the probability distributions
at the nodes
that's why we call factor graphs
so the probability distributions are
the factors are quite active on the margins
you can forget that
it's interesting to
remember
is you can generate these things automatically
and once you've done that
you can start to make little brains
that could actually be
and a lot of systems
or very large scale
silicon integration chips
for example or classical computers
Turing computers
so
once you've written down the factor graph
and you've learned the architecture
of the message passing
you can actually go to neuroanatomy
and as we're on the isomorphisms
in terms of the structure
of the dynamics
the terrible scattering of those
messages
in real brains
and it's an interesting
jigsaw problem to solve
but there are lots of immediate parallels
that we can evidence
when you just look at the factor graph
and you look at the textbook neuroanatomy
I just sketched out
some ideas here
we don't need to talk about this
the point is there's a very interesting opportunity
once you understand
what has to be
the computational anatomial
if you commit
to this
genetic model of erosion
and self-evidence and formulation
of belief updating behaviour
if you commit to that
then you've got that
necessary computational anatomy
you've got the empirical neuroanatomy
that we presume does this computation
so now you can start
to look for parallels
and assign different roles to different parts of the brain
so for example
in this instance
it looks as if
the nervous paradigm
contains labels
for horses for example
just on the basis of the connectivity
in reference to that factor graph
on a previous stage
but let me think about this by taking you through
conceptually
a genetic model
of a simulated agent
is doing a very simple form of pictographic reading
so here
there are no letters
but there are little icons
and the position of these icons
depends on a particular word
so
an icon can be
that comprises
each word if you like comprises two icons
therefore there's seeds
a bird
or a cat
and if
the cat is meant for the bird
that means the bird will flee
so that's the word flee
if the seeds are meant for a bird
the word feed
the bird can feed on the seeds
on the seeds
if however there's nothing
next to the bird
so the seeds are down here
from the diagonal corner
that just means weight
so it's a very simple little language
we've arbitrarily invented
and
the reason
for using this
pictographic form
is that the agent has to decide
where to look
if he wants to read this word
look at the letters in the word
it has to decide
where to look at
over here
has denoted by the locations
one, two, three and four
from the point of view of the genetic model
what does that mean
these are the states
the hidden states that you would need
to generate an outcome
so what would be the sensory outcome
well the sensory outcome
would be feeling that I'm looking
at positions one, two, three or four
or what I'm actually sampling
or foaming at that time
which can either do nothing
seeds, a bird
or a cat
but to generate those outcomes
I have to know
the configuration
of these pictographic letters
where I am looking
and I've introduced another
hidden state here
which is filling
presenting words in upper
or lower case
so with those three causes
I can generate any particular outcome
in a visual modality
and a proprioceptive
or feeling where I have
currently pointed my eyes
in modality
and because I have written down
the genetic model
I can use the standard
message passing
scheme of previous slide
to simulate inference
I can simulate what this
is a creature would do
in terms of foraging information
I try to understand what word it is looking at
but what I really want to do
is to do that with some deep
temporal structure
so diachronic aspect
I want it to remember the words in the seed
and from the point of view of the genetic model
generate sentences
or sequences of words
from the point of view
of servovenancy
inverting that genetic model
to recognise
what this word is
in the context of beliefs of our own sentences
so to do that
I now have to put together
four words or four different pages
if you like
and the four words
are basically sequences
of words here
typical of superscriptive sentences
flea-point, flea-point
and I classify those with an even higher level
which we actually do not want to show here
so now if I know the sentence
I know the sequence one
you know, flea-way, flea-point
and I know
where we are in terms of
which page we're looking at
I can now generate the word
I can generate the word
if I am now looking at information
if I am looking at whether I flip or not
I can now generate the outcome
and if I can generate the outcome
that means I can invert the outcomes
to make inferences of how beliefs
about the sentence
so I'm going to take that factor graph
that computational anatomy
and this genetic model
and then simulate reading
in terms of where
this page and law is
to try and accumulate evidence
to build postgeophilies
about the sentence it is reading
and the actual sentence it is reading
is flea-way, flea-way
and these are
the expectations
of the lowest level
about what is actually there
at the lowest level
and the key point
made in these simulations
is you can have
very precise beliefs
about
what you would see if you got over there
even though
you never actually got there
and these precise beliefs
come from this deep structure
so for example
you can see
that in the first
the first calendar
to the second word
and no point
because it actually samples
a stimulus that it either
sees or burns
it sees nothing on either
sample
and yet it knows
because it knows what could possibly happen
in terms of the alternative
and the structure of the sentence
the solution has to be
sees up here
and burns up here
and indeed its posterior beliefs
is hallucinating effectively
in a very positive and base-optical way
the existence
of these percents
even though we never looked there
and you see evidence of that
if you look in detail
the sequence of circadian eye movements
as they
form beliefs
they resolve uncertainty
their response when it is done in accordance
and go and get the next
sort of information
that will resolve uncertainty about
what this agent is looking at
I share the same results here
in a different format just to end of the slide
the separation of 10 plus gains
so
these are beliefs
at the higher level
about one of six sentences
that the
synthetic agent
was looking at
and notice
it's going to be right at the end
it actually resolves its uncertainty
about the sentence because
these two sentences share everything apart
from the last word
in no context immediately
it must be looking at these two sentences
because the first word is unique
to these two sentences
but the last word disambiguates
so this uncertainty
evolves slowly and it's been
slowly and it's only resolved
by the last word
in contrast
the beliefs about what particular word
I am currently looking at
develop much much more quickly
so these
converge
to a particular
posterior belief
and then that is
evidence for the higher sentence
based belief and then we start
again with a new outcome
a new outcome and a new outcome
that is hard to select with visual
impressions
and I try to get that in terms of
this separation of time scales
dictated by
and only by the belief updating
just want to make a point
a point again
what you actually see
in these
in cynical creatures
is very similar to what you see
as we are looking at for example
pre-secatted delay productivity
in the prefrontal cortex
shown here
in the raster format
looks very similar to the kind
of responses observed to the view of recordings
shown here in terms of the bar chart
furthermore we look at the deflections
associated with the belief updating
on a stimulus by stimulus basis
which is definitely
very much like the periscope
evoked potentials
during anti-vision in markets
and I just want to close by pursuing that
but by focusing on the responses
to stimuli
towards the end of the sentence
and I am going to play a trick
on this little creature
I am going to teach you a violation
or two violations
of a different sort
in the home of what we briefly seen
chemical responses you find
in cognitive neuroscience
namely
a pre-attentive like this much negativity
at about 100 to 170 milliseconds
and then a reorienting
novelty like response
and later
more indulgent response
700 versus a P300
associated with semantic violations
by changing
stimuli so there is a surprising
mean to the work
so I am going to do that
just by presenting it in other case
I am going to present it in no case
so this is if you like
the stimulus manipulation
at a low level
and I have shown the results
at a low level in blue
without the manipulation
and then probably the difference here
may be not very much like this much negativity
of the sort that you would see
if I
played you with a bottle of stimulus
in a stream of standard stimuli
without any differences
I would say another one of more semantic
representations
if I did the same trick
with this file
instead of just changing other cases to lower case
I now have to change the meaning of the word
to use the same stimuli
I now have a much more
semantic high level violation
and now the thing that recognises
the surprise
of the free energy
here is
first but also now
the second semantic level
but of course it has to wait longer
to get the evidence from the first level
to be surprised
to do with the belief updating to the sport
without surprise
which means that the difference weight
forms that are expressed
in the Paris film this time
in a regime that would correspond
to the EP300
so it's a very particular
specific example
but I use this
just to explain how far you can get
and understand the
classical results that are used
and have been used for decades
in cognitive neuroscience
with actual physiology
that can be understood in terms
of the computational architecture
and message passing
I would simply imperative
to minimise uncertainty
about the weight of the world
words and indeed how
can I work in that world
and this conclusion
is nice and summarised in relation
to my movements by Helmholtz
who was the farmer of many of
the
inferential interpretations
of the scheme
so each movement we make
the appearance of objects should be thought of
as an experiment designed to test
everything around us to correctly
the invariant relations of the phenomenon
of the forest that is the existence
of indefinite spatial relations
and with that
it remains for me to thank
the people of whose ideas I've been talking about
but most of all
thank you for your attention
thank you very much
exactly to the biological reality
so to clarify something
can we return to your first example
with the oral
and so I had two questions related
to this first example
the first one is
how in term of
how can we describe
the theory
the hundredth of the oral
why is
all come together
and why the world has
the belief that the prey should be
catched
it's the first question
and another one is related
and maybe it's how
I'm trying to resolve this problem
is the question is how
is active inference related to initial selection
and
because testing hypothesis is risky
it's time and energy
we're consuming
I mean that you are resolving uncertainty
you invest something
in terms of energy
and time
and so on
and what do you think about
how natural selection shapes these
prior beliefs to make them
more efficient in terms of survival
more complete
in terms of
complete
so to answer your questions
we have probably three questions there
so I think we're
going to start with the first question
so the first question
how do I account for
context for survival
what determines the best
sort of behavior
when I'm very hungry
as opposed to when I'm just eating
so in this scene
that all of the answers
usually result in
reduced to the form
of the challenging model
so that will be a nice example
of having a high mark for chapter 2 model
where
your prior preferences
will now become
conditioned upon different states
of behavior
so if I were to
now we're interested
that we are entering
the interesting world
of active inference
applied to the homistasis
bound spaces and intersection
let's say I have evolved
creating the next question
to have a genetic model
under the regimen
that was able to recognize
certain states of hunger
so that these
were good explanations
of particular gut feelings
of particular
particular
inputs from say
receptors measuring
blood sugar
and also my beliefs
about when I must
have something to eat
then if I had those
representations I would be able to do two things
first of all
I would be able to contextualize
my prior preferences
about what I think I would be doing in half an hour
which could be
being in a restaurant
or it could be continuing to work
or continuing to socialize
so you can contextualize
any behavior simply by
conditioning a parameter
of your genetic model
at one level
on both slowly context
dependent states at the high level
if you have a sufficiently
deep genetic model
and that leads to all sorts of interesting
issues you know the distinction between
homistasis and other spaces
so
I would imagine that a virus
unlike the alpha
doesn't worry about
whether it's hungry or not
in or just on let's say an
E.coli
doesn't worry about whether it's hungry
or not it just
assumes chemotaptic reagents
and
who can I
find a man
it's radically skeptical in this one
let's assume
let's use my
thermostat
that doesn't care whether it's hot or warm
so it just
immediately minimizes
it chooses
policies of a very trivial sort
which is just the very next thing to do
based upon fixed
fries and no change to the homistatic
set point
that's very different from having another level above
which recognizes a different
state
though would then actually change
the set point
from a homistatic reflex
to other spaces where we now start
to anticipate the causes
of our behavior for our
spaces
so I will go and eat something
before I need to have a clinical
monotonic reflex
so I think it's a great question
because what it speaks to
is a fact that we're not dealing
with simple general molecules
or the sort of temperature
for a thermostat or a virus
we're dealing with very different structure
that I repeat diachronic
in the sense of separation of temporal time
scales which are
the kinds of models which would be
necessary for you or me
possibly even a bacteria
but then the question is
where do those come from
because then I can answer that
by answering your third question
the model is just the prize
so the prize could be
of a form
of structural sort
how many levels does my model have
how many hidden states
so if you were doing machine
learning and deep learning
so using a very short encoder
you have a prize at least
and you say yes there are 12 hidden layers
hidden layer 6
has 217 hidden units
all of these are
formifiers and we believe
are fitting the purpose
and appropriate to the kind of
thing you want to classify
and then of course you actually have
the parametric prize
the actual prior expectations
distributions anything that you would normally
especially put in privately
so by model I mean prize
and obviously
there is an idea of an attribution of my tree
because the likelihood
just sits at the bottom
of these models
so if we get that
this graphic here
all of these are promise
the only time a lighter
becomes evident is right
in the pattern here
so all the interesting structure in terms of
depth and conditioning
and contextualization is a prize
structure and the actual
cost of a parametric prize
you apply to all of these variables
so that means you
me too or you
to your second question where do they come from
and
and again
you appeal to
hierarchical
difference
but now over
a more extended time frame
so from the point of view of
statistician
the way that you would
learn the good prize
for a particular environment
for a particular sorted data
via manifold learning for example
between 20 model selection
so now
you are selecting
the form of those models
then maximizes model difference
after a certain time
and if you
look for the physiological formula
lots of that could be things like life
as you'll see
I will be giving the lecture
I think it's shaped that point
towards the end at some point
the limit of change
we'll discuss this further
but probably more interesting I think
is neural development
to the next level
but as you've hinted
all of this takes place at an evolution time frame
so the way
mathematically we bring all of these things
now under the same
principle
is to interpret natural
selection as lazy model
selection
and that's actually very easy to do
but not only that but in the past 10 years
people have now started
to interpret
in theoretical biology
the models or the
dynamics of natural selection
in terms of Bayesian filtering
so for example
the regulator of dynamics
or the replicator equation
or the price equation
these are
very easily
shown to be spent with a
few simplified assumptions
they can be shown to be
Bayesian filters or Kalman filters
so what you're saying is that
evolution
is just nature's way
of doing basic model selection
to change or to
select those models that
prior structures was phenatized
that have the greatest evidence
what do you think by evidence
they're likely better than they are there
they're likely they are
the best model for that
environment
so from the environment's point of view
it is tested by hypothesis
that this is a good fit
for being the environment
or this phenotype
the evidence
that it is a good fit
for being the environment
corresponds to adaptive fitness
is scored by the time interval
of the variation of the energy
because that's the balance
of the ability of that
model being the right model
given the experience
of the environment
so the answer is
it all comes down to evolution
but it's exactly the same process as operation
very very very slowly
and in that context you wouldn't think about
the phenotype as being
the individual thing about cost-specific
so cycle of life
with one selection of critical
over a developmental cycle
so
thank you very much for the talk
I have a small question about
is there a small body
about human evolution
is it possible in terms of your theory
to describe
just to describe and explain
the huge quality
difference between humans
and other animals
and is there
any hint
that you think
or have solved this problem
thank you
that's a difficult question
I think it's a short answer
because I think it speaks very much
to what we were just talking about
I think it's just the depth
of the challenge involved
that distinguishes the kinds
and structures
meaning you
as opposed to say a dog
as opposed to say a fish
as opposed to say an insect
as opposed to say a single-cell organism
so just the distinction
between single-cell organisms
and multi-cell organisms
that immediately speak to a hierarchical aspect
and an ethnic aspect
but if you take that further
I just think what kinds
of hierarchical
extensions
would make you you as opposed to
a bacterium
or the me as opposed to a bacterium
I think the answer is
in the span of death in time
I think that's basically it
I think it almost reduces
to the very simple observation
that you and I plan
and the bacterium doesn't
and we can argue about
whether the bean delts or the dog does
but certainly the bacterium
during its chemotaxis
does not plan
it does not plan to go to school
or to find birthday presents
whereas we do
so what do you need to plan
to plan to select
various policies
which means you have to have a journey
of the future the consequences
of those policies
so that's just simply a statement
of the fact that we
infer our world
under journey models
for example death
they have a horizon that goes beyond
the present
it enables us to plan
and to think about
what would happen if I did that
now because as soon as you have that capacity
you now have to make a choice
so the bacterium doesn't have a choice
about what it does but you and I do
and I think that's a
qualitative
distinction
which again is just a structural
is a thing which would distinguish
high local life from low local life
it's not the same
where better the bacterium
or the virus
for any particular
economy or environment
there will be a free energy
expanse
so viruses are great for
fitting and inferring
their environment
just as the person said
about the cell
so we've been very doubtful
and after compressing down very very small
you will not do very well outside
the cell
but the virus will not do very well in the university
so it's all in relation
to
the way that you are
essentially puts from your environment
at your time space
and once you acknowledge that
then there are lots of
global minima or a global answer
that correspond all sorts of different
ways of being both in terms of
species but also in terms of
species then you can see
now an easy tax on
in terms of high local death
and sophistication and particularly
temporal death
that I think comfortably separates
us from other animals
from other animals from plants
from plants in certain organisms
Thank you
Mr. President
thank you very much for the lecture game
as I said in the very beginning
I would like to
make a little bit away from
scientific point of view towards
theoretical future prediction
whenever you think it is possible
for us to
fit current state of
psychological outlooks
towards personal belief
motivations and beliefs
into this key that you are describing
like saying that those
beliefs that are
wrongly believed to the person
and they could also
be in the states of the person
which is not recognising you know
and if so
is there a possibility of point of view
to create like a human impact
software
which will be possible to
predict
behaviour of each kind
of certain person in certain conditions
by that human kind
of enormous power I was having
to manipulate those people
Thank you
Right
So I think
a fascinating question
I just want to give more aspect to
the difference
Perhaps I will just take a practical
form
and take your question
as a psychiatrist
because then it becomes very important
in terms of understanding
made beliefs and false beliefs
and the remediation
of that false difference
that may or may not be
a good thing or a bad thing
but certainly being able to do it
and understand what you are doing
is practically very relevant
in a therapeutic confidence
in the quality of the quality of our treatment
by Christ
So the idea here is that
this psychiatric symptoms
can be thought of
as a form
of false
or aberrant influence
So a remediation
will be basically believing
in this theory
that something is there
when there is an essential evidence for it
that illusion
is having a conviction
in some state of affairs
usually in personal
for which there is no evidence
that a law person
would accept as an evidence for remediation
You could even take the stupid things
like anorexia
and dysmorphophobia
holding beliefs about myself
which have no evidence
when I look at myself
in the mirror for example
I see myself as fat
and furred
but I am fat even when
you might see me as being very thin
So you can certainly get an enormous
variety of
posterior beliefs
I would say they are quite accountable
because you bring them to
a certain number of fears
like death, hunger, whatever
that's why I am asking
so those of us who are not
accountable to me there
can be brought to
a final number of
accountable factors
Yes
I agree with you
there will be mathematical reasons
based on competitive evidence
that makes that true
I guess what I really meant was
the number of ways in which you can
I can deviate from you
are large but the number of dimensions
may be quite associated
So if that's the case
if there is an opportunity
and evidence for
a better belief updating
then
people have been focusing on
how that could happen
It seems that the most important
synaptic mechanism
that enables that
sort of false inference
is in the
precision afforded to various
sources of sensory evidence relative
to prior beliefs
So if you are a psychologist
there is an attention
So now the game becomes shifting
from how we form our beliefs
or our data beliefs
to how we attempt to
different things
and we were talking just before
about this being the same
mathematical problem as
they obviously think
that there is an effect
to any millennial society
and when you use the social media
becomes big data
to select
what you
accredit or assign
in precision
that enables that sort of
information to update your beliefs
So I think in terms of
understanding the mechanics of belief updating
and intervening
in that either therapeutically
or for commercial reasons
like in advertising for example
it's probably going to be all about
how you can get attention
and what you mean by attention
and the physiognomic mechanisms
of attention
and also
just gaining some high level
control of attention to be able to
mentalize it
So there are certain forms of attention
which we have known, not because of I data
but any control over
which it may be possible to learn to control
with suitable mindfulness
for example
So can it be expression
so this is the phenomenon when I move my eyes
as I look around the room
During the
motion of the eyes
I do not see the optical flow
I don't see the words sweep
or pass them
All I see are the static samples
that I then integrate into a coherent
coherent theme
So that saccadic suppression
is a very interesting example
of temporarily ignoring
or reducing the precision
of the lighting of mapping
here
in a very, very
tentatively precise way
which you cannot
affect by the least higher
in the model
Now imagine that you now had a connection
in the generative model
so you felt hungry
talking about contextualizing before
so it was some higher level
representation of self
or myself saying to self at this point
you could actually get eaten
and then suspend
that saccadic suppression
so you could choose whether to see
the world moving when you move your eyes
or not
In fact, to a certain extent you can
this isn't the old hand that was driven
you can see what it would look like
and you would push the side of your eyeball
and you see the world shift
So there are ways of getting around it
if you have a sufficiently deep generative model
So my question
I'm not sure what the implications were
in terms of the ethics of it
or the localization of that
which is another issue of course
but just in terms of practically
what you would be looking at
I think you'd be looking at the process
of the media and the precision
and the degree of the message
passing between these hierarchical levels
that would look very much like
what you could use for a change
or what you could ignore
which is to get control of another
for yourself and the possible
presentation that you may well
have in your own strategy
Thank you. I wasn't talking
about the therapeutic effect
later. I'm probing this
position. I was talking about
the investigation of this system
which is still being bad
you know
Can you give me a concrete example?
Just
Well it is the same thing
like as you said
advertisement rate so it's not
kind of changing human attitudes
explaining how bad
fast or bad or whatever
you know, not patriotized
but that just
predicts
what kind of
disorder
will react to this kind of
like, what will be the way
that people with these or that kind
of disorder, not psychiatric
kind of
to this certain message
like the hatred, not patriotized
that's a bad one. So will they still
die? Will they still like
will they say no? Will they say yes
I'm talking about kind of like
prognostication model not improvement
but just improvement of the
management, not improvement of
agents themselves. So what was
in the economics context then?
Some should have politically
because it's a
digitizing or whatever
I don't know because
this particular
mathematical formulation hasn't really
got that far. It's penetrated
theoretical biology
in terms of multi-agent games
and ecological structure
and anthropology. So there are
issues of how much of an agent
he finished constructing and
constrained their own conversion
behavior
and there have been
sort of multi-agent simulations and the
number of cells organizing different
patterns and conditions
but nobody to my knowledge
has taken these
variational free energy solutions
to model
markets of advertising or
gene political events. It's a
really exciting opportunity but
to my knowledge it hasn't
been done. It's only been
initially addressed in the past couple of years
in ethology
and in
literature in psychology
and in all the genesis.
Thank you very much for
an interesting presentation.
I would like to ask several questions
concerning Markov processes.
First of all
the principle feature
of Markov processes
is that the future
is determined by the past
only by the present.
Is this factor
resulted from the application where
or is only the simplification
to be able
to solve mathematical problems
associated with
problems solved?
The second question
is on this slide
devoted to
activity
and currents
there is two molecules
entropy
and energy.
Energy is non-dimensional
energy is dimensional
how do you explain the
difference between them?
And the third question
we're really
solved ordinary
general equations to predict
the area of
Markov worlds.
So a few easy questions
there.
We'll probably be a physicist.
Can I answer your
answers?
So a really interesting question
but what do you spend
on Markovian
dependencies
that are implicit in the Markov
decision process
for convenience?
Or do we think
or is one thing that these are
the only kinds of generated models
that fit for the universe
in which we live?
I think
technically
all of this maths
inherits from
the treatment
of random dynamic systems
in which case the
Markovian properties
are true and
that's where you start.
So
my answer would be
they are not
a device of mathematical convenience
they are actually dating
to the underlying premise
and that also enables me
to stress the third question
what we are basically
solving here
are not ordinary differential equations
that would follow from
a stochastic differential equation
that you can treat along
with others
that could be applied to the density
dynamics. For example
Fokker-Pak equation
on the density dynamics
on a straight wave equation
or a master equation.
So much of this really
all of these simulations are actually
created to sense on funtionals
where there's a function
a probability distribution
very much like the Fokker-Pak equation
so that's the belief-based aspect
that you can get away
from creating flows
on functions of states
or gradient flows
on functions of states
but in terms of now
in terms of gradient flows
there are functions on beliefs and coding
like states. It's a big technical
if you'd like to discuss that further
in the email I'll send you
something which I've never
done so much from here with you
that takes you through those arguments
very precisely.
The interesting thing
though
is coming back to the first
question
because clearly
this particular
MDP is semi-markoval
I have written the Markoval property
because I've now
got two times here
in place here
so in practice
what happens with
these immensely complicated
itinerant captive sets
that we use as a mathematical model
of
self-organizing systems
like biological systems
when you summarize it in terms
of a Markoval-like
process
in the sweet space
and in the sweet time
it looks like it has now
acquired the semi-markoval aspect
so it is interesting
that from
the purely Markovian
physics of it
due to the complicated nature
of the systems that we
like to study
when you find the
free-engine optimizing
models that turn out to be
hierarchical with
that
breaking the simple Markoval
into making the same Markoval
so
at that point I think the
disputed model of decision process
has become a mathematical approximation
to what is actually
a continuous time Markoval process
that looks as if
it's lost its simple Markoval
property because it's just become
so itinerant, so complicated
and so structured and so
interesting from a biological
perspective.
