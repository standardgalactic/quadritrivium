Hello, welcome everybody. It's November 1st, 2023. And we are in the closing discussion
section for this first instance of active inference for the social sciences. It's been
a journey. I'm sure we'll have many fun things to talk about and explore today. So Avil
please take it from here and maybe give an overview of what we're going to do and talk about today.
Okay, so this is the conclusion session for course on active inference and for the social
science. We have talked extensively about active inference, maybe less extensively about for the
social science parts. So the goal of the session would be basic to assess what we talked about
and how it is relevant or not to the practice of social sciences. Basically, we will, this is a
discussion session, so there is no clear plan, but I'd like to address how formally active inference
accounts for agency and normativity and identity as a kind of integrated phenomenon,
how it can compare our ads to our grounds, our clash with, I don't know, sociological and
political model of agency and of social evolution and of etc. etc. All the topics that we addressed
which are numerous and discuss about the plausible future for active inference, what it can be used
to, maybe what it will be used to, certainly how it may change and how it's relevant to the
discussion. So that is the crux of it. We have brought in Alexi, who is a philosopher interested
in social ontology, specifically the study of social kinds, which is from Cairo's research,
and I do not know who Colin is, but he's with us. Hi Colin. So how should we proceed,
Daniel, what do we do? If you'd like maybe pose a specific question or prompt, which could be
preceded by a statement, and then we can all hear everyone's voice on that. Okay, so a good
question would be, active inference describes agency and normativity and identity as a kind
of integrated phenomenon. I think we should go over how precisely it works. So yes, let's do that.
I will find some, do you say, illustration that will make it easier, but let's hear people
start on that, please. Can you pose your question just a tad more clearly? How are agency, normativity,
and identity addressed separately and together in active inference? Mal, go for it. So I think we'd
like to look at things in terms of interrelations. In active inference, nothing is defined by
itself. It's defined in relation to other things. And this definition in relation to
other things also defines the types of constraints that will be pushed on the thing which is
separate from other things. Once you have this, you necessitate these interrelationships to be
formative, ontological, and fundamentally contextual. So nothing, no relationship is perfectly
reproducible across a different context. It will take on a hermeneutics semantics, given the
exact context of the spatial temporality of the entities. Those are some first thoughts. Does
anybody have big objections to what I just said?
Okay, so let's start.
Yeah, please continue. Sorry.
Let's start with the concept of agency, for instance. Agency is just action selection. So
agents are modeled. They have a generative model, and they use it to predict sensory inputs based
on possible actions. They try to minimize the difference between predicted and sensory inputs.
So they're just trying to minimize free energy. And this minimization is fundamentally due to the
relationship of constraints in their environment. So let's imagine that I am an individual who,
sorry, I saw a comment and I didn't. So yeah, so you have an individual that tries to exert
control over the environment. Now if you scale this in nested structures, you can try to think
of power structures and how agency within those power structures is modulated by the
different kinds of constraints that are both embedded within the environment itself,
within the materiality of the environment, and also within the normative aspects of the nested
structures, which pull and push an individual within certain paths through some kinds of
deontic cues. So that's how you get to the notions of encoding agents, beliefs and preferences
about the world within the generative model through a form of normativity, which is just
a higher precision over a specific type of outcome or mapping. So your prior beliefs here
come from different layers in the hierarchy, and these act as what we call culture or normativity.
I could start here if you want to say something, Aval. So I agree with what you said at a high
level conceptual scale, but I think it's important to be clear about what formally
governs the statement, because what we have formally is much more limited than
what we agree that interpretation could be. So can you see the screen I'm sharing?
Can you see the mouse doing AIDS? Yeah. Okay. So at core, Active Inference is a framework
that provides geometry for chemical systems. That is not a very straightforward way to put it.
But what we have is a system with a space of states, and we have a flow of the system. A flow is
a function that basically tells you where a specific point goes with time. And what Active
Inference says is that given specific patterns of demical coupling and of statistical dependencies,
we have agent-like behavior. So the simplest kind of the basic requirement of Active Inference,
of sorry, the French principle, which is a core motivation for Active Inference, is that you
have a demical system, so something with states and a flow and some noise, because we need noise
to get information. And it has a boundary in the middle of it that statistically separates
the external internal states. By statistically separate, I mean that every information about
what's going on there that is in there, it disappears when conditioned on there. So
of information I have about this, that I could read here, I can also read there.
And that's subtly different from a demical coupling, but this is formalism, let's not
get too much into this. And then you have more complex behavior when you can partition
sensory and active states, and your particle, it can do things. In this specific context,
we can write, basically, we can write a geometry for the fluctuation of the system.
And this geometry entails belief over external states. So these internal states, it knows
things in a sense about what's going on out there through its coupling, through sensory and active
states. And the flow it has internally, the way its internal states move, they entail
a displacement of their belief. And this displacement happens to be near optimal, given
base constraints, blah, blah, blah. And the real interesting stuff happens in the case of
strange particles, which are particles where, as you can see, there is no direct effect of
from actions, active states, to internal states. The only action you have is mediated by sensory
and external states. In this case, the active states themselves, so the policy of an agent,
it becomes the subject of beliefs of the agent. And if it becomes the subject of beliefs,
you can have statistical inference. This is the crux of the framework. And if you can have
statistical inference, you can have complex, multi-level statistical inference over re-reactions.
And those are, basically, what we call decision-taking or what we call planning.
So what we have here is a formal architecture that can derive the kind of complicated
agency, not only agency, but agency that is embedded in a specific conceptual framework
that is relative to the specific structure of an agent and their environment and the coupling
in between. All that is traced back, basically, to dynamics. So we have a proof of existence
that in the world that everything is dynamics. We can have agency, we can have complex decision-making
under the form of inference over one's own actions. And then you have complications to
apply directly, of course, because the world is likely not in its various form, a chemical system.
It does not have a list of states that are, okay, there is not a list of states that are
possible and that's it. And there is one coupling that takes those states themselves
and nothing can change ever. This is not likely to be the case. But we have a minimal model of
agency that is purely physical, that is purely based on the causal relationship in the most minimal
way we can possibly represent it, and this is quite huge. And this tells us, this gives us a
very, very strong prior over what we can, what is the stuff that agency is made of, and the stuff
that entity is made of, at least higher-order agency that we like. Think about here in the
social context is belief over oneself. And so to control actions is to control belief over oneself.
And this is this duality, this like dual aspect of statistical organization as a complex cognitive
agent that is, in my opinion, at the moment, given the capabilities of modeling and formalism we have,
the core contribution of active inference to social senses written largest in psychology,
neuroscience, like sense of social stuff, because it gives you a very strong prior
over what agency is made of and the kind of stuff that can exist out there
in the social world and the kind of dynamics that bring about its stuff.
So, but there is a quite big bridge to be made between the pure,
dimical system formalism of active inference and the kind of toponality evolution that happens
out there. And I do think there is a high level of precaution to be taken when we talk about this
kind of stuff. And yes, does anyone want to react or agree or disagree violently because I just
attacked the common creeds?
I'm sure I perceived an attack perhaps from what I understood of what you said, basically
you have information geometry. It formalizes a belief space in a sort of geometric manifold.
The points represent possible belief systems that an agent can have. And the distance between
the points in the space can be interpreted as a measure of how different two belief systems are.
And this is necessarily tugged by the priors given by the environment, which also push
the agents to act in a certain way, given the type of thing that it is in order to maintain
itself, given the actions that it knows it has available.
And this becomes normative because of the strength of the attractors within the belief
space, which become the geometric landscape basically. So we can sort of model the attraction
through the curvature of the space around the attractor. And so high curvature means a strong
normative force, which pulls the agent to adopt a certain, I like to say social scripts because
that's what I've worked on, but you know, any sort of policy and or phenomenology norm.
And so in this context, the agents agency is kind of complicated because it's both
the ability to sort of navigate the landscape to move closer or farther away from the attractors.
And so the degree to which an agent has agency is a degree to which it doesn't go
necessarily directly towards the attractor, but has some degree of reflexivity over its own
action space in order to navigate that the different kinds of
tractors that may be available to it. And so we could see that the momentum would be like
affected by personal experiences, education in the tendencies, or even, you know, the tendency
to resist or yield to social pressures. I could go on, but I know that, A, you have your hand up,
so why don't you go? Okay, I guess Avel could answer before I talk a bit. So I was just trying to
have my hand raised before talking. So if Avel wants to answer you and afterwards I can talk.
I'm okay. I don't have anything specific to answer.
Okay. So you talked about the dual aspect of statistical organization of complex agents.
And you said that it was a core contribution of active influence to social sciences.
Can you dig a bit on that? And yeah, just articulate it a bit more, so we could grasp it
better. And then I could ask questions. Do I share my screen? Yes. So basically what we
quite we have in here is the formalism that builds from very basic dynamics in the,
like, just space. And there is stuff that depends on the space.
Zero level physical representation of literally anything can go there. And from there, we build
a model of first self-organization. Not quite that. Agentive self-organization, let us say,
something that can build a specific stable ecology and maintain itself in this ecology,
that is what we have here. And then, given the lack of coupling between active and total states,
we can build essentially more complex stuff that can implement a higher-order beliefs about
themselves and what they do and, like, do decision-making that is conditioned on information
they have on themselves, and a clarification under the form of beliefs over their own action.
And as such, this is, like, this is just math. This says nothing about the world
in and of itself until we claim it corresponds to things in the world. And we can claim that this
is a basic conceptual model that maps well into enculturation, basically social organization,
engagement with the social cultural world, because then we can account of the human ability for
very, very, very wide, open-ended learning as something that comes from there, as something
that allows us to infer things about ourselves and then develop complex policies and like them,
blah, blah, blah. And because, to my knowledge, there is no competing model that accounts for
anything near that, like the only competition, like the competition. I should not talk of
competition, but the other models of cognitive organization and enculturation that exist that
are trying to ground themselves in physics, like an chemical system. They are just talking about
dynamics. They are specifically avoiding talking about anything like content or semantics. So,
the fact of this piece of math as a monopoly on building semantics from the ground,
and what it tells you is that agency and identity and relativity, it's all the same
phenomenon. It's conditioned by a self-belief, basically, that is constructed in this specific way.
We can, how to say, because this is the only way that we can account for higher-order agency,
then we have, at least I would argue, we should have strong priors for a series of agency,
either mechanical or conceptual, that vibe well with that picture. So, this is the claim I'm making.
Yes, I want too much detail, so I hope this is enough.
Okay, so I have some, maybe not questions, but some points to make now. Thank you.
So, from what I see here, we could put the active inference paradigm into the individualistic
methodological individualism framework in sociology. So, the idea is that you try to model
an individual, and then when you have the good way to model the individual, you can generalize
to what everyone is doing. So, for instance, if I'm working on something in a certain way,
then I could generalize about that and say, okay, sociologically, I have this constraint
to work on this stuff. And then, not like everyone is doing that, but it could go like that. But
what is interesting here is that it's not only about one individual, but also that,
for instance, let's take the external states. You could say that external states here are other
agents, and also that, okay, so you have the active state in the internal states. So,
we could say that your internal states are totally influenced by another agent. So,
we could do something like that with two individuals, I guess. So, one is one of the
agents here, and the other drives the internal states of the model, because they are really
influential on yourself. So, there are some limitations about this kind of way of thinking,
because in general, in sociology or in sociological sciences, what you would like to say is that
there are some agents at a higher level than only individuals such as you and I. So, the trick
could be to say that some states, for instance, are some firms or agents for and by themselves.
So, you have agents which are not individuals or persons. How about you talk about
the approach to social histories? I don't understand what you tried to say, Avelis.
I was just trying to react to your slide,
because I don't see how it connects with my own work here. Oh, I'm talking tomorrow. Okay, nice.
So, if now you have something to say about what I just said, about how we could have,
let's say, two active agents trying to talk together.
Yeah. So, we have such simulations that already exist. Over various kinds of scales,
we have two agents coordinating that are animals like birds singing and over time
coordinating over the song they're going to sing. We have several models of leader follower
where you have one agent, two agents starting from relatively the same point, but one agent
developing more confidence and therefore developing a dynamic of leader follower with the other
agent. This is work that's possibly going to be followed by Francesco Balzan who is working on
models of education and how maybe the teacher and student dynamic may be cast under these terms.
I've done work with Axel Konstant and Axel Ramstead in terms of active inference in social
scripts. That's what Avelis was mentioning. And this notion that through the cues of the
environment, your own model is shaped both by the environment which includes other people
and the way in which you self-evidence within this environment. So, for instance,
there's two ways we can understand your question first. We can say that
minimizing free energy is basically an agent that has a form of autonomy and it's constantly
updating its model to align with the environment. So, by virtue of doing this, it's not fundamentally
individual, but that each agent has its own model of the world. Each agent reflects
a perspective, a very unique moment in space-time that will
