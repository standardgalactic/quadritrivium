on or on in biological physics or biophysics and stuff like that.
That's it. I mean, you have like a 0.999 probabilities that he never heard of patient
mechanics. While we have a whole agenda to, to, to, to, to following is that I think there is
way more to, to be done. It's like the, the down of this field of this agenda, let's say.
So I think the, the next years are quite exciting in that regard.
I, I totally agree. Like one meme or theme on that for me is like
the base graph on the screen on the table. It is what it is. And then there's the second level
where we annotate or assert that graph with cognitive phenomena. Like, well, this graph
reflects attention or awareness of attention or metacognition or regret or whatever we're
modeling. We kind of make an assertion about the base graph. And like you said, it's the dawn.
This isn't the answer on metacognition. This is like one very snappy, very,
following in line way of modeling metacognition. But there's no end, there's no end to that
question of how do you model metacognition? And so then it's just like every time in a
psychology paper or any, we see like a cognitive phenomena, which can include everything from
anticipation, you know, past, present, future. That's like our keyhole to bridge with this
generalized, unifying perspective on cognitive systems. Yeah, I totally agree. This work is really
this work here on the slide is very like a first work. But I mean, when it comes to
metacognition, for instance, I mean, I'm not an expert at all, but there are many concepts.
I don't know, mental actions, cognitive effort, whatever, there are many things, many layers.
And the, I think like translating all of these concepts of these phenomena processes, whatever,
into an actual Bayesian mechanics is really like what's coming, in fact, I think, in the next
years. So, and yeah, we'll see. And as you said, beyond the analytical work, there is also the
simulations, worked examples, whatever. So yeah, I think there are many, many works to be done and
which are coming in the, in the next years, I totally agree. Yeah, a kind of analogy that
brings to mind is like early in the periodic table, not saying that we're studying material
phenomena, or even that elements are material phenomena, but it's kind of like, well, the
rabbit has vision, taste and hearing. So if we've identified memory in vision and taste,
there's like a missing element for, maybe it's not there, maybe the memory for hearing is zero,
or maybe it's something very complex, but it's like, but there's a space there. It's like, there
should be a rare earth metal in the fourth row. There should be an attention variable on this.
And so it's kind of like a higher dimensional periodic table, where because we know about
certain patterns that are either kind of convergently arising in the real world because of
what is life, or they're convergently arising because we choose to model things a certain way,
then that brings a huge amount of concordance and juxtaposition,
like to the field of chemistry. Whereas previously, there might have been air chemistry and water
chemistry and fire chemistry. And then there'd be like, oh, but what happens when you throw water
on a fire? Or what happens when the air in the room burns out? There'd be like these edge cases
where it's like, oh, we don't do that. But that's what's happening when we don't have the unified
model for cognitive systems. People will kind of study one phenomena or character of a system.
To its limits, but the limits of any phenomena in our highly woven
life forms, like you don't chase it to the end. If you're studying foraging in the ant colony,
it's not like there's a, okay, that was the end of the rainbow foraging is over. It's like, oh,
well foraging is related to nursing. And then that's related to this and the weather. It never
just simply terminates with the inquiry. And possibly that could reflect the extremely
early stage of this formalization. Possibly there are fundamental unknowns and adjacencies
in our epistemic situation. Yeah. And I think, I mean, few years ago, the idea of
kind of extending physics to, in order to have an actual physics of cognition, it would be like
crazy, like the Holy Grail. And the fact that we have this early works is quite an achievement.
And I would also say that what's interesting here is that we already do have
formal models of many cognitive phenomena. For instance, you were talking about the
paper of last about metacognition. So we have very precise and formal active inference models,
for instance, of many different phenomena like metacognition and so on. So in a way, we kind of
already know what we should end up with. And the idea is how to do, how to play, for instance,
with the sparsity within the United States in order to go to get back, to rederive or
refine what people already modeled in a different literature earlier. So that's kind of the dynamics,
I think. So yeah, we'll see in the next years how it goes.
Yeah, that's a great point. A few more thoughts on that. Like, a lot of the adjacencies and
generalizations, mathematicians and physicists and statisticians, they're experts in this. Like,
if it was a fixed number, see if it could be variable. If there wasn't a variance, see if you
can add a variance. If it was this kind of distribution, swap it out for like, there are these
kind of syntactic moves that barely require much more than just like, yeah, these are the swaps
we make. Like, this is what it looks like to generalize a theory. It's like we could add a
variance on, you know, all, so those kinds of familiar moves. And then
so much can be explored on this topic. But when we think about a physics of cognitive systems or
a physics of cognition, sometimes I feel like I have one foot like is, it's like, eyed or somehow
trailing with the reductionism, like it's hard to escape the material basis. And it's also not
clear if we want to escape the material basis because of physics of cognitive systems. On one
hand, it might address this kind of like thermo info, negentropic Schrodinger, what is life question
about persistence and order of kind of quasi crystals, or leave all that mess separate,
mess and beauty. The pure Bayesian mechanics, if we just say, okay, now we're in the map,
we're leaving the territory behind, we're not going to talk about the actual calories and
the thermodynamics, we're just on the map. And a massive prior with a little attention is like a
piece of sand hitting a mountain. And a very loose prior with a highly attended to data point is
like a bowling ball, you know, smashing through a small little heap of sand. So it's like,
there's a physics to the collision of incoming data and prior, which is the Bayesian setting.
So it's interesting that there's a sort of
map Bayesian mechanics that kind of non controversially describes the collision of
priors of different mass in a way. And then the tantalizing question or connection
is whether that is like one in the same or an enabling factor or a downstream factor
of this actual thermo informational auto poesis for living systems.
If I may add something, I think here, I mean, an interesting point is that if you have, for
instance, I mean, I don't want to go there really, but if I have a software which is,
which can be implemented by many sort of hardware, for instance.
And this idea was actually a lot debated in the when it came to functionalism and stuff like
that. But anyway, here, such Bayesian mechanics, in a way, it's the physics of
how the overall system should behave. So there is, for instance, the minimization of this
free energy functional, but we are not saying how here we do not
explicitly say how the system actually does the computations. We just say that a
sparsely-copper-random mathematical system has somehow to do that stuff. And in a way, it is
neutral about what the actual system is made of. It's like when we say that the free energy
principle is more framework than a process theory or stuff like that. But I don't know very much
about these questions. I think that's a great point. It's like that's why a program or an
operating system can be run when a different processor is brought in just within a kind of
classical computing setting. As a cognitive mapping or cognitive modeling framework,
like, we don't know if that rabbit is a real biological rabbit. That rabbit might be a deep
fake rabbit. And we're interacting with it through a video channel. And we think that
we're doing behavioral research on a real rabbit, but it's just a really convincing synthetic data
rabbit. We don't know because we're only getting the observations that we're getting.
And then we can tell any number of possibly compatible stories or interpretations about
the data we're getting. And to say more or to go further, like, that's stepping past the
boundary of the actual observations we're making, which is great. Like, we want to propose hypotheses
for what we're not directly observing. That's the whole point of latent states and everything.
And yet there is this line where it's like, you can kind of falsely push the known knowns
beyond where they really are. And it seems like one example of that is going down and specifying
the actual mechanistic basis of a given computational function. And that that's if
that's important to specify, then the work itself is to specify it. However, at the framework level,
the framework's absence of that kind of a material substrate, like, that's the feature.
That's not a alakana in the framework. That is like, there's the USB stick and then there's
where you can plug it in. That is the plug in to any system. And if there was something already
pre plugged in there, like, well, it has to happen on Turing computer, or it can't happen on Turing
computer, that would have just hobbled the scope of applicability
by welding together what doesn't need to be welded. And I mean, if anything, this is a
journey and a challenge about proper articulation and about how sparsity and
nuance saying which are connected to what brings us cognitive phenomena. So it's like
many things to learn and reflect on. Yeah. And if I may add a related remark about the
the question of having a top down approach as opposed to bottom up approach.
I think sociologically speaking and historically speaking, it's very interesting that the people
started developing Bayesian mechanics are people who are not like supposed to be professional
physicists. Because I think when you it comes to like super emergent kind of phenomena, like
cognition, whatever, the people who was training is precisely to learn about cognition, about
agencies, the people who kind of know everything about what it takes to be an agent and so on.
These guys are neuroscientists basically. So they because they know what agency entails,
they can be the good ones to propose an actual Bayesian mechanics, which is a very
top down approach. Whereas if you go to the labs in like physics of complex systems lab and stuff
like that, people are pretty much bottom up. They will, for instance, I want to study the
brain. So I'm going to write down the upfield model, for instance. So a kind of icing model
where up is an activated neurons and down a non not activated neurons. And so I will have this
this very much bottom up approach. And I can, which is super interesting and super important,
but when it comes to this very much emergent behavior, the very emergent phenomena of the brain,
metacognition, blah, blah, blah, I can study for like five centuries, the upfield model,
I will never get any insight about the emergent behavior of the brain. And so I think here,
you have to have a top down approach, you have to write a very generic
long my question. And because you're a neuroscientist, and because you know what it takes to do an
inference to to be an inference machine, you're like, conditional independence is very different,
is very important three. So let's try to inject in my long run equation, some level of sparse
coupling. And then boom, you have the free energy principle. So even though sociologically speaking,
what's happening here might be super weird, like these guys are not supposed originally at least
to be physicists, and they are supposed to like kind of generated the next chapter of physics,
how weird is that? But in fact, in fact, I think there were precisely the good people to do that.
So yeah, it's quite interesting. I think there might be, oh, that's a great point.
There might be a fun history with physician, physician heal, myself, and the alliance of
medicine and physics. That's one point. Another point is on low road and high road.
And sometimes the disciplinary or the in group conversation is like very low road.
And then the idealistic and aspirational is like high road, it doesn't exactly map to those,
but I'm thinking of like, somebody says like, I want to drive somewhere, I want to travel somewhere,
there is no material basis for that travel yet. They're not there, there's no path, there's no
car. And then in the mechanic shop, it's like, well, we have this tool, this object, like the
low road, we're so surrounded by the low road, that it supports this incremental research agenda
using the tools and approaches that we have, and their materiality. Whereas someone from
outside the field, like comes to the ant researcher, it's like, have you had the ants build this new
thing? And it's like, well, we weren't even on that path. But now that's like a new North Star.
And that can now draw work in that direction. And so it's kind of like the low road building
out and then like the kind of the draw of the adjacent possible and the imagination that the
high road kind of grounds in. Alright, I'll ask a question from the live chat. Susan asks,
What can one equation contain? I'm imagining how to interpret and translate self modeling,
how to approach foraging resources and opportunities.
Can you, can you repeat please? Yes, it's an open ended question. So yeah,
feel free to however you like. What can one equation contain? I'm imagining how to interpret
and translate self modeling, how to approach foraging resources and opportunities.
So I could not answer the second part of the question. But if I can pick up on about the
question of what what these equations are all about, which is a bit what you asked last week,
like what works, does the framework do what these equations contain or whatever.
If you actually simulate a sparsely coupled random dynamical system, and actually there are
there already are examples out there, for instance, in the 2021 paper called
Stochastic Chaos and Markov Blanquets, if I remember well, with Thomas Thorne and
Carl Friston and others, they simulate a coupled Lorentz
systems, if I if I remember well. And if you do
simulate such systems, which verifies such sparsely coupled architecture,
you observe the behavior which is described by your equations. And if, for instance, you remove
fluctuations on particular states. So, well, your simulation, which follows the path of this
action, which is given by your equation. So it's, it's, it's, it's, it does really work
in the sense that it does describe indeed something, it's really a physics, in fact,
of such sparsely coupled systems. Great question. I think we can explore more on
what an equation can contain. But I'm just kind of struck by that there's like a latent large
set of to be clarified axioms and conclusions and so on. And when we see like one equation
written here, it's kind of like, we're just seeing like one glimpse, or one facet.
It's not like the other equations aren't in effect, but sometimes it's a little unclear
which equations are relevant. But in an equation, we see a symbolic expression
that within a given quantum reference frame, otherwise the Q and the A, it wouldn't mean
anything like within a semantic reference frame, the equation is just kind of like a check.
It's like, it's like, it's, there's probably many ways that we can kind of explore what it does.
But it's true that, I mean, I think many people who in addition don't necessarily have
a mathematical background or whatever, they have been, I mean, I'm not an expert in the
history of the theory principles, but a lot of people have been confused, especially in the early
steps where it was, as Lance say it many times, where it when it was even more
an intuition than a solid framework properly grounded in solid math. So people did get a
bit confused, I think by with the math, but now it's we have more and more worked examples,
simulations, solid math, etc. So it's quite, quite nice.
Okay, in closing, we have explain it like I'm a 10 year old. Now that that response may reveal
more about what somebody thinks 10 year olds are like. But now that we've been on this two part
journey, you know, dot zip it and close it, Richard. So explaining you mean about what I just said
like before? Just both sections or just our whole projects. Now that now that we can look back
in all the incredible quality summaries that we've provided, how do we just cap it and move forward
with a child? Yeah. So I think everything we did here, so both in this presentation and the previous
one is so basically we can so if I I would so in order to say in the most intuitive and simple
ways, I would say that very simply puts a system is just it's just it's just some things interacting,
let's say, so it's literally corresponds to a system as we use this word in a in a daily basis.
A pen is a system, an organism or any piece of any collection of things interacting with each
other. I can say this is a system, I just have to precisely delimit it and and say what are the
boundaries of my system. And given a system which has a certain dynamics, certain laws,
