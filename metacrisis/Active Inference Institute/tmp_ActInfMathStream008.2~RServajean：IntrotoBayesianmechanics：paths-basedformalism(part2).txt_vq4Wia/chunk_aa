Hello and welcome, everyone. It's February 2nd, 2024. And we are returning for Active
Mathstream 8.2 with Richard Cervezion, Introduction to Bayesian Mechanics, Free Energy Principle
and the Paths-Based Formalism. Thank you, Richard, for joining for this Part 2. Looking
forward to your presentation and then discussion.
I have a weird echo. Wait.
Are you in general synchrony with yourself on YouTube?
Wait, let me see.
Okay. Perfect. Sorry.
Okay. So, hi, everyone. And thank you again, Daniel. So, today, I'm going to present the
Path-Based Formulation of the Free Energy Principle. And I'm going to start by your brief reminder of
a couple of things we discussed last time. However, if you're not acquainted at all with
the notions of synchronization map of variational inference or long-run equations, it can be a
good idea to watch the first video. And if you do so, please check the comment I posted below
where I precise and correct a few things. So, a quick reminder of where we started and where we...
So, basically, if you consider such sparsely-coupled random-dynamical system where
mu corresponds to the internal states, eta to the external states, and a and s, the blanket states,
to respectively the active and sensory states, and they form together the so-called Markov
Blankets. And just a bit more vocabulary, a and mu form together the so-called autonomous states.
And finally, if you add the sensory states to the autonomous states, so you consider the
world Markov Blankets plus the internal states, you end up with the so-called
particular states, pi, and the particular states defines or constitute a particle, an agent,
bacteria in my schematic, for instance. So, if you consider such sparsely-coupled random-dynamical
system, you can interpret the dynamics of the autonomous states in terms of perceptual and
active inference. More precisely, you can see here in the bottom of my slide that the autonomous
mode minimized a free energy function, which is defined under a generative model, which is typically
the nest density, the non-equilibrium steady-state density of your system. So, more precisely,
the internal states mu parametrized the density q mu over external states. And if you look at the path
of the internal mode, it is so that the free energy associated with your variational density is always
minimized. And this license sees an interpretation in terms of Bayesian inference. And about action,
because you can see here that the active mode is also minimizer of the free energy. In fact,
it minimizes the surprise term within free energy so that you can see the particle as actively
sampling unsurprising or preferred sensory states, sensory inputs, which is active inference.
And yeah, if you remember well the last video, we saw that the generative model encodes the
preferences of your system. So, that was basically where we started and where we ended last time.
And today, I want to relax a couple of hypotheses. So, first of all,
no steady-state is assumed. We could be at steady-state, we could have a well-defined
nest density, but we don't do any assumptions here. There is no steady-state assumed.
So, it extends in a way the scope of the free energy principle. The second thing we do is to
relax the white noise assumption. This means that we don't deal anymore with infinitely rough
fluctuations, but we have fluctuations which are smooth. So, basically, we deal with collards
or correlated noise. And this means that the fluctuations become differentiable up to a
certain order. So, basically, instead of dealing just with x and x prime, let's say, you have x prime
prime and so on and so forth. You have higher dynamical orders, if you will. Note that this
vector x here, which precisely corresponds to x, x prime and so on, is called the generalized states.
And a shifted vector, this one, where the first component is x prime, we refer to it as the
generalized motion. And we also say that we work in so-called generalized coordinates of motion,
not to be confused with generalized coordinates in analytical mechanics. So, a lot of words,
but we are just saying that the fluctuations are smooth now, and we can differentiate
these fluctuations up to a certain order. And this order is the order of generalized motion,
and it tells you how large the correlation length of the fluctuations is, basically.
I also want to introduce the notion of generalized state space. So, basically, you can
augment state space with generalized motion. So, instead of just looking at x, the state of your
system, you look at x prime, x prime, prime, etc. And so, basically, we consider the so-called
generalized state space. Okay. So, once again, a lot of words just to say that fluctuations are
smooth now. So, if you look at the equation below, it seems that there is dots and primes here,
and it seems a bit redundant. So, in fact, what we call x dot here, you can view it as the actual
time derivative that you can evaluate anywhere, for instance, at t equal to. And the x prime here
is just the second component of the momentary generalized states of your system, for instance,
at t equal to, so that if you evaluate your time derivative at t equal to, it equates indeed x
prime. But the distinction between the two will become more clear later in the context of generalized
filtering. So, the cool thing here is that if you perform a Taylor expansion of the state of your
system, so you have an equation like that, you can see that generalized states constitute the
coefficients of your expansion. Indeed, you can see in this formula here that you have x, x prime,
x prime, x prime, etc. So, basically, you do a Taylor expansion around t equal to, basically,
and the coefficients of your expansions are generalized states. So, in a way, you can see
generalized states are as encoding a path, as encoding the future of your, of the state of your
system, thanks to this Taylor expansion. And that's basically what I wrote here, a point in
generalized state space corresponds to a path. That's exactly what I just said in virtue of
this Taylor expansion here. So, a consequence of that is that if you look at the surprise of
our generalized states, the negative log p of vector x here, and we call it the generalized
Lagrangian, it plays a role of an action, scoring the likelihood of a local path over the correlation
length of fluctuations. So, let me break down a bit this idea. Once again, here, the order
of generalized motion depends on how smooth the noise is. So, basically, when you do this Taylor
expansion, the time scale considered here corresponds to the correlation length of
your fluctuations. The more correlated your noise is, the more dynamical orders you have,
in a way, the larger the path encoded by generalized states. And the corresponding surprise,
the corresponding generalized Lagrangian, negative log p of vector x, is a quantity that scores
the likelihood of this path in virtue of the correspondence between points in generalized
state space and paths. So, a last remark I want to do in order to be sure that everything is clear
here is the following. You might be a bit confused, especially if you have a physics background,
because Lagrangians and actions are two different things. So, let's take a step back and ask,
I have a path trajectory in state space, if you will, and I want to compute
probability density associated with a path. How should I do? So, the first thing to do is to
discretize time. So, basically, you discretize your Langevin equation. So, for the people at
Quentin with stochastic calculus, just notice that it means choosing your alpha discretization,
either Ito or Satonovich, let's say. And from your discretized Langevin equation,
you define an infinitesimal propagator, just like for path integrals in quantum mechanics.
An infinitesimal propagator is just a transition density between one state to the next during a
time window dt. Then you multiply the infinitesimal propagators, and then you go to the continuous
time limits. So, in a nutshell, that's how you proceed to compute to write down a density
associated with a path. And if you do that, for instance, in the simple case of a vener process,
where the noise is the Gaussian white noise, you end up with the density of a path being
proportional to the exponential of minus something. And this something, we call it the action.
So, the smaller the action, the more likely the corresponding path. And this action,
in fact, corresponds to an integral over your path of something, and we call this something
a Lagrangian. So, the Lagrangian is defined at any point in time, while the action characterizes
the path as a whole thing. So, conceptually speaking, Lagrangians and actions are two very
different things. But here, the key move is to kind of leverage the idea that a point in
generalized state space encodes a path, so that the surprise over generalized states,
this negative log p of x, which is defined as generalized Lagrangian, plays a role indeed
of an action, once again, scoring the likelihood of a local path over the correlation length of
fluctuations. So, that's really the core idea underlying the path-based formulation of the
free energy principle. So, basically, now that we have introduced these ideas, let's look at
the generalized Lagrangian over autonomous states. So, I just want to point out that throughout the
presentation, in virtue of this correspondence between points in generalized states and path,
I will call generalized states path. For instance, here, I would say the Lagrangian of
autonomous path. I use these words in an interchangeable way. And similarly, when I am
dealing with a path minimizing a generalized Lagrangian, I will be talking of the path of
least action, because Lagrangians play the role of an action. So, be aware of this terminology.
So, if I'm looking at this generalized Lagrangian of autonomous path,
so negative log p of alpha, the cool thing here is that if I remove fluctuations,
noise on a particular state or path, so basically the particle responds deterministically to its
environment, I can rewrite this Lagrangian like that. And this formula coincides with an expected
free energy. So, what this formula is all about, well, we can reorganize it. And if we do so,
you can, for instance, write it that way. So, what it means is basically that
the path minimizing this Lagrangian, so the most lightly autonomous path,
average over all possible sensory path, has to minimize these two terms. And these two terms
are very interesting because the first one, if you look at it, is it is an expected Lagrangian
over sensory path. So, minimizing this Lagrangian means this expected Lagrangian means following
an autonomous path which yields unsurprising or preferred sensory path. And therefore,
it can be viewed indeed as an expected cost you want to minimize.
And if you minimize also the second term, this negative expected information gain,
you can see that it is just an expected KL divergence between two densities. And these
two densities, the difference between these two densities is just that the first one here
is conditioned upon S. So, basically, these two densities are different if the sensory path
is informative. So, maximizing this expected information gain means following an autonomous
path, yielding an informative sensory path. For instance, let's say you are in a dark room
where there is an ambiguous mapping between the hidden latent, the hidden external states and the
sensory stimuli. Let's say you can turn on the lights and then this action would yield
informative sensory inputs. So, that's the idea underlying the maximization of this expected
information gain. So, this quantity is very rich and, in fact, you can do connections and links
with many established ideas. For instance, you can speak of optimal Bayesian decisions and
optimal Bayesian design or of pragmatic value and epistemic value, et cetera. The whole idea here
is that this quantity entails the preference seeking imperative of the particles, that's the
first term, and the information seeking imperatives of the particles, that's the second term.
So, the path minimizing this Lagrangian kind of constitutes the best direction of travel,
the optimal direction of travel for the particle, so that you can view the particle as constantly
engaging in an optimal behavior. Okay. So, now, having said that, I want to go back to the whole
idea of synchronization map we talked about last week. So, in fact, in this setting, everything
is exactly the same. We just augmented state space, if you will. But you have mu parametrizing
the density, everything is the same. And if we consider the internal path of least action,
so the internal path minimizing this Lagrangian here, the corresponding parametrized density
over external path coincide with the density over external path given sensory path. So,
that if you write down the corresponding free energy, you have the first term which vanishes
in virtue of this above equality here, and free energy reduces to surprise, if you will, to this
Lagrangian over a particular path. I'm going to, so before using this to derive directly
the free energy principle, I need to briefly introduce the notion of generalized filtering.
So, in a nutshell, let's say that you have some data, you have the vector s here, a sensory path,
let's say, and you want to compute negative log p of s. That's the quantity you ultimately want to
evaluate. But it's intractable. Let's say that computing this p of s would require a monstrous
marginalization and you can't directly compute this guy. Instead, you define a proxy, you define
an upper bound, this variational free energy, which is parametrized by mu, by vector mu,
and you just want to minimize this free energy so that it coincides with what you ultimately
want to compute, namely, once again, negative log p of s. So, in order to minimize indeed
this free energy, you just follow a recognition or filtering dynamics, which is in fact a gradient
descent on free energy. In fact, the exact dynamics at play here is this equation here.
So, you could ask, but why don't we just have the gradient term here, nabla f? Why do we have
a second term here, this d mu? By the way, about this d mu here, what is it? Well, the matrix d here
is just this matrix with ones here in this line. So, basically, if you have a vector x, let's say,
x, x prime, x prime, prime, and so on, and you want to get from this vector a shifted vector,
x prime, the motion, if you will, you just have to apply this matrix d here and on x,
and it gives you indeed x prime. And so, basically, you can use this d mu here as being equal to
mu prime, basically. And the idea is that once the gradient term here is minimized,
when free energy is minimized, we look at the stationary solution of this equation,
if you will, mu dot coincide with d mu. And let me just explain why we don't just have the gradient
term here. If we only had the gradient term without the d mu here, we would go down on free energy
until a minimum is reached. And basically, we would have the first component of the vector mu
being nonzero, but all the higher dynamical orders would be zero because we are at the
minimum of free energy and we don't move anymore. But here, it is a wall vector mu
which parametrizes free energy and we don't want all the entries to be zero. And we want
an equation which guarantees that so that we add an additional term in the equation. So,
that's basically in a nutshell what generalized filtering is all about. And by the way, note that
if you consider the path of least action of some process x, you can write it in a very similar
fashion. The only difference is that here, the quantity minimized is just the generalized
Lagrangian here, whereas it was free energy in the context of generalized filtering.
And by the way, we just saw before that if we consider the internal path of least action,
the corresponding free energy here associated with the density, the internal path of least action
parametrized, it reduces to the Lagrangian. So, that's when we write down the equations here
verified by the autonomous path of least action. You can directly identify free energy to the
Lagrangian and we basically have the same equations that in generalized filtering. So, basically,
if we look at the autonomous path of least action, you can interpret the dynamics of the
internal path of least action. So, in terms of Bayesian inference, which takes the form here of
a Bayesian filtering scheme. And note that if we remove fluctuations on particular states or paths,
that the definition of dealing with a conservative particle, the autonomous path will coincide with
the autonomous path of least action. And note that ignoring fluctuations might be relevant
when it comes to very large particles where you can, so to very large particles, you can
coarse grained and you can check these papers here where they try to average out fluctuations
using a renormalization group approach. So, in the end, we find the free energy principle just as
before. But the difference is that here, the Bayesian inference takes the form of a Bayesian
filtering scheme. But otherwise, we still end up with a variational principle accounting for
the perceptual and active inference that the particle do. So, okay, now I want to do a bit
of zoology, of typology, let's say. I said last time that this path coupling architecture here was
a canonical path coupling architecture, but it was not a definitive feature of the free energy
principle and that we could look at other path coupling architecture. And I want now to look at
various path coupling architecture. So, the most simple ones you could imagine is one like that,
where you don't have active states. So, basically, the marker blanket is only made of sensory states.
In the end, you can still write down the internal path of least action like that,
but the idea that the particle encodes beliefs about its external environment,
it will not manifest to an observer because, by definition, an observer has only access to
the marker blanket. And that's what this quote is all about when it says that whether internal
