paths of least action parameterized beliefs about external paths and therefore minimize
variational free energy can only manifest via active states that is in active particles.
And, of course, no one would attribute any form of agency or a sentence to a simple piece of rock,
for instance. So, if we move to the realm of active particles now, we basically have the equations we
studied before. But the difference here with this path coupling architecture
is that the active states do not directly interact with the external states and the sensory states
do not directly interact with the internal states. This path coupling architecture is quite
interesting because it reminds, I would say, it reminds the way a bacteria is coupled with its
environment because you would have like the outer membrane with all the transparent brain
proteins, the receptors, whatever, which would correspond to the sensory states.
And then you would have the underlying cortex filaments which mediate many aspects of biotic
actions. So, I like very much this architecture here. But we can even go further in the sophistication
and consider the so-called strange particles. The only move here is that
we don't have any arrow from S to eta, but more importantly, we don't have any arrow from A to
mu. So, the active states do not directly influence the internal states. And this is interesting
because it means that now the internal states alone are independent of both the active and the
external states when conditioned upon the sensory states. So, from the point of view
of the internal states, the active states become latent cause just like the external states of
the sensory states. So, basically, everything is the same. You can write down a variational density
parameterized by the internal states or path, but now it is over both the external and the active path.
And so, we have this free energy here. We call it the generalized free energy G, but everything
is the same. It's just a variational free energy associated with our recognition density, which
is over both external and active path. So, that's in the end, we have this equation here where you
have in the equation of the internal path of least action, the gradient on G here. So, it's
very interesting because it basically means that the internal path infers and, in fact,
causes its own action, which then causes its sensory inputs. And I'm quoting here the paper
which introduced the notion of strange particles. You can view the active path, sorry,
as realizing the sensory consequences of the inferred action. So, basically, such a particle
kind of author its own action, its own action. And so, the idea here is that the particle kind
of infer its own course of action, which will yield preferred sensory outcomes. So, it's really
a form of planning of inference. Strange particles do planning as inference. So, that's
quite cool. And in fact, we can even go a bit further and assume a certain level of sparsity
within internal states. So, you would have this mu1 here, which influence mu2, but not the other
way around. So, from the point of view of the whole internal states, everything is the same. You
have it parametrized all together density q mu. And by the way, under a mean field approximation,
you can write it that way where you would have q mu1 and q mu2 here. But the very cool thing here
is that from the point of view of mu1 alone, well, mu1 is independent of mu2a and eta when
conditioned upon s. And you can view mu1 alone as parametrizing a density over mu2a and eta.
And we call it that way with the over script m. So, basically, q mu1 is a density or a belief
about mu2 and therefore about q mu2 so that you can view this q mu1m as a metacognitive belief
because it constitutes a belief about a belief because it's a belief about q mu2. So, that just
by assuming this simple architectural within internal states, we end up with a minimal Bayesian
mechanics, let's say, of metacognition. And it also introduces the notion of metacognitive
particles. So, I think that's what Bayesian mechanics is all about, meaning translating
cognitive abilities in simple physical terms. It constitutes, in a way, a physics of cognition,
if you will. So, having said that, thank you very much and especially thanks to
all these guys here who helped me a lot understanding the free energy principle and
especially the path-based formulation of the free energy principle. Thank you.
All right, awesome. Great. A lot of ways I could start, but it's so interesting that
how smoothly the path-based continues on. So, maybe could you give her a mark on just the
timeline in the literature, which one of these state and path-based were developed just roughly,
like in which ordering was one first or how did that happen? Yeah. So, I'm not an expert on the
history of the free energy principle, but I know that thinking in terms of path and in terms of
generalized filtering has been around forever, in fact, in the literature. But about
the most, I would say, definitive formulation in such terms, I would say that the most important
paper is, well, I have it here. It's called Path Integrals. Well, where it is, I can see it.
Well. First in Physics of Life Review 2023B, Path Integrals. Yeah, exactly. This paper here,
Path Integrals, Particular Kinds and Strengthings, which is also the paper. So,
which introduce all this typology of particles and it kind of really formulated the free energy
principle that way. So, I think that's pretty much a very, very important paper. And actually,
the one which introduced the notion of metacognitive particles, so one of Lenz and Lars,
this one, towards the Bayesian mechanics of metacognitive particles, the last one,
it is actually a commentary, a short commentary, very easily readable of the Path Integral paper
we just mentioned. And also, I would say that in the 2022 paper, the free energy principle made
simpler, but not too simple, published in 2023, actually. It is mainly focused on the state-based
formulation, but it also talks about paths and generalized states. So, it's also a very nice
paper and it kind of derives the whole thing from scratch. So, I think this paper is also very,
very important. And yeah, I think basically, in the last two or three years, there have been many
papers reformulating the free energy principle or grounding it in solid matter and so on. So,
it's, I think, currently, and let's say, the few years which followed from the 2019 monography of
Carl Friston, it has been very important years about when it comes specifically to Bayesian
mechanics and the actual physics underlying the free energy principle. Thank you. Yeah, I'll just
restate that. I think there's a few great points to explore. So, even as early as the early 2000s,
there was the notion that there was like physics of consciousness, physics of cognitive systems,
a free energy principle for the brain. There were physics-based equations in the 2010
Friston paper. There's a big tree with all these different inference algorithms. However,
they were all just kind of branches on that tree a little bit more evocatively or aspirationally,
but not formally. Then, dot, dot, dot, 2019, free energy principle for particular physics and the
reading group and all the work around that. And then, especially in the last years, since then,
I think that the decision and the move that you made to lead with the state-based,
and then almost nothing had to be said today. Of course, it was a great presentation,
but you said it all that we pointify the path. We make paths into points in a given space.
And so, I was thinking about like being in a car. And then, there's one path where like my first
derivative is one for two seconds and then it stops. And then, that was that path. And there's
another path where my first derivative is one for four seconds and then I stopped. And so, all of those
different paths, which do take the car to different locations,
they are also just points in this generalized space. And then, there's this interpretation of
those coefficients as the Taylor series expansion, but it just shows how versatile the formalism is
because it can take points in arbitrary state spaces, which means, yes, you can imagine arbitrary
state spaces that correspond to Taylor series expansions or potentially other kinds of constructs.
What do we get from paths? So, in fact, I think there are a couple of things which
motivated such a formulation because when, I mean, about the usual state-based formulation,
we talked about last time, there was many critiques, many, I mean, it was, there was many debates.
For instance, about the question about the next density being at steady state, is it
really relevant when it comes to real system, to real biological systems, for instance,
so there was many things which are now addressed by the path-based formulation
because as we saw, we relaxed a couple of hypotheses. And also, the second thing,
which is very much at the core of the path-based formulation, as you said, is, I mean, the fact
to move from states to path, to path which are, in fact, encoded by generalized states,
it allows you to speak of the future, to speak to the future path so that you can develop a
physics of particles planning, for instance, which was not at all the case with the previous
formulation. So, having such extension of the scope of the free energy principle,
it allows you to literally describe the Bayesian mechanics of particles planning.
And so, it's the fact to think in terms of path as opposed to states, it allows you to
develop a physics of, let's say, higher order cognitive abilities, I would say. So, it's definitely
very, very cool and a great achievement, let's say.
Responding to that, I would say planning is possible in the state-based formalism. It's just
more of a brute force tree branching engineering problem. So, it's almost like in the state-based
formalism, there was a physics of the perception action loop. And then, there were classical
computer science ways to deal with the branching of planning, just like a chess algorithm, like how
many depth deep in the time horizon, and then there's all these secondary strategies for branching
and pruning that search tree. But there's kind of like few to none in terms of the guarantee of the
time horizons of policy. You just kind of had to enumerate all the possible options.
But the real-time kernel was physically grounded and beautiful, and then planning
had to be a little bit enumerated. But when we have the path as an atomic entity,
then we can kind of extend the elegance or the simplicity that we were dealing with states in
the moment. But now, our state in the moment is like a Taylor expansion. And this comes up a lot
in the distinction between the discrete time and the continuous time models, like figure 4.3 in
the textbook, where in a discrete time model, if you want to plan 100 time steps in the future,
there's some variable, you know, T sub 100, like you literally are making a prediction,
but you have no prediction for T sub 99.5. You're just making discrete predictions.
Whereas a Taylor series, even a Taylor series for a super complex function, and you're only
going to go two levels of differentiation in, you will have a prediction even for any point.
It might be radically wrong, but you get the whole support from negative to positive infinity,
basically for free, without guarantees of it being accurate. But it's like you've kind of
pinned yourself to the timeline. And then every single derivative that you take is giving you
a better handle on that path, for sure, you'll never do worse. And so that is like, so similar,
yet also very different setting. It's true that I said that the timescale
considered was basically the correlation length of fluctuations on the number of the order of
generalized motion. But in principle, your Taylor expansion applied to, I mean, it's infinite.
But of course, above, beyond the correlation length of fluctuations, it becomes wrong.
And I also want to say about what you said in the beginning about the state-based formulation.
Yeah, it's true. And actually, in the paper, the free energy principle, simpler, but not too simple,
so you can write down the action of a path. So here we have a Gaussian white noise, everything is
so we are really in the state-based formulation of the FEP, you can write the action of a path,
and you realize that it coincides with an expected free energy as well. So you don't need to be in
the path-based formulation to get to the expected free energy thing, which equates the action of
autonomous path. Or here in our path-based formulation, it equates the generalized Lagrangian
of autonomous path. So yeah. Could you come back to where there was the generalized Lagrangian?
So this is a, okay, maybe one before this. Yes. Okay, thank you.
For those of us outside of the non-actim physics world, how is action used? What does action
correspond to in physical systems when we're talking about action as generalized Lagrangian?
Is this the same thing as what we're talking about with policy selection and movement and
embodied action? How is this physics concept of action being used?
So first of all, I would say that there is, I mean, it depends on what we're talking about
when it comes to actions. In Lagrangian, we usually think of analytical mechanics, but here,
it would be more in the context of stochastic calculus. And in the context of stochastic
calculus and path integrals in stochastic calculus, the action is just a quantity which scores the
likelihood of a path. So if, for instance, the density of a path is the exponential of minus
something, you would call by identification this thing, the action. And basically, the smaller
the action, the more likely the path because the higher the density of your path and vice versa.
So by the way, when we were saying, for instance, here that the action is equal to, I mean, we
define it as negative log density of a path. In principle, if the density, I mean, when it comes
to the usual definition of the action, if I write my density as a normalization factor times the
exponential of minus the action, then if I take the negative log of this density, I would have
the regular action plus something. And usually this constant is this is this guarded. We just
don't consider it so that the action reduces to negative log density of a path. But conceptually
speaking, this action is very different from the idea of Lagrangian because basically,
the I mean, usually speaking, the action is the integral over time over your path of
of a quantity called the Lagrangian. So at every point in time, there is a quantity defined. And
this is the Lagrangian, which is defined at any point in time, while the action is a quantity
which characterizes paths as whole thing. So conceptually speaking, actions in Lagrangian
are very different things. Lagrangian, once again, are defined at any point in time while the action
Okay, Lagrangian was defined at any point in time while the action.
Okay, I'll wait a few seconds for Richard to rejoin. If you're watching live,
please feel free to write questions in the chat. And we'll look at them.
You're back. It's all good. Yeah, Lagrangian is defined at every point in time, and then the action.
Yeah. And basically, so in order to just answer what you, well, here, yeah, when you said that,
is it different from the notion of action when in the active in front of each other, for instance,
and so on. Here, we use the word action, but it has nothing to do with the notion of action,
like acting in the world, etc. So yeah, for the people who never meet this concept,
so it can be super confusing. I guess when you, when you read patient mechanics papers,
you don't really know what action is. We are talking about them, but yeah, they are very
different. I know it's funny, like each path has an action value, the negative log density,
that in a way summarizes what we could say are the actions that that path entails,
but yet the actions or the affordances that are taken on that path that are summarized by the
physics action. So there's, yeah. Also, yeah, very cutting edge with reviewing the typology of
particles and the DeCosta and San Vetsmith metacognitive particle. That shows, I think,
a few things. One, that often there are implicit concepts and qualitative concepts that are built
up, like long have people said that there is a continuity of modeling between rocks and societies,
for example, popes and plaintiffs and plankton, all these other funny things that that Friston
et al. say, but not until this paper did we see the simple, the conservative and the strange,
and then with that target article, just with the DeCosta and San Vetsmith work,
they kind of take that in another level and like compose off to the side. And now we can go into
a metacognitive depth, combining back to like the hierarchical nested meta awareness work of San
Vetsmith from 2021. So it's just very cool how there's like a kind of earlier first pass
qualitative intuition. And then the empirical research question is like, where can we build
the high speed rail lines? And this is like the blueprint for the high speed rail now. And then
the next level will be like actually making the simulations or whatever it is to kind of show
that this is not just something that you can make in PowerPoint, but this is actually something
where the rabbit is going to be evincing some kind of behavior that it couldn't otherwise.
But it's kind of like that's like, in a way, it's not the only way, but it is like an agenda between
the intuitive to the sketched and just it builds forward in these ways that are being reviewed
pretty clearly and changing on a month by month.
Yeah. And I think I mean, this I, I mean, this agenda of translating
concepts like cognitive abilities and stuff in simple physical terms is quite interesting. And
I mean, we discussed it on by message on discord, but it's, it's, it would be cool. And it's,
it's coming. It's happening. But it's, it could be cool to for the, this
patient mechanics, this field to be more known and recognized by the physics community. Because
if you meet like a regular physicist, working, for instance, in the physics of complex systems
