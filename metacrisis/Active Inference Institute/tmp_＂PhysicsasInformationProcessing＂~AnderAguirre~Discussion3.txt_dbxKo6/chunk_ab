the resemblance to here. We have the measurement, which in this, in this case, you're trying to
measure concentration of food. You have your node here, C, which is your prior distribution for
concentration of food. And finally, you have the output, the preparation stage, which is your,
you know, this, the rest of this chemical network that will control and steer this
bacterium, right? So there's here, you want to call it the action degrees of freedom
that will steer this bacterium in the direction of food.
And likewise with cell division, this I understand even less, the network appears more complicated.
But I think it's fair to say that at the end of the day, all these chemical networks
that appear super complicated, somehow have to be mapped to this
category theoretical diagram. That's the tolerance to it. You're going to have the sensory input
and the action output. And you're going to have the default chemical concentration, which
amounts to this, to this node over here.
You remember this from last lecture, right, Daniel? Yeah. And the cone cocoon we explored also in
live stream 17 on the Bayesian semantic information flow. But I'll kind of at a point about these
biological systems in relationship to artificially specified systems and what that helps us understand
about perception cognition action. So the cone cocoon diagram has this bow tie architecture,
or this kind of like two pyramids touching point to point, where there's a preparation
and a measurement, which can be different dimensionalities or different scopes,
like you could be multi input multi output or multi input single output vice versa and so on.
But they come through this eye of the needle with C prime here. Now contrast that kind of
architecture represented here abstractly with what we see in the bacterial process
and in the cell division process. These have that kind of a bow tie perception cognition
action architecture or measurement cognitive integration, preparation architecture.
In contrast, we see, for example, an artificial neural network, where the input and the output layers
are usually lower dimensional, maybe an image coming in with several hundred pixels and a
single output like a classifier coming out the other end, but a dimensional explosion
in those internal cognitive layers. But in biological systems, it's actually exactly the
opposite. For example, many, many, many receptors on the cell surface on the holographic boundary,
the sensorium of the cell. But then there are these common secondary messengers
that many pathways converge upon. So that reflects the kind of radically different
architecture that a QRF embodies, as opposed to the approach taken by disembodied intelligence
frameworks, which use dimensional explosion internally, to try to categorize and classify
and find find edge cases versus this dimensional winnowing that is reflective of these embodied
intelligences. And if I may make a tangential comment here also, I think the good thing about
these two examples is that they also showcase the fact of how, you know, the deep implications of
a scale free biology, if you want to call it this way. We tend to think of these sorts of processes,
right, such as here, only happening at the level of the nervous system in animals.
Or, as you said, neural networks, right, we tend to associate this with neural networks.
And perhaps evolution is theorizing a way that endowd us with nervous systems to make these
things, maybe these are higher up in the layers. But really, that's a bit of an arbitrary distinction
that we make. The processes going on at the cellular level, even if they don't appear to have
anything to do with the nervous system, my understanding is that there are some generic
properties that are the same and everything that has to do with information processing.
It manifests maybe slightly different when it comes to explicit nerves, but at the end of the day,
it's the same generic process going on. Would you say that's right, Daniel?
The ontological claim is that it's the same generic process happening, whereas the more
instrumentalist claim is that we can model it with some shared abstractions.
Yeah, okay, so we can continue, right?
So, from, you know, I don't have a whole lot to say, Daniel said quite a bit about,
at the end of the day, QRF is, you can visualize it as this diagram. And, you know, you can think of
it as, if you are more familiar with the picture of neural network and ways on a neural network
and so on, that's the way to think about it. Now, let's continue with explicit embodiment,
if you wish. So, QRFs in the formalism have to be attached to a boundary,
boundary, degree, supreme. And I should add another remark here, I think,
and personally, to me also, like the hard part about this quantum pre-energy
principle formalism, if you wish, is what you said at the beginning is the fact that it's
topological, right? So, very often it's not clear what the boundary, degree, supreme are,
right? Because we tend to think of boundaries as, you know,
geometrical, and certainly the classical FEP treats them as geometrical, but that's not the case here
in the quantum pre-energy formalism. And where we have merchant space, as we'll be talked about
in later sessions, that's just like one quick remark to make. At the end of the day, though,
even if it's topological, we're going to have real degrees of freedom that this
QRF is attached to, this cone-cocoon diagram. And you're going to have measurement operators that
yield classical outcomes, class of minus one. And then you can think of this QRF,
or more abstractly, this cone-cocoon diagram as a neural network, if you wish, acting on those
boundary qubits. And then backpropagating some sort of action signal preparation.
Okay, then let's not forget that the Landau's principle and so on requires that we are mindful
of energy constraints on computation. And that gives us the following picture.
Number one, we're going to have to
use energy from the environment to fuel our computation, to fuel our observation.
That means that right away, you cannot use the entirety of your boundary to gather information.
It necessitates an allocation of resources. Here, E is the observed environment,
and the blue portion is a thermodynamical sector, where you extract free energy and
heat in order to run this computational process. And then furthermore, you can have
a memory sector where you write things on the boundary. And this takes up energy also,
writing information on the boundary by Landau's principle. We'll take up information.
And Chris called this the minimal interest in observer,
because it has a memory sector. And why minimal here implies that we have at least
minimal interest thing implies that we have more than one layer. Here, the process of
writing things into a memory sector requires us to have a clock so that we can label
those memories in time. So we do have time as part of this formalism, just not space yet.
Okay. And time has to be internal to the observer.
Just one piece on that that Chris mentioned. And as you echoed, time here is an attribute of
some cognitive systems in terms of their internal understanding so that they can sort
memories and understand what came earlier or later. It's not something that's a priori defined
externally, which is the case in the kind of space time first. Now, how do we fit communication
into here? We flip that, we're talking about the topology of communication as ontologically
primal. And now certain kinds of sophisticated agents, that's not like necessarily true of rock
or a metronome or a particle of a gas, but some kinds of cognitive systems are such that they
are able to generate an internal clock concept. And that doesn't have to be the same thing as
what's happening on the wall with chronos. This can reflect a purely internal time,
kairos that enables observers or interactors that have different clock structures. And then
Landauer's principle helps us arbitrage or connect the informational demands to the energetic or
the metabolic demands. Bean? So when I first listened to the lecture, I thought when the
term or phrase trade off was raised, I traditionally have thought of trade off as kind of a binary.
If I'm picking this, I'm trading off against all the other things that I didn't pick,
so one or the other or others plural. But when I saw this, and especially when I heard it in
the context of things like degrees of freedom, I began to wonder whether it is because it could sit
on either side of that boundary. It could be a priori or it could be ad hoc or post hoc, a trade
off, which prior to this conversation, I just assumed that a trade off was one or the other.
But essentially what this implies is it isn't even, it's still a kind of a degree of
of how much weight you put into it. And then it kind of crossed a threshold and then you've made
your pick. You've completed your trade off. Or did I, again, did I misinterpret what I was
hearing? If it's topological, as opposed to the more conventional space time perspective.
Is this, can a trade off be both ad hoc and post hoc, seemingly at the same time?
Very interesting question. Let us just let it float and continue on, enter.
All right. Because again, if it's, I'll just say this, if it can be, that would really move us
out of the classical realm. That would essentially say that anytime we've made a pick,
we really haven't made a pick. There's still a whole bunch of other things that are going to happen
that can change whatever that action is that we thought we carried out or enacted.
If we're talking about an internality state, which is what I think we want,
I think we want to be able to change our minds.
Let me take that one way, Dean. The analytical equations of the action perception loop
don't tell us in implementation, like if we're going to write it in code, whether we should
use action first procedurally to update our observations, or whether we enable our observations
to wag the dog and then select action at the end of the loop. So is it a perception action loop,
or is it an action perception loop? And those enable a kind of seesaw where sometimes we want
what we learn to change what we do, and other times we want what we do to change what we learn,
and having that kind of a fulcrum or a pivot, and then again to connect it to the vertex popping
in and out, the analytical formalisms inscribed on the screen of the FEP, like the textbooks,
they're ambiguous whether we lead with action and have inference follow, or whether we lead
with inference and have action follow, or lead with action and have inference follow, whichever
one of the combinations there are, and then that trade-off or run-off is broken by specific
embodied cognitive agents. That trade-off about the procedural primacy of perception or action
can't be broken generically. Right.
It certainly makes for a lot of waste heat if you're not careful.
It'd be exhausting a lot anyway.
Okay, so I see, I don't know if we can talk about intent much with this formalism,
but we can take a very descriptive approach to it and go down here a little more.
Actually, before I don't want to get ahead of myself, what I mean by that is
whether we can put intent or not in this hierarchy, I don't know if it matters a whole lot,
but at least we can talk about it operationally and descriptively and say just like when you have a
clock, that clock is just there. If you don't have the clock, you don't have the memory,
and that's it. Unlikewise here, if we don't have an attention control compartment, we cannot play
with all these QRFs that are non-commutative at the same time. If there is no attention control
system to begin with, we cannot talk about a system that has non-commutative QRFs,
meaning here one presumably goes to memory sectors, the other one goes to environment
sectors and so on. This is certainly a necessity of the fact that we have different sectors of
the boundary being allocated to different purposes, such as environmental observation
and memory and so on. Within the environment, it's worth remarking that here if you think deeply
about first principles and what it means to observe an entity, well, you still come down
to these differences that make a difference sort of thing, which involves whenever you're looking
at the environment, if you're going to identify a system, you need sort of a background that tells you
that puts the system in context so that you can identify the system as something distinct.
I think this again is something that we have talked about in previous discussions, where
the easiest picture here is something like the speed gauge in your car, where
the P is the gauge itself that tells you the speed, but it's meaningless without the reference
system. Outside of the thing that stays invariant, the context, the background,
that gauge moving means nothing to you. So come back to this idea of if we think of
information as differences that make a difference, in terms of first principles,
this environment sector that we saw earlier has to be further broken down into pointer and
reference states. Again, this is covered in the increases papers. I'm thinking particularly of
free energy for generating quantum systems.
Again, just to reiterate, this attention controls that compartment, which is by the way very reminiscent
to the hierarchy that was earlier with the clock arising higher up in the hierarchy,
deeper into the layer. Likewise, whenever you're writing something into a memory,
you need to have that clock. Whenever you are deploying noncommittative QRFs, you're going to
need an attention control compartment. We just described this operationally. If you didn't have
it, then the agent would not be what it is. It could not deploy those noncommittative QRFs.
So marching on, we'll just end here with the QRF alignment and the free energy principle.
Just a few more words. This is possibly the most interesting picture in this
presentation. We can recall here the possibilities for QRF alignment and how
free energy comes into play in this formalism. We call A the trivial interaction. We call this
a thermal interaction. Then you have a bunch of possibilities. Depending on each possibility,
you're going to see things as notes or as in the paper says, non-local in variables.
The last situation is what we call alignment when we have QRFs of the same size perfectly aligned.
I can't quite recall. I think this
would be the situation where you have noiseless classical computation. You have A and B just
interacting. This is the situation where, correct me if I'm wrong, Daniel. This is
entanglement, asymptotically. Once all the QRFs are aligned, you have entanglement. Now we can tie
back maybe to gains earlier. So these two slides conclude the discussion, basically, and then we
can open it up. So given these possibilities for how QRFs can be aligned, QRFs deployed by A and B
can be aligned, and how in each situation you're going to get noise or whatever,
then what does the free energy principle say in this quantum setting? Well,
minimizing variational free energy leads you to entanglement. So if theorem here,
if you're in the picture of B here, and the QRFs are aligned, A and B are going to be entangled.
Now there is a tension between this tendency towards alignment, as the free energy principle
will carry you, and observe reality, which is that we're not just a blob of entangled particles.
So there is separability, and systems are a tension between maintaining separability,
and at the same time being correlated enough to the environment,
which has to be able to predict the outcome. And now we can maybe go into a more philosophical
discussion on the free energy principle. I should also say, in the last month, just like I talked
earlier about QRFs, Lenny Saskin, whose recent paper that talks about QRF, he led me into a
rabbit hole of looking into his recent work, and he's talked a lot about complexity. I'm being
very speculative here, so if someone can pull me out, that would be good in the comments. But
just to skim it through some of his papers, I saw a monograph in 2018 where he talks about complexity,
and he puts forward the second law for complexity in quantum systems, an increased complexity,
and it is very reminiscent of what's going on here. You have a tension between
systems standing to entanglement, and the other side of the free energy functional
if you wish, where systems increase in complexity, and that necessarily requires
that AMB are separate. So Daniel, do you have any comments at this point?
Yeah, there's a lot to it. I like that you showed the four possibilities
in the image above and said it was one of the most interesting figures. I agree, and
how to connect this to the classical FEP, and also how to see the quantum FEP
not as just a second story built on top of the classical FEP, which would be kind of like a
historical chronological understanding of the theoretical apparatus, but it's almost like
the quantum FEP was like a basement we didn't know about, because it gives a broader context,
and though it appeared conceptually several years later in the timeline we understand,
that doesn't give it a secondary status. So what it really means for the classical FEP
to be kind of like a special case of this actually more generic setting, there's just a lot I'm
