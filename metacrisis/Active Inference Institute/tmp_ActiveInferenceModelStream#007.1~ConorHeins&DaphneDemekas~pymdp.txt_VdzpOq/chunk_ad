Now what we can do which we we can only do an SPM but we can't do in Pine VP yet until now is we can take a sequence of someone's behavior.
And then infer the best parameters of an active inference model that explain their behavior.
So given how someone decided I can say oh their a matrix must look like this or their C vector must have this precision to it like you could infer someone's risk sensitivity or.
Their risk aversion given their behavior and the nice thing about being probabilistic programming languages is there's so many different methods that haven't been really well explored.
For fitting active inference models in the MATLAB literature because almost everyone there uses this variational base approach where you basically minimize free energy.
You use a Gaussian approximation for the posterior is a very specific type of variational inference.
Now that it's in NumPyro or perhaps PymC3 again this will be very soon it's not fully implemented yet.
We'll be able to throw all different kinds of probabilistic inference techniques that have their different advantages and disadvantages.
Like a big thing in probabilistic inferences is MCMC Monte Carlo markup chain Monte Carlo inference.
It's supposed to give less biased posterior distributions like there's advantages to using MCMC over variational approaches to approximate basic inference.
And one thing that I haven't seen done which I'd love to see and a lot of people in the computational psychiatry community have complained and told me what they'd like to see is like a side by side comparison.
A variational base to infer PymDP parameters or PymDP parameters versus like MCMC approaches.
So once you have everything in probabilistic program framework you can do side by side comparisons between all the different inference techniques that you wouldn't necessarily have if you were limited by a language where only at one or two or three inference techniques are implemented.
So it's basically just taking advantage of all the work that people have worked on NumPyro have done in implementing all these different kinds of inference methods.
Yeah.
Awesome and fast to follow it up the primary back end for PymC is a Sarah but the new version can use jacks.
I might get around to writing the pie MC3 wrapper once the jacks version of PymDP is stable.
It sounds very doable.
Well, that's awesome.
If you see it as likely and you have the affordance, then just minimize your free energy and you won't be surprised when you do it.
Absolutely.
That's great.
That's promising.
Nice.
Jacob or Daphne or I can ask another question.
Well, you mentioned message passing several times in the context of PymDP.
So what is message passing and how was it used in PymDP?
It's a good question.
The message passing in general describes like a set of algorithms that you can use to do exact or approximate Bayesian inference.
So oftentimes in the to make it very concrete in the in the context of doing Bayesian inference about hidden states.
So what an active inference agent will have to do when they're faced with some observation, they'll have to combine messages like one message corresponds to the message the sensory information.
And then another message corresponds to their prior beliefs about the world.
And they use some algorithm to combine those messages to optimize a belief about the current hidden state of the world.
So in PymDP, we have a very naive kind of computationally efficient doing way of doing that, which we just call naive or vanilla fixed point iteration, which is like the most simple message passing scheme you can think of which is just I'm actively filtering hidden states using my
priors from the past. So I say, given where I was at the last time step, where should I be now, given my B matrix. And then I just essentially combine that with my incoming sensory message, which is just the observation passed through the likelihood
matrix, the matrix, and then I just combine those two messages together and that resulting thing is my posterior distribution, my posterior best belief about hidden states.
That's like the simplest form of message passing that has this very temporally shallow current evidence combined with prior to form the new belief it has this very kind of Bayesian flavor to it right where the best posture is just a product of the likelihood and the prior.
There's also more advanced message passing techniques that are used when your beliefs themselves are more complicated so in the full implementation of active inference that's in the MATLAB version.
Agents don't just have a belief about what the current hidden state is. They have a full predictive and post addictive kind of tensor or cube of beliefs about all the hidden states in the future and all the hidden states in the past.
Further condition on all the policies I will potentially take or could have taken in the past. So you have this massive like belief tensor, stretching into future and past hidden states and further factorized by policy.
And when you have that kind of belief that you need to update, you have to use more sophisticated message passing techniques, one of which is called a marginal message passing.
There's something called variational message passing and all these different message passing techniques are just essentially consistent passing messages forwards and backwards in time, as well as across different variables that characterize the hidden state which we call hidden state factors.
And the message passing algorithms are basically still amount to combining sensory information with prior beliefs, but they just have kind of more complicated trajectories through the space of beliefs in the future in the past.
There's people who can explain this much better than me. I've implemented some of these in PMDP, but I would refer people to, there's a really nice paper. I think you may have retweeted it the other day, Yaakov, it's about, it's called mean field.
Oh yeah, the paper comparing the mean field and Bethe approximation.
Neuronal message passing using mean field, Bethe and marginal approximation par Markovitch Keeble in first in 2019.
It's a paper that a few of us have been walking through looking at how the different free energy functionals look different under different approximations and it'll probably be a focal paper in 2023 for us to really dive into.
Because a lot of these vintage, let's say 2011 to 2019 papers now packages and development directions such as PMDP are facilitating these methods to be actually used.
And there's a huge wealth of conceptual possibility, proposed heuristics, exciting use cases, relevant other kinds of connections.
And as you brought up earlier, it was very MATLAB bound to bring those kinds of connections into the last mile.
And then especially the more granular or modular developments were under the umbrella of the SPM VBX, which prevented them from being meaningfully shared in a true distributed open science or decentralized science way.
And so that's why, of course, we've been so excited to work with and build on PMDP and learn about it more.
Because this is exactly the kind of composability of active inference agents and their different implementations that is going to be able to be worked on in a massively distributed way.
Somebody might specify a really interesting A matrix, somebody else might specify an interesting B, somebody else is going to link those together into a new kind of agent, someone else can implement it differently.
And so it brings like a natural kind of factorizes the process of developing these algorithms, which previously were almost always either fully MATLAB or and or bespoke and very custom and fit for a given paper,
but not necessarily adaptable along the relevant axes that one would want to use for a modern, especially pythonic setting.
Totally, I couldn't agree more. I mean, that's a great way of thinking about it too is like, I'm making modular flexible code that exists in the ecosystem of other packages you're essentially factorizing the collective minds representation of the task at hand,
where then different parts of that representation can be worked on without having to pass messages or take into account what's going on across the entire network of distributed workers so like someone can write their own, you know, even better message passing algorithm,
and then just slot it in to use with PyMDP without having had to learn about how every little facet of PyMDP works, you know. So yeah, that's a really important, I think thing about just open science and modular software development.
Nice. Well, in our closing minutes, of course, Jacob or Daphne any remarks or questions, and also any appetizer, what kind of models are people excited about, and or what might we see in the following live stream, which will be in January 2023 model stream 7.2.
I would just say that I think that the notebooks are really, really useful. So, like, it's a really great resource for people who are trying to build a model and understand like what's going on under the latest PyMDP.
And I think that it would be really cool to have an extension to those notebooks that also talks about learning the Dirichlet parameters for the A and B matrices. I think that that would be really, really cool.
And thank you so much Connor, you wanted to talk.
Yeah, thank you for coming. That's a really good point. And this is something that Daniel also said earlier in the emails that updating A and B is like, it's very under documented right now.
And I think that would be because that is a form of learning the generative model that right now we don't it's not the most sophisticated way you still have a fixed number of rows and columns so you make some assumptions.
But that is like a flexible way when the agents are themselves learning the B and A matrices. So, yeah, we should definitely maybe that can actually be a, I can just add that into the notebook that I was planning on showing this like a kind of epistemic two armed bandit task.
We can just add in some A or B learning to that and just show how that works or make a new notebook that uses that.
Well, eventually, for the textbook, and for every paper, it would be amazing to be able to see the code, the analytical representation, a graphical representation and different natural language representations, because they're all formally, formally connected.
And they could all be rendered as such and that would really, one might expect increase the accessibility and rigor of a model and help us compose and connect across different domains and just welcome and recognize many different kinds of learning and modeling.
Absolutely.
Jacob, any thoughts or questions?
No questions at this point, but also just thanks a lot for the awesome presentation and I'm really excited about all the emerging integrations and use cases that will undoubtedly spring up.
We've been, we started exploring non pyro as well and kind of discussing how that can be used for scalable active inference models.
And I'm really excited to help MEP will inter interoperate with all of these different integrations and it will be very exciting to use.
Thank you.
Connor, any penultimate words?
I guess maybe just in the spirit of what you were saying, I can just show a skeleton of what we could go through next time.
Oh, great. All right, we see it.
Yeah, is that okay?
It looks great.
So, yeah, basically, this is a co lab notebook. So I encourage anyone to go to the time dp tutorial website and each of the notebooks like Daphne was saying they have they're pretty useful and they have co lab links associated with them.
And you can just open the link and then explore this one, I think is part of the agent API.
Yeah, this is the same one, except I showed this one recently at the course on computational psychiatry. So I've updated a little bit.
So I can share this with you, Daniel, and then you could either put on the discord or wherever. This one's a little bit more updated, but the basic one here will still that you can access here will still show the same thing.
But in any case, the thing is you just open up co lab, you need a Google account. That's the one invitation to use these.
You can install locally, in for actively dash pine dp import numpy matplotlib. There's just some imports here. And then this whole the spirit of this notebook is essentially just going through all the steps in setting up a generative model.
So creating your hidden state factors that's something we didn't really talk about as factorized representations in the context of pine dp.
Building the B array, which not only has, like, you can just do it yourself, but there's also these hidden cells with solutions to each of these things.
And then the main branch of this notebook before running active inference is just stepping through and actually initializing the entries of the ABC and D arrays.
And next time I have some slides to go along with this so we can basically go between the slides and the actual code.
Same thing with your array. So you like have some representation of what you want the a matrix to look like, and then you go into the code and actually build it out.
And you do that sequentially for each of the components of the generative model.
And you're plotting them along the way so you can see what it looks like after you've built it.
And then we actually implement after you've built the generative model, then you actually plug it in to an active inference agent.
So the first stuff is building factorized A and B for a generic generative model that I think is just a more sophisticated grid world.
But then we actually that's kind of the introductory task and then we go in and we actually build the A's and B's and C's for this epistemic two armed bandit task, which is basically just like a team A's.
And then you build that out, you know, you're writing in all the little sub matrices of your A matrix.
That's why there's so many cells, like I said, it's like that's the longest part is actually building things out.
The C vector, basically the reward function, which as Daphne was saying earlier, you're actually encoding in terms of relative log probabilities.
And then finally, you basically do those, those steps that we discussed during the presentation, you just plug all your painstakingly generated A's and B's, hopefully not too painstaking into your agent class.
You generate the two armed bandit, the epistemic two armed bandit environment, which is just the rules about how the world works, given the agents actions.
And then you actually run this active inference loop, which is as we discussed just effectively running a loop over time doing hidden state inference policy inference action sampling, and then stepping the environment to get the new observation.
And then at the end, I've just written this like helper function that can basically plot the history of choices and beliefs.
So then you at the very end, this is like the more fun experimental part, you can mess with the parameters of the environment, and also the parameters of the agents model, and then start seeing how that changes behavior, just by kind of iteratively running active inference simulations and plotting the resulting choice behavior and history of beliefs.
So that's the general that's a little preview, I guess, of what we can do. And we can also have a little sub module in here, we're actually letting the agents update their beliefs about the a or the B matrix, which could be cool.
Awesome. Looks really exciting. And on a final SPM note, in the SPM textbook and in experiments, sometimes there are these incredible grayscale matrices that summarize like multiple experimental factors across 100 participants.
And so it's really interesting to see how you show with also that black and white or grayscale matrix representation, and how that provides a visual feel for some of these topics that we've been discussing it.
And of course, the representation is formally linked with a matrix, but sometimes just saying, well, you have two options and there's 10 states in the world.
And the likelihoods look like this instead of seeing that as like a spreadsheet with numbers, seeing them in the grayscale provides kind of a feel.
And it looks really nice. And so it looks like an awesome session we'll have for dot two.
Yeah, totally. That's interesting that you bring that up like that's something I've just always been doing. And I think it's very much because I learned all of that from reading those active inference and SPM papers.
So I very much just kind of borrowed that visualization technique from them.
And I kind of took it for granted. But yeah, it is interesting. It's clearly not the only way to go.
But I always just found it very intuitive to think of probability. You just kind of can color it use colors because the numbers are too specific.
It's the color the grayscale that visual aspect really like kind of just shows this thing is more likely than this thing.
Yeah. Yep. Cool. All right. Well, Yaka, Daphne and Connor, thanks a lot for this awesome session. And we'll see you in a little bit more than a month for the dot two.
Great. Thanks so much, Daniel. And thank you, everyone.
Peace.
Take care.
Thanks, everyone.
Thank you.
