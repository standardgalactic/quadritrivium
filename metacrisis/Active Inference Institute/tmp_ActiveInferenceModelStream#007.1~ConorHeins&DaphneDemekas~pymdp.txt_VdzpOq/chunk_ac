That's a really good question. Yeah, basically everything I said about the generative model kind of applies to the generative process as well, except the agents interesting behavior.
Yeah, I mean, you can you could think of the generative process as driving a lot of that too.
I guess the bottleneck is the generative model because if you create a really complex generative process so a really complex environment that has all kinds of fancy nonlinear dynamics but the agents model of the world is
super super simple so it just believes that there's you know a light switch that's either on or off.
Then the possible behavior you can get from such a simple agent is is limited by the complexity of its generative model.
So a very complex generative a very simple generative model will still not show very interesting behavior.
Even if it's embedded in a complex generative process, but the most rich dynamics will obviously happen when you have both a complex generative process and a complex generative model.
So all the work in in building the generative model which I would say is the first line up here can also be matched by a lot of work in generating the generative process as well.
Which in this case is this epistemic grid world environment which is just a set of rules that says when the agent is in the queue location show them the queue identity like this one is relatively simple.
But one interesting thing to think about and I'm sure like you Daniel have thought about this when it comes to.
You know your work on active inference and collective behavior is interesting thing about multi agent behavior.
Is in that case the generative process or the actions of other agents so the generative process my generative process are actually the outputs of another active inference agent.
So that's one of the most complicated things and what Daphne and I had to grapple with when we're doing the and and Mao as well Mao was the first author of the epistemic communities work this like social network echo chamber stuff.
In that context the generative process is a little bit more difficult because the the process itself is consisting of other active inference agents that are also acting.
So the control flow of that code will look a little bit different where you're going to have to loop over all agents get actions from them and then use those actions to parameterize the observations for all the other agents.
I mean that's just a generic statement about multi agent simulations in general but it's a it's particularly interesting when you think about.
Agents trying to model other agents because almost necessarily every active inference agent will have an impoverished model.
Of how the world works when the way the world works is a bunch of interacting active inference agents.
So you're gonna have to kind of necessarily equip each agent with a more simplified generative model.
Unless you want them to all have like infinite recursion depth and be able to simulate.
In their own generative model the generative models of every other agent so yeah that's a that I mean I was kind of a tangent about the multi agent case but I think it's just an interesting.
Interesting complex to think about the tension between the generative model complexity and the generative process complexity and how they kind of mutually constrain the behavior of each other.
Okay so I just proceed so that yeah the last two sides I think is the kind of exciting stuff.
So here are a list of things that we'd like to do with time to be in the future.
I'll just go through them and I'll do well on a few that I think are most important.
So one is fitting time to be models to empirical data.
So I've interacted a lot with people from the computational psychiatry community who are interested in actually creating models of behavior often human behavior.
That are their palm D.P. active inference models.
And one of the biggest I think limitations of time D.P. right now is that people can't use time D.P. to infer the active inference parameters of like a human subject that's performing some task.
That's what you can do an S.P.M. right now but unfortunately you can't do that and pine pine D.P.
So this is like really high in the priorities list.
I think this is what will help pine D.P. actually become competitive to S.P.M. for the communities that are interested in fitting pine D.P. models to data.
So these are like kind of more empirical scientific disciplines like computational psychiatry.
Other things is I think we need a better interfaces for actually generating and constructing generative models.
Right now all that code involved in building A and B matrices that really becomes the bottleneck for anyone trying to do active inference and in large part because constructing those arrays for complex generative models can be a real headache.
You have to do all this weird multi dimensional indexing because like if you have like a bunch of different interacting variables in the world you have to create massive multi dimensional arrays that have different numbers of extra dimensions that correspond to all these possible contingencies in the world.
It kind of becomes a massive lookup table that you have to encode all the relationships between variables and so I think there might be this is an ambitious project but there might be ways to actually create kind of UIs like user interfaces that help people build generative models by like asking them a sequence of questions.
For instance, do you want this variable to affect that variable and then depending on their answer you can kind of pre parameterize part of the A matrix or something and then the actual structure of the A matrix gets windowed down through a sequence of kind of yes no questions about the different contingencies in the world.
Another thing is interfacing with open AI gym which we kind of already have done like there's a few examples where we've done this I haven't put these on the on the infractively GitHub yet this is something that's an open.
This is like a very obvious and easy thing to do because like we wrote our environment class as if it was based as if it was a gym environment anyway.
So once you do that it will open up to compare active inference agents to all kinds of reinforcement learning algorithms.
On hierarchical models is a big one.
So basically allowing you to stack hierarchically active inference agents within each other.
So like yeah there's a lot of temporal depth that you can get out by stacking active inference agents into hierarchical things so like one time scale of inference and planning is happening at a slower one slower than a sub faster time scale.
We need more demos that demonstrate parameter learning so you can do updating of a B and D arrays I don't think you can update C so far.
And I know this is something Daniel you mentioned to me which is people in your in the active inference Institute are generally interested in updating the beliefs about the generative model parameters basically.
And then there's things like sophisticated inference which is a kind of a more recent version of planning under active inference.
That's kind of interesting and has some computational benefits to it and then hand in hand with sophisticated inference goes.
This thing that people have developed have had to deal with in deep reinforcement learning for a while which is how do you tame combinatorially explosive policy spaces so when you're doing deep planning over time.
The number of policies is exponential number of time steps that you plan in so that's there's various techniques for dealing with that like Monte Carlo tree search.
Which I think some people like tail field shampion and others have already tried to start to implement in their own implementations of palm DPs.
And so along these lines.
I want to just point out that we're actually very close to getting this working now so fitting palm palm DPM also empirical data so there's a.
A branch that Dimitri Markovic and I have been working on called the agent jacks branch.
We've basically written a back end for pine EP and jacks.
Which normally lets us use a bunch of statistical probabilistic inference techniques from like NumPyro.
To invert or infer the parameters of pine EP agents from like data for instance can be collected from human participants.
But the fact that it's also back ended in jacks means that pine EP is now fully auto differentiable.
So it means you could stack a deep neural network layer.
Onto the like before the a matrix layer of a pine EP agent.
And then you could use something like the variational free energy or any other objective functions.
To automatically train the parameters of a neural network that's linked to a pine EP agent.
So this I think just re implementing it in back ends like pie torch and jacks is like a huge.
Benefit because this will really allow you to extend a pine EP to much more high dimensional state spaces by linking up.
Deep neural networks to various components of the agent's body as you were describing it Daniel.
And so we originally did this just to allow you to do fitting of empirical data.
But it comes with this side benefit of allowing you to differentiate and pass like back propagate gradients that you would use for up a gating deep learning models which is I think really exciting.
So that's like almost done.
I mean, yeah, like we're very close to putting up a notebook that actually does that if you look in the agent jacks branch now it's not very organized but that that stuff is now there and implemented.
Another thing is nor Sajid and I have actually implemented some of the environments from her paper active inference demystified compared and we've actually done that with pine EP.
In open AI gym like in the frozen lake environment is a popular one for simulating be matrix learning.
So that's something that's also just like we've done that and we need to like upload that or I don't know write a short paper do something with that because so there's a lot of like these different tendrils that have been explored.
It's just a matter of pushing forward and actually putting them up on the pine EP repo.
Yeah, and then these other things I would like to find time to do but I just haven't but I mean as I kind of said in the beginning this was very much a collaborative effort so I don't also want to be.
I'm necessarily the one who's like doing all of this because I think it also is healthier for the development of the package of different people are kind of.
Taking the lead on different things and developing it in their own way so that's something I also just generally like to encourage is for all kinds of interested people to get involved in the development.
And I don't think Brennan is here but Brennan Klein also who's a postdoc and research scientist at Northeastern University at the network science institute.
He started these pine EP fellowships so you got funding from Northeastern I think also the Templeton Foundation to fund people to work on pine EP development or pine EP adjacent projects.
I think the first round of applications is over but it would just be a this is a good opportunity to advertise that I think there's going to be another cohort in the summer.
So this is kind of seemingly an ongoing source of funding so it's just nice to see that other people are kind of trying to push pine EP in their own directions.
So that's just an encouraging development that I want to keep everyone appraised of.
Oh yeah and then I'll just end by.
On the read the docs website which is really nice for creating auto documentation.
And so we have a bunch of demos up there we have different tutorials.
We have another a new demo that's not listed here which is about just calculating the variational free energy in discrete categorical models which is based on a demo from Ryan Smith and Christopher White and Carl Friston's paper.
On on like that big tutorial paper on active inference.
So I re implemented one of the demos from that paper.
And now that's also in the docs.
Yeah so you can open all those demo notebooks and co lab and just step through them and they're really you don't need to have even Python installed on your computer to use them you can just open the links and co lab and step through the code and like build your own active inference agents.
So just useful for pedagogy that's why I mentioned if you're just getting started I would definitely recommend going to the documentation.
So yeah, thank you all for listening and for letting giving me the chance to talk it was it was nice to be here as always.
And I guess, like yeah we.
I listed at the bottom for the next live stream we can go through some of the demo notebooks but we also could go through them now, if there's time, it will do discussion first and then just see there's time.
Awesome. Thanks. Yeah, let's address some questions from Daphne and Jacob.
I'll ask some from the live chat, and then perhaps you could share one or a few of the examples on the read the docs and we could just look structurally at what the anatomy and physiology is of a notebook.
So first Daphne or Jacob, any thoughts or questions.
Yeah, yeah, go for it.
I'm wondering on the on the jacks implementation.
Are there any requirements on defining the generative process at all.
Or is it just about defining the structure of the generative model that we then fit to experimental data. And I guess this also relates to another question I had in scaling these models to state spaces or generative processes that we as modelers don't have the liberty to actually define ourselves.
But we want to deploy and train these agents in generative processes that are already out there like in an online setting where you get categorical or discrete data coming in.
Yeah, totally. For it. So on the side of that's a great question on the side of say I had a pine B P agent that had a bunch of deep neural networks attached to it.
And I wanted to train it on in a deployed setting so it's like out there, you know, let's say it's an agent that's trading on the stock market or something it's like placing bets to buy cryptocurrency let's say, in that case, in the same way to train a deep neural
network on that kind of data, you don't need to pass gradients through the generative process, which of course you don't have access to your trading on the stock market.
So in that sense, no, there's no requirements on passing gradients or writing up a generative process that is also auto differentiable.
There is one case when you would want that, which is often in the case of empirically fitting pine B P models to data.
Often one thing that you want to do is you have a bunch of like, you basically have a history of actions and observations of a human participant.
You fit the model, the parameters of the pine B P agent that best explain the observed actions of your participant.
And you know the observations because you're an experimental who like decided this person is going to see the sequence of observations.
So you can do all that without having a differentiable generative process or environment.
But then there's something in in Bayesian inference that's called like a posterior predictive check, where you say, okay, given my inference about the the parameter of the pine B P agent, then I'd like to roll out the expected behavior of this agent,
and then my best guess for what this agent's parameters are.
So that's called like a posterior predictive density where you say, given my posterior estimate about the agent's parameters, what would it look like in the future under under these posterior parameters.
And to do that in in using NumPyro, which is the probabilistic inference framework that uses jacks as a back end, you would want to have a generative process that is also auto differentiable.
But in that case, I expect that writing those generative processes would be easy, because that would be in the case of fitting a human behavior to experimental data where they're like in a controlled task environment.
So if it was the case of trying to fit someone's parameters like the, the value of their C vector, and they were performing that scene construction task where they're circling around.
You could write the generative process, because you as experiment to develop to the psychophysical like tasks that they're interacting with you could write that also in jacks, when you're doing the modeling.
So that when you're doing these posterior predictive checks, you know that that's also written in jacks, and that you can compute those quantities.
But in a deployed setting, you're not going to even be able to do any kind of posterior predictive check in the future, because you don't know how the environment actually works right.
So you'd have to you that that wouldn't even be something that you tried to do in the first place.
But yeah, so there's nothing inherently stopping you from just as long as the models are differentiable, in the same way they are with deep neural networks, there's nothing stopping you from just throwing them into an environment where you don't know how the rules of the world work.
The inexorable logic of natural selection, or free energy minimization or just non equilibrium systems, whether or not they know what's out there, either it's going to work or it won't.
And if it fails, it fails. And the computational environment allows us to exist in this kind of gray zone where the computational agent might be quite poorly adapted to a given deployed setting, but the computer program will still run.
But of course we're interested in cases where the computer program runs, and the agent is able to event some kind of meaningful or even useful behavior.
Exactly. We could we could all imagine very simple PMDP models that would do terribly in some tasks, right, just like a done model that has two hidden states that it believes just to castically switch between each other.
And then you give it the task of making investments in like a 10 stock portfolio and of course its model is not fit.
But the promise of applying big deep function approximators to different ends of the PMDP agent means that hopefully you could then learn a good generative model and then still combine that with some lower dimensional generative model up top that can do all the nice
inference and planning with active inference, but it can deal with high dimensional or ugly hard to tame observation and action spaces by using deep neural networks.
So I think that's really the way to just in the same way deep learning has gotten that to work in a lot of cases. This is the way to kind of do it with with PMDP models as well.
Daphne any remarks or I'll ask a few from chat.
I don't really have any questions but I do think that is really fascinating and like I think it's really exciting to think about. Yeah, like as you said like learning the generative model of like an agent learning its own generative model given like some real world data to like figure out like what is
them and I guess like in terms of what you were talking about with like the function approximations and NumPyro and stuff. Is that still like what like pie DCM are you guys still working like from that code base and then final invert those are how to start from scratch.
Yeah, we pretty much started from scratch the pie DCM thing. I'm actually not sure what the like the IP status of that is because we worked on it as part of nested mine so I don't have access to that code anymore, but that was more implementing like
variational Laplace in which you were we worked on that together with variational plus in jacks which is the way that you do gradient descent done free energy when you're trying to do inference.
What we're doing now instead of that is we're saying, can you rewrite a time DP model such that you can pass gradients through it jacks like accelerated gradients and then use NumPyro to do all kinds of fitting routines not just variational Laplace, but you could use MCMC you could use like NumPyro just has a massive, you know, library of different probabilistic approximate a Bayesian inference techniques.
So you can kind of throw the kitchen sink of NumPyro inference techniques at a time DP model. So the challenge there is just rewriting a time DP model.
So you can define like a likelihood function that goes from like the time DP parameters to the observations which in this case would be the actions of the agent.
And in order to do that in a way so that can like play friendly with jacks we just had to make sure that all the interior functions of the time DP agent like the inference the planning action selection all that was written in jacks so that you can pass gradients through it when computing like likelihood gradients effectively.
Well, yeah, that makes a lot of sense.
Yeah.
All right, I'll ask a few questions from the live chat. So first.
Most descriptions of active inference across the literature are written in terms of matrices but pi MDP clearly works with tensors.
Do you have a good reference for how the operations are different when generalizing the equations from matrices to tensors.
That's a really good point. This is one of the things actually frustrated me a lot when I was first learning about active inference was I noticed exactly what this person asked is that a lot of the basic operations are written as if there's only single dimensional hidden states and single dimensional observations.
So everything is like they said matrix vector products and matrix math but what we're really doing is tensor multiplications and tensor products.
So in terms of references for how that works.
There's yeah so so essentially there's nothing super qualitatively different that these tensor operations that we do in pi MDP are basically just fancier ways of expressing sums of matrix multiplication so there's the math.
The mathematics of it is all still standard linear algebra is just the way we represent these high dimensional matrices as tensors is just a more efficient representation so mathematically it's nothing too crazy.
The way I learned about how that worked was just by staring at functions in MATLAB for like a year until I just figured it out but it wasn't easy and there's definitely better options out there now.
So one reference off the battle recommend is is the appendix appendices of pi MDP the paper the archive paper so that that like I think appendix A or if all those appendices basically deal with the full tensor factorized version where it's not dealing with matrices but we're actually indexing into higher dimensions.
Another one which I think originally discusses the tensor products and the tensor factorization is in an appendix of I think active inference curiosity and insight which is where they first talked about like novelty and parameter information game.
That's a paper I'm sorry I don't remember the year it came out to either 2017 or 2018 but I know the paper title is called active inference curiosity and insight and in one of the appendices they actually do the full tensor based mathematics.
And then finally another good reference is a recent paper that was I think headed by Theo Fio Champignon.
I'm just going to try to find it real quick because it's I don't want to forget this.
Maybe I'll stop sharing my screen.
Did I stop?
Okay.
It's a really good reference that has appendices about doing tensor math for active inference in particular.
We also recently learned about the branching time active inference which speaks to some of those questions of computational complexity and and all.
Right yeah I should have mentioned that that's like probably the most promising approach to date about the to finessing the computational complexity of active inference.
So yeah this this one is by Theo Fio Champignon, Mark Gresh, I guess that's one of his advisors and Howard Bowman his other advisor, and that is called multimodal and multi factor branching time active inference which I just posted.
So I haven't read this myself but I've heard from other people like I think Alec Chance told me that the appendices are really good for the full tensor generalization of active inference.
All right.
Awesome.
Well I've added all of those citations mentioned into the YouTube live chat.
Awesome.
Thank you.
I'm going to ask a following question and faster.
Using a jack's back end makes it easy to wrap py mc3 py mc3 around it, e.g. to have py mdp as an operator to use in a py mc3 model.
Is there any plan to do this.
I ask because there's a growing Bayesian community in Python around py mc3.
That's really interesting.
I didn't know actually that py mc3 was also had a jack's back end.
So I'm I don't know to be to be honest.
I'll start by saying that I don't know because my introduction to like probabilistic modeling in Python was through Demi Dimitri Markovic who basically sold me on NumPyro NumPyro is the way of the future.
And I know NumPyro has a jack's back end.
And I think NumPyro and py mc3 occupy a similar place in that ecosystem of probabilistic inference in Python.
I don't know how models are specified in py mc3.
I am assuming it's not too dissimilar from how it looks in NumPyro.
And because all the low level back end is now written in jacks.
I can't promise this but I would assume that you could just write a py mc3 model in the same way we wrote a NumPyro model that wraps py mdp functions but only the py mdp implementation in jacks.
So if py mc3 only depends on jacks at the low level then yes it certainly can work.
But I don't know is there anyone else here who has experience using py mc3 and might know.
Because I just don't know enough about it.
I use py mc3 a little bit but I think it is like yeah as you said like quite similar to NumPyro.
I think that probably you'd be able to do the same things that you're doing with NumPyro.
Like integrating NumPyro with py mc3 as well.
Ah cool.
And so it's primary on back end is jacks.
I didn't actually know that.
I didn't know that either.
In comparison with the matrix multiplication of MATLAB what makes you excited about the probabilistic programming direction and all of these packages and approaches that we're naming.
How does the probabilistic programming differ from just writing out the matrices and calculating them on paper.
And why does that have some promise for implementing active inference models.
I think the biggest advantage of the probabilistic programming is not necessarily for simulating active inference agents.
For simulating active inference agents for sure the matrix multiplications are sufficient.
Having it in jacks makes it much more scalable so you can use all the vectorized operations to run like tens of thousands of active inference agents simultaneously because you have these highly optimized just in time compiled functions and jacks that allow you to.
It just basically speeds things up in order of magnitude but the probabilistic programming angle is not as much for simulating active inference processes as it is for doing inference.
Or fitting models of active inference agents to empirical data.
So say I observe an animal or a person doing something.
