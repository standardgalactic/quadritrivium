Hello and welcome, everyone. It's September 30th, 2023. And we are in Physics as Information Processing.
Discussion five should be a fun discussion on a great fifth lecture. So, under if you'd like to give some opening remarks,
and then also anyone else, whether it's your first time joining a discussion or not, it would be great to hear your remarks on lecture five,
or just where you're coming at it today. So, first though, Andre.
Sure. Hello, Daniel. So, I may as well start off by sharing the slides, right? What do you think?
Sure.
So, just before, as a warm-up, let's review some of the things that Chris mentioned last time.
So, near the beginning, the main thing was this distinction between reductionist and scale-free theories.
Obviously, one very salient feature of the free energy literature is that it falls under scale-free theories.
These are theories where there is no preferred scale of energy or distance.
Reductionist theories are based on such a scale-existent, right? You want to break the pieces into the fundamental building blocks of the Lagos.
People think of usually high energy or particle physics as the archetype of this thing.
Whereas in scale-free theories, there is no such thing, and we should have the same skeletons or the same framework at different scales.
This is going to be very important. I, Chris, correct me if I'm wrong, but especially for the coming lecture where we talk about biology.
Chris himself made a few remarks on how the renormalization group flow, a.k.a. the process of going from smaller to higher scale, may be trivial in biology.
That is to say that there is a self-similarity.
Some features of biology should remain invariant at different scales.
That is, what cells are to a body, different individuals of a species, might be to an ecosystem. That sort of idea.
After talking about scale, and perhaps when we get to the question part, I guess this is the one thing that I would like Chris to explain a little more.
More precisely what these diagrams mean. I have a rough idea, but it would be nice to hear him talk about that again.
Anyways, in the second half, basically, we started asking, as is the theme in this course so far, from first principles, what do you need to talk about space and time?
And there were some theorizing that time might be more fundamental. That is, the things that you need to implement a clock.
We're thinking about what are the most basic constituents to implement a clock, and those may be even more basic than the things you need to implement.
After all, it seems like you need some spatial extension to perceive the space in the first place.
I can't remember if it was somebody who was tuning in for the lecture, or a question afterwards, or something like that.
But I think this remark gets to a very deep point.
Somebody, I recall, mentioned that some organisms, it might have increased himself, I can't remember really, that there are organisms, you may know the name, Daniel, that are so tiny, that if they try to implement a gradient to try to chase their food or whatever,
they're so small that they can't even perceive the gradient.
In any attempt at implementing such perception, they're going to feel the same amount of concentration in all directions, so they're basically not large enough to perceive space.
However, interestingly so, they can perceive time.
I don't know how this ties to the remarks that Chris made about space being more fundamental, I suppose.
Chris was getting at the point that you need fewer parts to perceive space, and the fact that such small organisms can't perceive time, but not space, I guess, is further empirical evidence for this thesis.
Actually, Andrew, if I can.
Yes, please.
I may have watched the explanation.
Yeah, I proposed earlier that time is actually more fundamental than space, that one has to have time to be able to see space.
So that's, further on in these slides, that issue is discussed.
Yeah, so do you want to say something about that, Chris?
Well, this is the right slide that, yeah, one just needs a memory, really, to have an external clock.
I mean, to have an internal clock when also has to have a memory to have an internal clock, but if you have a memory, and there's some kind of activity that's periodic in the environment, then you have a clock, an external clock.
But you don't need object identity to have a clock.
And that's what distinguishes it from space.
You have to have object identity.
Or in other words, motion, the ability to perceive motion to perceive space.
Right.
Yeah, any periodic behavior is effectively a clock.
Whereas, you know, for space, we need object persistence, which two comments that we've made, where that object persistence is the, or rather Chris made, is the defining feature of classicality.
You said that last time.
Is that right, Chris?
And also, that object persistence is precisely the notion of thickness, the way Christen would put it.
Yeah, object persistence is definitely a classical notion.
And it does seem to be the place where classicality enters quantum theory.
As far as I can tell is with this notion of object persistence, that that's the most fundamental place that it enters.
So how does that definition of, or rather, relationship between classicality and quantumness being object persistence?
How does it compare with other accounts coming from QDAR and decoherence and all of that?
Well, I'll say quantum Darwinism is a good example.
Quantum Darwinism assumes object persistence, but it assumes that there is some persistent thing that interacts over time with the environment according to some interaction that has fixed eigenvalues.
So quantum Darwinism already assumes object persistence, and it also assumes classical communication, as we discussed a couple of times ago, in that it's a theory that is about the ability of multiple observers to agree about the state of some other object,
which for them to agree about that object, not only does the object need to persist, the various observers need to have the same description of that object,
or the same name for that object, or the same way of identifying that object.
So yeah, quantum Darwinism actually assumes a lot of classical features.
The basic theory of environmental decoherence is, in effect, a single observer theory, so it doesn't have to assume classical communication, but it does assume object persistence,
which obviously, if we're going to talk about empirical science, you have to, right?
You have to assume that your detector is a thing that persists through time, or you can't do any experiment.
And more importantly than that, you have to assume that you're a thing that persists through time.
So we need these classical notions to talk about doing science.
I'm not the first person to point that out, of course.
I mean, Bohr pointed that out in 1928 in his paper in Science, where he summarizes quantum theory.
So it's a very, very old idea.
Right.
And I guess, right away, I have a question that I suspect I may have asked before, but maybe we can revisit it from the perspective of today's discussion, which is, and maybe I should pull the slide.
This is actually from session four.
So if we're talking about differences between what the defining feature of classicality is, to me that bears the question of here, right?
This TQFT diagrammatic notation for the classical and the quantum channels.
So if we're talking about object persistence as the defining feature of classicality, and this is the cartoon picture of what goes on on EPR experiment.
Chris, could you say maybe a few words about how the symmetry is broken between the quantum and classical channels?
I suspect it might have been mentioned that these are symmetrical, but yet one of the two has to be a quantum and the other one is a classical channel.
The quantum channel mediates some sort of unitary evolution.
Is that correct?
Whereas the classical channel is like an information redundancy reservoir, which maybe has to do something with object persistence, but I'm very much speculating at this point.
So I'm not sure if Chris, do you have any comments?
Yeah, well, an easy way to think about this, I think, is to actually think about a Bell EPR experiment where you have two observers that are separated in space.
So you have to assume here to talk about Bell EPR, you have to assume the notion of space to have a laboratory reference frame in which the two observers are spatially separated.
And in that situation, then the two observers both independently collect data for some amount of time on multiple replicates of some quantum state that's produced by a source.
So you have pairs of photons or pairs of electrons or pairs of whatever.
And at some point, the data collection stops.
And at that point, the observers have to compare their results.
So it's the comparison step that requires a classical channel.
And if you think about how this happens in practice, it happens via a file sent over the internet or a piece of paper on which the data are written that's handed by one of the experimenters to the other experimenter.
It happens by the experimenters talking to each other.
So one experimenter encodes a bunch of information in the ambient air and the other experimenter hears it.
Or it can be communicated by light signals, right?
But it's always communicated by some medium.
And that's what defines classical communication.
It's communication via a medium that persists through time in the observer's reference frame.
And the minimum time of the persistence of that medium is given by the speed of light.
So if the observers are a foot apart and they're communicating by a light signal, then it may only last a nanosecond.
But if they're talking to each other, it lasts several seconds.
And if they exchange a piece of paper, then that piece of paper may last for years in a lab notebook someplace.
So there's always the question of persistence over time that is deeply bound up with this notion of classicality as a process that takes time.
Information has to flow, has to be encoded in a medium and then read from that medium in some finite amount of time.
And in a sense, we're assuming something like that in the quantum description.
When we think of this boundary via which the A and B, the physical components interact, if we think of that boundary as a qubit array, then each of those qubits persists through time.
And that's what allows them to encode classical information.
So encode observational outcomes that are repeated in time.
That's what allows them to serve as a memory, to encode information in a way that's thermodynamically irreversible.
And if you think of the boundary in that way as a qubit array, then it has a certain thickness in time.
It's two plank times thick.
The plank time is 10 to the minus 43 seconds, so it's unmeasurably small.
But the operation of interacting with a qubit is a physical interaction that a relativistic point of view has to take this minimal time.
So it's in a sense persistence for times that are significantly longer than the plank time.
That is the marker of classicality here.
But even these plank time, even persistence over the plank time,
is a necessary ingredient for talking about communication, even quantum communication.
So it's a very, very deep concept with a very long philosophical history going back to the ship of Theseus and all that.
People have been wondering about what does it mean to say that something persists through time?
Does anyone want to make a comment on that or bring in a new question?
Please feel free to, if you haven't brought up anything yet.
Sure, I can speak more.
I also recall, and Chris, correct me if I'm wrong.
We said that, related to what you just said, that clock tick is always tantamount to one of these classical channels.
Is that correct? Did I remember that correctly?
Chris?
Yeah, an internal clock tick corresponds to an irreversible right on the boundary.
So one can then ask, what does it mean to say that that's irreversible?
What it means is, it took some energy to do it.
And if you go back to read that bit again, there's at least a reasonably high probability that it still is in the same state that you wrote it in.
And clearly that probability is going to degrade through time because that action is on the boundary.
So whatever you've written, whatever bits that you've written are now exposed to the environment.
So if Alice writes that they're now exposed to Bob, and to Bob's dynamics.
So as time goes on by your internal clock or any external clock, the probability of that memory being the same, when you go back to read it, slowly decreases, or maybe it decreases fast.
And we know that from our own case, our own memories degrade through time.
Because the physical world's interacting with our brains in ways that we don't control.
Killing neurons or changing their activity or whatever.
So whenever we talk about memory, it's always with this caveat that the memory is exposed to the environment, and it's not guaranteed to be the same.
It's only kind of grace of the environment being reasonably benign that any of us had memories at all.
So this thermodynamic cost to classical information sharing or writing, would it be fair to say that in a sense the price you'd have to pay to protect against decoherence or entangling this sector with the rest of the environment just to preserve its identity?
Would that be fair to say?
Yeah, I mean you can think of decoherence as a good thing or you can think of decoherence as a bad thing, right?
If you're trying to preserve a quantum state, then it's a bad thing.
You have to spend energy to prevent decoherence by cooling everything down to Millie Kelvin's.
But if you're interested in preserving classical data, then decoherence is a good thing because it prevents your classical data from being completely rearranged by becoming entangled with the environment.
So I mean think about trying to write classical memories using the states of atoms in the middle of the sun and the temperature so high that you can't do anything.
You can't rearrange the atoms in any way and expect them to stay put.
So there you're in effectively a completely quantum environment just because of the high temperature. So it's a plasma.
Yeah, and then just one final question that popped to my mind as you say this, and I can certainly leave it here for everyone else.
So if we're trying to protect against random loss, against the loss of information, I suppose it really begs the question of what is the source of this noise that can perturb the bits in the boundary.
There's obviously this distinction between thermal and quantum noise. Again, it's a stretch to see if we can think back with rotation about that.
But again, I recall earlier sessions where we talked how the noise here in this quantum theoretic picture of information processing is coming from the QRS failing to be aligned.
Then you hear about notions of quantum noise versus thermal noise. Chris, do you have any comments on all of that?
Yeah, I think an important thing here.
Let me back up. The notion of noise, like so many other notions, is very often treated as objective, as observer-independent.
And so when we're doing classical physics, we think of noise as just, you know, there's some objective randomness in the universe and we call that noise.
So in this picture, because we're working with just a bipartite decomposition, right, we just have Alice and Bob, and that's it.
That's the entire universe. There's no external environment here to impose any sort of noise.
But since we only have two systems, Alice and Bob equals everything else, you know, not Alice, then if we talk about Bob being a noisy environment, that's clearly relative to this boundary we've drawn between Alice and Bob.
So noise isn't observer-independent. What's noise for Alice is just Bob's dynamics.
Right. So if you think about where these systems come from, you've got some universe that is in some pure state because it's an isolated system.
And that state is evolving through time, which means it's just undergoing phase rotation.
So there's no noise in that system, right? It's perfectly unitary, et cetera, et cetera.
As soon as you draw a boundary, then there's information that the system on one side of the boundary doesn't have about the system on the other side.
So the individual systems are, their states can now be considered conditionally independent.
I mean, you can come up with a description in which their states are conditionally independent.
And that just means that what the other side is doing looks like noise unless Alice can come up with a way of analyzing the data that she sees on her boundary in a way that makes it make sense.
Right. And then we say it's information for Alice, but what does that mean?
It just means it's behavior on her boundary that she's smart enough to assign some kind of semantics to it.
And if she's not smart enough to do that, then it's just noise.
So as soon as you make the notion of noise observer dependent, it turns into something that makes a lot more sense.
And just to really finish this, I guess it's been a couple of months at least, but I think it was back in July that we talked about the distinction between what you're saying, which is things having the appearance of noise just because you have finite resources.
It does not make sense of Bob's internal dynamics as opposed to in that cartoon of the four possibilities for correct alignments, right?
Some of them were thermal in the sense that one side was acting on a boundary curate while the other one was not.
So then it truly looks like noise to the other side.
Does that get to the bottom of the distinction between quantum and thermal noise at all, Chris, or am I misunderstanding things here?
Yeah, it turns the distinction into essentially a QRF relative distinction.
I mean, languages provide a good example.
I mean, think of going to some place where you don't understand the language at all, like, you know, Hapa New Guinea or something like that.
I certainly wouldn't understand the language.
That language, the behavior is speaking that language encodes lots of information for those people and it encodes no information at all for me.
So it looks like noise to me.
I can't make sense of it, but it's not noise from their point of view.
And now let's think about this need to have a thermodynamic sector if you're an organism that has to burn energy or any system that has to burn energy to act irreversibly on your environment.
Oh, that thermodynamic sector looks to you like noise, but it's just temperature heat.
And you use that heat to drive your processing.
And if you're a really good heat engine, then you can use it pretty efficiently and get, you know, a lot of bang for the buck in terms of information processing.
If you're a really inefficient heat engine, then maybe you have to use almost your entire environment as heat to do any little bit of information processing at all.
So that's not a statement about the universe as a whole.
That's the statement about you and your information processing capabilities and your, and your thermal, your heat processing capabilities, you know, how good is your Carnot cycle determines the amount of information processing you can do.
Thank you, Chris. I'm Ian.
Hi.
Yeah, thank you everyone for putting on this series is the first time I've joined the discussion sessions.
And yeah, so it's a question about in one of the slides there was a green rectangle.
And we were talking about that being a or Chris was talking about that being a kind of thinking of that as a bacterium.
And it got me wondering whether I think how else I could get an intuitive grasp of this kind of space time emerging.
And so what I was thinking is, you know, it appears like to us humans, it appears like the universe is expanding through time.
And I was just trying to think, you know, a bacterium sing if you place the single bacterium on a petri dish at time zero.
And even something more simple, you know, let's say deep sea hydrothermal vent where life was supposed to are, you know, these agents were supposed to have maybe begun existing as phospholipid type molecules.
So I was just wondering, you know, if I was if I was a phospholipid within that bacterial membrane, just a single one single phospholipid.
And all I can measure is the existence of phospholipidness or not phospholipidness or and selfness and not selfness.
Then, you know, I was just trying to imagine as this bacteria divides after 20 minutes, let's say average sort of bacterial division time.
Then before that happened, all I could tell was I was surrounded by phospholipidness.
