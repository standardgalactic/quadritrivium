few research groups engaging in it. And it's just really cool what it's enabling.
No, yes, yes, exactly. I mean, that's also, I think the exciting part of this field a little bit
that is, I mean, there are definitely break breakthroughs out there that, that still have
to be discovered and probably like, for example, like, or as much as a breakthrough that paper was
they found like, they simply found out the right prior for acyclic structures. Okay, it's a
yeah, I mean, I, I don't know exactly, but it may be an idea that you have in one afternoon.
I don't know about the story of the, how the authors came up with that, but could potentially be
that if they, they are there at the whiteboard, you're like, Oh, that actually works. That's a
huge breakthrough. And I simply defined the prior. And also a lot of these breakthroughs,
they, they don't just stack. It's not like a, a tower of blocks, they layer and they compose.
So then something will be generalized to generalized coordinates or generalized
synchrony or arbitrarily large graphs or sensor fusion with multimodal inputs. And it's like those
all blend in really satisfying and effective ways. So, so even little things that again,
someone can just come up with in a moment can really have impact. Okay, ML Don says,
thanks a lot for asking my questions and thanks a million to Tomaso for the inspiring presentation.
So nice. Thank you very much. And then Bert asks,
how would language models using predictive coding differ from those using transformers?
Okay, I think that actually, if I would have to build today a language model using predictive
coding, I would still use transformers. So the idea is that, for example, if you have a,
let's say this hierarchical graphical model, or this hierarchical Bayesian network,
I've defined in the, in the very first slides, one arrow to encode a function, which is the linear
map. Okay, so one arrow was simply the multiplication of a, of the vector encoded in the latent
variables times the, this weight matrix that you can then make non-linear and things like that.
But that can be actually something much more complex. The, the function encoded in the arrow
can be a convolution, can be an attention mechanism. So, so actually how I would do it,
I will still use the, I mean, which is actually the way we did it in, in, in the Oxford group last
year is that we, we had exactly the structure. Every arrow is a transformer now. So one is
the attention mechanism and the, the next one is the feed forward network as transformers.
And basically the only difference that you have is that those variables you want to compute the
posterior and you make those posterior's independence, independent via, via mean field
approximation. So basically you follow all the steps that allow you to, to converge to the
very, to the variational free energy of creative coding. But the, the way, the way you compute
predictions and the way you, you send signals back is a, is done via transformer. So I will
still use transformers in general. I mean, they work so well that I, I don't think that we can be
arrogant and say, oh no, I'm going to do it better via a purely predictive coding way.
Structure learning is a way to do it, but we'll still approximate transformers anyway.
So you said structure learning would approximate the transformer approach?
Yes. Destruction learning I mentioned earlier in, when, when someone asked the similarities
between predictive coding and the attention mechanism.
Very, yeah, very interesting. One thing I am wondering from MLBong, I could not see the
concept of depth in the predictive coding networks you mentioned. Most likely I missed it. The
definition provided for predictive coding involved the concept of depth. What did you mean by depth?
No, yes, it's true. It's a, because the standard definition, as I said, multiple times is a,
is hierarchical. You have predictions going one directions and prediction error going the
opposite direction. Basically, what, what we did in, in this paper and also in the last one in
which is called the learning on arbitrary graph topologies via predictive coding
is that we can consider depth like as a, as independent, basically pair of latent variable,
latent variable, and arrow. And you have predictions going that direction and prediction
error going the other. But then you can compose these in how many, a lot of ways. So you can,
you can, so basically this composition doesn't have to be hierarchical in the end.
Can have cycles. So then you can, for example, plug in another,
another latent variable to the first one, and then connect the other two. And you can have a
structure that is as entangled as you want. So for example, in the, in the other paper, we train
the, a network that has the shape of a brain structure. So we have a lot of brain regions
that are sparsely connected inside and sparsely connected among each other. And, and there's,
there's nothing hierarchical there at the end, but you can still train it by minimizing
a ratio of free energy and by minimizing the, the total prediction error of the network.
So you could have for a given motif in a entangled graph, you might see three successive layers
that when you looked at them alone, you'd say, Oh, that's a three story building.
That's a three layer model that has a depth of three. But then when you take a bigger picture
there isn't like an explicit top or an explicit bottom to that network.
Yes, exactly. And this is basically given by the, by the fact that every operation in
creative coding networks is strictly local. So, so basically every message passing every
prediction and every prediction error that you send, you only send it to the very nearby neurons.
Okay. And whether the global structure is actually hierarchical or not,
the, the single message passing doesn't even see that.
I guess that's sort of the hope for learning new model architectures is the space of what is
designed top down is very small and a lot of models in use today,
albeit super effective models. Although you could ask effective per unit of compute or not,
that's a second level question. But a lot of effective models today do not have some of these
properties of predictive coding networks, like their capacity to use only local computations,
which gives biological realism or just spatio temporal realism, but also may provide a lot
of advantages in like federated compute or distributed computing settings.
No, yes, exactly. I completely agree. I think the idea in general is that, and I don't know if
that's going to be an advantage. I think it's very promising exactly for the reasons you said.
And the reason is that today's models string with back propagation,
you can basically summarize them as a model string back propagation is a function,
because basically you have a map from input to output, and back propagation basically
spreads information back from its computational graph. So every neural network model used today
is a function. While predictive coding and not only predictive coding, like the whole class of
functions, the class of methods that train in using local computations and actually work by
minimizing a global energy function, they're not limited to model functions from input to output.
They actually model something that kind of resembles physical systems. So you have a physical
system, you fix some values to whatever input you have, and you let the system converge,
and then you read some other value of neurons or variables that are supposed to be output.
But this physical system doesn't have to be a feedforward map. It doesn't have to be a function
that has an input space and an output space, and that's it. So the class of models that you can
learn is also basically you can see like feedforward models and functions, and then a much bigger
class, which is that of physical systems. Whether there's something interesting out here, I don't
know yet, because the functions are working extremely well. We are seeing those days with
back propagation, they work crazy well. So yeah, I don't know if there's anything interesting in
the big part, but the big part is quite big. There are a lot of models that you cannot
train with back propagation, and you can train with predictive coding,
or a background propagation or other methods. That is super interesting. Certainly biological
systems, physical systems solve all kinds of interesting problems. But there's still no free
lunch, and ant species does really well in this environment might not do very well in another
environment. And so out there in the in the hinterlands, there might be some really unique
special algorithms that are not well described by being a function,
yet still provide like a procedural way to to implement heuristics, which might be extremely,
extremely effective. No, yes, yes, exactly. And yeah, and I think this has been most of my
focus of research during my PhD, for example, like finding this application that is like out
here and not inside the the functions. Cool. Well, where does this work go from here? Like,
what directions are you excited about? And how do you see people in the active inference ecosystem
getting involved in this type of work? I think every probably the most promising
direction, which is something maybe I would like to explore a little bit is to, as I said,
there is to go behind statistical models. So everything I've shown so far is about static
data. So the data don't change over time, there's no time inside the definition of
predictive coding as it is as I presented it here. However, you can, for example,
generalize predictive coding to to work with temporal data using generalized coordinates,
as you mentioned earlier, by by presenting it as a as a Kalman Kalman filter generative model.
And and that's where, for example, the causal inference direction could be very useful,
because at that model, in at that point, maybe you can be able to model Granger causality and
and more complex and and useful
dynamical causal models, basically. Because in general, the the due calculus and the
interventional and counterfactual branch of science is mostly developed on on small models.
So it's like you don't do interventions on gigantic models in general. So if you if you
look at medical data, they use relatively small vision networks. And but of course,
if you want to have a dynamical causal model, that models a specific environment or a specific
reality, you have a lot of neurons inside, you have a lot of latent variables, they change over
time and an intervention at some more at some moment creates an effect in a different time step.
So maybe the next time step in 10 different time steps later. And I think that would be
very interesting to develop like a biologically plausible way of passing information
that is also able to model Granger causality, basically.
Where do you see action in these models?
Where do I see action? I didn't think of that. I think I see actions in those models,
maybe in the same way as I as you see in other models, because
creative coding is basically a model of perception. So so an action is you can see
that's a consequence of what you're experiencing. So by changing the way you're you're
experiencing something, then you can compute maybe you can simply perform a smarter action
now that you have more information. But but yeah, I don't think action is very easy. Like,
yeah, I don't see any explicit consequence of actions, besides the fact that this can allow
you to basically maybe to simply draw better conclusions to then perform actions in the future.
I'll add on to that a few ways that people have talked about predictive coding and action.
First off, internal action or covert action is attention. So we can think about perception
as an internal action that that's one approach. Another approach pretty micro is the outputs
of a given node. We can understand that node as a particular thing with its own sensory cognitive
and action states. And so in that sense, the output of a node. And then lastly, which we
explored a little bit in live stream 43, on the theoretical review on predictive coding,
we're reading all the way through. And it was all about perception all about perception. And then
it was like section 5.3. If you have expectations about action, then action is just another variable
in this architecture. And that's really aligned with inactive inference, where instead of having
like a reward or utility function that we maximize, we select action based upon it being the
likeliest course of action, the path of least action, that's Bayesian mechanics. And so it's
actually very natural to bring in an action variable and utilize it essentially as it as if it were
a prediction about something else. Exteroceptively in the world, because we're also expecting action.
No, yes, yes, exactly. No, I like the way of defining actions a lot, actually. And I still
think if it's been like, for example, there are not so many papers that apply this method. I think
there are a couple from from Alexander Orobrie does something similar. But in practice, like
outside of the pure active inference, like applying predictive coding and actions to
solve practical problems hasn't been explored a lot.
Well, thank you for this excellent presentation and discussion. Is there anything else that you
want to say or point people towards? No, just a big thank you for inviting me. And
it was really fun. And I hope to come back at some point for for some future works.
Cool. Anytime, anytime. Thank you, Thomas. So thank you, Daniel. See you. Bye. Bye.
You
