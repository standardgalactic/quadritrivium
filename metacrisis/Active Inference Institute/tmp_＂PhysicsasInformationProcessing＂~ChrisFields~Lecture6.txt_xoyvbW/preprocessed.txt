Hello and welcome everyone. It is October 12th, 2023, and we are in the final lecture,
session 6 in Physics is Information Processing with Chris Fields. So Chris, thank you for
this journey. Exciting to get to this final lecture, which will be followed only by the
last discussion for this go-around, so it's really awesome. And to you for this lecture.
Thank you Daniel, and welcome everyone to this last session that I'll be doing
with a focus on biology. And just to give a brief review as usual, we've focused in this course
on generic quantum systems, by which I mean just any quantum system that has some number of degrees
of freedom. And we really haven't made any assumptions about these systems other than the
assumption that both interacting partners have sufficient degrees of freedom that they can be
considered separable. So their boundary is small with respect to the total size of each of the
interacting systems. And I want to emphasize again that the approach we've taken is completely
topological, so we haven't assumed anything about embedding in space. And as we've characterized
these systems, we focused really on two things. One, the amount of information that the two systems
can exchange, and that amount is determined by the size of their boundary. It's determined by
this number N, which is the Hilbert space dimension of the boundary. And as we've discussed now on
several of the sessions, we can think of this boundary as a collection of N qubits, via which
the two systems A and B communicate. The other feature of the interaction on which we focused
is the reference frames that are used by the two systems to interact with this set of qubits.
And it's these reference frames that assign the information that flows between A and B
meaning or functional significance or actionability or however you want to
refer to the idea that when a system gets some information, it does something useful with it.
So those are very generic kinds of ways of characterizing an interaction.
You can think of it as a qualitative characterization, the semantics of the information,
and a quantitative characterization, the amount of information. But other than that,
we've left the nature of these systems open. And this characterization allowed us to reformulate
the free energy principle in quantum information theoretic terms as the principle that interacting
systems behave in a way that will asymptotically align their reference frames. And we saw that
full alignment of reference frames is equivalent to entanglement. So the FEP drives systems toward
entanglement, which is not surprising because that's what happens to generic quantum systems.
They may start out separable, but if they interact long enough, they'll become entangled.
So we've had a discussion that is really very generic.
Now, we showed a couple of sessions ago that under these very generic assumptions,
we got some interesting outcomes. And one is that if systems have sufficient degrees of freedom,
under the action of the FEP, they will be driven toward making
a diverse set of measurements of their environment because they're trying to get
information about it so that they can predict what it's going to do.
And that as they add ways of making measurements, they'll come up against
non-commutativity of their measurements. And this may be due to intrinsic mathematical
facts about their measurements, and it may just be due to their limited supply of free energy.
So either way, what this induces is compartmentalization and the requirement for internal classical
communication on internal boundaries. So I just wanted to reemphasize that this is a result of
basic physics, and we see compartmentalization, of course, ubiquitously in biology.
But this suggests to us that features of biology that are very familiar
actually follow from fairly deep physics, and compartmentalization is one of them.
We then talked last time about space and time and the computational requirements
of on any system that is able to perceive an external clock or perceive an external spatial
layout. And we discussed this these from a very kind of developmental psychology point of view.
We discussed it using essentially the kinds of terms on the right here, as opposed to
the kind of language that's much more technical and mathematical that's used in physics to
derive space time as emergent from information transactions.
But we at least hypothesized that both of these are ways of getting to the same sense of emergent
space time. And one important outcome of this discussion was that systems can perceive external
clocks. So external periodic behavior with fewer computational resources. So before they're able
to perceive spatial layouts. And we'll get back to this later. So organisms and maybe other
complex systems seem to manage a collection of capabilities that are all mutually dependent.
So memory depends on having layouts of persistent things that can be distinguished.
So it depends on space. And it certainly depends on time.
Space gives structure to persistent objects. Memory allows you to identify persistent objects.
And objects in turn give structure to space by being located in different places.
And objects enable the fundamental requirement for memory, which is some form of error correction.
So that one has enough redundancy in the memory to check to see whether a memory has been degraded.
So organisms seem to manage a physically very important process, which is the use of space time
and memory as a basis for cognition. You'll recognize these four functions that are mutually
interdependent as underlying complex cognition across the board. And you can't really do complex
cognition unless you have these capabilities. So today we're going to put some of these things
together in a discussion of biology and end by looking forward to future directions,
not just in biology, but in all of quantum information theory.
So let's talk about biological systems, living systems, which of course includes us,
but also includes all other organisms and communities of organisms and so forth at multiple scales.
And I want to put forward a fairly radical hypothesis that living systems are just generic
quantum systems that the FEP has driven to a high level of computational complexity.
So what does this really say? It suggests that living systems are just quantum systems
that have enough degrees of freedom and a sufficiently complicated internal dynamics
that the FEP, by requiring them to predict what their environment is going to do next,
has driven them to make complicated measurements and complicated inferences on the basis of those
measurements that enable fairly complicated actions on the environment. So these are systems
that you would characterize as computers, essentially information processing systems,
with a high degree of computational capability. Now this is clearly as much a philosophical
hypothesis as an empirical hypothesis, and that's due in part to the fact that we don't
really have a good definition of what a living system is. We can just point and say, you know,
that's a living system and that thing over there isn't. But beyond that, we don't have much of the
theory. And of course, people have worked on a theory of what is life for decades,
but there's not a lot of agreement. And so this is in a sense a definitional
kind of hypothesis. And we test such kinds of hypothesis by seeing if they're useful conceptually
to help us understand what living systems are doing. Now as soon as we put forward something
like this, inevitably the question comes up, are living systems really quantum systems?
Or are they classical in some intrinsic sense? And this question is really an artifact of two
things. One, the continuing association between quantum systems and microscopic systems,
which is of course traditional. Quantum theory was developed to deal with microscopic phenomena.
It was first tested as a theory of microscopic phenomena. And it's only in the past couple
of decades that quantum theory is being applied to big things, to cosmology, for example.
So there's a long tradition of association between quantum and microscopic and living
systems are mesoscopic, much bigger than atoms, bigger than molecules. And they're not nearly
as big as cosmological systems. So they're somewhere in between. And those systems have
traditionally been regarded as classical. And even chemistry, even biochemistry, is still taught
in a very classical way. So we're not used to thinking of these things as quantum systems.
But at least in the approach we've taken in this course, all physical systems are quantum systems
and classical information exists only on boundaries, only on boundaries between systems.
And it only describes their interaction. And I want to emphasize, I mean, I've said it before,
but since this is the last class, I want to say it again, that this is not a universally held view.
It's a view that's becoming more common. And I think a generation from now will probably be
the dominant view of things. But it's not fair to say that it's the dominant view now.
It's, I think, quite fair to say that it's a view on the rise, especially in the quantum
information and quantum gravity communities. But from a strict empirical perspective,
we know a number of things. We know that accurate molecular dynamics calculations
require quantum theory. We know that a lot of biologically important molecular processes
use quantum coherence. We know that things like hydrogen bonding can only be understood
using quantum theory. We know that cellular free energy budgets are way too small to support
fully classical information processing. If we think of information processing in terms of what
proteins are doing or what other molecules are doing in terms of changing shape, we know that
shape changes in proteins and other molecules underlie all cellular information processing.
So if we think of them as actually implementing cellular information processing, we have way
more information processing than could be funded classically. And finally, we know that human
cognition exhibits contextuality. So human cognition uses quantum coherence. It's not
a classically, a classical causal process in all cases. But this is still a very nascent field.
And it's a field with a lot of potential. And I think, again, a generation from now,
quantum biology is going to be regarded as a very mainstream endeavor,
even though it's something of a small emerging field now. And I'll just show you one picture
in support of this third point. This is a plot of measured free energy usage converted to
numbers of bits processed at one kilohertz, or a number of prokaryotic and eukaryotic cells,
all that I could find a few years ago that had good teleometric measurements,
versus the log of their area, their membrane surface area. And the thing to note here is that
these cells are processing classical information at pretty low rates, kilohertz to gigahertz rates
for a thousand bits at a time. And we know that a lot more is happening in cells than that.
Cells have many more than a thousand proteins, and those proteins are all moving all the time.
And if that motion is processing information, then there's not nearly enough classical,
not nearly enough thermodynamic power to power all of that information processing.
So let's now talk a little bit about life and living systems, and what they look like.
Here's a view of living systems from the point of view of genome diversity. This is a few years old,
so it's out of date by now. But it tells us a lot qualitatively.
It tells us that almost all genome diversity is microbial, that the sorts of organisms that
we're familiar with, medium-sized organisms like us, animals and plants, have only a tiny amount
of genome diversity. So we think of ourselves as pretty diverse. We think of ourselves as quite
different from other animals, from flies or worms or sponges or something like that.
But in fact, we're not all that different from them. We share many, many proteins with all of
those other organisms. We share the same cellular organization and so forth. We're not, in fact,
all that different from plants. And we're much more similar to the fungi than to the plants.
So we get a very biased view of genome diversity when we just look at familiar, large types of
living systems. Most genome diversity is buried down there in the microbial world.
This isn't the only way we can look at life as a diverse set of organisms. We can also look at it
in terms of a cell lineage. The fact that we're all related at the DNA level
tells us that we're all descendants of a common ancestor, which is usually called Luca, the last
universal common ancestor. And Luca is generally modeled as being a cell, more or less like a
bacterial cell, so fairly simple with not very many pathways, with maybe a DNA genome. And if Luca
didn't have one, then they arose fairly shortly thereafter because all organisms that we know
of have DNA genomes. But the point of looking at life as a lineage is that we get a diagram
that looks very much like the cell lineage from an embryological situation, much like the cell
lineage of our own bodies growing from a fertilized egg. And in particular, looking at life as a
lineage shows us that not only do we share DNA with all other organisms, we actually share a
membrane, a cytoplasm, that's continuous in time all the way back to Luca. And so continuous in
time between us and bacteria. So if you look at life this way, you realize that life is in a sense
all one organism, all one connected structure that's developed over time through division, cell
division. And so we're very closely related to all other parts of life in the same way that
different cells in our bodies are closely related to each other. The time span's just longer, I mean
here the time span's three and a half or four billion years between us and Luca. These lineages
have been diverging for that long, but they're still continuous. And in particular,
they form a continuous cell membrane. So when you think of life in this way, we realize that we are
reasoning from just one example when we think about terrestrial life. And this strongly limits
what we can say about living systems, what we can say about biology, that we really only have
one example, the lineage that descends from Luca here on earth. And at some point we may have more
examples, and there's certainly groups working on artificial organisms that aren't part of this
lineage, that are constructed from parts derived from this lineage, but aren't members of this
lineage themselves. And that may tell us something new about life. But if we think of life this way,
we see something very important, which is that as life grows, its boundary gets bigger.
And since the boundary of a system constitutes its informational environment,
its dimension getting bigger means that more information flows into it from its environment,
and more information flows out of it into its environment. So as life develops from Luca,
it gets a larger and larger informational environment, and this dimension of its
boundary grows and grows. Now what that means if you go back to our original picture of two
interacting systems, is that the number of the dimensionality of the physical environment is
decreasing. And we think of the physical environment as increasing in size, we have the expanding
universe and all that. But what's increasing in size is space. And if space is emergent,
then that increase is not a real increase in degrees of freedom. What we're really interested in is
the Hilbert space of the physical environment as distinct from the Hilbert space of life.
And as life gets bigger, it literally, quite literally eats the physical environment and
it turns it into more life. So there's less physical environment around. So the trajectory
of life is toward a bigger informational environment, a smaller physical environment.
And as the physical environment gets smaller, you might imagine it gets easier to predict.
And as the informational environment gets bigger, you have more information with
which to predict the behavior of the physical environment. So this all hangs together very
nicely with the free energy principle. Here's another picture of this same thing.
If we start with some boundary here on the left labeled B around some system
labeled S and it's embedded in an environment E, then as S makes copies of itself,
through some process like cell division, then it starts to fill up more of E. It's actually
converting degrees of freedom of E into degrees of freedom of its copies that it's made of itself.
And if we think of some larger boundary drawn somewhere in E, here on the right side, I've
labeled that B prime. What happens is that B prime gets slowly filled up with copies of S
and it starts to look like a large organism. And that's what life is doing in the physical
environment. It's making a bigger boundary for itself at the expensive degrees of freedom of
its physical environment. So we can ask, what drives this process? Why is life doing this?
Why is it making copies of itself? And the answer to that question, at least one answer
to that question, is the free energy principle drives it to do this. And I'll just show you
some simulations from several years ago of a cell population in this upper left panel. The
green cells are stem cells that divide and they've been embedded in an environment that's safe on
the left side and 100% lethal on the right side. So they're embedded in an environment that's
that's conducive to life on one side and very dangerous as you get toward the middle.
And the purpose of these simulations was to study what happens when the stem cells are able to
divide and create not just other stem cells, but create specialized progeny that don't divide.
So somatic progeny that don't divide and hence have free energy resources,
thermodynamic resources that they can devote to doing something other than dividing.
Cell division is incredibly expensive when it comes to energy. So if you take that energy
and apply it not to cell division, but to protecting the stem cells,
you can allow the stem cell population to expand. And that's what these other
simulations show. The blue cells are somatic cells that have very varying ability to protect the
stem cells. And if they're fairly good at protection and they're fairly hard to kill
down in the right bottom quadrant, you can actually get a population expanding well into
the highly lethal part of the environment. So this shows you the FEP in action.
What the stem cells are doing is constructing a very predictable neighborhood around themselves
in the environment by dividing to make progeny that don't themselves divide, that just
sit there and help protect the stem cells. So the stem cells are now living in a safer,
more predictable environment. And that allows them to invade more and more of their physical
environment by having this fairly benign informational environment. So this is the FEP in
action, driving the expansion of life at the expense of the physical environment.
So that lets us go back to this question that was raised last time about the mechanism
of these scale transitions that we see ubiquitously in life. Life gets bigger and bigger
as time goes on phytogenetically and as time goes on developmentally. We start with some
molecular pathways that somehow get assembled into a cell. That's the origin of life question.
How does that happen? And about 2 billion years later cells start to group together to make
multi-cellular organisms. Now bacteria group together to make facultative multi-cellular
systems like microbial mats 3 billion years ago, very, very early on. But we don't see the emergence
of obligate multi-cellulars until much, much later before the Cambrian explosion, but still
less than a billion years ago. And from there things get more complicated very quickly. So
one has large multi-cellular organisms. They develop complicated social relations
that probably first emerged with social insects but are certainly well developed in invertebrates
including in mammals. Organisms group together in very complex ecosystems and recall here that
it's now known that all multi-cellular organisms have obligate microbial symbionts. So all of our
bodies are in fact very complex ecosystems populated by many, many different species of bacteria.
And that's true not just for us but for trees and insects and worms and sponges and everything else.
So
organisms from a body point of view are themselves ecosystems and organisms
organize themselves into ecosystems and these ecosystems come into contact
across the entire biosphere. So process is as simple as the wind
disperse organisms as small as bacteria all over the planet. So this scaling of life toward
larger and larger organizational structures is in a sense the major thing for biology to explain.
And the hypothesis that we floated last time was that this transition from very small scales
to very large scales uses the same mechanism over and over again or a mechanism that has
the same structure over and over again. So the the renormalization group is is trivial
basically it's this it's just the identity operating at different scales
or mapping from one scale to the next. So the question is can we can we approach this in any
way? Does this make sense? And to try to make sense of it we can go to the the one real developed
theory that we have in biology which has been formulated by Dawkins and others as universal
Darwinism. This is just kind of an abstraction of the of the modern synthesis between Darwinian
evolution and genetics. But universal Darwinism is incredibly simple it it's and very obvious it
says if you have systems and they can copy each other they can copy themselves and the copies
can diversify. Then if you want to know what's going to happen at the population level
what you will find is the systems that copy themselves and diversify most efficiently
will win because there'll be more of them so they end up dominating the population.
And winning gets called natural selection but natural selection is not an extra part of the
Darwinian process it's just the outcome of efficiency of the systems that copy themselves
most efficiently coming to dominate any population. So there's no sort of kind of
hand of God or whatever reaching down and selecting some organisms and not others.
And of course when Darwin put the idea of natural selection together
he was he was thinking very explicitly of the analogy of a gardener or a farmer
selecting the the crops or the animals or whatever that that the gardener liked best
and keeping those and that's where this selection metaphor comes from. But there's no real process
of selection in evolution by natural selection it's just copying and diversifying.
But this clearly is just the outline of what a real mechanistic theory would be
because we need to have a story about what copying is and what diversifying is
and what efficiently means. And in particular to address the question that we raised a couple
of slides ago we need to know whether these mechanisms are the same or at least isomorphic
of the same form at different scales. So that's what I want to talk about for the next little bit.
Let's start with copying.
Up until the 70s copying in biology really meant DNA replication
and to some extent cell division but the focus in evolutionary theory was on DNA replication.
And in the 70s it was realized that whole genes could be duplicated so whole genes could be copied
and then shortly after that it was realized that particularly in prokaryotes where genes
functionally related genes are next to each other and chromosomes often
in what are called operons that operons could be duplicated and so entire pathways could be
duplicated. And as genomes began to be sequenced and structures of genomes were understood
it became clear that genomes could be copied. And of course we have two copies in each of
our cells with the exception of red blood cells of our complete genome but some plants for example
have six or eight or even more copies of their genome in each of their cells.
So there's large-scale genome duplication. Cell division is clonal duplication of cells,
organismal reproduction works by cell division in all known systems.
Colonies or societies of organisms reproduce themselves in part through cultural transmission
and entire niches reproduce themselves. For example in processes like
forest evolution or desertification or even urbanization we see humans reproducing the
same sorts of niches in city after city for example. So these forms of copying
have the kind of hierarchical dependencies that one might expect. So to duplicate pathways
you have to duplicate genes. To duplicate cells you have to duplicate the genome.
To duplicate organisms you have to duplicate cells. And this suggests that this copying operation
is indeed scale free. That each level, the copying operation at each level enables the
copying operation at the next level. Now with diversification we see much the same thing.
In the early days of the modern synthesis and still in the work of people like Richard Dawkins
diversification is generally thought of as random. So mutation for example is thought of as random.
And here I have Barbara McClintock who is kind of the hero of non-randomness
in doggedly over decades pointing out that much of genome diversification is not random at all.
And that genomes actively diversify by moving whole clusters of genes around
and duplicating them or just changing their positions so that they're under the influence
of different local control. So at the gene and genome level you have active diversification
by various processes. Enzomatic processes as McClintock showed us transposed on
mediated mechanisms which are enzymatic at the bottom.
Cells actively diversified by lots of different mechanisms and in the 70s
Carl Lowe's was in part personally responsible for pointing out that in the microbial world
there's a lot of horizontal gene transfer and again no one believed him for quite a while.
But now it's broadly accepted that microbes exchange DNA very frequently and across
large distances phylogenetically and this is how things like microbial
resistance to antibiotics spread so quickly or one way that it spreads so quickly.
And it's a tremendous agent of essentially speciation to the extent that that even makes
any sense in the microbial world. Of course in our cells we have functional differentiation.
As mentioned earlier there are lots of symbiotic interactions that lead to diversification in
cells by radically altering their local environments and of course sex is a mechanism for diversification.
Organisms actively diversify in many different ways the most obvious one is just by moving around
by moving to a different environment. The organism is exposed to different inputs and
is allowed different outputs and so it can it can move into a different direction
morphologically genetically etc. Organisms can regulate their own evolvability by
altering things like DNA repair systems or activating transposons.
Again these are sorts of things that
went very much against the grain when they were first discovered but are now pretty well accepted.
And of course organisms can learn and so can diversify their behavior by diversifying
their computational capabilities. And social groups of course actively diversify in many
different ways and organisms are increasingly non-human organisms are increasingly regarded
as having cultures that they pass on intergenerationally by intergenerational learning
and can exchange with with other groups. So diversification is active and occurs at every scale
and again diversity although this is a bit less clear than in the case of copying
diversification mechanisms at one scale enable diversification mechanisms at other scales.
So for example transposon mediated mechanisms enable horizontal gene transfer in microorganisms.
And the FEP tells us that efficiency is actually about intelligence
because the FEP drives systems to build good models of their environments or the behavior of
their environments. And what a good model that's a system do is reach a single goal by many different
means because it allows in a sense planning and it allows flexibility and adaptability.
And I put William James here on this slide because he was the first as far as I know to define
intelligence as this ability to use different means to reach the same goal. Now in evolution
that's that's long been known and it's called convergent evolution when you see two lineages
adapting to a single environment with very different genetics and very different morphologies.
And often the organisms will end up with similar morphologies that work well in that environment
but very different genetics and very different biochemistry.
So throughout evolution we see this phenomenon of functional convergence
balancing structural divergence at many many different levels. So we have multiple genes for
very similar proteins. We have multiple pathways that do more or less the same thing.
We have different cell types that support the same basic functions. We have tissues that have
that are fairly different but that have the same functions for example eyes and different
kinds of organisms that allow vision but have very different structure. And of course we have
functional convergence in social relations. And if we look at how cells interact traditional
evolutionary theory really focuses on competition but we now know that cells cooperate that they
exchange resources in various ways even across vast differences in phylogeny for example the
interchange between plants and fungi or between bacteria and us. We know that cells in a sense
persuade each other by secreting things like hormones that cause other cells to do different
things. Cells deceive each other for example microbes that are trying to escape the immune
system and cells coerce each other cells even kill each other and they detect for example genetic
defects. So these sorts of social and economic and even political ideas are useful for describing
living systems from the level of cells on up. They were developed in social settings
to describe what goes on in human societies and then extended to other animals and now it's very
clear that they extend to individual cells. So when we think about social intelligence
we can think about social intelligence even at the level of individual cells and we see these
sorts of competition, cooperation, resource exchange etc even at the level of microbial
mats so biological structures that are three billion years old. Now of course intelligence
is necessary but it's not sufficient for being selected. It won't protect you from
impacts of asteroids that happen to land on your planet which has happened often in the
evolution of the earth and we're now trying to figure out how to predict and prevent such things
but it's you know who knows whether whether we'll be successful at that
but this intelligence is necessary when it's viewed in this FEP sort of way. Intelligence
is what lets you build models that enable you to predict the environment.
So where does this leave us? By thinking of evolutionary theory in terms of scale free
mechanisms we seem to have a picture in which we start with quantum systems with a certain
level of complexity and the FEP actually gives us scale free biology or something very close
to scale free biology and that's very interesting because the FEP of course is a generic principle
it just says that systems do what they need to do to keep existing
and this way of thinking gives us some predictions.
One is that we'll find compartmentalized problem solving everywhere
because the FEP drives compartmentalization and the reason is just non-commutativity of
measurement processes. It predicts that we'll see hierarchical organization everywhere
in the same way we did on that first compartmentalization slide where once you have a number
of compartments you need a meta compartment that if nothing else distributes free energy
so some sort of very basic attention system and we see attention systems of course throughout
biology. It predicts that living systems will have very limited classical data structures
so since they have to write classical data on their boundaries and their boundaries are
much smaller than they are then they'll and because writing classical data is expensive
that living systems will tend to use as little classical data as they can get away with
since classical data is needed for thermodynamic irreversibility
where we see thermodynamic irreversibility that's where we look for classical data.
We saw that organisms will be able to detect time first before they can detect space
so we can expect organisms to have clocks even before they can represent space
and of course we see things like diurnal variation throughout biology
and finally the the FEP predicts this asymptotic collapse of separability
back to entanglement so it predicts that living systems will eventually degrade
and become indistinguishable from their environments and we know that happens at the cell
level and the individual organism level you know we call it death. So the FEP seems to give us a
lot of the features of biology and it gives us these features in a scale-free way and it derives
them from this very basic physics. So where does that leave us? I think it leaves us here with a
challenge not just to thinking about the FEP which is what this course has been about
but to quantum information theory in general
and that challenge is to evolve from the kind of conceptual and theoretical utility
that we've been discussing in this course and which is is very well developed in the physics
community to some sorts of empirical and technological utility
and I've listed three areas here where QIT is very active, one in quantum gravity and cosmology
and you're probably familiar with things like string theory that sort of
barely famously seemed not to be empirically testable and the quantum gravity community is
enormous of many thousands of people working in this area but coming up with theories that could be
tested empirically at the scales that we can actually do experiments so at accessible energy
scales for example has proved to be very difficult. So this is a real challenge to the field is somehow
getting not just to empirical testability but to some sort of technological utility
and you can imagine that if the main prediction of quantum gravity is that spacetime is emergent
that there could be enormous utility in that
some ability to manipulate the way spacetime emerges.
The second area of course is is quantum information and computing and here massive resources are being
put into technological utility and I think it's reasonable to expect that we'll have useful
quantum computers within a generation at any rate. So there I think the field is going quite well
and the last area of what we've talked about here is quantum biochemistry and biology and
this I think is an area with enormous practice of promise that maybe some of you will actually
contribute to making this area more useful technologically and more accessible empirically.
But at least we have a picture of how these different areas fit together.
So that's it thank you very much for participating in this class.
Andrew will be doing
this.
Sorry could you just repeat the last like 30 seconds from Andrew will be
Chris?
Awesome. I don't know if I didn't get that kick up.
Andrew will be his last discussion session on Saturday the 20th of October at the usual time
8 a.m. Pacific time and the interactive Q&A is open. I really appreciate your questions. I try to
answer them and thank you very much. Awesome. Can I ask a question or do you want to call it here?
Sure go ahead. All right.
Inks wrote, Chris spoke last time introducing the mechanisms of scale transition.
I'll read your question then I'll fix the cropping on the live stream. Chris spoke last
time introducing the mechanisms of scale transition of these essentially semantic theories
about how one scale embeds in another scale. I would love to learn more about this especially
in terms of natural language semantics and human cognition semantics versus machine learning.
Wow well that's a that's a very good question.
I think that's a very relevant question given the sorts of machine learning that we see deployed
in systems like chat GPT and especially as these systems start to associate language with images
for example and as such systems are embedded in robotic systems that can actually move around
in the world and interact with real objects. I think one of the one of the key questions in
natural language semantics is to what extent does it depend on reference? To what extent
do the meanings we attach to words or the usages that we allow for words depend on
our ability to connect words to external objects and to what extent do those abilities
rely on connections between words themselves? So if you think of an LLM like chat GPT by itself
it's just a statistical model of relationships between words as used in some corpus of text which
is large of course but we can debate its representativeness and so that's a model of semantics
that's entirely self-contained it's entirely relations between different pieces of language
whereas when we start to connect those words statistics to images or better yet to actual
objects that are interacted with not just visually but haptically for example by a robot
they start to be connected to external reference and that transition I think is going to be very
very interesting to watch and it's just starting so we all have ringside seats on an incredible
experiment in semantics and so that would be my response really to that question is
keep your eyes on this experiment and see how it goes because it's bound to tell us something about
how semantics really works and I suspect that there will be enormous opportunity to start
relating the results of that experiment to what we see in in developmental psychology for example.
Wow awesome all right Tucker asks areas of macroscopic quantum mediated phenomena in
biology that get Chris Fields excited? I think the one that excites me the most
right now is just this question of how cells are managing to do the information processing that
they're doing and how much of it they can accomplish or I think the right way to put it is
how can they get away with so little classical information and I don't think we have the cell
biology yet to answer that question but I think asking the question may help us design the right
kinds of cell biology to look for an answer and our cell biology has been organized around the idea
that the structures that we see are essentially static that they're classical
and that they're constructed in a way that's thermodynamically irreversible
but if we think of what we measure as not necessarily reflecting a static structure
I think we'll start to conceptualize it differently and build models of it differently.
I mean clearly when we look at things like protein structure we're looking at snapshots
of something that's very dynamic and when we look in a chemistry textbook and we see you know
pictures of this confirmation that changes to that confirmation we think of those as static
stable structures that that's kind of a switch but it's not actually a switch the way a light
switch is it's a much more dynamic process and the kinds of molecular dynamic simulations that
allow you to study that process are incredibly complicated and time expensive and uncertain
and resolution problems and other things but I think thinking of these as
kind of fluid reversible processes is going to change the way we think about them.
That's a great point and it reminds me of the more physics based way of thinking about the
paths that could happen between observations or the statistics based way of samples of a
dynamical process and in biology we know that even if we take a snapshot okay this organism is
one centimeter today it's two centimeters tomorrow something changed so we know there
was a developmental process then we know there's an ecological process and then there's an evolutionary
context eco-evo-devo and then from that more biological understanding of contextual developing
organisms all of these different biological phenomena actually help us expand our space
of measurements and analysis for material that on one hand some people may have called inanimate
but then they have their own dynamics different time scales and so bringing some of those
like the challenges of measuring and observing intervening in historical and biological
things gives us a big understanding even on measuring and summarizing analyzing
ensembles or scales that that don't immediately appear to have that kind of
historicity like pieces of silicon or carbon.
Yeah that's well put and I think we have the same problem as we go up in scale also.
We tend not to think of things like societies as living systems
but in one sense they clearly are and to the extent that we can think of these structures
that are much larger than we are individually as living systems cognitive systems etc I think
we'll understand their dynamics better. Okay final question upcycle club wrote
how can a quantum system detect and respond to quantum context shifts switches which are
changes in the measurement basis or the entanglement structure of the system?
Well the answer here is is simple and not very informative it's by making measurements
which is all that quantum systems can actually do and making measurements that follow probing actions
that try to push the boundaries of the model of a context.
You know when when having this discussion I I always like to go back to the frame problem
in artificial intelligence which is the problem
formulated in the late 60s of predicting what what won't change as the result of an action
so it started the inverse of the problem of predicting the side effects
and if you could predict all of the side effects you can predict what doesn't change so it's
equivalent to the question of predicting all the side effects and context change is a side effect
and it's often an unobserved and maybe unobservable side effect but if you have a model
that says I'm working in this context then you can intentionally probe the boundaries of that model
and see if you can actually alter the context you're in as a way of discovering what context you're in
and no humans do that in social settings all the time
but I I think this is something that we need to to think about happening at many different scales
I suspect that cells are doing this all the time we just don't know how
there's so much to say there it just makes me think of the the paradox
or the tension between expecting the expected expecting the unexpected
and life needing to expect both of that right so thank you Chris it's been an amazing lecture
series many people in the live chat are very appreciative and and we'll look forward to
their submitted questions and their participation in the final discussion coming soon so thank you
Chris till next time okay and thank you all bye ciao
you
