Alright, July 25th, 2023, and we are in the discussion section, Basics of Active Emference.
This is the first discussion section that we've had for this course, so thank you all
for joining, and it's going to be regarding the topics that Ben White introduced in his
recent lecture.
So everyone will be welcome to pop in and introduce themselves, and then I know that
Ben has some ideas to discuss, and many other spontaneous and written questions will come
into play.
So I will, uh, with that exit for now, and pass to perhaps some of our first time live
stream guests.
I guess I've already spoken, so I may as well continue.
So I'm Darius, I am master's student, I'm just about to finish at UCL in sort of social
distributed cognition.
I work in the social cognition lab, looking at salient regulation and attentional mechanisms
within social contexts, but all within an Active Inference framework, within the Bayesian
Brain Hypothesis framework, and yeah, it's a sort of recent discovery and obsession,
and so I'm sort of getting to grips with both the high road and the low road, and so I've
had the opportunity to chat to Mark and some other researchers who have been super informative,
but always looking to learn more and get my head around even more of the sort of philosophical
and mathematical theory.
Oh, sounds good.
Hi everyone, can you hear me?
Yep.
I'm Francisco Balcan, I'm a PhD student at the University of Bologna, Italy, actually
working on an intersection between Artificial Intelligence and Education, I have a background
in Cognitive Anthropology and Philosophy of Science, and I met Axel and Maxel in a few
years ago, so I depth dive into the rabbit hole of the arrangement of an Active Inference,
and currently pretty much interested in multi-scale Active Inference models of scientific cognition,
so pretty interested about the agent-level modeling of the scientific reasoning assumption
that might emerge from the interaction with the scientific environment, so we're referring
to scientific instruction and all these type of top-down and bottom-up interactions, so
super interested to hear something from you.
Thank you.
Thank you very much.
Would anybody else like to introduce themselves before we start?
Hi, I'm Regina Sagin, I'm from Guatemala, and I'm not from the social sciences, I come
from biology and neuroscience, and I'm here because I'm working on a project as a technical
operator in this big project in the ex-escape of material minds, and I do the technical
part and experiments, but I want to learn the philosophical part, that's the background
that makes the theory of everything we're going to experiment, so I'm here to learn,
and also I am like, when you see the Olympics, that you see all the swimmers, and I wish
there was a normal guy to see how good these people are, so you could compare, so that's
me today, I understand half of what's going on, but I'm happy to be here, so yeah, hi.
Hi, sorry I'm late, so my name's Lee, I'm a PhD student at the University of New York
and I'm joining because I'm using perceptual control theory at the minute to model examples
of effective practice in organisations, and I've read quite a lot of active inference papers,
and I understand that there's a lot of resonance overlap between perceptual control theory and
active inference, although I understand it's within a predictive framework, and also it's a
level of abstraction higher, so you're able to quantify the difference between the predictor
state or the outcome state and the current state, so what I'm really trying to understand is,
how might that level of abstraction be useful in what I'm doing actually, because I understand
it's a much more kind of concurrent theory and framework than perceptual control theory.
Yeah, very cool. Anybody else? I think there's, is that everybody? Okay, well was everybody present,
has everybody seen the lecture that I gave a couple of weeks ago? Okay, so I think it might be
helpful then if I kind of very, very briefly go over what we covered in that lecture just to
kind of jog people's memories and then we can maybe pick up some questions from there. So the
lecture last week was on the basics of active inference and it was intended to be an introduction
to the framework on a very abstract philosophical level, so it left out all of the kind of
mathematics and technical aspects of the framework. And the objective really was to lay the
groundwork for future weeks in this course, because this is obviously a course on active
inference in the social sciences. And so in the subsequent weeks, we're going to be looking at
topics like collective behavior, social cognition, shared norms and niche construction. And so what
I wanted to do is to put on the table a kind of fully fleshed out picture of what the individual
agent looks like in active inference. And so to do this, we looked at emotion, agency, mind. So
we looked at kind of the role of action and perception, the role of internal representations
in active inference. And then as a case study, we kind of, we looked at a active inference based
account of addiction to kind of bring all of these threads together to kind of articulate a lot of
the things that I'd said in the previous sections. So I mean, the questions here don't have to be
specifically tethered to that lecture. I suppose we can just start with any general questions
about active inference and philosophy and how active inference applies to individual agents. Or
if anybody did want to pick up on any threads from the lecture, then we can go from there.
Can I ask something just for the basic questions? Yeah, of course. I don't understand, because I
think you explained it later, but how I'll just creativity and science in general enters active
inference. How just trying to be creative and not put doing what you predict enters this like
rule. Yeah. Yeah, this is a really good question. And I think so were you there? Have you, did you
see the lecture? Yeah, but I remember half of it. Yeah, that's fine. But I think, I think, do you
remember the dark room problem? Yeah, yeah, I know that's that's where the answer is. But yeah,
well, it's, it's, it's, I think there are several interesting dark room problem, some of the more,
some of the more interesting than others. And I tried to cover, I did obviously didn't have
time to cover all of those in the lecture. But the kind of for those that perhaps aren't familiar,
the dark room problem is this kind of canonical philosophical worry about predictive process in
an active inference that says, essentially, if it's if all we're trying to do is minimize
prediction errors, why don't we just find maximally predictable environments? And, you know, why do
we not just lay in a dark room hooked up to an intravenous drip and enjoy kind of error free
lifestyle? So I think that's the kind of, that's the question that you're articulating there. I just
quickly see a hand from Darius. Darius, did you want to jump in or was it a separate question?
It's a separate question. So I would just do it in advance. But yeah, I'll circle back around in a
second. But I should say, actually, this is the first time I've kind of shared a discussion like
this. So I'll be explicit and say, people should just feel free to jump in whenever they want,
if you want to take the disco, if you want to kind of add something or, or kind of build on a
question that we're answering, feel free to jump in. But yeah, with the dark room problem, as I'm
aware, the first answer to that question, and this is something that I did cover in the lecture is
essentially a big part of active inference is to recognize that the agents are, it's a kind of
fundamentally embodied framework. Okay, so what that that can be kind of cashed out in various
ways. But one of the, one of the most important ways is that the expected states of the organism
or that the agent are necessarily rooted in the phenotype of the organism and the kind of
evolutionary biological needs that come with having a particular body. So there was a paper that I
referenced in the lecture by, there's three authors on this paper, it's Andy Clark, Carl
Friston, and then I'm forgetting the name of the third author, if anybody can recall, feel free
to drop in the chat. But this is, this is an answer to the dark room, where he builds on that
notion of embodiment and says, look, creatures like us, human and good, and sit in the dark room
and do nothing and just kind of enjoy the very predictable march of hunger, thirst, etc. But
obviously those particular biologists of the room. And so you have this very fundamental level.
We have this very fundamental kind of basis upon which we have these needs that need to
be met. And so we need to engage in exploratory behaviors. On the topic of novelty, because
that's a kind of base, I take that to be a kind of baseline answer. But there are clearly
kinds of activities and behaviors that we do engage in, going beyond the dark room,
kind of curiosity, play, creativity, engaging in kind of, why do we create works of art?
And there's not an obvious link between those kinds of behaviors and the kinds of biological
needs that are emphasized in the original answer to the dark room worry. So in answer
to Regina's question about creativity, I think that a good starting point for this is the section
on aerodynamics that I introduced in the lecture. So this was the idea that it, there's this strong
connection between affectivity as a kind of emotional embodied feeling state and the changes
to the rate in prediction error minimization. So I don't know, I am now very much articulating
Mark's work here. So I don't know if Mark wants to jump in at any point and do a much better job
than I can. I think there's there's certainly there's certainly work on the horizon. I know
that there are people who are currently building up theories of artistic critique that are based on
this this idea of aerodynamics. So Mark's paper on play with Mark Anderman that I mentioned
has a really interesting idea where if you explain playful behaviors, which are kind of
fundamentally creative and funny, we are, you know, it's an inherently creative exercise.
I think the really interesting idea that comes out of that is one thing that we engage in because
it feels good is we, we create niches of very manageable prediction error that we can then
minimize. So yeah, that's playful behavior on is the kind of the answer to the puzzle of play.
So why do we in the puzzle of play is why do we engage in view are metabolically quite costly?
And they don't have any obvious benefit. And the idea there's that, well, there's there's kind of
several ideas in there. But one of them is that it just literally feels good because minimizing
prediction error feels good to us. So whenever we do better than expected at minimizing prediction
error, it feels good. And so I think, so obviously, I don't know for sure, but I think that any
answer that we give regarding artistic creativity is going to fall within that kind of bulk that
essentially we engage in the part of the creative process is just constructing those that give us
tasks, problems, and the games of manageable prediction error that ideally sit at the boundaries
of our skill capabilities. Can I add two quick things there, Ben? So just so that was a great
explanation. But just to hit two points a little bit harder, one, you might think all that matter
is doing error. That's why it looked a little bit paradoxical that we also create
antithetical to our modus operandi, which is to reduce error. But when you remember that for our
kind prediction error minimizing system, we have a really deep temporal model. We're managing
uncertainty at a big horizon, maybe even multigenerational, you know, where we're thinking
about our kids or our kids. I mean, who knows how deep the generative model actually runs?
It turns out that it
has errors that stop developing error minimizing skills and abilities and just hangs out in one
micro niche, because that micro niche is going to be upset sooner or later, right? I mean,
it's such a great example of where we thought we were in a really set vector state. And then
suddenly it gets jostled and all of us go, Oh, my goodness, like, what do we do? We've been bumped.
And it turns out that the best air minimized will be the
two kinds of errors that are and hates those errors are digestible. So that means not too
complex that you can't do anything with it. You can't learn anything from it, but also not so
boring that there's nothing to learn. If we hang out, if we're sensitive to and we hang out at the
edge of our capability, then we keep developing new error minimizing abilities, which actually
sets us up to be good error minimizing systems over the long run. So even though we're investing
metabolism now, we're getting we're setting ourselves up to be able to manage, you know,
in especially the deep end of the pool, black swans manage uncertainty that we're not going
to be able to predict the really unpredictable, unpredictable. That comes from hanging out at
this edge. So part of our curiosity and playfulness and creativity are going to be about us making
and digesting novel slopes of volatility. I think that's one that's one really great answer for
why you get playfulness and curiosity out of this and creativity. I'll just drop one more.
And we don't have to get into it too deeply here, but here's one other one that we're thinking of.
There's something really special in the creation of art, especially in a public sphere that I
think is so interesting in that somebody needs to be sort of looking at this. There's actually a
new collection coming out in Philosophical Trans B on art and predictive processing, which I think
you should check out if you're interested in these topics. But the idea that we've been thinking about
is there are ways that we can bring our generative model out and put it into a public sphere.
You can take something which is typically on the inside and you can put it outside.
And then you can have other error minimizing systems look at it and fiddle around with it,
and then we can reenvive it. I mean, we're doing this all the time. I mean, that's what
language allows us to do and what writing allows us to do. Think about maths. You're bringing
there part of your predictive understanding. You're laying it out and then other predictive
agents can fiddle around with it and then you can take it back in as part of your updating your own
model. And I don't know how much more I can say here. I just think this is a kind of horizon,
but I think there's a really juicy thing to say here about where real art is like Tolstoy,
maybe Leo Tolstoy was already on this, where you put something of the creator in the creation
and then other people receive that and then they can do something else with it and then you're able
to sort of take it back in all under the guise of sort of minimizing volatility or understanding
volatility. Maybe that was a bit deep. No, that was really good. Yeah. I just in the chat,
I just dropped a link to, yeah, so somebody just asked about papers related to hanging
out, edge of our capabilities. I'll do that right now. There sure are some papers on that.
Mark's got a few. I already dropped a link in there to an Aeon article by some of the old
Expect Project crew, including Mark, Kate Nave, George Deed and Andy Clark on the value of uncertainty,
which is, I think it's a really good start point for some of these questions.
Just because Aeon is a kind of non-academic place where you can, you know, it's a non-technical
introduction and there's a wonderful example in that paper of a guy named, I think it's Max Hawkins.
Is that right, Mark? Max, who he's a kind of tech guy and he realized he was getting kind of bored
with his life, he inadvertently trapped himself in a dark room because his life had become so
wrote and scheduled and systematic. He realized that he would be kind of incredibly easy to
kidnap because he was in the same place at the same time every single day. And to get, he took
drastic action to break out of that dark room. So he kind of introduced a randomization algorithm
that would, it would kind of choose for him where he was going to eat, where he was going to go,
which shows he was going to attend. And this example is a really nice centerpiece in this
article. So, and I think, yeah, I think this is a nice place to start because it's also grounded
in discussions about epistemic actions as well, because there's also, you know, as cool as play
and art and creativity are, there's also really, really good reasons that uncertainty is valuable
as well, right? Because while we might want to exploit all of the opportunities for kind of
nourishment and valuable prediction error minimization in our environment, there are of
course going to be times where those opportunities are exhausted and we need to go and explore
different ones. And I think there's some stuff in there as well on epistemic actions within
the context of navigation as well. So sometimes we're going to have to, we're going to have to
temporarily move further away from our target in order to minimize our uncertainty about where
we're going. So there's lots and lots of stuff on the value of uncertainty. And it kind of is
very much at the forefront of some of the really interesting philosophical applications of the
framework for sure. Okay, yeah, by all means, yeah, we've got time.
You just said something, I know you have a question that is, but with the value of
uncertainty, it's just that I'm thinking, because I've been working a lot with the magicians.
