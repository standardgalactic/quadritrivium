Alright, July 25th, 2023, and we are in the discussion section, Basics of Active Emference.
This is the first discussion section that we've had for this course, so thank you all
for joining, and it's going to be regarding the topics that Ben White introduced in his
recent lecture.
So everyone will be welcome to pop in and introduce themselves, and then I know that
Ben has some ideas to discuss, and many other spontaneous and written questions will come
into play.
So I will, uh, with that exit for now, and pass to perhaps some of our first time live
stream guests.
I guess I've already spoken, so I may as well continue.
So I'm Darius, I am master's student, I'm just about to finish at UCL in sort of social
distributed cognition.
I work in the social cognition lab, looking at salient regulation and attentional mechanisms
within social contexts, but all within an Active Inference framework, within the Bayesian
Brain Hypothesis framework, and yeah, it's a sort of recent discovery and obsession,
and so I'm sort of getting to grips with both the high road and the low road, and so I've
had the opportunity to chat to Mark and some other researchers who have been super informative,
but always looking to learn more and get my head around even more of the sort of philosophical
and mathematical theory.
Oh, sounds good.
Hi everyone, can you hear me?
Yep.
I'm Francisco Balcan, I'm a PhD student at the University of Bologna, Italy, actually
working on an intersection between Artificial Intelligence and Education, I have a background
in Cognitive Anthropology and Philosophy of Science, and I met Axel and Maxel in a few
years ago, so I depth dive into the rabbit hole of the arrangement of an Active Inference,
and currently pretty much interested in multi-scale Active Inference models of scientific cognition,
so pretty interested about the agent-level modeling of the scientific reasoning assumption
that might emerge from the interaction with the scientific environment, so we're referring
to scientific instruction and all these type of top-down and bottom-up interactions, so
super interested to hear something from you.
Thank you.
Thank you very much.
Would anybody else like to introduce themselves before we start?
Hi, I'm Regina Sagin, I'm from Guatemala, and I'm not from the social sciences, I come
from biology and neuroscience, and I'm here because I'm working on a project as a technical
operator in this big project in the ex-escape of material minds, and I do the technical
part and experiments, but I want to learn the philosophical part, that's the background
that makes the theory of everything we're going to experiment, so I'm here to learn,
and also I am like, when you see the Olympics, that you see all the swimmers, and I wish
there was a normal guy to see how good these people are, so you could compare, so that's
me today, I understand half of what's going on, but I'm happy to be here, so yeah, hi.
Hi, sorry I'm late, so my name's Lee, I'm a PhD student at the University of New York
and I'm joining because I'm using perceptual control theory at the minute to model examples
of effective practice in organisations, and I've read quite a lot of active inference papers,
and I understand that there's a lot of resonance overlap between perceptual control theory and
active inference, although I understand it's within a predictive framework, and also it's a
level of abstraction higher, so you're able to quantify the difference between the predictor
state or the outcome state and the current state, so what I'm really trying to understand is,
how might that level of abstraction be useful in what I'm doing actually, because I understand
it's a much more kind of concurrent theory and framework than perceptual control theory.
Yeah, very cool. Anybody else? I think there's, is that everybody? Okay, well was everybody present,
has everybody seen the lecture that I gave a couple of weeks ago? Okay, so I think it might be
helpful then if I kind of very, very briefly go over what we covered in that lecture just to
kind of jog people's memories and then we can maybe pick up some questions from there. So the
lecture last week was on the basics of active inference and it was intended to be an introduction
to the framework on a very abstract philosophical level, so it left out all of the kind of
mathematics and technical aspects of the framework. And the objective really was to lay the
groundwork for future weeks in this course, because this is obviously a course on active
inference in the social sciences. And so in the subsequent weeks, we're going to be looking at
topics like collective behavior, social cognition, shared norms and niche construction. And so what
I wanted to do is to put on the table a kind of fully fleshed out picture of what the individual
agent looks like in active inference. And so to do this, we looked at emotion, agency, mind. So
we looked at kind of the role of action and perception, the role of internal representations
in active inference. And then as a case study, we kind of, we looked at a active inference based
account of addiction to kind of bring all of these threads together to kind of articulate a lot of
the things that I'd said in the previous sections. So I mean, the questions here don't have to be
specifically tethered to that lecture. I suppose we can just start with any general questions
about active inference and philosophy and how active inference applies to individual agents. Or
if anybody did want to pick up on any threads from the lecture, then we can go from there.
Can I ask something just for the basic questions? Yeah, of course. I don't understand, because I
think you explained it later, but how I'll just creativity and science in general enters active
inference. How just trying to be creative and not put doing what you predict enters this like
rule. Yeah. Yeah, this is a really good question. And I think so were you there? Have you, did you
see the lecture? Yeah, but I remember half of it. Yeah, that's fine. But I think, I think, do you
remember the dark room problem? Yeah, yeah, I know that's that's where the answer is. But yeah,
well, it's, it's, it's, I think there are several interesting dark room problem, some of the more,
some of the more interesting than others. And I tried to cover, I did obviously didn't have
time to cover all of those in the lecture. But the kind of for those that perhaps aren't familiar,
the dark room problem is this kind of canonical philosophical worry about predictive process in
an active inference that says, essentially, if it's if all we're trying to do is minimize
prediction errors, why don't we just find maximally predictable environments? And, you know, why do
we not just lay in a dark room hooked up to an intravenous drip and enjoy kind of error free
lifestyle? So I think that's the kind of, that's the question that you're articulating there. I just
quickly see a hand from Darius. Darius, did you want to jump in or was it a separate question?
It's a separate question. So I would just do it in advance. But yeah, I'll circle back around in a
second. But I should say, actually, this is the first time I've kind of shared a discussion like
this. So I'll be explicit and say, people should just feel free to jump in whenever they want,
if you want to take the disco, if you want to kind of add something or, or kind of build on a
question that we're answering, feel free to jump in. But yeah, with the dark room problem, as I'm
aware, the first answer to that question, and this is something that I did cover in the lecture is
essentially a big part of active inference is to recognize that the agents are, it's a kind of
fundamentally embodied framework. Okay, so what that that can be kind of cashed out in various
ways. But one of the, one of the most important ways is that the expected states of the organism
or that the agent are necessarily rooted in the phenotype of the organism and the kind of
evolutionary biological needs that come with having a particular body. So there was a paper that I
referenced in the lecture by, there's three authors on this paper, it's Andy Clark, Carl
Friston, and then I'm forgetting the name of the third author, if anybody can recall, feel free
to drop in the chat. But this is, this is an answer to the dark room, where he builds on that
notion of embodiment and says, look, creatures like us, human and good, and sit in the dark room
and do nothing and just kind of enjoy the very predictable march of hunger, thirst, etc. But
obviously those particular biologists of the room. And so you have this very fundamental level.
We have this very fundamental kind of basis upon which we have these needs that need to
be met. And so we need to engage in exploratory behaviors. On the topic of novelty, because
that's a kind of base, I take that to be a kind of baseline answer. But there are clearly
kinds of activities and behaviors that we do engage in, going beyond the dark room,
kind of curiosity, play, creativity, engaging in kind of, why do we create works of art?
And there's not an obvious link between those kinds of behaviors and the kinds of biological
needs that are emphasized in the original answer to the dark room worry. So in answer
to Regina's question about creativity, I think that a good starting point for this is the section
on aerodynamics that I introduced in the lecture. So this was the idea that it, there's this strong
connection between affectivity as a kind of emotional embodied feeling state and the changes
to the rate in prediction error minimization. So I don't know, I am now very much articulating
Mark's work here. So I don't know if Mark wants to jump in at any point and do a much better job
than I can. I think there's there's certainly there's certainly work on the horizon. I know
that there are people who are currently building up theories of artistic critique that are based on
this this idea of aerodynamics. So Mark's paper on play with Mark Anderman that I mentioned
has a really interesting idea where if you explain playful behaviors, which are kind of
fundamentally creative and funny, we are, you know, it's an inherently creative exercise.
I think the really interesting idea that comes out of that is one thing that we engage in because
it feels good is we, we create niches of very manageable prediction error that we can then
minimize. So yeah, that's playful behavior on is the kind of the answer to the puzzle of play.
So why do we in the puzzle of play is why do we engage in view are metabolically quite costly?
And they don't have any obvious benefit. And the idea there's that, well, there's there's kind of
several ideas in there. But one of them is that it just literally feels good because minimizing
prediction error feels good to us. So whenever we do better than expected at minimizing prediction
error, it feels good. And so I think, so obviously, I don't know for sure, but I think that any
answer that we give regarding artistic creativity is going to fall within that kind of bulk that
essentially we engage in the part of the creative process is just constructing those that give us
tasks, problems, and the games of manageable prediction error that ideally sit at the boundaries
of our skill capabilities. Can I add two quick things there, Ben? So just so that was a great
explanation. But just to hit two points a little bit harder, one, you might think all that matter
is doing error. That's why it looked a little bit paradoxical that we also create
antithetical to our modus operandi, which is to reduce error. But when you remember that for our
kind prediction error minimizing system, we have a really deep temporal model. We're managing
uncertainty at a big horizon, maybe even multigenerational, you know, where we're thinking
about our kids or our kids. I mean, who knows how deep the generative model actually runs?
It turns out that it
has errors that stop developing error minimizing skills and abilities and just hangs out in one
micro niche, because that micro niche is going to be upset sooner or later, right? I mean,
it's such a great example of where we thought we were in a really set vector state. And then
suddenly it gets jostled and all of us go, Oh, my goodness, like, what do we do? We've been bumped.
And it turns out that the best air minimized will be the
two kinds of errors that are and hates those errors are digestible. So that means not too
complex that you can't do anything with it. You can't learn anything from it, but also not so
boring that there's nothing to learn. If we hang out, if we're sensitive to and we hang out at the
edge of our capability, then we keep developing new error minimizing abilities, which actually
sets us up to be good error minimizing systems over the long run. So even though we're investing
metabolism now, we're getting we're setting ourselves up to be able to manage, you know,
in especially the deep end of the pool, black swans manage uncertainty that we're not going
to be able to predict the really unpredictable, unpredictable. That comes from hanging out at
this edge. So part of our curiosity and playfulness and creativity are going to be about us making
and digesting novel slopes of volatility. I think that's one that's one really great answer for
why you get playfulness and curiosity out of this and creativity. I'll just drop one more.
And we don't have to get into it too deeply here, but here's one other one that we're thinking of.
There's something really special in the creation of art, especially in a public sphere that I
think is so interesting in that somebody needs to be sort of looking at this. There's actually a
new collection coming out in Philosophical Trans B on art and predictive processing, which I think
you should check out if you're interested in these topics. But the idea that we've been thinking about
is there are ways that we can bring our generative model out and put it into a public sphere.
You can take something which is typically on the inside and you can put it outside.
And then you can have other error minimizing systems look at it and fiddle around with it,
and then we can reenvive it. I mean, we're doing this all the time. I mean, that's what
language allows us to do and what writing allows us to do. Think about maths. You're bringing
there part of your predictive understanding. You're laying it out and then other predictive
agents can fiddle around with it and then you can take it back in as part of your updating your own
model. And I don't know how much more I can say here. I just think this is a kind of horizon,
but I think there's a really juicy thing to say here about where real art is like Tolstoy,
maybe Leo Tolstoy was already on this, where you put something of the creator in the creation
and then other people receive that and then they can do something else with it and then you're able
to sort of take it back in all under the guise of sort of minimizing volatility or understanding
volatility. Maybe that was a bit deep. No, that was really good. Yeah. I just in the chat,
I just dropped a link to, yeah, so somebody just asked about papers related to hanging
out, edge of our capabilities. I'll do that right now. There sure are some papers on that.
Mark's got a few. I already dropped a link in there to an Aeon article by some of the old
Expect Project crew, including Mark, Kate Nave, George Deed and Andy Clark on the value of uncertainty,
which is, I think it's a really good start point for some of these questions.
Just because Aeon is a kind of non-academic place where you can, you know, it's a non-technical
introduction and there's a wonderful example in that paper of a guy named, I think it's Max Hawkins.
Is that right, Mark? Max, who he's a kind of tech guy and he realized he was getting kind of bored
with his life, he inadvertently trapped himself in a dark room because his life had become so
wrote and scheduled and systematic. He realized that he would be kind of incredibly easy to
kidnap because he was in the same place at the same time every single day. And to get, he took
drastic action to break out of that dark room. So he kind of introduced a randomization algorithm
that would, it would kind of choose for him where he was going to eat, where he was going to go,
which shows he was going to attend. And this example is a really nice centerpiece in this
article. So, and I think, yeah, I think this is a nice place to start because it's also grounded
in discussions about epistemic actions as well, because there's also, you know, as cool as play
and art and creativity are, there's also really, really good reasons that uncertainty is valuable
as well, right? Because while we might want to exploit all of the opportunities for kind of
nourishment and valuable prediction error minimization in our environment, there are of
course going to be times where those opportunities are exhausted and we need to go and explore
different ones. And I think there's some stuff in there as well on epistemic actions within
the context of navigation as well. So sometimes we're going to have to, we're going to have to
temporarily move further away from our target in order to minimize our uncertainty about where
we're going. So there's lots and lots of stuff on the value of uncertainty. And it kind of is
very much at the forefront of some of the really interesting philosophical applications of the
framework for sure. Okay, yeah, by all means, yeah, we've got time.
You just said something, I know you have a question that is, but with the value of
uncertainty, it's just that I'm thinking, because I've been working a lot with the magicians.
And there's a way of using uncertainty as entertainment. And it's very difficult to
understand as a, you know, as a concept for entertainment, why would you like to be in a
place where you cannot, you want to predict, but you cannot and you still want to participate in
this activity. So for me, magic shows, it's kind of breaking a little bit.
Yeah, I think I spoke to, I forget the person's name, but there was a
Xscape meeting here at Sussex. And I spoke to one of the guys on Xscape who had been working on magic.
I don't know who I'm talking about, but I think they have a book on magic.
And I think that's really cool to think about from a predictive processing perspective,
the idea that magic is just these wonderful kind of violations of expectations in a certain sense.
I think predictive processing provides a nice, really intuitive framework of thinking about
those kinds of things. One little point there, Regina, just about, again, if it feels paradoxical,
just to sort of, um, complexify your view. Remember that the, this is always happening in
a hierarchical system. So just because you have errors at one level of the system doesn't mean
you're going to have sort of critical cascading unbearable errors at higher levels. So that's
why it's fun to go to horror movies. So I dropped the paper here. Also, we have a new paper coming
out on, on horror movies. I'm pretty interested in this, but it's the same as the, it's the same as
going to the magic show in some way. Now, the reason why those errors are, are fun is because
we're safe in a theater where with our friends, we have lots of sugar in our system from eating
popcorn and candy. We can control the amount of scary by, by, you know, covering our eyes or
like, there's lots of control here. And yet we're getting media that is, that's pinging all of our
evolutionarily ancient error tracking systems so that we're getting jumps in the physiology
as if there's a bunch of volatility that we need to manage. And yet we're in a completely safe
space, which is really fun for our kind of system because we're hierarchically deep predictive
systems. The high level here isn't jeopardized. It knows I'm in a theater, but the low level
stuff is still registering all sorts of little volatilities, but of course they get squashed.
They don't cascade all the way up. Or if you're the kind of person where they do tend to cast
all the way up, then you're also the kind of person who doesn't like going to horror movies
because it kind of scare like you go home and think, oh goodness, maybe ghosts are real and
maybe I live with them. You wouldn't be going there then. So with magic, it's the same sort of
thing. Um, we know do certain things. So with error, I don't know if you've ever seen, um,
I can, um, who does the really extreme magic where he like was in a block. Yeah, David Blaine,
have you ever seen him? He goes to Haiti where you have a community that really believes in
magic and he does some magic and he gets into trouble. Like suddenly all the young men are
like, Oh, no, no, no. No, that's, that's no bueno that, that you're doing this. And then he had to,
the camera pans back and he goes, no, no, no, hold on. I'll show you here. I'll show you how
it's done. It was just a trick. I'll just show you outside. It's not real magic because there,
they're not having fun with it anymore. They're like, no, that's like not a good thing to do.
Yeah. So it just goes to show that like, um, our, our engagement with magic is mostly a sort of
scary play. Yeah. I think one thing I just kind of, sorry about the seagulls. I don't know if you
can hear those. There are seagulls going crazy just outside my window. Um, one thing I would add
is I think, um, another aspect to this, this part of the framework wherein you have this value of
prediction error, kind of epistemic and affective emotional value of predict prediction error. It's
one of the kind of key elements in this notion of, uh, agency get in active inference that I think is
really, it's going to be really important in mind as you go through the further weeks of this course
as well. So what, uh, you know, like I said in the lecture, it's not necessarily speaking to a
quite the metaphysical question of free will, but it's certainly moving us away from this picture
of, of, of the agent as a kind of automaton that's just following rules. There's real
space here for kind of individuality and creativity as well.
Okay. Darius has been waiting a little while. So, um, let's go over to him.
Happily patient. Happily. Um, yeah. I mean, this is this question, I guess, is deriving from
my thoughts about the meeting of the, the high road and the low road.
Um, some of the reason why there's been coming out on Maxwell Ramsey and actually a conversation
I had with him, which is a, the generative model of the state. So my question, given that,
given and tall is regarding the notion of affordances, I think it's natural that as
cognitive scientists and philosophers, we take the perspective intuitively of the
agents in the agent arena relationship and how the agent is in the business of reducing
prediction error. I was just wondering whether as philosophers, um, you and Mark have thought
about what it would, what, what is it like out for the whole system to be in the business of
reducing its prediction error. So I'm interested in flow states. Um, and so for example, my thinking
is, is that in the canonical example of a flow state, let's say a rock climber, the, the climbing
ball is also in the business of losing its prediction error as to afford the opportunity
for it to be exploited self or themselves are in the business of reducing prediction error.
So I'm wondering whether this expansion of affordances is bi-directional, tri-infinity
direction?
That's an amazing question. So, um, you, uh, I think you mentioned Axol constant,
but uh, someone else, but I spoke to Maxwell Ramstein last week. Um, yeah, yeah.
There's a, there's a paper on, uh, I'll find it in a second on, uh, niche construction, um, and,
um, affordances. I think it's Axol constant, what they talk about the kind of the, the
symmetry between, uh, a niche and an agent, um, very much in like the same vein as you were
just talking about there, this idea that it's not just, uh, it, there's not just this unidirectional
kind of fit between the agent and the environment, but the, or the niche is actually modeling
generative model of the agent as well implicitly. Um, so I think the best I can do that direction
of some really interesting work on that, but it's, um, certainly it's not, it's, it's not something
that plays a central role in my thinking recently. Um, yeah. So we have the, but just
yeah, a variation approach to niche construction. Yeah. I don't know if, uh, if Mark has anything
to add or, um, anybody else, um, which we're thinking about. Yeah.
Darius, can I just check one thing you asked? I don't know how much I need to add here, but, um,
did you think that the wall was reducing free energy relative to the climber? Did you say that?
That's right. So my, so I don't know how that, can that be the case? Can that be the case?
The wall, the wall as a thing is maintaining itself and I mean, relative
self evidence thing, right? Yeah. But, but it's not really a duet of one here. It's not like
it has a generative model that's deep where it's modeling the climber modeling it.
Like the same way as tango dancers do tango, the tango duo are, are, are having cooperative
flow states because each movement opens a vista of possible air minimizing opportunities for the
partner who in turn opens a vista of air minimizing opportunities for the partner.
Yeah. And backwards and forwards into this ever opening expanse of affordance capabilities,
but an inanimate object in an agent don't really have that same dynamic. So I was wondering what
you were thinking there. So my thinking was, is that this kind of bleeds into the notion of
fluidity of affordances in the kind of Gibsonian sense and the fluidity of concepts. So I agree
in the, in the sense of physical self evidencing, it needs to model the rain, it needs to model the
physical environment so as to maintain itself. But what about as it's a, it's, it's
so a sheer rock face is not a climbing wall. And that's because it doesn't self evidence as a
climbing wall. It doesn't offer the affordances to be climbed. That's why I was kind of referring
to, which is that affordances change based on the, on the agent arena relationship, right? Your
car's affordances change whether it's working or broken down. Similarly, the climbing will
change is whether it's got footholds, handholds or whether it's just a sheer rock face. That was
my thinking. It seems slightly spook, it seems slightly spooky to me that we'd think of the wall
as self evidencing in that way. I think, I think the language that we tend to use because Julian
Kivastien, Eric Reichfeld, Yele Brunberg and folks often use the idea of affordances and
fields of affordances in the active inference way. The, the, the radical end of the pool there is
typically that the affordances don't only happen on the agent side, but rather happen from a dynamic
of the changing volatile environment and the generative model of the agent and that they're,
they're collaborating in dynamic ongoing ways such that the affordances are emergent between
them. That certainly, that certainly seems right to me. The, the idea to push it a little bit
further and think about the wall self evidencing, it's a, it's a, I think it's a step too spooky for
me. I think I would, I would feel safer, safer, a little bit closer to thinking about the affordances
are changing relative to the dynamics of the wall. But I don't know what it would mean for the wall
to be evidencing the climber or itself. Yeah, just to kind of, that's stood a couple of thoughts.
A little longer on the word affordances, because there's this really nice distinction in their
work between what they call, well, I'm not sure if they, I think, I think the term landscape of
affordances is a little bit older, but they make this distinction between a landscape of affordances
and a field of affordances. And I think the reason this is, it's really important to get on the table
is because it, this distinction is kind of directly targeting the dynamic shifting very
affective nature of affordances. So on the one hand, you have this landscape of affordances that
is relatively static. So, so right now my landscape of affordances is, is brightened.
And that's the landscape of affordances in that sense is not really going to change very rapidly
unless I kind of jump on a plane and go somewhere else. But the field of affordances has this thoroughly
kind of normative affective character to it. So depending on my internal state at any given time,
depending on my expectations or my desires say, my field of affordances is going to
shift very, very rapidly. And it's not just not just predicated on my internal state,
but also kind of contextual cues as well. So if something were to happen in the environment that
was afforded very high precision weight in, then that's likely to shift my field of affordances
significantly. I think that the reason that I'm kind of emphasizing this to Darius's point is
and kind of building on what Mark said, it, it doesn't seem like this distinction at least
would apply from the perspective of the perspective of the wall, say, because this kind of affectivity
and normativity just isn't a feature of the wall's experience of the world. And also to kind of run
with that the, I mean affordances, perhaps you could say a bit more about how you would kind of
think about this, Darius, because affordances are kind of opportunities for actions. Okay, so it's
they're kind of, I like to, there's some debate about this, but I like to think of them as like
a relational property between of like this, you have the skilled capabilities of an embodied agent,
and then you have some feature of the environment. So I think when you're thinking in from the
perspective of the wall, you have the features of the environment, because you have the embodied
characteristics of the agent are kind of playing that role. But it's not clear to me what the,
the kind of skilled capabilities of the wall is. So, yeah, if you could just say a bit more about
that. Yeah, I mean, it may be the case, as you pointed out, that actually the technical
term affordance as being opportunities for action is misplaced here. Okay, so I can see, again,
this is a lot of this, I've been formulating having read this very new paper by Ramsey and
colleagues on Bayesian mechanics of physics often by beliefs, where he really rams home this
point that the system, the generative model is the system of the kind of stochastic, stochastic
differential equations across the state space. So across the marker blanket, across the particle
with its marker blanket and the external states. And that is the system which is in that system
itself is in the business of reducing free energy. So it's not just the active inference agent,
the whole system, which is embedded in the whole system of other things. And so that was my general
thinking is that just on the prerequisite that these systems exist, just on that a priori axiom,
there has to be some kind of self evidencing of that system itself. So maybe affordances is the
wrong word. Yeah, that might be the trick right there. As soon as you provoke affordance, you're
provoking phenomenology. And so now we're not talking just about statistical variations. Now
we're talking about lived experience. That might be that might be the the linchpin right there,
I think. I think that is right. Yeah. And I would say I think, Darius, you're absolutely on
the right track. And you're in, I mean, there is this ambiguity about affordances. But aside
from that, I think you're absolutely right. I mean, it's, it's just nonsensical to think about
an agent, absent an environment under active inference, you have to, it is this agent environment
system in its totality that's minimizing free energy, they have to be, they have to be taken
together as one. And I know, Abel, you've had your hand up for a little while there. Do you
want to say something you wanted to add? Yep. Do you hear me well? We do. I do anyway. Okay.
So, about the affordances world, I think affordances. And basically, the symmetry of
agents in environment is a property of active inference, well, of the French principle. So if
you buy a French principle, and you also buy that it entails that agent have affordances or any
proximal notion, then you also buy that world's other affordances. So there are basically three
positions you can have on that. One is that active inference is correct. World are talking
affordances and they do self evildancing, which I would not go with. Another option is that you
have basically devolved in the detail. So for example, maybe the agent environment is not
the wall. It's something that is broader, like Gaia system, whatever. And it just so happens
it includes the wall, but it is not the wall. And it does do self evildancing. And the third
is that active inference is wrong. We don't have affordances based on whatever is the
formal presentation of active inference. And I would go in that direction
of this phenomenology stuff. So we have a, I would say, philosophical evidence in the
sense that denying this would lead to nonsense, but the information is based on observation.
And some system do observing much more actively than others. And maybe it's a good thing to have
in your formalism, I'd say. So you have maybe a stronger case for the way phenomenology affordances
are constructed in the quantum formulation of the FEP. If there is such a thing, which
like Chris Fields, someone who we should baseline believe claims there is, because then you have
formalization, which is not in terms of dynamics per se, so causal constraints,
but observation and interactive phenomenology. Maybe you have something that is stronger there,
but right now the link, oh, and yeah, sorry, there is actually a bunch of people who have a quite
good hold on science, which are based on the inecological activity and cognition on one hand,
and between cognition and the metabolism, the constitution of the living thing that
cognites on the other. And one of their, that definition of agency, cognition, and pick one,
entails interactional asymmetry, I think is the word.
That is something we would need to translate into active inference, well, into the FEP
for active inference to have a strong grip over this affordance thing.
Until then, we have a kind of hand waving way it relates it to more conceptual approaches
that are related to an active and ecological approach to psychology. And
yeah, the formalism lags basically behind the concept for now. Sorry for the long talk.
No, that was great. Much appreciated.
Is anybody else want to come in on a question of affordances? Because I know affordances played
a fairly substantial role in the lectures. So anybody has any questions related to affordances
or action, perception and affordances? Then now's the time.
Yeah, I do have one, but it's not well structured yet.
The same thing that I've been thinking about for the last months, because I started to
keep an artificial intelligence field up, coming from a humanities background and philosophical
background. So I'm mixing many things in this period, mainly following the active inference
as a crossword between many disciplines. This is very beautiful about the framework.
I was super curious about the question proposed by Darius. I was then thinking about
now we're actually facing a new environment and a new landscape in which we're interacting with the
and
comes in extra actually generating
over a revolutionary time and synchronizing over a logical alien agencies operating within our
landscape and field of affordances. So I think there's
a lot of really interesting work to potentially be done there. I will take the opportunity to
shamelessly plug a preprint that Mark and I have released recently where
we one thing. So one thing that I'm really interested in that I can kind of speak with
some confidence on is the fact that I do think there's a point at which the theory of affordances
or the language of affordances starts to break down.
So the preprint that I'll share around is looking at ambient technology specifically. So this is
technology that you the whole kind of impetus behind its design and conceptualization is that
the user doesn't have to actually do anything. So it proceeds the user pragmatically and
epistemically. It knows what kinds of things you want it to do and it just does them in the
background and it works by shifting kind of it suddenly shifts the material environment such
that it impacts your field of affordances in real time. And the argument that we make in that paper
is essentially that the affordances approach doesn't really work for this and that we need to kind
of think again. So yeah I mean I think that that might be a nice but like how to conceptualize
generative AI for example under the affordances framework. I'm not I don't know anybody that's
done any work on that but it would be it would certainly make a really cool project.
You are making it right now.
You are making it right now I know because you set me the paper to review.
Oh yeah. Thank you. Thank you. We were looking at we so we are
early stages of a paper on the role of generative AI in classrooms. So from the perspective of
thinking about what kinds of affordances generative AI represent in a learning environment
particularly with we're kind of applying active inference to classroom design and looking at it
from the different angles of different educational and pedagogical theories.
But it's very early to date with that stuff. Yeah this is I suppose it probably depends on
your view of generative AI in general I mean it depends whether you would consider it a real
cognitive agent or not. I think I think some people are more inclined to think of it as you
know this thing this is a thing that has agency it has real understanding it has like
you know and other people are maybe less inclined to think of it in those terms and I think that
might be that might bear significantly on on how you think of it. Yeah that's super cool that
basically the last project you mentioned is very very in line with my PhD project right now because
my main PhD project is our European Farmings and it's about the AI for personalized education
and I'm trying to follow it through the the active inference framework from a multi-level
perspective. So yeah very cool yeah we should we should probably talk more about that.
Okay Darius.
Yeah I wanted to ask I mean this may be directed more at Mark because I know this is kind of his
work in terms of slopes of uncertainty and about doing better than expected at reducing prediction
error over time. I was wondering kind of how the architecture of that is built into the into the
particle into the into the generative model because we have the kind of for me there's I don't know
if it's an out and out sort of conflict but we have these kind of implicit priors that we're going to
fulfill certain expectations or minimize prediction error regarding certain things right so
homeostatic priors or happiness well-being whatever it is but then your claim is that we
have the higher order beliefs the higher order predictions that over and above that I also need
to become I also need to do well better than expected at reducing prediction error over time.
So is that I it's still quite fuzzy in my mind but is there a kind of potential conflict there
between the general priors that the system has and then going actually in a sense violating
those expectations by going over and above them which itself constitutes an expectation how do
you kind of resolve that tension? Yeah that's interesting but this is very much in Ben's
wheelhouse too. Ben and I have been working on slopey stuff for almost as long as I've been
on
this original paper called we'll get it we'll get it up they do a really good job of showing
technically where this sits within a deep parametric model. Lara Sanved Smith's paper on
metacognition also does this by showing you have these you have these depths of modeling
where models above are modeling models below okay and optimizing over those models below.
So we have some good computational backbone for thinking for not only thinking that this is the
case but beginning to express how it does the work it does so let's let's leave that for digging
into it though technically on sort of on our own let me say sort of at a higher more abstract level
still hopefully it's useful. It's not weird to think that this kind of anticipatory system is not
only making predictions about the world but it's also part of what it's predicting is how fast or
slow how efficient it is in particular contexts at resolving certain kinds of errors that's a
perfectly fine thing to think that we're also predicting slopes of engagement and then and then
all we're saying then is system also pays attention to when those expectations are breached and it's
learning from those breaches that's that should just be the bread and butter for what the system
does anyway so precision is a second order is a second order process in much the same way
precision is about how well how how reliable are lower level predictions and then using that
that amount to toggle how impactful either errors or predictions are so we've already
got baked into the system right from early days this idea that the system is not only making
predictions but monitoring its own predictive processing regimes and then toggling based on
how reliable those those substreams are all we're adding here is you know when we first when we
first thought about those mechanisms one thing that can happen this is just good for everybody
who's interested in active inference because I bump into this with my students all the time
when we say something like precision waiting a tendency to think of this thing
so we go to define this precision way like where's the biological instead or like this precision
waiting when we actually get into a bio system and we look for these things the truth is precision
is going to be weighted in lots of different ways I mean that's the real frontier of this
research is to actually find how these things are instantiated and the answer is going to be
multifarious I mean it's going to be you're going to have precision adjustments happening throughout
the system in lots of ways it could be synchrony and asynchronous and desynchronies between systems
it could be neuromodulatory chemicals it could be structural structural shapes within the brain
I mean precision is going to be set in in lots of different ways so
all all that we're pointing out here is is that one of the ways that the precision is being set
one of the ways that the system is tracking how efficient it is and then upping or lowering
the amount of impact error signals or predictions have is that it's happening in an embodied way
so we've looked over to the affective search and and lo and behold there are all these signatures
that we were looking for for this kind of for this part of the machinery so yeah so not weird
that the system is tracking its own regularities and adjusting that was baked in right from the
beginning how it does that that's one of the frontiers it's going to happen in lots of different
ways lo and behold affective dynamics the shoe fits they look like they do that stuff and then
you bring it to the lab and you go back to like reward prediction error research and sure enough
neuromodulatory chemicals reward systems are tuning affective dynamics relative to better
than and worse than slopes of uncertainty management it's exactly what we would expect
given the computational model so then it's an easy it was an easy next step to start saying well
look there's one of the way is that precision there's one of the ways that affective system
and i just noticed there if the only decision is that and not the only thing the affective
system is doing we never want to say we never sort of we're careful not to be reductionist
to say oh affect is always error dynamics i don't think that's right i think is that error
dynamics are expressed in part affectively and they have this impact on the system that we can
that we've known about for a long time even from just the reward prediction error
literature does that help or was that a bit is that okay yeah uh yeah just to just to add to
two things really quickly there because i know time is kind of catching up with us i would
emphasize as well like just as a kind of general point the one of the things i really like about
the work on aerodynamics and affect is it has this nice kind of broad capture of the kinds of
affectivity that agents can experience so we're not just when we talk about affectivity we're not
just talking about full-blooded emotions or even just moods but um we're talking about what one of
the things i kind of drew attention to in the lecture was matthew wrackliffe's work on existential
feelings which i think is just such a um that the connection between active inference and phenomenology
that you find in some of this work is just insanely powerful and it's one of the things
that really drew me into the framework um the second thing just building
one thing that i don't think i mentioned in lecture is active inference as it has been
described as a quintessentially metacognitive framework so you have kind of built into the
architecture you have expectations over expectations so you have kind of predictions
about predictions and this has proved to be um just you know again just phenomenally useful for
thinking about certain aspects of phenomenology as well so um yeah i think that these are these
are like real strengths of the framework okay um i don't know how we're doing for time are we are we
strictly limited on or can we we are not as far as i know Daniela
well um i can probably do i definitely do another 15 um if anybody has any more questions
and people i should say as well we're not that doesn't mean that we're all held captive
to my time frame so if people if people do need to leave within the next five or ten minutes that's
absolutely fine but um i'm certainly happy to to carry on if anybody has any more questions
or comments
um if no one else has got any i would quite like to go back to
earlier in the discussion you were talking about the value of uncertainty
um because uh in organizations in which i'm working with we often have conversations about
uncertainty and what we find is over time there tends to be a drift towards risk aversion
so we're working with a large uh international construction company at the minute and that they
used to have a culture in which innovation um uh was uh was quite well embedded and and over time
is kind of drifted towards very very risk averse culture where actually rather than
learning through the process and being able to tolerate uncertainty you know around opportunities
and you know what can be accomplished and that kind of the valence that comes with
the intrinsic reward i suppose of being able to reduce uncertainty about capabilities to
a situation where they're trying to anticipate all of the risks up front before they even get
involved in the project so you know there's there's some kind of valence switch market and you
mentioned um david blaine earlier you know and something about the context you know there was
a switch in valence from yeah this is this is a kind of a play this is a safe thing to do to
actually know this is you know this has real consequences so i'm just kind of i'd like to
explore that a little bit more actually if anyone's got kind of any insights or papers or comments
yeah so i think that's a really interesting question actually and i i think um so it seems like
one of the things one of the things we've been talking about is this connection between uncertainty
prediction error minimization and affectivity in individual agents and it sounds like what you're
asking is like how does that translate to uh like collectives so one of the things about active
inference that we're going to see in subsequent weeks is how it scales up to kind of larger systems
like companies or you know groups that are trying to achieve some kind of shared goal
um how do you how does the value of uncertainty translate onto like how is it scalable in that
sense right is that would that be a fair kind of yeah i i guess so um i i guess it's um i mean
the uncertainty often when it's talked about uncertainty is talked about as risk which is
you know i suppose is you know predictions or anticipation of outcomes that we don't want
right whereas there there's also positive uncertainty right you know which is you know i
suppose you know simply stated opportunities you know through curiosity you know what might we
be able to achieve you know this kind of novelty seeking i guess that you know new opportunities
that we haven't exploited um and they're just you know in the kind of organizational systems
you know i i think there are various pressures that cause it but but over time you see these
cultural shifts towards uh you know a very very kind of risk averse you know where you know where
the valence is obviously quite negative you know you know quite a non-pleasant feeling for people
and yeah yeah this is yeah this is good this this is right at the heart of my current work um i'm
really interested so you know we just had a big stint where active inference models were starting
to be used in computational psychiatry especially for pathological disorders so addiction depression
disassociative disorders OCD PTSD um it's a really it's quite a it's a quite um a sexy framework
for thinking about some of the ways that the cognitive system breaks down and the sort of
new move right now i mean we have a collection coming out right now in neuroscience of consciousness
is to think about these things in terms of okay if we are predictive systems and we have a
sufficiently rich model of how that system works in a particular niche what sorts of what sorts of
what sorts of ways can we intervene on that system in order to have positive outcomes
rather than just modeling what the negative outcomes are and i hear that a lot in what
you're saying now so i'm just going to drop one link for you there this is kasper hasp again
wrote a little a very small paper with a nice little model called sophisticated affective
inference he has a little bot that tends towards catastrophe catastrophizing the future if it's
given if it's given like fun medium fun medium fun dangerous over time it tends to it tends to
expect the dangerous one um uh like after 10 000 iterations it basically lives in the worst possible
scenario which is a nice little song this is my wife i'm going to give this is this is most people
today you know so the question is um i want to know given the model why does that happen
and what can we be doing to intervene and part of the answer is going to be
we need to become more tolerant of uncertainty that's one of the things that the system can
be better or worse at so this just takes the computational modeling and then looks to things
that we already know about emotional regulation that that's that's part of the story um so um
we've done a little bit of work on this with our predictive dynamics of happiness and well-being
and ryan smith is definitely doing work on this with active inference and well-being um so
definitely check that out if you're if you're interested here um but i just flag one interesting
thing here that relates just to what we were just talking about about layers of modeling
one way that let's say two ways there's two ways that a system and it's probably gonna be lots but
the two that come to mind that a system can become more tolerant uncertainty is one exposure
so this is why exposure therapy might be useful for our kind of a system
you want to expose the system to volatility at the lower and middle levels of the hierarchy
and have it turn out okay so that this one of the things that the system can come to predict
is not only you know particular outcomes but it can also predict how much error is involved
in particular outcomes so for instance um when i used to give um a pro talk i was always really
nervous um and i don't know if that ever really went away but i've had so much exposure to the
anxiety of giving a professional talk that basically i don't notice it anymore but if you
were to ask me at the beginning of my talk mark right now what's your phenomenology
and i sort of meditatively looked i'd probably say yeah i'm nervous but if you hadn't have said
that and you were just like hey what's up i've been like oh yeah i'm great like it's all good i
don't even notice it anymore that's because the system knows that i have errors
but as soon as i start talking they drop away and because i know the arc that even error in the
system it becomes non-newsworthy it's no longer interesting volatility to be tracking that's
just from exposure okay so what's happening is you're having errors at a lower or middle level
that a higher level is now modeling saying when we come here we should expect this arc of error
same thing when you work out like real gem rats they can feel good
well you're having your jet your tiller skeletal system right but at the higher level it's now
learned not only that that has a natural arc but that that's a good sign at a higher level
so now you're getting a positive you're getting positive prediction error slope high
and negative prediction error slope low okay so one yes exposure to you can model your own
responses this is something ben and i work on with horror movies you can you can you can
you can take an active role in mindfully observing your own reactions to volatility
and um this comes up in our paper on horror we've already dropped the link today if you
want to check it out something really special happens when the system models its own reaction
to volatility it starts to learn that um even reactions to volatility uh don't need to be um
they don't need to be compounded up into dangers that it's okay it's okay to be uncertain at certain
levels of the system so how that translates in the business i'm not sure other than i know
tolerance to uncertainty as a marker of business success and um i suspect the framework gonna fit
lots of mindfulness mindfulness work about learning to tolerate uncertainty
is there anything about um the role of language in kind of modulating those metacognitive
oh it's good if i may i was uh preparing an answer on that specifically and i was
nervously waiting for the opportunity so um
like meta in terms of evolutionary um cognitive archaeology we don't know when language emerge
but we do know that's uh let's say an anchoring semantic system so you can build things in
language and you can expect things in the world to correspond to things in language
so for example if you that's abstract as i say it's abstract but you can for example have a
self identity and i'm a french i'm a french and i communicate with the expectation that are
embedded in that identity with other people and that means we communicate over and over so so we
have specific expectation of what we will do and those expectations they become embedded in specific
symbolic markers that are embedded in language and uh something that uh like the thing that it
was strongly evoked in my mind when you talked of tolerance to uncertainty is that um
as far as documented history goes uh europeans well indoeuropeans they are pretty strong on the
idea that things have a nature and they act lawfully and their nature and their laws they
somehow correspond to linguistic categories so i can say stuff like um chickens quack and that's a
proper explanation of what are chicken and why they quack and if you look in chinese philosophy
as far as written history goes you have a much more accent on the way we weigh so um a poor
translation would be a effortless action closer translation would be action without action so
it's a form it's something that is quite close to the phenomenology of flow in that you observe
yourself doing things and you do not apply a conscious effort to uh the flow of what you're
doing and that looks like something that is uh closer to the phenomenology you'd expect if you
apply you know recursive proactive cognition with less or less heavy or more effectively integrated
symbolic concurring like use of language as something that you actually expect to be meaningful
and to uh constrain strongly reactions and marginally i'd expect very strongly
to expect that linguistic categories will map and what you build with it so i don't know self
identities plans whatever uh will map cleanly onto what you observe you will be very very
anxious about things because that does not happen usually um and yeah um besides uh grand discourse
on the interpreter preference traits which are usually not that constructive i'd uh
yeah sorry i got lost because i do not i the speech tonight tonight let me just say one thing
before before we move off this point uh a simple way that language might help is by invoking
cognitive flexibility so um oftentimes we think about the management of error being either updating
predictions or acting on the world those are the that's the dyad usually what it overlooks is the
third one which is we can also manage volatility by redeploying precision in a better way so rather
than just updating your model to fit the world or updating the world to fit your model you can just
change the set of what matters so that you're not you're not really updating the model and you're
not really changing the world you're just changing the problem landscape and that's something language
allows us to do it's maybe one of the one of the really amazing things that language allows us to
do is we can use language to bootstrap that kind of precision adjustment so if the train doesn't
come on time we both notice it okay and we feel bad that's perceptual updating we might go and
get a taxi that's active updating but i might just say to you um wow look isn't that isn't it lovely
that now we get a little bit more time to read our book or to continue our conversation or let's
finish our coffee with a little bit of ease i mean we get an extra 20 minutes now even just saying
that redeploys precision over the problem space now the train being late isn't volatility in the
system the train being late is signaling to the system that a better than expected slope has been
achieved isn't that so interesting the exact same occurrence is either undigestible volatility
right like you're gonna be late oh my goodness or it's an opportunity for an improvement in the
system which is now you get more time with the person that you're um taking the train with
and that was just a matter of linguistic um perturbance of the way that precision is being
deployed so i if you're looking at if you wanted to dig into the research here i would look up cognitive
flexibility and language or coaching cognitive flexibility is such a good point here
if i meant for something um so the uh you have a paper by nick lark on
this specific and coring role of language and something it entails is that basically you got
like if the acting from specter is correct you will flexibly predict the flow in the
interoceptive proprioceptive exteroceptive is that even a thing uh space and that is that is what
build an integrating experience integrated you know um cognition and language it adds another
layer of complexity if you can just talk to yourself in your head that is another dimension
that you can predict and that can be coherent or incoherent with uh you want and so that is
an extremely powerful and coring system because i just have to like tell a plan to myself and boom
that uh pushes me nudges me nicely to follow the plan but then you can have a different level
of meta expectation over how language corresponds to reality and i'd say a very very strong factor of
you know a version to incident is whether you expect your plans or your linguistic structure
to nicely map onto reality because it will not happen but if you expect strongly that it will
be the case you will have to make it happen somehow and here you will adapt rigid strategies and you
will like lose flexibility but also language and sorry for flexibility to be the case in the
first place so it's about coupling between dimension of cognition
yeah and i would just uh just kind of this risk and danger are uh two things that i've been
really interested in across a kind of variety of different contexts and i i would say
some of the things that have been said like the kind of how you can influence the system by
externalizing things through language and the different strategies that systems whatever scale
they're on have that minimize in prediction error um minimize in free energy but also i would just
emphasize the importance of like external context here as well so even in the case of like a
collective like a business you still have to take into account the environment in which the
business is operating and i i've been really interested in a particularly extreme example
of context um i used to do still do some work in philosophy of sport and i've been really
interested in dangerous sports and why there seems to be this insane contextual effect where
within a very kind of narrow contextual band of sporting practice people seem willing to
take on risks that outside of that context would just be completely insane um and i think
this is something that's probably going to come up again again in uh you know subsequent weeks as
well here when we talk about um the way that expectations on an individual or a collective
basis can be set but through other minds uh select patient so what somebody else expect myself to do
and so on and so on uh darius you've had your hand up a while do you want to jump in yes please
i'm not sure this is the sort of grand synthesis of any of this but um flow was mentioned as i say
that's the kind of um pet topic of mine and something that we know about flow and this
why it's integrated into this idea of language and agency is that at least in its original
conception success mahali and the sort of qualitative experience associated with flow
you would find stuff like not only the dilation of time but also the reduction in self-consciousness
and now this is sort of picking up a lot of work that happens at ucl and people like jeremy
skipper how integrated languages into the sense of self and it seems to me and i you know this is
kind of shooting from the hip that all of these very deep rooted i guess they're kind of psychotechnologies
the self language seem to dissipate at this goldilocks zone at this point of at the at this
edge of criticality at this flow state which makes me think if the flow state is a phenomenological
option of being you know optimally reducing prediction error what is the kind of role
of the concept of the self or linguistic functions because it seems to me that that
becomes a regulatory function when that optimality is reduced when stuff starts going wrong um so i
think you can also think about this in the kind of heideggerian or drafus sense of just opening a
door you only start to represent the door in yourself you only give it the linguistic
object of a door when you can't open it when you open the door standard there is no representation
going there i mean you could do the argue there's no quality at that so i'm wondering how deep that
runs and what the kind of what we can say about the role of agency selfhood maybe even consciousness
because they don't seem to be that prevalent at least from my understanding
when we are at the edge of criticality the suggestion you're making there is um
it sounds like what you're saying that these things you call them psychotechnologies which i
really like you know like language and and and self like certain aspects of self modeling they are
a kind of scaffolding uh or like a ladder that you then kind of gets kicked away once you reach a
certain kind of edge of criticality like where the performance becomes i don't know what you kind
of want to say there but you're performing at such a level that you just don't need those those
scaffoldings yeah or the self regulatory mechanisms that we harness when we're not in flow
are linguistic or agentic in essence and once yes once you sort of you don't need that when
you're the sort of yes when you're at this edge of criticality um and i you know i only
postulate that because i want i'm only i'm only thinking how deep does that go because i know
obviously the the active inference framework is trying to tackle in some ways the hard problem
as well and there are some floatations of the idea at least within the flow community about
the kind of i don't want to say elimination but the moderation the modulation of qualia
under flow states so could that could we also consider that to be a construct
which happens when we're not necessarily
at optimally you know producing prediction error so a couple of things i so i'm certainly not the
person to start talking about consciousness so i won't um but i would just um i one of some of the
readings that i mentioned in the lecture might be interesting for you on this topic so if we're
if we're talking about certain structures that seem very very pervasive in our phenomenology
and how those structures can sometimes kind of dissolve away um and how that might be
accounted for under an active inference framework there's some really interesting work on psychedelics
by george deen and some of george deen's uh co-conspirators i know i know mark
and sam welkinson worked on a paper with george so george deen's done some work on
kind of ego dissolution and certain kinds of experiences um related to selfhood um kind of
and i i kind of don't want to overstep the mark i but i think they kind of come they fall generally
under this kind of rebus model of um psychedelic efficacy so i don't know if people are familiar
with this but this kind of finds a natural articulation through predictive processing
and hierarchical self-modeling and and that kind of stuff i also wanted to really quickly flag on
this topic i'll find the paper and i'll put it up on the coda because i don't think i'll be able to
find it quickly enough now but there was a paper that came out very recently um that showed the
efficacy of um internal self-talk on sports performance so there were so they did a they
did an experiment with cyclists and they found that when you um when cyclists were allowed
to engage in kind of constant self-talk with them so like an inner monologue in their head
their their performance at cycling was like measurably boosted which i thought was really
interesting and kind of relevant here so but it's it's interesting because it kind of just kind of
uh it sounds like it might prima facia be in tension with what we were saying about flow states
as well right so it's if if the real edge of performance is is a place where these structures
of phenomenology phenomenology bleed away um it kind of calls into question like to what extent
are these psychotechnologies effective and in what way are they effective and yeah there's a yeah just
a whole kind of universe of really interesting questions there so if i may uh serve food indirectly
will be the the central topic of the last two sessions uh my position about it is that it's
self-food in a sense we use all of the time uh is a quiet high-level construct that
emerges from the ability we have to compare our activity to a socially embedded model of our
activity so that is something that is quite specific to humans because of their linguistic
ability and or because of their tendency to what tomasello calls a shared intentionality so the
ability to collectively define and like plants um so basically this is something that enables a very
deep very um profound and robust transmission transmission of cultural knowledge and transmission
of norms this is what enables the construction of norms uh but it's quite heavy cognitively uh and
it is predictable that if you're busy comparing what you do to what an idealized idealized version
of yourself is doing you're gonna invest less cognitive energy in actually doing the thing
that you would if you just you know did a thing so i'd say you have a pretty direct entailment of
the uh this flow thing uh from this model
yeah yes this is my question sorry um i think so we've run uh almost 30 minutes over time
and i know uh marks marks had to go and i'm gonna have to go very i think i'm pretty much have to go
so um i just wondered if anybody has any final kind of quick questions or comments maybe we
can move towards wrapping it up um i'll i'll i'll make a few comments but then you you're
welcome to leave and other people welcome to stay um if they would like so thank you for
yeah yeah well first um just on a on a on a logistical note there was a little bit of lag
so i'll encourage everyone who's listening as well as who's participating that we eventually
plan to as with all of our live streams develop a transcript which will be curated and published
and eventually not so far away in the future that'll be enabled with speech modeling to generate
podcast quality audio so the future will be smooth we promise um but a few really interesting
pieces that i that i picked out while i was embodying and listening
um so Regina you you opened the discussion with the discussion with uh surprise and creativity
and indeed it sounds like it's going to be attention how how can a framework who's imperative
is bounded surprise as opposed to say maximized reward how can a framework who's imperative
is surprise minimization and bounding be used to generate novelty and i felt like
people provided a lot of really cool answers and one other thing it reminds me of is uh
doug hoffstetter's notion of spec spec dishnish i don't know how do you pronounce it but sph
ex ish n e s s and it's the specs wasp and so he says well forget this whole creativity thing
because when we talk about creativity it's like some sort of you know pantheon like
divine status the muses have to be uh you know called in and so then oh that's not real creativity
and this isn't real creativity so instead he says well let's just focus on what would be the opposite
and that would be the road procedural following even when there's an opportunity for what we would
call creativity and then there's a continuum so why does somebody paint that painting well why
didn't they invent a new genre well why didn't they invent a new media and so all activity is
existing within this continuum of creativeness which has many features such as generativity
and productivity but also novelty but a bounded novelty it's not creative to knock the chessboard
pieces off in a way that there might be an elegant chess move who only somebody in a
certain cognitive setting could detect the aesthetics of but i think that that was awesome
um and then the second uh piece that really was was powerful was what mark uh mark's train
the i guess the trains don't run on time where mark is but but that's okay because he was able
to rather than treat that as an undigestible surprise that was able to be basically cognitively
metabolized into like an opportunity for friendship through language as a social medium and then
he connected that to cognitive flexibility and coaching and then I thought about self-talk
and our inner monologue inner voice and then Darius that that was very um provocative that
like we aren't having self-talk potentially not even having a self in the flow manifold
experience of a self or the the speech self self-talk or again potentially even the total
actual self as a technology and so then like wealthy self-talk would guide us to the flow
and be kind of like a self-limiting technology because it would be like used in order to not
be needed to be used which is kind of how we would hope adaptive technologies would be
versus a maladaptive technology would be something that um entrenches its own utilization
potentially at the expense of the functionality kind of like doom scrolling status but that's
internal rumination and those are the kinds of things that people have simulated in active
inference so those were some really cool pieces that was a great discussion
could I just uh just just add something on the topic of creativity that I uh should have said
earlier as well because I think it's really relevant to Regina's question and just the topic of
creative and novel behaviors in general and their active inference I think that
whenever we talk about especially artistic creativity there's a tendency
even even for people who are kind of well very very well borrowed into active inference and
and activism and and these kinds of frameworks from cognitive science I think there's a tendency
to think of creativity as as still like it's almost like the last bastion of internal
cognitivist thinking like you think creativity is something that happens in here and bursts
outwards and so how does that happen with this kind of whatever cognitive architecture we're
positing but there's really very cool work by uh have to give a shout out to Mike Wheeler
who's written some papers on the extended mind and creativity and one thing that's not really
come up very much that I didn't get time to talk about in the lecture is this really nice natural
marriage between the extended mind and active inference something that Andy Clark has been
working on and I know he's gonna gonna be doing a lot more work on it but the claim Wheeler makes
and some others um I think Jana Zalinska has written written a little bit about this as well
is the fact that creativity itself is just as subject to kind of uh material in but the
the sculpting effects of material environments and socio-cultural environments as everything
else is so create creativity is not this kind of romantic with a capital R kind of internal
process that kind of bursts forth but it's creative thinking is just as much extended and
embedded as everything else and there's some really great examples in in Mike Wheeler's
essay um I don't know is anybody familiar with the band Alt J they're a British band they were
kind of really big a few years ago they won the Mercury Music Award because they have a super
original sound so Alt J have this really quiet tinkling uh yeah they are a great band they're
one of my favorites and they have this really quiet tinky sound that everybody kind of assumed
was just the result of some kind of internal genius on the part of the band and as it turns out
Alt J originally they they tried to rehearse as a as an indie rock band but they were confined
to rehearsing in an apartment block and they kept getting noise complaints and so they ended up
developing this quiet tinkly sounds because it was the only sounds they could rehearse that
wouldn't get them kicked out of their apartment and I think this is a really beautiful example of how
like even the most creative processes that seem on the face of it really creative are in fact
just as subject to these external kind of this kind of agent environment system that underpins
the whole framework so it's that's something that's going to apply to absolutely everything
awesome and just a last question people are welcome to to drop off um the next section
that we're heading into I'll be doing the lecture that's going to be in August and it's going to
be on collective behavior so what would people like to learn or focus on about collective behavior
so
anyone who hasn't um spoken or or it can just be a thought question
but I haven't prepared the slides at all so I'm happy to take suggestions
I think what might be interesting is if we're saying that these uh systems are all in the
business of reducing prediction error of self-evidencing why do we see a diversity
of um why do we see a diversity of social cultures of norms of standards at a global scale
why do we not just see some um homogeneous way to reduce picture error which would manifest as
the kind of singular culture which which is in the kind of business of self-evidencing
that just kind of popped my mind cool
anyone else want to give give it that on collective behavior or on any other aspect
otherwise it's been great I'd like to make a comment of creativity
so but uh does anyone like it's a moment if you want to make a comment on the next session
I'm not going to cut that
okay I'd say that to complement what Ben said that creativity is something that is intrinsically
very hard to model because by definition creativity is something that brings about
something new let us say and the mathematics we have to describe physics and life they are
not very good at new things because the most basic tool you have the basic way to represent a system
that literally everyone uses is a state space which is the least of all possibilities of the system
if you say something is creative you're likely to think that it means it can bring about new
possibilities and this intuition it conflicts directly with the very basic use of math
describe it so it is basically the same issues I was referring to all year when I talked about
the comparison between active in France and an activist so let's say activity biology inspired
model of cognition and a core concept historically in those circles is autopoiesis so the ability
of the living to self-create literally this is Greek for self-creation and you had a lot of drift
and concept politicization and ambiguities that were resolved or not resolved and led to the
crisis or frame of blah blah blah but today we talk of autonomy rather than autopoiesis and we
define autonomy as the property for a system of constraints over the activity of a system
to reproduce and and because we're talking constraints just the ability to influence
cause area outcomes there is no really a prior that dynamics in this space would be
conservative so we have a possibility for constraints to you know bring about new things
and reconfigure themselves and the notion of agency ad use is based on that it's the ability to
let's say reconfigure constraints in your environments and so is the notion of creativity
which would be a likely a very close proxy to that but it's something that we do not know how to
advance and most of the mathematics that exist are structurally unable to represent and so yeah
that's a big one
no true
michael
i uh good to be here sorry i was late
what comes to mind for me at the collective you know i mentioned units of collective life
what is it of we is it of we a parent you know but you know what what are the what are the units of
we and any thoughts or insights about that uh that the stages of the emergence of formation
into a collective from a me to a we for example or um oh my god i had one of those on the tip
of my tongue and it's just a statement oh um you know this idea of precision that um that
i think it was part of what we were talking about for matt um saying um you know uh
if there's options in the
looking at collectives and what might be some of the most well understood limiting beliefs about
when we use language of collective that keeps us repeating the same blind spots
and how might we say differently about collective so that we we escape those predispositions
make sense
they'll do what i can do in the solo lecture and i'll i'll look forward to the conversation
where we can unpack it yeah exciting thank you for doing it i'm looking looking forward to it
yeah that's awesome um nate thinner david you want to add anything
all right then thank you all hope everyone is um enjoying the course so far thanks aval again
for for coordinating it and to ben for this great section now you can put on your student hat again
so and to you for organizing thank you see you all next time thanks everyone bye thank you
thanks thanks everyone
you
