And there's a way of using uncertainty as entertainment. And it's very difficult to
understand as a, you know, as a concept for entertainment, why would you like to be in a
place where you cannot, you want to predict, but you cannot and you still want to participate in
this activity. So for me, magic shows, it's kind of breaking a little bit.
Yeah, I think I spoke to, I forget the person's name, but there was a
Xscape meeting here at Sussex. And I spoke to one of the guys on Xscape who had been working on magic.
I don't know who I'm talking about, but I think they have a book on magic.
And I think that's really cool to think about from a predictive processing perspective,
the idea that magic is just these wonderful kind of violations of expectations in a certain sense.
I think predictive processing provides a nice, really intuitive framework of thinking about
those kinds of things. One little point there, Regina, just about, again, if it feels paradoxical,
just to sort of, um, complexify your view. Remember that the, this is always happening in
a hierarchical system. So just because you have errors at one level of the system doesn't mean
you're going to have sort of critical cascading unbearable errors at higher levels. So that's
why it's fun to go to horror movies. So I dropped the paper here. Also, we have a new paper coming
out on, on horror movies. I'm pretty interested in this, but it's the same as the, it's the same as
going to the magic show in some way. Now, the reason why those errors are, are fun is because
we're safe in a theater where with our friends, we have lots of sugar in our system from eating
popcorn and candy. We can control the amount of scary by, by, you know, covering our eyes or
like, there's lots of control here. And yet we're getting media that is, that's pinging all of our
evolutionarily ancient error tracking systems so that we're getting jumps in the physiology
as if there's a bunch of volatility that we need to manage. And yet we're in a completely safe
space, which is really fun for our kind of system because we're hierarchically deep predictive
systems. The high level here isn't jeopardized. It knows I'm in a theater, but the low level
stuff is still registering all sorts of little volatilities, but of course they get squashed.
They don't cascade all the way up. Or if you're the kind of person where they do tend to cast
all the way up, then you're also the kind of person who doesn't like going to horror movies
because it kind of scare like you go home and think, oh goodness, maybe ghosts are real and
maybe I live with them. You wouldn't be going there then. So with magic, it's the same sort of
thing. Um, we know do certain things. So with error, I don't know if you've ever seen, um,
I can, um, who does the really extreme magic where he like was in a block. Yeah, David Blaine,
have you ever seen him? He goes to Haiti where you have a community that really believes in
magic and he does some magic and he gets into trouble. Like suddenly all the young men are
like, Oh, no, no, no. No, that's, that's no bueno that, that you're doing this. And then he had to,
the camera pans back and he goes, no, no, no, hold on. I'll show you here. I'll show you how
it's done. It was just a trick. I'll just show you outside. It's not real magic because there,
they're not having fun with it anymore. They're like, no, that's like not a good thing to do.
Yeah. So it just goes to show that like, um, our, our engagement with magic is mostly a sort of
scary play. Yeah. I think one thing I just kind of, sorry about the seagulls. I don't know if you
can hear those. There are seagulls going crazy just outside my window. Um, one thing I would add
is I think, um, another aspect to this, this part of the framework wherein you have this value of
prediction error, kind of epistemic and affective emotional value of predict prediction error. It's
one of the kind of key elements in this notion of, uh, agency get in active inference that I think is
really, it's going to be really important in mind as you go through the further weeks of this course
as well. So what, uh, you know, like I said in the lecture, it's not necessarily speaking to a
quite the metaphysical question of free will, but it's certainly moving us away from this picture
of, of, of the agent as a kind of automaton that's just following rules. There's real
space here for kind of individuality and creativity as well.
Okay. Darius has been waiting a little while. So, um, let's go over to him.
Happily patient. Happily. Um, yeah. I mean, this is this question, I guess, is deriving from
my thoughts about the meeting of the, the high road and the low road.
Um, some of the reason why there's been coming out on Maxwell Ramsey and actually a conversation
I had with him, which is a, the generative model of the state. So my question, given that,
given and tall is regarding the notion of affordances, I think it's natural that as
cognitive scientists and philosophers, we take the perspective intuitively of the
agents in the agent arena relationship and how the agent is in the business of reducing
prediction error. I was just wondering whether as philosophers, um, you and Mark have thought
about what it would, what, what is it like out for the whole system to be in the business of
reducing its prediction error. So I'm interested in flow states. Um, and so for example, my thinking
is, is that in the canonical example of a flow state, let's say a rock climber, the, the climbing
ball is also in the business of losing its prediction error as to afford the opportunity
for it to be exploited self or themselves are in the business of reducing prediction error.
So I'm wondering whether this expansion of affordances is bi-directional, tri-infinity
direction?
That's an amazing question. So, um, you, uh, I think you mentioned Axol constant,
but uh, someone else, but I spoke to Maxwell Ramstein last week. Um, yeah, yeah.
There's a, there's a paper on, uh, I'll find it in a second on, uh, niche construction, um, and,
um, affordances. I think it's Axol constant, what they talk about the kind of the, the
symmetry between, uh, a niche and an agent, um, very much in like the same vein as you were
just talking about there, this idea that it's not just, uh, it, there's not just this unidirectional
kind of fit between the agent and the environment, but the, or the niche is actually modeling
generative model of the agent as well implicitly. Um, so I think the best I can do that direction
of some really interesting work on that, but it's, um, certainly it's not, it's, it's not something
that plays a central role in my thinking recently. Um, yeah. So we have the, but just
yeah, a variation approach to niche construction. Yeah. I don't know if, uh, if Mark has anything
to add or, um, anybody else, um, which we're thinking about. Yeah.
Darius, can I just check one thing you asked? I don't know how much I need to add here, but, um,
did you think that the wall was reducing free energy relative to the climber? Did you say that?
That's right. So my, so I don't know how that, can that be the case? Can that be the case?
The wall, the wall as a thing is maintaining itself and I mean, relative
self evidence thing, right? Yeah. But, but it's not really a duet of one here. It's not like
it has a generative model that's deep where it's modeling the climber modeling it.
Like the same way as tango dancers do tango, the tango duo are, are, are having cooperative
flow states because each movement opens a vista of possible air minimizing opportunities for the
partner who in turn opens a vista of air minimizing opportunities for the partner.
Yeah. And backwards and forwards into this ever opening expanse of affordance capabilities,
but an inanimate object in an agent don't really have that same dynamic. So I was wondering what
you were thinking there. So my thinking was, is that this kind of bleeds into the notion of
fluidity of affordances in the kind of Gibsonian sense and the fluidity of concepts. So I agree
in the, in the sense of physical self evidencing, it needs to model the rain, it needs to model the
physical environment so as to maintain itself. But what about as it's a, it's, it's
so a sheer rock face is not a climbing wall. And that's because it doesn't self evidence as a
climbing wall. It doesn't offer the affordances to be climbed. That's why I was kind of referring
to, which is that affordances change based on the, on the agent arena relationship, right? Your
car's affordances change whether it's working or broken down. Similarly, the climbing will
change is whether it's got footholds, handholds or whether it's just a sheer rock face. That was
my thinking. It seems slightly spook, it seems slightly spooky to me that we'd think of the wall
as self evidencing in that way. I think, I think the language that we tend to use because Julian
Kivastien, Eric Reichfeld, Yele Brunberg and folks often use the idea of affordances and
fields of affordances in the active inference way. The, the, the radical end of the pool there is
typically that the affordances don't only happen on the agent side, but rather happen from a dynamic
of the changing volatile environment and the generative model of the agent and that they're,
they're collaborating in dynamic ongoing ways such that the affordances are emergent between
them. That certainly, that certainly seems right to me. The, the idea to push it a little bit
further and think about the wall self evidencing, it's a, it's a, I think it's a step too spooky for
me. I think I would, I would feel safer, safer, a little bit closer to thinking about the affordances
are changing relative to the dynamics of the wall. But I don't know what it would mean for the wall
to be evidencing the climber or itself. Yeah, just to kind of, that's stood a couple of thoughts.
A little longer on the word affordances, because there's this really nice distinction in their
work between what they call, well, I'm not sure if they, I think, I think the term landscape of
affordances is a little bit older, but they make this distinction between a landscape of affordances
and a field of affordances. And I think the reason this is, it's really important to get on the table
is because it, this distinction is kind of directly targeting the dynamic shifting very
affective nature of affordances. So on the one hand, you have this landscape of affordances that
is relatively static. So, so right now my landscape of affordances is, is brightened.
And that's the landscape of affordances in that sense is not really going to change very rapidly
unless I kind of jump on a plane and go somewhere else. But the field of affordances has this thoroughly
kind of normative affective character to it. So depending on my internal state at any given time,
depending on my expectations or my desires say, my field of affordances is going to
shift very, very rapidly. And it's not just not just predicated on my internal state,
but also kind of contextual cues as well. So if something were to happen in the environment that
was afforded very high precision weight in, then that's likely to shift my field of affordances
significantly. I think that the reason that I'm kind of emphasizing this to Darius's point is
and kind of building on what Mark said, it, it doesn't seem like this distinction at least
would apply from the perspective of the perspective of the wall, say, because this kind of affectivity
and normativity just isn't a feature of the wall's experience of the world. And also to kind of run
with that the, I mean affordances, perhaps you could say a bit more about how you would kind of
think about this, Darius, because affordances are kind of opportunities for actions. Okay, so it's
they're kind of, I like to, there's some debate about this, but I like to think of them as like
a relational property between of like this, you have the skilled capabilities of an embodied agent,
and then you have some feature of the environment. So I think when you're thinking in from the
perspective of the wall, you have the features of the environment, because you have the embodied
characteristics of the agent are kind of playing that role. But it's not clear to me what the,
the kind of skilled capabilities of the wall is. So, yeah, if you could just say a bit more about
that. Yeah, I mean, it may be the case, as you pointed out, that actually the technical
term affordance as being opportunities for action is misplaced here. Okay, so I can see, again,
this is a lot of this, I've been formulating having read this very new paper by Ramsey and
colleagues on Bayesian mechanics of physics often by beliefs, where he really rams home this
point that the system, the generative model is the system of the kind of stochastic, stochastic
differential equations across the state space. So across the marker blanket, across the particle
with its marker blanket and the external states. And that is the system which is in that system
itself is in the business of reducing free energy. So it's not just the active inference agent,
the whole system, which is embedded in the whole system of other things. And so that was my general
thinking is that just on the prerequisite that these systems exist, just on that a priori axiom,
there has to be some kind of self evidencing of that system itself. So maybe affordances is the
wrong word. Yeah, that might be the trick right there. As soon as you provoke affordance, you're
provoking phenomenology. And so now we're not talking just about statistical variations. Now
we're talking about lived experience. That might be that might be the the linchpin right there,
I think. I think that is right. Yeah. And I would say I think, Darius, you're absolutely on
the right track. And you're in, I mean, there is this ambiguity about affordances. But aside
from that, I think you're absolutely right. I mean, it's, it's just nonsensical to think about
an agent, absent an environment under active inference, you have to, it is this agent environment
system in its totality that's minimizing free energy, they have to be, they have to be taken
together as one. And I know, Abel, you've had your hand up for a little while there. Do you
want to say something you wanted to add? Yep. Do you hear me well? We do. I do anyway. Okay.
So, about the affordances world, I think affordances. And basically, the symmetry of
agents in environment is a property of active inference, well, of the French principle. So if
you buy a French principle, and you also buy that it entails that agent have affordances or any
proximal notion, then you also buy that world's other affordances. So there are basically three
positions you can have on that. One is that active inference is correct. World are talking
affordances and they do self evildancing, which I would not go with. Another option is that you
have basically devolved in the detail. So for example, maybe the agent environment is not
the wall. It's something that is broader, like Gaia system, whatever. And it just so happens
it includes the wall, but it is not the wall. And it does do self evildancing. And the third
is that active inference is wrong. We don't have affordances based on whatever is the
formal presentation of active inference. And I would go in that direction
of this phenomenology stuff. So we have a, I would say, philosophical evidence in the
sense that denying this would lead to nonsense, but the information is based on observation.
And some system do observing much more actively than others. And maybe it's a good thing to have
in your formalism, I'd say. So you have maybe a stronger case for the way phenomenology affordances
are constructed in the quantum formulation of the FEP. If there is such a thing, which
like Chris Fields, someone who we should baseline believe claims there is, because then you have
formalization, which is not in terms of dynamics per se, so causal constraints,
but observation and interactive phenomenology. Maybe you have something that is stronger there,
but right now the link, oh, and yeah, sorry, there is actually a bunch of people who have a quite
good hold on science, which are based on the inecological activity and cognition on one hand,
and between cognition and the metabolism, the constitution of the living thing that
cognites on the other. And one of their, that definition of agency, cognition, and pick one,
entails interactional asymmetry, I think is the word.
That is something we would need to translate into active inference, well, into the FEP
for active inference to have a strong grip over this affordance thing.
Until then, we have a kind of hand waving way it relates it to more conceptual approaches
that are related to an active and ecological approach to psychology. And
yeah, the formalism lags basically behind the concept for now. Sorry for the long talk.
No, that was great. Much appreciated.
Is anybody else want to come in on a question of affordances? Because I know affordances played
a fairly substantial role in the lectures. So anybody has any questions related to affordances
or action, perception and affordances? Then now's the time.
Yeah, I do have one, but it's not well structured yet.
The same thing that I've been thinking about for the last months, because I started to
keep an artificial intelligence field up, coming from a humanities background and philosophical
background. So I'm mixing many things in this period, mainly following the active inference
as a crossword between many disciplines. This is very beautiful about the framework.
I was super curious about the question proposed by Darius. I was then thinking about
now we're actually facing a new environment and a new landscape in which we're interacting with the
and
comes in extra actually generating
over a revolutionary time and synchronizing over a logical alien agencies operating within our
landscape and field of affordances. So I think there's
a lot of really interesting work to potentially be done there. I will take the opportunity to
