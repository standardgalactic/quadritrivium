Hello and welcome. It's August 16th, 2023. We're in the Collective Behavior Discussion
section of the Active Inference for the Social Sciences course in 2023. So perhaps let us
all go around and give an opening introduction and or reflection and see who joins and what
happens from there. But just so that everybody has said hello.
Hi everyone, I'm Bryn. I'm PM in South Africa and yeah, just excited to be here and see what
happens. Hi, I'm Andrew. I'm a graduate student in Indiana and I guess my field of interest
now is the knowledge management and I think that figuring out how we collectively learn
and can share information is a really interesting topic and I'd like to see how this would apply.
Hi, I'm Regina and I'm from Guatemala, but I'm living in Spain, studying and doing experiments
related to this topic and trying to learn a little bit of the theory that's behind it so we can, you know,
advance better. I'm excited. Hello, my name is Sasha. I'm calling in from California. I'm also a graduate
student. Yeah, just really enjoyed the spirited presentation last week. I'm looking forward to
discussion. All right, well, how about anyone can give a first reflection on collective behavior or
what was their thought or context before and where are they at as we kind of begin? Yeah, Regina.
Okay, so I just want to make sure that I understand because I took like two big lessons from your
lesson, right? And the first one is that, you know, this famous model of active inference that has
the agent and the environment and the mark of blanket in the middle, right, and just interacts
with everything, right? So I think what I got from what you discussed, maybe I didn't have a good
definition of an agent, but first that you can have that agent not be just an individual, but also
your definition of an individual changes, depending on what you want to study in the behavior, right?
So an agent can be an ant, it can be an ecosystem, it can be an eye looking at something, or it can
be as a society, for example. And I think that's a big take for me because it changes a lot the
concept of how to study things and use active inference just by changing how big the agent can
be. So I don't know if I got that right, right? So first that clarification.
So what is an agent?
Yeah, so I don't know if there's like a formal definition of an agent in active inference, right?
But if we, if we want to study whatever we want to study, because I'm not going to study because I
have to do that's like my goal, whatever I'm doing. So I want to study whatever I have to choose
what's going to be my agent and the environment it has. So choosing the agent, you can do it to
create a model or to make an experiment, whatever. But the choice you make, it will depend on your
and what you understand as an individual or as an agent, I think so, right?
Awesome. Anyone have a thought on that?
No, if I continue with just to add something else and this will be my mind. And then I'm thinking is that
also a big problem that we have or I think I have is that since I am part of the environment, you
know, you know, the perspective of whoever is studying whatever it is, it's also going to be an
effect in it. So maybe, maybe scientists already decided, but I don't know that we can never have an
objective way of studying something if you're part of the environment of the agent. So I don't know
we already forgot it, or we already decided that's it. We cannot have objective observations of
behavior in general. But you know, you always think about like the agent environment, and you
start in it as something else, but the something else is also affecting it. So I see that as a
problem, or maybe something that has to be said, like, we are not objective, because we're part of
what it's affecting our agents in the behavior collectively too. So those are the thoughts I
have to share.
Regina, I'm also new to all of this. So my preliminary understanding of what is an agent,
is anything that has any good reason to self evidence, and to itself, or to survive,
that doesn't want to dissipate, that might delineate the boundary of what an agent is that then
sets up the boundaries with which it will, as you described, start interacting with the world,
the environment. So if something, as I understand it, if something has a reason to go on being, to
survive, then it is an agent in the world.
Okay, but that agent could be anything, right? Like, is that what you're saying, right? Like, if he
wants to survive, can be an ant surviving individually, or a cell or a group? Okay, yeah,
that's a good, that's like a good definition.
Yeah, Sasha.
Great points, Regina. So much to say there. It's something that I have experienced with as a
researcher in biology is deciding the kind of the statistics or sampling approach to use,
whether we're taking, you know, one cell from one individual, or we're taking many cells from
many individuals, and how to do the statistics and kind of sampling approach on that. That is a,
you know, an evergreen question that we're always reevaluating to see how to think about the
independencies within biological systems. And then another thing that you mentioned was about
the individual being part of the ecosystem. And that makes me think a lot about complexity
science and something that is addressed there in thinking about the interplay of the scientists
and what they're studying. Yeah, thank you for those points.
Sasha, sorry, I'm not raising my hand. I'm just unmuting. That's okay. Can you say a bit more
about what you mean by complexity science? It is
maybe muted. Oh, can't speak at the moment.
Yeah, complexity science has looked at agent, agent based modeling as a fundamental tool,
John Holland signals and boundaries, focusing on what, from an active inference side, we might say
as like message passing or communication for the messages and then boundaries with the whole
discussion around the boundaries in the world, map territory, map territory fallacy, map territory
fallacy, fallacy, doing iterative modeling. Sasha brought up limited experimental resources in the
scientific setting. And that's kind of analogous to the limited energy budget or attentional
budget, ultimately, or just decision making budget of the kinds of active entities that
make sense to model the ones that kind of have those characteristics. This is really the question
of what makes something first principles or what are the first principles. One aspect of it as brought
up is the censoring of the persistence. So from the outside, that's kind of like an empiricist's
view of persistence, like is it measurable, but not saying that something is necessarily that,
which is the statistical tool. And then the sort of like inside out implementation type.
But there's a lot more to say in that who wants to bring in some new angle or
or how do they see collective behavior? Why do we talk about collective behavior?
Why not just behavior, recognize that behavior is multi scale or is social?
What's really being communicated with the collective?
I mean, I believe that we chose those levels so we can make it more simple for our brains to
understand it. Because if we talk about collective behavior, actually is the universe
behaving in the particles and everything, right? So I don't know if that's a little bit just based
on I don't know what's the word like just in the material world and how it physically moves.
And that's like deterministic or whatever, right? But I think we chose to have those limitations
so we could understand the world. But also we should acknowledge that are limited because we're
part of the system. I'm having a little trouble on my kind of understanding the
I guess where the schism lies between kind of the Markov blanket and the Umwelt in
semiotics of like the animals sensory experience.
Anyone have a maybe maybe someone could I mean, Daniel, do you know
like the difference between that two?
Can you be a little louder? Thank you though. Andrew, anyone have a thought on that?
I'll bring in a definition of Umwelt and then and then we can see. But meanwhile,
does anyone have a thought? Sorry, I was just muted on Zoom. Andrew, you're a little quiet,
but I'm going to bring in a definition of Umwelt and then meanwhile, does anyone have a thought?
I hope I'm not
the diluting Andrews question. But I think of collective behavior in kind of like a,
I don't know, football team or soccer team. And what that provides
is the the group who is
share some common ethos and what that does to the how that regulates the their collective or
individual and collective free energies during a match or throughout the season and how that
that gives some charge to some investment because it's my team against yours. And we have to try
and win. And so, you know, without without that collective behavior, it's it's might be far harder
to achieve groups goals if they aren't able to collaborate and share, you know, implicitly and
explicitly certain traits, behaviors, thoughts, feelings, ideals, ideologies, whatever they might be
and how that then allows us to compete in the world.
I see what you think it's it's been. Yes. Okay. Okay. I see what you're seeing,
especially because we're watching the World Cup, right? Women's World Cup.
Yeah. So it's very relevant. Yeah. But I see that in all the
these things you've said, it seems that for you behavior needs to have like a goal.
And I don't know if I if I agree with that, it's either survival or winning.
But for me, it's just something that happens. And maybe the consequence is surviving.
But it's not the goal to survive or to win the game. I mean, in the football, it is right.
But in general, maybe there's no goal to the behavior collectively.
It's just just a thought. It's interesting.
Yeah, a great comments. Well, the paper of Connor Heinz at all on the collective behavior as
surprise minimization that points the way towards using the act in fontology, these kinds of modeling
approaches for collective behavioral situations, and really just recognizing them as a certain type
of behavioral modeling. The simplest case might just be a single closed system.
All part of the composition that leads to the ability to describe at very least a lot of
different kinds of systems, just like a linear model can describe a lot of systems. So then
it's also really interesting, a topic that came up in one of the recent textbook groups
with what's normative about active inference. Because the term of the process theory, even
of active inference, being normative is mentioned multiple times. And that's definitely a topic
that connects to the social sciences. One can imagine the kind of niche normativity or niche
regularities in a broad sense, and then the real minute particulars of how they play out,
which kind of hints at the kind of descriptive or causal minimum to start making some
anything but toy specific generative models.
So it's been an interesting theme to see even already in Avel's and Ben's lectures and discussions.
This question between description, process of describing, which is what I associated with
Professor Gordon's approach to ant watching, how that descriptive process,
which is what we can say that we have for active inference, just like a linear modeling ecosystem
could say about their linear modeling in principle, and how to then articulate the
normativities of the framework, if that concept, if that separation can even exist
from the behavioral normativities that include the basis of social fabric in all different
kinds of communities.
Here's another question. So what is the role of any technical detail in the social sciences,
whether more on the statistical connecting with data or more category,
theoretic like just formal? What's the role of formal methods in
different kinds of academic or practical expressions about social systems?
Does it matter at all how we think about a framework at all?
Well, for formalizing aspects of a social system, I would say that the purpose is for
communication between individuals, because just we can't verify that.
Well, formalizing is just setting a system on top of what you're observing,
but there is no explicit guarantee that you're saying encompasses everything of the phenomena
you're observing. And just kind of going back to Taoism of the name that can be named is not
the true eternal name. And so it's just a way of, it's a slice of what we can observe,
and the way to, you know, maybe you can make predictions or maybe you can generate something
that acts like the phenomena you're observing, but it's just a way to kind of,
it's just a way to kind of approximate our understanding of some phenomena and you have
to slice it in a specific way, but also understanding that it is a slice or,
you know, it is a tangent line that you're approximating as opposed to
encompassing the whole system from verbalizing it.
I was at, maybe it's not the goal, but something that happened instead of
describing any system, like Andrew said, it's like the goal to modify it or to
or to co-opt it in some way to gain control or whatever. If you know the model,
you know how to play the game, kind of. So you write instructions and try to see if you can
outsmart someone else. I mean, it sounds kind of dark, right? But maybe it's one of the goals to
or something that just happens out of nulling the rules that nobody else's knows.
I mean, I guess when you talk about control, there is a
shade that can be gained from that specific wording, but control in terms of, you know,
control theory or, you know, that comes from electrical engineering. It's really just what
shapes the behavior or what are the inputs that drive the behavior. And when you're talking about
control, it's really just about, well, if you change these inputs, how does that change the
behavior? And so you can actually, you know, from electrical engineering of controlling some sort
of electromechanical system, but then you can make analogous statements on like control into
society, which doesn't necessarily mean like the dark negative control. But like, you know, maybe
there's some pathological behavior in a society or, you know, even pathological
pathological responses within the brain. And it's like, well, what is what is driving that?
And is it possible to change the drivers of that to have something that is more beneficial to the
system? Yeah, just to add to what Andrew's saying, because it matters sometimes how you manipulate
you know, a system or it matters how you affect a brain. So it cannot be random. I mean, you know,
we've come a long way, for example, from lobotomy, which had disastrous effects. And
it matters to a system how you affect it. And so to know more formally, the most effective way
to create a desired effect, whatever that might be, it's essential that it's not just kind of poking
and prodding. As much as that is part of the scientific method to update that method in
accordance with what you're learning. So it is important. No, I think you're both right. I
didn't have to be back. But also something that Andrew said about predicting, I think that's one
of also the big goals, trying to predict whether to be prepared to, or just to, I mean, couldn't be
to control, right? But if you can somehow predict how people respond to this or how a system will
behave in this other scenario, you can, you know, change what input is, or prepare for whatever comes,
I guess. Yeah, a lot of great points. Some of the commonly held, not equally by everyone, everyone,
but some of the tenants of science being to explain predict designing control,
where explanation and prediction are on the pathway towards systems designing and
and maintenance and other other words that people can add. But that's the pragmatic utility oriented
view, which doesn't have to be an absolutist view. But certainly there are regimes of attention
socially, now and seemingly for long, long times, where people were wanting to retain and to
constrain the variance distribution on what we would say is their generative model, some norm,
and then other times, engaging in these functions. And that instrumentalist usage of active inference
is like, we're going to be able to model it with a pretty minimum framework that's commonly used
in statistical systems, where some things we observe and some we don't. And at least we know
and how all the pieces are connected. And then that is an artifact in model based design,
as people develop that line through time socially, just like probably has been always
the case for complex projects and scientific collaboration.
There's a few other interesting pieces, but yeah, please, please.
I'm just, I'm just wondering if now that I'm thinking a lot, isn't that like a problem
for confirmation bias, right? Like, there's a paper in here here, because we create the
knowledge and we tell everyone the knowledge. This is the model, this is how everything behaves.
And then we update our knowledge about it. And then we look for everything to just,
