explain how semantics are built into that computation, right? I don't think anyone has a very
strong answer to that. You have to really buy into the idea of information processing. And that's
something that brought me a little bit to that thing. If you buy into the metaphor of information
processing, then you need to have semantics within the brain. If you try to lose a little bit of
this notion, if you try to understand process and information in different terms, what happens?
I think that was more or less the question that I was trying to ask. And effective inference and
bio semantics can, because they have less assumptions in terms of what happens inside the
processing information content in the mind, if that can bring interesting answers.
Or if you can use as a model to organize behavior. And there's another point that also
brought me to this type of thinking was trying to understand how active inference can include
the historicity of the agent. Because I think that something comes across
debated in active inference, how you bring novelty into the state space. Like once you
define that state space, the state space is more or less deterministic. Because everything will
happen within the specific range. So how does novelty comes within this type of modeling?
So how can you explain that? If it does, I don't know, it's more like, it's more like an
it's it's more like an exploratory question that I was trying to make and see how that
pans out. I don't I actually don't have an answer for that. But
if you take seriously some more inactive claims that you need history of interactions
to understand how agents behave, you cannot understand agents without that. So
how does active inference answer this question specifically?
Right, because once yeah, that's just I think there's a few kind of debated. I'm not sure if
there's new developments in this specific topic. But I remember I think two years ago was like this
specific papers from the Apollo, I think the forking laying down a forking path is specifically
focusing on that in the formalisms and etc. So I don't know if these two things can
bring a little bit of more to the conversation. Maybe not.
This is great. I'll just ask some some more general questions. You're adding a lot with
these thoughts. So you said that social interaction in this account is not reduced to prediction.
So how would you unpack that? And how would you relate this?
I don't know exactly what term of art would go here, but this kind of social epistemology
that active inference provides us in contrast to say predictive processing.
So how is it that that we would or wouldn't reduce something to prediction? And then what
is it that active inference brings into that discussion? Well, I think I have two points
in that active inference in that sense has a type of modeling that tries to include all the time
and everywhere the embodied agent. If you take seriously the idea of the model, the
generative model is always accurately modeling that specific agent. And because it cannot be
true or false that the model is your current state is like that. Even if you are not feeling
really well, you just know that you're not feeling well in relation to something else.
And that that story is still very accurate to your state's condition right now, right?
So the prediction against traction in socially at least in that sense, not in the specific detail
of like predictive predictive processing, I think, because I think that's more complicated,
but socially in social cognition, at least, we can talk about this predictive value,
I think is a more interesting way to do that. Because the model, the example that I use in
terms of catching out symbols, we are using something that was meant to make something
intelligible that have very bad consequences that were not even close to be predicted.
So in that sense, and how these consequences happen, the prediction cannot be there everywhere
and all the time. The prediction in this has an orientation as well, right? So that that's
going to unfold only in terms of the orientation, but that's not all encompassing.
So, well, what does that say about the prediction? That's why I was trying to think of it as not
being primitive, but something that comes along with these dynamics. But yeah.
Well, this is a very deep, impressive point that because the causal structure of the world changes,
historicity, agents change, they learn, and they attend, and then the niche changes with
Stigmergy and niche modifications. So because things really do change through time,
then just training a data set at one time point, and then using that same generative model
and carrying it forward, it's like picking a speed in a direction when you're on a winding road,
and just saying, all right, now let's turn on cruise control right now and just keep going
in this direction. It's working right now. So then to connect that to the legibility of the
forests, as the causal model changed and externalities were not taken into account and so on,
all these different features you brought in. So now is active inference and cognitive modeling,
cognitive technologies increasing our legibility of perception, cognition, and action
through surveillance technology and other mechanisms, such that there could be slash,
we expect there to be also hidden dynamics and externalities that we are also failing to see
when we make some aspects of cognitive systems legible in the way that research in the neurosciences
is happening towards. Yeah, I think in the sense like if you're trying to do that, you cannot have
a know, like in a model, it encompasses everything, right, that would be non-informative. In terms of
for you, when you do that, you have one interested thing, you're interested in something, right?
You have one thing in mind when you're trying to flesh out in terms of cognitive modeling.
So how that applies to these more all-encompassing situations, I think that's like, that that
model is how I'm trying to ask this question. So you can model them in this like a sliced
sense and that's what we do as scientists and that's how we learn about things,
but that only way of seeing that that very specific model does not all-encompassing for
all answers. So how can you use that in comparison to other situations? So how can you integrate
this type of thing? I don't know. I don't have a question and an answer for that. I don't know if
we do have an answer for this type of question currently, but I think it's a very valid question
to ask because also in the terms of sometimes applying that socially,
that sort of ratifies in a way and then it becomes an organizing principle that becomes
somewhat ratified. So keep an eye for this kind of metaphorical use, like assuming a little bit
that all this talk can be metaphorical and it can be interesting and useful to catch them out
in these terms because you don't have other ways to talk about them. So how we don't ratify them
and how they are, you know, because I think I'm having a hard time to get there,
but I think I'm making the point of people criticizing the causal primacy. So when you
reduce these complex systems to one single cause, caching out everything that organizes the principle,
these complex systems and one primal cause, then you are losing the complexity. However,
if you don't do that, how can you slice it out to understand the system? So I think that's the
two tensions here that I'm trying to propose as a question in turn instead of an answer.
I don't know if that makes sense, but thank you. Yeah, I hope people continue that discussion.
I'm going to build on that just to maybe circle around that because it's really important. So
in the forestry case, the realist perspective, again, using retro casting, the way we
or contemporary discussions, some of them in the active inference and free energy principle space
are, the realist says that region of land is just economic potential. It is a natural resource.
That becomes a kind of handle. The instrumentalist perspective takes a step back and says it's as
if that piece of land is a natural resource. So yeah, the territory is indescribable and there's
still a space for mystery. But then when the proxies come out, because policies are being selected,
the as if in some ways carries similar consequences to the actual because they and they may totally
agree and the realists and the instrumentalists might be like, yeah, it is economic potential
or represents or it could be treated as such or it could be engaged with as such like that
cognitive diversity can align on the social policy that then connects to these broader
social questions and histories. And so it's kind of interesting like what work does this
instrumentalism do like, Oh, it's just a principle. What work does it do and what doesn't it do?
And the ways that that science and technical engineering
fields are and aren't deployed alone or together with other considerations.
Yeah, that's very interesting. Like, in the sense that either if you're a realist or instrumentalist
about that, like, if you think like models are not either true or false, they're just models,
right? They might have views and it might, they might be capturing real properties. But
the problem is in this conversation, even when you push them, like have realists and have
instrumentalists try to like lose a little bit as assumptions, they still come, they still end up
refining those principles and taking them to be more or less true or false, right? Well, that's
a plot twist. It's like you're appealing to what surprise minimization as unifying
the diversity responses that the realists and instrumentalists do. So then does that make
surprise or cognitive inertia like the principle where the maze just ends and it explains itself?
Or how does that play in a pluralistic scientific setting?
Yeah, that's the, that's the, you might, you can have a third answer to that, like, right? I have two,
I think the answer that I try to give is more eliminativist in the sense that eliminates the
cause or primacy of them, of these two modes of answering. So when you think, I'm thinking I
have in mind now, like actually just to try to make sense of that, when you, when you think about
biological information, you can think about biological information as being reword, as being
metaphorical or an instrumental. Or you have these guys like Susan O'Yama or Richard Leuhernting,
they try to bring some, they are against this cause or primacy, they try to advocate for
systems that do have that, but they have like a lot of more going on. So that cannot be the only
answer because those systems are not everywhere, scientifically cash. They don't have to be everywhere
that. So for example, going back to the forestry, forestry, so we really is going to say
that territory is value property. And in the sense the instrumental is going to say, look as if,
you know, it can be used as if, but it's not necessarily value property. It doesn't matter.
You can say like, well, this terrain is seen from one perspective as value property,
but it also has other uses around them. So you had to be more inclusive of this diversity.
Because the only organization principle around that specific terrain is not
only to generate value or if it does, this value doesn't have one single output.
It can have more than one output in terms of very specific terms. You can cash it out very
materially. This terrain that has to provide monoculture needs to also, has to provide also
value for the diversity of the fauna and the diversity of the flora around it. And that is
not included in the model because that's not what the model is done for. The model has a specific
use and that's fine. However, that does not reduce the terrain to that. And well, when you're talking
about cognition, that might be more complicated, but I think it's easy. It's an easy way to talk
about this causal primacy when you talk about forestry, because we are very much now experiencing
this climate crisis and we see these things happening right now. And how difficult, because
this type of thinking is built over time and so well fixed in the way we see things and we are
understanding how hard it is to change that. It's a paradigm shift that needs to happen
for that to change. It's not necessarily the model that is right or wrong. It's just how you
understand and apply them. So there are pragmatics into that. It's not only an instrumental, but it
has something that the instrumentalist take does not capture and I don't know how to cash it out
in one single word. But that's what Biosematics was offering. Biosematics was offering the idea of
practice and pragmatics. I don't know if it's the whole story, but it's another point into that story.
A lot of great points all connect that note of pragmatism to a little bit of the active
inference formalism. So when it comes to policy selection, behavior selection,
some but not all cognitive entities can act as if they're calculating expected free energy.
So these are the active, the truly active entities, whether they're simple or whether
they're sophisticated and they do planning, expected free energy is how those agents are
being modeled as if they're making decisions. And it consists of the pragmatic and the epistemic
value. That's how these different policies are evaluated. And so I see two angles or windows
that that supports at least from my non social sciences background, a new kind of meeting in
the middle there. So first is the expansion of pragmatic value under the principle that surprise
minimization or bounding is the imperative. Right there in the pragmatic value, it doesn't
have to be just body temperature or financial income. We can expect and prefer
ourselves to be learning new things or meeting new people. And so we can load into the pragmatism
different goals that under a narrower definition of utility or pragma have not traditionally
be included. So I think that first way is it speaks to a more inclusive concept of utility.
You might say I'm also de risking on forest fires alongside the timber and already you've had you
have now plural pragma. So I think that's the kind of crossover. And then the deeper and second,
and not saying there's only two ways that that the conversation continues, we have epistemic
utility in terms of epistemic value. And so the balance in the waiting between pragmatic value
and epistemic or learning oriented activity overall helps control a dynamic balance with just
like how tight is the grip and the preference overall. And maybe we have some preference
for timber to be exported from a region, but we really don't know, we don't have long term
modeling, we don't have deep causal analysis. And so we're going to put 5% on the pragmatic
extraction and other pragmatic features and leave the rest of the policy in an exploratory mode
and come to a blend that's not just on the spectrum from explore to exploit, which is how
this has been approached in like cognitive sciences previously. It's like this is the third thing
where policies that are on the frontier of exploring and exploiting rise to the top through
their contributions to pragmatic and epistemic value. And we made the model. So that isn't
to say that that is what's happening on the ground, or maybe that's just the instrumentalist perspective.
Yeah, yeah. Yeah, but if it's an instrumentalist perspective, it might be a good one, right?
In the sense, the idea of inclusion is kind of the interesting one, right? Because if you
really find a nation of maximization, because you can use that in certain ways to understand
what happens within when you're modeling something, what is the limit of that maximization. So that's
you can model agents as if maximizing utility, for instance. But maximizing utility is something
that needs to be balanced out with the utility of everyone around them, right?
And that's not that's not trivial how that happens, right? And even if it does,
and even if it were a trivial, it's not something that maps out completely
identically with all every single agent, they don't that's not that there's not going to be
there's going to be diversity there. So how do you make that notion more inclusive and less
refined in that sense? Because then if the more you're refined, the more you single it out into
around only one general type of understanding. So when you think them more individually,
then you kind of lose you lose that strength of this one single principle
organized, like the one single way of catching out utility, that's not the principle like sorry.
So I think that's like speaks a lot with like the type of instrumental use and the type of
pragmatism and how the time the types of application of this practices, right?
Remember, in the sense of the scientific forestry, it's also a practice. It's not
something that is true in itself. It's true in terms of practice, right? In terms of applications,
in terms of building communities around them. So without this use, they have no grounding.
Yeah, one really strong and salient point that I got from the lecture was about generalized
synchrony. And it's almost funny that we have to advocate or delineate generalized synchrony
because the alternative the absence of generalized synchrony is just like kind of like an ideal gas.
It's like there wouldn't be regularities in society. We wouldn't be clustered in space or in time.
We wouldn't have information and communication and we wouldn't have what differentiates
a society or a group or civilization or a colony or whatever from literally anything else.
So generalized synchrony is almost like all of the space between nothing and anything
happening. And then it supports all these different scenarios. We could have
this kind of mind in this kind of brain and this kind of environment and this kind of niche.
And so we can talk about the colony foraging algorithms that work in the desert. And there
might be mutual, non-exhausted, open-ended change of algorithms and what works in a different setting.
And with humans, we have the sophistication and the history and the scope and the scale
