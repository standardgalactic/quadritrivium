that is going up the hill and then entropy is keeping things away from just going up the hill
and keeping this other component in but if um entropy overwhelms the entropy the energy then
the solution will not kind of fit the situation so at first sight variational inference and
predictive processing are solely useful to characterize the average internal state given
blanket states at steady state it is then surprising to see that the free energy says a great deal
about a system's expected trajectories as it relaxes the steady state pretty interesting
so here's how they kind of show that figure five is using that free energy minimizing
framework to look at variational inference and predictive processing so the highlighted part
says the figure illustrates the system's behavior after experiencing a surprising blanket state
so kind of like a perturbation this is a multi-dimensional ornstein obeck ou process
with two external blanket and internal variables initialized at the steady state density conditioned
on an improbable blanket state which was given at the initial time actual distribution of x and b
at time zero and on the left top left quadrant is sort of this um red to blue gradient of free
energy so it's kind of high elevation to low elevation and through time the blanket states
just converge down to the bottom of the bowl so that's the free energy minimization in action
the upper right is the is the free energy over time averaged over multiple trajectories so it
starts out really high and then it kind of rolls down and it converges to this low level at 40 time
points the lower left is showing this uh predictive processing framing of the q distribution versus the
actual distribution and said at steady state from time step about 100 the predictions become accurate
so that's showing how for the estimate of the parameter converges to the accurate
external states under their simulation be cool to do a walkthrough and then on the bottom right
is um looking at the error prediction errors the covariance of so the two co errors
the evolution of precision weighted prediction errors over time these are normally distributed
with zero mean at steady state uh figure six is uh maybe i didn't change not sure exactly
it's a similar figure it has a little bit of differences uh again showing the predictive
processing lock in on a free energy minimizing process showing the average free energy initially
having a slight increase maybe and then just decreasing through time and then also just showing
that the um the relationship of the covariance um was raised up from zero and then started
converging back to zero so just cool figures but cool to see what other people would think about them
in figure four or sorry section four we get to active inference and stochastic control
so they write in order to model agents that interact with their environment we now partition
blanket states into sensory and active states so for active everything that we've talked about
before is like an undirected Bayesian graph um it's not using that frist and blanket separation
so that's where we're going to be bringing in a lot of other uh cool formalisms and ideas so
let's go from that sort of blanket one type of uh fiber in the blanket to two now uh in order to
model agents to interact with their environment we now partition blanket states into sensory and
active states so the blanket state b of t blanket through c is now two subsets of sensory and action
states through time so now that whole tuple the whole set that you need to infer the four kinds
of states are external sense action and internal et a s a u and now that previous example of the
bacillus so here we had just one we had external and internal states mediated by one kind of node
and now the external states are coupled to the sensory states that's s of t and sensory states
are coupled to internal states internal states are coupled to action states and actions connect
back to external states also sense and action are connected to each other but i wonder if that part
is needed or i'm always wondering what topologies of connectedness different functionalities arise from
and uh uh miguel aguilera's paper and recent uh gas stream speak to that so
we take that dynamic marco blanket model from the previous sections and now split the blanket
states into sense and action that was this piece here now then they write intuitively in agents
actions and internal states depend upon its sensations therefore we are interested in
characterizing autonomous i.e. active and internal so we can't control our senses directly but we can
control internal states and active states so those two states we're going to think about that pair
of notes given sensory states so that is the following free energy equation that was brought up
earlier so taking that free energy minimizing perspective on the distribution of mu internal
states and blanket states as a whole b before we introduce the split here then do a similar free
energy equation with three variables on the sensory action and internal states which is
just another way of saying the blanket states and the internal states mu and then etc etc
more details that people can explain if they know better but the results that um
um comes out relates to action so it'd be cool to learn more about what this equation means
but then they write this is known as active inference because expected autonomous states
minimize free energy crucially active inference is a well-known framework to describe and generate
adaptive behavior in neuroscience machine learning and robotics c figure eight so figure eight
is a similar diagram to we had before but now it's an active inference agent rather than just
the free energy minimizer of the previous framing and then they write the figure illustrates a system's
behavior after experiencing a surprising sensory state averaging internal variables for any blanket
state this is an ornstein olbeck process with two external one sensory one active and two internal
variables initialized at steady state density conditioned upon improbable sensory state
and um also one pattern that they found was that the free energy minimization here it's
relatively monotonic it kind of doesn't ever bump back up it just goes down or stays the same
but then it was kind of interesting they said we plot the free energy of the expected internal
state averaged over multiple trajectories so this is not just one aberrant run in this example
or maybe this is just one example but they wrote the average free energy does not decrease
monotonically c figure five for an explanation and then um maybe we can learn more about that
but that was kind of cool okay they continue on and write that any mean stationary mean zero
stationary Gaussian process with exponentially decaying autocovariance function so it resembles
itself less and less through time is an ornstein olbeck process which is kind of cool because in
phylogenetics we sometimes would use this for let's just say the average femur length of some
mammal and then you would be inferring a model that had an average value so it was kind of like a
peg and then like a tether so it was like a diffusion term and then a mean so just a mean
in a variance that drift through time is like the ornstein olbeck or the o u process sometimes
is known as dubbs theorem so those kinds of processes which are apparently general enough
to be really good model systems for studying math i guess thus if c equals the finite sum of exponentially
decaying functions we can express s of t the states sensory states as a linear function
of several nested o u processes i.e. an integrator chain from control theory
so the integrator chain was kind of a cool idea and we'll talk about maybe applications of
integrator chain in a few slides but just to continue with the math that they have so there's
this s of t states through time sensory states is going to be this f function and then there's these
um d these these kind of similar d equations so it says in this example f and f sub i are
suitably chosen linear functions not sure what the pronunciation is but the swivel r matrices
and w are standard Brownian motion thus we can see sensory states through time s t as the output
of a continuous time of hidden markov model whose hidden states s of t superscript i
encode various orders of motion position velocity jerk etc these are known as generalized coordinates
of motion in the bayesian filtering literature which will look at graphically in figure nine
and more generally the state process s of t in a function f need not be linear which enables to
realize non-linear non-gaussian processes s of t technically this follows as ornstein-olbeck
processes are the only stationary gaussian markov processes yet we emphasize that stochastic
realization is not as well developed in the general case so this is um in a way saying that
we're going to have like the position of the ball is the sensory data that's like the first pass
of where the ball is that's the measurement that's the sensory data then there's the variance
and then there's the second derivative of that statistical moment and so if the variance is
equal through time then you can just integrate away and the higher levels are zero and you've
kind of locked on to the pattern after just one or two levels but there's other distributions
where as you go to higher and higher distribution uh uh derivatives higher moments there's just
more or different information so there's this concept of the integrator chain where these
relationships of equations are all integrals or derivatives of each other which are kind of like
the going up or down in this rows of equations and then this helps use gaussian type mathematics
like the o u stochastic process where a lot of the math is clean it allows you to apply
these um systems of equations of well-behaved types o u to model highly non-linear system so
this was related to some interesting discussions um uh avil i'll look forward to hearing what you
have to say about these um so-called generalized coordinates of motion
and that relationship between control theory and then looking at non-linear functions as
relationships of integrals and derivatives leads to this discussion of the PID control
so proportional integral derivative control PID is a well-known control method in engineering
more than 90 of controllers in engineering systems implement either PID or PI no derivative
like just proportional integral control the goal of PID control is to control a signal s sub t
it's integral s sub t with a zero instead of a one and its derivative s sub t with a two
close to a pre-specified target value so it's like i want 95 battery and i want it to be
a rectangle at 95 percent and its derivative to be such and such during use this turns out to be
exactly what happens when we take stochastic control of an integrator chain with two with
three orders of motion so that's just a three-level model in this sort of infinite rows of the
moments of the distribution the three levels are just what are described here the signal the
integral and the derivative um when f is linear expected autonomous states control to what extent
integral proportional and derivative processes s of t at zero one and two levels of um derivative
are from their target value of zero so it's like if it's a linear response function then the first
derivative is going to be a constant value as in the second derivative you get rid of it
furthermore from f and k alone one can derive integral proportional derivative gains which
penalize deviations of these three moments respectively from the target value of zero
so these are highly optimizable problems and computable crucially these control gains
are simple byproducts of the steady state density and the stochastic realization problems
this is a cool question why restrict ourselves to pid control when stochastic control of
integrator chains is available it turns out that when sensory states s of t are expressed as a
function of an integrator chain one to get away with controlling an approximation of the true
sensory process obtained by truncating high orders of motion as these have less effect
on the dynamics though knowing when this is warranted is a problem in approximation theory so
how um let's just say we open the door to doing infinite derivatives of statistical distributions
infinite variances upon variances how would we know when to stop that's the problem in approximation
theory or approximation science this may explain why integral feedback control which is just like
battery good p i control n equals one and then the pid control with the two extra layers of the
derivatives are the most ubiquitous control methods in engineering applications however when
simulating biological biological control usually with highly nonlinear systems it is not uncommon
to consider generalized motion to fourth or sixth order so that's pretty cool um like how many levels
of recursion and depth in modeling are needed to have a people so calling back to here when we
defined that initial sense function as part of this integrator chain setting off the integrator
chain here's that initial sense function as part of a broader set of dependencies so here is that
sense function at time three six and nine the figure is depicting in a graphical format
the Bayesian network of those equations flipped the encircled variables are random variables
and the processes are indexed at an arbitrary sub an arbitrary arbitrary sequence of subsequent
times the arrows represent relationships of causality so the sensory states are not causing
each other through time they're getting measured through time but they are being emitted through
time by this s at the zeroeth level like the just the base generative model of this s of zero level
function so this is the generative process then that can have higher derivatives of change and each
of those are being framed as well behaved statistically so in the hidden markup model and
these white nodes are hidden states but they're inferred by statistics the hidden integrator
state hidden state processes s at is given by an integrator chain i.e. nested stochastic differential
equations these processes can be seen as encoding the position velocity jerk etc so higher derivatives
of the distribution so this integrator chain is kind of a cool idea but here was one paper
stabilization of integrator chains in the presence of magnitude and rate saturations
against scheduling approach so this paper wrote and the conclusions in this paper we have given
a time varying controller so kind of like a heuristic or an algorithm for control
for stabilizing a chain of integrators in the presence of magnitude and rate saturations
it is proved that the controller gives a convergent closed loop system i.e. for any bounded state
initial or state initial condition the state will converge to the origin the main strength of the
controller is that it gives provable convergence without being overly conservative this is verified
in a simulation study so it's kind of like we have the the frame of the airplane at steady state
and then which is flying through the air so how are we going to re-equilibrate all the sensors
so that if we get knocked off the side what's the path by which we're going to get those
sensors back to their desired level and it's just a question i oh and this is kind of what it looked
like one of the figures from the paper so these are these derivative functions they get get like
bumped and then they come come back to the level that they're desired almost in this signal processing
like way so what are integrator chains how are they used maybe someone has used them before that'd
be cool and then one kind of random thought was there's a lot of cases where we frame a process
as mean zero because it allows thinking about something in relationship to a defined axis
whether it's the number line or whether it's some other variable it kind of splits half the
things negative and positive or there's various other times but there's actually a bunch of places
and maybe more or maybe these are not all the same so it's okay if somebody knows more and
helps us all out but there's actually a few cases where a distribution that's hard to estimate is
replaced with a zero mean like sometimes there's replacing elements of a list with a z-square
like their standard deviation from the mean or the mode um but then it's like half or above
and half or below so that's like replacing something with a zero centered z-square or t
distribution sometimes there are error distributions which are extracted from a signal it's like a
signal is the underlying line and the goal of the signal extraction is to leave your error
distribution mean zero and then equally distributed in both directions so sometimes
we're pulling out an error distribution sometimes we're trying to find uh that mean zero get to a
level of derivative of a signal where the mean is zero like where the rate of change of some
high derivative is zero which implies that it's not changing at that level and then sometimes
we're trying to get like in predictive processing study the differentiable or predictive processing
with trying to get a zero centered variance on the sensory input but more about how we can study
the differential between some controllable distribution and then some other distribution
that we can't control and then how to make how to zero center that to determine which
solutions are better or worse than each other and there's a lot of different methods there
and then there was this other paper time optimal regulation of a chain of integrators
with saturated input and internal plant variables an application to trajectory planning
so again just kind of a open question what is the relationship between integrator chains
this idea that we talk about a lot with action planning as inference
then the conclusion this paper outlines some of the key relationships between stationary
processes inference and control these relationships rest upon partitioning the world into those
things that are internal or external to a statistical boundary known as a marco blanket
when equipped with dynamics the expected internal states appear to engage in variational inference
while the expected active states appear to be performing active inference in various forms of
stochastic control the rationale behind these findings is rather simple if a marco blanket
derives from a steady state density the states the system will look as if they are responding
adaptively to external perturbations in order to recover the steady state conversely well known
