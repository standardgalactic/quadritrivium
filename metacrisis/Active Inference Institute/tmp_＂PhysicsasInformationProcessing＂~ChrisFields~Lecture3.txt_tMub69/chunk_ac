than it has to use to modify the states of other bits? That's what this,
if you will, metabolic question is all about. In the case of an organism, is it,
can I get more energy from some of the chemistry that I have access to
than I need to use to modify the chemistry that I need to modify? And if not, then life stops,
right? Everything grinds to a halt.
Now, can the heat exhaust
informationally be useful for another agent somehow? I mean, can't we recover heat in
a steam engine and use it to do useful work? Not to the point of a perpetual motion machine,
but how can we recover exhaust and then what does the perpetual motion machine look like?
Well, the environment is the system sitting over on the other side of the boundary.
That is absorbing whatever waste heat is generated by the system. Let's call it Alice,
that we're interested in. So that environment may be, and Alice can't tell this,
it may be divided up into lots of different compartments, some of which are basically sucking
in Alice's waste heat and doing something with it. So this is really a question about
how is the environment structured and what operations does the environment execute
with the input that it gets? How does it interpret that input?
And what would a... So this gets back to this question about
how do we talk about multiple agents that are communicating with each other,
right? Instead of talking about an environment that we don't characterize at all,
how do we talk about an environment that includes some specified or preferred systems
that are treated as or known to be other agents? So let me get back to your question about
perpetual motion machine. Notice that in classical thermodynamics, there's always
the assumption that there's a big environment out there, the rest of the universe or whatever,
the whole environment that's not on earth, that is an arbitrarily large source of, or
it's not an arbitrarily large source of free energy, but it's a large source of free energy,
and it's a large sink for entropy, a kind of arbitrarily large sink for entropy.
So the second law of thermodynamics says the entropy of this entire system,
counting the whole surrounding environment, doesn't decrease. So it can increase
and still satisfy the second law. So this gives you the classical 19th century heat death of the
universe idea, and so your proposed machine is sitting somewhere embedded in this gigantic
environment that can provide some finite amount of free energy but can exhaust effectively an
arbitrary amount of entropy. So any machine has to dissipate entropy as it runs to fill up this
kind of arbitrary sink of entropy that's the classical rest of the universe. Now compare that
to the picture in quantum theory. The picture in quantum theory is the universe by definition
is an isolated system. So its total information content doesn't change,
right? It's evolving unitary operations preserve information, so they're just moving information
around. So from the point of view of any local system, the local system's getting information
from its environment, so it sees its environment losing information, so gaining entropy.
What this tells us is that entropy is in fact not a globally definable quantity.
Entropy is always defined relative to some observer, some division, some boundary.
And this is another kind of big change in the last few decades and has led to,
for example, in tropic definitions of time. Now my local external time arrow is whatever direction
I see entropy increasing the most. So again, I would refer to people like Revelli
and Max Taymark who developed many of these ideas. Awesome. All right. Thank you, Chris and
Ander. Looking forward to seeing everyone's questions submitted and their preparation
and participation and measurements in the discussion section. So thank you. Till next time.
All right. Thanks again, Daniel. Thank you, Ander. We'll see you later. Bye.
