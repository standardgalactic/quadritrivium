one to store information about the states of those objects. So this requires much more metabolism.
And again, the solution is core screen. Typically what we core screen is our memory
of the object that we've identified. So what does this do to systems?
Because making measurements costs energy and recording memories costs energy,
we have to make decisions about what QRFs to use at what time, given our finite energy budgets.
We can't look at the world with all of our measurement capabilities at the same time,
because it's too expensive. And now we see the effect of a theorem in quantum information theory,
which is that if two QRFs can't be deployed simultaneously, for whatever reason,
that corresponds to them not commuting as operators. And if they don't commute as operators,
they have to be implemented by compartments that are sufferable. So compartments that only
communicate classically. The consequence of this theorem is that as soon as one has
too many sensory and motor capabilities to run all at the same time, given your energy budget,
you end up being compartmentalized into compartments that only communicate classically.
So you end up looking like this diagram, where there are a bunch of components that do
sensory motor loops or memory, one or the other, and they can only communicate classically,
and they're controlled by some sort of attention system that selects which ones to activate,
depending on the amount of free energy that's available. And clearly this clock function
becomes part of this control system. So the physics alone of any system that's acting as a fair,
that executes a fairly complicated interaction with its environment, gives us this hierarchical
compartmentalized structure without having to add any biological or cognitive science type assumptions
at all. So we can go in three directions from this. We can go deeper into the biology, which we're
going to do in October. We can go deeper into the physics, which we're going to do in August and
September. And we can go deeper into this issue of alignment, which is what we're going to do today.
So there are four possibilities. If you think about two agents that have QRFs that are interacting
with across this boundary. And the first one is trivial. If the B agent, the agent on the right
side doesn't actually employ any QRFs, if it just interacts with the boundary thermally,
then there is no alignment. You're in a trivial situation where A can measure something about B,
but not in return. If the B agent deploys a QRF that's much broader in scope than the A agent,
what we show here in panel B, then the A agent can learn something about the B agent,
but misses most of what the B agent is doing. In panel C, we have agents with
QRFs of the same size on the boundary, but they're not lined up correctly. So each one
misses part of what the other is doing. And finally, in D, we have the optimal situation
where they have QRFs of the same size and they're actually lined up. So each sees what the other
is doing, at least on this sector of the boundary. And since the agents have to allocate some of
the boundary to free energy supply and can't look at that part, then they can't tell what's
happening across their entire boundaries. They can only tell what's happening in this sector
or whether they can actually deploy a QRF. But let's now look at this interesting
situation, situation D, where the QRFs are aligned between A and B.
As I said, that's the optimal channel for A and B. And if we think about this, we can write
the variational free energy or the uncertainty or the prediction error for A, for the QRFX,
as the action that it sees, i.e. B's action, the difference between that and what it expects B to
do, so what it can predict about B's action. And this is just the notion of free energy
from the free energy principle, except translated into the situation where we have two QRFs and
A can measure what's B has done, but it can also use its QRF to predict
because it's predicting the very state that it's going to observe next of the same sector that
B is using. Now, if we look at this diagram, we can see easily that the way to minimize the
variational free energy and therefore maximize predictive capability is for these two QRFs
to actually be the same. So if A is doing the same thing to the boundary that B is,
A can predict B's next action perfectly because it's B is going to do whatever A is doing.
So what the free energy principle tells us in this case is that A and B,
as they minimize their variational free energies, will approach having identical QRFs.
Well, again, we have a theorem that tells us that if these QRFs are shared, A and B are not
separable but entangled, and this is also fairly easy to see because it depends on this notion of
non-fungibility. If X, A and X, B both encode non-fungible information, which is quantum systems
they do, their states aren't cloneable, so they can't be copies of each other because one can't
clone an unknown system. So they can only be identical if they're actually identical systems.
Oh, this is exactly the same point made earlier about Alice having to actually send her QRF
to Bob if she wants Bob to use her QRF. So minimizing VFE for quantum systems is becoming
entangled. So the classical free energy principle, which tells us to minimize VFE,
actually drives quantum systems toward entanglement. And that's why it's a special case, the principle
of uniterity, which just says that any isolated joint system is going to asymptotically approach
entanglement. So this raises an obvious question, which is why all of us aren't entangled with our
environments all the time and entangled with each other. And the answer is that entanglement
is really hard for complex systems. And this illustrates the sense in which the FEP is moving
systems in two different directions at once. The FEP is driving systems to maintain their
separability, but it's also driving systems toward entanglement. And as the system becomes
more and more complex, the difference between those two outcomes becomes larger and larger.
So recall from last time that the condition for separability is that the two systems have
dimensions that are much larger than the dimension of their boundary. And this is the condition that
allows them to have internal states, to have them have states that aren't located on their boundaries.
And clearly to formulate the free energy principle, you have to have internal states.
So if you're a complex QRF that's in a lot of computation, then you need a lot of internal
degrees of freedom to implement that computation. So you need a lot of internal state. So you have
to have large dimensions. So complexity favors separability. As the system becomes more complex,
it has to have more internal states. So it has to be in a sense more separable from whatever it's
interacting with. Now think about this classically. If you have a complex system that's doing a lot
of computation, then it requires a lot of free energy. And it has to dissipate a lot of entropy
in the form of heat, typically. But something, some form of energy transfer that its environment
is going to see as noise, as not informative. So a complex system is working very hard to
predict its environment's next state. But by working very hard, it's dumping a lot of entropy
into its environment. And putting in that extra entropy makes the environment's behavior even
harder to predict. So the more you work at predicting what the environment is going to do,
the more you yourself make the environment's behavior less predictable. And this is the
the paradox of the FEP, which is not really a paradox. It's just what the physics does.
So we can think of the FEP by driving systems to increase their distinctness from their
environments, or to self-evidence, as Carl Friston calls it. As driving this increased
complexity, that both makes predictions better and makes predictions harder by transferring
entropy into the environment. So what this tells us is that the FEP by itself will drive the
development of systems with larger and larger complexity. And this clearly has enormous
implications for evolutionary theory, which we'll talk about in October.
But I want to emphasize here that this is just the physics. It's just what the FEP does
when it's forced to maintain a boundary. And before stopping here, I want to consider one
aspect of this in particular, which is language. For example, human language, but
any kind of language connecting any systems that are communicating with QRFs that are fairly close.
And language is a complex QRF that we basically share. Otherwise, things like this interaction
would be impossible. But we also remain distinct systems. So the question arises,
how do we manage to do this? How do we manage to largely share a QRF while escaping becoming entangled?
And this is a question that's largely been ignored in physics because physicists have
tended to ignore language and just assume that observers can communicate classically.
So for example, in talking about a Bell EPR experiment, which is the canonical experiment
for measuring entanglement, the observers have to be able to share their results,
or they can't observe entanglement. The observed result is a bunch of observational
statistics that violate Bell's inequality. And those statistics can only be computed,
given the results that both of the observers obtained. So the observers have to share a
language to encode these results. So how come the observers aren't entangled? How come there are
still separable? What we end up appealing to is some sort of common cause in the past to explain
why they share a language. They both learned it from their culture. So their culture is some
sort of common cause. But all such assumptions are fine-tuning assumptions. So they all have
basically the status of the value of something like the fine structure constant without which
we wouldn't have atoms. And so we wouldn't have us. This value has to be within very small
limits of the value we actually observe. And that's a case of fine-tuning. The universe seems
fine-tuned in a way that allows us to exist. And if it wasn't fine-tuned in that way,
we wouldn't exist. And so we wouldn't observe anything. But fine-tuning assumptions are a
problem. They're a pointer to something we don't understand. And so I just want to leave you with
the point that we have to be very careful when talking about interacting observers. So in talking
about two components of some system that jointly interact with some environment but also communicate
classically. And if you think back a few slides, that's exactly the structure that we've shown
that the physics forces any complicated system to have. So next time what we're going to focus
on is this very question of how we describe observers that are both interacting with the
quantum system and communicating classically in some language. So that session will be in
August. At the end of this month, there's a discussion of this session with Andrew,
and I encourage you all to use the interactive Q&A to ask questions. You've been asking very
good questions that I hope I've been managing to answer. So thank you very much. And Daniel, over to
you. Well, we have a few minutes for some questions. Maybe, Andrew, if you want to
bring up any questions first. I'll unmute and then go for it.
I was curious if you could say any words on the slide where you had all the possible
alignments of KRFs and what you meant more by interacting thermally. So when you have a trivial
agent on one side, what exactly does it mean to say that you're interacting thermally?
If you think about a system that is only interacting thermally with its environment,
you end up thinking classically about, for example, an ideal gas that's in some sort of
container. And some of the molecules are very near the surface, and their motions depend on the
motions of all the other molecules that are inside. So there's a set of internal states
that interact randomly with the external states that are near the boundary. And so those external
states interact randomly with the boundary. But notice in thinking in this way, you've imposed
a space time embedded. So you've actually used space as a way of separating the internal states
from the boundary states. And a system that, if you drop this assumption of a spatial boundary,
then a system that's only interacting thermally with its environment is going to look like a system
that doesn't have any real internal states. It's going to look like a system that just has boundary
states. And so a pure thermal interaction is going to start to look like entanglement.
So we're actually only really interested in systems that aren't interacting only purely
thermally with their environments. We're interested in systems that have enough internal structure
that they're using that thermal energy to do something internally. So to give their internal
dynamics some particular shape so that their internal dynamics is actually circling around
some well-defined attractor that requires some energy to maintain itself.
Yeah, I'm continuing with that question. I saw in the paper, free energy principle for quantum
systems, that if you're in that situation, when both keras are non-trivial, but perhaps
B is larger than A, A perceives non-local hidden variables. So I wonder if there is a way to
relate those by taking a limit of making A small and recover the thermal interaction.
Presumably, if you let A become small, you should recover that thermal interaction,
so to speak, right? Yeah, that's a very interesting comment,
actually. So if your system and all of your environment's variables are effectively hidden
to you, then you can't do any information processing because you don't have any access
to any of your system, your environment's variables. So yeah, your interaction can only
be thermal. I think that's correct. Thank you.
I guess, yeah, go for it. Since we're in this topic and we don't have to
context-switch in that way, on the other hand, you have noise, right? In one of those other
situations, I can't recall which one. I guess in the reversed one, right? When A is QRF,
is larger than that of B, so it encompasses more of the boundary, decrease of freedom,
those that are not overlapping, A perceives as noise. Is that correct, right?
Yeah, A will be looking at B's thermal sector, B's free energy sector.
Right. So A may be interpreting, in a sense, what it's doing as informative,
and A may even be seeing what B is doing as informative. So noise for B may be signal for A,
depending on what, how A's QRF is structured. But A is seeing more information than B is trying
to send it. So it's essentially the reverse of the hidden variable case. There are variables
in the other system that aren't telling you anything about what the other system is actually doing.
That's very interesting in terms of reading too much or too little between the lines,
connecting too many dots or connecting not enough dots. But these challenges where noise for one
quantum cognitive agent might be signal for another and vice versa, those are the challenges
that we want to address because to have a physics that doesn't recognize those situations
is kind of taking the view from nowhere or not really addressing the complexity of a cognitive
engagement. Yeah, it's describing interactions between effectively systems that don't share the
same language. I have a question about the free energy principle here. Only in the last several
years has the quantum free energy principle relationship come into light. So maybe could
you just share a little bit about what incremental or quantum advances enabled that to happen,
or what degrees of freedom were pre-existing or added to enable work arising from perception
and action in neural systems to also so naturally enter this context with the quantum information?
Well, I think at least from a historical point of view, that connection was made based on the
analogy between a Markov blanket and a holographic screen. So these are structures developed in
different parts of physics that essentially serve the same function of limiting the information
that one system can have about another system. So it's that functional analogy
between a Markov blanket defined classically and a holographic screen defined in quantum theory
that made it seem obvious that we could translate the free energy principle into a quantum
theoretic principle. Yes, in live stream 40, we talked a lot about this, but I think that
remains one of the most remarkable advances inside or outside the free energy principle literature
based upon this functional acknowledgement of boundaries and the conditions that they entail,
which again are the challenges that we want to address, lest we ignore boundaries.
Right. Yeah, precisely. I mean, the free energy principle is all about what happens when you have a boundary.
The waste heat.
Is this the actual thermal exhaust from our CPU? Or how can we think about the heat
being released topologically rather than geometrically like the location where it's released?
What does it mean to consider physical processes topologically that we might otherwise just use
a geometric way of thinking about? Well, you basically put your finger on it and that you
are not worried about the spatial difference between the geometric spatial difference between
where one kind of information flows through the boundary and where another kind of information
flows through the boundary. And you can think about this in Markov blanket terms.
In the Markov blanket is just a network and some of the causal arrows flowing through that blanket
network are effectively transmitting noise. And you can think of it in the same way with
respect to a holographic screen. If you're doing a certain amount of information processing,
and this brings up the whole issue of how efficient is a system in its information processing,
how close is it to the land hour limit, basically? Can it extract more energy from some bits
