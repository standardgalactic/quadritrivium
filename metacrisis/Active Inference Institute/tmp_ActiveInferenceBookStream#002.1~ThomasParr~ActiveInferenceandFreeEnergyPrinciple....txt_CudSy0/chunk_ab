Just generally speaking with applications, what applications are developed or possible today
that when you were starting your PhD seemed like they were just implausible?
So I think if we go back a bit, I suppose some of the earlier implementations were
almost all in the continuous domain. So they're all based upon
things like these generalized filtering type algorithms that
were initially developed as sort of filtering methods to perform time series inference.
Those things then equipped with an active component then became some of the earlier
active inference type simulations. And a lot of that focused on things in the movement domain,
whether that be eye movements or control of limbs to the extent that you can sort of
develop handwriting and those sorts of things. One of the interesting things that started to
happen based upon that was to think about how you then get something that looks more sequential
emerged from those continuous dynamics. And handwriting was actually a really good example
of that, where there were some simulations developed in which the continuous model
effectively had something a bit like a Lotka-Volterra dynamic in it. The idea there being that you
can sort of... So Lotka-Volterra dynamics are a kind of dynamical system often used for modeling
things like predator-prey interruptions. And the idea is that you get a peak in terms of a predator
population, sorry, prey population, followed by a peak in the prey, the predators as they eat the
prey causing drop in the prey population. But then as the predators die out, the prey come back and
you get this sort of sequence of peaks from predator-prey, predator-prey. You can generalize
that to then have multiple different populations, each preying on one another. So you get this
sequence of peaks over time. And that sort of emergence of sequences from continuous dynamics
I think was one of the key moves early on in terms of thinking about things through a bit more
cognitive in terms of how do I do this and then this and this and start to plan and generate
much more purposeful type of behavior. So that went so far until things moved much more to a
an explicitly discrete or sequential style of modeling. That's when things like Markov decision
processes started to the employed in the active inference domain or partially observed Markov
decision processes. So those are models that say, I assume my world is a sequence of states over
time one after another, each of which generates some observations. And from those observations,
I can make inferences about the states. You can then say, well, if I can act upon the world,
I can change the sequence of states as they evolve over time. And by selecting different
actions or different ways I can change that sequence, I'm effectively planning and making
decisions. So that's again where you get into a much more cognitive sort of domain.
Some of the key advances sort of early on while I was doing my PhD were the emergence of things
like deep hierarchical models of things like Markov decision processes. So here the idea was
that in the world around us, there are lots of things that evolve over different sorts of time
scales. And so one of the early examples of this was reading the idea that when you move your eyes
around the page, you're sort of looking at an individual word or the letters within that word,
but that word is itself part of a sentence. And the time it takes you to infer what the word is,
is going to be much shorter than the time it takes you to work out what's going on in terms of the
sentence and the sentence and the paragraph and the paragraph on the page and the page and the
book and etc. And so there's a whole hierarchy of different time scales in the world around us.
And one way of accounting for that relatively simply in these sorts of models is to simply
stack them on top of one another. So the outcomes you're now predicting from one of the Markov
decision process type models I was describing now reflects a sequence of very fast states.
And each of those states, yes, exactly is the graphic of this. And then each of those
outcomes predicts another sequence of very fast states. So what you're left with is at the very
top level, a very slow progression of state after state after state. But each of those states
which might be the sentence, you then have the words in that sentence beneath it. And then for
each of those words, you might have each of the letters in that sentence, oh sorry, each of the
letters in that word. And so that then sort of expanded the range of things that we can do in
terms of how we give some sort of deep temporal structure into the kinds of models we develop.
Sometimes people refer to that as kind of breaking the Markov property. So for those who
aren't familiar with this, the Markov property is the idea that each step in time depends only
upon the step immediately previous to it. That all you need to know about the next time step is
what's happening in the current time step. Nothing else in the past is useful once you know that.
And people often suggest that means that these processes are effectively memoryless because
it's only where I am now that matters. It's not what was happening well into the past.
By having a hierarchical structure where you have a higher level state that is more slowly
changing, that's contextualizing what's going on at the lower level, it means that the fast
sequence of changes is actually dependent upon something much slower that's happening. And that
itself is dependent upon something much slower and that gives you a sort of memory. It allows for
the Markov property to be broken. So like I said, we're sort of starting off with continuous,
the emergence of discrete from continuous, the explicit modeling of continuous models,
decision making, and the sort of exploration, exploitation type trade-offs that you get once
you treat planning as being in this process. The idea that you can then stack these things
hierarchically and have a range of different timescales that break the Markov process allow
us to think about things like memory and working memory. And I suppose one of the next stages was
the combination or the reintroduction of the continuous models as the lowest level of one
of these hierarchies. The idea that actually it's all very well being in to make decisions,
but at some stage you need to implement those decisions in a world that's made up of physics and
muscle lengths and continuous sensory inputs. And so putting these sort of hybrid models together
where you can use your decisions to then predict short sequences and trajectories
to find in a continuous domain. And I suppose since then there have been a range of further
developments in active inference in that setting and a range of developments
in a number of other directions and sort of in parallel. So some of those developments have been
thinking about implementation in other languages. Some of those developments have been thinking
about combination with methods from deep learning and the introduction of variational autoencoders
and function approximators and amortized inference, which a lot of people in the robotics community
have been pioneering particularly. And so that would be one direction that things
have been developed in. And I suppose the other direction that's seen a lot of development recently
has been the sort of underlying principles, the physics that underwrites active inference,
the principles and how you justify the sort of dynamics and where free energy comes from as a
concept and why it's useful in understanding how systems behave. So I hope that wasn't too much
all at once, but there was a sort of run through of some of the developments that spring to mind
over the last few years. Awesome. Perry or Ali, any comments on that? Quick historical review.
Again, yeah, I had another question regarding. Actually, it's a question out of mere curiosity.
Did you have any specific reason for adopting this particular mathematical notation throughout
the book? Because it seems like it somewhat diverges from the notations used in some of the
well-known papers in the literature. And I know active inference notation is not
consistently used across the literature, but even in the papers that came up after the publication
of this book, written by Professor Friston or others, I don't see this specific notation used
a lot in those papers. So I just wanted to ask about the reasons behind this choice.
Okay, I mean, I think you're absolutely right to say that it's not always been used consistently.
And it's worth saying that in some, there are a couple of different tensions that affect this.
So one is the idea that in a lot of papers that are published, because it's only dealing with an
aspect of active inference and not trying to try to put it all together, they can sort of use a
notation that may be the same as a notation you might use in another field without worry that
people will get conflicted and misinterpret one variable for another because everything's just
defined within that one domain. Another aspect to it is that in, depending upon the paper in
question and the audience is aimed at, sometimes the notation is designed to match what might be
used in that broader field. Whereas we've tried to try to make it as consistent as possible across
different fields. Are there any particular notations that you were thinking of or
would like to help clarify? Yes, so for example, as just a very simple example,
using eta for external states instead of x that's been used or s and a for active states and
sensory states or other kinds of uses of lowercase matrices and uppercase matrices,
which is used differently in a paper such as a step-by-step tutorial on active inference
and these kinds of rotational divergences. Okay, so yes, I mean there's some quite nice
illustrations. So things like a and s, which as you say are often used in some of the more
physics-orientated papers. Unfortunately, if you use those in a Markov decision process paper,
people will interpret those as being states and parameters of a likelihood matrix.
So unfortunately, we couldn't use those same letters without causing more confusion. So
what we try to do there is to focus more on the sort of practical inference side of things of,
you know, the actual implementations we tend to use of active inference in particular problem
settings. And there when you're constructing a generative model, particularly if it's in the
continuous domain, we'll often use x as being the states that I have to infer, which from the
perspective of the physics type papers are the external states, the things that are having an
effect on my sensory states. I can't remember whether we used y or o for the sensory states
or the data in the book. I think it's y. I think it's y, okay. And that sort of fits with the idea
of using it in the continuous domain, where in a lot of settings when you're trying to predict
sensory data, often y will end up being the variable that we end up using.
So I appreciate that it can be confusing, sort of jumping between different resources.
But what we strove for in this one was internal consistency as much as we could,
and trying not to overload specific variables or symbols. Thank you. Thanks.
Bigger 4.3, we bound ourself coming back to again and again. It for sages chapters seven and eight.
And it lays out discrete time on top and continuous time on the bottom in terms of their
structural similarities, but also they have some really important differences.
So could you just, as you see it, how do the discrete time and the continuous time models
have similarities and differences such that you can lay them out in a graphically or visually
similar way? Yet there's also some key differences, for example, in what each of the nodes mean. So
how are they similar and different? And what did you hope to illustrate by laying out figure 4.3
this way? So the reason that they can be seen as similar is that effectively what you're trying
to do in both cases is to represent a trajectory. We're trying to represent how something evolves
in time. And that something may be the states s in the discrete time, or they may be the
trajectory of some hidden states x in the continuous domain. And when you're trying to say
how do I actually put together a set of numbers that tell me how something's evolved or evolving,
there are a couple of different ways you can do that. One is to say I'm going to tell you where
it is at time one, and then I'm going to tell you where it is at time two, and then at time three,
et cetera, et cetera. And that's a perfectly legitimate and perfectly reasonable way of
writing down a trajectory. It obviously misses out all the times between time one and time two,
which may or may not be significant, depending upon what the problem is you're dealing with.
The second way that we approach it is to say, well, you can use what's known as a Taylor series
approximation or a Taylor series or a polynomial expression for that trajectory. So essentially
what we're saying there is that you just construct a function that follows the shape of that trajectory
of the time. And you can construct that function by saying, well, let's look at where I am now
at this point in time and my position. How am I changing over time? If you just took those two
variables together, you just have a straight line telling you where you are and where you're going
to be. If you then take account of your acceleration, you may even have a curve line which says, I'm
here now, I'm going to be there then. And as you add in more and more elements to this, so the rate
of change of the velocity and the rate of change of the rate of change of the velocity, et cetera,
and just add in more and more rates of change, you effectively get a more and more precise
function telling you, at least locally around where you are now, where you're going to be
at various other times. So that difference, either using Taylor series coefficients, which are just
successive rates of change, or by using a sequence of states over time, are what's illustrated in
the lower and upper graphics here, respectively. Each of those things has, as you said, they have a
lot in common in terms of their structure, in terms of the number of numbers you need to be able to
describe them. But each has their advantages and disadvantages, depending upon what you're trying
to actually model. And I think, for me, I tend to think of the sequence of categorical states over
time as being quite useful in thinking about anything to do with decision making, deciding
between alternatives, thinking about sequences like language and words, and
even sequences in terms of the eye movement you make, looking in one place, then the next,
then the next, rather than continuously moving your eyes around space in a smooth fashion.
Whereas the process of interpreting sensory data that's coming in from your retinor or from your
stretcher structures or whatever else, or in terms of actually driving action that changes
continuous variables in the world, there, I think, is much more useful to be able to describe
things in terms of a continuous number and those sorts of continuous trajectories that you can
get through using these Taylor series type approximations, which are often referred to in
this context as generalized coordinates of motion. Awesome. Cool. Well, another figure
that we come back to again and again, tucked away in chapter nine, but giving a lot of context,
is a figure 9.1 on what is termed meta Bayesian inference. So could you describe what
is happening in this figure? And is this exactly as every empirical ethologist is going to agree
with? Is this controversial? Is this novel? So what is it doing for active inference when we
conceptualize our empirical task structurally like this? And do you think that that is exactly how
ethologists have long seen this topic? Or is this something contentious?
I think so. I'll talk through the figure, but then you can tell me if that's how ethologists
traditionally look at it and whether it's contentious or interested. So the idea behind
this figure is to highlight that when dealing in psychology or neuroscience or fields where you're
trying to understand what a particular system is behaving or how it's essentially what's going
on in the mind or the brain or the nervous system of some creature that is behaving in some way.
There are two levels at which you can look at it. One is saying, well, from my perspective as
the experimenter, what are the data I'm measuring? And that may be behavioral measurements from that
creature. It may be taking electrophysiological measurements. It may be asking it a question if
it's a patient in a clinical setting. And I'm essentially now trying to optimize my model of
this system. Now, in the neurosciences and in the settings I outlined above, the kind of system we're
interested in is the sort of system that has its own model of other sorts of system. And so the
kinds of questions we're interested in, the kind of parameters we're interested in, are things like
the prior belief that this creature has about this thing or how precise it thinks its data are.
And so the parameters I'm now asking a question about are the parameters of the beliefs of another
system. So the outside box here, the one that the parameters are going into, the experimental
stimuli are going into and the observed behavior are coming out of, is essentially my model of how
this other system behaves. Now, the inside box here, the one in the dotted line or the dash line,
that now represents the model that that system has to understand the world around it.
And so when we construct our model, that contains another model inside it.
And by saying, if this creature believed this, this is how they would make inferences about
their environment and generate behavior, I can now predict the behavior I would observe if this
creature believed this thing. And so the subjective objective idea is that the objective model is
is the experimenter and its beliefs and the experimenter's beliefs and the observations
they make by measuring what the participant or experimental subject does. And the subjective
model is the participant's model of the world around them. So that I think would be my summary
of how this figure works and the idea it's trying to get across. Now, you can tell me how
the logists may disagree with that or agree with it or what they'd find controversial.
