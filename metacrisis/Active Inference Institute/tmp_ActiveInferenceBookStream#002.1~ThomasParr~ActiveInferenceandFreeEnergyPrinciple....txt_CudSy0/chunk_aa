Hello, and welcome. It's February 20th, 7th, 2023. We're here in Active Inference Bookstream,
number 2.1 with Thomas Parr, as well as Terry and Ali. So thank you all for joining. This
should be a very fun discussion, and let's go first by way of introduction and beginning to
Thomas. Welcome, and please, how did you come to write this textbook in collaboration with
Pazulo and Friston? Well, again, thank you very much for having me here. How did we come to
write this textbook? That's a good question. I think Giovanni was the person who really had
the idea and pushed for this, but I think Carl had already previously been approached by the
editor who ended up managing the publication of the book. And when Giovanni had the idea that
this would be a really useful contribution, he and I had a number of discussions about it,
both in London and in Rome, where he's based, and sort of put out a plan and sort of came up
with something that we hoped would be useful for the community. I suppose part of the reason why
we thought it'd be a useful thing to do is that Active Inference is a very multidisciplinary
type field that draws a lot from lots of different domains. And I think one of the struggles we all
had when we started out in it, and I think certainly what students and people who are interested in
the topics say to us is that it's often quite difficult trying to find all of these different
topics, trying to find the right background when they don't all come from one field. So putting
it all together in one book with a consistent notation, consistent language, and trying to make
it complete, we hoped would just make the field a little bit more accessible to others who wanted
to get involved.
How did this dovetail or integrate with your own education and research
directions? Like what phases or stages were you moving through while this discussion was happening?
Well, I think so when we initially started discussing it, it must have been probably the
last year of my PhD. And so by that stage, I'd spent two to three years sort of getting
to grips with Active Inference, being relatively recent in terms of learning some of the key
material myself. I think it was quite a good stage to be at in terms of thinking about what
I would have wanted to know a few years previously. The actual writing of the book then carried on
over the next year or two. And so by that stage, I was back in clinical training as well,
which I think is also a useful perspective in terms of some of the later chapters and thinking
about application of Active Inference type models in the context of clinical conditions and
psychiatry, neurology and those sorts of areas.
That's actually a really interesting note. How did the clinical experiences
give a perspective on the book? Or how did the book or your learning in these
abstract and theoretical domains give a different insight in the clinical setting?
It's a good question. And I think you're right to highlight the bi-directionality of it,
both are useful in different ways. I think, for me, the clinical setting is quite useful in terms
of thinking, first of all, interacting with different sort of audience. So people who
may be much more skilled on the clinical side of things maybe had less experience on the
mathematical, computational side of things, but may still find concepts very useful.
So from that side of things, it's quite a useful exercise in being able to communicate
these things. And then there's sort of the interaction on the patient side of things and
trying to, you know, I think it makes a big difference. First of all, interacting with patients
has an impact on how you might think about the interesting questions and the things you might
want to use them to inference for. But also having an understanding of principles behind
it helps you, I think, formulate your questions about how individual patients might present
or the reasons for that. I think it's a useful way of thinking about, I mean, I suppose on two
levels. So one, one in terms of understanding, understanding particular sorts of pathology
in terms of the inferences that might have gone wrong. But also in terms of understanding your
own active inferential processes when you're trying to work out what's going on yourself,
asking the right sort of questions to gather the right sort of information and test those
internal hypotheses. I think that's a very useful way of thinking about being a doctor.
Awesome. Yeah, a lot to say about that. The Bayesian optimal differential diagnosis.
Ali or Terry on any of these thoughts, do you have any questions or comments you want to
raise there or any follow ups? Well, yeah, actually, I just wanted to ask,
what are the intended audience of the book? And what do you think are the minimum prerequisites
for going through the whole book? Because I'm sure you'll agree that even today,
the intersection between the people who are well versed in mathematics and the people who have
a solid background in say neurobiology are quite narrow. So what's the solution here? And what
did you think about about the organizational structure of the book that could accommodate
various audiences? So again, another really good question. And I think you're right to
highlight that that intersection is relatively narrow. And there are lots of lots of people who I
think struggle to feel involved in those kinds of discussions. And you're absolutely right to
say that. And I think one of the solutions is the sorts of things that you guys are doing in
terms of setting up these reading groups, trying to open that up, trying to provide
educational resources. I think that's really very important. In terms of the specific
questions about the book itself, who's the audience? Well, and, you know, what are the
prerequisites? I think it sort of depends what you want to get out of it and what your purpose
is in reading it. So some aspects of the book, I suppose, will appeal more to some audiences and
others to other kinds of audience. I would hope that the readership or the audience is
relatively broad, because we've tried to provide as much background as we can on the
mathematical and the neurobiological side of things to try and complement the skill set of
whoever's not in that intersection who comes to it, who may need a bit more sort of neurobiological
grounding or who may need a bit more mathematical and technical grounding. But I think ultimately,
like with most textbooks, you don't necessarily need to come to it thinking, I'm going to understand
everything in this book when I come away from it. Some people may want to, but other people,
depending upon what they want to get out of it, they might say, actually, what I really want to
get out of this is an understanding of some of the kind of message passing as it manifests in
the brain. Whereas other people might come to it and say, actually, I already understand a bit
about that. And what I want to get out of this is to understand a bit more of the technical detail.
You know, if your roboticist is coming to this, it probably doesn't matter too much about how things
are implemented in the brain. If you're a neurobiologist coming to this, you may not need to
know the details of the implementation, as long as you can understand it conceptually. And I hope
the organization, particularly putting things like appendices with detailed information at the back,
tries to keep most of the text a bit more accessible, the early chapters being relatively
light on the technical material and building up the concepts before then moving into the more
technical aspects.
About the chapters, let's actually just take a quick look at the chapters. We're in the
Coda document that we use. So perhaps you could just say one or a few sentences on each chapter.
What's the short of each chapter? What is it doing in this 10 chapter work?
We're testing my memory now. The titles are there. The cues are there.
Epistemic cues are there.
Okay. Well, the overview is what it says on the tin. It's a description of what's to come in
the subsequent chapters to try and orientate people. And the low-road and high-road, I think,
again, Giovanni has to take credit for this idea of saying, actually, it's often difficult to know
where to begin when you're trying to understand active enterprise and the free energy principle
and the Bayesian brain and all those sorts of things, because it seems like there are so many
potential starting points, all of which ultimately, I think, get at the same thing, but knowing where
you begin is often really quite difficult. And so these two chapters were designed to explicitly
acknowledge that difficulty. So the idea of the low-road is to say, well, let's take a pragmatic
perspective where we take ideas that are developed in neuroscience based upon our understanding of
the brain and of psychology and models that have been developed to explain those things.
And let's take those to their conclusion, which is, in a sense, the free energy principle,
which is active inference, the idea of using our internal models both to drive behavior and to
understand what's going on in the world around us. The high-road perspective was designed to
take a different approach to that. And instead of starting from what's already been developed and
the sort of natural trajectory in the neurosciences, the high-road chapter was more saying,
let's start from those principles as much as we can. And here was a tricky balance to try and
make sure that we didn't go too far in depth, that we put people off by the third chapter, but
enough that people might get a bit of a conceptual sense of where you might go with this. And here
we sort of started from the kind of physics of self-organization, the ideas that come
underneath that, and how those ideas can then feed back into this same idea of active inference,
that the neurosciences and psychology seem to have arrived at relatively naturally.
So chapter four is when things start getting a bit more technical and starts dealing with the
specifics that I think most people would want to know if they were implementing these models
themselves. So trying to understand exactly how you construct an internal model, how you specify
it, write it down mathematically, how you perform inference with those, how you understand the
message-passing schemes. Chapter five then takes a step back and thinks, well, in the context of
the brain, in the context of neurobiology, what do those things actually look like? How do we
understand those inferential processes with different kinds of generative models in terms of
what we know about message-passing and synaptic communication? And those five chapters together
really are the first part of the book, and the subsequent five chapters really then take you
through the idea of actually applying those ideas in particular domains. So chapter six is sort of
the overview chapter looking at the rest of it, and it's really setting out if you wanted to sit
down and design a model, either conceptually or computationally. These are the steps you would
have to go through to construct that. And then chapters seven and eight take you through that
sort of recipe for several examples, building up different concepts, both for models designed in
discrete time where you're formulating things as a sequence of events and models formulated in
continuous time where you work with continuous dynamical systems and differential equations.
Chapter nine, as I mentioned before, you know, one of my interests is in the clinical domain
and trying to understand what sort of models people use to form inference, how those can go
wrong. And part of the research on that is thinking, well, how do we then fit these models and use
them to actually draw inferences about what's going on, particular individuals or groups of
individuals. And then chapter 10 takes the broadest perspective and looks at how that relates to
a range of other theories and ideas, both in the neuroscience and beyond. And then I'm sure the
appendices speak for themselves. Awesome. Great overview. Let's come back to our questions. So
you laid out that the first half of the book is about learning and the second half of the book
is about applying and it begins with that recipe. So if chapter six is the recipe, as a chef and
sous chef yourself, what else have you found was important in the restaurant? What is your
full stack active inference modeling look like? And maybe summarizing in six or going beyond
what was in six, like what have you found to be important as part of the modeling journey,
especially with teams where people might have like different levels of domain specific knowledge
or active knowledge? I like the restaurant analogy, actually. I was thinking, I suppose the
first thing that anybody needs to do if they're setting up a restaurant or a model is thinking
about who their customers are and what they might want. And so in the scientific domain,
you're thinking, well, what sort of journal am I planning on submitting this to? What sort of
questions are the communities who read those journal articles interested in?
And I think that's a really important first step so that you know what I'm actually trying
to do with this model. What's not such a good idea often, although you can find interesting
things by doing it, is to say, well, I'm going to develop a model and work out what it's for later
on. You can end up sort of tying yourself up a little bit by doing that. Although there is value
in exploring us, I think we would all agree. Then I suppose in terms of ingredients is relatively
straightforward and deliberately so. I suppose the idea of these sorts of models is that they
should be relatively accessible, relatively easy to construct without having to make use of large
supercomputers or anything like that. A lot of the models that I developed can be run on a laptop
fairly straightforwardly. So obviously just picking your computing language and how you're
going to construct that, there are now a couple of different options out there. Matlab being the one
that I think is most well developed, but now lots of people developing Python-based implementations
of excellent print schemes and particularly in the Markov decision process realm.
So that gives you, I suppose, some of the key ingredients. But then it's really
sitting down and thinking, well, how would I now actually construct this model? The key question,
I think, often is, if you have a particular phenomena or a particular task in mind that
you want the model to perform, it's thinking, well, how would I go about actually constructing the
data that's presented to a participant performing that task or presented to an agent that's trying
to perform this task? And if you can explain how those data are generated, then you effectively
have the generative model that implicitly your agent or your participant or whoever else should
be using to be able to perform that task. So really, all you need to be able to do is to work
out how to create the experimental stimuli. And once you've done that, you've almost already
created your model. And the rest comes from predefined, pre-existing inversion schemes
that actually minimize the free energy for that model. So at that stage, it becomes relatively
straightforward. I say relatively because as anybody who's as experienced in coding knows,
a lot of time is spent debugging and throwing up errors and spending a while trying to work out why
a little bit of Googling to work out your solution around that. I think those are all
important parts of the process. Awesome. Ollie or Terry on that recipe and modelling question.
Any thoughts on that?
Yeah, actually, I also wanted to ask if you have a plan for extending the
codes or supplementary materials to include other languages such as
IMDP packages or any other packages that might come up later and would be widely used in active
inference. Because as far as I know, there isn't any specific GitHub repo or something
dedicated for this book so far. So do you have any plans in developing such a supplementary
material for the book? We don't at the moment. It might be an interesting thing. I mean,
it might be a useful thing to be done by the active inference community as well as a way of
sort of being engaged and involved in it. I suppose one of the difficulties of doing that for a book
is that often these things move on so quickly by the time it comes out in the book that those
packages have moved on. So I think it was useful for us to give a simple example of
Matlab implementation to demonstrate the principles in one of the packages that we've
been involved in developing. So it's part of the SPM package where we've been involved in
developing the active inference routines as part of that. And I think it is certainly a good idea
thinking about having other repositories out there with all sorts of demonstrations. So the
SPM package does have a range of different demonstrations for different sorts of implementations
as well for different kinds of models, which is a really helpful resource. And I often suggest
to people that one of the first ways of getting a sense of how to build these models is to look at
one that's already been built and do their best to break it and change things and make it behave in
different ways. And so I think you're absolutely right to say examples of the code and how it's
implemented are vital in bringing people into this. But yes, I think you're absolutely right
to say that it would be really helpful to have both Python and Julia implementations and all
sorts of different ways of doing it and examples so that people can pick those up completely.
And of course, one of the advantages of Python and Julia is that they're open source and you
don't necessarily need an academic license to use it, which again, I think increases the number of
people who can access it. Giving an overview to someone who might not have been following in the
blow by blow of our little literature corner over the last few years. How would you say
active inference modeling has evolved during your time in this space? Where are we at?
