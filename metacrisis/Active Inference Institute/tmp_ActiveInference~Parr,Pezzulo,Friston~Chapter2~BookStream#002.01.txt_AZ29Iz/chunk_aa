On to Chapter 2, The Low Road to Active Inference.
So, all chapters begin with a short quotation,
and the quotation here reads,
My thinking is first and last and always
for the sake of my doing, William James.
So, even before reading the chapter,
these quotations are often great places to jump off
and have a discussion.
So, Ali, please begin and go as long as you want
on the Low Road to Active Inference.
Okay, so, yes.
Chapter 2, as the title suggests,
it's the construction of Active Inference theory
from the viewpoint of the Low Road Active Inference.
So, it begins by providing this notion of perception
as inference, because more often than not,
we usually think of perception as something just
in a computational sense of the sense
is the processing of the inputs,
or rather, it's the raw processing of the inputs.
But here it shows that it can also be described
as or even more accurately described as a kind of inference.
So, it's not just a simple and raw processing of the inputs
as my computational model or a computer analogy might suggest.
It's more like something that we predict
and then we compare our inputs
or the inputs we get from the stimuli
with our prediction and then try to somehow minimize
that prediction error.
So, I believe that this notion of perception as inference
is the most central notion of all the related theories
of predictive coding, predictive processing,
Bayesian brain hypothesis.
So, up to now, active inference is not very different
from all the other theories.
It's basically a subset or a variant of those theories.
But then it progresses into distinguishing the active inference
from all the other theories and how it stands apart
from the other ones.
So, in section 2.1, we began with some of the basics
of probability theory, namely the Bayes theorem in box 2.1
and some simple examples about how Bayes theorem can be applied.
And again, a very important page or important part of this section
will be page 20, which describes the concept of surprise
and specifically the statistical surprise
and how it differs from the phenomenological surprise
or psychological surprise.
So, and how we can formulate the statistical surprise.
Yes.
Yes, just to catch up here.
This example that's going to come back again and again
is a person who's guessing the object that's in their hand
and it could be a frog or an apple
and the object is going to jump or not.
And so, that's used as a way to talk about the Bayesian updating
that forms the kernel of a variety of Bayesian brain-like models,
including active inference.
And then, there are the presentation of the exact Bayes.
So, in simple cases, you can compute exactly what you want
with Bayes theorem.
However, it's a lot more effective on large datasets
to use certain approximations and heuristics
that we're going to be discussing.
And then, Ali has highlighted that there are two concepts
that are very closely related to each other regarding surprise.
There's surprise by itself and then there's Bayesian surprise.
So, please pick up there.
What are surprise and Bayesian surprise?
And why do they matter here?
Yes.
So, well, surprise.
I mean, the regular surprise as we're all familiar with
is something more related to our sense of surprise
or psychological sense of surprise of observing
some unexpected phenomena or unexpected behavior.
But Bayesian surprise or statistical surprise is, of course,
closely related with the psychological sense of surprise,
but a bit more rigorous in which it's a way to compare
two probabilistic information using callback-Liebler divergence
and somehow getting the, I mean, how unexpected
that information emerging from callback divergence
and they call it the surprise.
So, surprise in other words is a way to formulating
those unexpected probabilistic information.
And it doesn't necessarily align or maps
unto perfectly our psychological sense of surprise,
but as I said, it's closely related with that.
Yes.
So, by surprise, I mean for almost, yes.
No, you take it out.
I know.
I was just going to say that by surprise,
almost in the rest all the other sections and chapters of the book,
we basically mean this Bayesian surprise sense of the word.
And in order to distinguish that with the regular sense of surprise,
sometimes in the literature, surprise is used to refer to Bayesian surprise.
Yes.
So, they're both measured in information theoretic units.
This is all happening in information geometric spaces.
The first concept of surprise is applied to a given single observations.
How surprising is that one observation?
And so, in that sense, it's a lot like the z-score of a data point coming in
with respect to a statistical distribution.
So, it's like you have a height distribution in a classroom
and you measure one person and then you can say,
what is the z-score of that measurement?
Was it right at the center of the distribution with a z-score of zero
or were they two standard deviations higher with a z-score of two?
So, it's kind of like that.
And that's why there's a discussion of probability distributions
and their support, which is the x values for which they're defined
and surprise function with the fancy I.
And that's going to be a function that helps you compute
how surprising each observation is given a parameterization of that distribution.
Whereas this Bayesian surprise is more related to learning,
it has to do with how much updating happens between the prior and the posterior
and that's before and after the observation.
So, one could imagine a surprising observation, surprise concept one,
that either does or doesn't update the prior into a very different posterior.
So, as Ali mentioned, they are not exactly the same,
but it's going to be important to understand how they're different
and that's worked out again in the case of the Apple jumping.
Box 2.2 continues with a discussion of expectations.
Now, expectation in everyday parlance might be specifically referring to something in the future,
like I expect it to rain tomorrow.
And in statistics, when we talk about the expectation,
we're talking about the weighted average or the center of gravity of a distribution.
And that can be in both a discrete distribution,
at which point you have a weighted sum,
or a continuous distribution, in which case it's an integral.
So, you can have an expectation for the humidity tomorrow.
And so, that might refer to the center of gravity at a t equals plus one,
but just taken alone, expectation means center of gravity of a statistical distribution,
not anticipation.
Section 2.3 is going to describe some of this how,
this low road that we're on is going to connect to biological inference.
There's more discussion of the generative model and the generative process
and a little bit of a hint that the generative model captures aspects of the generative process,
which is where we see a lot of the classical cybernetic theorems and concepts,
like requisite diversity, good regulator theorem, and so on.
However, the generative model does not have to be exactly isomorphic with the generative process.
For example, the generative process, the temperature in the room might be a continuous variable,
but then the generative model might be discrete, only modeling integer-based temperatures,
or might be categorical, like too hot, just right, and too cold.
So, there's a lot of articulations that can be done
because of how flexible and interoperable generative models are with each other.
Figure 2.2 is going to expand upon that Chapter 1 representation of the cybernetic action perception loop,
and we're going to see this more in terms of a generative model and generative process articulation,
and there are incoming, speaking from the perspective of the generative model, the agent,
there are incoming and outgoing dependencies in this graph,
and this is a little bit like a schema, more so than a formal graph, but also it is like a Bayesian graph,
where nodes are variables and edges are causal relationships,
and so we have the internal states of the model, the external states of the generative process,
and then the blanket states that make internal and external states conditionally independent,
and again, speaking from the perspective of the agent, although there is a symmetry,
we can talk about the incoming sensory signals happening from the observations,
handed from the process, passed on to the internal states of the generative model,
and then the outgoing actions that are selected that then can influence the hidden state of the world,
for example, going and turning on the heater to increase the temperature in the room.
And so this action perception loop, or particular partition,
is going to get explored in a lot more detail in the coming sections.
Previous section 2.3 was on perception as inference,
and now action as inference is going to be discussed,
and that is where they say the discussion to this point is common to all Bayesian brain theories.
We now introduce the simple but fundamental advance offered by active inference,
which is the extension of this inferential perspective to consideration of action as inference.
Perception and action cooperate to realize a single objective.
Section 2.5 is about minimizing the discrepancy between the model and the world.
We already described that there's two ways for this to happen.
Change your mind and change the world.
That's how the discrepancy can be reduced or managed.
We see a variant of the action perception loop,
where the agent is making perceptions predictive models of the world
that through perception are being juxtaposed with observations handed from the generative process, the world,
and a discrepancy is realized, some non-zero discrepancy.
And then here are those two paths to minimize free energy.
Change beliefs by perception and learning, or change the world through action.
Section 2.6 is going to discuss how the exact Bayesian approach described earlier is absolutely spot-on
if you have infinite computing resources.
However, we're often interested in rapid or large data sets
where we want to be able to get approximate Bayesian computation
or probably approximately correct computation in a vastly accelerated fashion.
And so that is going to be approached using what's called variational Bayesian inference
that's unpacked in chapter 4.
But it suffices to say that variational Bayesian inference implies substituting two intractable quantities,
the posterior probability and log model evidence,
with two quantities that approximate them but can be computed efficiently,
the approximate posterior queue and a variational free energy.
So it transforms an intractable estimation problem into a highly tractable optimization problem.
Pick up from there, Ali.
Yes, sorry, I just wanted to point out a couple of things,
especially about Section 2.3,
because I believe it is one of the crucial sections of this chapter
and in fact the whole book because it provides some of the justifications of using Bayesian inference
as opposed to some other mathematical techniques such as maximum likelihood estimation.
But more important than that, I think it's this concept of optimality
which comes into play in almost everywhere in the literature and of course in this book.
So there are actually two notions of optimality which is not discussed in detail here,
namely Bayesian optimality and Jain's optimality.
But in some of the recent papers on Bayesian mechanics,
