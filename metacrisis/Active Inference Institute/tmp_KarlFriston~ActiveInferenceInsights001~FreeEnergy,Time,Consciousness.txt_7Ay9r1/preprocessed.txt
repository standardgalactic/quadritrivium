Excellent, and we're away. Okay, so welcome everybody to the first episode of Active Inference
Insights, brought to you by the Active Inference Institute. I am your host, Darius Parvee Zwayne,
and today I have the privilege of speaking to Professor Carl Friston, one of the most
revolutionary thinkers in the fields of neuroscience, cognitive science, theoretical biology, and
dare I say, physics and philosophy. A leading authority in neuroimaging, he is the inventor
of statistical parametric modeling and voxel-based morphometry, I hope I pronounce that correctly.
More recently, he has posited the free energy principle, which is technically a normative
account of self-organization in terms of optimal Bayesian design, or in other words, a description
of how things continue to be things. As such, his groundbreaking ideas hold profound implications
not only for biology and psychology, but also the very nature of reality itself. Ladies
and gentlemen, it is my honor to introduce Professor Carl Friston. Professor Friston,
thank you so much for joining us.
Well, thank you. Thank you for that lovely introduction. But what you can say is I just
invented lots of three-letter acronyms. That's much simpler than you said.
And I sense a lot of three-letter acronyms have also spawned from a lot of your work.
Excellent. Well, this podcast, this is the first episode, as I was saying off camera, this is
very exciting for me, hopefully very exciting for everyone tuning in. The reason why it's come
about is that we wanted the Active Inference Institute, wanted a way to introduce the ideas
of active inference and the free energy principle, perhaps to an audience who were not PhD holders,
scholars in the area, but had a kind of latent interest in psychology, neuroscience, maths,
biology, whatever it is, and wanted to explore these ideas a little bit further. So it's a
non-specialized introduction to the ideas of active inference and the free energy principle.
And as the author, inventor, discoverer of the free energy principle, we can have an
interesting philosophical conversation about what that is. It's an absolute delight to have you.
So I guess my first question that I need to ask for everyone listening is,
could you give us a very brief, or not very brief, but a very accessible definition of
the free energy principle, what free energy is, and what this principle says about reality and
ourselves? Yes, I'm not very good at giving brief answers. We have a while, so go ahead.
So just to put things in context, the free energy principle is a principle as read by a
physicist or engineer. That means it's a method, much like Hamilton's principle of least action,
that you can apply. So I might ask, what are the most important applications of the free energy
principle? I guess that would be active inference. So I will answer your question, and I will say
what the free energy principle is, but that may have to be qualified by looking specifically
at the application, which is active inference, and what that means, teleologically, heuristically,
what it brings to the table when you do apply the free energy principle. But the free energy
principle itself is just a description of things that persist or exist, and it rests upon a careful
specification of what you mean by a thing. It starts with the exactly the same assumptions
that all of physics starts with basically a random dynamical system. Some people describe that in
terms of stochastic differential equations, if you're not familiar with that kind of description,
is just saying that you can describe the universe in terms of the way that states change as a
function of themselves. So it's a very generic description of any given universe that just
commits to the notion that there is a state of the universe, and it could be very high dimensional,
and that it has some dynamics. So that's where the free energy principle starts. But the special
thing about the free energy principle that distinguishes it from other formulations in physics,
for example, quantum thermodynamics, statistical and classical mechanics, all of which can be,
if you like, derived from this basic description of the world as a random dynamical system.
The thing that separates the free energy principle or gives it its particular flavor
is a careful distinction between the states of something and everything else. And the way that
we do that is by inducing a separation, you know, technically a partition of all possible states
into three kinds, the states of something that are internal to the thing, everything else external
to the thing, and then crucially a set of states that separate the internal from the external states
that allow and couple the inside to the outside, and that's referred to as the blanket states or
a Markov blanket or boundary. So a lot of this rests upon this notion of a boundary
that on the one hand separates the inside from the outside of something and by a thing, I mean,
anything from a small particle to a priest or a person, anything that can be individuated and
possesses characteristic states constitutes something. And with tongue in cheek, you therefore
have a theory of every space thing, not everything. So this Markov boundary or Markov blanket
is a sort of crucial device in the sense that it allows you to individuate something from
everything else, but at the same time, it couples the internal to the external states.
So we're now talking about a special kind of physics, probably a more ubiquitous kind of
physics, which is the physics of open systems, because the inside is now vocariously open to in
exchange with the outside across the Markov blanket. And just for interest, because this will be
relevant later on for active inference, we usually divide the blanket states into active and sensory
states that can be regarded very simply as the inputs and the outputs. Technically, the inputs
of the sensory states are defined in the sense that the internal states don't influence the sensory
states. And conversely, the active states are defined such that the external states don't influence
the active states. So, but more simply, what we're saying is that something can be defined in terms
of the influences upon it and the influences that it exerts through the blanket states on the outside
world. So just given that assumption that entails existence in the sense that to define this Markov
blanket, you need for the system to have some characteristic states, technically an attracting
set of states that you'd find the thing in, just by assuming the existence of this attracting set
of this random dynamical system that possesses this distinction between the inside and the outside,
everything else follows. And everything else, simply put, is you can read the internal and active
states, sometimes referred to as the autonomous states of a particle or a priest or a person,
as either if you're a physicist conforming to a particular principle of least action and that
principle of least action is that it minimizes the path integral of the variational free energy.
If you want to think of this more intuitively, because that free energy also stands in for,
or it's an approximation to a bound upon model evidence, you can also say that it must be the
case that the autonomous states of anything will look as if they are trying to maximize
the evidence for what we would now consider the internal states to be a model of what's going on
on the outside. So some people refer to that as self-evidencing. So if I just repeat that,
from the physicist's point of view, given the assumption that you've got this random dynamical
system with an attracting set that has this partition that allows you to individuate something
within this system, it has to be the case that the dynamics of the autonomous states of that system
perform a gradient flow on a quantity called variational free energy.
That's it. Is that interesting? Well, it becomes interesting if you realize that this variational
free energy has a particular meaning and a particular interpretation that gives you a
teleology for this kind of dynamic, and that teleology is often referred to in terms of
Bayesian mechanics. Why? Well, because the variational free energy is the same quantity
that measures the evidence for a generative model of the causes of some data, if you're a statistician.
And in this instance, the data that we're talking about are the impressions of the outside state
on the Markov blanket. So what you're now in a position, or you're now in a position,
you are now licensed to talk about anything that exists in some simple elemental sense,
performing inference and possessing this or evincing this kind of Bayesian mechanics.
And in philosophy, people like Jacob Howey nicely summarizes as self-evidencing. So you can imagine
that it looks as if anything that exists is basically moving in a way, sensing and acting
upon its world in a way that's garnering evidence for its own existence. So this is,
if you like, a slight cheat in the sense that what we're doing is describing the dynamics of
something that exists, and then we're saying, but it now looks as if, in virtue of its existence,
it is now, it can be described theologically as acting to gather evidence for its own existence,
its own structure, and that structure entails a generative model of what's going on on the outside.
So how does that help? Well, it doesn't really help in any fundamental way other
than it's very pretty, and it's nice to talk about Bayesian mechanics as being a sort of complement
or another kind of physics that comes from the same stable as quantum mechanics and statistical
mechanics and, I repeat, classical or Lagrangian mechanics. However, there is a nice application
at hand once you realize that this, once you interpret the variational free energy in terms of
a, technically, the logarithm of some model evidence, what that means is that you can now build
things. You can build things and you can simulate those things. Why? Well, because you know that
the dynamics must be conforming to this principle of least action, another way of thinking about this
is that it does a gradient descent or a hill climbing on a particular functional, which is
this variational free energy or the negative variational free energy, which is the log evidence.
So because this log evidence is a function of a model that just is a description of the
characteristic states things occupy or things are found in, you can now write down the generative
model, which is just a probability distribution over the characteristic states or defining the
characteristic states you want your thing to be attracted to. This is the attracting set.
And once you've written down your generative model, you can then work out the gradients
of the free energy functional of that generative model. And then you can simply
integrate or mathematically solve for the dynamics, the flow, the motion, the movement of
this thing. So I know this isn't terribly accessible, but it's a way I think of these
things that you are now in a position, it's always looking at something and saying, oh,
I wonder what generative model would be fit for purpose to describe this particular thing.
You can now turn that on its head and say, okay, I want this kind of thing and I'm going to describe
and define this kind of thing with a particular generative model. I just have to write down the
probability distribution over the causes and consequences from the point of view of the
thing in question, namely the external states and its impressions upon the Markov blanket.
And once I've written that down, I can now simulate the autonomous states. I can now
create a little autonomous article, a little autonomous particle that behaves in exactly the
same way as something that existed that had that kind of generative model. So it's a very practical,
if you like, it's a principle that can be applied in a very practical way to simulate things. And
if you can then simulate things, you can start to build things, you can start to
do computational neuroscience, you can start to sort of naturalize cognitive
neuroscience and possibly even sort of psychology in terms of the physics
that is inherent in this Bayesian mechanics that comes from the free energy principle.
You can also start to ask questions about the beliefs of another person. Why? Well,
part of this generative model or the generative model can always be sort of
split into two things, sort of priors before you see some data and the likelihood,
the likelihood of that data given the causes of that data. This would be the external state. So
you have a pri belief over the causes, the external states, and you have a likelihood that maps the
causes to the consequences, which are your observations or your sensations.
And therefore, you can now fiddle with and say a synthetic subject or person
who is being simulated in the computer until their behavior, their actions, possibly their
decisions matches that of any given cohort or any given subject or animal. And then having adjusted
the priors part of the generative model and possibly the likelihood, you've now basically
created a digital twin that emulates the same kind of belief updating the same kind of Bayesian
mechanics that you can now infer is possessed by the thinking question. So this is a sort of
quite a high end application, which is one of the motivations for developing the free energy
principle and active influences and application that enables you to essentially phenotype
another thing, another person, for example, in terms of this belief updating in terms of this
Bayesian mechanics. And that can be quite useful in contexts when you want to understand how people
work and particularly how their belief updating works. This becomes particularly interesting
in the context of computational psychiatry, where you want to be able to explain people's behavior
in terms of what do they believe about the world out there, how are they sense making,
how are they assimilating evidence for their world model, which you can read as the generative model,
and under what priors are they doing the sort of Bayesian assimilation or evidence accumulation
that underwrites their decisions. So that's one particular application. There will be other
applications. If you want to make intelligent artifacts or you want to understand the mechanisms
of belief updating at different temporal scales, belief sharing between two things that are in
communication or transacting across their shared Markov blanket or indeed looking at a shared world
and then one can start to get into the world of distributed cognition and federation inference.
There are all sorts of things you can do once you start to apply active inference.
Yeah, that was fantastic. I mean, we have a lot to get our teeth into. And probably
some concepts there that are new to our audience. So it might be worth sort of backtracking certain
things and trying to find a kind of, yeah, let's sort of dissect some of these concepts together.
The first thing I want to speak about is this notion that the internal states in some sense embody
the kind of desirable model given their attractor state, the desirable model of the world. I think
one of these, one of the questions that one has when one enters into the world of active
inference is whether an organism is a model or whether an organism has a model. And here we
sort of have a backtrack to cybernetics and the good regulator theorem that all good regulatory
systems have a model of their environment if we think about thermostats or anything alike. So
maybe it's worth unpacking that because I think a lot of people might have this
intuitive sense that there's a homunculus in the brain which has a model of the world and
it's very internalist, but maybe from a more physics perspective, we can adopt a more externalist
position where there isn't this little thing which has a sort of representative picture of the world,
but actually is just enacting some model of itself, which in many ways is just some
some version of its external dynamics. So let's start there because I think that will
feel nicely into maybe a conversation about internal and external dynamics and exactly what
that looks like in the free energy principle. That's a great question and you're some sort of
deep issues unearthed by that and it's nice you've introduced cybernetics and the notion of the
good regulator theorems. On one view, I think you can look at the free energy principle as just a
21st century version of that kind of cybernetic thinking. There are other things that the free
energy principle inherits from James' Max Mentor principle, lots of ideas in psychology
perception as hypothesis testing. There are lots of different roads that converge upon this
formulation that is on offer in terms of the free energy principle, but that particular question
is really interesting. I have to say that I usually try to elude that question by saying that the
internal states entail a gerative model. However, if one was pressed upon it, then
I would say very clearly that the internal states, the thing is a gerative model.
It's not, if you like, a picture that you painted in terms of that homunculus looking at its
virtual reality inside its head and trying to predict what's going on. It is instantiated,
is realized in its physics, in its existence, in its dynamics. The reason I use the word entailed
is that the generative model is technically just a probability distribution.
So you ask yourself, does a probability distribution exist in some physical sense?
And the answer is, well, no, a probability distribution is what it is. It's a mathematical
description. However, that probability distribution will have sufficient statistics
that could exist. So what I'm saying is that, for example, let's take a Gaussian distribution.
I can express mathematically and write down the notation for your Gaussian bell shaped
distribution over some variable that goes from plus to minus infinity. Or I can say,
I can characterize or specify this Gaussian distribution in terms of its mean and its
variance. And those are two numbers that are not random variables. They are sufficient statistics.
And it may be, and in fact, it is the case that the free energy principle associates the physical
internal states with the sufficient statistics of these Bayesian beliefs. And there's a lovely story
in mathematics that would take you down the path of information geometries and statistical manifolds
and belief updateings as movements in these geometries and try to understand the metrics
in these spaces and how that relates to uncertainty and precision. Oh, that's a lovely story.
We don't need to really pursue that at the moment. The key point being made here,
the gerative model is not physically instantiated other than in terms of some sufficient statistics
in any setting. However, in the free energy principle, the gerative model is in or of itself
never actually instantiated in terms or realized in terms of its sufficient statistics. And that's
because of something that we were talking about before, which is the dynamics. So the dynamics
is a gradient flow, which means that all we need are the gradients of the free energy.
So we don't need the gerative model. All we need is the gradients of this free energy function,
or technically a function or a function of a function of the gerative model. So
if I was building an artifact, I could certainly prescribe the right dynamics by writing down
the gerative model, and then I could evaluate the gradients of that free energy function of the
gerative model. And then those gradients would actually drive the dynamics. I could simulate
self-organization, I could simulate active inference, I could simulate belief sharing,
whatever I wanted to do. But in that simulation, all I really needed were the gradients of the
free energy. And we only need the gerative model because the free energy is a function of the
gerative model. So in that sense, the gerative model is really a theological description that
you would bring to the table to understand your sense-making of another thing. The thing in and
of itself just needs the free energy gradients. It just needs to self-evidence by moving in the
direction of maximizing the, on average, the log evidence for some abstraction, which is a
gerative model. But he doesn't need to know that. Just so we don't confuse people. So moving up
those log evidence gradients very much like the paradox of moving up concentration gradients
to clump together and to keep in this attracting set and to resist the dispersion of the random
fluctuations inherent in these random dynamical systems is just the same as moving down the
negative log evidence, which is the free energy itself. It's the same thing.
So what does that mean? Well, what it means is the gerative model is something that you bring
to the table to endow the behavior of this thing with an explainable teleology of the kind. It
looks as if this thing is acting in a way to maximize the evidence or gather the evidence
for its gerative model. And this is what I think its gerative model is. But notice the
thing in and of itself doesn't go through this process. It could, of course. So if I and now
people, things like you and me, we do have a model. We do have and we communicated and we talk about
it. But most things would not possess that deep structure. So you can invoke homuncular,
you can invoke self-modeling, you can invoke the kind of not homunculus in the sense that you
would normally end up with an infinite regress, but the kind of metacognitive aspect that comes
from any deep or deeply structured hierarchical gerative model. You can get that sort of homunculus
like detachment and metacognitive perspective on things. But strictly speaking, the gerative model
is only entailed by the dynamics. And I should say that this is probably best to think about
applications of the free energy principle as being limited to simulating and modeling and
understanding other things as opposed to oneself, unless one's doing or self-modeling.
And so in that sense, you are ascribing a teleology, a purpose
that would explain the behavior of something that you're observing. But notice, because you're
observing it from its point of view, you are an external state. And from your point of view,
all you can see is the Markov blanket. You cannot see what's going on on the inside. So it is,
it would be mathematically impossible for you to ever know whether what's going on in the inside
is indeed describable as even a gradient flow on a free energy functional, let alone did it have its
own internal model, did it have its own beliefs. It just looks like that from your point of view.
Because you will never, ever know by definition. If you knew, then you would, by definition,
have breached the Markov blanket, and that thing would cease to exist as the kind of thing that it
was before. It may sound obvious or it may sound trivial, but I don't think it is if you just look
at people like me, who spend our entire lives trying to peer through the Markov blanket using
brain imaging, for example, and, you know, or people doing comparative anatomy by dissecting
dead things, or by inventing new techniques to try to try and get, you can never get beneath
the Markov blanket, but you can certainly sort of have some perspective on the Markov blanket
that are closer and closer to the internal states, but you can never actually get in there.
I imagine a whole philosophy on this, that you couldn't see your own visual processing.
You couldn't hear your own cochlear dynamics. You can't ever have access to the inside very
much in the spirit that internalists would say you can never have direct access to the outside.
So I think that also applies to these stories about generative models and the Bayesian mechanic
interpretation of that comes along with the with the free ownership principle. Does that help in
some way? It's a little bit subtle, and I can just imagine a lot of my friends tearing their hair
out because they have very particular views about this. You know, people think it's a model of a
model. Some people think it's, you know, take it very internally, some people externalist,
but mathematically, you know, it's not the model which drives as, you know, it is the dynamics
which drives us, and that dynamics can be interpreted in relation to a generative model,
should you want to. Excellent. Well, I'm going to follow that philosophical line of thinking,
and what I want to ask is, this is an interesting point, the notion that we can get to a closer
approximation of what the internal states of ourselves are, for example, but it's always
going to be an approximation because piercing the mark of blanket would constitute self-disintegration
under the under the rules of all the principle, the free energy principle per se. How in a sense,
therefore, do we know or how how how much can we even make the claim therefore that there is such
a thing as an external dynamic that goes beyond anything, goes beyond our sensory inputs? It may
seem like a deeply non-scientific question, but the way you were speaking, I couldn't help but
think of people like George Barkley and even Kant and this phenomenal, numinal distinction.
If we don't ever have direct access to so-called external dynamics, because that is
part and parcel of the physical game that we're in, why can't we just say that there are no hidden
states and all we get are probability distributions over sensory appearances, but we don't need
something like a likelihood mapping to something that's latent? Well, you could say that and a lot
of my friends do say that and I think in the sense that the notion of direct access means that you
will never know in some sort of heuristic sense what the external states are if they exist at all.
And on the other hand, you could also argue that there is profound access to the
and existentially meaningful access to the external states. It's just organized in such a way
that it has to be transacted by the Markov blanket. So, I haven't had this conversation
for several years now. I used to have lots of pat answers, which depending on who I was talking to,
but the way that you phrase a question, which was very clever, just made me think, well,
what is the internalist argument? Does it mean that because I don't have direct access, that the
external states don't directly influence me, that means that they don't exist?
Is that the argument that an internalist would make? Well, might it be the case that all we have,
we don't need to invoke a kind of further realm, a further causal realm, an underlying ontological
realm. If all we have are just the streams of sensory input and seemingly some regularities,
some patterned regularities in them. Why, at least in terms of doing the Bayesian modelling,
do we need to invoke a hidden state or an underlying cause? For example, if we just take
a look at the low road tax of inference, we talk about how cognitive creatures like ourselves
predict the world, let's say at a very simple level. A question that I've always had is why
why does the claims of predictive processing or predictive coding more generally?
Why does it make claims about hidden states? Why doesn't it make claims just about regularities
within streams of appearances? That's the way that I would pose that question.
Right. I'm just mindful you've introduced predictive coding and predictive processing.
We have the energy cost. Just for those people who may not know that the intimate
relationship between all these things. Another way of looking at free energy is the amount of
prediction error. More specifically, if you're talking to some people, it would be the total
amount of precision weighted prediction error, which means that there's another reading of
minimising free energy, which is not the maximising the model evidence, but minimising
surprise where surprise is the implausibility of some sensory data given your model of that data.
In exactly the same way that if I go around gathering data that I find continuously surprising,
then that's basically evidence I haven't got the right kind of model to be able to explain,
i.e. predict those data. Again, we have one of these completely equivalent descriptions,
but they have very different flavours that to maximise model evidence is to minimise surprise,
which is to minimise a prediction error, which is to maximise predictability, which is to minimise
variational free energy and so on and so forth. They're all the same. They're all the same thing.
So when you're talking about predictive coding as a particular algorithm for minimising free energy,
technically a variational scheme, which is known in engineering as a Kalman filter,
what you're saying is I'm making certain assumptions about my generative model
that mean I can write down these free energy gradients as prediction errors. So literally
the prediction error, my apologies, the precision way to prediction error
literally is mathematically exactly the gradient that we were talking about before.
So just join the dots. So thank you for your question. Why is it that I need to invoke latent
states in order to make sense of data? I would argue that the sense making is just explaining
data in terms of latent states. And those latent states are often referred to in the technical
literature as hidden states. And what do you mean by that? Well, it just means they're unobservable
from the point of view of the free energy principle, they are hidden behind the Markov blanket.
So I would say that detecting patterns simply is invoking latent states that organise the
structure of those patterns. So I don't think there's anything magical about latent states.
So the latent states that are, if you like, entertained by your internal dynamics and your
sense making are not the external states. They are descriptions that are only relevant to the
generative model that you need in order to define the prediction errors or the free energy gradients
in order to simulate or describe your sense making in terms of your neuronal dynamics or
your internal dynamics or the operations, say a thermostat. But there's a twist here. There's
a reason it's called active inference because it's got a big active at the front. So it's not
good enough just to say, oh, I can understand psychology just as making lots of sense of my
sensory impressions. That's not good enough. Because you are coupled to the world
in reciprocally, which means that you actually are not only are you exposed to the world,
but the world is exposed to you in an exactly symmetrical way. Then how could one describe
that? Then we come back to where we started with this partition of blanket states into sensory and
active states into the inputs and the outputs, which means that sense making is quintessentially
active. So one way of phrasing that is that, yes, I'm making sense of all this sensory data
and all the patterns, but at the same time, I'm actually in charge of actively soliciting those
data, causing those patterns. So I think once you bring that sort of inactive aspect to the table,
so I notice that you treated predictive coding as a sort of generalization,
predictive processing. It might be easier if you do it the other way around because then
you have the grace to accommodate action in predictive processing its most general sense.
If you don't, then predictive processing I think is an incomplete story. You have to have,
as part of the processing, the active solicitation, the garnering and the structuring
and querying the world in a way that reciprocates with the right kind of information that allows you
to do the good sense making in terms of the latent states that we're talking about.
I mean, formally, this takes us into another part of the story which we didn't previously unpack
about active inference. So somebody might ask, well, okay, so we've got this
application of a free entry principle that a physicist might be quite comfortable with
to behavior that entails some kind of sense making, cheekily, I like to call this sentient
behavior, then I get told off for that. So how does this differ from reinforcement learning?
How are behavioral psychology? It differs in a quite fundamental way because the big thing
that active inference brings to the table is that, first of all, it says you are in charge,
you are actively sensing. So this is vision, active perception, active inference in this
most general sense, which means now what are the imperatives for generating your own data?
Now you could if you were doing behavioral psychology of a behaviorist sort in the 20th
century, you could say, well, I just want to generate those sensations that I find rewarding.
And so I've got some privileged sensory channels that I'm going to label as reward,
and I'm just going to act in a way that maximizes the reward that comes in.
From the point of view of the free energy principle, that's not what happens. What happens is
I want to find those data that resolve the expected surprise or the expected free energy
consequent on acting, soliciting those data. So what's expected surprise? Well, technically,
it's an entropy, it's just a methodical measure of uncertainty. So what that means is that the
description of things that persist or exist over some particular period of time
reduces now to a kind of Bayesian mechanics in which the behavior will look as if it is
information seeking and uncertainty resolving. It will look as if it is responding to these
epistemic affordances under constraints. And it is those constraints that, if you like,
would be the homologue of the reward. They are literally the constraints endowed by the prize
on the generative model, the kind of sensory states that constitute this attracting set,
to which I am attracted. But the vast majority of the drives for good behavior or behavior
that things that exist would evince is this resolution of uncertainty, this information
seeking. And indeed, that leads you into considerations. Well, how would you describe
that kind of information, that optimal information seeking behavior if you were a scientist or
if you were an engineer? And if you were a scientist, you'd be looking at the principle
of optimal Bayesian design, articulated by people like Dennis Lindley in the middle of
the last century, where you measure the quality of an action in terms of the information gain
afforded by the data that you secure by acting in this way. Exactly the same idea emerged in
the context of active learning in machine learning. This is the problem. If getting data is costly,
what data point would I need to resolve the greatest uncertainty about my beliefs about the
latent causes of those data? So active learning, again, notice your active and explicit part of
this process. So in answer to your question about would it be sufficient just to understand
sentience in its most basic or elemental form? As discovering patterns in data, I would say no,
because that denies the openness of any given system immersed in her world in two directions,
the world influencing you and you influencing the world. As soon as you put that into the mix,
I think it's very difficult to conceive of any construct, possibility in philosophy,
but certainly any construct in computer science or physics that would
that would permit a complete description of sentient behavior just in terms of sensing patterns.
Does that make sense? Yeah, that makes sense. That makes sense. Makes sense to me.
Yes, I want to stay on action for a second, because I think the notion of the minimization of free
energy or the maximization of model evidence could make some intuitive sense for an agent like
ourselves in the sense that we have our sensory inputs, which are divergent from our priors,
and we act to change the world to make those sensory outcomes more in line with our expectations,
our preferences. However, at a more fundamental level, one definition that we spoke about with
the free energy principle is that the internal and external states look like they're tracking
one another across a Markov blanket. Now, a question that comes to my mind when I see a
definition like that, which is that makes sense for me for a sentient, conscious human,
but what would a stone be tracking or what would a drop of oil be tracking to use an example that
you've used before? I think going to something a bit more less animate, and I presumably answer lies
in animacy, I think would be a really interesting avenue to go down, because it gets these fundamental
questions of how does something as minimal as a particle retain its particle-ness,
and what does that really look like when we presume that they're not conscious,
unless we're pan-psychists, but we won't go just down that route just yet.
That's where you were taking us, which is a fun place to be. How does one elude pan-psychism in
the free energy principle? Well, I think you've just answered your own question there,
perhaps we'll just unpack that a little bit. What's the difference between a stone
and a thermostat and me? I think what you're now asking is, are there,
what I will call natural kinds, but I wasn't allowed to because that has a lot of philosophical
baggage, but for the purpose of this conversation I'll just say, are there natural kinds of things
that display different kinds of behavior that can be equipped with different kinds of
teleology, and I would say absolutely, and you've just rehearsed some of the key things.
So, as you noted, to be animate is a big thing, in the sense that the stone is not animate,
in the sense that it moves itself. You know, stones started wandering uphill or flying around,
that would be much more interesting, but they don't have that animacy that is characteristic
of biotic self-organization. So, what does that mean in a deflationary sense of the free energy
principle? It just means that the active states are an empty set, and usually for stones you might
also argue that the internal states are empty. We don't have to. The stone can be making sense
of its world in terms of its latent states, or acquire that interpretation. Perhaps that's a
nice example of what we were trying to drill down on earlier on in terms of, is there a generative
model? I mean, one could argue that a stone has a generative model of external milieu in terms of
the temperature, and that there's a latent variable, which is a hidden state of a latent state, you know,
as well known in statistical thermodynamics, which is a sufficient system called the distribution
of things. And the temperature could well be inferred by the internal, the interior of a stone,
and therefore it is making sense of the pattern of its sensory exchanges with the world on the
surface of the stone, simply because it's warming and cooling, and therefore tracking the ambient
environmental temperature. So, that's perfectly free energy principle consistent. It's a very
boring kind of sense making, but, you know, and it is that boring kind of sense making that I had
in mind when talking about, if you preclude the active part of active inference, and just think
about sort of perceptual inference, then you're sort of missing the point, really. But I think a
stone is a good example of that. Now, would you say the stone has a generative model? You could
argue that, but, you know, it's you trying to explain the behavior of a stone, but the stone
doesn't have very much behavior. But you could start to think, well, now if you test a hypothesis,
it is actually registering the temperature on the inside. And again, just to rehearse the argument,
the fundamental argument we were talking about before, you will never know, though, until you
break the stone, because once you break the stone, it's no longer a stone, it's just a broken stone.
So you're exactly the same problems or issues confront you, even with the stone. But you're
focusing on that sort of big move from things with and without active states. I think then you're
talking about things that are animate, things that have animacy and active on the world.
Is that sufficient to get the kind of behavior that we've been talking about, which is, you know,
the kernel of active inference in terms of what active inference brings to the table in terms of
information seeking and having a variety of different affordances, particularly epistemic
affordances, as an explanation for behavior. You could argue, no, a thermostat can act upon the
world. It can switch heating elements on or off and it senses things by its thermo receptors.
You could say like very much like a Watts governor. It now has active states, it has inputs and
outputs, and it has internal dynamics. And in one sense, the Watts governor is a good regulator
and therefore conforms to the cybernetic view of a gerative model. And it's acting in the right
kind of way. So does this kind of system have the curiosity that would be associated with
information seeking and resolving uncertainty? And you would argue, well, no, it doesn't.
So now you've got another kind of natural kind, which does. So what's the difference between
a Watts governor or a thermostat or possibly a virus and me? Well, I think the key difference is
a particular kind of self modeling that just comes from being very big and a bit structurally
complicated in the sense that there are certain parts inside my body and inside my brain that are
so distant from the active states that are actually moving my arms, my actuators or are
engaging my autonomic reflexes that I cannot see them directly. And if that is the case,
the only way that I now can sense the consequences of my action is to carelessly through the sensory
states. Now this introduces a really interesting distinction between me and a virus. It means
that I now will start to treat my own action as a hidden or latent cause of my sensations.
And that brings to the table. Okay, well, if now my own action is being inferred as a random
variable, then now there's a separation between what I think I'm doing or what my active inference
would allow me to talk about. It tells what I'm planning to do or what I'm inferring to do
in the spirit of planning as inference and what I'm actually doing. So this brings you to an even more
a different kind of thing, which would be something like me, that now has beliefs about
its own action, which is distinct from the actual real variables that constitute the active states
of the Markov blanket. And as soon as I have beliefs about my own action, I have to ask myself,
well, as a physicist, I would ask, well, what are the probability distributions over my
active states, those states that actually change the causes or the external states generating my
sensations? And when you write that down, what you get is exactly what we're talking about before,
which is this mixture of expected information gain, basically expected free energy that has
can be decomposed into this information seeking part, and the constraints afforded by your prior
the prior part of your journal model, the things that you find very surprising.
Plus it is to unpack that intuitively. Let's take the predictive processing surprise minimization
view of self organization and an active inference. And that means that I now have the
the kind of creature that exists. Therefore, I must be minimizing my surprise. Furthermore,
I now have beliefs about my actions. I have prior beliefs. I must have prior beliefs about my actions.
Of course, this is all sub personal. So what kind of prize would I have about my own actions?
Well, I'm going to because I exist and I'm a free energy surprise minimizing kind of thing because
I exist, then I must choose those actions that minimize the surprise I expect following that
action. So that means I'm going to minimize my expected surprise. Now there are two ways in
which I can do that. And we've already spoken explicitly about the two ways. One way is just
to notice that the average surprise, the expected surprise is just uncertainty. So I can reduce
my expected surprise or my anticipated or my average surprise by getting to grips and knowing
what would happen if I did that with greater precision. So this is information seeking.
This is the sort of the curiosity. It's the novelty seeking part. It is the exactly the part
that underwrites the the basic principles of optimum Bayesian design, getting the data that
minimize my uncertainty because uncertainty just is expected surprise. There's another way of doing
minimizing expected surprise. If I know what is very surprising, if you know, by being
at very, very low temperatures or being very poor or being snubbed socially, everything that is,
if you like, not characteristic of me given that I exist in a particular way,
then any deviations of that basically can be thought of as surprising. So if I stray beyond
very much in the spirit of homeostasis, although now we're talking about allostasis because we're
talking about the future, then I'm going to choose those actions. Then don't just do the
information seeking responding to the epistemic affordances, but also will elude those kinds of
surprising states that are very uncharacteristic of me being very poor, missing out on that opportunity,
being embarrassed, being in pain. Although pain is probably a bad example. We're talking about
the sensations that we want to want to avoid. So that would speak to the prior cost or the
prior surprise, the negative which was the preferences you mentioned before. So you can
look at these constraints afforded by the priors, the pragmatic part, if you like, of these affordances.
Some people call them instrumental. So you've got epistemic and instrumental affordances that
just are the expected information gain and the negative expected cost, which would be the
manifestation of the constraints. You can look at the complement of constraints in terms of
where I don't go in my sensory state space as where I do go, which are my preferences,
my preferred and characteristic attracting sets. So just to remind myself and you and
people who are listening still at this stage, why are we going through all this? Well, because this
is what comes out of a consideration of beliefs, prior beliefs, about the way active state should
unfold. And that becomes very pertinent when now I have to actually embody those beliefs
in my gerative model. So suddenly now I become something that is very distinct from
a thermostat or a virus, because now I have a gerative model of the consequences of my action.
And that gerative model is very simple. It just says a priori. I will a priori think that the
action that maximizes information gain and maximizes this instrumental value
are going to be the most likely policies. And this could be construed as a high end
kind of planning as inference. It's not as trivial or simple as a sort of KL control,
because we've got this epistemic part of it, but it still has a spirit of planning of inference.
So what I'm saying quite simply is there are certain things that plan and there are certain
kinds of things that don't plan. A virus doesn't plan. The weather doesn't plan. Evolution doesn't
plan. The stone doesn't plan. And you could argue that many smaller insects don't plan.
But as you get bigger things, then they start to plan. And I think you move from non-planning to
planning at which point, by definition, you are ascribing to these bigger things, like you and
me, ascribing a teleology to our behavior that rests upon a gerative model that includes the
consequences of its own action, which crucially equips it with a temporal depth because the
consequences are in the future. So unlike the thermostat, that doesn't need to look very far
into the future. Things that plan that are so big that they lose contact with their actual actuators.
Now, look as if they have this sort of temporal depth, this temporal thickness
to their gerative models, specifically enabling them to plan their actions into the future.
So that's how I would get out of the panpsychism argument.
Okay, I've never heard that argument before about the distance from the actuators. That's very
interesting because it seems in that sense that the temporal depth is downstream on size, in a sense.
Is that a correct reading? And is there a reading of your argument that you've just laid out there
in which you can have deep temporal modeling, planning as inference, and allostasis as well as
a sense of retrospective inference, without being a large thing? Or is this notion of being
far from your actuators so that you have to start disambiguating what is your action and what is the
action of the world or other people? Is that fundamental? Yeah, I mean, this is a really
interesting notion because I've actually never heard it really be elucidated like that. So I'd
love to know whether there is a way that a virus could be doing deep temporal modeling despite
its minimal size. Right. I mean, to be honest, I don't know. But a sort of an intuitive answer
would be no size really does matter. It really does matter. So by size, I'm implicitly talking
about the sparse coupling that underwrites the conditional dependencies in mathematical
systems that give rise to Markov blankets and blankets and blankets. So I'm not literally
talking about how wide something is in terms of millimeters. I'm talking about the sort of
the hierarchical depth of conditional dependencies and being secluded behind Markov blanket after
Markov blanket after Markov blanket. So if you're comfortable associating physical size with that
hierarchical depth in terms of what a thing is in terms of having this internal hierarchical
structure internal Markov blankets, then I think the answer is very clear. No, you have to have,
you have to be sufficiently big. So I'd be extremely surprised. So for example, I haven't
said this before, but I would imagine very, very small insects can't plan, whereas
something the size of a bee might be able to plan. So I'd imagine that a Drosophila couldn't plan,
but I would imagine a bee might just be able to get there. And it starts,
first of all, that immediately speaks to a philosophical vagueness in terms of that
temporal thickness, which is interesting. I mean, is it categorical? Can I say this kind of artifact
can be explained in terms of a generative model that does not cover its own action because it has
direct access to its actuators because it's sufficiently simple and small. There are no
Markov blankets that intervene between the effectively the sense making part and the,
for example, sending predictions and the predictive processing spirit down to the
actuators. Whereas this thing is so big that there are inevitably, with probability one,
so many Markov blankets intervene, there is no now direct access to action upon the world.
And so that might be a bright line. It might be a qualitative distinction between things that do
and do not have a representation of their own actions. On the other hand, the counterargument,
I think, would be this more vaguenation that even a thermostat could be construed as having
a little glimpse of the future simply because it could be cast as, say, a PID controller, which
basically invokes now rates of change. And as soon as you evoke rates of change, you've got sort of,
you know, a mathematical image of a little trajectory into the future. So it could be a great,
it could be a great thing. I've lost, I've lost the importance of your question. I'll ask you a
question again. It was probably unimportant. But this is really, sorry, I'll go again. This is
very interesting line that I'd love to dive down into. So my interpretation of this, my reading of
this, is that in a sense, having bundles of Markov blankets embedded in Markov blankets
leads to the inevitable inference that there is something like me which is doing something and
there is something that's not like me, which is also causing sensory data that I'm receiving.
That makes sense. Now, let's tie in temporality to this. Does it, does this,
does this mean that in a sense, temporality is a corollary of selfhood in the sense that
the selfhood is almost more fundamental than the temporality because it comes from
the dimensionality of the things that are Markov blankets upon Markov blankets.
And how can we integrate temporality and temporal thickness or depth into this picture?
Right. That's absolutely right. You could tell the story in a number of different ways. If you're
talking to, for example, Chris Fields or Maxwell Ramstead, they might start talking about irreducible
Markov blankets that necessarily require the notion of nested Markov blankets and that there is some
one or more core irreducible Markov blankets that would have this aspect of looking at one's own
inference processes and acting internally. And they get the notion of mental action,
you can then start to work towards sort of qualitative experiences in terms of
self-modeling and what that might look like. The other way that you could tell this story
is to know that to invoke the renormalization group if you were a physicist and just know that
when you're talking about any hierarchical generative model, there is inevitably a
coarse graining that includes time in that depth, which means very simply that the deeper parts of
my generative model and indeed viruses are on a free energy principle view.
Encoding beliefs about things that change more and more slowly as you go deeper and deeper. So
there's a separation temporal scales. So a common sensical view of this is that the neuronal
representations down near my primary auditory cortex or indeed in the brainstem are representing very,
very fast fluctuations in pressure and frequencies and sort of scenographic-like
representations that are changing your possibly even infractions of a millisecond if you're an owl.
But certainly over 100 milliseconds that I move up to sort of your primary auditory cortex and I may
be in the realm of hundreds of milliseconds and sort of frequency lines that define phonemes and
I move up to secondary auditory cortices and then through the auditory hierarchy getting to the level
of words right up to say, you know, some parts of prefrontal cortex where we've got entire semantics
and syntax and narratives and stories start to emerge and as every time we go deeper into the
hierarchy we slow down or we extend the temporal compass thereby providing a context for the faster
influences and fluctuations at the level below. So again we come to this, you know, notion of
size entailing a certain kind of depth and this is a hierarchical depth in the generative model
that as you say necessarily goes in hand in hand with a temporal depth and a separation of temporal
scales. So I think you're absolutely right there has to be a temporal aspect to deep generative
models and by deep I just mean that there are nested Markov blankets. So, you know, to define
a hierarchy is only defined in terms of the conditional independences and implicitly the
Markov blankets of one level in the hierarchy that defines it as a level in the hierarchy without
the Markov blanket the hierarchy would not be there. So that's another example of this sort of
being open but being closed and being able to individuate something from something else
and this is the thing is just the level of a hierarchical generative model that we're ascribing
to the dynamics of some internal states. I think there's a third story you could tell which is
possibly where you're going which is how it relates to consciousness. In the sense and this is a very
simple story that if I am forming beliefs and doing belief, Bayesian belief updating as prescribed
by active inference about the consequences of my actions then that has to be in the future as we
just said and perhaps certain things think deeper into the future than other things. But notice what
we've done here it's about my actions. So not only have you committed to temporality and temporal
depth and temporal thickness as an attribute of things that plan and more like you and me
but you've also committed to agency. So now you've created from something that was previously not an
agent into an agent where I'm using agency in the sense that one would not say that a thermostat
had agency but you would say that I have agency in the sense that I have beliefs about the consequences
of my action and I will or can be described as using those beliefs to select a particular action
and I'm going back to predictive coding formulations that that selection would basically
I'm going to predict the state of my multiplanet or my autonomic nervous system and provide the
right set points and then the active states will actually reflexively fulfill those
prophecies, those predictions and everything is working properly. I'll be a good alastat
or in Russian terms a good homestat. So what you've done there is bring agency into the game
and I think that again this speaks to the inactive part that you now because you've got beliefs about
the future and specifically the future that you have caused that you have authored you have now
become an agent. So we have I think got this this stage to consciousness and self-awareness
but I think we've got the necessary foundation that there are only certain things that have to be
agents I think to be conscious of themselves as agents as doing things as things that exist
in a world in the sense that their existence is manifest in terms of the consequences of
the way that they act upon that world. If it wasn't you wouldn't need any of this you wouldn't need
this temple thickness you just be you know you just need the apparatus of a stone or a thermostat
to do your sense making but as soon as you've got agency in the game I think then you've got
something which takes a step closer to having a very deep and possibly it's this irreducible
Markov blanket there of the generative model or level of a deep generative model which actually
now starts to entertain the hypothesis I am an agent which you don't need but you could
and you have to ask yourself why would you ever want to entertain the hypothesis I am an agent
so this would be minimal selfhood just a representation that I can be in different
states of mind and those states of mind are something that underwrite or I can condition
on in terms of what I am going to do and that doing could be internal it could be how I deploy
attention in terms of precision weighting in predictive occurring so it could be covert
action or it could be overt action I could now select certain plans at a lower level that would
be then enacted by my motor system or my autonomic system if I was that kind of creature does that
make sense it makes sense and it's opened up a can of worms in my head well inevitably because
we bought in lots of concepts here and I want to try and unpick them for people at home and for
myself but it's fascinating so I'm loving it so let's keep going along this along this road
we've got agency consciousness and temporality as these three things I want to have a little
look at starting with the first thing you mentioned as a response to my question about
temporality that we have a deep hierarchy in which more deeper levels of the hierarchy are
tracking slower fluctuations in the external dynamics and therefore contextualize and constrain
the higher order faster dynamics is it are we in this model are we invoking time as a fundamental
aspect of this external dynamics or is it an inference that the that the that the organism
is making about the nature of reality that it's experiencing well that's again an excellent
question it certainly does not it does not address time perception your in terms of the
psychophysics of time perception does it address time in a more fundamental sense I don't think it
does in a sort of sort of folk psychological sense it's really so the the answer to that question
normally is framed in terms of relative movements in a belief space and so if you think of time as
part of some metric space time then what you're talking about is time as something that can be
measured time that has a a distance a milliseconds or seconds or under like could me could me as
a generative model ever have access to or build hypotheses of time as a metric yes we certainly
could however it would be very difficult you're ignoring sort of internal clocks and the like
well naturally no you have to ignore internal clocks you then ask how do you do it and normally
what what the story the story is it's the the number of moves you make at one level relative
to another level of a deep generative model and the number of moves is quite crucial here in terms
of tying that down mathematically and my favorite way of thinking about the number of moves is
basically something called the information length and the information length refers back to something
we've mentioned before which is information geometry so as if you think of our so one picture
of the free energy principle it's a quite a technical picture but I think it's quite useful
is that our internal say brain states or the internal states of a thermostat
encode a probability distribution a Bayesian belief a conditional belief about some latent states
which means that for every state of the brain there is if you like a point in the state space
of all the physical states of the brain but each point in that space now stands in for a probability
distribution and that means that this is a special kind of space because it is equipped with a metric
what is that metric well it's the KL divergence well the pathological infinitesimally small KL
divergences as I move through this space so this is what this this is what defines information
geometry the information geometry is a very particular bit of mathematics or theorizing
that applies to very very special state spaces or manifolds where every point in that on that
manifold corresponds to a belief or a probability distribution so now what if the metric is the
the KL divergence or you know the information length which is related to the the accumulated
KL divergences as I move from one point to another and what we are saying is that the
the number of moves I make the number of units as measured with the this kind of metric this
information geometric measure which actually technically is this visual information is
basically a description of the precision by which I measure whether I've changed my mind
so if we say that I've made n moves that means I've changed my mind n times and I know that because
I can measure the information length and I've actually moved a significant by a significant
by a measure that is large simply because it is large in relation to the precision that
that provides the distance between any two points on this so what that means to put it very simply
is that time can be measured by the number of times I change my mind at level n in my hierarchy
divided by the number of times I change my mind at the lower level so now you've got a relational
you can gauge time by the relative degrees of belief updating your the information rate which is the
confusingly the the the rate of change of the of the length with with time but where time is now
contextualized by the level above or by the level below so you have this very relativistic view of
time and you could have different levels you know I would imagine if you you attend different
levels of your hierarchy you could get a very different kind of time perception indeed we know
the attentional set and in conditions where say taking psychedelics or in things like Parkinson's
disease where where you get changes in the neurobiological encoding upon certainty and therefore
this fish information metric you can get distortions and different senses of time
so what I'm saying is there are probably as many different
senses of time as there are levels in a hierarchical model and it can only really
be measured in a in a relative sense in terms of how many moves do I make at one level
in for any given move at another level so that what we've done now is if you like
take temporality off the table to the extent now that we're down just talking about movements in
an information space or a belief space that has this kind of information geometry these are really
fascinating issues I think yet to be fully explored my friend Zaf has done probably some of
the best work in in in this area but you know it is it is to my mind a really interesting issue
because you know it really forces you to think about the what you mean by separation temporal
scales and what we are what what kind of cost grading over time is implicit in this kind of
move from one level to to the next level does that address your what you were what you were
yeah I mean as I was saying this is all really interesting and again something I hadn't thought
of before in terms of in terms of this in terms of this contextualization process being about
moves which implies to me that there has to be it's like this sense of time is contingent on
these moves that are being done at the different levels of the hierarchy does that process itself
not imply some dynamic some temporal dynamics how can one distinguish a move of 10 relative to a
move of five without having segmented moves in some kind of space-time geometry yes it is exactly
that segmentation that appeals to the information geometry so you know how would you actually do
that segmentation how how would you measure the amount of belief updating in universal or clock
time at one level of a hierarchy and this is where the information geometry comes in it's
basically the number of different brain states that you have entertained during your movement on
this statistical manifold or which is also you know I think very nicely articulated in terms
of belief updating so you can literally think of this sort of the space that would be traced out
if I were to plot the activity of all my neurons on every axis of some very high dimensional
state space that would be a statistical manifold my belief updating which is a continuous process my
gradient flow is literally moving on this manifold the distance I move is the information length
that literally scores the degree to which I change my mind it's also mathematically the
information gain as measured well closely related to the information gain as measured by
KL divergence between my prior and my posterior after I do my belief updating and I'm moving
on this manifold and the question is you know how far have I moved and can I segment that into
units and that's basically what the information length allows you to do so I love this picture
because if you just think about what kind of flows on this manifold would be prescribed by the free
energy principle because the free energy is a functional of the beliefs encoded at each point
then the free energy is a landscape on this statistical manifold so we are perpetually
falling downhill on this manifold the free energy gradients are themselves and the free energy is
itself changing because my beliefs are changing so I've got this lovely itinerant you know model
or picture in mind where I've got a statistical manifold it is now where I have gradient flows
where I'm flowing on this manifold using a gradient flow on free energy where the free energy now
provides a waddington like landscape chasing minima all the time and of course that chasing
reflects the fact that the free energy itself changes as you move around the manifold because
your beliefs are changing and the free energy is a functional belief and then you introduce this
notion which I think is really important the notion that the high level of a deep model
provides the context and what would the context look like in terms of this free energy landscape
well it means that the landscape would change so you know I've got this gradient flow which is
from on a fast time scale just flowing down the landscape down the landscape but at the slow
level the landscape is itself now changing all the time so I'm perpetually chasing minima
and moving minima because the gradients themselves are contextualized and are changing slowly so you
get this deep structure to the temporal dynamics which has this very non-Markovian aspect so now
we've got this interesting picture where things like you and me that are big where big just means
that there are lots of Markov blankets that constitute my deep generative model that enable
this separation of time scales you've got this picture where each level is now providing the
landscape for the level below with very very fast changes but of course these are now changing the
the landscape is itself changing so that now you've got a non-Markovian model of a universe
that we know is Markovian so we know because we started if you remember right at the beginning
with this notion of a random dynamical system that is usually associated with things like
a launch van equation or you know a Markovian process and so we're starting from a Markovian
universe with effectively no memory and now we've found things inside this universe that look as if
they found a non-Markovian explanation a coarse grained sense sensible and sense making explanation
for their sensory impressions that is quintessentially non-Markovian that has this deep
temporal structure of the kind you find in language yeah the whole point of say for example
your hierarchical Dirichlet process models of natural language right through to the
current focus on transformer architectures in large language models they're all about breaking
the Markovian they're all about finding non-Markovian explanations for what at the end of the day
must be you know a Markovian process and you may ask well where does that come from well
if we spend most of our time trying to model input where that input is generated by things
like us and we are complex deep things that generate non-Markovian actions and in fact our
universe now becomes non-Markovian simply because we have other things in it that are sufficiently big
to have these deep generative models and then you go to language and communication and
you know the itinerancy which is I think quite unique to us you know I don't think you'll find
this kind of dynamics if you get too big and certainly as we've already discussed it can't
exist at a very macroscopic scale so even in your head your macromolar kills in the 16th
dendrite in the ca1 field of your left hippocampus that doesn't do any planning it's too small
it doesn't have that requisite depth of or nesting of Markov blankets
so small stuff can't do can't have this separation temporal scales and this particular
deep itinerancy and sort of your Markovian breaking like property but interestingly when you get too
big you also can't do it either so you go on the motion of the heavenly bodies the the moon and the
sun and the like they don't plan and you know it's interesting to ask well why not well because
they don't have because a lot but effective because they're so big all the random fluctuations in
their world have gone away and you now are left with classical mechanics so you know you could
sort of get termistic chaos in body problems but there wouldn't be a description that would
be usefully interpreted in terms of planning as inference or active inference in the way that
we've been talking about so I think there's a golden lox regime you've got to be big enough
but not too big to do this to do this kind of planning wow amazing yeah I mean it's
it's bringing up all of these existential potentially fluffy questions in my mind
which I I would like to sort of ask at least one which is we could ask why let's take the
macro structures the celestial bodies black hole the universe itself we could ask why why in a
mechanistic mathematical sense do they not have this kind of non-marcovian temporal horizon
so there's a mathematical answer to that which or a physical physical in the sense of being
explained by physicists there's an answer to that there isn't necessarily an existential answer to
that and I guess I do not expect a concrete answer because I'm sure there isn't one but
millennia has been dedicated to the question of the human condition and why maybe that itinerancy is
so fundamentally defining of our nature which is that we can't seem to kind of sit still we are open
and the world is affecting us so we're affecting the world as you said and we're in this constantly
dynamic coupling I guess I would love to just hear intuitive thoughts that you might have on
why the universe would unfold in such a way that you do have a goldilocks own
why why is it the case that things like us
have this wandering openness rather than just being either in the soup or being
firmly rigid forever if you have any thoughts on that
you are yet not well formed thoughts but I mean it is a fascinating thing to reflect upon
I think the answers that someone like me would give you would inherit from a
sort of a classical view of physics as opposed to a quantum information
theoretic view so you may get a very different answer if you ask somebody like
Carlo Revelli or Stephen Wolfram or you know my friend Chris Fields
but if you're happy with a sort of 101 physicists response to that the way that I would look at
that is through the lens of the renormalization group which just says that things exist at
different scales and there is a you are looking for explanations of those that scale
free behavior in terms of laws that are dynamics or Lagrangians technically
that are conserved over different levels and for the free energy principle that is just the
the dynamics the gradient flow on the free energy defined at each level or each scale
and that leads you to then a view of the same kind of things sorry the same kind of processes
and the same principles applying at each and every scale of the universe so that you would
at a very very fine time scale and a very very fine spatial scale so in the quantum scale you would
have lots of very very fast hot stones moving around where the random fluctuations predominate
and there is very little of this kind of long-term itinerancy now technically that results from
some a certain aspect of the way that you can always decompose any dynamics any gradient flow
so I've spoken about the dynamics exclusively in terms of gradient flows flowing down the
flowing down the free energy landscape say on a statistical manifold being my favorite picture of
that that denies a really another really important aspect of the flow which is the flow orthogonal
to that gradient flow known as solenoidal flow or divergence free flow so the way that I look
that I look at this through the lens of a sort of classical physicist that would predicate
everything on this random dynamical system or large one approach is that you've got a
continuum between the very small and the very big where now we're not talking so much about
sort of the degree of nesting of Markov Planckets but simply the contribution of random fluctuations
to the dynamics and the important thing to bear in mind is that there is any dynamics any flow
has this solenoidal part this conservative part and this dissipative part that inherits from the
random fluctuations so if you're very very small then all the random fluctuations have not yet
been averaged away and the dissipative part predominates over the conservative part the
solenoidal part which means that at the very very small scales you are effectively in the world of
thermodynamics where you're effectively ignoring the solenoidal part so everything is
dissipative you get fluctuation dissipation theorems you know integral fluctuation theorems
and then you can drive generalizations in the second law and all that good stuff
and then as we get bigger and bigger and bigger the course-graining implicit in the
what's known as an RG operator in the renormalization you know I look at this as a grouping and
dimensional reduction a course-graining entails an averaging and as you average the random
fluctuations average out to zero so now the dissipative part disappears and you just left
with this solenoidal flow which is just the conservative dynamics of Newtonian mechanics
and Lagrangian mechanics and the solenoidal aspect is just a description of like the moon
going around the earth and the earth going around the sun it's things that have orbits stable orbits
or quasi-periodic orbits that are approaching deterministic simply because they are very very
big so the interesting thing happens in the middle where you've got a mixture of dissipative
dynamics and conservative dynamics what would the conservative dynamics look like well they
would look like this sort of itinerant oscillation it would look like the same kind of classical
conservative oscillation that the moon does but it will be much more itinerant it'll look like
a biarrhythm it will look like a life cycle it will look it will have that property that we
associate with living movement so you know we talked before about the fact to be autonomous is
to move it is to have active states one would also argue that movement in and of itself is not
sufficient you know the moon moves the oceans move are they biotic in their self-organization
i think you've been looking now for a special kind of movement which emphasizes this solenoid
a mixture of solenoidal and dissipative uh dissipative dynamics um so sandwiched in between
the very big and the very small is a goldilocks regime where indeed you do have this opportunity
for the biotic kind of self-organization that characterizes our existence that is not only
um manifest in terms of delicately crafted solenoidal diversion three dynamics but also
nested at different timescales so just think about all the different timescales that your
body entertains solenoidal dynamics um rotational dynamics from the fast gamma oscillations again
in that hippocampal neuron through to your cardiac cycle through to your respiratory cycle through to
your diurnal cycles through to your slower cycles right through to your life cycle
and so on and so forth and then you take it up to any scale you want but the key thing the point
being made here is that not only do you have this admixture of dissipative gradient flows that
underwrites self-evidencing this is in the context of this solenoidal flow at multiple scales at
nested scales so again we come back to this sort of this deep nesting um so on that view there will
be a goldilocks regime and of course it is only at that in that regime will you ever get systems
that start to self-model and communicate and co-construct their their niches will you get
cultural niche construction will you get the kind of will you get language will you have
conversations like this it's not going to happen at the level of macromolecules or cells and it's
not going to happen at the level of heavenly bodies but it will happen at our level um
um uh and clearly has happened if i can believe my senses yeah i guess the
yes i guess the i mean my follow-up my my inevitable follow-up would be why are there
these different sizes but i don't i don't want to get into that because then it's just turtles all
the way down about why i mean we can bring it to close very quickly but that's it it is turtles
all the way down that's i think a fundamental insight uh and once you once you commit to that
everything starts to make a lot more sense so um you know just in terms of um you know how long
will my markoff blanket last where it will last you know for a long time at my temporal scale but
the um the scale above um will last much longer so i have an environment and a niche
that lasts longer than i do and my body lasts longer than anyone's cell and my cell last
lasts longer than any one intercellular component and you know that component will
last longer than any particular macromolecular configuration so uh so it is all the way down
and you need it at each level you have to have the context being a thing having its own markoff
blanket at its scale in order to um provide the context for the faster coming and going of markoff
blankets at the lower scale but in the same sense because the larger scale inherits from the dynamics
of the lower scale there's a circular causality which people like george ellis would cast in terms
of top down and bottom up causation put simply what that means is i cannot exist well but let's
put it another way my hippocampal cell cannot exist unless my brain is in good shape my brain
cannot be in good shape unless i'm doing good active inference and relating correctly within
my family in my conspecifics my conspecifics cannot work uh exist unless there is um a biosphere
that sustains that kind of life the biosphere cannot exist and and so on and so forth all the way up
and all the way down and every level there are things and those things have to have markoff
blankets and at every level they can be construed as doing some kind of elemental inference uh or
self-evidencing um the the story we're telling though is the special kind of self-evidencing
that comes out at a particular scale but the existence of that scale requires exactly the same
um repeat from the perspective of the renormalization group it requires exactly the same dynamics
or the rodent or functional form of the dynamics um at you know at every level and you know on this
view because the explanatory target or the free energy principle it's basically relational it's
trying to understand self-organization um of a thing that can be individuated um in this context
and in terms of what it is contextualizing it's a very myopic ambition it doesn't describe you know
cosmology or um you know the universe uh you're not going to get electromagnetism from the free
energy principle um um and so it doesn't really have to worry about when does this you know when
what is the largest scale what is the smallest scale you can keep on going all the way down
and if you had to hedge your bets because i guess it is a hedge better bet bet hedger rather
um does it stop does does the does is it or is it just it just goes on marco blankets on marco
blankets yes yes mathematically yes yeah there is yeah it's a little bit like you asked me uh
where's the um um where's the edge of the earth when does the earth stop you know yeah if you if
you're committed to the re-normalization group um now it just keeps on going forever um that um
and you sort of i'm quite comfortable with that because um you know it emerges from a sort of
a question which is what is a state so we've been talking glibly about state spaces statistical
manifolds and states of affairs that were named states and latent states um to have a state space
and particularly specifically to have a um a state space that could be that can be interpreted or
construed as a statistical manifold you have to have states but what where do states come from
and the argument sorry i shouldn't ask you the argument is that they are the states of things
where do things come from oh we just said it's a partition of state space
where did the states come from and if you try to answer that question um then you all you have to do
is basically um determine the mapping between um things or particles and states and the answer
is quite simple it is it is basically one way of looking at this sort of um the or using the
apparatus of the renormalization group but the state of a thing is the state of its Markov
blanket states um and then the the then that state itself now has a Markovian or a a partition into
Markov blankets so you now get blankets and blankets um and so that you can resolve the
paradox or the um the catch 22 you know what's the state of something well what's the thing well
a thing is it is determined by uh condition independence among the states you know you
can resolve that infinite regress just by saying it is just a recursion the you know states at one
level inherit the averages of the Markov blanket states of things at the next level but at every
level there are things so you have this um you know you just keep on going down I should say um
you know there are people who believe that um there is a smallest scale or it is sufficient I'm not
absolutely sure about this but if you ever get the chance in later life if you can talk to uh
again people like Carlo Rovelli or Steven Wolfram um you know from the point of view of quantum
loop gravity or from the point of view of the Ruliad um then the you know there there is this
notion that there is some irreducible um um smallness scale uh beyond which you can't go
and then the game is how do you get a continuous world out of this sort of quantum discrete um
very very small description of things yes yeah yeah yeah strange loops makes me think of
Hofstahler and strange loops also makes me think slightly of the holographic principle
what you just mentioned there about projections onto the screen um this this notion of um reading
off the Markov blanket you said something that I said we had three things that I wanted to talk about
and we covered temporality albeit over a long temporal scale I wanted to very quickly ask you
mentioned um in passing um about celestial bodies being nearly deterministic and my is pricked up um
I've on an internless model of the free energy principle I sense that there's actually a kind
of licensing for free will because we have this internal model and we act upon the world is to
confirm the model that we we wish to we wish to observe on an externalist perspective where
we really are no different from another physical entity except for the fact that we have the
possibility of moving things and and acting to to self-evidence there isn't so much space for free
will but my is pricked up when you spoke about agency and when you spoke about the celestial
bodies being nearly deterministic because it makes me think it seems to imply at least uh
heuristically that being open to the environment being an itinerant being licenses agents agency
but I want to make sure this is true metaphysical agency in the sense of not hard determinism
or whether this is agency in the sense of self-conception as a free agent because those
are two different things um it's we won't be denying that we perceive ourselves to be free
I guess the fun the more fundamental question there is whether that's an illusion or not
and so I was wondering whether free energy principle has anything to say about a kind
of libertarian versus deterministic perspective on free will um well I mean you could certainly use
the the the um the free energy principle to tell stories that speak to those arguments
and I think you picked up on some you know some of the key parts of those stories
so your deterministic chaos that you get with body problems when thinking about so
massive bodies dancing around each other um you know there is still chaos in mix in the mix
so there's an unpredictability and sensitivity to initial conditions in
the good old fashioned way of non-linear dynamical system theory of a deterministic sort
but once you get to um you know things like you and me um you're really in the world of
stochastic chaos say the stochastic bit inheriting from the the random fluctuations where you've got
two kinds of um if you like or two aspects of uncertainty and implicitly then in modeling
that uncertainty um the opportunity to talk about sort of free will and selection um one
interesting twist here is that the um if you watch you want to apply the free energy principle as a
principle of least action to things like you and me um what you have to imagine is that we are
deterministic things in a stochastic and chaotic world um so in making sense of things we only do
so at a particular scale we're talking before about the averaging away but I'm sufficiently big
to average away my random fluctuations under the free energy principle that literally means you
have to take the average of lots of neurons so the kind of sense making the kind of uh dynamics
that you would simulate under the free energy principle applies to and only to the ensemble
behavior where you can average away any of the stochastic estimates so you will not get you will
not be able to deduce evidence or um solicit or find evidence from the free energy principle by
looking at single neural or single synaptic it has to be at the the ensemble level where the the um
well there are sorts of arguments where that has to be the case but um from our point of view
it's when the random fluctuations are averaged away um so um I'm just qualifying what I'm saying
I'm not saying that the brain is stochastic or shows stochastic chaos what I'm saying is
that the brain has to provide an apt explanation or approximation um to explain stochastic chaos
um and crucially um the um stochastic chaos associated with our own behavior um with the
consequences of our own actions so you've got a deterministic system trying to now model a
non-deterministic stochastic chaotic system and and you're in so doing well that's easy to do because
of course we're talking about um that modeling being in terms of belief or probability distribution
so that's absolutely no problem um so um on that view I think you could easily motivate um free will
of a certain kind um in the sense that you when uh when you're planning you have effectively to
select amongst different models of the future technically this will be based on model selection
and selection is an act and so again we have a different kind of agency here but it has it's a
kind of agency inherent in the selection amongst competing plans or policies narratives paths to
into the future um that I think has all the space to um say that this and it's you doing the choosing
remember you can't there's nothing on the outside that can influence directly that choice on the
inside so from your point of view you certainly have free will would it look like you have free will
from the outside um um I think that's a more vexed question uh of course you'll never know but
but uh I think you'd probably you'd be in the game of of a game practically how I spend most of my
day job is inferring to what extent is this artifact or this person
um doing good um planning as inference good planning um you know for example if somebody's
in a coma or in the bedroom or asleep or has a psychiatric disorder um you know you you need
to know to what extent they are um and in what way they are self-modeling um so you know um
this is a slightly sort of clinical and abstract example but it illustrates the point that you
will never know whether something has free will all you can do is infer that they are behaving
as if they had a generative model that entailed a self-model and and thereby a model of the
consequences of action and therefore as if they were a true agent and possibly they may know they're
a true agent they may not you know they may be again um you know that would require another
level of of the Markov blanket is that what you had in mind yes I mean I think um I guess that
the kind of hardline determinist response would always be pushing you to say whether that organism
or particle could have done otherwise so it may have this reflexive quality of okay I'm doing
Bayesian model selection to my sense of self and we will come to consciousness because I think
that's the kind of crux of this issue is why is any of this happening online anyway but it might have
this self um reflexive notion of being a free agent but the hardline determinist from the kind
of external position of physics might always say well could that bundle of atoms ever have done
otherwise in terms of its Bayesian model selection but it's it's again it might just be one of the
these sort of loops that just keep spinning um yeah it's it's all um fascinating I had a question
that I've just popped out of my head when I was talking about free will which was um
I will come back to it I will come back to me um consciousness
I know it's I don't know if it's being considered I don't know if we can call it a red herring yet
in um the academic world because it's become a very hot topic um and people are getting very
heated about us and there's no need to bring up particular examples of when people have got
heated about it but people are very invested in their theories and I guess rightly so it
seems to be this one thing that people can't seem to couch within their theories of everything
if they have one do you let's starting with a very simple question do you consider it to
be a real problem do you take something like the hard problem seriously or for you is it
more of a meta question or can it all does a deflationary account just do the job in terms of
the hard problem um it really depends who I'm talking to as my friend Jeff Beck would say
it depends which pants I'm wearing so yeah I think I think very much it's it's a question of
um a conversation and you have to you have to infer how much investment the person you're
talking about has in this issue and what position they're taking um and I mean that you know just
in terms of being polite and engaging you know with integrity and scientific uh debate or indeed
philosophical debate but I also mean it uh in a slightly more fundamental way that consciousness
is is an illusion um and but and I think illusions are fantastic they're literally fantasies and I
think that's what makes our brains fantastic organs I think they're hypotheses I think the
illusion is um the thing that we uh that we test it is the thing that generates the predictions
in predictive processing so I think consciousness is another illusion um very much along the lines
that one reading of Andy Clark's basing qualia paper um that even qualitative experience qualia
are just illusions they're just things they're just constructs we bring to the table including
selfhood um they're just hypothesis illusions that are particularly apt at explaining everything
that we sense and making good sense of it as as a a parsimonious hypothesis consciousness itself I think
is exactly that because it only applies the hypothesis is that um is this thing conscious or not
only applies because there are other things in my universe that I'm trying to have to model like you
so it's the question is not whether I am conscious the question is whether you are conscious and of
course we've already said that is an answerable because you have a markoff blanket so it's an
unanswerable question but crucially it's a question about the things I observe that I'm trying to make
sense of um it only becomes I think um only in the spirit of the meta hard problem or the meta
problem um it only becomes um um vexed when you make the mistake of asking am I conscious
I don't think that's what the question is there for that's the illusion is not for me
it's for you the illusion is the consciousness is a construct hypothesis and a very plausible one
all the evidence that I have at hand would suggest that you are conscious and indeed literally
because there is that evidence it is there in the sense of an evidence maximizing illusion
hypothesis or component of my generative model so I I go through that just to make it clear that
the answer depends upon who you're talking to but also who you're trying to ascribe consciousness
so if I was talking to um
well if I was talking to um people like Jacob Howie um you know the first thing he'd say is
that the free energy principle is not a theory of consciousness and in fact he's like saying that
every at every opportunity so there's nothing there's nothing um there's nothing in the free
energy principle that has anything explicit to say about consciousness on the other hand
people have used it in different ways to address the hard problem um uh you could take the view
that Andy Clark takes that there isn't a hard problem and perhaps even with David Chalmers's
work recently on the meta problem the meta problem that's from your more interesting problem
um or you could you could grasp the the nettle and start to talk about it if you were talking to
my colleagues Chris Frith and um and um Adam Saffron and Maxwell Ramstead and
and uh oh oh this and that um certainly um so I think inspired uh by something that you mentioned
earlier on which was the holographic principle in um in quantum information theory where the
holographic screen now plays a role of of the Markov blanket that separates the inside and the
outside in terms of bulk reading and writing to um the um the um the holographic screen um
if you're talking to him um then he would start to talk about these minimal screens these minimal
Markov blankets um and develop quite a quite a sort of nice argument that if you can't reduce
in the sense that we're talking about nested Markov blankets inside a Markov blanket
if there are no more reductions at hand then the only way that the internal states of that
irreducible Markov blanket can know about their own existence is by acting upon lower levels
and therefore there's some um there's something unique that there exists a unique Markov blanket
that that your um maybe um um have the attribute of of consciousness um if you're talking to something
like Vanier Weiss um um he would you know tackle this in terms of um trying to resolve
uh a dualistic position by offering a dual aspect monism um of a Markovian sort
and that rests very heavily upon this information geometry so if you remember before we're talking
about sort of a state space equipped with free energy functionals um on it um um that um plays
a role of a cisco manifold but but there are two cisco manifolds that are jointly sit up sit in this
in the same state space of say neural activity one is that for any given point there is a
probability of being there from a point of view of neural activity and the thermodynamics
so this would be a thermodynamic um kind of information geometry and then the other one
is what the free energy principle uses which is the encode using that point to encode beliefs about
external states so you've got two um information geometries belief structures if you like um that's
super been on exactly the same um material um process one of which is pertains to probability
distributions or beliefs about the internal states and the other one is probability distributions
or beliefs encoded by the internal states about the external states so you could constrain one
as being the mental and one as being the material and then you've got this dual aspect monism where
you're now asking questions about or what are the lawful relationships between the thermodynamic
free energy and the um the um the variational free energy that pertains to beliefs about things
so you've got now a mechanics that talks about beliefs and that may well be one way of repairing
that sort of a dualistic approach and there's another another perspective which you would get
if you were talking to talking to people like um uh julio tenoni and um cereal um well my colleagues
involved in one of the templeton foundation abyssal research collaborations um where you're
trying to find bright lines between the free energy principle and integrated information theory
which is not necessarily the best thing to do because a lot of integrated information theories
exactly conciliate with the free energy principle however if you are going to get funding by
trying to tease them apart then the thing that distinguishes those approaches to
consciousness is really the the active part that we're talking about so uh boiling this down
in a way that something like I repeat jakob how it might might articulate this is it's the
difference between seeing and looking you know to be conscious I have to look it's not enough to see
um it's um you know to be conscious I have to listen it's not enough to hear
so you're putting action into games as active sensing this in this sort of closing the the
loop between the inside and the outside maybe um the thing that um is necessary for consciousness
and simply because you're saying that consciousness is an attribute of agents
and agents have to act what do they act on their sensations what does that mean the they do active
sensing so to be an agent is to be an active sensor yes to do active inference um and you know
if you're saying that things that aren't agents can be conscious then you wouldn't worry about that
but if you are committed to a deep um to the notion that to be conscious um of to have a minimal
selfhood um then you have to have the notion of self if you have to have the notion of self then
you have to be an agent if you have to be an agent you have to um have generative models about the
consequences of your agency your actions uh and that has to have the temp and then we go through
the all of those nice links that we've talked about before with temporality and you know and the
like and indeed the hierarchical structure takes us back to the chris fields um irreducible um
holographic screen or or um or markoff blanket so that would be the way that i would um converse
with that crowd uh and i've run out yes i've run out of people that i might talk about it
uh so i have to find out what you like and then i'd i'd tell a story that you like let you tell
a story that that you like well i guess my question to you would be can you imagine a world
of self-evidencing can you imagine okay let's put it another way can you imagine a perfect
replica world like ours where the lights are turned off entirely there is no consciousness
or is it do you imagine it's a necessary uh consequence of the way that creatures are like
like us are structured that to do deep temporal planning to do planning as inference whatever
it is or self-hooding we need consciousness could there be another way the universe would have
unfolded without us being online um i suspect not um sorry i i'm i'm torn between um um been taken
by you down sort of your philosophical zombie roots versus um another um story that comes out
in a free energy principle about consciousness which is um the um the the the the importance of
self-modeling in relation to other modeling and the fact that we are actually living in a world
of things like us so and one story i didn't cover which is a story you would tell if you
were talking to um my friend chris fifth or people who are much more interested in the sort of social
neuroscience and uh or say attachment theory um and you know neurodevelopmental issues um that are
induced by a sort of evolutionary psychology view or niche construction for example all of these
views of consciousness means that consciousness is just there um which is where i started to infer
um the state the disposition the intentions state of mind of somebody else um why and how can you
do that well you can only do that if that thing is sufficiently like you to be able to use your
generative model um as obviously your physical actions as a model of their physical actions
to infer their intentions and the like um and when one takes that to its limit then um often
what the real problem is is not in terms of inferring the content of some communication or some
um exchange of of um semiotic cues it really is inference about agency again it's did you do that
or did i do that so that ambiguity now requires you to have a model of self versus other so it's
a much more relational um um notion of self so you know sometimes i think people talk about
minimal selfhood um as something which is monolithic i don't think that's necessary as
part of generative model it certainly would be important to have um different um different kinds
of self you know am i embarrassed am i in love you know as we were talking about in you know in the
tmb meeting a few days ago um that would be you know an expressive and very necessary part of
generative model where i have to contextualize my own emotional and pre-social and or autonomic
and motoric behaviors um but there's no one self it's his self you know self like this like this
like this a more fundamental relationship relational aspect of selfhood is in relation to
otherhood you know mom um you know versus me and am i mum or is your um is is mother thing
am i a thing i'm the same thing as mum as you know he's going to sort of climb in um uh um so
arguments there so put simply what that means is it may well be only in universes or worlds
that are populated by ensembles of conspecifics that are sufficiently similar would you need
to selfhood simply to distinguish itself from other in a universe where there's only me i wouldn't
need selfhood so it would not be it would not pay its way in terms of model complexity or model
evidence to have the notion of me being a self if there's only me it only pays its way if i now
have to actually entertain the hypothesis that either i caused that or you caused that
so the question now is is it inevitable that you get a universe with lots of similar things
emerging all disambiguating themselves or attributing agency to themselves in the golden
uh in the golden zone i think it probably is i think that would be i think if you simulated
sufficiently accurately artificial life i think you would you would get the emergence of
populations of similar things and they would niche construct and they would thereby drive their own
um so nest increasingly nested and structurally complicated um only sparsely structured
organizations in terms of their Markov blankets um and this would um this at some point would
inevitably invoke um modeling of others and therefore almost by default um a a minimal notion
of uh of self of selfhood i think that would be emergent you know um but it would require being
in the Goldilocks regime for a sufficient amount of time for this kind of niche construction uh
culturally construction to actually play out so you know you'd have to have this very slow
timescale providing the right kind of context for this this kind of thing to uh thing to emerge
yeah yeah i think my what i have some i think i have some sympathies to the to the argument that
charmers were laid out in or did lay out in 95 in his original hard problem paper which is that
i think i can still ask the further question which is can systems like me make the functional
distinction between myself and others without there being a sense of what it's like to be me
can that just be an offline-ness which is done purely in some algorithmic manner which need not
involve some qualia of my self-ness so yeah there's a point that there's an element in me
where i don't want to say that that in a sense resolves the hard problem because at least i can
hypothetically envision that being done offline um i wonder whether you've given much thought to
mark soames's idea which is that consciousness might be rooted in affect because this seems to
mean to be a bit more of a self-confirming idea which is that feelings must be felt now i think
there's still an open question there which is affect arises at the point of uncertainty
and drives us to resolve uncertainty and when we do so we feel good about ourselves now again
i still think i when i was reading his book i still had this open question well why would that
have to why would why would affect even emerge in that place why wouldn't we just have this drive
to resolve that uncertainty without there being the online-ness so at least for me
although i may be wrong and i'm very happy to be wrong there is still no simple parsimonious
explanation which can get around this um this point that charmers makes which is you can give
me the function but you still you can't give me the explanatory power why it needs to be online
um and i wonder if there ever will be some mechanism which is sufficiently
which isn't just purely tautological or invokes consciousness as some fundamental reality
which makes me which makes me wonder whether you've heard of donald hoffman
whether you're familiar with his work because i sense that in some ways it has some interesting
implications maybe for the free energy principle in the sense of space and time not being fundamental
units of reality we've been speaking a little bit about how um where do space and time come from
how much do space and time overlap in the sense of generating um like we need
expanse expansive creatures like us with embedded mark of blankets inevitably have
a sense of temporal remodeling and there's these interesting interactions does the idea of space
and time being what he would say applications on a desktop does that have any real do you sense
has any real ontological implications for free energy principle or is it a red herring
um well you've introduced two important things i forgot to mention mark so is another friend
so i would say it's all about this irreducible mark of blanket that acts upon the rest of the
brain whereas that action it's going to be in the neuromodulator systems that set the precision
the precision is exactly that fissure metric which tells you about how much you're updating your
beliefs it is the way that you do mental action it is as you intimated um feeling in the sense
that it is quintessentially balanced by increasing or decreasing the precision or uncertainty
so um that's how i would tie in mark's um formulation to which i think is internally
consistent with um say chris fields formulation or um of anus formulation so mark so uh focuses
you know on those i think a key aspect of um of active inference which is uh if you're a
psychologist it will be attention it's basically acting in a way on the inside to um get the an
estimate and deploy the right confidence or the right precision in um um mathematically the curvature
of the of the um the free energy in and of itself um getting that right um and um that has a lovely
you know connection to attention it means that you can't divorce um consciousness from attention
you can't divorce it from agency in the sense of mental action or internal action
you now have a deep connection to um thomas metzinger's um their distinction between
you know um opaque and phenomenal transparency um and uh and the way that mark would tell the story
would be that this is just feeling and feeling is at the heart of of any qualitative experience
so yeah thank you for the for reminding me he was one person i forgot to cover
the the second thing um you know the the space and time being illusions um i mean yeah i sort of
start off there so i i'm not quite sure that it so if you're saying that dolls um and i should
say he's a friend i think i've never met him but i think he's a friend of chris fielder mike levin
so yeah there's a small world here um but if you're just saying that um space and time are
illusions in the sense that we would talk about illusions as being fantastic and the thing that
makes us into fantastic little beings and have beings and um and our brain into a fantastic
organ yeah absolutely i mean you know the question for me is why on earth would you um what what
must be the case for us to have this illusion of spacetime and that we are living in a metric space
and it's practically very important i mean a lot of people spend a lot of time in machine learning
in bedding things in metric spaces um and sometimes it's very difficult to see what
licenses there to do that uh you can certainly see how it would work in terms of projective
geometries in metric spaces um but the deep question is why you know you know i can't um
i can't imagine a um you know uh an amoeba really having having a notion of space um i may be wrong
and so knows um um you know if you listen to people like um um steven warfram um you know
the notion of spacetime um itself may the illusion of spacetime itself may be just an artifact of
the fact that our sensory organs respond very very slowly in relation to the speed of light
so if light traveled very very slowly imagine a world in which um um we saw with sound and sound
was very very very slow um would that would that be would that give you the illusion of space um
you know and distance as an action of the kind that you know we sort of implicitly assume when
we're talking about sort of visual objects so i think he has this nice notion that you know in
this kind of world um with these kinds of sense organs um you know when something moves from here
to here is it the same thing anymore because that's what you're saying when you have a metric space
in which objects move um you know some certain symmetries or variances are inherited from the
notion of movement in a metric space but that may well just be be be a fantasy we've gone off
qualitative experience in the hard problem yeah well no i mean by the way it all ties back it's
a beautiful it's a very good question which is why would this why would space and time be a
an in the interface for us i guess that is the deep question um and yet it appears that at least
it it is something at least in conscious awareness i did remember my question and it
actually feeds into the last couple of questions i will have which is you mentioned um that you
spend a lot of your time inferring in the technical and layman sense whether other people have i think
you say good generative models there's an interesting question here i think which which
i may have had intuitively when i started reading about active inference which is is there any such
thing as good self-evidencing in the sense that i may so so a loss of of course you know as you wrote
a lot of papers a lot of psychiatric disorders and psychological disorders have been rooted in
disruptions to precision weighting mechanisms for example can we consider are the words good
bad optimal suboptimal are these useful terms in this context or is it that that individual
has a set of priors which are different from you and i and everyone else and we all actually have
a sense of we all have kind of different priors so all self-evidencing in unique ways and yet
philosophical vagueness allows us to clump us together into a group is there such a thing as
what it is to be a good self-evidence as a human with beyond beyond just a trivial point that we're
not just dissipating into the the heat bath yeah that's an excellent question um so i i think the
answer to that is yes um but as you correctly pointed out they should be qualified by the the
complete class there so you're clearly referred to the complete class so it might be just wise to
um just define what that means and the implications for discussions of good and bad
generative models so the complete class in the way i like to summarize it is that for any given
pair of behaviors and loss functions there exists some priors that render your behavior
base optimal which means that there is always a description of every behavior as base optimal
under some priors so in that sense you can't be good or bad where the thing is basically your
decisions because this inherits from basic decision theory so it's not quite full as
active inference in accommodating information game but within the within the confines of
basic decision theory you can't be you can't be good or bad you just have different priors so
my favorite example is that you know if we were all went to live on um on mars or a much heavier
planet people with Parkinson's disease will probably be much better have better priors
sub-personal priors in terms of dopamine deficits because you know they move more slowly and then
sort of more more cautiously yeah so you know i think from the point of view of the complete
class so i think it's important to bear that in mind you know there are just different priors
but i i do think that you can so just say well hang on a second what about well they're good
and bad prize and i think then we get into this again this hierarchical story because of course
as soon as you have a hierarchical generative model there are no prize you know everything's an
empirical prime everything can be contextualized everything is conditioned for everything else
including your prize and then you're just back into the um into the game of self-evidencing
what is good self-evidencing it's achieving a higher martinal likelihood or model evidence
how would you do that by finding the right priors how would you do that by learning how would you
do that by changing your model with basic model selection or structural learning how would you
do that at an evolutionary scale you do basic model selection with natural selection so yeah
on that view the log evidence as bounded by the free energy
is just adaptive fitness is how well your priors are adapted to this world you are trying to explain
so i think yes absolutely you can you can you can be a good self-evidencer you can be a bad
self-evidencer if you're in natural selection that matters because if you're a bad self-evidencer
that means you won't be around in the in the next generation so the marginal likelihood if you
existing at an evolutionary timescale is low so the your your evidence is also the probability
that you will be found exist you will exist so it's quite important to get to be a good self-evidencer
and because that's your marginal likelihood of existing and i've now slipped in another
synonym for free energy beyond prediction weighted prediction errors or beyond surprise or surprise
or self-information beyond log evidence it's also it's just it's called the log marginal likelihood
it's the the likelihood of your sensory exchanges with your world your eco niche having marginalized
out or averaged away all the unknowns which in this context are all the states out there
you know the hidden causes or the sorry the external states which you model in terms of hidden
in terms of hidden causes so yeah i think it's very important to be good at bad at evidencing
the measure of goodness and badness is just the marginal likelihood of the moral evidence
and the free energy there is nothing else if you're saying does that speak to
some creatures that will be able to actually assess how good they are at self-evidencing
then you see absolutely people like Mattias Joffily looked at this specifically from the
point of view of emotion and developed a whole taxonomy of emotion in terms of
rates of change of free energy and you're going to stories of slope chasing
looking for gradients and gradients and gradients of self-evidencing on the measurement of the
goodness of self-evidencing which is which is which is the free energy and more refined stories
more recent stories would basically be looking at certain kinds of uncertainty being encoded
explicitly in your generative model as underlying affect particularly the the you know the certainty
about what you want to do next for example then we get back to the story that Mark Somes would like
to tell which is the precision of your beliefs is the most you know the most important attribute
that defines you know its valence and that you're you're feeling at this sort of minimal
effective level yeah yeah the complete classroom is an interesting one because
I think it leads people it leads one into a potential these potential strange conclusions
it makes me think of animals that commit suicide oddly so I think sort of
aphids might explode themselves in the context of a predator it ultimately comes back down to
your model evidence I guess so I am the type of creature that will commit suicide if I'm in
the presence of a ladybug of course but then those kinds of examples I sense for me
show that the words good or bad I'm just pushing a little bit back just intuitively
the words good or back in in in the form of continued existence slightly put the cart before
the horse because who said that that's the imperative so if I existed in the world and my
everyone's imperative was to no longer exist you know god forbid then that then I would be doing
bad self-evidencing on that standard if I didn't if I continued to persist so is there a point at
which even the yeah like do you see how well do you see that argument holding any water
or is it just now we're just so dissolving into semantics
well no no I think I think it's an interesting thing to to contemplate
you're you're you're basically I think undermining that particular argument by
a proof abduct to absurd them so if you think you are the kind of thing that will
self-destruct or to evite or commit suicide then you can't exist because you killed yourself
so I will be extremely surprised if there were any common natural
subhuman artifacts that kill themselves I didn't know about the avid example I'm very I mean
obviously Lemmings is the sort of popular culture one but I think they were extremely rare
and then you have to understand the selection at an evolutionary or transgenerational level
in order to apply the free energy principle but in you know I think you're absolutely right
I'm very mindful that a couple weeks ago I was asked to review a paper applying active
influence to suicide and it was a very artful paper and I do remember thinking not to show
whether the point was made implicitly or explicitly in the paper but you know it's it made me think
in the exact other way that you were you were talking about you know the imperatives to survive
and are they the right way to think about the causes of our behavior and I would say absolutely
no not this is not about wanting to survive this is simply wanting to avoid uncharacteristic
sensations and then we put up post hoc hypothesis oh that's because I want to survive then right
and that's a fantasy that's another illusion so you know we do not know what it is like to be dead
so yes it cannot be a but it can be surprising but it certainly can't be the kind of surprise that
you'd register in terms of a free energy so it's not that we're frightened of being dead
we are going to avoid by these pragmatic constraints states that we've have inherited
that portend cessation and dissipation and death death in or itself is not at all frightening
we've got to sleep every every you know suspension of God is going to sleep every every night so you
know I I would I would sorry yeah and the final point I think is I think what you were doing though
you were probably creating a slightly vexed and self-defeating argument by saying by assuming that
we can understand things in terms of imperatives the whole point of the free energy principle is
there aren't any imperatives this is where it starts things that exist must behave like this
and part of that behaving like this means that you can interpret them as optimizing something
and complying with imperatives but that's just an interpretation you'll bring to the table when
you apply to something else if you then apply it to yourself then you know then things might get
interesting you might have hard problems but there are no imperatives you know in fact even
minimizing free energy is not an imperative you can have the free energy principle applying to
things that have very dissipated dissipated attracting sets that have very very high entropy
all it's saying is that there has to be a certain gradient flow that counters the random fluctuations
then you ask yourself well hang on a second so why does it look as if we're always trying to
attain some very precise homeostasis and the free energy principle will return that on its head
and say well look okay in some universes there may be very precise things and these precise things
what would they look like oh it would look as if they were trying that they had aspirations to
evincing a very precise homeostasis and indeed hella stasis so you get this notion of another
kind of natural thing which are precise things and so if precise things exist it would look as if
they're they are compelled to comply to very specific imperatives but from the free energy
point of view it's not saying they exist because they comply with the imperative it's saying existence
implies it looks as if they have this imperative right now and one final point you know I'm aware
that we've we've now approached in three hours well final point though I've you introduced the word
optimization I think that was the right and important thing to introduce because you know
it's only when you bring free energy into the game as a bound on marginal likelihood or self
the negative block marginal likelihood with the self-information or surprise or surprise or
do you convert an existential description into an optimization problem so that's exactly the
move that Richard Feynman made when he introduced variation free energy he had this impossible
marginalization problem that to actually evaluate the marginal likelihood of paths so exactly the
same kind of problem that we talked about in terms of what am I priors over policies and plans and
paths into the future you can't you can't evaluate that exhaustively analytically and practically
physically not realizable so the marginalization problem the true inference problem if you like
the true existential problem if there is one and cannot be solved but what you can do is
introduce this bound and turn it into an optimization problem so just by using free energy
or just by appealing to this teleology that comes from predicate anything on this evidence
lower bound you are actually saying that it looks as if creatures that exist are optimizing
something what does it look as what are they optimizing it looks as if they're optimizing
a bound on their marginal likelihood or their adaptive fitness what does that look like where
it looks exactly like Bayesian inference or if you talk to somebody machine learning it would look
as if you're optimizing your negative variation free energy known as an elbow so this is an
evidence lower bound it is exactly objective function used in sort of high-end neural networks
like variation autoencoders so you know I think that the distinction between just being and optimizing
is quite crucial and you're absolutely right that once you make the move
of framing things in terms of variational bounds using variational calculus or variational Bayes
then you have actually committed to an optimization narrative
you don't didn't have to just to exist your you could
yes yeah I was going to have this funky philosophical argument about
needing to exist to predict but I won't go there I won't go there because we are going to wrap up
all of this philosophical mathematical thoughts and consciousness thoughts has brought to my
mind Thomas Nagel Thomas Nagel has this idea that death is bad because life is inherently good
and we've been talking about life and being and what it is to be and what one needs to do to be
and persist to be if we're going to wrap everything up is there a sense in which that kind of related
to what we were just talking about in terms of imperatives of course there is no imperative to
be in any sense but you said it was an interesting thing you said there was it looks like we are all
being anyway right even if we didn't have to it looks like we are there's no god
granted plan for us to be but we seem to be doing it anyway does any of Nagel's
romantic philosophical idea that life is fundamentally good being is good does any
of that resonate with you yes it does because it's it's it's you know it's nice isn't it
and I think you'd probably you'd probably sort of license that with with phrases of the kind
that you know to exist is to be curious so this speaks to this sort of you know the ability to
respond to epistemic affordances and certainly you know to exist as curious creatures is obviously
the good way to exist in your in any given world and it's your would be mandated I can't resist
saying though of course this only really applies to you it doesn't apply to me so you are good
because you are curious and you exist I wish I could say the same for me but I can't strictly
speaking but you could if you wanted to I could I could abstract to you it's up the
great I can infer that there is a you great um and then I guess we can wrap it up there with
one more question we've just spoken about life being good I'll flip the question I don't think
I've ever heard you talk about death although we briefly touched upon it I won't make it too
personal but if life is kind of good in some sense because of the concomitant parts of
living as we do as I don't know if it's good to be a stone but it's nice to be me having these
conversations would that make death bad is there is there is there is you said we fear dying because
we fear in an affective sense um that which we don't expect to the states we don't expect to embody
and in some sense we don't expect to embody death because it doesn't fit in with our priors
but beyond that free energy principle perspective is there a broader position in which
just returning back to the fabric of the universe is bad is there something to say about
reentering that mark of blanket does do my mark of blankets dissipate um what does that process
look like and does that strike fear in you or strike awe um well more awe but I don't want to
overstate it um so it is it is beautiful um from a from a pure mathematical point of view um so I
I have a very sanguine view of this and we've already said you know you've never been dead I've
never been dead so no one can tell me it's an unpleasant experience um so I I'm not particularly
I'm not going to um avoid being dead I certainly think all the all the paths to being dead are
probably very surprising and unpleasant so I'm going to avoid those um death in and of itself I don't
think is uh is is sort of um quintessentially bad um in the same way that um natal being curious
and being engaged with the world is a good is it is good while you exist um um I think that's
perfectly okay but I think death is you know um the the life cycle that's kind of a life cycle that
that it's slightly less um um viewed with um morbidity um the life cycle is is is quite important
because um if you just look at um if you just take this um multi-scale um um view of um self
organization cast in terms of this Bayesian mechanics um the you know for example natural
selection being Bayesian model selection um then um if you put that together with what we're talking
about before about um ecosystems and niche construction constantly changing the lived world
then what you need to do is to do constant Bayesian model selection um in order to get
the right structures very much in the spirit that we talked about before where there are good
priors and there are bad priors in the sense of the marginal lighted or adaptive fitness
to learn those good priors you sometimes have to start from scratch again um with a different
structure and of course this is exactly what Bayesian model selection does by structure
learning at an evolutionary timescale will entail death so that picture basically says that we have
to keep keep refreshing sort of sometimes cast in terms of Bayes optimal forgetting so the fact
that we die our base is could be construed as a Bayes optimal forgetting where we are the environment's
memory of what is good for this eco niche but the environment on this natural selection knows
that the environment is changing so what was good last generation will not necessarily be good for
the subsequent generation so it has to forget in the same way that you learn by forgetting you
have insights by dispensing with redundant information so in a sense death for in that
life cycle is an essential part of um uh of the self-evident of the species so it may be
bad for you I suppose you know in a natal-esque sense in that it's denying the opportunity
to be curious and engaged with the olive world but it's certainly good for your children and
your children's children right right right I'm a I'm a forewarning for them that's good
I'm glad I'm glad to be that pawn in that game and a kind of cheery note on which to end
will be a slightly more morbid question Carl this was an absolute pleasure
despite the occasional wi-fi hiccup I think it's um it's gone you know I've been incredibly happy
with it thank you so much for being our first guest um and answering my suite of sometimes
questions it was a real joy on my part right well it was been a real pleasure talking to you
your questions were excellent I have no idea how long you're gonna have to spend editing all this
I thank you again for that opportunity to uh you know to talk about these wonderful issues
and hopefully we'll do it again excellent thank you
