I think just in this sense of I mean persisting through time. And the notion that allows for this
thing to act as it persists through time is Markup Lankett. So Markup Lankett is one of the most
essential ingredients of the high road approach to active inference and that's why this section opens
up with describing how Markup Lankett allows to describe the situation of interest through this
conceptual and mathematical tool. But one thing that I always point out in almost all our
textbook cohorts is in this section it doesn't I mean exactly describe Markup Lankett
rigorously enough in terms of its carving up the I mean state space and so on. So
one thing I think is can be clarifying in following all the discussions around Markup Lankett
is to keep in mind that it's just a boundary in the state space so it's not necessarily
spatial temporal boundary. Although in many cases it manifests itself as spatial temporal
boundary such as the I don't know cell membranes or organelle organelle membranes and so on but
it's not necessarily the case. So I think it can be helpful to keep that in mind when we
everywhere we see Markup Lankett. But in a very simply Markup Lankett is what allows for the agent
or the system to be statistically separated from its environment as is shown here in figure 3.1.
So basically Markup Lankett mathematically is just the I mean the sensory and active states together.
It consists of both of those states and it statistically separates what happened externally
or internally from each other. So in other words internal states cannot observe or infer anything
about the external states directly but only through the Markup Lankett. And that's why it's
essential to describe the systems in this way because obviously in any sparse coupled systems
there isn't a possibility to observe the external states directly but only through
those sensory and active states. And one other thing that I also believe can be a bit confusing
in this picture is that yes typo in the active states and sensory states because it's important
to observe that active state only or the flow in the active states more precisely
only depends on internal and Markup states or Lankett states. And on the other hand
in sensory states only depend on the external and Lankett states. So mu and x in those two
equations should be exchanged. Yes. Let me just unpack this before we continue.
Yes. So this is what's known as the particular partition and that terminology was brought to
the fore by Carl Friston's famous monograph in 2019. And it's a little bit of a pun. It's a
particular partition because this is just one way to partition agent from environment figure from
ground. And we call what it partitions out the blankets and internal states as the particle.
So we can think about the most inert least cognitive particle is like a speck of dust
doing Brownian diffusion. But also there are more sophisticated kinds of cognitive particles
that can include world models counterfactuals. What would happen if I did this all of those kinds
of sophisticated cognitive operations that we can explore in active inference. So note the small
typo that Ali mentioned internal states and also these edges reflect causal possibilities amongst
internal external and blanket states blanket constituting the active you and sensory why
states. So these are map not territory. This is not a spatio temporal articulation. These are like
causal maps of the world that may have to do with spatial temporal boundaries but are not simply that
and sensory data or sensory states flow on to internal states. Internal states are involved
in action selection resulting in active states which have some causal consequence in the world.
The generative process the external states which results in different sensory states coming in
again. And so the Markov blanket is what makes the internal and the external states conditionally
independent and that can be thought of as just a no telekinesis no telepathy clause. The only way
the information comes across internal and external states which are symmetrical with
each other is through the boundary or the holographic screen or the Markov blanket.
You can continue on Ali. Okay so the next section is about surprise minimization and
self evidencing. So again this term self evidencing is a common term in active inference literature
first proposed by Jacob Howie. So basically it refers to how a system or agent or in other words
particular state can gather the evidence for its self persistence or self existence through time. In
other words by inferring the state of the environment and comparing that inference with its internal
states or in other words with its generative model it's basically a way I mean an interpretation
of that that kind of inference is on the one hand there is this dynamical interaction between the
internal and external state but we can somehow interpret that physical dynamics as engaging
in the active inference or as a model for the persistence of the agent through time. So that's
basically what refers to as self evidencing and then we go through the subsection 3.3.1
which sets the stage for the recent formulation of active inference
as in mechanics which is to somehow to interpret the active surprise minimization
as minimizing the action through the Hamiltonian principle of least action which is a
variational principle and by variational principle is what is meant here is just a computational
mathematical tool that allows for the computation or the derivative the I mean specific derivations
to happen so it's not identical to scientific theories or scientific I don't know facts or
observations it's just a tool a principle mathematical tool so again one of the main
misconceptions about free energy principle is that it is unfalsifiable obviously if we see it in
this way it doesn't make sense to say that a mathematical tool or principle is unfalsifiable
because it doesn't say anything about the empirical evidence of the phenomena we're talking about so
that's why here it's important to understand how the surprise minimization can be seen as this kind
of variational principle and then equation equation 3.1 draws the parallel between
the surprising as defined in section in chapter 2 sorry and this chapter so it kind of ties up
all the arguments provided in the previous chapter with this one and how everything comes together
in a single formulation of active inference but there are just the two distinct approaches to
arrive at same destination and then we go also sorry the other important equation and again
another key equation here is equation 3.2 which is a kind of sorry
yes equation I meant to say equation 3.2 not equation 3.1 sorry my bad so yes
the other section is about the relations between inference cognition and stochastic dynamics as
I mean all the previous discussions around how the active inference can be seen as a kind of
self-evidencing through the variational principle such as FEP comes together to
reframe the previous discussions we saw in chapter 2 about perception as inference and action as
inference and to see the concepts of variational free energy and expected free energy through the
lens of variational free energy variational principle of least action so it unifies nicely all the
material from chapters 2 and 3 into something that I mean not necessarily distinct from each other
but just two sides of it. Awesome yeah I find table 3.1 to be very exciting it draws together
statistical physics, Bayesian information, information theory and cognitive interpretations
so it's kind of like learn one thing learn many things statistical physics has been talking about
minimization of variational free energy for a long time and such methods are absolutely every day
and professionalized in Bayesian statistics active inference is using exactly just that
to describe perception and action and so on so that's very exciting box 3.2 describes
free energy in statistical physics and active inference I sometimes joke that we have a few
kinds of free energy we have tesla like electrical power should be available to everybody for no
cost we're not talking about that right now there's Gibbs free energy which is the quantity
that makes chemical or thermochemical reactions irreversible like the hydrolysis of ATP
and when we're talking about variational free energy we're talking about an information
geometric space with similar dynamics similar kinetics and thermodynamics but rather than
describing the reaction coordinates of a chemical reaction we're thinking about it in terms of
Bayesian updating and this is all called the Bayesian mechanics
3.41 continues on with variational free energy 3.42 goes into expected free energy so we see
this a lot f variational free energy that's the real time unfolding sensory flow and then g
expected free energy and the policy planning as inference
section 3.5 concludes with a novel foundation active inference to understand behavior and
cognition and it describes a few features of active inference including its distinguishing
features from a few other ways that people have looked at behavior and cybernetics
section 3.6 goes into a bit more detail on models policies and trajectories
having to do with agency and policy selection 3.7 reconciliation of inactive cybernetic
and predictive theories under active inference again the exact kind of thing that there's a
whole literature on and it's always amazing to hear everybody's perspective on in the textbook
groups 3.8 active inference from the emergence of life to agency and 3.9 summary you want to
just give any other thoughts that you have on chapter 3 again it's one of the probably most
fundamental chapters and I mean the topics covered in this chapter is
essential or absolutely essential to understand everything active inference related but
specifically the discussions in section 3.7 3.6 onward again I believe is really important
to understand the broader context of active inference and how it relates to
all the other theories but specifically section 3.8 provides a nice view of how we can
use the same modeling to the same theoretical tools to model both
non-living dynamical systems or sparse couple dynamical stochastic systems and also to
the systems that has agency or sentience so it's a much broader theoretical framework that
doesn't restrict itself to only particular kinds of systems or agents and we'll see
much more elaboration on that in the later
wonderful all right that concludes our overview on chapter 3 now we're going to skip to chapter 6
so again this live stream is just providing some materials on chapters 1 2 3 and 6 eventually
we're going to get to all chapters and version them and have as many of you as wants join into
the process of constructing these but this is also that our textbook groups can be really
interactive and people can show up having listened to these background and context videos
all right so now we are in chapter 6 a recipe for designing active inference models
Abraham Lincoln give me six hours to chop down a tree and I will spend the first four sharpening
the axe all right Ali what does the quote mean and please lead us into this discussion
okay so as the opening quotation suggests it's about honing the skill set and skill set for
applying active inference framework to model the actual empirical situations that we want to
we may use active inference for and it frames it as a four step recipe to actually do this kind of
model although it's turned this recipe but I believe it's more like a guideline and it's not like I
don't know cooking recipe that needs to be needs to be observed strictly so it's more like suggestions
or guidelines to begin to apply active inference framework in any kind of situation we'd like so
section 6.2 outlines those four steps so the first step is which system are we modeling
in terms of how we can define the markup blanket that most effectively and efficiently
the problem or question we want to explore through that modeling through the modeling
of that situation so first step is about defining those boundaries through markup
blanket and the second step is about what's the most appropriate form for the generator model
because obviously we can have many different types of generative models depending on again
what phenomenon or what questions we're trying to address this the third stage is
how to set up the generator model so after settling upon the type of the generator model
we want to use we can talk about the details of the generator model and how it can be efficiently
model to be both tractable and also useful to address the situation of interest and finally
how to set up the generative process so as we saw in chapter two there's an important
but slight distinction between generative process and generative model so they're not always the
same but they're closely related to each other generator process to the hidden states of the
external world and generator model is how the agent infer about those hidden states
provided by generator process so considering that the environment is always very complex to
be modeled precisely and exactly with every parameter accounted for we need to have
a restricted set of parameters to account for in the generator process so that's what
stage four deals for deals about so all of these steps even if not
observed or followed sequentially are really I mean essential to setting up I mean or the
initial setup of the situation we're trying to model and I cannot imagine how any scenario can
progress without observing any of these any of these steps at least I mean just by
thinking about how to set up the situation or scenario awesome and in the rest of the
rest of the chapter yes just wanted to highlight again these steps don't have to be followed
in order they really are like a summary as mark has just written in the live chat here
it really is like a summary of the earlier parts of the book in terms of things that you want to
capture in your consideration and also it's a great way to connect a lot of the technical
ideas that are brought up about generative model generative process and so on with some bigger
questions like who are we why are we making this model how is the model going to be used
so we take that in a lot of different ways in the textbook groups but which system are we modeling
what is the most appropriate form for the generative model how should we set up the
generative model and how to set up the generative process are all questions that
must be addressed at least when actually coming through with carrying out a theoretical or
empirical active inference modeling task and the following sections are going to go into more
detail on each of those four questions so Ali do you want to go for this six three and carry on
okay so section six six one three is the elaboration of the first step that we just
saw which I mean what systems are we modeling and by this question we mean how I mean what kind of
system I mean how the system carves up the state space using the markup blanket or more precisely
the active states and sensory states and I believe it is both one of the most fundamental and also
one of the probably one of the most challenging steps to be carried out because well markup
blanket is just a conceptual tool we use to frame the natural phenomena or any other scenario we
want to model so that scenario or that model obviously doesn't care about how we set up our
markup blanket or how we need our markup blanket but deciding on a proper set of active states
and sensory states that would allow us to address the problems we need to explore or the questions
we need to answer is not a trivial task and it needs lots of lots of consideration and even
creativity on part of the researcher or anyone who wants to design an active inference based
model for the problem so that's where the I mean the significance of doing doing these kinds of
modeling with the insights and creativity of a researcher is I mean it will be obvious because
it's not just something mechanical or despite the fact that the word recipe can somehow make us
believe that it's just a recipe to follow but in actuality it's not the case at all so that's
the discussion of a markup blanket and what criteria we need to keep in mind to settle upon
a proper yeah proper markup blanket around our system and the next section what is the most
appropriate form for the generative model so here again we can have various way to set up our
generative model in terms of whether it's discrete or continuous variables we want to account for
about the timescale is it shallow or hierarchical about or about the temporal depth of the inference
and planning so these are all problems we need to be precise about or questions we need to
precise about and whenever we want to set up our generative model and then we go to section 6.5
how to set up sorry yeah how to set up the generative model so after the precisely describing
what needs to be accounted or what parameters and the nature of the generative model
needs to be accounted for then we will probably need to address this question of how can that
generative model be actually set up so setting up the variables for the generative model
will I mean we will be concerned about how those matrices as a b c and d matrices matrices
can be defined as we saw in chapter 4 and then which parts of the generative model are fixed
and what is learned so again it's really important to know what are the dynamics of the of those
parameters are in terms of the learning process and what what needs to be updated consistently
or learned as opposed to the variables that either don't require consistent updating or they
vary quite slowly as compared to the timescale of the generative model and then we go through the
process of setting up the generative process and as I mentioned earlier it is probably one of the
most complicated steps of the recipe because of the complexity the I mean the enormous complexity
of any real-time situation and particularly the environment that the agent will act and behave
but even if not having I mean even if there is not any strict or I don't know obvious way to go
