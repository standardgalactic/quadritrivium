are, is absolutely rife with hype and various kinds of misjurification of entanglement. And
authors trying to convince you that entanglement is this amazing kind of woo-woo thing.
And whenever you run across that, go back to the definition. I mean, entanglement simply means
this simple mathematical condition of not separability or a state that isn't factorizable.
And that means that the state does not display classical conditional independence.
So classically, that's the way to think about it. It's a failure of conditional independence.
And it's ubiquitous in quantum theory, even though it wasn't actually hipster for almost
50 years after it was predicted. So here's what all these experiments look like. They're called
Bell EPR experiments after John Bell, who derived the statistical criterion for detecting entanglement.
And EPR, Einstein, Podolski, and Rosen, who did this as a thought experiment and said,
if this occurs in the theory, it can't possibly be real. And of course, it is real.
It's now amply demonstrated by experimentation. Here's how they work. There's a source.
The source produces a state that is entangled. And I've written the typical what's called a Bell state.
It's up plus or minus down divided by the square root of 2, just to normalize it.
But up plus or minus down is clearly not the same as up times down. So this is not a separable state.
And this state propagates outward in space and time to two observers who have independent laboratories,
for example, on different continents in that space-based experiment that I showed you the picture
of from the cover of Science a few years ago, 2017, I think. The two observers have freedom
to choose their own reference frame, their own z-axis for measuring spin. They do a spin measurement,
and they do this over and over and over again. They accumulate statistics, and they exchange their
results so that they can analyze the joint statistics of their experiment, and they check to see
whether that joint statistics is consistent with classical probability theory. And if it isn't,
to a statistically significant level, then they've been able to detect entanglement.
Now, notice that this process requires classical communication. They have to make their independent
measurements in their own laboratories, and then they have to exchange results.
Or one of them has to send results to the other one, or they both have to send their results
to some third party. But in all of these cases, they're exchanging some classical data, and so we
have the assumption that whoever gets that classical data knows the language it was recorded in,
and so can do a joint analysis. So I'll just show you another picture of this experiment
that's in a standard space-time diagram. Here, time is vertical, space is horizontal.
The two observers are labeled Alice and Bob. They share a quantum channel
that goes from Alice to the source to Bob. That's the entangled state.
They do some processing, and then one of them here, Bob, sends the results to Alice,
and that's a classical communication. It takes time, and it traverses space.
So this step is classical. So this is why we have to assume classical communication to talk about
detecting or using entanglement. So now I want to represent this in a different way,
using our little picture earlier. We're going to think of Alice again as two components,
A1 and A2. They're separable, so they have to communicate classically. They have a classical
channel that goes through Bob, and they also now share some quantum channel. They share an
entangled state, and the entangled state, of course, is produced by Bob. The source is part of Bob,
and their detectors, if you want to think about it that way, are located on this boundary B,
or their interface with the source is on this boundary B,
and each of them executes a process that accumulates data from the quantum channel
and communicates it to the other observer via the classical channel.
Now this picture illustrates what's called a LOC protocol. LOC means local operations
in classical communication. So A1 and A2 are each operating locally on their boundary.
They're making measurements locally on their boundary, and they're communicating via actions
locally on their boundary and observations locally on their boundary. So for example,
I'm communicating with my computer here, we can consider it my boundary, and stuff is happening
in the environment that's implemented by the internet, and you're receiving those communications
locally on your boundary, on your laptop, or whatever it is you're using.
So that's what local operations means, and these protocols specifically involve classical
communication, and so they're able to detect entanglement. And a Bell EPR experiment is just
an example of a LOC protocol. The observers exchange information about how they're going
to do their experiments, they're both going to measure the spin, they're going to use independently
chosen reference frames, and they're going to look at the output from some agreed upon source.
So that's all classically set up, then they actually make their observations, and then
they classically communicate the results. So classical communication front and back.
LOC protocols are not limited to this sort of Bell EPR sort of setting. We can also represent
a scattering experiment as a LOC protocol. So here's a representation of scattering as a LOC
protocol, and you can see all I've done is cut that previous boundary out the division between
8.1 and 8.2, and I've then extended it in some external time, the time that is
counted by Bob's clock, not by Alice's clock, that's what's meant by external, and I've relabeled
Alice 2 as Alice 1 at a later time. So now what Alice is doing is communicating with her past self,
or A1 is communicating with her future self, and they're each doing something different.
A1 is executing a procedure that in the laboratory we call state preparation.
She's preparing a state that we'll call N, which is just the initial state of some
scattering experiment. So for example, at the LHC, N is some state of two protons that are
quartering around the ring at the LHC at close to the speed of light, and Alice then later on
at t plus delta t is doing a different kind of quantum process. She's analyzing the data
coming out of something like the Atlas detector, which is a multi-particle counter that's located
at the LHC. So they share a quantum channel, which is the scattering channel that takes the
incoming state and produces the outgoing state, and I recall from the very first session, as Feynman
told us, to understand this transition from N to out, we have to integrate over all possible paths
that are consistent with conservation of spin-holicity, basically momentum plus spin.
All the different spins that are relevant in a high-energy physics experiment,
including things like lepton number, which is basically a spin.
Now, how do we know? How do we know what we have to conserve? We know what we have to conserve
because Alice is doing the experiment, has a classical memory that allows her to remember
what she prepared. She can remember that what she did back in the past was set to protons
counter-rotating in the LHC, and they had certain energies, and so they had certain momenta,
and they were protons, so they had certain spin variables. All of that has to be remembered to
make any sense of the output of the detectors, and so to actually come up with a measured state
that makes sense. Very often, this memory channel is neglected by physicists, and I'm going to pause
here and let Andrew ask a question. Thank you, Chris. Does this imply that every time you have a
block channel, the quantum part is like a scattering picture, like a unitary evolution,
even in the earlier EPR picture. Is that quantum channel portion always a unitary evolution
scattering picture? Thank you. Yes, for essentially the reason that I'll define the classical
channel, you're always assuming you have something that's protected from decoherence.
By the environment. So, yeah, if you're doing an EPR experiment, you have to assume that you
don't have any environmental decoherence between the source and the detectors,
and similarly, when you're doing a scattering experiment, you have to make the assumption
that the environment is not reaching in there and messing with the outgoing state that you're
going to see or reaching in and messing with the incoming state and changing it in some way
that re-prepares it in a way that you don't know, that you have no knowledge of.
So, yes, you're making a fairly strong anti-decoherence assumption in any of these settings when you're
talking about having a quantum channel. Does that answer the question? Yes, thank you.
Okay, great. So, we can think of, we can think of LOC, we can think of scattering as LOC.
And I just wanted to now emphasize that effectively what LOC is implementing is two
parallel memories, a classical memory, which as we said in the case of scattering is memory for
preparation. In the EPR case, it's memory for preparation for what the experimental setup is,
for what the instructions for doing the experiment are. And we also have a quantum channel,
which is effectively another memory. It's something that's extended through time,
and again, it's implemented by the environment, implemented by Bob, and it involves Bob's clock
ticking. So, whenever we have two memories in parallel, we can construct an error-correcting
code. So, think of a simple classical error-correcting code, for example, the use of parity bits
in exchanging digital data. So, if I send you a bit string, classically, and I send it to you
two or three times, so there's some redundancy in my signal, and I send you a parity bit.
I say, okay, add up your bit string, and the result should be one. It's one on my side.
If you've added up and you get zero, there's an error someplace. You can use that parity bit to
detect errors. So, you can throw out the bit strings that you receive that have parity as zero
and say, oh, the environment interfered somehow with the signal, or some eavesdropper interfered
with the signal and made a mistake, or something like that. So, this corresponds
to environmental decoherence not being a good assumption, even though it's classical. Environmental
interference is not a good assumption in this case. So, a quantum error-correcting code is
basically the same idea. I use some feature of the fact that I have two different memories,
and that I'm encoding something in time, I'm encoding multiple replicates of something in time,
to provide a way of checking to make sure that I'm sending the correct message.
So, I can, for example, consider the message to be my classical memory,
and consider the quantum process as a process that tests that memory. So, I remember that I
need to do experiment X, and I will get result Y. I actually do experiment X on this quantum channel
and see if I get result Y. And if I don't get result Y, then something's wrong. Either I can't
trust the quantum channel, or I've remembered my preparation conditions incorrectly. So, I'm
using one memory to check the accuracy of the other. And this problem
of using something about the environment, some channel in the environment, to check memory
is absolutely ubiquitous, and we use it all the time. So, for example, look around your room,
and your room hopefully looks more or less the same now that it did at the start of this session.
And that's very reassuring. It reassures you that something's not happening in the environment
that's dangerous and disturbing. And if you couldn't do that, if your environment was constantly
changing, and there was no familiarity about the environment, you wouldn't be able to check your
memory. You wouldn't be able to check your sanity. So, even though we don't think about
our local environments as effectively an error correcting code, that's exactly how we use it.
We use the emerging memory or memory out there in the environment as a way of checking our own
memories and assuring that our memory is okay. So, I talked a little bit about quantum security.
Here's how quantum security system works. Again, it's a lock protocol. We have some classical
signal that can be thought of as a code or a key or a one-time pad, for example,
that encodes a way of doing experiments. And once that's been exchanged, assuming it's secure,
then we can use the quantum channel to communicate information. And the classical channel has told
us what we have to do with that quantum channel. We have to make certain kinds of measurements
at, say, particular clock times as measured, and we'll get information sent from the past,
from the sender. And the classical channel protects the quantum channel from adversarial agents,
because anything that an adversarial agent does to the quantum channel, if some agent
tries to eavesdrop, for example, on the quantum channel, they'll disrupt the quantum channel,
and the results of our measurement will not be what's expected given the protocol that we run,
that we have run. So quantum communication is secured by the fact that interfering with some
entangled state actually destroys the state, so it's detectable. We can always know if someone is
trying to disrupt our communications, which isn't true if we just have two classical channels.
Charlie can always intercept a message and then recreate it, and that's not possible
with a quantum channel. So let's refold this diagram so that we've taken the external time
back out of it. And we have this picture where the two components of Alice are just interacting
via their shared boundary with their environment, Bob. And now we can see that the source of
redundancy is not time, it's the boundary itself. Just sharing the boundary allows
Alice's components, A1 and A2, to put copies of the same information on different places
on the boundary. So the boundary now becomes a resource for redundant storage of information.
So Alice 1 and Alice 2 can use different parts of the boundary
to check what other parts of the boundary say, to check the information that's encoded on other
parts of the boundary. So they can define an error correcting code on the boundary itself
using this lock protocol. So I just want to leave you with this idea that using classical and quantum
channels together allows us to define error correcting codes on boundaries that we share
as separate agents. And leave you to think about what shared measurements, what shared
quantum reference frames, let us as agents see the same things. And this is what we'll talk about
next time in September. We'll talk specifically about how space provides us with an error correcting
code and try to understand why space is treated as emergent from something else, basically,
from communication in most of quantum gravity. So thank you very much. I encourage you to use
the interactive QA and to attend the discussion sessions and we'll see you in September. Thank you.
Awesome. Chris, thank you for the lecture. Andrew, do you have any remarks or questions?
Not right now. Thank you. I'll just ask a few quick questions and if anyone has one quickly
in the live chat. So you mentioned the tick of the clock and in active inference, we often hold
up side by side both the discrete time models and the continuous time models. So do clocks have to
tick discreetly or how do we think about continuous time modeling? In this in this quantum setting,
they do have to tick discreetly because one has to be able to distinguish
Alice's preparation of the qubits on her boundary from Bob's measurements of the
qubits on the boundary. And this process can be extremely fast with respect to any kind of sense
of macroscopic time. You know, your eyes are responding to photons in I think it's hundreds
of femtoseconds. So the discrete transitions that are effectively time measurements for you
are at that very fast molecular time scale, much, much faster than our typical clocks.
When we try to do very fast timing, we're constructing a faster clock than that,
but it's a clock that we can only observe indirectly.
Awesome. Okay. Now this one maybe connects a little bit to application, but with all the
developments happening in theory, some of which you're reviewing here, and also in practice with
quantum computation, and then keeping in mind this distinction. Sorry, I've lost you. Back.
I've lost you, Daniel. Okay, we'll wait till you're back. I can see you. No. Okay. Yeah,
just repeat your question, please. Yeah, so given these rapid and ongoing developments in
theory and practice related to quantum information science and quantum information security,
how are people using this distinction of the classical Stigmergic memory and then the
quantum cognitive process to anticipate
how to develop information systems that are reliable going forward?
I don't know of any instances in which thinking about quantum cognition has entered directly into
any design of communication systems. The ability of humans to interact with these systems is just
assumed. So it's just assumed that the user can interact with, say, a computer interface,
which is the sort of interface that will be provided or is provided to any quantum computer.
So if you think about a quantum computer, a practical quantum computer, it has classical
interfaces front and back. So in thinking about interacting with the computer, I'm giving it some
classical problem statement, for example, and asking for some classical answer. And what it's
going to give me is a probability distribution of classical answers. But I can, by running the
calculation many times, make that probability distribution fairly tight.
So yeah, I don't know of anyone talking about quantum BCIs at this point. It'd be an interesting
question. Was it always understood these sorts of blind spots and axioms associated with classical
communication? Was it developed as kind of like a proposal or like a special case? And more unpacking
was left for later? Or are these blind spots things that we're now coming into awareness of,
