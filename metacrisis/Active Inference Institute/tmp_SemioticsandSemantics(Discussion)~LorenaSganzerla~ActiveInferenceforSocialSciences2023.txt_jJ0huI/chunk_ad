where like your prices act as some sorts of like information signals and like like can use active
inference to then talk about aggregation in of market entities or something I'm guessing this
would also be covered in the same list indeed people have explored cognitive economics and
people are working on it but that doesn't mean it's a done deal theoretically or especially in
practice so keep going it's quite experimental still but there are a bunch of people working on
that I guess I don't remember any specific paper right now but I can I can look it up and forward
to you but yeah yeah it would be great I can drop my email address here yeah sure the third is
probably more trickier than both of these which is is there an active inference account of natural
language um yes thankfully colleagues like Elliot Murphy and others have explored specifically
the linguistic aspects of natural speech I think Lorena's lecture and area of focus generalizes
a bit beyond specific natural language because we're talking about semiotics and semantics
in a more intermodal sense however yes there's been limited work from a computational
linguistics and neurobiology perspective on speech okay so then
okay so you said something like first principles stuff when you're making a commentary on what
active inference brings I have still I have I'm still often like struggling what is active
inference offering and I like try to encounter different things I think I enjoy a lot of
philosophical questions at the conversation opens up but like I'm still like very ambivalent about
the theory um and when I read like this new book uh which Friston has not written uh but like is
and quarter I don't remember was the name of the book um uh yeah I don't exactly remember there's
a book right which is like supposedly like supposed to be the canon and like Friston as a
co-author but in the preface he says so so that's the 2022 par Friston Pazulo textbook right par yeah
yeah I wouldn't quite say it's the canon since it's a short book but certainly it is a landmark
moment for the fields right and when I read that the one thing that bothered me was
it brings up the Helmholtz free energy thing but it sort of argues that by fiat like okay this is a
simple principle it can model a lot of things but that doesn't tell me why I should why I should
trust it like what what is the reason to act why why does this principle lead to cognition like
what like sure you're positive a very simple principle and then said hey look this simple
principle can explain so many things but well it can it also explain things that don't look like
cognition and like I like I'm not sure like there's an I got an account of why that principle is like
uh works or something the rain I go for it I'll think of some other ways to say it yeah you can
think of like modeling by construction and modeling by first principles and if modeling by first
principles you have you have some limitations in which you cannot fully explain some things but
the virtue of the model and how the first principle organizes everything that comes along with the
model usually might be sufficient or might be a useful a useful tool to help you explain that
phenomena that based on the first principle that you were bringing along and that's one way of
one part of answering this question is I think it might be a big question for the for the field
for the field yeah here here's some short little threads on that
yeah we can describe maladaptive cognitive systems or adaptive cognitive systems whether
something's adaptive or not is always in relationship to its niche like the foraging algorithm that
works in the desert doesn't necessarily work in the rainforest so these systems are like intrinsically
adaptive or not we want to have natural language that allows sentences that are valid and invalid
and have different kinds of semantics so again this is just an expressivity framework
that enables people to build cognitive models of high reliability or important settings or you
could make something that looks just like a beautiful circuit board and not even worry about
what the outcome is so yeah for sure you can describe all kinds of systems that would be like
having a less than functional methodological system if we said well we're doing the linear
regression framework but we only want positive regressions it's like well no at the methodological
level we want it to be able to do any slope so here in the cognitive modeling setting we want
more expressivity so that we can actually construct the ones that we're interested in
and then how does this really do cognition how is it that a first principles like surprise
minimization or the bounding of surprise through free energy how can that really cover
so many cognitive phenomena that's the question and the play but how is it that
Newton's laws of motion can describe so many objects being dropped off a tower
how is it that Bayesian mechanics can describe so many different priors being updated
and so by understanding cognitive paths as paths of least action which is the free energy principle
a wide variety of models become of a of a similar kind now yeah whether that's useful to a given
person in a given setting like if you make an active inference model of your business it doesn't
mean you're gonna succeed if you make a self-driving car with active inference it doesn't mean it's
gonna work this isn't a guarantee of success but it's a method that can be utilized and we know
that the method reaches different kinds of modeling outcomes and supports subsequent
perspectives and models from where it reaches but we can't a priori limit where the method reaches
to like only the successful ones or only biological systems then we wouldn't even have
the expressivity to talk about cognitive ecosystems with synthetic intelligences
um and when you're talking about cognition also we can use this kind of first principles
to model aspects of cognition but you might not necessarily think that cognition is all encompassing
like that everywhere all the same but you can ease that to model specific things that you're
interested in in cognitive behavior like adaptivity does it give me any insight to understand what is
adaptive adaptive behavior for instance and which kind of insights do i get are they interesting
are they useful so that's what the availability that this kind of model bring along so you can
you don't have to believe in in the whole story but it gives you a lot of leverage
to ask ask questions and what kind of questions you'll be asking
okay so let's say that like free like active inference and free energy allows me to talk about
systems but does it give also give me vocabulary to then classify those systems
in terms of let's say adaptivity would be one property but like there could be other properties
in terms of like how much how rich the world model is or stuff like that or yeah um if you have
a portfolio of generative models you could summarize them according to the tj statistic
you could summarize them according to the number of nodes you could put them into a common environment
or different environments and summarize their activity in any number of ways but we can't
talk about a ranking or summarization of a portfolio of generative models that's not in hand
this is a framework that lets us build those diverse generative models
and then in a very open-ended way do model comparison model selection model adequacy
all the kinds of complex systems engineering methods that we want
and also I would ask you where do you see a peer or a comparison first principle
you know active inference has legible first principles which are reflected in the active
inference ontology and expressions using it which can be represented in natural language so that's
the talking about it but it's not only represented in natural language other frameworks have other
first principles that may or may not be legible and people may choose different paths to go down
for whichever number of reasons well right models like they have the virtue you can compare them
and see which one gives you the best insight that you're looking for
well so yeah I think like something that I could compare to active inference is like say the
Bayesian utility maximization thing and which has a different ontology I'm not a fan of that either
like that also I'll just note that Bayesian utility maximization is a special case of free energy
where there's no epistemic value all you have is pragmatic value and so a special diminished case
not necessarily you have value of information and you have explore exploit trade-offs
in Bayesian utility maximization as well like you like like if you load into your utility function
if you can beg the question and load episteme into pragma you're right then all you need is
pragma but in expected free energy we have epistemic and pragmatic value which is what enables
us this expressivity but I think we're aligned on that right I think like I'm somewhat like also
slightly confused because in the Bayesian utility like between the languages comparing the languages
as such like in the Bayesian utility maximization the exploration parts that are prioritized based on
your X and the estimation on the value of information whereas I'm not sure that holds true
for the active inference model as well that the epistemic exploration is prioritized or valued
in terms of some of the same pragmatic thing as well. You'll have a lot to explore and learn
you can make a model that is 80-20 or 20-80 or 100-0 between epistemic and pragmatic
there's nothing we can say across generative models about whether active inference prioritizes
episteme or not because you can make a model that's 100% or 0. Sorry I meant more like does active
inference allow us to talk about systems that the Bayesian utility maximization doesn't allow us to
talk about. I'm talking particularly about expressive power of the language. Are there
things that the Bayesian utility maximization can talk about that active inference cannot
other things that active inference can talk about that Bayesian utility maximization cannot.
Two short answers one short answer utility maximization must cram epistemic value into
pragmatic value we gain more expressivity when we can articulate out pragmatic value which is the
alignment of preferences with observations from epistemic value which is information gain so
that's a huge articulation and the second thing is when you're in a anything maximization framework
when you're in a utility function now again bagging the question how you constructed this
function that you're trying to maximize. When you're in a maximization framework we have a well
known set of approaches for finding local and global maxima using optimization or maximization
frameworks. What active inference uniquely provides is it describes the path that that
cognitive thing takes as a path of least action that minimizes surprise so instead of climbing
to the top of the hill up are we on a foothill or are we on the biggest hill we're like a ball rolling
to the bottom of the hill finding the least surprising path now that least surprising path
can still include novelty and information gain but it turns out to be a lot more tractable
and connected with statistical physics and quantum mechanics when we talk about the path of
least action ball rolling down the hill rather than this sort of question bag on top of a mountain
climbing adventure Bayesian utility approach. But it's up to each person to feel how they want to
feel. Yeah it's a little bit what's in the book as well when you take the low and high road for
energy principle right because how much you want to have your utility maximization function being
disconnected to the pragma to do to the action.
Because when you're modeling behavior it will be hard to do that independently like you have a
lot of you have way more assumptions you're committing too much to a greater level of assumptions
for your utility function if you don't do that.
Because with the pragma with the action first that pragmatizes you have reasons to describe
have reasons to believe why that information gain works the way that it does. You can leverage
explanations on that without it you have a model that has more assumptions and I think if you have
a model with less assumptions it's always healthier let's say so.
Yeah so I think like that that that does talk about the compare compare the analysis of the
expressivity but I would also say as a meta point that like I'm not happy with either of those languages
I'm like I suspect that both of those languages claim certain ontological assumptions and I'm
like always suspicious but wait but like where are these ontological assumptions coming from.
A few other points we tap into an absolutely meaningful nexus of statistical methods and
message passing schemes with active inference if you can state something in the active inference
ontology and construct a generative model then message passing algorithms can be deployed that
contractively compute that model so that's absolutely non-trivial otherwise it's possible
just to get wrapped up in some analytical formalism but then once you want to do that on a 4k video
now you're on square zero with the computer engineering this is not that way and then I
will respond to your meta point with a meta point which is when we've enumerated the alternatives
the one that we like best personally I feel happy with I'm also open to new alternatives arising but
being unhappy when all things considered is in play why. What bothers you specifically on the ontology
of the active inference. Yeah like I think like I'm still looking for I don't know what exactly
I'm looking for but I'm I feel dissatisfied with the account given for why Helmholtz free energy
least action thing like is the central thing here or something like why does it work like why
does this principle yeah. There's a lot of funny answers I could give there that that delta that
discrepancy that's curiosity and that's the space of the open and that's learning and that's your
unique contribution to make and that's everything so that's not just a thorn in your shoe that's like
our experience of action amidst uncertainty which is the water we're in and so whether we
take a higher order narrative perspective on that discrepancy being dissatisfying
or that discrepancy being satisfying I think it's pretty. I just need to minimize my surprise there
yeah and you can choose to minimize your surprise through your attention
you can choose to minimize surprise at a higher narrative order like I'm satisfied and complacent
that I don't understand number theory but I use numbers to count objects around me
so that discrepancy and understanding knowing that there's a thousand years of research
that could be done on numbers it doesn't unsettle me but for someone else that might be unsettling
and that might lead them to ruminate it also might lead them to do a phd and number theory
so just different paths for different individuals and contexts but there's always so many technical
and meta levels with active huh. Okay so I don't want to like keep you guys over time but I would
ask one last reference based thing which is are there active inference accounts of seeing
like a state phenomena uh in any literature I think I heard you mention it once so I was like
yeah like this yeah check out live stream 33 series but also this course that we're literally
actually enacting in with Avel is where these accounts come to roost and where we're creating
a space to develop it and it's not a cathedral for us just to spectate at today but if you
want to make an active inference generative model of whatever social setting when you have the model
in hand a lot of your questions will be sidestepped okay where is the 33 thing that you mentioned
if you go to the page with all of our institute live streams and look in the live stream
series like the paper discussions in the 33 series there's a dot zero video with background and
context and then we have a dot one and a dot two conversation with the authors but Avel who's also
the course coordinator for this course and kairos research like Avel's and and colleagues work has
heavily built on the seeing like a state thinking like a state optimal grasp all these different
topics yeah I'm yeah I'm on your youtube channel I'm slightly finding it hard to find the thing
if you look up live stream 033.0 or if you go to in the video description of any video where it says
all live streams here go there and search for but you'll find it and you can always email us
or get in contact but yeah and I think Avel's paper like thinking like a state also can help
you a lot to understand how how active inference modeling is useful for the social sciences in
comparison to other types of modeling he makes an comprehensive description interesting
great thanks and this is this is our first iteration on this course we are going to continue
bringing new information to the table and supporting individuals who want to build
generative models you know around this area whether it's part of an internship program
or part of a course credit or different kinds of programs that we'll be able to develop but
this is the real thing and we're able to work with people who want to think and do
make sense indeed any closing thoughts on tj then I will go and then Lorena with last word
um no that this was great thanks thanks for the conversation
thank you well thank you for bringing tj for joining Lorena for the lecture this was a fun
discussion we never really know where how it's gonna go but I'm glad that we could cover
so many of these topics and probably raise more questions and footholds than door slams so thank
you again Lorena yeah thank you for inviting me and I think active inference like holds a lot of
space for experimenting as well some things you try to see if they make sense and they're gonna hold
up and open new questions and that might be an interesting aspect of uh of the framework itself
thank you everybody thank you everybody for the great live chat comments there's a lot
there I couldn't read at all so till next time
you
