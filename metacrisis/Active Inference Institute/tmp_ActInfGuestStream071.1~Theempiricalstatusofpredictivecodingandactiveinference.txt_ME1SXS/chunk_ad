philosophical methods um things that are conceptually problematic right so you can get down to kind of
the set of frameworks or the set of yeah the set of sort of interlinked concepts that make up a theory
you can find a set of them that are at least internally consistent and and have some sort of
general sort of sufficient coherence to them but once you've weeded things down to the kind of
subset of possible theories that are internally consistent right and and don't have any philosophical
problems associated with them then then i think um things really kind of need to get empirical um
you know because because you know to the extent that different kind of competing
conceptual sort of theoretical frameworks um to the extent that they make different predictions
and to the extent that the goal of this whole project is to try to come up with an accurate
theory of what you know what brains are doing right um if that is the goal then the way the
only way ultimately to validate that is by actually looking at brains and seeing what they're
actually doing um and um and so and so i think i think that's kind of where rubber meets the road
a bit right this is that um um yeah you need to know what's plausible right and that's where i
think philosophy can help a lot but after you know what's plausible then testing what's kind of
actual right this is kind of the next necessary step and um and this kind of comes back to what
roan was saying um was that testing the unique predictions of say some given act of inference
model versus some competing model from another framework like reinforcement learning um can be
tricky um usually you have to do this in an incremental way and you do that by finding by
identifying some prediction that is different between those two models and then designing
a task that would really put people in a decision in a position where they have to make choices that
are consistent with either the prediction of one or the other um and um it really requires some
creativity right and coming up with the right kind of the task with the right sort of decision
making demands um and constraints um that will do that because there's lots of tasks um where say
the kind of simplest most straightforward um active inference model will really make like
almost exactly the same predictions as well like a simpler reinforcement learning model would make
right so in those cases you really can't differentiate with you because they pretty
much predict the same thing um and um you know and as as roan mentioned even though it's true that
active inference is kind of motivated from these sort of first principles um which is super nice um
the the thing that you ultimately end up converging on in terms of the decision making algorithms and
active inference start to look pretty similar to the sorts of things that people in machine
learning and reinforcement learning have ended up kind of coming to anyway they just haven't come to
it from a first principles perspective they've come to it because they just kind of like tinkering
around and figure out what works um and so um and so that that's also kind of an interesting question
is is you know where can we find differences between active inference and the other stuff
that's out there that has nothing that has no connection to active inference but is kind of
converged on a similar type of solution um and uh you know and then you get to a point where okay well
if we've gotten to the case where we have two algorithms that have different origins but are
basically doing the same thing right then there is no competition anymore we've just
gotten to the same solution two different ways um so that's uh I don't know I guess I guess
goes a little bit beyond your question but but I think um hopefully is all sufficiently relevant
that's awesome maybe um marshka and then like kind of just in closing here um
how do people pick up and run with the work and just how do people continue with it
but first how do you approach this at a bigger level yeah um so I come from like a different
side to this I come from more empirical background like what Ryan was saying so to me it's more about
taking all of this information kind of accepting the broad literature that that's out there not
just in active inference or predictive coding but also more from the psychology in your science side
of things and kind of seeing where these things fit in an empirical setting where do these algorithmic
ways um can be tested in a plausible manner for example like how Ryan was talking about
the last fmri study was done in like 2015 that actually tested like active inference models
that to me is like the first things where we would want to test what is actually happening
in the brain whether it's through fmri eg kind of testing at different levels through different
computational models what the brain is doing to me that's the most interesting next step like
taking the computational work out there and trying to relate it back to brain and behavior
oh Rowan and then Ryan or anyone else can just kind of give any last thoughts or what they're
going to take going forward
go for it go for it Rowan if there's anything you want to say
sorry I was muted and yeah I think I think active inference is in a it's in an interesting spot
and I think the world of AI is in a very interesting spot I know you know this
by AI I mean artificial intelligence or active inference if we want to look at active inference
as a sort of an element of artificial intelligence it represents a side of things which is sort of
neuroscience inspired artificial intelligence and as we all know there's a there's a bit of a
war going on between that and the large language model I'm a kind of things and I think active
inference is yeah I think while it's tempting to sort of go ahead with amassing more data and
training larger models I think that it's really important not to to forget about this aspect of
trying to not just come up with with you know more architecture and more data but to come up
with more interesting frameworks I also think that unlike traditional artificial intelligence
or machine learning it's important to remember that there's this tension between as we mentioned
before scalability and and just the efficiency and biological plausibility we don't always want
a solution a model to just be better and quicker that isn't necessarily what we're going for we
know that in many cases artificial intelligence can do things better and quicker than the human brain
but we shouldn't necessarily only care about that sometimes yeah it's important to get a solution
where it doesn't act more effectively but acts more like data empirical data that we have gotten
from actual human behavior and that it even if it isn't the most efficient sort of architectural
algorithmic structure it matches the structure that the brain might implement so I think it's
important to remember these factors in this world where yeah it's fast developing into
you know big data and massive models sometimes I find myself drawn to just always trying to
make active inference faster and always trying to make it more efficient and oh I sometimes
have to check myself with that and and remember what I'm actually interested in so yeah yeah and
I guess I guess as a you know concluding on my end I mean you know Daniel you asked specifically
kind of about future directions um you know and and the kind of thing that we're doing in the lab
right now is you know very kind of inspired by what we said you know needs to be done in the
in the in the paper right I mean it's always a little bit of an advertisement for uh in a certain
sense for you know here's what we've done and here's what needs to be done and you know that we're
trying to kind of follow that ourselves um but um you know and again you know very very much kind
of in the context of of trying to also use these frameworks to you know be of some kind of practical
benefit to the world right so I mean you know we kind of in tandem right use this as an opportunity
to to one you know test theories about you know how brains and minds work but also to um take it
as a as a simultaneous opportunity to look for where these sorts of mechanisms may be you know
going wrong a bit and people with different sorts of disorders and whether or not that can
you know give clinicians right like ideas for novel treatment targets right like to target
mechanism x versus y you know as kind of shown by what the differences are in models when we
fit them to behavior and say like healthy versus clinical populations um and um and so you know
the sorts of things that you know we're doing now on the on the corner more basic science side is
is um you know I have another grad student um co-paying um chow who's not on the call here but
you know she's done um some very extensive work now fitting um um something like 50 or so different
models um to um some decision-making behavior that we have in both a Taiwanese sample um where she's
from and and an American sample from around here um and you know trying to find right like
which model fits best and so these are a range of simpler kind of reinforcement learning models
and a range of different active inference models that are just parameterized in different ways
right so ones that assume sort of like you know static versus dynamic decision noise or static
versus dynamic learning or I mean again there's tons of little variants on these things um and so
you know she's she's found in in both samples that you know the model that best fits the data
um and wins in model comparison is a is a specific um active inference model that has
six parameters I think um that involves a you know dynamic learning or dynamic decision noise
that includes particular sort of forgetting rate function um that's you know not included in kind of
the simplest version of active inference um and um you know so showing much more kind of
conclusively in two different data sets um you know that um active inference um at least
wins in model comparison against some of these other um other kind of competing models um that
being said I think it's important that even though it wins in model comparison when you actually look
at the predictive accuracies um they're very similar you know we're talking about active
inference being able to explain like 81.5 percent of the you know like data versus uh the best
reinforcement water reinforcement learning model being able to pick like 80.6 percent of the behavior
you know so I mean these differences are minor right it comes down to being better at predicting
just a couple of choices um but sometimes if those choices follow from different sorts of
expected dynamics along the way then that can still be meaningful um you know so that's the
kind of thing you know that we've been doing on the on the more kind of basic science end but
follows up on you know what we were saying needs to be done um you know on the
sort of clinical end still not super clinical it's you know we have a study that where that's
ongoing right now um that has both an online and a um in-person component where we came up with
five different um five different tasks that um where different models would predict different
patterns of behavior um in distinct ways in each of those tasks um a couple of them were designed
specifically for active inference um others were designed like more in relation to the hgf the
hierarchical Gaussian filter um and um you know so we're in the process of collecting a lot of data
in those where again we'll be able to fit different models and um that one we're also focusing a lot
on um into on whether or not we can find models and parameter values in those models that predict
individual differences in subjective well-being um as well as um negative affective stuff so we're
trying to go for not just predicting like symptoms and negative emotional stuff but also um positive
emotional stuff and what makes a difference to decision patterns that are say more consistent
with um greater satisfaction with life and subjective well-being and things like that so
you know we're doing that we're also doing some um computational sort of Bayesian
modeling of um interception data so how well people can like detect differences in their um
heartbeats or differences in their kind of like respiratory difficulty things like that um and
how they're always anxiety disorders so so we're um it's very much kind of a combination of
this basic science stuff and the and trying to move the the usefulness of this thing clinically
at the same time so it can be kind of practically helpful to people
that's awesome dean and then anyone else and then that will be awesome but where where where do you
go from here dean um have a shower i don't know i'm not i don't have anything really planned
but i appreciate the uh i appreciate the explanations and like i said when you start
from a place where you take two things and hold them up together at the same time that's
that's the part that i uh appreciate here and i think it again reading through all of this um
i didn't understand all of the math but um it also i think based on what you were able to show
i wasn't sort of questioning what what process you went through to try your conclusions and
and state what some of the limitations are until those tests have have been carried out so yeah
yeah thank you for the very clear very relevant paper so good luck and you're always welcome back
to share more we can follow up and um it'll be an ongoing rolling literature meta analysis across
different systems there will be thousands of fractal sub reviews empirical status in the amygdala
on this kind of thing so it's great to hear how you did it this time
but thanks for having us yeah thanks so much bye bye
you
