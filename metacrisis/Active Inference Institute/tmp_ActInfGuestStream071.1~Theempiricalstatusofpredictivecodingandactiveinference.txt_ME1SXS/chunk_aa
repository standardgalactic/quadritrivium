Hello and welcome. This is Active Inference Gas Stream 71.1 on February 22nd, 2024, 22222.
And we're here with Ryan Smith, Rowan Hodson and Rishka Mehta. There will be a quick overview
and then discussion on their recent work, the empirical status of predictive coding
in Active Inference. So thank you all and let's hear about it.
Okay, so you just want me to jump in and go? Yeah. Okay, cool. Well, thanks a ton, Daniel,
for inviting us on. It's fun to get to present some of this stuff and hopefully get it out to the
broader community a little bit. So I'm going to quickly just walk through sections of the paper
to orient people to generally what the point is and what we're trying to do. And then at that
point, I think the goal is just to kind of launch a discussion and see if we can kind of extract out
some of the more interesting points that might be most relevant or interesting to the Active
Inference community. So just to start out with here, so the paper, as Daniel said, is called
the empirical status of predictive coding in Active Inference. The main point of this is just
that, you know, as a lot of people in this community know, it's, you know, at its kind of
beginning and for a long time, you know, like the Active Inferences primarily, so the literature
you'll see has been very focused on theoretical sort of conceptual work and simulation based work,
right? So you'll see a lot of things out there that's kind of, you know, an Active Inference
model of X, where X is just some interesting psychological phenomena or condition. And usually
that involves showing some, you know, fun, interesting simulations that are kind of potential
computational explanations for, you know, whatever the, you know, specific phenomenon of interest
is. And that work is great. And I think there's been a lot of developments there. But, you know,
at a certain point, you know, we can come up with as many theories as we want. But without actually
being able to test them scientifically, it's really hard to be able to say with any confidence that
these are kind of accurate stories of what the brain's doing and what are the kind of,
yeah, again, like empirically supported theory, you know, what, which of all these different
sort of models than simulations people are proposing sort of actually correspond to what
the brain's doing and whether they can actually explain human behavior. So what we were interested
in doing is actually kind of taking a step back and looking at what the, what the empirical studies
that have been done using these sorts of modeling approaches, what they actually say,
and how supportive the evidence actually is for, you know, the hypothesis that the brain is doing
things like predictive coding and active inference. So that's why it's called the empirical status,
right, as we're trying to say, okay, what is the current evidence? And where is evidence missing,
right? So what should future work and future studies focus on to try to actually, you know,
like, like fill in and answer questions and provide additional support or not for, you know, for,
for these theories as hypotheses for what, for what the brain is doing. So to kind of walk you
through sections here, so we focused, you know, so people use this umbrella term of like predictive
processing, but that's really a fairly vague overarching kind of umbrella term. And so we picked
kind of the primary, you know, actually sort of well-defined algorithms, you know, in that are
most prominent within the kind of under the predictive processing umbrella, which is predictive
coding and active inference is a kind of well-defined mathematical algorithms that can be
sufficiently precise to test empirically. So the first section is more or less just kind of an
introduction that says more or less the sort of thing I just said about predictive coding and
active inference being the kind of most prominent precisely formulated algorithms that the brain
might be doing and the importance of testing these things empirically, et cetera, et cetera.
And so I should say that, you know, most of the credit for this paper should really go to the
first author, which is Rowan Hudson here, who I'm hoping will certainly say much more after I give
this kind of brief overview. But, you know, so what Rowan did is he started out in each of these
sections by defining the algorithm and laying out the associated mathematics in a way that was
really very clear, I thought, of course, I'm bragging a little bit about a paper that I'm on,
so take that with a grain of salt. But I thought he did a very good job of laying it out, you know,
being explicit, showing the mathematics, but describing it in a way that was what I think
should be very accessible to people that don't have a ton of mathematical background. And the
idea was that we would just, you know, introduce this so that what we were talking about was clear,
but the focus really isn't on, you know, just the mathematics. We're just introducing a
mathematics so it can be kind of more understandable what, you know, what the studies that we review
are actually testing. And so we just kind of walk through a lot of that, and I'll come back to this
figure in a second. But, you know, the underlying mathematics, so for instance, you know, here is
a definition of the negative free energy when applied within predictive coding. And just kind
of how you get to some of the predictions and prediction errors and things like that that we
actually use. And this figure is a figure that took a long time to make and to try to be clear on,
but, you know, we thought it ended up being pretty, you know, colorful and engaging. And
it looks complicated, but we tried pretty hard to kind of walk people through step by step,
but this is what this is hypothesizing. But this is just a representation of one way that
cortical columns in the brain might implement hierarchical predictive coding. And this is a
particular form of a particular predictive coding algorithm that allows for a certain type of temporal
depth to it, where you have essentially a higher level hidden cause that's being represented that
actually predicts dynamics in the representations at the level below, as opposed to just predicting
and trying to minimize prediction error with respect to some sort of static equivalent temporal
scale representation at the level below. So we try to kind of lay that out so that people
have an understanding of what, again, what the kind of general basis and what the hypothesis is.
It's kind of important here because predictive coding at an algorithmic level
is a different thing to test than trying to test a theory about the specific neural mechanisms
that implement predictive coding. So I think it's a really important point is that you can test
a theory empirically by looking at the brain to try to test a hypothesis about a specific
way the brain could be set up to do predictive coding, but the brain could be set up in more
than one way that would implement predictive coding. So to be specific about testing something
about the brain process, you need to specify what algorithm you want to see whether there's
evidence that the brain is doing that. More generally, though, you could also just test
for evidence of predictive coding at the algorithmic level and you could do that behaviorally just
by looking at whether, you know, people's, people's, what people detect perceptually and how that
evolves over time, whether that is just consistent with the, with the predictive coding algorithm.
So just, just the mathematics, not some more specific hypothesis about the way the brain is
doing it through different patterns of connectivity. So then, as I mentioned, we kind of go through
now just we lay out what the proposed neural implementation is, or as I said, one commonly
proposed implementation. There's actually a couple that we talk about. And then here in this section
we have the empirical studies of predictive coding and we review more or less what the evidence is
for these different, for, for different kind of aspects or testing different predictions
that predictive coding might make about what you would see, either behaviorally or in the brain.
And I won't kind of go into it in detail here. We can obviously talk about it when we get
born to the discussion. But, you know, take home is, is really there is a lot of indirect evidence.
But more, there's a lot of studies that still kind of remain to be done to test more specific
hypotheses about the neural implementation. You know, whether or not, for example, there actually
are separate neurons in the brain that are responding just to prediction errors and other
ones that are representing just predictions and things like that. There really is more kind of
explicit model fitting that needs to be done to test out this, you know, predictions associated
with really both quantitative simulations and what those predict based on the predictive coding
algorithm. One place where probably the most kind of related evidence is, is not with predictive
coding proper, but with hierarchical Gaussian filter, which is a different model than predictive
coding. But it has related high, it has, it predicts dynamics that are related to predictive
coding. So for instance, it does have prediction errors in it, and it does have a precision
weighting on those predictions. And it can be the updates can be modeled in relation to
prediction errors. And one difference, though, is instead of being hierarchical in the sense of
each level in a hierarchy representing different causes, in the hierarchical Gaussian filter,
higher levels represent predictions about the stability of the contingencies at the level
below. So, so basically, the highest level is representing something like how quickly it expects
the predictive relationships between hidden states and outcomes, how quickly it expects those will
change over time. And so it can do this kind of like dynamic precision weighting, depending on
essentially how much you should trust the predictions you have in a given moment based on how you
think those predictive relationships will change over time. So it's not the same thing as predictive
coding, but it's related. And people have done neuroimaging studies, for example, and looked at
the explicit relationship between the prediction error dynamics that this model, the predictions
it makes about those prediction and prediction error dynamics, and whether or not you can find
neural responses that look like they match those predicted simulated time courses. And there
haven't been a few studies that do support that specific brain regions are encoding prediction
errors and predictions and things like that, and different precisions. So it's not the same thing
as testing predictive coding directly, but it is testing and finding evidence for a neural basis
of encoding of precision weighted prediction errors, which again overlaps, in interesting
ways, as kind of again, indirect but important evidence. So then after we go through that,
then we switch to talking about active inference. And again, kind of similar structure. First,
Rowan introduced the mathematics associated with the active inference framework. And for
people that are watching this active inference institute program regularly and should be aware
that active inference nowadays has evolved into kind of also being a broader umbrella term for
multiple different specific mathematical formalisms. And so to be clear, this one that we go
through here is just the kind of standard, initial, partially observable markup decision
process framework. So this is a specific model of decision making based on a particular exploit
trade-off in a model-based way, where instead of just using reward as a cost function,
or an objective function, it's based on the expected free energy, which is just this
combination of expected reward and expected information gain. So it's talking about a specific
algorithm and kind of the original algorithm under active inference, but now there's lots
of different kind of variants of it. So we're just going through the basic one. So again,
we talk about how it's related to predictive coding and what's different about it from
predictive coding. And then in this case, what we do is there is actually quite a bit more
in active inference, at least this version of it. There are a number of empirical studies that have
directly fit active inference models to decision-making behavior. You know, several of these come
out of our lab, actually, but there are some other ones that haven't. And so we reviewed each
of these in detail, kind of laid out how the models were set up to model specific decision-making
or perceptual decision-making tasks. So for instance, here we kind of introduced the model for
a specific task we used to model inter-receptions, a cardiac inter-reception. And then, yeah, here
you can just see this is just kind of a standard version of a depiction of the active inference
model. And then let's see, you know, again, these are sort of standard things you see in lots of
active inference papers, right? So just describing and laying out the mathematics of the general
update equations and the overall algorithm and then a very kind of coarse-grain, generic sort of
representation of one way that the brain might implement those algorithms, kind of inspired by
cortical column structure. But so anyway, you can see this is a model that we used to an active
inference model. We set up to model a three-armed bandit task that we used in substance use disorders
to show that, and in this one, you know, what we were able to show, for example, was that
substance users showed slower learning rates from negative outcomes than healthy individuals.
So you could see it's much more based on trying to answer psychiatric questions about clinical
groups, because our lab is focused on computational psychiatry in particular.
To look through that, we walked through a task that we modeled using an approach avoidance conflict
paradigm, and that model also was able to show differences in decision uncertainty and what we
called emotion conflict. It's a type of preference precision, effectively, that also differed in
affective disorders and substance use disorders from healthy controls in an interesting way.
There was also a couple others. One really cool study that was not by us, but by Gidson was the
first author, and they took, for example, a set of publicly available data sets for what's called
a two-step task, which is just a common task used in reinforcement learning models, and in that task
there's a standard reinforcement learning model that's used that's essentially kind of a
mixture-based model of what a model-free reinforcement learning model versus a model-based
reinforcement learning model would predict, and what that task was designed to do initially was
to use this kind of mixture reinforcement learning model to test individual differences in how
model-based versus model-free people are. We can talk about that a little more if people
listening aren't totally familiar with model-based versus model-free distinction,
but what they did, which was really cool, was they took that data and fit an active inference
model to it and then compared the ability of active inference to explain behavior compared to
the standard reinforcement learning model I just mentioned, and what they were able to show was
that the active inference model in two of the four data sets was actually a little bit better
at explaining the behavioral patterns than the reinforcement learning model was in the other
two data sets the models were about equivalent. So that was probably the most direct evidence
that has been shown, and this was one of the major points I think that we wanted to make is that
even though it's the case that us and other people have started to do
actual empirical studies trying to fit active inference models to data, the main purpose so far
and what people have done really hasn't been to provide unique evidence for active inference. It's
just been using active inference as a way to try to identify individual differences or group
differences in a psychiatric research context. So one thing that is still really needed aside
from this one Gidgen study I mentioned is more studies where people actually take
you know behavioral data or collect behavioral data on decision-making tasks and fit a bunch of
fit different active inference models to it and also fit a bunch of sort of competing models
like reinforcement learning models to it to really show that the active inference that the
behavioral patterns that active inference predicts are that active inference can do a better job
of predicting that behavior than competing models can because that's really the only way it's not
enough basically to show that active inference models fit well. You need to show that active
inference models fit better than competing models because that's how you'd really show that active
inference is more likely what the brain is doing when people are making decisions.
And so you know the overarching conclusion is that you know the evidence is promising right I mean
there's nothing that suggests that the brain isn't doing active inference and certainly it's consistent
with people doing active people using active inference but a lot more still needs to be done
to show that active inference is a is a better explanation for what people do than simpler
competing models. So that's you know just as a kind of broad brief overview of the general
structure of the paper and the message we're trying to get across so you know we can we can
certainly talk about it more just kind of interactively now there's lots that I didn't talk about
but hopefully that starts as just kind of an initial launching point for for discussion so
I guess I'll just stop there. Thank you awesome perhaps the other authors could give the first
to introduce themselves. Sure I'll start um yeah I'm I'm Rowan um I'm a PhD student uh
Ryan's my supervisor I'm at the Royal Institute for Brain Research um I did my masters at the
University of Cape Town under Jonathan Shock, Mark Swames and Ryan as well. I think yeah just to
talk a bit more generally about this paper this this paper started off as a book chapter actually
which was only going to be focused on active inference and sort of especially particularly
parallel states of active inference and in the process of writing this I found myself
uh what needing almost to write about predictive coding um it's it's I think whenever we can
we should take the opportunity to really um present this in a in a very methodical and
complete way and I think sometimes I remember when I was first learning about active inference
