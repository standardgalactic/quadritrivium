it's very hard to dive in in the into the middle and I think that's how it sort of became it morphed
from just being focused on active inference to being focused on active inference and predictive
coding where you predictive coding acts as a sort of foundation um for a large aspect of active
inference um and I think that's how that sort of happened and then of course it morphed a
little bit from just uh just talking about predictive studies to also talking about the
sort of the background mathematics and theoretical foundations and so I I think this is the sort of
field where um it's a noble cause to try whenever we can get the opportunity to try present a
quite a thorough review of all aspects of this because um it's a difficult field to learn
can be very confusing so yeah I really hope that this review I'm on top of presenting
the empirical side of things also acts as a reasonably intuitive way to look at the
foundational theory of predictive coding active inference. Yeah and one thing one thing I will
say just to kind of add to that is is that um you know for for people that you know have more of a
kind of broad conceptual or philosophical interest in inactive inference as opposed to
you know more of the kind of like detailed mathematical modeling sort of understanding
often what I've seen in the past is is that um predictive coding and active inference get a
little bit kind of conflated right so you know people think that active inference is somehow
just predictive coding plus motor control or plus decision making or something and
so making a claim that's actually really not the case I think is important right that predictive
coding is actually an entirely different algorithm it has a different generative model associated
with it um you know it uses continuous state spaces whereas active inference uses discrete
state spaces at a discrete time like to really lay out like I think Rowan did very well um you
know with Meriska's help also um was um you know to kind of state clearly what the connection is
between predictive coding and active inference but but that they are not the same thing and
they're not even directly connected to each other so to make that to make that a little bit more
more clear and more intuitive maybe so that was just another thing I wanted to say that I thought
I thought that they that they did pretty well and is another kind of maybe useful take on point
from the paper. Hi I'm Meriska um so I'm also like Rowan a second year PhD student at the
Laureate Institute and Ryan is my supervisor my background's more um neuroscience and psychology
so this paper was like a really cool and challenging first step in my PhD where I come from a more
empirical background so kind of working on this paper was uh kind of going not taking baby step
but deep dive into the active inference and the predictive coding literature and again um I'm the
people that Ryan was talking about who had more interest on the empirical side and kind of going
through this journey like really helped me like walk step by step into like different aspects of the
just like predictive coding or active inference literature that you should take into consideration
and think about really like the algorithmic side the neural side of things and kind of
like connecting those three levels how we how different people kind of just think about from
one perspective but what really is needed is connecting all those three things and I felt
like I was playing a supportive role in this paper but this really was a great learning journey for me.
Okay why not to Mr. Empirical, Dean.
Um so my interest in this was um anytime I see a title where there's a minimum of two
ideas being brought together as the unit of analysis I'm I'm always curious is it okay if I
just because I have one question that's sort of an unpacking question around predictive coding
and one question related to active inference at the conclusion would it be okay if I read a little
section of the paper
oh sorry just start just just start just there's a little microphone thing can you just repeat again
okay so I'm on page eight of the paper then the section that I select a little get a little
bit of unpacking around is thus fitting predictive coding models to responses on perception tasks
and testing were quantitative predictions from simulations remains an important direction for
work going forward this is crucial because simulated dynamics and predictive coding models can make
predictions that are not always straightforward a priori and that depend like this depend on the
specific hypotheses built into a formal model or Ryan kind of touched on that in his introduction
for example the specific mathematical form assumed for the mapping between levels in a
hierarchy the direction in which neural activity is assumed to represent a particular posterior
estimate often this is the thing I was hoping somebody could unpack for me often sequential
dependencies between task trials and patterns and dynamics can be missed in summary statistics
that average over trials so models are necessary to predict and test for the presence of those
precise dynamics I was hoping maybe somebody could
feel cut put some color on that that process and what it means
I'm sure I can take a stab at that and I mean you know Rowan and or Mariska can as well but
all um I I'm pretty sure that was something that I wrote so maybe that's for uh for me to be the
one to at least take a start on it um so yeah I mean the in in so in the field of computational
psychiatry more broadly right so not just active inference but um you know the goal is really just
to take a take a set of task behavior right so we can ask people to do say some kind of like
sequential decision-making tasks that involves usually like exploits by dynamics of some form
right so so say like one common one would be I give people so like a three-armed band at task
right so I give people that play some little game and there's three different options and they don't
know what their reward probabilities are um so and then they can just trial and error in the beginning
they can say choose option three and they can see whether they win or lose and if they win you know
let's say they probably stick with option three again um but if they lose maybe they try option
two and then say if they lose again they could try option three again or they could try option one
and so on and so forth right and so predictive and an active inference model in this case I'm
just using this as a kind of a simpler starting example um an active inference model um under
different parameter settings in that model right under different learning rates or under different
directed exploration drives um or whatever you want to parameterize it um would make different
predictions about what that sequence of choices would be um and there's a sequential dependence
because the choices on each trial are not independent right so what a person chooses
on trial two depends very much on the outcome they saw trial one um and what they see on option
three what they choose an option three will depend on both what they saw choice you know after choice
one and choice two um so if I do this standard right empirical thing that you would like analytic
thing that you would do for a task like that that's not model based is you might just have some
summary statistics right you might do something like a common thing to do would just be to count
the number of times they switched what option they chose after they lost or how many times they
stuck with the same choice after they lost so we call those like win stays or win switches
or same thing like if you lose did you stick with the stick stick with the same one or did
you switch so this is win stay win shift lose stay lose shift you could just kind of count the
proportions of those right so you could see something that you know maybe you know how often
people um lose switch for example might might tell you something kind of like their learning
rate for losses right like they they might learn more quicker they might learn more quickly right
update their beliefs more after a loss um if they if they're the kind of person that switches away
right they'd be more quick to assume okay if this option led to a loss this time um that's probably
not a good option anymore so I'm going to switch to something else right whereas if a person has
a slow learning rate for losses then maybe they'll stick to the same one a couple times before they
decide okay this is definitely a bad option they have to see like a few losses in a row right so
but the point is is that if all you do is kind of average over trials and get some kind of summary
statistic about how many times people you know win shifted or lose stayed etc um what you're not
going to get is anything about the pattern in the dynamics right so if they like for instance if they
like lose shifted in the early first few choices right like that tells you something pretty different
than if they lose stay or lose shift on some of those later choices um right the early choices
might be driven much more by like exploratory drives by information seeking whereas on later
trials that much might be much better explained by differences in learning rates um so so fitting
models to behavior which again just means you have the actual behavior and then you see what
the model predicts under a bunch of different parameter values right and you try to find the
parameter values for a person that best reproduces their behavior right so point is is that we've
done that kind of thing several times now for active inference right which you can do with
just by taking patterns of decisions right that people make on games um but you can do that same
thing for predictive coding right you can give people perceptual decision-making tasks right
where people say okay this is what i perceive this time okay now this is what i perceive this time
etc and those are also going to have sequential dependencies because people are going to build
up prior expectations about what they're going to see next right um and so predictive coding models
again under certain parameter values might say okay well if they saw the same thing the last
five times they're going to probably a lot more biased right they're probably going to have a much
more precise prior that they're going to see that again so the probability they're going to say they
saw that again even if you showed something different would be would be higher right and so
and so there are the point is is that it's not always the case that predictive a predictive coding
model is going to predict some trajectory of choices that's going to be really obvious without
actually fitting the model um you know if for instance the person like has no tendency whatsoever
to um be more likely to say they saw one thing just because they saw it a bunch more times in the
past right um that wouldn't really be very consistent with the idea that people are using
predictive coding um and um it gets even a little trickier than that because predictive coding is um
based on a continuous state space so it's not really even something like a person would be you
know just like choosing i saw this i saw that it'd be much more something like them kind of
continuously turning a dial or something you know as they see something get brighter or dimmer or
you know like motion in a direction or another direction and um because the prediction error
equations are are set up in this kind of continuous way they also have these kind of like oscillatory
dynamics to them right so it's like not like you get error and then it drops as the thing resolves
but it kind of oscillates up and down a little bit right and so that would also predict pretty
kind of sometimes funny like not a definitely not something you could just predict a priori
like exactly how someone's going to like turn a dial um so that's that's the kind of thing i mean
okay uh in my in very simple terms daniel i've had some conversations around if you're in a
and if you're in a situation where your focus or your concentration is on the next move or if you
can look and see the entire space and take an all moves perspective so my asking you the question
was to get out of the sort of model piece of it and that so what what do people actually do and I
think you're the question around the oscillate there that's around the oscillation sort of
speaks to that it's it's difficult when you're focusing on that next part of the sequence
to be able to take in the entirety of the and vice versa if you're focusing on the averages
maybe you're not able to pick up on the nuances of the next step can i ask one more question
sure or would the other authors like to continue to fill in on that first answer
i think ryan explained that very well i think this is a general um i'll talk about it i know we
that is referring to predictive coding but in something like it's something i'm very interested
in active inference is along the lines of differentiating for example between
a model that uses reinforcement learning and a model that uses active inference and
yeah using summary statistics sometimes it can be hard to actually see differential behavior
right this is what we care about when we are looking at comparing different models what do
they actually predict differential behavior and that differential behavior can be difficult to
capture in summary statistics sometimes um so in general i think in the world of sort of um
yeah model fitting this is just a common common theme and as ryan said while we're doing this
active inference they are limited limited applications of that methodology in predictive coding
so okay marishka so i'll ask this the other thing this was in the in the conclusion of the paper
again i'll just read it in contrast to predictive coding research in contrast
predictive coding research can be traced back nearly four decades and make specific predictions
that can be investigated across a variety of fields so there's a deeper well of priors there
i assume that's what that means um it will be an important direction for future research to further
develop the neural process theory underlying active inference and allow for precise implementation
level as opposed to simply algorithmic level predictions about random behavior i completely
agree until that time confidence and active inference as a neural model of decision making
should remain tentative but this is the part that i thought was really interesting he wrote
another important limitation associated with the current active inference scheme
is that of scalability which constrains the phenomena that can be examined in empirical
studies that is while these models work well in the context of simple tasks become less tractable
if applied to many real-world problems thigh dimension sets of states observations of policies
my question was um is the idea of strategy because its active inference is known kind of as a basis
for strategizing behavior is the is the question around scalability one that ties into the idea
that even when humans are trying to strategize um how far out they can generalize their strategy
is a difficult measure to get precise given that most contexts are dynamic and changing
so there's there's several kind of related things here um so so the the tractability issue kind of
comes in two different flavors so one flavor is tractability with respect to like our that our
ability to like use these models to even simulate behavior um in in in contexts where the kind of
space of options and how far in the future people are planning right when that gets big
right the other the other question is more about psychological plausibility which is that um even if
i can get you know an active inference model to simulate kind of like 10 steps ahead and you know
where there's like ends up being like 30 or 40 different combinations of like 10 moves or something
like that right um it's not really very plausible but humans are really doing that right that the
brain is really doing that and yeah standard computer it's going to take like i don't know like
roan you know roan has these uh fun planning models that he has this paper that um you know we uh
i think are pretty close to submitting there's a preprint of an earlier version that's out um
where you know the thing does like plan right a bunch of different possible paths that it can take
to you know find you know different sorts of rewards um and uh you know it takes like hours
right to run like simulations on a computer to do something that however humans are doing it they
can do it just like you know in a minute or something right so so um you know i don't so it's
just not very plausible that the way that active inference is solving problems like that um is in
any kind of exact form the same way that humans are doing it um so there's kind of scalability
with respect to what humans can do because humans can't do this explicitly in a fully model-based
way it doesn't seem like um after a certain sort of level of complexity to the the planning problem
that needs to be solved and then the the other part is distractibility with you know actually doing
the modeling itself uh because of just like how just um interactively long it could take um to
actually run these simulations um and so both of those things kind of come into play and it's not
super clear exactly how you know to address this i mean there's there's certainly ideas out there
but most of them involve um taking additional kind of machine learning tricks um you know like
adding like adding like deep neural networks to active inference models for example or you know
doing doing um you know various other sorts of um you know a little kind of heuristic
shortcutty things that make stuff tractable right like not actually searching all the way down every
possible branch of a decision tree but using some heuristic to kind of say two steps in or something
no this branch seems bad i'm just gonna cut this off and not consider it anymore you know things
things like that or like sampling based approaches um for exploring just kind of little bits of the
decision tree at a time um you know it doesn't it's no longer pure active inference anymore right i
mean it's it's a kind of combination of active inference and a bunch of other machine learning
things um but you know to a certain extent like that's probably just like necessary and i mean
bottom line is the brain probably has to be doing something other than fully model based active
inference um to be to be tractable and so figuring out exactly what parts of what the brain do is
doing might be pure kind of active inference and what parts are these other things to to make
