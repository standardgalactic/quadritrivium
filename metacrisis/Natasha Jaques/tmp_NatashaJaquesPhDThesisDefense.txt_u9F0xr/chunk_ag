Well, we compare each of those models
to their single-task learning
or traditional machine learning equivalent.
So SVM, logistic regression, and neural networks.
And we see that in single-task learning,
we still get pretty low accuracy.
So very typical of the literature, not very performant.
If we apply these techniques,
where we treat the different tasks
as just the different related moods,
we don't really see convincing performance gains.
So it's not that the techniques themselves
are solving this problem,
but what we do see is that if we use those techniques
to customize the model to each individual to personalize,
then we see very large performance gains,
sometimes up to 20%.
So at the time we publish this paper,
this was actually state-of-the-art
in predicting these outcomes.
So we were very happy about that.
But what's more interesting is to look
into what the model actually learned.
So these are the weights that the model is placing
on the different features for each individual.
And what we see is that for the stress model,
these are all like stressed out undergrads
from a certain institution.
So we see that they're pretty much
regular to be quite similar,
but for mood, it's very individualistic.
So what we're seeing is that for some people,
the weather is incredibly important to their mood.
But for others, it's not really at all.
So that's showing that we need this model
to account for these individual differences.
Similarly, this is one of my favorite findings.
We actually looked into what this hierarchical
Bayesian model learned in terms of the clusters.
And we did a post-hoc analysis of the individuals
belonging to each cluster and looked at whether
they differed from the group significantly in any way.
And we see that cluster zero doesn't differ
significantly from the group.
So it's kind of your standard person.
Cluster one is a significantly higher GPA
and significantly higher conscientiousness.
So they're more organized.
They're more like on time, punctual.
They have their stuff together.
And interestingly, that cluster actually really
enjoys routine.
If their day is more likely under their normal day model,
they'll feel less stressed.
So we think of this as like our studious cluster, basically.
This cluster, however, in contrast,
is very highly extroverted and has lower physical health.
So I don't know what extroverted undergrads are doing
that's lowering their physical health.
You can make some guesses.
But what we see is that the extroverts,
if they spend a ton of time on campus
and they text a lot of people, especially late at night,
then they actually feel less stressed the next day.
That's a good day for them.
But in contrast, the studious people,
if they do the exact same thing.
So they're on campus and they're texting a lot of people.
They are much more stressed the next day.
So we see that if we had lumped these people together
into the same model, it wouldn't have been
able to account for this difference at all.
And if we tried to make predictions using these features,
it would have washed out.
So this personalization is really important.
So we extended this to actually predicting
people's not only their binary classification of whether they
were stressed or not, but actually the regressing
on their stress level.
And we did that with a Gaussian process approach
using domain adaptations.
So we trained your standard Gaussian process
on everyone else's data.
And then we used this domain adaptation approach
to adjust the mean and variance of that Gaussian process
towards the individual's data.
And then for neural networks, all we did
was just change the loss function.
So deep learning is nice and easy.
So then we see that these personalized models in terms
of regression perform better for the large majority
of the participants.
And in terms of the model fit to the data,
we see very vast performance improvements.
So this interclass correlation not only
accounts for the mean absolute error
in predicting the outcome, but also how well it
fits the trend of the data.
So we see very large performance improvements there.
So in conclusion, I presented work
on improving well-being detection and working with noisy data,
improving multi-agent reinforcement learning
through social learning from other agents,
improving conversational AI with sentiment detection,
and improving a generative model with facial feedback.
Oh, wait, what does this say?
Thesis proposal.
Oh, right.
That's because that's actually what I proposed to do.
So yay, I managed to get those projects done.
And I really want to take an idea from my friend Juliana.
She suggested to be a little more honest,
though, about how hard these things can sometimes be.
So my thesis proposal was very nice and neat.
I was going to finish these projects in this order.
And I was going to leave all of 2019 for writing my thesis.
So things slipped a little and left only a couple months
to actually write the thesis.
And then I decided to do all my job interviews
in those couple of months.
So I would not recommend doing that.
It's been quite a wild ride for the last few months.
But we made it, so we're here.
So in conclusion, the research direction
that I really want to emphasize is
that I think social learning is an incredibly powerful
mechanism for human learning.
So it allows us to rapidly adapt to new situations.
It allows us to transmit knowledge amongst ourselves
and build on that knowledge.
And so I think not only can multi-agent systems
benefit from learning from other agents,
but that any AI system can benefit from learning from humans.
Because humans are smart, they know what to do,
and they're the best arbiter of their own preferences.
But in order to learn those from human social cues,
you need to be able to detect them, which often
necessitates accurate detection of affective signals.
So in future work, what I'd like to be able to do
is integrate these two directions
to training multi-agent policies that
are able to coordinate quickly with other agents,
made with new agents, and then generalize that
to coordinating quickly with humans
in these cooperative environments.
So I think that could be cool.
I also didn't get to fit all of the papers I published.
So these are extra papers that did make it
into this presentation.
If you're curious, please let me know.
And then, of course, I want to deeply thank everyone who's
helped me with this thesis.
So especially calling out my advisor,
Roz, who's been incredibly supportive and an amazing
advisor, and really giving me the freedom to pursue
the research direction that I'm passionate about,
which has been so important for me having a happy PhD
and enjoying myself.
And also, Doug Eck has supported me for many years.
I met him in 2016.
And when I was first starting to learn about deep learning,
he's really helped my career.
Nando has been incredibly insightful.
I think he actually asked the question
that originally spurred the causal influence work.
And that ended up winning an honorable mention
at ICML for Best Paper.
So we were pretty stoked about that.
So thank you so much.
And Joelle has been incredibly patient and amazing
and actually sat down with me and giving me
deep technical feedback on hyperparameter tuning and stuff.
That's amazing of you.
So thank you so much.
And of course, I want to recognize all of my collaborators.
So I've had a series of amazing collaborations,
have the privilege to work with incredibly smart
and amazing people.
And I couldn't have done it without you.
So I really want to call out Sarah Taylor, Asma Khan,
Dehar Yoon, Judy Chen, Vincent Chen, Akane Ehisana
Masakare Kwanesano, Shane Gu at Google Brain,
Chalara Gulchahar.
I'm not sure I'm saying that, right?
But at DeepMind, Craig Ferguson has been amazing.
Christy, you've been amazing.
So I really want to say thank you to you.
And of course, my parents would kill me
if I didn't call out how much they have helped me,
but they really have.
My parents are incredibly supportive.
Anytime something goes wrong in my life, they've been amazing.
And I just want to, you know, I didn't know how to write
down their names in the right order.
So I just want to call it that there was an equal contribution
of both parents.
My brother has been amazing.
My grandma has always supported me.
Mavis, Arlene, both grandparents.
I've got Tiffany and my aunts, Linda and Bill and Auntie Pam,
