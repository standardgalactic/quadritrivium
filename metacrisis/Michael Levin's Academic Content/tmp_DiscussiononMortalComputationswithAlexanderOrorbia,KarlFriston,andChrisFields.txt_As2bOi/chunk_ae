But these are just stories predicated on the Lagrangian
that governs the intrinsic dynamics
and all that the free energy principle brings to the table
is that you can express that Lagrangian
as a function of a probabilistic gerative model.
So your job is now to identify the form,
the functional form and structure of that model
and all the processes that it entails.
But every time you do that,
you're just testing a hypothesis theory of mind for me
and theory of mind for your Xenobox
and theory of mind for yourselves.
Of course, you can break down at different scales.
So it would be possible to ask about the sense making
and sentient behavior of a single cell in my brain
if you were able to isolate it and get inside there
and do molecular biology or do cellular biology.
But you would no longer be looking at my brain at that scale.
And so, you know, but you could sort of cut across scales
in the good old fashioned way
and start to tell an internally coherent story
about how it all fits together across scales.
Could you back up what Carl said quickly?
Not to interrupt you, Michael.
Yeah, go for it, go for it.
And it's partially gonna be a question for Carl
as he triggered an interesting thought
and then just to quickly say to you, Michael,
that's also why I was hesitant because by definition
since mortal computation rests on the Markov blanket
and it's underwritten by the free energy principle,
I also commit to that as well that no, the answer is no,
you can't see what's under the Markov blanket.
And that's why I was curious enough Carl
would give me anything that may I just didn't know about.
So that was one comment to you,
to Carl and to everyone, really.
So mortal computation also subsumes artificial systems.
So this is where I was curious to know
if Carl, we were to design the internal states,
all the dynamics, we, again, we have the environment
but let's just say you dissimulate it,
you're designing the environment
and you design the Markov blanket
because we talk about even in our paper,
potential sketches of things that you could use
to build the boundary and the transduction pumps
and all the sub pumps and to actually build
a viable artificial organism.
Now we have the internal dynamics.
We are the designer and we have specified internal,
external and the boundary.
Is there something I'm missing that we would still,
cause we've created the Markov blanket.
So now we know what's on the other side.
So the answer to Michael is not for natural systems
that we obviously cannot, did not create, but we made it.
So we made the internal systems.
There's some other concept I'm missing
cause you would be able to now say,
I know everything cause I built the internal states,
I specified every bit of the dynamics
and let's say the environment, you know,
we've constructed that,
we've constructed the Markov blanket, the boundary.
What about that case?
Is it, now we are inspecting it cause we made it.
So we obviously don't need to infer it, we know it.
What about that?
I was curious to know your thought of designed internal states
and designed external states and designed Markov blankets.
If that makes any sense.
Yeah, Mike's gone to the door, so I'll respond to that.
So, yeah, I'm not going to give you
any deep philosophical insight.
You don't already have, but just a very practical one.
I mean, you know, what you just described
is an application of the free energy principle
as a method to simulate various mortal computations
in the service of building hypotheses
about how this thing might work mortally.
So practically that's what we use the free energy principle for
and the design is at least mathematically
very straightforward in the sense I repeat,
all you need to know is the gerative model.
So all you need to be able to write down
is a probability distribution of all the causes
and consequences that constitute your system.
That's it.
If you can write that down
and you can instantiate that in a von Neumann architecture,
you then just solve the equations of motion
that are the gradient flows.
We will have a certain amount of component on that Lagrangian
and you can simulate sentient behavior
and sense making, perceptual actions, self-organization,
everything that you want to do.
Why would you ever want to do that?
Well, in order to test hypotheses
that this reproduces the kind of behavioral thing of interest
which for something like me would be a psychiatric patient
for something like might be a multicellular organism.
So you are now using a simulation
as a way of generating predictions
that then you can match against the observable parts
of the system of interest which adjust the surface.
You have to adjust the action on that system
and to the extent that the sensory inputs of that system
are also known.
That's all you have access to.
So literally that's how we practically use
active inference for example.
We just create simulations of Bayesian mechanics
in a given paradigm
and then we adjust the gerative model
more specifically the priors of that gerative model
until it renders impurity observed choice behavior
the most likely under the probability distribution
of the actions of my simulated simulated.
So in that sense you're specifying the structure
but one could argue that even treating the laptop computer
that is so non-unique
because it affords the opportunity to abstract
and do these simulations.
I'll come back to Chris's point.
Even then you don't actually know
what's going on underneath the hood.
And certainly in conversation
with people designing some risk architectures
and sort of looking at the most efficient buses
they have to guess what's actually being passed here
and there and measure it and get proxies
like temperature and that kind of thing.
You can certainly specify the initial conditions
and the structure and you can do a,
you can reboot and reset it.
So you can to a certain precision specify
the initial conditions and the structure
of which the, you know, that the ensuing dynamics will occur
but to actually know the message passing of a computer
even in simulation, I think would be,
I think you would be able to return to your hard no.
Certainly on the level of, you know
the quantum level that Chris was referring to.
Again, it would be unknowable.
But it's an interesting point
but it does foreground the role of simulations in this,
I think and it comes back to, you know, this, you know
why do we want to know all this?
Well, it's just to basically build,
formalize hypotheses in terms of simulations
that now embody our hypothesis
and then look at the empirical system
to see whether, you know
that hypothesis was correct.
Can I just add another point of view on this?
And if we think about what we do in practice
with ordinary computers
where we have built the thing, et cetera,
part of building the thing,
it's not just assembling the hardware.
We also put a lot of work into building these interfaces
that we call programs.
And so if I'm using some sort of debugging tool
or something like that
where I can run a program in one window
and see what's happening
at some level of the execution trace in some other window
what I've done is constructed a Markov blanket effectively
to use that language
that has a bunch of different IO channels
that access different parts of what's going on in the device.
So we could think about from a biological perspective,
we have these cells
that come equipped with their own native IO channels.
But there's nothing that says that we couldn't,
in principle, build some more channels into the things
so that we could see,
we could see more about what was going on in the inside
not by penetrating the Markov blanket
but by adding some IO capacity to the Markov blanket.
What does that mean physically?
It just means you're using a different interaction
because it's the interaction that defines the blanket
as a set of information transmitting states.
So I think we always have the hard no of the Markov blanket
but we also from an engineering perspective
because we can interact with these systems
in ways that other parts of their environments
can't interact with them or don't interact with them at least.
We're a part of the environment that can open up
new communication channels through the blanket
by changing the interaction
that effectively changes the state space
in which the blanket is defined.
Augmenting the Markov, let's say with reporters
or with optogenetics, I would imagine
it's a good example of this too.
Yeah, well, I mean, in a sense,
FMRI is a good example of that.
