why would that still happen?
And I definitely think mills,
that piece of the backbone of mortal computation
would speak to that.
Now, in terms of the observer effect
and what does that tell us about what's going on inside?
I have tag team Carl.
What do you have to say to that Carl?
Right.
Well, before I address that,
which in my world is a very simple answer, you can't.
This week I come back to the,
so that was a really interesting exchange
and really interesting examples there.
And I was just thinking from the point of view
of the sort of the classical flows and physics
that would provide a simple picture
of how on earth you can remember stuff
without changing your connection weights.
And I think Alex, you identified the key thing here,
which is the temporal scale.
So, well, where to start?
It's interesting you introduced Wolfgang Maas
because he for many years has been the king
of liquid computation and neck of state machines,
which is not, has the same kind of semantics
as the liquid brain and it's a very powerful
black boxy like kind of a dynamical system
approximator that has been proposed as one architecture
for doing predictive processing
and model computation of the sort.
But the key, I think the key point that has just been made here
is that the dynamics matter
and the dynamics are shaped by the landscape
Lagrangian variation free energy, whatever you want.
And that is a function of the implicit gradients
that depend upon the sensitivity of all say the nodes
in any given network.
That sensitivity can either be read as a connection strength
or it can just be read as a sensitivity,
in terms of to what extent do I change my internal dynamics
given this particular external perturbation.
And of course, that becomes time and context sensitive
with any nonlinearities.
So if you're talking about a nonlinear system,
then there is a, the bright line between the connection
strengths and the current effective connectivity
at this point of time in this context,
in this part of face space or state space
becomes very blurred.
So if you're writing down the differential equations,
you could go one of two ways.
You could just write down a random differential equation
with loads of variables representing interactions
between different types of states
and the response, the rate of change
of any particular state that would entail
the nonlinearity in question.
Or you could arbitrarily say, okay,
now one subset of these variables changes very, very slowly
and I'm gonna call them connection strengths.
And I'm now gonna lift those out of my equation.
So I'm now left with a much simpler sort of
autonomous differential equations
that are now parameterized by other states
that change very, very slowly.
Mathematically, you haven't done anything
but introduce a separation of temporal time scales.
But in so doing, you have now got a different kind of rhetoric
where initially you were talking about voltage sensitive
receptors and sensitivity
and contextualization conductances and the like,
which sets the synaptic efficacy,
which is fluctuating moment to moment.
And now you're talking about these being the connection
strengths, the parameters of your structure
in a mills-like context or the strengths of your connections
or weights in a machine learning context.
But the only difference, I repeat, is just the time scale.
So talking to Mike's example,
how can you have memory without changing your connectivity?
Well, you're just appealing to initial conditions
in the context of a nonlinear dynamical
and run of a dynamical system.
At what point would you start calling this
the kind of memory that could be encoded
in terms of connection strengths?
Well, in those kinds of systems
where the key, not second order nonlinear interactions
rest upon a subset of variables that change very, very slowly
and you say, well, okay, under that adiabatic approximation,
then we'll now call this a different kind of memory.
And it's just because it's slightly slower.
So I think it's, well, I liked the emphasis
on the separation of time scales
because I think that would have dissolved the reviewer's concerns
if you were just talking about really fast learning
in the moment that is all in the nonlinearities
and the dynamics.
I keep emphasizing the nonlinearities, Mike,
because of that sort of the paradox of change.
So as soon as you have nonlinear dynamics in any system
that has at one particular time scale
an attracting set or a random or a pullback attractor,
you have that itinerancy,
which means that there will be some form
of changing sensitivity to all the things
that I am coupled to.
That is definitional of things that have that biotic
or sort of characteristic kind of set.
So, you know, the nonlinearities are certainly
from a classical perspective,
I think they're absolutely key here
and resolve a lot of the distinctions
and give you now a relatively simple picture
that if there was some way to tell the next version of me
where I started, give the next version of me
my initial conditions in the past version of me,
you can, I would imagine quite simply
just write down systems that have this kind of memory
which does not involve it anyway,
a change in the connection weights.
And I'm just wondering whether that, you know,
that if you wanted to simulate that remarkable fact
that the worms remember
that they are on a two-headed trajectory
even when they start again.
I mean, I think the deep question here is
how on earth did they inherit the initial conditions
that characterised the termination of their parent
or what they inherited from.
I think, again, that speaks to this coupling
between different temporal scales.
You know, is this a messenger RNA, you know,
and how does that propagate through to the electric fields
and how does it get back top-down causation,
get back in again, it's a fascinating example.
And I've heard that before, I'm sure you've told me
but I probably ignored it because it's so remarkable.
Not easy to explain.
In answer to the question, can you ever know
what's going on inside a system?
No.
And I say no polemically from the point of view
of the Fianco principle.
You can never know what's beneath a Markov blanket.
You can never know what's on the other side
of a holographic screen.
That's the whole point of a holographic screen
or a Markov blanket.
All you can do is bring a best guess
and as if explanation to the poly computing,
if you like, in the bulk on the other side,
which means, you know, I think that's simple observation.
The whole point of that screen or Markov boundary
is that there is a conditional independence
given what you can measure.
So you can never know other than infer
by what you measure from the behavior,
the inputs and the outputs of a particular system.
Amazing.
So two questions then.
One is, is there, is it just a flat no?
Or is there a degree that is easier to know
for certain kinds of systems?
And then for sort of advanced living cognitive systems,
it's really no.
Or is it just like, is it always the same?
Or is it a matter of degree?
If you're directing at me,
the answer I'm afraid is always no.
But I don't mean that in a sort of pessimistic or,
I mean, the question, you know,
how do you infer what kind of Bayesian mechanics
or poly computation is going on underneath the Markov blanket
or inside a cell or inside a brain?
That question is, of course, my day job
and the day job of nearly every neuroscientist.
It's peaking underneath the Markov blanket
in a noninvasive way that doesn't destroy it
to try and understand the mechanics
and to test hypotheses about what is going on.
But you're always testing hypotheses you will never know.
So there will be situations where the functional anatomy
or the architect reveals itself
through noninvasive imaging, for example,
or even invasive techniques
of the kind that you use every day.
But all you're doing is basically testing hypotheses
about what you think the gerative model is under the hood.
And once you know that or put it another way,
if you knew the gerative model,
then you know the Lagrangian.
If you know the Lagrangian,
you know the intrinsic or internal dynamics
and you can tell a story about poly computing,
tell a story about Bayesian mechanics.
You can tell a story about perception.
You can tell a story about memory.
You can tell your basal cognition.
