some uh some gems yes yeah would you want to start talking or should we just wait for
let's just let's let's just start I think he's heard my introduction to this before so we can
yeah so you know I guess
yeah well yeah go ahead and ask me again what you need to ask yeah just just to kind of summarize
what I'd love to hear you talk about so so my my claim is that the process of evolution
is not guaranteed to optimize for most if not all of the things that we value so so happy
intelligence meaning all of these things and therefore the condition in which we find
ourselves meaning the various limitations of our bodies of our minds all these different features
I think are fundamentally up for improvement and so as one as one changes the various aspects of
the physiology integrates the design devices changes the biology we will change and so at
some point what is a human and and and then your views on what is it that we should not change
what's the kind of essential yes hey Richard yes hello start to keep you hi Richard hi um yeah
and happy Easter by the way Easter so um yeah um so we've just started I was just gonna comment on
something um that Michael's said it's a very important I think about um the way we're evolving
what we're capable of doing whether um evolution takes any note of the things that we would actually
value or not and I think there are there are several things really to to say about that um
um one is to do with um the model that we have of a human and what effect that has on us as well as
on the research and and another is to do with the whole business of teleology direction whether
there is I mean you're saying effectively that there is no direction to evolution and that's a
a very I think you're saying that anyway but that's a very common position well just to say
actually no I I'm not sure that's true at all okay I'm just I'm just saying that if there is a
direction it and and I think there are many sort of smaller directions I'm not just convinced
that that direction is aligned as the current terminology is aligned with the things that we
would like it to be aligned with yeah yeah yeah yeah well I think the biggest problem for us is
is I've always found and increasingly found and have critiqued at length the the sole use of the
model of the mechanism or machine in describing what a human being is and I think that at the
same time that we believe although the belief may not be well founded that we're creating machines
that are more like humans humans are indisputably being forced to be a little more like machines
in order to interact all the time with what is increasingly a machine at the other end of the
process not another human being so I think it has its impact for good or ill and I think largely
for ill it can help us answer certain very small scale questions because in a complex
system you can always find small areas if you um if you if you home in narrowly enough you
can find an area where a mechanism is actually quite a useful way of thinking but it's not a good
model of the the organism as a whole so um this also entails that when we think about human beings
we think of them largely in terms of a certain kind of cognition that we liken to something a
computer might be able to do but pretty much everything that matters in our lives is not at
all like this and when you listen to an astounding piece of music when your daughter gets married
when you simply um turn outwards to the beauty of nature um almost anything that we do that is not
rigorously tied to some matter of expounding in words we are always bringing a whole host
of things to bear that are other things that do give meaning to life and you know there is a
tendency to say there can't be meaning and there can't be values I'm not saying this is your position
but I'm just saying this is a position that one frequently counters um and and my my feeling is
that there's a problem with it because we decided in the late 17th century that we were going to
pursue a kind of science in which ideas of any ideas of purpose directional value were ruled out
at the base and so it's a bit of a um a pretty open QP to um spend a couple of hundred years
examining um the world and then say we can't find any purpose or values in it because we build them
out at the start of the process and I think being aware of that and the unspoken force that is so
important of these things that we value they might be usefully can be thought of in terms of the
great platonic virtues of goodness beauty and truth that these are not bad things to orientate
your life by and that I'm not sure that whatever it is we're doing at the moment is improving them
I also believe um that there is enormous value in what looks very negative to our point of view
because the very idea of negation is to us something bad but in fact negation is how anything comes
into being by being uh defined sequestered from something else and that in fact the business of
not doing and not thinking and indeed of silence is absolutely critical to every important human
endeavor I'm absolutely convinced of this and what we're doing is to drive out that space in which
the other things can flourish and machines don't help us with this in many ways they distract us
they substitute for that fruitful silence in which we can actually at last be creative and see deeply
into the nature of things they substitute something more familiar more trivial so I think those are
some of the problems and on teleology which is another angle um whether we're going anywhere that
sort of would um would do us any good I I mean I just have a simple observation really which is that
you know why is the life at all um and why are why is it going in the direction that it seems to
be going in terms of evolution uh I think I said last time and I'm not sure that both of you didn't
agree that the consciousness may not be something that emanates from life but is actually there in
the cosmos uh is is a an ontological primitive if that's the case then what life brings is not
actually consciousness but what it seems to do is is enormously increased responsiveness and that
responsiveness is to these these values I mean I can't tell whether a lump of wrong is is valuing
things I don't think it can value um creatures can value and some creatures can value rather
narrowly and others value I mean a single cell can value certain things but we can value more than
any other creatures and so something is happening in evolution that is at the cost of survival
because we are fragile um short-lived vulnerable creatures compared with many far far far longer
ancestors and I may mention this but you know there are single examples of actin of bacteria in
the depths of the ocean that are themselves um around a million years old so going through the
redwood forest um with their thousands and thousands of years and coming to the human being with
this measly 70 years and we're obviously not doing terribly well on surviving I'm I think
that there's something that's driving this and I think it is responsiveness I think it is that we
are responsive to these deep things and response has in it this idea of responsibility and the
sort of moral engagement with the world and I know this is nothing like what what I'm sure
is normally talked about in in the world in which either of you operate but I do think it's important
that just actually um
creating texts including from a computer that can spew out a text is taking us further and
further away from essentially creative essentially connective reverberative um resonant nature of
human experience so sorry I rather um did a little spiel there but I was trying to compress
quite a lot into a short space
I'm totally with you Ian
are you yeah that's wonderful yeah
what do you think Mike yeah I mean I'm I'm definitely in on the part where uh I I do think that uh
the things that we're interested in including consciousness and mind and all that
predate life I agree with that I think it is a I think it is a primitive and I think what life is
as you said what life is very good at is scaling it up and I've tried to formalize this notion of
a cognitive light cone which literally is the spatiotemporal boundary of the biggest thing you
can care about so the biggest thing you can activate the goals right so so I've got this formalization
of the the the biggest goal that you as a cognitive system is are capable of pursuing from
little tiny local goals of bacteria and things like this to you know humans potentially having
planetary and wider scale goals and things like this including maybe uniquely the the first ability
to have goals that are bigger than your lifespan right you know if you're if you're a goldfish
you're all your goals are achievable because they're smaller than your expected lifespan so it's
it's fine but if you're a human many of your goals are fundamentally unachievable perhaps and so
there could be various psychological pressures there but you know I'm I'm completely with you on
all of that um I think uh I think I think I see them the the machine thing a little bit differently
because and I think goals are essential and I think that we are essentially uh uh goal driven
observers and with values and all of that um I just see I just see a real spectrum between uh
you know if we if we look down the evolutionary tree and even in even just in our own in our own
bodies one can start very sort of very slowly and gradually replacing various things and you know
when we've got our our wheelchairs and our glasses and things like this which to a you know to a
primitive natural human may look oh my god like what is this you know you're you're engineered to
the gills you know but obviously that's not the that's not the limit of course you know and you're
brushing your teeth and you're you're doing all these things to extend you know your natural
state which is which is quite different than than than where we are now so um you know I'm I'm very
interested in this in this question of to me to me I think it's inevitable that we make we end up
make it because because we are physical beings in in in large part we it's inevitable that we are
going to make some some machines that are other kinds of minds I don't think they're like us at all
you know I think I think just because we can talk to them doesn't mean that they're like us at all
I think that uh the question of whether or not they're dangerous doesn't hinge on whether they're
like us I think they can be completely unlike us and also be very dangerous or not um I you know
I think I think uh yeah I'm sort of focused on this diverse intelligence idea where where there
are many other types of minds some of them are very different than ours and there are pros and cons to
you know sort of uh relating to them but but there are many different different types of entities out
there and you're not talking about living creatures here you're talking about artificial
uh in so-called intelligence networks of some kind the whole the whole business I you know there's
there's I've I've tried to literally draw out a space of like we there's a space of possible
beings that you can make yet yes there are ai's now that you wouldn't call living for many reasons
but we also have in our lab we have hybrids which are you know there's some neurons and they're
driving a little robot and they're you know and and and they really do care about what happens
but their body is now different they're not driving this kind of body they're driving
something else and that robot may not even be in three-dimensional space it may be in
physiological space they may live in a completely different problem space and partly you know there
are parts of them that you would call living and parts that you would call not uh as as as you might
with a with a crab shell or something you know there are components that have mechanical properties
that aren't actually alive but the whole thing is sort of you would call that alive so there's just
you know the space of possible I think these crisp categories used to be quite useful when the
technology wasn't there to blur them but now we're starting to see that the possibilities
are such that I'm I'm I'm not sure these these very um binary categories can be maintained
you know in the space of possible beings I think we're going to be able to explore and
maybe out there in the universe already you know so it's already been done but we are going to
explore all kinds of the hybrids and cyborgs and every possible you know combination that
that has a novel body and mind and we're gonna have to figure out ways to so I'm very interested
also in the ethics aspect of it how do you relate to them right because in the olden days it was
pretty pretty easy you sort of come and you can you knock on it and if you hear a metallic clangy
sound that tells you everything you need to know it came out of a factory and it's pretty boring
and you can do whatever you want to it and then and that's fine and if you hear sort of a you know
a soft thud then you say you better be nice to it because it's a naturally evolved creature
but that's not going to do for us in the coming decades that's just not going to work anymore
and I don't think those categories were actually ever really any good but now they're definitely
not going to be usable so we have to come up with new ways to relate to something that's
not just based on what do you look like and and and how you got here you know that's that's kind of
not just in the sense of what's what it's made out of but also so the but also the behavioral
properties right so so I was thinking I was looking at my towel rail the other day and thinking
that's made out of metal and trying to imagine it as the vibrating atoms in the lattices connected
with one another resonating in lockstep in a way that keeps all the bonds tidy and trying to think
of it as an active thing and then I was thinking about a machine in the classical sense which has
a causal a causal topology at a completely different scale this part's pushing that part that
part's pushing this part and machines are classical machines are generally built in such a way that
the causal scale that you're interested in at the machine level is completely disconnected from
the causal dynamics at the molecular level I don't I don't want what this part is made out of
to matter to the machine this you know I can make this this arm or this lever or this cog
out of something that has to behave like an arm or a lever or a cog and I don't care whether it's
made out of I shouldn't have to care whether it's made out of steel or iron or brass or whatever
and the thing that's the thing that's different about organic systems is how well connected those
different dynamical scales are that they are connected with all of the scales in between
that we have a causal scale at the at the scale of the organism where there are parts and systems
interacting with one another and this part pushes that part and that part pushes the other part
creating homeostatic cycles at that level which are causally there's a causally self-contained
story at that level that makes sense but it's really close to the level below where the level
below shows through and interacts with it in a way that well if you if you push it a bit or you
stress it a bit it begins to do something different it changes into a different you know causal story
at the higher level because because the parts are giving way the parts are squirming the parts are
changing and that in a in a truly organic system a living system filters down through all of the
levels right down to the molecular components that we can change our gene expression by thinking
about it by deciding to which is just insane right we can go from from this causal level
of something that's happening at the scale of our bodies to something that's happening
at the atomic scale and those causal scales are connected with one another upwards and downwards
so usually when we interact with the machine we are you know we feel ethically safe in turning
it off or taking it apart because when you look inside it's just some parts it's just this part
pushing another part and those parts so once you get down to the there's a there's a you go down a
couple of levels you take this apart you take that apart and then it's just material right it's just
like there's no more stuff inside that now that's just a cog there's no point looking inside the
cog you know you until you go down to the atomic scale there's nothing inside the cog right there's
no connection between that causal scale and all the others and the the thing that is a bit different
about the AIs that are occurring now is that they have quite a bit of causal depth
and they are you know their deep learning systems as there's a clue in the name they have quite a
bit of causal depth there's quite a bit of squirm there's quite a bit of parts inside parts inside
parts and they are harmonized with higher level structures that that are meaningful to us you
know they're using words that are meaningful to us they're using ideas that are meaningful
to us they're using things that are meaningful to us that are that are in tune with us and
synchronized with us but they are not connected all the way down they are they are
are not connected all the way down like we are.
And that I do think it makes them a bit more dangerous
than other kinds of machines
and other kinds of diverse intelligences.
Because it, because-
I think them, yeah.
No, go on.
No, because we're likely to think that it's like us
because it looks like us on the surface, basically.
And I don't know exactly, I think it's not that it,
you know, that it has either notes like us,
but no, I know a few layers of causal structure.
They, oh, that's like me, yeah.
Is I think the danger, I mean, we sort of often
misconceive, it seems to me, the nature of the danger,
that it's something that these creatures will do to us
in a sort of willful way.
But in fact, I think they are dangerous
simply because people will mistake themselves
for these machines and the machines for themselves.
Because the whole way of thinking
about what we're doing, who we are and so on
has become so narrow.
Children have taught from a very early age
that really we're machines.
And in fact, in an amazing royal institution lecture
to children, the lecture begins by saying, you know,
it's wonderful, take a look at one another.
And this is marvelous
because you're all just complicated machines.
That seems like a harmless remark
in the sort of world in which we move,
but packed into it is something longer
than the encyclopedia Britannica
about how we conceive of what life is,
what we're doing here and what our goal should be.
Even the phrase, goal directed,
which I know Mike was using and everybody does,
is only a part of what we do.
It's what the left hemisphere,
which is designed to have a goal
and go straight for it and get it, does.
But I'd like to put it another way
that there are things to which we are attracted.
It's not so much that we're sort of pushed towards a goal
and we know the steps and we take them,
but there are things that we can't entirely account for
but are powerfully attractant.
And therefore, something like a final cause
is operating, some idea of what could be,
which is really just a potential
that we're sort of not able to specify exactly,
but we know there's something there in that area
and we're drawn towards realizing it.
That is a quite different idea
from being a goal directed being.
And it complicates the idea of what a cause is
because famously Aristotle had four kinds of causes
and two of them have been removed.
One is the formal cause and the other is the final cause,
the thing towards which whatever it was was designed.
And we've been left simply with
the pushing and shoving kind of causation.
And that seems to me, yes, that's what a machine is,
but an organism, you need to understand the whole
before you can understand the parts
and you need to understand the parts
before you can understand the whole.
And I know that's a paradox,
but I believe that when you get close to the truth
in these areas, the paradox is what you find.
To be able to say what a spleen is,
you first of all got to know what a mammal is
that has a spleen and then you can understand it.
So we're going all the time backwards and forwards
between the whole and its parts,
whereas the kind of thinking that is mechanical
goes in one direction from the bottom up.
I said, we can do this, that has a knock on on that
and produce it, that what I'm trying to say about that,
it is nothing wrong with it,
but it's just a kind of very, very limited way of thinking
about what we're dealing with,
which is useful for some purposes.
And because it's so useful in making us powerful,
that bit of us that just seeks power,
more money, greed, whatever it is is gratified by this
and can't let go of it.
And that may turn out to be dangerous,
not as I say, because machines may turn against us.
I mean, they might do I suppose,
but in a certain curious sense,
they're already doing so, if I may say so.
I have found my life, let me make a homely aside,
I found that my life has become vastly more difficult
over the last four or five years.
And one can say COVID and when this country,
one can say Brexit and so on,
but talking to people of all ages,
everyone is finding the same thing.
And it's to do with the fact that more and more and more
of everything we have to do in daily life
has become automated.
And I know that's a million miles away
from the really exciting imaginative sort of uses
of artificial intelligence that we're talking about.
But the fact is that all our lives are being deteriorated
in front of our eyes by this business,
that we no longer can get an intelligent answer
from a person.
Everything has been delegated to a machine
and the machine can't understand the context.
It can't understand any ramifications.
It can't understand anything that's implicit.
And that is actually having a tangible,
depressing, exhausting effect
on the entire population of the West.
I think it's one of the things
that is already playing into why we're sick.
So let me just put that on the table.
Yeah, I completely agree again.
Go ahead, Mike.
Well, so I definitely agree again with the first part.
So I think that story of drilling down to the parts
which we can do and we can see all the little cogs
and things that are inside of ourselves,
I mean, literally little cogs and things,
and say, well, look, you're nothing but a machine.
I mean, I agree that that is a very pernicious story.
And I think that there are other such stories
as we've talked with Richard many times
about the standard doggie dog view of evolution
and free will, the business are on free will.
And all of these I think are very pernicious stories
for the human kind of experience.
But I have kind of a weird, I won't say solution,
but I think the answer lies in sort of
the opposite direction.
So long-term, and I don't know, by the way,
that we will make it out of this.
I think we're in a local minimum.
I think things are trending downwards in these cases,
as you said.
But I think, and if we make it out of it,
I think the way to make it out is actually
to go in the opposite direction
and to really embrace this diverse intelligence field.
So what I see in a lot of discussions about this is,
people will say these things are just like us
and therefore all this good stuff,
or they're not at all like,
they're just like us and all this bad stuff.
I think we have to embrace the idea
that we are not the measure of all things
and that we have a tendency to look at everything.
And as you say, it's extremely dangerous.
Both of you have said this, I think it's very true.
It is extremely dangerous to misunderstand
your interaction partner in every interaction,
in the good ones, in the bad, in the adversarial ones.
If you have a fundamental misunderstanding
of what you are interacting with,
you are not going to do well.
That's just, but I think the answer to this
is to really get comfortable.
And I hope the people of the future,
and I think kids are not bad at this natively,
will have this intuitive understanding
that we can relate to many things
and many of them are just not like us at all.
And that's okay.
And we don't need to assume that they must be like us
because they speak like us.
That used to be true.
It used to be that the only thing that talks
were things that kind of like you,
but that's not going to be true in the future.
Your tea kettle will have opinions
about how much caffeine you should have
and things like this.
And everything in your life will talk,
but that doesn't mean that they are like us.
And I think if we truly embrace
the lessons of diverse intelligence,
we will figure out that there are many minds
and many of them fail in different ways than we do.
And we do too, we confabulate
and we make things up and whatever, fine.
But they will have different failure modes
and you just need to know much like we have
with our various animals and things.
And this will just scale that up.
So I think really, really biting down on this idea
that there will be things that mimic aspects
of our behavior but are just not like us at all.
I think in the end, we will come to grips with that
and then we will have more productive interactions
with each other, with them, with everything else.
I think this ability to only look at things
through our own, which of course it's natural,
kind of through our own lens is really hurting us here
and it's going to.
And exactly as you said,
not because they're going to do anything to us
because we are too myopic to realize
that not everything is exactly like us.
I noticed a bit of what I would feel
is a bit of a slippage in what you said.
In that you were looking for examples of intelligences
other than our own and you mentioned that ghastly kettle
that I shall put straight in the bin
if it speaks to me even once about my caffeine intake.
But, and so was that.
And then you did also mention
and you might not have wanted to conflate this in any way
but you mentioned animals.
And one of the things I feel very strongly about
I'm not a terrifically a person
to pick up the fashion to the moment
but one word that I do think has become commoner
and is important is anthropocentric.
That our view that we are, I mean, we are very special.
No doubt about it.
And we have qualities and characteristics
that other animals don't.
But the idea that somehow there's any comparison
between a machine's ability to have
what I insist is not intelligence
which would require understanding
which would mean having feelings,
appreciating history, context, and having a body
and knowing it were going to die.
That is not the same as a more,
as we look at it limited intelligence of an animal
which comes out very rough on this
because if we prize particularly
with a kind of cognitive processing
to use the jargon that as it were a machine can do
and think that's what's special about humans.
Well, these animals can't do it to the same extent
but I'd like to say that there's an awful lot going on
in the minds of animals.
And the more, you will know about this more than I do Mike
but I mean, in researching over the last 30 years
the capacities for animals to understand things,
to think, to make calculations,
but also to feel things, to honor things,
to have rituals too.
I mean, they are truly intelligent beings
in the way that I don't think that the machine
however suave its overview of Wikipedia is
and suddenly coming up with 300 words
on what does Ian McGilchrist really about
in his latest book which somebody showed me the other day.
It wasn't a bad stab but I mean, it's not intelligence.
So I just wanted to just try and preserve a distinction there
because I think it's important
between different kinds of living intelligence
and I don't think you can then do a segue and go
but these machines are just rather like that.
I don't think they are rather like that.
Would that be aligned with a sentiment
that I have more in common with
and there's more shared values
and more appropriate compassion for a cockroach
than I would for chat GBT.
Is that the mind?
Yes, yes, there is.
I think that when you stress a cockroach
that's the same kind of stress
that I feel when I'm stressed.
It's cockroach stress, not human stress
but there's something shared and valued.
There's some shared value there
that there isn't between me and you.
I think that's right.
I mean, that's giving it a hard test
because cockroaches are not what most people want to
as it were and we can never get inside them
and know how stressed they are.
But I believe that yes, this is a continuum
with feelings that we have certainly in many animals.
There are, I think we ought to be awfully careful
about what we assume about animals,
what we do with animals
because we do have a responsibility again
that word that brings something about a relationship
that is a two-way relationship.
Yeah, so there's something about the cockroach
or the other living thing that might be limited
in its cognitive like cone compared to me.
But it's-
Enormously.
But, well, thank you.
But built to the same stuff.
And I don't really mean that it's organic.
I really mean that it has the same causal structures
at the deep levels like I do.
Whereas when I look at myself in a mirror,
I see something very like me.
I see something that appears
to have the same causal structures that I do.
And if I were to watch a video of myself,
then again, I would see something that's very like me
but not an obvious reflection of me.
It's a little bit delayed or lagged.
And AIs are able to make reflections of us
and not just reflections of one person, but of humankind.
Yes.
But there isn't another,
there isn't another,
and there isn't another,
oh, fuck it.
There isn't another soul in it, right?
There isn't other in it.
It's just a reflection of us.
And reflections of us might be useful,
but they're not.
But the cockroach really does have another thing in it.
It's a, it's also a reflection of me
because it's from the same tree of life.
But the depth of the folds involved
between me and my relationship with the cockroach
go much, much deeper than the depths of the folds involved
between me and an AI that's just a reflection
of you lay it deep.
Yes, and I'm reminded of another insect,
good old Drosophila,
and Barbara McKintock's revelation
that some kind of meaning is going on here,
that the whole organism is able to react
to parts of itself that it knows are not working,
repair them and do so in a way
that it may not ever have been prepared for
either by heredity or by its own experience.
So odd things like this
that we now know are going on all over the place.
These apparently intelligent decision-making
coming from the hole and going back to the part
seemed to me an important part of what we're talking about here
when we're talking about a living,
it's only a part of it, of course, about a living thing.
But what you, I mean, I'm very pleased
that you're not afraid to,
I'm going to have a campaign
to reintroduce the concept of the word soul,
the meaning of which I haven't any idea.
But I have lectured several times on its indispensability.
And if you've got a spare hour,
I can show you how there is no way
you can do without this word.
It won't be translated into emotion,
intelligence, cognition, whatever,
will or anything else.
But there's something there which is experiential
and that is the difference.
And it's not just a technical difference, that difference.
It's a vast difference,
which is why I'm slightly concerned about
the slippage I feel that can be made in this area
between a living being and a mechanism, a machine,
which is useful, of course,
but it's only useful if we're wise enough
to know how to use it and when not to use it
as with all tools.
And we've got amazing power to alter the world
without any noticeable recent increase in wisdom.
In fact, on my wisdom counter,
the thing is sort of sagging towards zero.
Yeah, that's very interesting.
I mean, the slippage, of course, to me,
the slippage is essential because as we look down
at the origin of life in the simpler forms,
I would like to think that the Paramecium has a soul
in our sort of parlance here,
but it's awfully close to the kinds of things
that molecular biologists are going to be able to make
using fairly machine-like interventions
and one can imagine replacing some parts of it.
And so I think that aspect of slippage is unavoidable.
However, and I completely agree with you
that today's, what we call AI today,
does not share the things that we're looking for here.
Okay, I don't think it has that.
However, I have a lot of trouble thinking
that evolution has a monopoly on creating things
that do matter.
I think that these beings that we talk about,
even though we don't have any purely artificial ones today
that match this description,
I find it very hard to believe
that only the process of evolution can create them.
And I think that if we knew...
Well, evolution didn't create those either.
Yes, that's a whole other thing, I agree with that too.
But I mean, but typically people, right?
When people say, look, this is an organism
and the machine is never going to whatever,
what they mean is it's some sort of natural product
of this tree of life and this.
I really can't believe that that is the only way
these things can ever come to be.
And I think that the shared...
So I also like what you guys said about having a shared
causal structure and things like that.
Here's what I think is essential to be shared.
I don't think it's to be on the same tree of life
because otherwise we can't relate to aliens and whatnot.
I think what needs to be shared is the existential struggle.
I think that what we want in common,
and you can sort of think about this,
somebody asked me this once,
if you were gonna go live on Mars or off in a cave somewhere,
what do you want with you?
Well, you don't want a Roomba with you,
that's not going to help.
You want a human experience.
Because I'm not sure I want a human experience necessarily.
I think I could get along with an alien
that didn't have a human experience.
But what I do think we need to share
is that basic existential struggle,
that auto-poesis where you constructed yourself
from your bootstraps at the beginning of,
and there's a lot more that can be said about this,
from scratch, from parts.
And you didn't know ahead of time
as you were coming into this world what you were
or what your parts are,
what you're where the boundary between you and the world is,
what your effectors are, what you said.
All of that had to be self-constructed.
You are in danger of disappearing pretty much at any moment.
And so these are the sorts of things,
this lack of a better terminology,
this existential struggle,
which current machines and robots and such don't have.
They're told from day one, this is your body,
here's the border between you and the outside world,
this is what you're going to do.
You get all the energy you want,
all of these things are completely different from us.
So that's where I would pin it.
I wouldn't, I think it's more about that.
It's more about knowing that we are both facing
the same kind of fundamental existential problem in the world
of figuring out who and what we are
and where we begin and where we end.
And from that, I think we can build rich,
fruitful, ethical relationships with things
that have that origin story,
even if they are nothing like us and so on.
Interesting.
Wouldn't they have to have experience though, Mike?
You know, in a way, what you said is
the machine knows all this stuff
because it's been told it, yes.
And that is absolutely non-experiential.
What you're saying about a human being
is that we learn everything through experience.
Well, let me qualify that
because we know that there's a lot
that is inherited in some way.
And that seems to be getting more complicated
and difficult to follow than it once was,
quite where that's coming from and what it is.
But still, there is that shape
and it's therefore to do with experience.
And if you were in a spaceship
with something that you didn't know
had any kind of experience
but was just programmed to say certain things,
I think that would undermine for me
entirely any quality in it
because there would be no shared feelings.
We seem to glide away from whatever you want to call it,
feeling, experience, emotion, consciousness.
These things that give us everything, actually, that matters.
I mean, as soon as you start to think about it,
everything that really makes life worth living
is not something that you can measure in the lab,
find or insert in another creature.
I mean, what is love?
Love is indisputably in existence.
I mean, anyone who's had any kind of a life
must be people who've never experienced love, very sadly.
But it would be mad to deny it,
but we can't say anything about it,
where it is, how big it is,
or how to put it into another object or a being.
It's not like that.
And so, that's just one example,
and you could say the same thing about beauty and truth and so on.
What you can do, and what people like me
who are interested in the brain can do,
is seem to answer a question,
but actually answering a completely different question.
They're saying, what goes on in the brain when you experience X,
which is not the same as what is X at all?
And so, that's another slippage
that we need to be wary of.
Oh, do you think I'm missing something there?
Well, no, I agree with all of that at the human level.
I just, and I'm sorry to keep beating the same sort of drum,
but when you say experience,
I immediately think of a single-cell organism.
And I think what is, which I do think has real experiences
in exactly the same way that we do.
And so, what does that experience look like?
Well, you know, here comes a noxious bit of salt or something,
and one can give an account of the processes
that are involved in that experience.
And then there's a causal structure,
so this thing will learn from that experience
and never try to not come back to that same area,
and it will be stressed.
And because it's stressed, it will make other mistakes
and all of these things that we would readily understand.
And I think that the fact that all of the details
about that story could have been swapped out,
and in fact, at some point, at that level,
will be reproducible.
I just, I just, I cannot fathom what,
like what would be the barrier, you know,
100 years from now from people synthetically reproducing
those events with all of the causal structure
that, you know, everything that follows.
I just, it seems inevitable to me that people will be able
to reproduce that at some point.
And I think that will be a real experience.
I think if it's real in the paramecium,
I mean, I guess the question is,
what are we going to do when 100 years from now somebody says,
look, I've put this thing together from scratch.
It does all of the things the paramecium does.
I agree with you that the paramecium has real feeling.
Why does my construct not, right?
Why don't I need to morally worry about it?
Because I actually think that,
I actually think it's very dangerous to make those kind of
distinctions because they lead to you being able to discount
in a kind of ethical concern way things that we really should be
worried about for that reason, you know.
I just don't know what the answer then would be.
Why, if we buy it in the paramecium,
why would we not buy it in another construct that was,
you know, sort of technologically attainable at some point?
I'm going to, if I may take issue with you, Mike,
about the struggle for existence.
I think that's really interesting to say,
you know, it doesn't have to be made from the same stuff.
It doesn't have to have been from the same evolutionary lineage.
It doesn't have to have been part of the same tree of life as me.
But if it has, if there's a struggle for existence,
which is meaningful to it, then we have something in common.
If I heard you right.
So I don't think I want to go that way.
I don't want to view my existence as a struggle even.
I don't think life is a struggle for existence.
That's part of the mythology created around the
separateness of me and everything else.
Life is really a harmonious resonance between me and everything else,
not a separateness, not a me trying to persist
whilst everything else that's not me doesn't matter to me.
All of the meaning is taken from my relationship to
between me and the other.
So if I would, I would gravitate towards something like
I seem more likely to have a genuine relationship with something
in a way that matters to me and is meaningful to me.
If it has the same harmonic depth that I do,
that there's multiple levels of causal structure inside it
in the same way that I do.
But how am I going to know that if it's not in the same key as me?
If it's operating...
So you can build a song out of...
You start with a particular fundamental
and you add lots of other harmonics
and you take some particular harmonics out
and you phase shift some others
and you look at the intervals between them
and you create this construct which has lots of harmonic depths to it.
And now it meets another song.
And do they have any relationship to one another?
It's like, well, if they really weren't built from the same fundamental,
then they could be discordant with each other
at every level of that hierarchy
in a way that they just don't dance together at all.
I think that what that will look like to us
is not another living thing that we can't get on with.
What that looks like to us is nothing at all,
that it has no harmonic resonance with us at any causal scale.
We can't even see it. It's not even there.
But to the extent that things are there,
it's because they're built from a similar harmonic scale as we are.
And when one song meets another and it says,
oh, look how we are harmonizing together,
how we're jazzing together here,
it's because, oh, I've got part of that refrain too.
Oh, yeah, I know that.
That little refrain makes sense to me.
I've heard it before.
Look how it fits together with mine.
And the only way that it fits together with mine
is because we are actually different branches of the same tree
drawn from the same fundamental
because there isn't any reason for us to harmonize with one another otherwise.
Yeah.
Well, I agree completely that it may be extremely difficult,
if not impossible to really be able to tell that
when your implementation is significantly different.
And so this is something, I always come back to the,
I mean, this has been retread in science fiction from day one,
that there may be intelligences that are so alien
that we are just not smart enough.
And our concepts are just not mapping at all.
That we can recognize each other in that way.
And I think that's certainly possible.
But, you know, and I also, I take your point about the struggle.
That's a very deep thing that I don't know yet what to say about that.
But I will tell you that it's more like, there's a,
I'll send this around later on.
We don't have the time for me to read this all out.
But there's a poem, I guess, is what it is by
Oraya Mountain Dreamer that basically talks about
this very issue, which are these, you know, it's,
what keeps you up at night, you know, like that,
it's not that like, you know, I'm not claiming that life is supposed to be a struggle,
but having shared concerns,
which automatically presupposes, right, that you've got goals
and that you are not a constant, you know, the paradox of transformation
and all of these things that are fundamentally kind of,
you know, even if we are in harmony and so on,
I still think that these fundamental big questions,
as far as what we are and what we ought to be doing, you know, these,
I just don't see, and maybe this is my own limited development,
but I don't see any way of getting rid of those,
even with the love and the IQ and everything else,
I don't see any way of getting rid of those fundamental questions
that are supposed to be keeping us up at night.
And that, you know, I'll send this around.
This kind of says that he said it better than I ever could.
I like the emphasis on the relationship in what you had to say, Richard,
because I believe the relationships are absolutely fundamental
it's not about a thing that is atomistically angsting about its survival,
but it's already constituted by a web of interconnections
and is part of that.
And heaven knows, I mean, I'm not going to deny that life is very often a struggle,
it surely is, but there's also a lot left out of the picture
if we focus only on that.
And we've had this about evolution, that evolution used to be presented
as purely a matter of competition, but we know that it's more a matter of collaboration
than it is of competition, though competition plays a very important part.
So there's a lot of relational stuff that's very important to the existence of a being.
And I don't know how...
You see, I think to go back to your paramecium,
I think if you make the creature simple enough
that you can actually have bits of other paramecia
in a way you've sort of done the Lego job on it, you've taken it apart
and you go, well, if I put this back in there and back in there and back in there
with any luck it'll take off again.
But you haven't really created anything there, all you've done is reverse an act of destruction.
Because the thing itself is not created by humans or by anything like that.
We don't have to be from the same tree of life in the sense that
there are many branches of it, of course, and so forth.
But there has to be a recognition that whatever we do
that helps us by saying, look, we made a paramecium,
what we're really doing is piggybacking on something that nature has given us
that we don't fully understand, but we've just about to reverse something.
It's not terribly different from doing a heart transplant.
You know, a person needs a heart, there is a heart, put the heart in.
But of course, what's really exciting and interesting about heart transplants
is it's not an urban myth.
It's how, so many accounts of this, how after a heart transplant
the person takes on something of the person whose heart they've received.
And I know of one senior surgeon at Hairstock in this country,
which is a centre for transplants, who gave up doing his work
because he was so spooked by what he was doing to people.
So even when we think we're doing a kind of parts job,
we don't really know what kind of a hole is coming with it.
We're fixated on the idea that everything can be broken down into parts
and then reconstituted, if you like.
But I think the relationship between parts and holes is greatly misunderstood.
Don't want to keep banging on about that, but it is important.
Yeah, yeah, yeah.
That I think is absolutely critical.
And I've been giving a couple of talks about this and writing some about this too.
You know, this idea that we know automatically what we have
when we understand the parts, you know, it's just completely wrong,
but very pervasive.
And I think, I agree with you about taking apart the paramecium and all that.
Let's go even further down then.
And there's this emerging field of active matter,
which I think is extremely interesting.
And I think it really, see a lot of people think that this sort of undermines
the kind of humanist, organist things that we've been saying here
and I think it's just the opposite.
I think all of this work on these amazing, unpredictable, emergent properties
of very simple systems are actually highlighting exactly what we started out with,
which is this claim that deep cognition is in some way a feature of the universe
and that we're, you know, in many ways just basically pulling these out of,
when we create these machines, these physical bodies,
we're basically just pulling out some interesting things
out of some platonic space of minds out there.
You can, there is truly minimal matter.
We're talking about two or three chemicals at most.
I mean, that's it.
So this is not like taking apart some complex paramecium
because we don't really know how this is.
This is literally like you see all the ingredients.
It's just three of them.
And what you're starting to see is unexpected problem solving behavior.
Now, I'm not claiming that this is, of course, got all the richness of the human experience,
of course, but I think that the thing that you've got with a paramecium
can already be sort of begun.
And I know you may not like the slippage,
but I really think it's a continuum, right?
You've already got it there and you didn't put it, I agree with you on this.
There are parts that you did, which is to put together the physical system
and there are aspects of the whole that you did not put in.
You didn't create, you didn't predict, you didn't know it was going to be there.
None of those are on you.
What you created was a physical manifestation that seems to, you know,
somehow pull down some of these dynamics that we have a very poor understanding of.
And on a further note of Concord before we finish,
I'd just like to say, no, I don't consider that the kind of slippage that was worrying me at all.
I too believe that, well, we don't think that we'd not equipped to understand
what consciousness exactly is or even what matter is.
But I do believe that all of that seamlessly, it is a continuum towards,
I don't make a hard and fast difference between animosity and inanimacy.
I think that they are extensions and this is why consciousness doesn't need to begin with life.
It's there anyway.
And so is some kind of direction, not a direction that is that of a tinkering God engineer,
but some sort of sense of urgent towards something complex and beautiful, I believe,
this divergence of why is it that cosmos produce such amazing variety?
Because this is the unpacking of potential that's within that whole.
And so I absolutely agree with you that I would expect to see just what you're describing from these three chemicals.
You know, and I asked him, the scientist who makes these things,
I asked him, how long did you have to search for to find these three chemicals?
You know, they run mazes and they do all kinds of stuff.
And I said, how long did you have to search for to pick the right three chemicals?
He says, these were the first three things on my shelf, I tried.
And so that tells me, okay, what else is out there?
You know, that if this was the first thing you tried, my God, what else is out there?
So this space of possible implementations is not sparse, I don't think.
I think it's incredibly dense with these things.
Yes, possibly limitless, yeah.
