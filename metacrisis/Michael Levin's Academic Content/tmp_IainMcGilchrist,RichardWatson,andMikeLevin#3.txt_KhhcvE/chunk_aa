some uh some gems yes yeah would you want to start talking or should we just wait for
let's just let's let's just start I think he's heard my introduction to this before so we can
yeah so you know I guess
yeah well yeah go ahead and ask me again what you need to ask yeah just just to kind of summarize
what I'd love to hear you talk about so so my my claim is that the process of evolution
is not guaranteed to optimize for most if not all of the things that we value so so happy
intelligence meaning all of these things and therefore the condition in which we find
ourselves meaning the various limitations of our bodies of our minds all these different features
I think are fundamentally up for improvement and so as one as one changes the various aspects of
the physiology integrates the design devices changes the biology we will change and so at
some point what is a human and and and then your views on what is it that we should not change
what's the kind of essential yes hey Richard yes hello start to keep you hi Richard hi um yeah
and happy Easter by the way Easter so um yeah um so we've just started I was just gonna comment on
something um that Michael's said it's a very important I think about um the way we're evolving
what we're capable of doing whether um evolution takes any note of the things that we would actually
value or not and I think there are there are several things really to to say about that um
um one is to do with um the model that we have of a human and what effect that has on us as well as
on the research and and another is to do with the whole business of teleology direction whether
there is I mean you're saying effectively that there is no direction to evolution and that's a
a very I think you're saying that anyway but that's a very common position well just to say
actually no I I'm not sure that's true at all okay I'm just I'm just saying that if there is a
direction it and and I think there are many sort of smaller directions I'm not just convinced
that that direction is aligned as the current terminology is aligned with the things that we
would like it to be aligned with yeah yeah yeah yeah well I think the biggest problem for us is
is I've always found and increasingly found and have critiqued at length the the sole use of the
model of the mechanism or machine in describing what a human being is and I think that at the
same time that we believe although the belief may not be well founded that we're creating machines
that are more like humans humans are indisputably being forced to be a little more like machines
in order to interact all the time with what is increasingly a machine at the other end of the
process not another human being so I think it has its impact for good or ill and I think largely
for ill it can help us answer certain very small scale questions because in a complex
system you can always find small areas if you um if you if you home in narrowly enough you
can find an area where a mechanism is actually quite a useful way of thinking but it's not a good
model of the the organism as a whole so um this also entails that when we think about human beings
we think of them largely in terms of a certain kind of cognition that we liken to something a
computer might be able to do but pretty much everything that matters in our lives is not at
all like this and when you listen to an astounding piece of music when your daughter gets married
when you simply um turn outwards to the beauty of nature um almost anything that we do that is not
rigorously tied to some matter of expounding in words we are always bringing a whole host
of things to bear that are other things that do give meaning to life and you know there is a
tendency to say there can't be meaning and there can't be values I'm not saying this is your position
but I'm just saying this is a position that one frequently counters um and and my my feeling is
that there's a problem with it because we decided in the late 17th century that we were going to
pursue a kind of science in which ideas of any ideas of purpose directional value were ruled out
at the base and so it's a bit of a um a pretty open QP to um spend a couple of hundred years
examining um the world and then say we can't find any purpose or values in it because we build them
out at the start of the process and I think being aware of that and the unspoken force that is so
important of these things that we value they might be usefully can be thought of in terms of the
great platonic virtues of goodness beauty and truth that these are not bad things to orientate
your life by and that I'm not sure that whatever it is we're doing at the moment is improving them
I also believe um that there is enormous value in what looks very negative to our point of view
because the very idea of negation is to us something bad but in fact negation is how anything comes
into being by being uh defined sequestered from something else and that in fact the business of
not doing and not thinking and indeed of silence is absolutely critical to every important human
endeavor I'm absolutely convinced of this and what we're doing is to drive out that space in which
the other things can flourish and machines don't help us with this in many ways they distract us
they substitute for that fruitful silence in which we can actually at last be creative and see deeply
into the nature of things they substitute something more familiar more trivial so I think those are
some of the problems and on teleology which is another angle um whether we're going anywhere that
sort of would um would do us any good I I mean I just have a simple observation really which is that
you know why is the life at all um and why are why is it going in the direction that it seems to
be going in terms of evolution uh I think I said last time and I'm not sure that both of you didn't
agree that the consciousness may not be something that emanates from life but is actually there in
the cosmos uh is is a an ontological primitive if that's the case then what life brings is not
actually consciousness but what it seems to do is is enormously increased responsiveness and that
responsiveness is to these these values I mean I can't tell whether a lump of wrong is is valuing
things I don't think it can value um creatures can value and some creatures can value rather
narrowly and others value I mean a single cell can value certain things but we can value more than
any other creatures and so something is happening in evolution that is at the cost of survival
because we are fragile um short-lived vulnerable creatures compared with many far far far longer
ancestors and I may mention this but you know there are single examples of actin of bacteria in
the depths of the ocean that are themselves um around a million years old so going through the
redwood forest um with their thousands and thousands of years and coming to the human being with
this measly 70 years and we're obviously not doing terribly well on surviving I'm I think
that there's something that's driving this and I think it is responsiveness I think it is that we
are responsive to these deep things and response has in it this idea of responsibility and the
sort of moral engagement with the world and I know this is nothing like what what I'm sure
is normally talked about in in the world in which either of you operate but I do think it's important
that just actually um
creating texts including from a computer that can spew out a text is taking us further and
further away from essentially creative essentially connective reverberative um resonant nature of
human experience so sorry I rather um did a little spiel there but I was trying to compress
quite a lot into a short space
I'm totally with you Ian
are you yeah that's wonderful yeah
what do you think Mike yeah I mean I'm I'm definitely in on the part where uh I I do think that uh
the things that we're interested in including consciousness and mind and all that
predate life I agree with that I think it is a I think it is a primitive and I think what life is
as you said what life is very good at is scaling it up and I've tried to formalize this notion of
a cognitive light cone which literally is the spatiotemporal boundary of the biggest thing you
can care about so the biggest thing you can activate the goals right so so I've got this formalization
of the the the biggest goal that you as a cognitive system is are capable of pursuing from
little tiny local goals of bacteria and things like this to you know humans potentially having
planetary and wider scale goals and things like this including maybe uniquely the the first ability
to have goals that are bigger than your lifespan right you know if you're if you're a goldfish
you're all your goals are achievable because they're smaller than your expected lifespan so it's
it's fine but if you're a human many of your goals are fundamentally unachievable perhaps and so
there could be various psychological pressures there but you know I'm I'm completely with you on
all of that um I think uh I think I think I see them the the machine thing a little bit differently
because and I think goals are essential and I think that we are essentially uh uh goal driven
observers and with values and all of that um I just see I just see a real spectrum between uh
you know if we if we look down the evolutionary tree and even in even just in our own in our own
bodies one can start very sort of very slowly and gradually replacing various things and you know
when we've got our our wheelchairs and our glasses and things like this which to a you know to a
primitive natural human may look oh my god like what is this you know you're you're engineered to
the gills you know but obviously that's not the that's not the limit of course you know and you're
brushing your teeth and you're you're doing all these things to extend you know your natural
state which is which is quite different than than than where we are now so um you know I'm I'm very
interested in this in this question of to me to me I think it's inevitable that we make we end up
make it because because we are physical beings in in in large part we it's inevitable that we are
going to make some some machines that are other kinds of minds I don't think they're like us at all
you know I think I think just because we can talk to them doesn't mean that they're like us at all
I think that uh the question of whether or not they're dangerous doesn't hinge on whether they're
like us I think they can be completely unlike us and also be very dangerous or not um I you know
I think I think uh yeah I'm sort of focused on this diverse intelligence idea where where there
are many other types of minds some of them are very different than ours and there are pros and cons to
you know sort of uh relating to them but but there are many different different types of entities out
there and you're not talking about living creatures here you're talking about artificial
uh in so-called intelligence networks of some kind the whole the whole business I you know there's
there's I've I've tried to literally draw out a space of like we there's a space of possible
beings that you can make yet yes there are ai's now that you wouldn't call living for many reasons
but we also have in our lab we have hybrids which are you know there's some neurons and they're
driving a little robot and they're you know and and and they really do care about what happens
but their body is now different they're not driving this kind of body they're driving
something else and that robot may not even be in three-dimensional space it may be in
physiological space they may live in a completely different problem space and partly you know there
are parts of them that you would call living and parts that you would call not uh as as as you might
with a with a crab shell or something you know there are components that have mechanical properties
that aren't actually alive but the whole thing is sort of you would call that alive so there's just
you know the space of possible I think these crisp categories used to be quite useful when the
technology wasn't there to blur them but now we're starting to see that the possibilities
are such that I'm I'm I'm not sure these these very um binary categories can be maintained
you know in the space of possible beings I think we're going to be able to explore and
maybe out there in the universe already you know so it's already been done but we are going to
explore all kinds of the hybrids and cyborgs and every possible you know combination that
that has a novel body and mind and we're gonna have to figure out ways to so I'm very interested
also in the ethics aspect of it how do you relate to them right because in the olden days it was
pretty pretty easy you sort of come and you can you knock on it and if you hear a metallic clangy
sound that tells you everything you need to know it came out of a factory and it's pretty boring
and you can do whatever you want to it and then and that's fine and if you hear sort of a you know
a soft thud then you say you better be nice to it because it's a naturally evolved creature
but that's not going to do for us in the coming decades that's just not going to work anymore
and I don't think those categories were actually ever really any good but now they're definitely
not going to be usable so we have to come up with new ways to relate to something that's
not just based on what do you look like and and and how you got here you know that's that's kind of
not just in the sense of what's what it's made out of but also so the but also the behavioral
properties right so so I was thinking I was looking at my towel rail the other day and thinking
that's made out of metal and trying to imagine it as the vibrating atoms in the lattices connected
with one another resonating in lockstep in a way that keeps all the bonds tidy and trying to think
of it as an active thing and then I was thinking about a machine in the classical sense which has
a causal a causal topology at a completely different scale this part's pushing that part that
part's pushing this part and machines are classical machines are generally built in such a way that
the causal scale that you're interested in at the machine level is completely disconnected from
the causal dynamics at the molecular level I don't I don't want what this part is made out of
to matter to the machine this you know I can make this this arm or this lever or this cog
out of something that has to behave like an arm or a lever or a cog and I don't care whether it's
made out of I shouldn't have to care whether it's made out of steel or iron or brass or whatever
and the thing that's the thing that's different about organic systems is how well connected those
different dynamical scales are that they are connected with all of the scales in between
that we have a causal scale at the at the scale of the organism where there are parts and systems
interacting with one another and this part pushes that part and that part pushes the other part
creating homeostatic cycles at that level which are causally there's a causally self-contained
story at that level that makes sense but it's really close to the level below where the level
below shows through and interacts with it in a way that well if you if you push it a bit or you
stress it a bit it begins to do something different it changes into a different you know causal story
at the higher level because because the parts are giving way the parts are squirming the parts are
changing and that in a in a truly organic system a living system filters down through all of the
levels right down to the molecular components that we can change our gene expression by thinking
about it by deciding to which is just insane right we can go from from this causal level
of something that's happening at the scale of our bodies to something that's happening
at the atomic scale and those causal scales are connected with one another upwards and downwards
so usually when we interact with the machine we are you know we feel ethically safe in turning
it off or taking it apart because when you look inside it's just some parts it's just this part
pushing another part and those parts so once you get down to the there's a there's a you go down a
couple of levels you take this apart you take that apart and then it's just material right it's just
like there's no more stuff inside that now that's just a cog there's no point looking inside the
cog you know you until you go down to the atomic scale there's nothing inside the cog right there's
no connection between that causal scale and all the others and the the thing that is a bit different
about the AIs that are occurring now is that they have quite a bit of causal depth
and they are you know their deep learning systems as there's a clue in the name they have quite a
bit of causal depth there's quite a bit of squirm there's quite a bit of parts inside parts inside
parts and they are harmonized with higher level structures that that are meaningful to us you
know they're using words that are meaningful to us they're using ideas that are meaningful
to us they're using things that are meaningful to us that are that are in tune with us and
synchronized with us but they are not connected all the way down they are they are
are not connected all the way down like we are.
And that I do think it makes them a bit more dangerous
than other kinds of machines
and other kinds of diverse intelligences.
Because it, because-
I think them, yeah.
No, go on.
No, because we're likely to think that it's like us
because it looks like us on the surface, basically.
And I don't know exactly, I think it's not that it,
you know, that it has either notes like us,
but no, I know a few layers of causal structure.
They, oh, that's like me, yeah.
Is I think the danger, I mean, we sort of often
misconceive, it seems to me, the nature of the danger,
