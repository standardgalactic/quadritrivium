So that's, that's what we're going.
Maybe it's just as easy to start from the other end.
Well, and I once we publish this paper hope some people try to use the eye.
I have a short life. I've got to pick you have to pick what you think is your best bet and go for it and my best bet is three or four gluons, as opposed to a quadrillion is where I'm going to get the testable.
I think of rather than billing, it seems like you went from from, you know, there's only consciousness.
There are special kinds of geometries and mathematical relationships out of which I can build space time and particles.
And then in space time and particles, I could build complex assemblies of particles which eventually would look something like consciousness.
It would look something like an intelligent agent.
It wouldn't. It's not the consciousness that created it all, but it's the, it's something that looks like it that resembles agency and intelligence, right?
Yeah, well, it's the, it's the headset that we use, we build the headset that we use, and the headset gives us more or less insight into the consciousness behind.
Right. So, so on this point of view, I would, I would argue that the distinction we make between living and non living is not principled.
In the sense, so right now we're on a zoom, and I am seeing you only through a screen.
And some of the pixels are pixels of your face. And there are other pixels of a wall and a picture behind you.
Now the pixels on the wall give me no insight into consciousness whatsoever.
The pixels of your face give me quite a bit of insight into what you're thinking and your expressions and what you understand or don't understand or agree or disagree.
Now, if I would just were to say, aha, that means that there are some conscious pixels and some unconscious pixels.
That's, that's a really dumb mistake. And it's the same mistake that we make when we distinguish between conscious physical objects and unconscious physical objects.
It's exactly the same mistake. We're, we're, it's, it's not a principal distinction we're making.
So we're always interacting with consciousness, but a headset dumbs things down. That's what it does. That's what it's for.
And so sometimes it reveals less about the consciousness and sometimes it reveals more because it's dumbing things down.
And we then make a category error and say, Oh, those rock is not conscious and the human body is.
No, that's just the wrong way of thinking about it. No pixel in the headset is conscious or unconscious living or non living.
Right. I could communicate with you as a conscious agent through a communication channel that only allowed most code that only allowed a single bit at a time.
Or I could communicate with you as a conscious agent through a rich multidimensional interface and many frequencies simultaneously.
Exactly. Exactly.
I get that.
So I, I think about learning and intelligence in, in ordinary physical Newtonian systems in a very simplistic way, right?
So I have this model that I call natural induction where you have a system of particles connected by springs.
And the interactions of the, of the particles with one another or with an external environment creates tensions in the springs.
And if those springs are slightly plastic, then the springs deform in a way that changes the energy function of the particles.
And you can show that it changes in exactly the same way that you would expect Hebs rule to modify the connections of a neural network.
Oh, well, okay.
So the network becomes a model of its own history in such a way that it can then anticipate the original energy function and find better solutions to the problem of constraints that were originally in the, in the, in the weights.
So if it's, if it, all that's really happening is that you're allowing the forcing on the system to deform its internal arrangement.
You know, how did it get smart? It was pushed, right? It was, it was just pushed.
Well, that's not smart. Like, you know, I can make an imprint in clay and it's a record, but it's not smart.
What makes it smart is the folding of the space, right? That the, or the compression of the, the symmetries in the way in which was pushed, whether that's over time or over space are folded into an idealized compressed representation of what happened.
And then when that pushes back, it looks like it's doing something smart because it's doing coordinated action, which is informed by that past history.
Yes. It's not really anticipating anything. I like to think of it as, it's just reacting, not anticipating.
But when everything is circular, when, when all activity is circular and periodic, being just the right amount of late is the same as anticipating.
So smart entities, entities that are intelligent are, are modified by their history and pushing back on the world as a reaction with just the right amount of late that they look like they're anticipating.
You can't really tell whether time is going forwards or backwards.
Right.
I think that you can do that with ordinary particles and springs at the macro scale without any quantum funny nurse going on.
And that, that that's actually that the, the, the violin string is, is intelligent in the, in the same way, like on the same scale, but not the same amount in the same way as, as, as other kinds of, should we say, intelligence is we find more relatable.
I was going to, I was, I was tempted to say better intelligences.
Exactly. Right.
So, so that, so that I don't have to build it from the quarks up, right. I can start at any level of organization and the thing that makes it smart is the relationships between a few different levels connected together.
Does that make sense.
It absolutely does. And there's a couple levels of which I would think about that one is that I could model this with just the Markovian kernels outside of space time in an interesting way I could say I've got this big, say, 10 by 10 again, and I have this other
say a five by five, and they share three states.
And in some sense, so that the 10 by 10 is more complicated than the five by five, but if they actually share three states and they're compatible, then in some sense when I join them, I can get a resonance of the big dynamics now gets resonated into the smaller one, and it
has a more compact representation so within this trace logic I can begin to formally do with mathematical precision the kind of thing that you're doing and looking at it that way.
So that's what one one direction, but now looking at it, it things inside space time.
It seems to me.
So first I should say outside of space time. These Markovian kernels, the dynamics need not have increasing entropy, the entropy can be constant at each step.
Which means there need not be an arrow of time in the basic Markovian dynamics beyond space time.
But it's a theorem.
When you take a slice of them there is an entropy right.
When you when you lose any information in a projection, you get as an artifact of that loss of information, the entropy increases now in evolution.
The fundamental limited resource is time.
If you don't made in time, you don't reproduce if you don't eat in time you die if you don't breathe in time you die time is the fundamental limited resource.
My guess is that the arrow of time that we see inside space time is not an insight into a deeper reality at all.
It's entirely 100% an artifact of loss of information.
And that means that our entire picture, but by the way, let me preface what I'm about to say with this.
I love Darwin's theory.
And I've done a lot of work on Darwin's theory.
It's the best theory that we have of biological evolution.
There's nothing close to it.
So we just put that right out there.
Now, every scientific theory has its limits.
Everyone.
And my claim is that all of Darwin's theory is an artifact of the loss of information from in the project projection into space time.
And that means that the, the distinction that we make between organisms and resources and all of that, the whole thing, competing nature, red and tooth and claw, all of it is not an insight into a deeper reality beyond space time.
Every bit of it is an artifact of the limitations of our headset period, nothing, no insight.
Yeah.
So that's why looking inside space time for the evolution of intelligence may be the wrong thing.
That's the wrong in that framework.
Oh, yeah.
But I'm not looking for the evolution of intelligence.
Good. Good.
We're on the same page.
Evolution.
That's sorry.
Yeah.
No, evolution is a product of intelligence, not the, not the, not the process that creates it.
So it's a product of the loss of information about the way intelligence really works.
Yeah.
So, you know, when you, when, when harmonic relationships are set up in a resonator, they're already cognitive.
You didn't need any natural selection for that.
Right.
Right.
Exactly.
Right.
When you view it at a particular time slice, a particular stroke, when you look at it with
another song, it'll look like a discrete object that's reproducing.
Yes.
The, when you view one octave with another octave, what you see is the, instead of a big loop that
twists in folds on itself and then unfolds back into a big loop, it appears to do a big loop that
folds and twists and divides and creates two.
Yes.
Yes.
And so when you, when you view one octave with another octave that's a little bit off, you
get this sort of continuous expansion of, you know, creating stuff out of stuff out of stuff.
Right.
And it has, it has this weird property that you, it looks like you took something and you broke
it in half, but the two halves that you have, they're not halves, they're holes.
Right.
Right.
You know, because the hole is, is already folded inside, right?
It feels sort of pre-formationist, but that's what harmonics are, right?
The hole is already folded into all of the parts in a sort of hole.
Exactly right.
Right.
Exactly right.
You know, I agree.
Now that's, and I think those intuitions can be cashed out with this precise mathematics.
I have not done that, but, but I, but I would be a direction that I would agree is a very
fascinating direction.
So I wonder, I wonder if there's something, I wonder what, you know, basically I'm wondering
what's left for me to add, right?
If you've already done all the math, because I'm, because I'm working at an intuitive level,
but you've already done all the maths.
So I wonder if there's, if there's something in that notion of how a physical system can
come to have knowledge of an environment just through an ordinary Newtonian sort of deformation
of its internal structure, that, you know, it's just a ball rolling downhill.
It's just local energy minimization, which puts knowledge into it.
If it has this folded structure, there's two levels of architecture happening at once.
So that it's not just a language in which you can write intelligent things, but it's a,
it's a description of the process that puts the intelligence into it as well.
Well, first off, I don't want to give the impression that we've solved everything.
That's not the impression I want to give.
I think that we've taken a first step in what's going to be, I think, a really interesting
and long journey, but just the first baby step is the way I look at it.
For example, I can't tell you yet how to model even a quirk in our theory outside of space time, right?
So all the fun work is ahead still on that.
And we have hints, right?
So I can say what some of the hints are to try to make this kind of connection into space time.
One is,
we propose, and we do this in the paper that I'm writing right now,
that the mass of a particle corresponds to the entropy rate of the Markovian,
the recurrent communicating class of the Markovian kernel that is a projection of.
So the entropy rate is, so a kernel, each row is a probability measure, right?
Each row is a probability measure.
So you can talk about the entropy of each row.
So each row has its own entropy.
And then you, if it's an ergodic kernel, you have a stationary measure.
So you have a probability measure for each row.
So you can just add up all the entropies weighted by their stationary measure.
And it's called the entropy rate.
So it's a very, very simple. It's a nice clean notion of the entropy of the entire kernel.
And we propose that that is what corresponds to mass in physics.
The entropy rate, it's telling you how much each state,
the entropy rate of the system is telling you effectively how influential it is, right?
If you have all zeros and ones, then you don't hardly influence anybody else.
You only influence one thing.
So you're influenced, so that's, and that's going to be zero entropy.
So if you have a bunch of zeros and a one in a row, well, that row has zero entropy.
It's going to have no influence.
It has no mass.
And that entropy will be, so that's, you're only ever seeing the entropy of a particular projection, right?
Because you're not seeing the true entropy or the true mass, right?
And that's going to be really important empirical tests of our theory,
because we need to actually understand the statistics of this partial sampling process that's going to happen.
So the trace chains are, as I mentioned, they're assuming an infinite trace.
But we will have finite traces.
And what we plan to show is that that makes a difference in what we get in our physics.
So at the quarks and gluons inside the proton, I'll just mention.
When you look at the horses spatial and temporal scales inside the proton,
what they call Bjork and X, which is the temporal scale and Q-scored, which is the spatial scale.
You see three valence quarks, two up quarks and a down quark.
As you start to get finer and finer spatial and temporal resolution,
you'll see a bunch of quark, anti-quark pairs of what they call a quark-c,
and a bunch of gluon, an ocean of gluons.
And then as you continue to go even further down, you get just an ocean of gluons.
It's just like seething gluons, and that's all you see.
How are we going to explain that kind of thing?
Well, quarks are fermions, they're massive particles,
and gluons are massless.
They have no mass, so they're traveling at the speed of light inside a proton.
So it's frenetic.
The inside of a proton is frenetic because there are particles traveling back and forth
at the speed of light inside this tiny, tiny little thing.
This is truly a seething thing.
Now, what is a massless particle in our theory?
It corresponds to a matrix, a Markov matrix that has only zeros and ones.
So actually, given our definition of entropy rate being mass,
we now know what massless particles are.
The massless spin-1 particles are particles that are periodic.
So you can start to see, we can start to get this really beautiful dictionary.
Now, what happens when we start trying to build up a trace chain
at really, really high, so really small time samples and really fine resolution?
Well, the way you're going to do it is you're going to have to sample.
So I got this state, now I got this state, now I got this state.
So now I can start to figure out, okay, there's probably going from this state to this state.
So I can start to build up.
What am I going to see?
My initial matrices are going to be zeros and ones because I don't have enough data to do anything finer.
But that's not an insight into the nature of reality.
That's sampling error.
