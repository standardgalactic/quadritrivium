Exactly. So we're going to show this like I'm, we'll give examples.
So if you want vibrations, you got vibrations here, you got all possible vibrations. You have an organization that good that a logic that ties all of them together in one beautiful symphony.
And it there's no single greatest at the top. This is a heterarchy. It's really, really quite interesting. So, I mean, if I was to go spiritual and say, instead of saying there is the one, say one consciousness, there is, I would have to say the whole, because there isn't just the one, it's it there is no
greatest element, there is something far richer than that.
So, I was nodding as it was going through because as you were going through all the stuff, I was ticking off on this back. Yeah, you can do that. Yeah. Everything that you're you were saying, here is a mathematical way to do it.
Now, I said, there was one proviso.
Here's the proviso.
Markov kernels are universal for any
probabilistic process that has a finite memory.
Now that finite memory can be as big as you want. In other words, like when we define a Turing machine, right, we say there's a tape, and the tape is as long as you need it to be.
And as everybody goes, okay, well, I don't care about that. There's no restriction here. It's the same thing with Markov chain. Yeah, it's fine, but it's as big as you want it to be just like the Turing tape can be as long as you want it to be.
So, in practice, it's universal.
In practice, it's universal. And so, so, so we're working on on this with this called the trace order and the trace logic.
And then there's a beautiful thing that comes out of it.
What we propose is, so there's been a big open problem in science. And that is, please, what is an observer.
In Newtonian physics, the observer was aloof.
Didn't affect what it was observing and you didn't have you didn't need a model of it because you could ignore it.
We now know that that's too simplistic in Einstein.
There is the observer and you have to use the notion of an observer but it's really just a reference frame. It's a system of clocks and coordinates. That's all.
There's no real deep theory of an observer in quantum theory.
Now the observer comes front and center, right, because the evolution of state in quantum theory is linear.
When the system is not observed, it's a shorting or a question, it's linear.
When you observe, the change of state is nonlinear.
You go from a superposition, you know, a complex superposition of eigenstates to a single eigenstate. That's nonlinear.
That means you cannot use quantum theory to give you a model of the observer, period.
Can't do it. The linear quantum apparatus cannot model it.
And decoherence doesn't solve it at all because all decoherence does is it maps from a complex superposition of the eigenstates to a classical mixture of eigenstates.
But it does not take you to a single eigenstate. So decoherence is a red herring. It doesn't do the job.
There is no job that can be done using quantum theory.
So that's why they've been pulling their hair out about the observer.
And Wolfgang Pauli said, you know, this is one of the big problems. In 1954, he said, this is a big problem. We need a theory of the observer.
And then just two years ago, Frank Wilczek said basically the same thing in an interview.
So quantum theorists are still, what is an observer? And I actually went to a physics conference a few years ago in Banff where it was all about the role of the observer in quantum physics.
And by the way, saying, well, we won't talk about observers, we'll talk about measuring apparatuses, measurement apparatuses, which is what Heisenberg did and Asher Parris did and a lot of people do.
Well, that solves nothing because the measurement apparatus must embody a non-linear process. It has to be non-linear.
So you have the same problem. Whether you call it an observer or not, you can't do it with quantum mechanics.
And measurement apparatus has no reductive explanation in quantum theory.
So that's one of the big open problems in science. So here's what we propose.
We've talked about these agents being represented by Markov kernels and so forth.
One agent observes another if it's a trace. End of story.
The trace operation. If one kernel is a trace of the other, it is observing the bigger kernel.
Now notice what this does. It's truly remarkable.
We wanted to have observers that were independent aloof and don't affect the, this is different.
If you observe, you are an organic aspect of the very thing that you're observing.
You are intimately and organically, not just looking at it, you are part of it. That's what this is saying.
And that seems right to me. That seems very, very right.
So this gives you a theory of observation. Now what are the outcomes of observations?
There are observations and then there are outcomes.
So I've said what an observer is and what an observation is.
But now what are possible outcomes for this and how do I model that?
And so one interesting thing about Markov kernels, if they're ergodic and unless they're periodic.
So you need to be ergodic. You need to be a periodic.
Right. And you need to have a single communicating class.
So, and we can talk about the others because the others are really interesting and I have some things to say about them, but.
But let's just talk about ergodic ones because they're the math that I'm at least on clean mathematical grounds and I can say precisely what the answer is.
For the ergodic ones, which are the bulk.
You can talk about the what's called the stationary measure of the of the Markov chain.
For example, for the 10 by 10, the stationary measure is a probability measure on the 10 states.
And what it describes is the long term probability and being state one or being in state two all the way up through state n.
So it actually it solves the equation if if the kernel is P capital P and the stationary measure is mu, then mu P equals mu.
That's the that's the equation you have to solve mu P equals mu pretty straightforward.
That's the stationary measure gives you the long term.
In some sense, the long term probability of what you're going to see the outcome of your observation.
So, so it turns out that we have this this non Boolean logic on observers, the trace logic.
So, what we're proposing is there's a map from the observers to these probability measures that are the stationary measures.
So we need to ask ourselves is there a logic on these probability measures, right, because we would like to have effectively a logic homomorphism between the observers and the kinds of probabilistic beliefs that observers might have as a result of observation.
Well, it turns out there is a logic.
And I and a couple collaborators published it 30 years ago. It's called the Lebesgue logic of probability measures.
And that logic has also a trivial definition.
And the definition is that one probability measure mu is less than or equal to a probability measure new.
If mu is a normalized restriction of new period, that's simple.
So, so mu is, you know, it's on a subset of states of new.
And when you restrict new to that subset of states, you get me that's all.
That gives you an incredibly beautiful logic. It's again non Boolean.
There is no greatest element.
It's locally Boolean. If you take a particular probability measure and you look at all the probability measures that are less than it, then they form a Boolean logic.
It's more general than the ortho modular complemented lattices of quantum logic theory.
So it's more, more general than that.
And it turns out, we're showing in this paper that the map between this trace logic of the dynamical systems into this Lebesgue logic probability measures, which is the, you know, the probabilistic beliefs that come out is a homomorphism.
So the whole thing ties up unbelievably beautiful. There's a homomorphism between observation and probabilistic belief.
So, and harmonic behavior is that is the core of it.
When you actually look at these Markov kernels, that's, that's what you look at all the eigenfunctions, for example, of the space time chains or just of the regular kernels themselves.
It's all about harmonics.
Now, you know, what we're so, so I'm, that's why I was nodding the whole time. I mean, everything.
I would, I could say, here's the piece of mathematics that models that that's that's what models that and it's so I mean, so I'm completely on board with what you're saying and so there's a wonderful dialogue, you know, to go for now, where to go where we're trying to go with this.
Can I can I reflect some some additional symmetries, which I noticed so the word that I'm using for a stack of frequencies in harmonic relations is a song.
Yes, the finite memory that you're talking about means that the song is always eventually cyclic right that it's going to it's going to come around again right that it's that it's a repeating thing right.
Not necessarily chaotic stuff stuff can happen out of finite systems.
Okay, we'll come back to that. Yeah, the trace in in my mind relates to what it means to resonate one song with another.
So when one song meets another song and they resonate.
That the two songs have to share some frequencies in common, otherwise they can't resonate right or have a harmonic relationship between those frequencies right. Absolutely.
And the, that means that in order to observe in order for one song to be sensitive to another song, they both have to be drawn from the same super song.
They have to be harmonically related to one another, otherwise they can't be observed.
And the ability to observe the detail or agential nature of one song requires an agent, an observer which is just as agential, which has the same harmonic relationships between it.
Yes, that's right.
And it's, it's not just a question of saying, you know, can you measure all the frequencies which are in this song we're like, like a Fourier decomposition does.
Because you say, you know, it's got it's got a lot of this frequency and it's got a lot of that frequency there I measured it, right. It's like, no, you didn't really see it yet, because that frequency and that frequency, you know, they, they're not really different from that frequency and that frequency that's moved a little bit,
but that's completely different. That's a completely different thing. Why is it a completely different thing? Because these were in the octave relationship and those weren't, right?
Right, right.
Because you're not just seeing the frequencies that are in it, you're seeing the relationships between the frequencies.
Absolutely.
See that you need to be the octave, not just have the two frequencies in it.
That's right. The way that we capture that kind of intuition in this trace logic is when we have, when you have a logic, there's what's called the meet and the join.
And the join of, of two entities, right? The and and the or.
So the meat is the and the, the join is the or, but, but they call it meet and join.
Now, if you have two Markov kernels and they both have say, they both have 10 states, but, but seven of the states are different than they only share three states between them, right?
So this guy has 10 states. This guy has 10 states. They share three states, but each has seven different states, right?
That, that, that for most of the time, if you just give me two random kernels like that, they are incomparable because they, they do not agree on the states where they overlap.
Which means they can't observe each other.
They can't observe each other. They can't form a join. They can't form a meet. They are incomparable.
Apples and oranges.
The apples and oranges and most of them are right. The probability of that is very, very high.
Yeah.
But if they do, if you have the two 10 by 10s, for example, they overlap in three, but they do have a meat. So they do agree.
And there is a trace that they both share on those, they both share the same trace chain on those three states.
Then you can take their union there. You can take their join.
And what that does is that then there are new transitions because there were no transitions before the seven extra states of the first guy and the seven extra states of the second guy never had any direct communication before, before, right?
Yeah.
But when you make the join, the new kernel has all the right connections between them to make the whole thing harmonious to make the right song.
A chemistry that makes a new thing that reacts.
It's unique in general. So there's a unique right song that melds the two original songs if they overlap. So that's why I was nodding all the time. Your your intuitions are really being captured.
So, so it crudely this meet and join it's like the inner and outer product and if you do it properly, it's like the Clifford algebra right with the wedge product.
I would love to prove that that that I mean I've been thinking about that.
And I've, I wrote down actually an order relationship on geometric algebra entities as well.
I said it may be homomorphic to these logics as well. So there may be. So, so, so, so yes I've been looking in that direction. And I actually, a few, few months ago, gave a paper to chase on my, my mathematic collaborator with a partial order on Clifford Algebras, which I should go back and look at it
because it may be homomorphic to this which which case would be really good.
So my intuition says that it is because the through from the songs and the frequencies you can get to the list of your figures and from the list of your figures you can get to the shapes and geometries.
And then the introduction of two songs is the geometric algebra that converts one shape into another shape.
Yes, yes.
I'm completely on board. And I should pull out that piece of paper again that I sent to Chaitan and then go over that logic.
That would be I might even want to include that in the paper we're doing right now but just point that out that's that's yeah.
So the, the computational part.
The second point is that when you, when you strobe a song at a particular frequency and it looks discreet, if you've got the right frequency it looks like a nice orbit, or it looks like a another list of your figure.
It's stationary if you if you strobe it at the right combination of frequencies that that structure that structure that it describes has correspondence with the Lambda calculus too.
So that you can you can describe what a song is the discrete the discrete stationary structure of a song when viewed at a particular frequency is a program and the interaction of two songs can be described as the application of one song to another as the application of one
Lambda calculus expression to another Lambda calculus expression to create an output.
Well that that I would be very interested to see that that would be lovely and that would be new to me that would be very new to me so I would I would really anything that you could send me on that I would be most most interested.
Yeah, I did just intuitive at the moment.
Well, sure, sure.
But but but also intuitively, when you look. So, if you look at a Markov kernel, and you look at one that is periodic.
So every row is all zeros except there's a single element that has a one.
And this.
And then, you know, you cycle through the end states in some order, one right to end. And then you so that has a specific clean frequency, right.
Now, suppose you take another Markov chain that's also 01 but it's also on 10 states say, but it's a different different order.
And now you add the two and waited. So maybe 0.3 of one and plus 0.7 of the other. Well, now you have a Markov kernel which is now ergodic.
It's now an ergodic kernel, but it actually has two basic frequencies. And if you keep doing this you realize that all these ergodic kernels are really just sums of these frequencies of basic kernels.
That's what you really and you're just waiting them. So, so each one of these complicated kernels is a complex harmonic score of all possible frequencies that are going on and you could have some frequencies and they don't all have to be frequency of 10.
So, so it's quite rich that way.
Awesome.
So the, how do you speak to the interest in whether, you know, so the Markov kernels and their ability to interact or relate to one another, you know, interacting is really just seeing what the relationship is between them, right.
How do you speak to the possibility of those that the origination of those kernels and how they come to have information that's shall we say intelligent in capable of producing intelligent action.
Well, the first thing to know again as we talked about before is that the Markov kernels are computationally universal.
Sure. So they could be anything. How do they get to be something specific.
Well, my guess is that anything that's possible is actual.
Why, why not any. So I think this entire trace order and all the possible kernels is a
I'll put this way. I think reality is no less complicated than that.
It's probably much my own attitude about scientific theories is everything we thought of so far is trivial compared to reality, including my the current theory that I put out there it's trivial compared to reality.
But so, but I would say that reality whatever it is is at least as complicated as the entire trace logic and all the possible kernels on it, and we're seeing just a little bit piece of it.
Yeah. So I mean, that I think I'm, I think I'm okay with that. But in our little corner of the universe where you're where we have where we have some shared history.
Yes, you know, and you know, we can talk about the same space time and the same entities and the particles in it and shit like that.
We were interested in agents that know stuff about the world that and and we're interested in the processes by which they came to know it.
And what it means to be able to, you know, act in the world intelligently, right?
Yes. Right. So that is a very high priority on stuff I'm doing right now that to try to answer that question and here's here's the direction that we're going on.
What I want to do is actually try to solve that kind of problem by showing that if I start with only this logic of the trace logic of Markov kernels.
I can build space time and quantum physics and general relativity out of it as a headset basically that certain of these conscious agents used to interact with others.
So that's so that's now to do that is a non trivial thing I want to use the architecture of these Markovian kernels as a computational architecture now like a neural network to build to actually build a space time as a user interface to answer to as a way to answer your question.
Now, to do that I really am going to ultimately have to get a mapping from the Markovian dynamics that I've been talking about into space, you know, a model of space time with quantum field theory and the whole bit.
Now, fortunately, we have some help in this from high energy theoretical physicists just in the last decade.
And here's what they've done.
They realized a few decades ago that space time cannot be fundamental get falls apart at the plank scale.
So it's not fundamental.
David Gross wrote a paper in 2005, you know, the centennial of Einstein's discovery of special relativity so as a, you know, an honor of Einstein said thank you Einstein for space time and then David gross then went on to say space time is doomed.
Thank you Einstein for giving us space time but space time is doomed. It cannot be fundamental and we need to. So in the, the intervening almost 20 years.
We've gone at it. And in the last 10 years they found new structures entirely outside of space time. So they're, these are not structures like curled up inside space time like you think about in string theory.
These are structures utterly beyond space time. And by the way, utterly beyond quantum theory. There are no Hilbert spaces here.
So they found that the new field is called the field of positive geometries and the European Research Council, just a few weeks ago, launched a 10 million euro multinational collaboration.
The conference just a few weeks ago, a couple weeks ago, 100 over 100 mathematicians and mathematical physicists. They're, they, and it's called universe plus you if you go online and look up ERC universe plus.
It's all caps universe and then a plus sign at the end of it, you can read their very ambitious statement, we're basically saying we're going outside of space time, beyond quantum theory we're using positive geometries for a new foundation for physics.
The scientists have realized space time is not fundamental. And in the last decade, they've stepped outside of space time that positive geometries are things like amp to Hydra, associate Hydra cosmological polytopes, and then words I've heard but yeah, right, right, right.
But yeah, they're, they're, they're, they're positive geometries they that's really interesting they're like polytopes. In some cases they are polytopes, but the the amp to Hydran is not a polytope but it's polytope like that they're positive geometries.
And they've also found these combinatorial objects that they can use to classify these, these positive geometry. And in particular, decorated permutations. So these are permutations with a little twist if you're interested I can tell you what the twist is but but for now just leave it as decorated permutations and if you want I'll tell you what the twist is.
But what we found. So, don't worry, I'm not going to say that's not a decorated permutation.
I'm not decorated enough for me. This question is that who ordered that and why, right. And so, here's what we're up to. We have these more coven dynamics we have this trace logic, and the Lebesgue logic, and so forth.
We've already made connection with the decorated permutations we actually said, the decorated permutations classify these positive geometries.
Can they classify our Markovian dynamics, and I can send you a paper we published that. Yes, they do. And what they and when we did the classification, what it said was the thing you want to look at are the recurrent classes.
And that's what corresponds to particles in physics. So that that that one step already told us where to look in making this map from the Markovian dynamics to to particle representation in space time, these recurrent communicating classes correspond to particles.
If you're going to build intelligent agents.
You're going to have to build space time particles and all the rest of it first, and then build intelligent agents out of that.
I want to do it in in what looks like a physicalist matter, sure.
I think of these, these conscious agents as already intelligent agents.
So, basically, it's building a space time is only to build a way of sort of giving a physicalist instantiation of this intelligence.
The reason we have to do that, by the way, is that's where we can make experimental tests right it's only inside space time that we can test our theories.
So I have to project this theory of conscious agents into space time. Otherwise, it's just airy fairy mathematics on testable.
So, our goal is to is to precisely predict the momentum distributions of quarks and gluons inside the proton using this this to actually show how space time arises.
So precisely what a quark and glue on is from our theory that we predict exactly to 10 decimal places the momentum distributions of quarks and gluons inside protons.
Then, then the theory is probably still not right but at least it should be taken seriously. So that's that's what we're up to.
I see that does sound hard.
I mean, nothing, nothing less is science right you if you have to go big or go home that there's no reason for anybody to take this theory seriously if we can't make a prediction that you can test at the large Hadron collider for example.
And the reason, by the way, we're going there is because those are the simplest predictions that we can make single quarks and gluons or small numbers.
If I look at the brain now I'm talking about quadrillions of quarks and gluons. Why should I start with quadrillions. Let me start with one or two, and then work my way up to quadrillions.
