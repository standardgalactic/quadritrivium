So I'm pitching for cognition first theory of evolution.
Okay.
The usual orthodox understanding of the relationship between cognition and evolution is that cognition is a product of evolution.
And evolution by natural selection comes first and it sometimes will be it rarely produces things which are cognitive.
And I'm considering the reverse that cognition comes first and that in special cases sometimes perhaps rarely produces natural selection processes.
So the, you know, obviously that has some, you know, the words are slightly different, but it has some resonance with a consciousness first sort of theory of things.
But I don't want to end up with a model of things which has a sort of a strong physical stroke non physical distinction between things.
I would rather have a theory where there's a graded scale of things which are more physical and things which are less physical.
And that there are so there are different multiple different levels of causes, which are each of which is slightly real to the level see the side of it.
How are we doing so far.
Hang it in there.
Let's see how this goes.
All right.
So, one way.
One sort of motivation.
Let's do the motivation first right so I'm trying to keep things tied to biology and answer questions that need answering in biology.
And in biological systems, you know, the sort of the orthodox view that genes control everything at the bottom and everything that organisms do above that.
The regulatory activity, the cellular activity, the tissues and organs and organisms are all just products of the genes and none of the processes which are going on at those higher levels of organization matter except in so much as they are consequences of genes which affect
infection.
Is there, you know, everything at the bottom is the only level that matters.
Whereas, in reality, we know that there are self sustaining causal processes going on at all of those levels of organization.
You know, the cells are at the level of organization of cells, real things that interact with other cells with certain kinds of signaling that create self sustaining conditions for cycles that recreate the conditions for their own
information at that level of organization.
It's great to be able to say something like that and have somebody nod.
The thing about, you know, that's true in physical systems too, but you know, from, you know, quarks to cosmos, but the thing about biological systems, organisms is the connections between those levels and the relationships between them.
So the levels below smaller scales create the entities that get involved in the relationships at the higher level.
And the levels above create the context or boundary conditions in which those entities move or interact with each other.
So the level above and the level below is needed to define whatever is going on at the focal level that we're talking about.
But what's the relationship between those levels because it isn't, we're not satisfied with the story where the bottom level determines everything.
Right.
Because it doesn't determine the boundary conditions under which those entities move.
And we're a bit uncomfortable with starting at the other end that, you know, as though, because it seems to imply that there was a plan into which everything should fit.
A plan that created all of the parts that was necessary to make, you know, the high level thing that was intended in some sense.
So, let me see if I can stop my laptop pinging a second.
So, I want to suggest that the, that there's a, that the way in which those levels interact with each other has a specific general form that's to do with compression and expansion between levels.
And that when levels are linked in that way, the interaction between levels is what agency is interaction between levels is what cognition is.
And that that kind that kind of multi level structure arises spontaneously and naturally without presupposing any of this particular biological machinery.
And that it's a natural property of physical systems and that it's cognitive in nature so that it's capable of holding memories doing learning and using learned knowledge to act in the world in a way which constitutes intelligent problem solving.
So, I drew a little picture today riffing off a picture from your work, Don.
Okay.
Can I, let's find that document.
You'll note, I'll share it in a second, but you'll note that these are hot off the press because I drew them with the pen and paper and took a picture of them I haven't turned them into a, into a electronic form yet.
Let's see.
Share the screen.
Okay, can we see that.
Yes.
Okay, so in figure a, we have an agent separated from the world.
And the detail of the world is sensed by the agent into Percepts.
Sort of decision process cognitive process happens which turns that into a decision. And then the decision.
Organizes the actions back into the world. So that's inspired by your way of decomposing things don't make sense.
Okay, so now I'm going to turn that into a slightly more computational way of thinking about those relationships.
So out there in the world we have some system of entities with interactions between one another which is all sorts of complicated.
That detail is compressed into a lower dimensional model of what's going on in the world.
You run that model.
A little bit.
Things happen.
And the results of running that model and then expanded back into the world.
Information integration run the model and then collective action transferred back to the world.
So I think that, you know, from a sort of computational cognitive science cognitive intelligent agent way of thinking about things we would say that a system that did that was doing something.
And what you mean by being able to do something essential is that you have an abstracted view of the world that you can run forward in time.
Faster than the real world.
And then take actions as it were in advance of the things which were going to happen in the real words that you anticipate what happens in the world rather than reacting to it.
Okay.
So now I want all of that to just happen spontaneously for nothing for free.
That's not something that requires you to build, you know, a neural network or a deep order correlator or something like that, or to evolve machinery that does it that that's just something that happens for free in the natural world.
Okay.
And the way I'm going to get there is through harmonic resonance.
So in figure C, we have one causal process at the top of the figure, a cycle, you know, just a cyclic attractor something's happening in the world. That's a cyclic attractor.
And the thing that's happening in the world looks like there's different things, you know, there are black particles and white particles and they're not in the same space at the same time.
You know, there's stuff happening in the world.
But it turns out there are symmetries in the world that in the sense, you know, the black particle and the white particle are different from each other that different particles and different points in space and time.
But really, they're not so different from each other because they're also both particles both in the same space of entities.
They're in a sense a reflection of one another.
They might be not the same, but they're also not different in every respect.
And that symmetry means that the cycle, the causal loop that they're in can collapse, twist, collapse, twist and fold in such a way that it creates a loop of half the size where everything is going round twice as fast, a doubling of the frequency.
That's the model where the symmetry between the black particle and the white particle has been collapsed into that's just particles.
Like this is a general model of particles. It doesn't care about whether it's a black particle or a white particle.
I can run that general model, turn that general model through time to see what will happen in the next time step faster.
Because it's a higher frequency model like I go around that once I've actually gone around in the real world twice, right?
And as that loop then unfolds to unpack the symmetry that was in it to split that symmetry back out into an unfolding and connect it back to the world.
I've made something which is influencing the real world in a way which you can think of as anticipating what would happen.
But you can also think of it as, well, these are just two symmetries in the world which coexist at the same time and influence one another in both directions simultaneously.
Ah, still nodding. Okay.
Yes.
All right.
So now I'm just going to do that through multiple levels in figure D.
Right. So it's, you know, you start with, there are many different things in the world. You fold them up once.
That creates a sort of lower dimensional model. You fold them up again. That creates a lower dimensional model. You fold them up again all the way down, all the way down to what?
At the bottom of everything, it's like, everything is the same thing.
Like there's only one electron in the universe.
And time isn't even really a thing. Like nothing really changes. Everything's the same.
Nothing, there's nothing actually happening.
And as you come back up the other side unfolding, unfolding, unfolding, unfolding, all of the symmetries are broken.
And all of the complexity and diversity of physics, life, the universe and everything is recreated back again.
All of those levels are there simultaneously. And all of those levels are connected.
But they're not connected in an arbitrary way. They're connected in a specific way, which is to do with folding of removing one dimension from the space at a time.
Folding it in a line of symmetry that retains as much of the local integrity that you had at one level is maintained as you fold it into the next level.
And that in musical terms, each fold is a two to one octave, a two to one relationship.
So I don't think that this is just a model of what happens in physics, right?
What, you know, super symmetry stuff that happens in quarks and stuff.
I think that that's the stuff that happens at that kind of level of physics is the same as the stuff that we were talking about in figure A.
And that, you know, that arises spontaneously even when you do something simple like bow a violin string.
The violin string is imbued with agency when you do that.
And its ability to act agentially on the world is not very much, but it's not nothing.
And I can tell you the story about how it does that if you're ready.
Sure.
All right.
So let's say that the violin string is not vibrating to start with and we start dragging the bow along the string.
What's happening?
There are microscopic disorganized interactions between the bow and the string.
They're not in phase with one another.
They're not at the natural frequency of the string.
They're, you know, they're far away from the natural frequency of the string, but they're putting a little bit of energy into it, almost like, you know, just sort of heat at that stage, right?
So they are going to start resonating in the string.
The resonant frequencies that build up in the string, notice that they involve top down and bottom up causation at the same time, because the frequencies that build up in the string depend on the macro scale geometry of the string like its length.
And they also depend on the micro scale properties of the material that it's made of like the elastic bonds between the molecules at that particular tension.
And those bottom up and top down determine which frequencies build up in the string and which frequencies don't.
And the energy which is going into the string is converted into organized oscillations which stack up and form simultaneously at all of those levels.
What's interesting, though, is that in so doing, the string pushes back on the bow, and it changes the nature of the interface between the bow and the string.
How does it do that?
Well, what you needed in order to play the fundamental frequency, this massive long wavelength frequency that you get when the playing is when the stroke of the bow is in full flow, as it were, when the string is singing loudly.
What you need is to convert the linear motion of the bow into a reciprocal motion of the string.
Like, how do you do that, right?
The bow is just pushing it, but it needs to push the string when the string is going that way, and it needs to not push the string when the string is coming back.
So the string is organizing the stick and slip dynamics with the bow.
It's allowing the bow to push it when it's stuck.
And once the tension builds up, it slips, it joins to a different part of the bow, a little tick backwards, which then drags it forward again in the right direction.
So that you have, in a sense, a percussive motion of the bow.
The linear drawing of the bow is turned into a percussive motion of the bow, almost as though the string doesn't see the whole bow.
It only sees intervals on the bow that are the right distances apart for it to drive the fundamental.
So the string is organizing the way the interface that was providing the energy to give it energy at the right intervals that sustain the fundamental.
Once the fundamental is going, it's sort of obvious that it does that, but it had to create the fundamental in order to push back in that specific organized way.
The disorganized energy is converted into an organized energy that controls in a quantized way the interaction between the string and the bow in such a way that it sustains the fundamental, which wasn't even there to start with.
And I think, but I haven't heard anybody say it, that the agency of the string is of the, or rather of the stack of harmonics in the string is nonzero because it has the ability to compensate for small fluctuations in the stick and slip dynamics that are needed to drive the fundamental.
So if a slip, if one of the slips was a little bit too long or a little bit too short, the next slip would be just right to compensate for that, because the string will take energy from the higher frequency dynamics and push them convert them between those levels to do the right amount of compensation for the next stick and slip.
Yep, still not him.
Sounds good so far.
So the, what I'm, what I'm suggesting then is that living things are resonators like the string is, but they have better sustain.
Why do they have better sustain because they're more agential, why do they more agential because that's what it means to be more agential is to have better sustain it means that you have the ability to convert energy between different levels of organization.
Because that converting energy between different levels of organization is the agency diagram that we started with in a right, it's the ability to abstract the world to take something which is happening at one frequency and convert it into another frequency.
Run that model of the world forward in time.
And then act on the world based on the results of running that model as it were.
The reason that organisms have better sustain than strings is because you can set up multiple different harmonics in an organism and not just the octave relationships right when you skip levels with the with other intervals like the third or the fourth.
You're making bindings between different levels which converts energies from one level to a skipping a few levels to another level more easily and quickly which makes them more powerful more agential.
It's the same thing as saying that they have more internal geometry to hold on to and more internal energy to deploy in maintaining that geometry.
So one living organism, which we notionally think of as being created from a genotype is really an unfolding of compressed information into multiple different instantiations in the distribution of population right and selection we can think of as the folding process, which collapses the information from that distribution back to genetic modifications.
But that expansion and compression in biology in conventional biology we think that that has feed forward feed forward feed forward feed forward up to phenotype and then feedback feedback feedback feedback just in one step right the organism lives or dies and that's it but it's not like that.
That that feed forward and feedback is happening in the construction of the intracellular organelles from the genotype, but they are already pushing back on the genotype to say which genes should be expressed.
And in the construction of the cell from those organic molecules, but the cell is already pushing back on the organic molecules which are pushing back on the genes from the cells into the tissues, which are differentiating into into tissues, but it's the organ which is already controlling how the cells differentiate
which is controlling how the intracellular components metabolites and proteins are operating which is controlling how the genes are being expressed which is even modifying how the gene sequences, all of those different levels are cells are agents in the process of development.
And just as much as the organism as a whole is, and the feedbacks are happening at multiple timescales and multiple organizations, not just in that sort of conventional loop.
That's it.
That's wonderful.
That's, I agree that I can make a few few comments and please.
So, at the very start you talked about, we needed to have something that was going to be, you know, effectively computationally universal, right so that it can do all this stuff, right.
And yet we want, if we want to turn these ideas into a mathematically precise theory we need some kind of precise, but minimal mathematical structure to try to capture your ideas, right.
And the, the simplest, and yet completely general, except for one little exception we can talk about model mathematical model for these kinds of probabilistic interactions that we're talking about would be Markov Markov kernels right that would be they they are the minimal
mathematical way to talk about these probabilistic interactions and it's trivial to show that Markov kernels are computationally universal, so you networks of Markov kernels can do anything that neural networks can do.
Now, it's the reason I've been nodding is that we're writing a paper on this using Markov kernels and this is the papers.
I've been writing it just the last few days last actually a few weeks and probably be at it for another month or two.
We're going to call it traces of consciousness.
And there's a key idea that that really is a mathematical concomitant of what you're saying here. And so what we've discovered is a new property of Markov kernels.
They are partially ordered. There is a heterarchy of these kernels, just like you have a heterarchy of these interacting agents.
And the heterarchy has a very clean definition.
So, if you have a Markov kernel.
And just to be precise in case somebody out of this group looks at this video right we may post this and so forth so suppose also be very concrete suppose I have a kernel that's a 10 by 10 matrix, right.
And to be a Markov kernel each row consists of numbers between zero and one, and the sum of the numbers in that row is one.
That's that's what I mean. So it's a Markov kernel very very simple square matrix each row sums to one. They're all positive numbers between zero and one.
And if you if I, I can run one of these kernels right I can see if it's on 10 states I can see, you know, if it's in state one, what's the probability it goes to state two through 10 and so forth, or if it stays at state one I can just so I can look at this dynamics.
And ultimately, if it's got a kernel, I can find a stationary measure I can see long term probability of being in state 123 through 10 right.
Now so I can say, I only want to look at states one two and three. So I'm running the bigger kernel, but I'm ignoring I'm only attending to states one two and three.
So if I only do that, what is the Markov kernel that would apparently see only involving one two and three right which would be induced by the bigger one.
And in technical terms is called a trace chain. So in math, so there's a formula for it.
I can do it. If you want, I can put the formula up on the screen but it's, there's a formula for it. It involves the mathematics involves looking essentially at infinitely long sequences of of chains of the big one, and seeing how often they go out of this three that you're interested
to go and then go into it and so forth. But but it turns out if you look at that infinite sequence, you can give a closed form solution for so you don't have to do anything infinite you can do a closed form solution that captures this infinite sequence.
So, so here's the, the, the partial order. It's defined by one kernel M is less than or equal to another kernel N.
And if M is a trace chain of N, that's it. That simple.
It gives you a non Boolean logic on every possible dynamics.
In other words, all possible dynamics are now given a an order relationship and a logic. It's a non Boolean logic.
There's no global greatest element.
And that has many, many elements are incomparable.
So, you know, many dynamics are not less than or equal to each other. They're incomparable.
But if you take one kernel.
And you look at all of the kernels that are less than that one kernel.
And if you look at the subset of dynamics, they are a Boolean logic.
So you get a Boolean logic.
So what this allows is, and by the way, when you, when you take a kernel like this 10 by 10, and you look at the three by three that comes, you know, from trace, and you look at the probabilities on those three states, the transition.
They're utterly different from what they were on the 10 by 10. As far as you could tell, this is an utterly new kernel.
If you were thinking about the probabilities as free will, the free will decisions of the three by three are utterly different in their probabilities than the free will decisions on the same states of the 10 by 10.
In other words, they can be not they have to be right.
In fact, they have to be different in general.
In general, they will be different with probability one, I think they'll be be different. I haven't proven that but just intuitively it seems like with probability one, they will be different.
So what you get is this really from one trivial definition and less than M.
If N is a trace of M, that's it.
This whole beautiful logic falls out. Now, of course, these kernels have if you look at their eigenfunctions, you are going to find their vibration rates.
And in fact, in the paper that that we're publishing, I'm looking at what you can do is take these kernels, a regular Markov kernel, and just add one little feature to it, which is standard in Markov chain theory.
You add a little counter that increments every time you take a step of the chain. So you start off at zero and it goes one, two, three, four.
So you have the normal chain, but you then have this quote unquote time parameter, which you add to it, it's called a space time, and you can now take the the eigenfunctions of that space time kernel.
Okay. And when you do it, what you get is is a function which is identical in form to the quantum mechanical wave function for a free particle.
It's a momentum eigenstate for free particles.
