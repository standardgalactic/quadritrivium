And then even more, more sort of widen this all out.
Horizontally, you can imagine now,
as we will, as we already are and will more with technology,
you can step away and you say, well, I can modify,
I can be modified biologically.
I might get some tentacles and I might live under water someday.
And I really would like to see an infrared.
I mean, what's this with these limited retinas, you know?
And so you can biologically, also technologically, right?
I can have implants and all kinds of, you know, at some point,
today, maybe 2% of my brain is an implant that's helping me out.
But eventually, it might be 58% of my brain is some kind of construct.
So you got all of this.
And then that really, and obviously,
science fiction has been on top of this for 100 years,
but a lot of people, especially who talk about AI,
are just now catching onto this idea that human is not a sharp category.
And then that raises the question of, so what do we really mean?
And I tend to think about this as the kind of thing that,
you know, you're going to Mars for the next 30 years.
You get to take something with you.
What do you take with you?
What's important that you take?
You know, you don't want a Roomba.
You don't want, you know, you want, what are you really looking for, right?
So I want a human companion.
What does that mean?
Is it the DNA?
Do you care about the DNA?
I don't.
A lot of people are super into the DNA.
And if you change your DNA, my God, then, you know,
you're no longer, I don't care about DNA.
It's then people like, well, it's the standard body.
You know, once you put wheels on and gotten, you know,
tentacles and a propeller, you're no longer human.
I don't care if you have all your standard parts
that evolution happens to have given you
and you're subjected to back, you know, lower back pain
and the stigmatism, all this dumb stuff that we ended up evolving.
I don't think that's, I don't think that's what we mean by human.
So what do we mean?
So, so I think it's really interesting to think about
what's essential about it.
And I think what we mean when we say human
is a certain impedance match between us with respect
to the size of your cognitive light bone of compassion,
literally like, what are the size of your goals?
And what, you know, what is the radius of compassion
that you can muster?
Because if you're, because, because it actually,
the mismatch can be in either direction.
If the cognitive light bone is tiny,
we're not going to have much of a relationship.
If you can't care about the same level of thing,
but conversely too, if you've got this like,
you know, galactic scale mind, we may not be able
to do the normal thing that, you know,
the normal human interaction.
So, so I think, I think that's what we're talking about.
We're talking about the size of your goals
and the things you can care about in the compassion sense
of the act, the practical, not the affect,
but the practical like pursuit of goals.
That's, that's what I think.
Lovely.
I really appreciate that.
Yeah.
I want to respond to that because I think that's important.
I think that I agree with Mike, the discussion,
I think the discussion around human
is actually an equivocation.
I think it's equivocation from some sort of biological notion
and Mike is just can just devastate that as he just did.
And another notion, which is a moral legal notion,
which is a person.
And there, we've got enough science fiction
that lets us know that you don't have to be humans
to be persons.
And then I think we try to find some anatomical locus
of personhood within a biological humanity.
And that is just a doomed project from the beginning.
That will not work.
And I think a lot of the tech people and the AI people
are like, they're bumping into this,
but they're bumping into it.
And we've said this multiple times with old categories
and old schemas, and they're saying often equivocal
and sloppy things about it.
I mean, and the move you made, and of course,
you brought this in, Mike, you brought in the notion
of compassion.
This is ultimately, you know, a Kantian,
but even properly a Hegelian move.
It's like, well, persons are beings that can recognize
each other as having moral responsibility
and moral obligations.
And I give that to you as you give that to me.
Do unto others as you would have them do unto you.
The golden rule, and I'm compressing a huge amount
of much more sophisticated argument.
But this notion of reciprocal recognition
of our responsibilities and our authority,
I can obligate you.
I can say, don't do that because that's immoral.
And I don't have to appeal to your desires.
I don't have to appeal to your projects.
I can just say, don't do that, that's immoral.
And you are, if you're a moral agent,
you're at least responsible to that.
You don't have to agree with me,
but you're responsible.
And I think, and you know, and Hegel said,
this is when we become geistly.
We become spiritual beings when we become capable
of this reciprocal recognition of moral authority
and moral responsibility such that we are no longer
driven just by our desires.
We can be driven by what we are obligated to do.
And less people think, I'm just talking about ethics.
Reason is that kind of obligation thing.
You should conclude this because of that.
And I can say that to you, regardless of your desires.
In fact, we criticize people, motivated reasoning,
who deviate from what they should conclude
because of their desires, et cetera.
Sorry for that.
They're building a battleship next door.
It's very annoying.
So I think that that compassion, if you understand it,
more broadly as this reciprocal recognition
of normative responsibility and normative authority,
that's what we're talking about
when we're talking about personhood.
And notice we do that even with human beings.
We, we do this weird thing.
We don't obligate two year olds to our moral obligations.
Because, and we, well, they're persons.
Well, they are and they aren't.
They're in this nebulous status.
They're persons in that we have moral obligations to them
because by undertaking those moral obligations,
we will actually turn them into persons.
And so, but we don't let two year olds get married.
We don't let them vote.
We don't let them bear arms.
We don't let them drive cars.
We can hold them in a location, kidnapping them.
We can force them to go where we want, like,
but many of the standards of personhood,
we don't allow them to have.
And so I think what needs to be done
is a clean separation from this discussion of human,
which can mean some kind of
psychobiological, psychosocial biological entity.
And, and I agree totally with you, Mike.
I think trying to pin that down is a fool's errand.
And I think they're reasoning the right,
what the reason why there are people
are trying to pin that down is they're trying
to find a place for personhood.
And here I know you don't like it,
but here I think that is a category mistake.
I think personhood is different from,
and it is not locatable in a psychosocial biological entity.
It's about this capacity for mutual recognition,
reciprocal recognition.
Yeah, I don't disagree with that.
I think that's exactly right.
I would just say that it's a degree, right?
That's all, that's all I'm saying is that I think it's a,
so, so for example, you know, we in the,
let's take the legal system,
we've arbitrarily decided that 18 means adult, right?
I mean, it's total nonsense.
Nothing happens on your 18th birthday.
However, at least in the U.S.,
if you want to rent a car, you got to be 25.
Why 25?
They didn't do what the legal system did,
which is just to kind of guess,
and well, just to kind of set it.
They have actuarial data,
and they just realized that 25 is when your brain's mature enough
that we ought to be, you can be trusted with a car.
That's empirical, you know, that comes from,
and so I, you know, I think putting a more understanding
that it's a, that it is a continuum,
and that certain things develop faster than other things.
And if we agree, right, if we can, and I don't know,
by the way, it's way beyond my pay grade
to try and figure out a legal system
that will work in the future of hybrids
and all this stuff, like, I don't know.
But just as a step to accept that it's not a yes or no thing,
that it's not, you know, the Twinkie defense is crazy,
but serotonin actually does make neurons go,
I mean, there's going to be a, like, it's a spectrum.
We need to figure this out.
That's, I think, part of it.
