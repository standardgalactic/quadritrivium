of enlarging our own cognitive light bone
so that we actually can recognize
and have compassion for beings that don't look like us,
they don't have the same origin as we do,
they're different in every way.
Yeah, I look forward to a future
in which the kinds of distinctions
that we make currently about within the normal human variation,
we say, oh, these are like us, that is other,
that they're not like us.
Like these things are gonna be so laughable
in the future when the wide,
when really a freedom of embodiment really takes off
and we're all in whatever, right, you come into this world
and you're not stuck with whatever body evolution just happened to have,
when genetics happened to have landed you in,
the diversity of bodies and minds
that are gonna be out there
is gonna make all these current distinctions
completely laughable.
And I think that's good.
I think we have to...
I'm too mature.
I think we have to drop a lot of old categories
which made sense in olden times,
but they don't make sense anymore
because they don't actually capture
what's unique about this essentially
and being worthy of compassion.
And so anyway, so that's kind of the general stuff.
I wanna say one thing about the more specific issue
of what we are.
So this goes back to John's point
about the problems that any being faces.
So there's one more interesting problem which is this.
It goes across scales and evolution
is called Bateson's Paradox.
And the idea is that if you're a species,
the world's gonna change and you've got two options.
If you don't change, you try to remain the same,
you're done for, you're gonna disappear.
If you do change, in a certain sense,
you've also disappeared
because now you're something else, you've changed.
So every agent faces this interesting problem
that if you're going to persist
or better yet learn and improve
and whatever your journey is gonna be,
you are not going to be the same.
So committing to a static representation
of what you are is doomed, right?
It's doomed at the evolutionary scale,
it's doomed at the personal scale for the following reason.
And this also goes back to the point
that John raised about the relevance or the salience
you called it or no, I called it salience,
you said relevance of information.
Imagine, let's just for a minute think
about the butterfly caterpillar kind of situation, right?
So you got a caterpillar,
caterpillar lives in a two-dimensional world, eats leaves,
and it has to turn into, and it's a soft-bodied creature,
so it's a very particular kind of controller
you have to have when you can't push on anything
there are no hard parts, has to turn into a butterfly.
So in order to do that,
what happens is the brain basically gets dissolved,
most of the cells are killed off,
all the connections are broken,
you build a new kind of brain.
So one amazing thing that has been found in various systems
is that the butterfly or moth actually remembers things
that you train the caterpillar on, so memories persist.
Now, you might focus on the question of,
wow, where is the memory?
If you refactor the brain, how do you still have it?
And so that's a fantastic question
for developmental biology, for actually computer science,
and we don't have any memory media that will work that way.
But there's a deeper issue here, which is that,
oh, and so I should say what it is that they learn.
So you have a disc of a particular color,
let's say, I don't know, purple,
and the caterpillars learn that they get fed on this purple disc,
and then when you get the butterfly,
it will go there and try to eat.
Well, here's the interesting thing.
So not only do butterflies and caterpillars
not eat the same stuff, caterpillar wants leaves,
butterfly doesn't care about leaves, butterfly wants nectar.
Not only that's the case,
but also the physical embodiment is completely different.
So what you have to do,
it's not enough to keep the memory as it is,
the memory as it is is completely useless.
You have to transform that memory,
keep the salience, dump the details,
and remap it into a new,
so another sort of a weirdly grandiose way of putting it is,
in your new life, in your new higher dimensional life,
like literally because the butterfly lives in a 3D world,
so literally in your new high dimensional life,
you will not store,
you will not keep the memories of your past life,
but you will keep the deep lessons you learn, right?
You're not gonna know that moving certain muscles
in a certain stimulus gets you to leaves,
you don't care about leaves,
you don't have those muscles anymore,
you have something completely different.
And so being able to remap across,
when everything changes,
being able to remap that information is really fundamental.
And so when we think about what we are,
here's what I'm getting at,
you might think that what we are,
so you might think, okay, so butterfly caterpillar,
that's a really sort of extreme example,
I mean, we don't do that,
plan area that learn and then you chop off their heads
and they regrow a new brain and they imprint their memories,
okay, we don't do that, so these are like weird.
I think this is all of us,
this is, we are absolutely that type of being,
that is not a static structure,
and our job is to keep that structure intact
against all the things that happen.
Fundamentally, I think that at any given moment,
you don't have access to the past as it were,
as it was, what you have access to are the engrams,
the messages that your past self left for you
in your brain and your body,
and you have to interpret those, right?
So puberty will alter your brain in various ways,
all your priorities will change,
your preferences will change in many ways,
when you're 90, you will still have memories
of your childhood, but not because you've kept,
there is no molecular structure in the brain
that stays the same for that period of time,
and everything's bubbling around,
molecules come in and out, cells, and so on.
What you are constantly doing
is reconstructing yourself and your memories
to make them applicable in the new scenario.
So what does this look like across scales?
For the human, it just means that as things in your brain
and body go in and out,
you are maintaining a coherent self-model of some sort.
In evolutionary terms, it means that evolution long before
we had brains or any of that,
double down on this idea that everything is going to change.
You know the environment is going to change,
your parts are going to change because you will be mutated,
we know you're going to change,
and so this is why we have these amazing examples of,
you know, when we make tadpoles with an eye
on its butt instead of in its head,
they don't need new generations of adaptation,
they can see and they can learn in visual assays immediately,
right? There are many, I write about this stuff a lot,
there are many amazing situations
where you can radically change the,
not just the environment,
but actually the parts themselves.
You can put in weird nanomaterials and then all this stuff.
You always get something coherent because, I think,
because what biology does is assumes that you can't just learn
the structure of the past,
you have to learn,
you have to make problem-solving agents
and the body and then eventually,
the brain and the mind are continuously reconstructing
because you know everything has changed.
So this, and there's some other things
that could be said about that,
but I'll stop in a minute.
This is just, I think this is one of those things
that we're learning from all of this,
is that if you want to know what we are,
it is less plausible to think of ourselves as
some sort of static structure
that tries to hold on to the n-grams of the past.
We are a continuous process of sense-making
and reinterpretation.
I mean, I'm obviously not the first person to say this,
but we now see that across scales,
from evolutionarily to molecularly to developmentally,
from the robustness of the body
to the robustness of cognitive systems,
confabulation, like all this,
the noise and the unreliability of the substrate
is not a bug, it's a feature.
It's the thing that makes us intelligent and robust
because you assume right off the bat
that everything's going to change
and that our number one fundamental capacity
is to remap onto new scenarios.
And if you think about,
if you think about what happened in computer science
