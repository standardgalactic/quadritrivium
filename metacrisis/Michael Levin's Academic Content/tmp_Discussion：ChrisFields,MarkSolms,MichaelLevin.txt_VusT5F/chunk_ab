And, but that to the extent that the agent is making choices, which are rooted in these, what I think you can only call feelings.
In other words, it's, it's, it's, it's monitoring of its own, if it's own needs, its own existential needs across the different parameters that I was just mentioning.
And that to the extent that it is able to make choices which are not given that they are its own, the products of its own cognition.
And that's that are rooted that are ultimately tethered to these to these needs states, you know, I'm, I'm persuaded that such an agent.
It feels like something to be such an agent.
So, so I wanted us to have a symposium where we can look at what this agent doing talk about things that can, but, but really just about how what kind of behavior do we want to see what sort of behavior would we predict if we were to do this what do we think
would happen etc, just among ourselves not trying to persuade people who start from prejudices that you know are insurmountable, so that we can, as a community, relatively like minded people come up with some criteria.
You know, which are at least rational.
You know, if not, if not empirically persuasive they are at least rationally persuasive that that makes sense in terms of those principles for those who, you know, who shared basic assumptions that such a thing is possible.
But then, so that's the one concrete step that you know I very much hope I'll be able to persuade you guys to come over and experience the joys of Cape Town for a week or a few days.
And we'll look after you very well and we'll, and we can talk about these things and come up with a consensus in a statement about about what what what we what we would consider are the kinds of behaviors and
and whatnot that that would convince us at least.
Then the other second thing which goes more to what you were saying Mike. Again, it's a very concrete thing and forgive me for bringing this all down to such concrete steps is that I've been thinking with my group that if we once we've done this, we're saying here we believe the agent is
feeling this. That's how it's doing what it's doing here we believe the agent is feeling that and in relation to thinking this in other words as you know, as it's as the numbers are showing what's happening to the precision waiting in relation to the
current active policy, you know, across the three different needs states and so on.
If it had a feeling at this point it would feel like this to be that agent, then to work with colleagues in virtual reality to create us a virtual reality that we can immerse ourselves in that is basically the same as our agent is confronted
by so that you know we know okay I've got these three needs. I'm monitoring them on the screen, you know and here I'm in this environment and and I'm trying to find the things that I need and deal with the challenges that I'm that I'm confronted with.
Do I feel what we infer the agent would feel. And I know it's artificial in all sorts of ways because we're not literally going to die in that virtual reality.
But you know it's at least empath, it's a it's a little bit more than just empathizing with the system it's a little more literally putting yourself in the system shoes.
And the prediction then which is beginnings of something empirical is to say, I predicted this point, I would feel something along or a human being in this environment will report feeling.
This is feeling better and this is feeling worse and you know this is here I'm losing confidence in this in the subjective meaning of the word.
I don't think it's a very brilliant idea. It's a very concrete idea but I think something along those lines might be might be a way to go.
I think you go ahead person.
I was going to say that in what you describe is very much like a video game type of environment.
And there's loads of available data out there.
Or data, I think that could be collected about how people who immerse themselves in video games, which I've never done actually but feel about what they're doing and interacting with with virtual environments that have those kinds of requirements for for resources for repair, etc.
And I don't know of any literature in this regard, but I expect that it would be data that would be fairly easy to acquire, even with things like physiological monitoring or EEG or things like that as a as a supplement.
You know where some it just occurred to me some some data that might come of this. So, so there are data on people using various prosthetics the kind of extended mind idea right when they you get you get an extra hand or an extra, you know finger or something like this.
But it just occurred to me that in those cases, as far as I know, all of the prosthetics that people use are themselves very low agency devices right they don't do much on their own.
But I wonder if we could imagine having imagine if you're if you're bought is is a prosthetic where we are joined in the right the player in this in this virtual environment is joined to that system, the way that two minds would be joined and in the same sort of biological
and the way that people do immerse themselves in, hey, this, this, you know, this hand that rotates a full, you know, full 360 degrees that's now my hand and that I mean that works perfectly well for her apply with neuroplasticity.
But I wonder if at the other end was another, you know, you could make a temporarily joined agent within that video game where you were you do share a consciousness actually.
Well, a model for that, although it's not quite what you're saying but it's in that direction is the experiments of about 10 or 15 years ago with they still being done but they were introduced about 10 or 15 years ago with the body swap illusion.
And where where the, the, the research participant has has goggles VR goggles, which are onto which are projected, what is seen by the other person through the camera mounted on their for it.
So you experience the world from the point of view of the experiment and in fact it's also been done with mannequins, so that you, you know, and you're perfectly aware that the what the experimental setup is you know I'm Mark Jones, I've got a VR goggles set on my face.
And I, and onto this is being projected what the experiment or the mannequin is seeing, and you, you, you rapidly feel yourself to be the mannequin or to be the experimenter.
You then shake hands with the experimenter, and you, you feel as if you're shaking hands with this guy called Mark songs, you know, you don't feel you are Mark songs, you know you are but you don't feel you are you feel that guys Mark songs and I'm shaking his hand.
And then to your point Chris about about a skin conductance and so on.
If you threaten to stab the mannequin, even though I know I'm not I'm not the mannequin I'm me.
The physiological stress response is greater when the knife is lunged toward the mannequin than it is than when it is toward me which kind of is like kind of objective evidence that I am identified with the spatial embodied the embodied space of the mannequin.
So, yeah, that's very interesting so it's building, building upon that sort of paradigm into this is said that what you experiencing is from the point of view of the agent that is that is that is navigating this environment.
You know, it also occurs to me there's a yeah you said something really important earlier which which was this this bond, you know this concept of bond.
And I think that it addresses both the issue of this kind of like generational attitude shift, and also the attempts to to synthesize to synthetically create these kinds of agents and that's this.
The whole, of course, developing and I mean the roots of it are very very old but but this developing idea of making synthetic companions of various types right ai's that we're going to interact with in various ways.
And one thing that I hear all the time from, let's say, some of my dad's friends and people even you know if my generation to is, I don't want a bond with a synthetic I bought I want to bond with a human.
And I say, I argue back that you don't really want to bond with a human what you actually want, you don't want a human bond which you actually want is a spiritual bond.
That's the question of the okay so now what does that actually mean because I don't think anybody actually cares or knows most people who say that don't actually know what's under your skin and they don't care.
You know, really what the what the physiology and the genetics are.
When you think about what it what is it that you want from a bond right is this somebody you're going to be friends with somebody you might have a spouse somebody you might want to take with you if you're going to Mars like what what is the bond that we want.
These that come to my mind and I'd love to hear what you guys think about this. One is that you need to have a shared existential struggle.
Specifically that all the questions of where do I end and the world begins how do I know what I am where I'm like all of these things that the basic I mean so I think all three of us have spent a lot of time thinking about what happens at the very
beginning when you have this undifferentiated medium whether they'd be cells or neurons or whatever it's going to be. And out of this mass of multiplicity comes some sort of one semi unified agent that that considers themselves and a single thing and separate
from everybody. So what are the, what are the dynamics that lead up to this because it's not obvious you don't upfront know what you are what kind of effectors you have what kind of senses you have.
What is your environment versus where do you stop like you or we don't know any of that upfront we have to develop models of it and so I feel like what we're really looking for is something that has been through that authentic process not something like a modern
where everything is your energy needs are met we know here's the here's what you are here's everything is sort of given to you you've not had that issue.
And so that so that shared existential struggle and a kind of that cognitive light cone that I talk about which is this idea of what types of goals and what spaces and what size of goals can you potentially
work towards you know if there's a huge mismatch it's not going to work right it's very hard to be friends with some it's something that's you know has a bacteria size cognitive light cone.
And I'm sure the reverse is true to right I don't know how you would have that relationship with a cosmic intelligence of this massive light cone that you couldn't even begin to understand what they're doing.
And so that kind of kind of impedance match right between the the goal setting and that and that those that that struggle that that comes from emerging as an individual in the first place.
I think that's what should and so and so all that goes to say I think the, the young people in the future who are going to be surrounded with the kind of agents that that you're talking about Mark and various other things.
That's in the end going to be the criteria and it's not going to be the origin story of where you came from or what's inside of you or any of that stuff.
It's going to be these kind of what can I count on you to do what kind of struggle have you been through what are your goals and then then after that it kind of doesn't matter what your provenance is or what you're made of them then we can you know then then you're real as far as I'm concerned.
I feel like that's going that's where things are moving.
I feel as if I'm probably speaking too much so Chris forgive me, I'll be brief.
I think to two sets of things in different directions, flowing from what you've just said, the one which the other one is a reaction to the one thought is, well, these values.
These shared values, existential values.
You know, of course they are, for want of a better word they arbitrary, apart from the actual existence of the system that that's kind of universal for that that that that's sort of at the heart of the, of the free energy principle I suppose or what Carl calls his particular
context which you guys are building on the idea of, you know, of meanness or fitness or a system as opposed to not system.
Apart from that which seems fundamental. The other values.
Like, you know, I fear, you know, I don't want to be harmed by this thing, or I don't want to be impeded by this thing that makes it into a not me type of thing, as opposed to we're on the same side.
We're in the same boat together.
Your survival is my survival we're a, we're a team we're a group. It's us versus them rather than me versus them.
We're affiliative bonds of that kind in attachment bonding in mammals, for example, and, and, and play, which is a wonderful emotional drive that that all mammals at least, possibly spurred to, you know, share, they all relatively arbitrary it's just you know, because
you know, what kinds of creatures we are.
The, so that was the one line of thought I was thinking well, you know what would be.
We want something fundamental that doesn't reflect our mammalian values or that you know.
And so that led me to this other thought which is that I suppose it's an extremely simple thought that is speaking more formally.
And that justifies your drawing a blanket around you and these other things.
If mechanistically it's justifiable to say that you are that that that your mark of blanket and this other agents mark of blanket can themselves be justifiably blanketed by a meta blanket.
And then you, you are formally describing the state of affairs that you're describing you know which raises the much more sort of reductionist question of what justifies the drawing of a blanket.
Because I've always because I am stuck in the envelope I'm stuck in, you know, I've always I find it much easier to think, yeah, my, my nervous system is is is blanketed.
And that within that, you know, the, the various nuclei are themselves blanketed and within that the individual cells are themselves blanketed and so on I find it easier to realize to feel that I am a composite of blanketed agents which is again something
that you have forced me to see and I have no difficulty seeing it anymore when I say post I mean I was compelled by the, but by the force of your arguments to realize of course that's right.
And, you know, and Carl says the same thing has been for a long time but you know I'd never, but I find it much harder to go in the beyond that as soon as I start myself.
You mean I'm, you know, is there a consciousness that that is shared by all of humanity or all of all living things.
Is there literally a consciousness of all living things that you can speak of as as as an, and you know, and formally I think you can I mean it must.
I mean the whole of natural selection ultimately is just a self organizing system, but I find it harder intuitively to, I want to stop with myself, you know.
Yeah, I think that that's in a sense the flip side of this discussion is what what would be required to make it experientially evident in the way that you were discussing earlier.
So that I am a component of a larger system whose experiences I am not having cannot have and can't even properly conceive of with the with the tools available to me, except perhaps in a very abstract way.
Of course, we have to have this very abstract way to even have this conversation.
But the FEP gives us that abstract way.
I mean, one can from a purely okay Mike is leaving.
Yeah, I do have to go in four minutes but to address the second part of his comment. I would love to carry on. Not today I can't but to arrange a follow up meeting.
You're saying that Chris, that's it, you know, I that's that I agree with that every word of what you're saying. It's, I guess I would just propose adding that to your earlier goal for trying to sort out as an important question.
Well this has been this has been great. Thank you.
Yeah, thank you. Thank you. Thank you so much super interesting. So I will I will I will connect again and we'll we'll make the next part to marvelous.
Thank you again Mike for facilitating it and thank you Chris great to meet you truly great. Yes.
Absolutely. Thank you guys talk to you.
Right.
Thanks.
