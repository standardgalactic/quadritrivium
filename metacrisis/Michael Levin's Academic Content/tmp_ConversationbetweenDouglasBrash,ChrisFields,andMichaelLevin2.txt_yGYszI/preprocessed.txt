you. Yeah, good. Hey, Chris.
So I don't know if you guys have an agenda. I have been assembling stuff. I just, I wanted to
be more organized, but I just shot you guys an email that has some of my thoughts down and writing
in case that makes it easier. Go for it. Yeah, I just received it. Thanks. Oh, okay. Yeah, go for it.
Yeah. So I have infinitely many questions, but probably I could do some, you know, like
definitions of things as I was going through the quantum free energy paper. But the more
interesting than specific questions are something that just hit me last night. So there's like two
basically two main topics. One is like, what's the organizing principle for embryos and where is it?
And what's that telling us? And the other one is, okay, you know, what's the definition of a thing
and how does that get us anywhere in cognition? And the two are sort of beginning to merge in my
mind, although, you know, I wish I understood all of your papers better. But the thing that
occurred to me last night is about the competency experiment. So what, so that's the one where you
have this array of numbers, like one through 10, they're scrambled up and you're trying to get them
back one through 10 by doing swapping. Okay. And it dawned on me that while there's actually two
things in that box, there's numerals that are getting rearranged and there's numbers,
which are where the information is actually sitting and the constraint is actually sitting.
And you're basically using the number information and comparing current positions to the number
ordering. Numerals don't have an ordering property, you know, they're just scratches on paper.
And then as soon as you have that dichotomy, you're now basically at the same dichotomy as the genotype
phenotype blueprint object that you're making and so forth and so on. And so among those,
and that confers in a number of interesting properties. First of all, you can swap things
at the blueprint level and not necessarily get any change at the phenotype level.
Or maybe you do, maybe you don't. And that's the sort of option that lets the stress selection and
genetic simulation work and so forth. The other is that as soon as you have, think of it in terms
of like these two levels with blueprint and the output, the first thing you want is to have parts.
And so by analogy with the DNA, which is actually, I think probably a pretty good analogy in many
ways, you know, you've got different bases. And then on the other hand, you've got amino acids.
And then, so what actually happens with that? Well, you've got a very rigid
code that goes from DNA to the amino acids and then to the protein.
But which proteins you decide to make and how those proteins assemble or get assembled by
another protein. That's the part that is subject to optimization, I would guess. And so if I were
going to look for a place to apply a free energy principle, that's where I would guess it would
look. Now, maybe in evolutionary history, there's a similar principle for just deriving a code.
But in any event, so then now if you're looking for some kind of electrical code that's the analog
to that, then A, you would like some parts. Sorry, if you're liking one, an electrical blueprint
that is the macroscopic blueprint that's constraining your organism, even if you push its eyes around
or something, then A, you would like some parts of some kind, like sub electric fields. And B,
you'd like some code for how that gets translated over into actually building the organism.
And then the funny thing about the genetic code, so we know about the reading frame as
basically restricting how to go from ATGC to an amino acid. But I remember in grad school,
I asked, well, okay, where is that code sitting? And where it's sitting is in the tRNA synthet
case. And so then the question is, okay, can you look for analogs of all this stuff
with the electric fields? Yeah, I mean, it's, you're right, you're right. And it's really critical
for all these bioelectric states to ask who the interpreter is. So the mapping, right, much like
with the DNA, the mapping between a distribution of voltage states and then some anatomical,
you know, the state later on is really critical. And we spent a lot of time and we're still thinking
about, originally, we thought that it might be specific voltage levels mapped to specific organs,
and then we saw that that wasn't right. And then it really appears to be a pattern
of, you know, differences across space. So what was all the interesting thing happens when
certain cells of a particular voltage are sitting next to cells of a different voltage,
and it's the difference that's actually meaningful to the outcome, not the absolute values of either
side. It's the difference that matters. And so all of this brings to mind, okay, well, who's reading
this? You know, what's the interpretation machinery? So we have a few models now.
We put out one, and there's one that's in revision right now, of asking, how does a collection of
cells read a spatially distributed bioelectric pattern and turn on specific genes as a consequence
of this? So not an individual cell voltage turns on genes within that cell. That's kind of easy,
and we found that years ago. There are five or six different transduction pathways that do it. But
much more interesting is how do they recognize a pattern and how do they know if the pattern
is correct? How do they know what it means? And so on. And so, yeah, so that's what we're
wrestling now with now, and there's definitely an interpretation issue there. And so there are,
you know, we have a computational model of how that happens. It also, I think, ties into a very
deep issue about memory, because there are these memory transfer experiments, where you transfer,
you know, somebody like David Glansman might just transfer RNA from a trained animal into a naive
brain. We've done, we've transferred pieces. So we'll do things like transfer pieces of an animal
from one from one to another. And we look at propagation of morphological memory, propagation
of behavioral memories, and so on. And you have the same issue with the decoding on the other end.
So the thing that's always bothered me about, and it's not just for RNA, it's for any material
substrate for memories, is that if I train an animal to some sort of weird relationship that
never, you know, sort of not evolutionarily prepared for, so, you know, I don't know,
three yellow light flashes means take two steps to your left, or otherwise you get shocked, right?
So animals can learn this. So let's say that ends up being encoded in the NNN gram of some kind of
crazy molecular structure, maybe it's an RNA, maybe it's something else. I take that, I shove it into
into a naive brain. And there's got to be a, there's got to be a decoding mechanism that can
look at that structure, go, oh, look at this hairpin turn, oh, I see three yellow light flashes,
ah, right, got it. Well, where's that, where's that code book? Like, you know, and you can imagine
something like that, something for something evolutionarily expected, like fear of the dark
or something, we can all share the same code book, because you know, it's built in. But for
these really arbitrary things that is not plausible, that we share a code book that,
that already pre-specifies that it becomes really hard. And then the worst problem is,
it's bad enough when you're moving it from, from, from body to body,
but recall within the same body is the exact same issue, because, because for, right, for,
for me to read my NN grams, I don't have access to the past, all I have is, is whatever was left,
whatever traces were left in my brain and body, right, maybe not, not even just the brain,
but I have to interpret those. So, you know, the three hours from now, I'm going to have to
interpret whatever was left by past me as a message to my future self, I have to do the
exact same thing, I have to look at these, at these, at whatever this is, and, and, and figure
out what they mean, and just sort of on the fly, keep, keep rebuilding this. Yeah. So, yeah, so,
I think, I think, I don't know, Chris, what, what you think, but I think this, this interpretation
machinery is, is, is really the key to all of this.
Yeah, I, I, I agree that it's a very interesting and very tangled issue.
You know, and if you think about an electric field, for example, and you want to think about
components, then really the, the only options are charge center locations, which you could mix and
match into an electric field to change its shape, or frequencies, mix and match into a field to
change its, its temporal shape. But that doesn't give you a whole lot to play with. And in the
developmental setting, it's not clear that frequencies are playing a role, whereas in the
brain, for example, they clearly are playing a role. So, you know, which, which degrees of freedom
in the encoding itself is an interesting and difficult question, what counts as a component.
But in the developmental setting, it's very clear that you have cells as components. So,
you have components in the reader, even if you don't have components in the source.
And so the question becomes, how do the different components of the reader
communicate with each other about their joint interpretation of the field? So you have the field
becomes one communication medium, that these, these multiple components have to jointly interpret.
But to do the joint interpretation, they have to somehow talk to each other.
Otherwise, they would have no basis for knowing what a difference is, for example.
So, we're faced in this case, I think, with a minimum of two different languages. The language that's
embedded in the field itself, talk to each other about their local measurements.
So they may be talking bioelectrically through gap junctions or something.
But that's, that's a code, you know, bioelectric code that's in addition to the overall code that
they're reading. Can you get, and this is, I was going to say, you know, and this translates into
thinking about natural languages in terms of, you know, positional effects and grammars and that
kind of thing, that influence what the semantics of the different words are.
Can, can you get any traction, or is there anything that gets provided by either having some of this
bioelectricity being a carrier wave or something, helping cells, individual cells
contribute to some overall pattern that then gets communicated back to each of the guys who
contributed to the party, or resonance doing something like that?
Yeah. We don't, we don't have any data yet on resonance, but I think you're absolutely right.
And that, well, first of all, the carrier wave business. So, so every cell, by itself,
at, during the cell cycle and just, you know, sitting there, it has these little,
these little fluctuations. So, of VMM. And so in addition to that, you know, whatever, whatever
bi-electrics they're doing as part of patterning has to sit on top of this baseline. In fact,
back in, I don't know, 2000, when I was first talking about starting to try to manipulate
resting potential, this is what everybody said is that, is that, well, this is a housekeeping
parameter, you know, you can't, you can't mess with it, otherwise the cells will die and, you
know, nothing, nothing will happen. So, so, so, yeah, they do have this like baseline wave,
and then on everything else happens on top of that as, so I think, I think the carrier wave thing
makes sense. Also, I, yeah, I think it's, it is true that, that functionally, the electrical
activities of these cells are added up to what in effect is a global computation that then ends up,
it's the same, I mean, it's, it's funny, the, the interpreter is the same cells as the generator,
in this case, because the cells, right, they, they have to generate these patterns, it's the
same cells that are then going to read that pattern and do something as a result. So they're
sort of talking to themselves in a way, but, but, but, but there's also a jump in level of
organization, because by what the computations that they're doing by this bi-electrical signaling
take place in an entirely different space. So the individual cells are computing things like,
when do I divide, how's my metabolic state, you know, who's my neighbor, this kind of stuff,
but the collective has to, the collective has to make decisions about huge things like,
how many fingers do we have, and where do the eyes go, and how many eyes do we have, right,
it's an entirely different, different problem space. And so that, that, they're executing
these, these computations as, as part of a collective intelligence, which then immediately
filters back down and says, okay, you're going to be a bone cell, and you're going to be a nerve
cell, and you're going to be a muscle cell, but that isn't what the initial computations were,
it sort of comes up and then goes back down. So since you mentioned the computations, another
thing that this two level hierarchy, the genotype phenotype kind of hierarchy, or syntax semantics
kind of hierarchy, buys you is the ability to do particular computations instead of mixing.
Do you guys know about William Abler's particular principle? So I can send you guys the paper,
it's actually, I think very important, and almost nobody knows about it. But
so the question is, if you have a red and white, and do something, do you get
some variations of red or white, or do you get pink? And of one of the reasons Darwin was stuck
with going to Lamarck, was not that he liked Lamarck, but he couldn't see any way out of the
red plus white equals pink. Whereas as soon as you have a genotype and a phenotype, you can now
be mixing the genes, and so in the case of Darwin, so you've got tall and short. Well,
a couple generations down, everybody's going to be in the middle, if all you do is mixing.
There won't be any tall people or any short people. And so how do you get out of that? And
the solution with genes were essentially, they do the particular computation. So you don't lose
the origin, the identity of the original element to the computation, they're still sitting there.
You just recombine them in different ways, and then you now generate a phenotype from the new
combination. Yeah, you had some other stuff. When we think about writers and readers being
the same systems, it naturally leads one to think of the field as a memory structure.
You know, Mike, as we were discussing with Santosh the other day in computational meeting.
So you can think of the cells as writing to this memory structure,
and then reading from this memory structure.
But one memory can also read from it, and they may be reading from it in a different language
than you wrote to it. So the collective may be interpreting the same memory structure
using a different syntax and a different semantics from the
entities that wrote into the memory structure. And in a sense, you see this in the genetic code
because you have coding redundancy for amino acids,
and different codons code for amino acids with different efficiencies because of the
kinetics of the different tRNAs are different. But from the protein's point of view, and hence
for the evolutionary system that's selecting changes in the genotype, it may not be sensitive
to that language at all. It's sensitive to the reproductive capacity of that entire system,
be it a cell or an organism or whatever. So the collective is speaking, in a sense,
a completely different language from the codon language that's spoken by the DNA
that's used by the DNA to write the instructions for proteins.
And the proteins in this case are serving, in a sense, as the shared memory device.
That's nice. And it happens to work. That reminds me of an old paper which I can also send you
having to do, basically, the question is, okay, we speak languages, but we can also understand
the guy. How is it that speakers and listeners converged on using the same language, you know,
human speakers? And basically, if you introduce a couple of constraints, which in my case,
I think it turns out to actually be this analog to a reading frame that I think language is used,
but you introduce a couple of constraints. And then it's not all that hard to converge on
a common generator, you know, reader and writer, that even if they're different,
can at least understand each other.
There's another lens on this, too, which Josh Bongard and I just put out a paper on
polycomputing, which is this idea that, you know, the exact same set of physical events
can be interpreted in different ways by different observers and thus be doing different computations
literally at the same time. And so we talked about he and his student, Atusa, have this amazing
sort of mechanical example of multiple computations being done by the same, you know,
piece of particulate matter. And I picked out a bunch of biological examples from that paper,
where basically one way to, the title, which Josh came up with is, there's plenty of room right here,
which goes back to like this, this idea of room at the bottom, right? And so this idea that in
biology, there isn't any room anywhere else because it's all packed full of stuff, there's
stuff everywhere. And so the way to squeeze more out of it is to evolve additional observers who
do interesting things with what is already going on, right? So as opposed to trying to
tack on new mechanisms. And one thing that's interesting about that is that if what you're
evolving is a new perspective on an existing set of events, it means that you don't risk breaking
those events, that's completely different than trying to make tweaks when hope that you don't
lose your past gains, right? You basically don't touch the, you know, it's observation only, right?
So you don't touch the thing that's going on. And as a simple example of that, we had this,
we had this other paper recently where you take a gene regulatory network, and depending on how
you look at it, meaning you pick three nodes and you call one of them the condition stimulus,
one of them the unconditioned stimulus, and one of them is the response. If you pick the right
nodes as your CSUSNR, you can show that that thing is doing associative learning. But only
if that's your perspective on the system, if you have a different perspective, you'll see it doing
something completely different. And in fact, multiple observers can have two different mappings,
and they will see it, they will have two different pictures of what it's doing,
but nobody's touching the actual network. You're not rewiring it. You're not changing
synaptic weights for memory. You're not doing any of that stuff. It's literally what perspective
you're taking as an observer. So, and there's many, many examples of symbiologists. That's
another thing, right? You've got this, you've got some kind of a code encoding system, and it's
working great for one thing. Pretty soon, something will evolve, which takes advantage of that just
by interpreting that as a different kind of computation that you can make some sort of use
out of. So that's, you know, that's kind of another aspect of this.
So basically, what's going on is underlying it all has been some set of correlations.
And then you're projecting it into some other world where it could have been completely gibberish,
but at least they're still correlated. Yeah. Because they inherited the correlation.
Yeah. That's cute. Yeah. And then I'll find it momentarily. But Jeremy Gay, who does all our
graphic design, he did a, I asked him to do a version of, you know, the classic Gerd Lescher
Bach cover from Hofstadter's book. So he did, he did an amazing version of that for embryos
for us, which for that, for that book, which I'll show momentarily. But that's exactly,
that's exactly what you just said. It's, it's, it may, depending on how you look at it, it may
look like gibberish or it may not. Yeah. In a sense to put this in more computer
sciencey language, this is what interpreters and compilers are doing, but particularly interpreters.
Oh, right. You have down at the, at the machine level, or slightly above the machine level,
you've got a whole bunch of processing going on and layering a high level language on top of it
is layering an interpretation. It's assigning a different semantics to all of that processing
that's already happening. And within that, using that semantics, one can interpret what's going on
as, you know, a zoom call or something. Yeah. Whereas without that semantics,
you have a completely different idea of what's happening.
Well, and look at how powerful that is, right? If, if, if you had a, you know, if you were,
if you were running a software company or something and you had a, you had a candidate
that you were interviewing and they say to you, well, I'm a reductionist, I don't, but, you know,
I think the, you know, there's no such thing as an algorithm. It's the, it's Maxwell's equations
that govern what the electrons do. They just do what they're going to do. You'd never hire that
person because they wouldn't be able to, they wouldn't code anything. It's, it's, it's hugely
empowering to think that the algorithm makes the electrons dance, right? Because then you, then,
then you would go on and you would write things when you, when you're thinking about it at that
level. If you lack that abstraction, you know, it's, it's, it's extremely hard to, to, to do
anything. And I think I'm here, check, check this out. This is the, this is the, this is the cover.
So that, that Jeremy made, right? And so the idea is you've got that, you've got the same
batch of DNA. So this in particular is, is, is, is our Xenobot example. You have the exact same
batch of DNA. We don't change the genome, but depending on how that DNA ends up being interpreted,
you end up with a frog embryo or you end up with a Xenobot. And it's the exact same, right? It's
the exact same DNA that is somehow, you know, what is it encoding, right? Well, it depends.
If it doesn't just encode a frog, who knows what the heck else it, you know,
down here, who knows what else. So it's, it's this idea of, I don't know, info information or, or
environment or something is sort of, is the prompt that gets this thing to generate. It's like a,
it's like a generative in the, you know, encoding of some sort. And there's a prompt that gets it to
go in a particular direction and you end up with something like this, or you end up with something
like that. Almost like a hologram, right? Because as I recall, if you shine the light in different
directions, you get us a different readout from your flat piece of hologram film.
Well, yeah, right. And that's interesting too, back to the memory thing. So, so, yeah, so, so I
think the point there is that, yeah, you can, you can store multiple images sort of on the same piece
of film and just recover them with different, different signals. There's a, there's an amazing
book called Shuffle Brain. And it's this guy, Paul Peach, back in the 80s, who did all these
experiments in memory in Salamander. And he basically was, you know, he started out by looking
for memory and taking out different pieces of the brain and showing them, well, it's actually
everywhere. And, and then he would move the pieces around and the salamander was, you know, would
basically be completely fine and do all the tasks and everything. And then, and then he would move
pieces from goldfish to a salamander and the vegetarian would become a meat eater and me,
and the meat eater vegetarian. It's just amazing. But the second half as well. So the first half
of this book is all these experiments. The second half of this book is, is a holographic
model of memory, where he's sort of inspired by these experiments of non-locality, like he couldn't
find it anywhere in a particular region and so on. He pulls out all these analogies of trying to,
trying to store multiple different memories and, you know, whatever else is in there,
in literally the same hardware, right, they all have to overlap somehow.
Then I guess that gets us back again to where what's the location where all this is stored
and your question of this macro storage thing, you know, deducing the micro from the macro
roughly. And that reminded me, as I was reading, I was reading this paper for two
wrote last year. And, you know, one of the citations was to David Pine's paper from
year 2000 about mac phenomenon physics that were macro not deducible from micro.
And I don't know enough physics to know where those constraints are stored.
Do you know, Chris, how, let's see, he gave a few specific examples.
I took a quick look at it this morning.
Oh, the theory of everything paper. So he says the quantum hall effect is one,
Josephson effect is another, and you can't predict them from the micro level. So do you know
what where the constraint is coming from? I don't.
Well, in many cases, the constraint is coming from the macro, the environment, which is macroscopic.
And is providing top down boundary conditions of one kind or other on behavior that
that one can describe microscopically only by putting it into a kind of box that's specified
at this larger scale. Huh. Okay. So this is beginning to remind me of like gravity effects,
your Markov blanket. And there's something else that just get me on all this. But anyway,
I see what you mean. Yeah, you know, this issue of where is it's where is it stored has been
driving me nuts for a long time because there are many such there are many such things.
When, you know, the distribution of primes and all the way where like that stuff doesn't seem to
be, you know, it doesn't seem to depend on the physical facts of the universe, like where is
all that, or even just the, you know, the thing where you've seen this Galton board. Yeah, it's
just it's a it's a piece of wood and it's got a bunch of nails stuck into it. You take a box of
marbles and you dump it over and they go boom, boom, boom, boom, boom. And in the end, you get
this bell curve, right? Yeah, you always get the bell curve. So now you could ask where is the shape
of this bell curve stored. So you start looking at the wood and you look at the nails and then you
look at the distribution of the nails. None of those have anything with, you know, none of them
make it in code in the strict set. So where the heck does it come from? Right? There's a million
of these things. Yeah. Why are there normal distributions? Right. Or truth tables, right?
So you evolve, I like this too, you evolve an iron, a voltage gated ion channel, which is
basically a voltage gated current conductance, it's basically a transistor, you have a couple
of these things, you can make a gate, if you have a logic gate, you have a truth table.
Where's this truth table, like you gain and the fact that you know, the NAND is special and all
this kind of stuff. Where is all that it wasn't it sure wasn't in your in your, you know, ion channel
design, it's it's you get that for free somehow, it's like this, this incredible free gift from
from, I don't know where it comes from. It's relational information
that we typically don't know how to predict, given the low level.
My quantum mechanics professor used to joke, we'd be complaining about how long it was
taking to do the homework. And he said, yeah, but the add-ons can do it like that.
Well, I could ask questions about the other topic, if that's okay. Go for it.
So this has more to do with the things and cognition. And I noticed a couple of things there.
The Markov Blanket way of looking at it took me the longest time to kind of wrap my head around
that. And I suddenly, suddenly realized that, oh, basically, you guys and Tristan are trying to exclude
stuff out in the environment that would normally just be bumping into the thing that you're trying
to look at. Whereas I've been looking at it the other way, which I got all these totally isolated
parts, how do I put them together anyway, to make something? But it's sort of the same problem.
So like I've been looking at it from the construction point of view, and that's sort of looking at it
from the installation point of view. And either way, you can make hierarchies out of them. So I like
the idea of hierarchies of Markov Blankets. That makes sense. And there's this old idea from,
I can't remember names anymore, G. Spencer Brown, Laws of Form of Outdrawing Distinction.
And there's, I can tell, the Markov Blanket idea is that, oh, that distinction actually has some
structure to it. You can divide it into sensors and effectors and so forth. So that is all fine.
And then am I right that you guys are trying to find a general principle for agents that can do
self-organization? And all I'm trying to do is find a particular organization used by humans.
But so anything that I might say about language and cognition is essentially my proposal for the
special case that probably satisfies the constraints that you guys have been working out mathematically.
So I'm pretty much all fine with that, although I have a long list of things that I need to
find definitions for before I can actually really understand, you know, all your derivation,
but I've got the gist of it. And then in particular, and then Chris and I emailed a little bit,
your reference states are, I think, exactly what I'm calling the specified
relations that define the things. And your pointer states are the various
substitutable ones that I've been saying that, well, okay, you could, it could be this or it could be
that, you know, I could have a hat on or not. And it's still me. And so I think that is all
in parallel. I do have one quick question. Is there an advantage to having pointers rather than
talking about the state itself? Or is that just a mathematical convenience?
Oh, it's just a historically traditional name. Oh, okay. Physicists, physicists talked about
pointer states, looking back to the idea of old analog meters that actually had pointers that
could point to one or two or two and a half or whatever. Oh, I was thinking more like language
comes from. I see I was thinking of like computer pointers, you know, pointing from here to there
or something. Okay, I see what you mean. Yeah. Okay. All right. No, it's a far older language.
I just got all tangled up. Okay, there's an advertisement for Bluetooth.
Okay, that's that's why that that's why the pointer states are the states that can vary.
Okay, all right. So the rest of the rest of the meter keeps its shape. And the pointer swings
around from one number to another. Okay, then so far, we're in agreement about what's going on.
Then the only thing I would say is that the reference state is not something we identify,
but the primitive cognitive act is to stipulate the reference state or whatever. And then that is
what makes you now a cognitive organism, which I define as something that can detect things.
Otherwise, it's just a bunch of flashes of light and noise coming and going. And I'm not
cognizing, but as soon as I can define a thing, then I'm capable of doing cognition.
Yeah. If I if I encode a particular reference frame that lets me identify a table,
then I'm in effect stipulating what counts for me as a table. Yeah. Okay. Oh, I see. So, okay,
that's what in anything that fits those criteria is a table by stipulation. Yeah. Okay. Okay. Maybe
totally different for you. Fine, fair. And then what I would say is that various things you do
in cognition, like an abstraction, are just moving things from one column to the other. So,
I've got a list of properties. I'll say what I mean by a property in a minute, but and those
properties are either these specified or substitutable, you know, your reference or pointer,
and the and the substitutable, I think, are the same as swappable, evidently. And then,
so if, for example, I say I have an organism, and I stipulate that it moves and it eat plants,
then, okay, that defines a vegetarian. If instead, I say it moves and eats meat, well, that wasn't
swappable. So, the meat, the meat versus plants was not swappable. I changed it down to definition
level. The open definitive book level I've got now cardboard. On the other hand, if I move
the the bit about exactly what it eats from being in a specified column over to the substitutable
column, I've now generalized from vegetarians and carnivores, I've generalized to animal.
And so that you could pretty much do this on a laptop, I suppose, just shuffling stuff from
one column to the other is either specified or substitutable, and you do various cognitive things
like, you know, abstraction definition. And then there's a hierarchy of things, I would say. So,
if you start out with per seps, those can only be created and destroyed. And the next level up,
I would say, you can have a set of them, I call them constellations, but you can't change them,
they can only be created or destroyed. So, there's still not things. It's a set of things in some
sort of arbitrary relationship. But as soon as I have something that has both specified and
substitutable, now I have a thing. And it is no longer just only created and destroyed,
it can change. And that's what lets us do thinking.
Yeah, that's super, super interesting, because it ties to some stuff that I've been thinking
about with respect to in development and metamorphosis and regeneration and all that,
which is this old idea, this old ship of thesis idea. And so, thinking about the fact that the
important thing about the ship of thesis was they replace the planks and all that and it stays the
same ship is that what allows all this to happen is the policies in the ones doing the replacing.
So, it's the policies of the people, cells, whoever it's going to be that are replacing the
components that makes this thing the same because they need to execute their changes
in a way that preserves some kind of invariant for them. So, they're going to choose where to put
the boards and everything in a way that preserves what they think of as the ship. That's the only
way this is going to work. So, again, we're back to this idea of observers and starting off with
the notion that if you want the thing to stay the same, despite molecules come and go and the body
cells come and go, if you're a cognitive system, ideas come and go and mental states come and go,
but you're going to stay the same. For you to stay the same, there has to be a replacement policy
of some sort. And then that gives you the ability to do what you just said, which is
better than staying the same is actually a policy for changing you slowly into something else.
So, if you're a caterpillar, you are maintained for a while, but eventually there's a new policy
that actually maintains you and turns you into a butterfly. And are you the same? You've got
some of the same memories and you've got some other stuff, but a lot of things have changed.
But it's all about the policies that are not just keeping you the same, but actually
slowly transitioning you to some future sort of representation of where you're what you're
going to be. And in order to do that, you have to place the molecules, the cells, the information
in the right places to be consistent. To take this back to the previous conversation,
this is precisely the kind of relational information or boundary condition information
that we were talking about with respect to Pine's paper earlier. It's exactly the kind of
macroscale structures that aren't predictable, but they end up being stipulated by something,
some aspect of the environment. In this case, the aspect of the environment is the actual
user of the representation that says, what gives this representation an identity condition for me
is a particular utility. And as long as I alter the representation in a way that
changes that utility only slowly, I can count it as the same thing.
Otherwise, there will be some dramatic failure. It loses its identity
for me because it no longer does the job I need it to do.
And analogy I have for that is sort of like jokes where there's this cartoon I saw once,
where somebody goes up to his bicycle, he grabs it, starts to walk with it,
but the rear wheel stays right where it was. Well, okay, so you can define everything like
being next to each other that does not yet get you a thing because it didn't have any utility
anymore because the wheel was still there. So there's a little more than just spatial location.
Yeah, they're lovely old, old experiments by Elizabeth Spelke, her various collaborators,
with infants in the kind of three to six month old range in which they
glue various parts of things together or detach them in ways that lead to
surprising conjunctions of things or disjunctions of things following manipulation.
So for example, they have a toy person in a toy car and they manipulate them separately.
And then they present the infant with the toy person glued in place in the toy car
so that if you pick up the person, the car comes too. And at three months old,
that doesn't surprise the infant at all, but at six months old, they're very surprised and react
in a stereotypical way. So they've developed this concept that these are two different things,
whereas before, it was just all one connected sensory mess. Yeah, that's nice, that's nice.
So you can actually see these capabilities developing in real time.
So I should say then a little more about what I think a property is because that might
sort of be relevant too. So the properties I think of as two entities in the relationship
between them. So like if you're trying to define a snowflake, it's going to have
like six fold symmetry and blah, blah, blah, and it'll be cold and it'll be white and so forth.
But all those can be expressed as two objects in a relation and two entities in a relation.
And each of those entities is in turn defined by two entities in a relation.
And so you get this hierarchy. And then if you take the specified and substitutable thing,
where that sits is in the relationship rather than in the entities. Now the entities have their
own specified relation, but that's inside them. So then what happens, for example, is if you say,
okay, I'm looking at two things out in the world. One of them has exactly the same parts,
the same component entities. But the relationship to the world differs. You would say, oh, that's
particle motion. But what happens if you have the same relations, but different entities? Oh,
well, that's what a wave is. Because you've got the same relationship, but it's made out of different
particles of water. And then what happened with language is that one day I said, oh, well,
does this work for language as well? And are we thinking entity relation entity in our language?
And the answer is in English, yes. But you don't notice it right away because we leave out most
of the system component relations. And so you have data compression that makes doing chompskin
linguistics, which I think is basically correct, very, very hard and complicated. And then other
languages like Japanese or entity entity relation. But again, you have this like reading frame that
has to be imposed externally. You know, it's external because words are, you know, both words
have multiple meanings, we can still understand it. So it's imposed externally. So it's again,
a macroscopic constraint that's sitting on this and imposes this pattern.
Yeah, another form of stipulated relational information at the high level.
Yeah. Yeah, I would say it's wired in your brain. But a, we can't talk any FMRI people into letting
us do the experiment or NSF into letting test, you could test it with, you know, like these
iFlash kinds of experiments, but you can't get NSF to pay for it. Actually, so that I wanted to
ask you guys, so for a paper like you've been doing on the pre-energy stuff, I mean, it can't be easy
to find reviewers for a paper like that, right? Never mind a publisher.
It seems to take a lot of the editors a long time to find them, that's for sure.
Okay. Yeah, well, it's, I mean, it's, yes, it's hard. It's, this is a generic problem now anyway,
finding reviewers for anything is really hard now. Oh, you find that, really?
Oh, yeah. Yeah, yeah, yeah. Oh, even, even relatively mainstream things that are not nearly
as interdisciplinary as, you know, straight up biology papers that we put out, it's brutal.
Yeah, finding people willing to review things is really tough, for sure. And yeah, I've been editing
a bunch of guests, you know, guests, I guess, editing a bunch of issues and whatever. And so,
so I see it from the other end. It's like, yeah, it's very hard.
Is that because people are so busy or because they don't want to deal with new ideas?
I think it's mostly because they're busy. I, you know, but, but we, you know, we've got,
we get, I mean, that's what happens, right? So, so a lot of people are busy and eventually,
you end up with a kind of a self selected group that either that wants to review it,
why do they want to review it, either because they're really into it, or and if they're really
into it, they may have an axe to grind. And so they may not like, you know, your view on it,
they have their own view on it, right? Or there's some other reason why, why it's, it's, it's, it's
gotten way harder. You know, it's gotten way harder. Publishers is easier. I like, we've had a couple
of a few things in places like entropy, which it's, it's nice because biosystems, entropy,
like these, these, a Royal Society, they're good with really interdisciplinary stuff that,
that would be hard for a conventional journal. Yeah. Well, society, we finally tried and they
were quite nice, but they couldn't find any reviewers, which I was surprised, but you're
saying I shouldn't be surprised. You should not.
