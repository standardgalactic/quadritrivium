How's that? Can you see what you expect to see? Okay, great. Hi, everyone. I'm excited
to chat with you today. So I sort of debated a few different projects to talk about and
landed on some stuff. But like, like Professor Levin said, I'm always happy to talk, talk
about collective behavior. And I'm nearby. And also, yeah, please feel free to interrupt
if you have questions. This can be just more of a conversation. I realized just, you know,
a minute ago that perhaps I should tell you a little bit about who I am in my background.
So I did my PhD at the University of Colorado in Boulder, where I studied collective ant
behavior. And I did a postdoc kind of spread out at a few locations. So at Michigan State
University, and at at Harvard in Roddick and Naugpal's group, if you might know some
of her work, she's a computer scientist, doing collective behavior, but with sort of bio
inspired robotics, especially. But I was still studying, studying animals, studying ants
there and doing and doing modeling and theory stuff. So I did not myself, Dell very far into
the realm of robotics, but it was really great to, to do that really interdisciplinary work
and spend time with with folks who think about these questions pretty differently. Yeah,
and then yeah, I landed. Oh, and I also Albert Cow is a new, new collective behavior professor
at UMass Boston. So I spent some time, I had collaborated with him for a while spent some
time in his group as well. So and he is brand new there. So also an interesting person to
chat with if you're interested who's local. All right, so today I thought I'd focus on
problem solving and dynamic control and self organized systems. So yeah, so I my work is
broadly motivated by wanting to understand how complexity and patterns and even intelligence
emerge from groups of simple individuals. And I think this group group is really familiar
with with this, but across all scales, we know that collectives are capable of accomplishing
tasks that are a lot more complicated or a lot more difficult than what the individuals in those
groups can can accomplish. And in a lot of cases groups are groups also can outperform
so called intelligent intelligent individuals, like individual people. And this is perhaps
surprising because we might expect collective systems. Sorry, I'm not sure what the
I don't know. Okay, my keyboard is not working. That's okay. We might expect
collective systems to face particular control challenges, because they have to integrate
all of their sensing decision making and actions across dispersed individuals that might be
physically separated by a lot of space might be only loosely connected. So how can decentralized
systems coordinate? So I just want to expand on this for a moment and think about a spectrum
between distributed systems that have no leader like these ants here and systems with really
centralized processing where you have a single entity gathering information and making decisions.
We already know that there are a bunch of benefits to being over on the distributed end
of the spectrum. So we know that just decentralized groups are really robust. And they also often
make better more rational decisions than individuals, but they're also cost to distributed processing.
So we at least imagine that centralized approaches might be faster and more nimble in the
sense that they can respond more to changes or to new information. So I sort of think about this
as distributed systems having high inertia and the potential cost of high inertia is going to
matter more in some groups and for some tasks than others. So tasks that require a lot of flexibility
because they're being performed in conditions that are constantly changing or tasks that
require a lot of trial and error. I think it's reasonable to expect that those kinds of tasks
might be particularly challenging for distributed groups. So I have a few tasks kind of focused,
a few projects that I have focused on each of these kinds of tasks. I was going to say that
I'll talk about each of these, but I actually decided this morning to focus a little bit less on
the dynamic control of self-assembled bridges and a bit more on the trial and error tasks.
So I'm happy to tell you about this self-assembled bridge project in Army Ants that I finished more
recently. But like I said, I'm going to focus today on collective problem solving during obstacle
navigation. So I first explored this collective obstacle navigation problem in the context of
cooperative transport, which is what I studied for my PhD. So this is an example of cooperative
transport. This is a group of paratrokina longicornus ants. The common name for this ant species is
longhorn crazy ants. So I'll probably just refer to them as crazy ants. And they're working together
here to carry this large dead cricket. And you can see they're good at this. They're moving really
quickly or relatively quickly. They are not stopping and starting all the time. So these
particular ants, this ant species is really good at cooperative transport. But just for some context,
most ant species are really not very good at this at all. So most species, if they even try to work
together to carry something, they'll pull in opposite directions, perhaps for a long time.
They'll stop and start a lot. But I studied the crazy ants. I did actually do some comparative
work about the differences maybe between groups that are species that are good and species that
are not so good. But I'm just going to talk about the crazy ants today. So let's take a look at the
whole process of cooperative transport. The first thing that usually happens when we see
cooperative transport is that an ant that happens to be foraging comes across a large food resource
and decides that she can't carry it herself. She needs help. She'll then typically return to her
nest to recruit more workers. Oh, I apologize for that. She'll recruit more workers. And once there
are enough ants around the object that they're able to move it, they need to make a collective
decision about which way to go. And this direction that they pick, though, is not going to work for
the whole journey back to their nest, because they're going to run into things like obstacles,
like twigs, like leaves, or like this rock here. Really, anything is an obstacle when you're the
scale of an ant. And to navigate around these obstacles, they have to make a whole series of
new decisions. If they can do that, though, they're likely to make it all the way back to their nest.
So during my PhD, I spent a lot of time researching the mechanisms of this initial part of the process
on how groups make a collective decision in the first place. So I studied the individual traits
and behaviors that promote a group level success, why some species are better than others, as I
mentioned. But today, I'm really just going to tell you about the part of my PhD work that was on
obstacle navigation. Because, like I said, this is a task that requires trial and error.
So I want to convince you that obstacle navigation requires problem-solving. It requires
a whole series of decisions that build on one another. Because, like I said, the first direction,
they might choose to turn, initially, when they hit an obstacle, they might choose to turn left,
but then they have to choose when to turn back towards their goal, or perhaps
turning left in the first place doesn't actually work. Maybe it's a really complex obstacle.
Maybe they have to move backwards in order to get around it. So they may have to try multiple
directions and what the optimal choice at any given moment might depend on the decisions that
they just made. So let's think about potential strategies for navigating around obstacles.
I was really interested, particularly in whether a strategy or, yeah, is simple versus robust. So
strategies that might be really easy for ants to accomplish may work well for some obstacles,
but there may be obstacles that you need a much more robust strategy for. So let's just talk about
an example here. Let's say we have this simple obstacle here, a simple wall, and let's imagine
that the ants' strategy for navigating around obstacles is that when they hit an obstacle,
they choose the direction to move, and then as soon as the path, as soon as the direction of
their goal becomes available, again, they switch and move directly in that direction. So that would
work really well for this obstacle here. And I say this is a simple strategy in large part,
because we might expect ants to be particularly good at this kind of strategy. The only information
you need to know to do this is the direction of your goal. And ants are really good at knowing
the direction of their nest or they tend to be. So you don't actually need any other information
to succeed here. And if the ants were following that strategy, they would succeed with this obstacle
without any issues. But of course, we can imagine more complex obstacles, as I mentioned,
where this strategy would fail. So here, because the ants have to move backwards to escape this
obstacle, the direction of their goal is physically going to be unblocked well before they have
escaped. As soon as they start to move backwards, you might imagine they could say, oh, the direction
of the nest is free again. I'm going to move in that direction before they've even gotten out of
the obstacle. And we can imagine other strategies, of course, that would work for this kind of obstacle
too, but they all require having more information or more complex processing than the simpler
strategy. So for example, if they are keeping track not only of the direction of their nest,
but also of how close they are to their nest at every moment, using both of those pieces of
information has been shown to be able to solve any obstacle at all, but does, of course, require
more information. I just want to say a side note, which is that this project was
inspired in part by known simple obstacle navigation strategies from the field of robotics.
So this was a collaboration with Radhika Nagpal and sort of these kind of endpoints, these sorts of
endpoints of this spectrum from simple to robust, where it was coming from this robot
navigation literature. That's a tangential question. Yeah, please. Yeah, so you said that the task on
the left hand side of the screen is relatively simple, but even within that, you would need all
the answers to sort of come to a consensus in terms of, so there must be some kind of a communication
or all that stuff. So it's not as simple as it might seem, right? That's absolutely right.
And that's, I think, so the question that I spent most of my PhD really working on is how
might they come to a consensus in the first place? And for various reasons, it's kind of
experimentally a lot more challenging to study that question while they're already moving than
for the first decision they make. So I focused, in terms of the actual mechanisms of coordination,
I focused a bit more on the first decision they make to go from not moving at all to moving,
but change the decision to change directions. I think a lot of similar processes are likely
involved, but it's a little bit more experimentally difficult. So I have less, in terms of the
behavioral mechanisms, I have perhaps less satisfying answers to that, but I'll show you
some examples of them maintaining consensus. And to make a long story short, I think
they're feeling kind of voting by feeling the forces through the objects they're carrying,
right? So they're physically tethered together. If one pulls strongly, the others will feel it.
And especially on a simpler, you know, if the object they're carrying is relatively simple
and not doesn't have like moving pieces, although it often does. But then I think individual
persistence is a big part of it. So persistence or stubbornness, if you have, I did some theoretical
work as well, and some comparative work across species that if individuals, the kind of more
persistent individuals are about their direction, even the more stubborn they are, surprisingly,
that improves coordination. They're able to coordinate better. I was initially expecting
the opposite, but I think that the problem of like, nobody has a strong opinion is harder
in the case of the, you know, at least in the ants that I was looking at, that's a harder problem
than the problem of like, two individuals are pulling in opposite directions. So that was maybe
a bit rambly, but yes, I agree that the problem on the left is by no means simple. But with respect
to the obstacle itself, the challenge of that problem isn't so much the shape of the obstacle,
it's just the fact that they have to maintain consensus. So yeah, maybe that does that get
to your question about? Yes, absolutely. Thank you so much. Cool. Yeah. Okay, great. So like I said,
part of this work was inspired by the robot navigation literature. And I just wanted to know,
we wanted to know, you know, how are ants going to do these, these really different kinds of
obstacles? You know, so if they're following a really simple obstacle navigation strategy,
a strategy that we expect to be really easy for ants, where they only need to know the
direction of the goal, we would expect them to do really well at the obstacle on the left and
perhaps completely fail to navigate the obstacle on the right. And if they are using an extremely
robust strategy, then we would expect them to be performed relatively equally well with these
obstacles. So I went to the field to do, to study this in Arizona. This is my field assistant,
Zach Dix. And we gave ants groups of crazy ants little pieces of tuna to carry. We blocked their
paths with obstacles that look like this, as well as an impossible obstacle to see how they
how they handle that. And of course, we recorded them doing it many times. So here's one of the
videos. And one of the things I want you to pay attention to as what we were just talking about,
how rapidly they change direction when they do. I was really surprised. I thought when they first
hit this obstacle, they would kind of stop and have to regroup. But even, you know, even when
they don't know where to go, it's clear that they don't, they don't, you know, they change
direction several times. It's not like they, there's no trail here already formed. I didn't
put the obstacle down until they were almost there. So I knew that, but it's not like they
know where to go. They don't. But they are, are, it doesn't, it takes them like, you know, a moment
or like a second or less to change direction. So Justin, they are really amazing at maintaining
consensus, which I looked at quantitatively as well. But that was one of the take home messages
that these, these crazy ants are really good at maintaining consensus. And I think that that's
one of the primary things that distinguishes them from the species that are that don't do
cooperative transport well, which makes a lot of sense. Okay, so once I had recordings of all of
these obstacle navigation events, I extracted from those recordings the trajectory of the piece
of tuna. So this is just looking at the group level trajectory. I have some other, you know,
work and thoughts about individual movements and individual contributions to this. But, but
these images are just the trajectory of the whole group. And you can see that they do navigate
around these simpler obstacles, pretty effectively, you know, as, as you saw in the video example,
they do change their minds, they do change direction, but they were able to navigate
around all of these pretty rapidly. And they also have out, however, succeeded at navigating around
all of the more challenging obstacles, not so easily, you know, so it took them significantly
longer, they had significantly more circuitous paths, you know, they spent a lot more time
navigating around these more challenging obstacles. But I was actually surprised initially that
they succeeded at all. It never took them longer than about 10 minutes to escape these harder
obstacles, even though they have to move backwards away from their goal to do it. So I wanted to
look more carefully at how, how are they escaping those obstacles. Just to show you a video example
of that. First, this is obviously sped up dramatically, and now it's speeding up even more.
And you can see that they do, in fact, have a strong bias towards moving in the goal, in the
direction of their goal, you know, they, every time they move away, they're very likely to turn
back towards their goal. But they do eventually manage to completely escape the obstacle and move
on. So let's take a closer look at one of these trajectories, focusing just on one particular
trial. So you might notice that when they first hit the obstacle, which is the pink part of the line,
they spend most of their time along this back wall, which is as close to their nest as they can get.
And it's not until later on, the blue part of the line that they seem to explore the space more. So
this may be wonder, do they actually, are they, are they more likely to move further backwards the
longer they've been stuck in an obstacle? So to find out, I extracted the distances of all of the
backwards movements from all of their trajectories, where I counted it as a single backwards movement
for as long as they were moving away from that wall. And as soon as they, the distance to that
back wall started decreasing again, that was the end of that backwards movement. Okay, so yeah,
and then I just ask, do those distances of backwards movements change in time? So here are
the, here are density plots showing the distributions of the distances of backwards movements for,
for these trials where I've broken, these different lines are showing different time
intervals, I've broken the trials up into different chunks of time. So if you look at just the very
first time interval, when they first hit these obstacles, almost all of their backwards movements
are very, very short. They're essentially bouncing around along the back wall. But then by the last
few time intervals, they're much more likely to move substantial distances backwards. And you know,
I excluded the, the final backwards movement that led to their escape from all of my analyses,
and confirmed statistically that yes, the mass of this distribution is shifting more towards
the right, the longer they're stuck. So the longer they're stuck in these obstacles, the further
backwards they move. Yeah, go ahead. Can I ask a very quick question? From the videos that we're
seeing, do the other ends also interact with the answer, the carrying the load, are they also
reporting what the environment looks like, what the best trajectory is? That's a really great
question. And I spent quite a bit of time on that question. I've spent quite a bit of time thinking
about that question. And the short answer is yes. So those are referred to as escort ants.
And they, they do seem to play an important role. And there's another group who has done quite a bit
of obstacle navigation work on this species, the Feynman group, offer Feynman's group at,
oh, I'm blanking, I want to say Hertzberg. But anyway, they have, they, they found in the
population, they're studying that, yes, those escort ants joining, if they, if they join
the transport group, they have an outsize influence on the, on the direction.
And I think that is likely to be important in some contexts. They also have found that, that they,
and I can confirm that the, these other ants that are around are sometimes laying some pheromone
trail. It's really conspicuous when these ants lay pheromone. And that's sort of happening
in the vicinity of this, of the cooperative transport group pretty frequently, even after
they're, they're moving. So that could be another additional source of information.
I, I noticed though, I, I, I tried to sort of do a pretty careful analysis of this,
you know, initially qualitatively, but the, that's not happening very much while,
while they're in the, this hard obstacle, though, I'm not seeing that kind of information while
they're navigating around this, this challenging obstacle or obstacles in general. So that doesn't
mean that they're not providing information, but I will say kind of, I think they are, I don't think
they're required, however, because sort of, you know, there's, there's a lot of variation in how
many of those there are around. And trials where there were few, if any, it didn't seem like they
were substantially worse at navigating around obstacles than when there were many. I also see
actually fairly low turnover. So in terms of the possibility of ants joining and, and providing
you information, I think that absolutely happens, but, but even when, you know, there, there isn't as
much turnover as you might expect in, in my, in my prod, in this project anyway, when,
if, if that, if that was really crucial information, you would expect more turnover.
And, and I also looked really carefully at the specific, the specific turns that led to their
success when, you know, the, the, the last turn they made that allowed them to escape.
And some of those did coincide with another ant joining, but, but the majority of those,
there was nothing that I could see. Obviously, I'm not an ant. There's nothing I could see though,
that, that kind of directed that. So, yeah, long story short, absolutely the other ants are playing
a role. In fact, I mentioned in passing that I also gave them an impossible obstacle, which was
it was just this same obstacle here, but with the door shut. And their behavior in that shot to me
because they, I expected it to look pretty similar, their trajectories to look maybe pretty similar
to, to this, this, this obstacle here. And maybe eventually they would kind of give up, but they
almost immediately start to give up. It's like they know very, very quickly that something
is different. And so I think what explanation for that might be that in the case where this door is
shut, the escort ants, these extra ants around, there's, there's maybe fewer of them, they're
not changing over. Anyway, I'm rambling a bit, but I want to say I think they're really important.
I don't think they are absolutely necessary, especially not for obstacle navigation.
And, and I don't know more about their importance really.
Oh, sorry. Is it possible to track pheromone trails laid by escort ants? Is it any method or
technique? Yeah, so actually that's something that the Feynman group has, has done. So, you know,
and I could quibble a bit with some of the ways they're doing it. And I would be, I would be
fascinated to apply that method to my videos, which I think the trick there is that in order
to do that, they had to be, they had a moving camera that was focused on the object so they
could be really close, which is hard to couple, certainly not impossible, but hard to couple
with needing a wider view for obstacle navigation. So yeah, I think, so that has been done, has not
been done in the content, I don't think in the context of obstacle navigation, but, but yeah,
it's a very, because it's tricky because the only thing you can see, you can't, you can't
chemically track as far as I know, you can't sort of pick it up. But you can, they have this
halting movement pattern when they're laying pheromone trail where they, they pause every centimeter
or so, just for a fraction, split second to touch their gaster down to the ground to lay
that pheromone trail. So, so you can kind of see it in a video. And that is, that's what the, what
the Feynman group used to get that automatic kind of information. So, yes, to some extent you can.
Helen, if you compare these behaviors, so these rules that you're sort of sussing out about how
these navigate different environments, how does that compare to if you had the same species, but
a solitary individual carrying a single piece of cargo? Are they scaling up the rules of the
individual or is it a completely different strategy? I don't think they're scaling up the
rules of the individual. Oh man, you're all asking such great questions, which is not surprising.
And it's also just reminding me of all of my like zombie data projects that I haven't done because
I, so I, I collected videos of individual ants facing these same obstacles with
any bitty pieces of tuna. And also with, you know, like using like liquid, liquid bait,
where their behavior is actually kind of different. But the, these ants, the challenge is,
it was really, yeah, so this was, this was, I, you know, actually, if I, if I did turn back to it,
I might be better equipped now, but the challenge is, there's a real computer vision challenge in
tracking these individuals because they move absurdly quickly and in very, very like,
they're called crazy ants because they have this really crazy movement pattern. They kind of like
jolt all over the place and it's, it's quite unpredictable. And I think it's fine for tracking
out close up. But the videos that I have, which are not that close, they're similar to this
because of the scale of the obstacle just made it challenging to track the individuals. So even,
even, even manually, even, you know, just with by eye, not impossible, but it never, it hasn't
happened. It could happen in the future still. But, but my intuition, however, from having just,
you know, not quantitatively analyzed it at all, but having actually just done that experiment is
that it's very different. The individuals, they, they, they often would run up to the obstacle and
just, just bounce back and forth like a lot. They're moving so fast. I think the, I think that
my impression is that the additional effort of like having a really circuitous path and, and
going far more distance than you need to is just like not important at the scale of the individual
when the, when the object is small enough that, you know, they don't, there's not like a huge
amount of effort to actually move it in the first place. So I do think it's a wholly different set
of rules. Can I ask a quick question as well? Yeah. So from your videos, it's, these are,
these are really cool. But there are two ways that they could solve this problem is that just
bounce around all along the wall and then accidentally discover, oh, there is the whole
here through which we can escape or after doing some whatever information gathering, they can
know, okay, here's the whole, let's go for it. And it looks from the video is that it's like,
like the latter because it's like they are struggling, struggling, and then suddenly
they get it and they, they just go through that gap even without touching the, the corners or,
or anything like that. Does that make any sense? It doesn't make sense. I guess I will say you,
you saw one video, which I, you know, I, I could look back through. I don't think it was as clean
in all of the videos. I think that, but there, I think it is true that maybe, and maybe this speaks,
maybe this gets at what you're saying, I hadn't thought about specifically how they're interacting
with the exit, but it is true that across the board, once they do exit, they immediately turn
around and know where to go. And that is still very surprising to me. So yeah, there's something
potentially interesting going on there. And that might, that might be affecting the exit itself as
well. And even if it may be at something that, you know, they don't, they don't appear to be exploring
the space enough to like build a map. They, you know, there were, there were plenty of examples
where they escaped a lot faster, although that certainly might have been random. What isn't happening,
I don't think at least not by a rule, at least not that the majority of the time is that individuals
are leaving and exploring to see where the exit is. And then coming back, I looked for that and
didn't find that to be a common thing that was happening. But yeah, I mean, you're right that
so, so what I, what I know so far is, is pretty basic in terms of I can compare their performance
with what we would expect with some kind of really gross ideas about what their strategy could be.
But there are pieces to the strategy that I certainly, you know, I don't, I don't pretend to
know what the strategy is. Very cool. Yeah. Yeah. Yeah. Thanks. They're also, you know,
side note normally would be the option of just climbing, they can, they can lift these things
and go vertical too. So normally they'd also be able to climb the walls, which I've prevented by
just making them really slippery. So, and maybe that's affecting things, maybe they're just trying
that over and over, although they don't, they certainly don't seem to be. All right, so I'll,
I'll kind of recap this, this, what I've told you about this project, which is just sort of
scratching the surface a bit. What I learned about their collective strategy, which again,
as we just talked about, is, is I don't know what it is, but I know that it involves sticking
together. So they are extremely good at maintaining consensus, even when they do not know where to go.
So they stick together, they maintain consensus. They are also flexible. So, you know, they,
they don't, even though they start off with this tendency to want to move as the way I'm
interpreting it, this tendency to, you know, have this strong bias to moving towards their,
their nest, which is the easy thing, right? We, they, we, they are good at knowing the
direction of their nest, that should be an easy strategy for them to use. They will shift over
time to a more complex strategy, one that is more robust over time, if that initial strategy
doesn't work. So that's, that's what I did with cooperative transport with obstacle navigation
in the context of cooperative transport. But cooperative transport working together to carry
something heavy, that's unusual. That's not normally how groups move through the world. And
it's actually as, basically, we think just ants really, and humans, and maybe a couple other
species, but mostly just ants and humans that even do that at all. And, you know, most, most
groups that are moving through the world, including groups that are very invested in,
in sticking together, are not tethered together, right, by the objects that they're carrying in
the case of cooperative transport. So I really wanted to explore how these more typical groups
navigate around obstacles. And I just have done one project, looking at this in theory. I think
there's potential for a lot, a lot more interesting stuff here. But I just thought I'd share a little
bit about what I've learned with this, this little theory project. So, so a bit more motivation
in context for this. So we, there's been a lot of really great work on flocking models on, on
modeling swarm movement. It's one of the really well studied behaviors in collective behavior,
going back decades. You know, we know that quite simple individual rules can reproduce
behavior that appears very similar to what swarms do, what swarms of schools of fish,
you know, flocks of birds, things like that. But those kind of standard well studied flocking
models typically exclude obstacles. When in real life, in the, in, in nature, animals that are
moving through the world are going to be facing obstacles very frequently. So how do you, so,
so with, with some collaborators, Justin Whirlpool, Stefan Popp and Varun Joshi, we wanted to explore
how does those, those basic flocking models, I say basic, they're not, they're not basic, but
those existing flocking models that are well studied, how do they behave when we just throw
some obstacles at them? So this was, you know, really inspired by the project I showed with,
I showed you, as I mentioned already. But we, we wanted to kind of apply that concept again to
these flocking models. So we started with these well studied models, where they have zones of
avoidance, alignment and attraction. So, you know, you have some individuals, they have behavioral
rules. This kind of Ian Cousins was one of the persons, one of the people,
Reynolds sort of came up with this initially. Ian Cousins was one of the people who kind of
developed this modeling framework a lot more, especially in the context of biology. And in
these well studied models, these Boyd's models, individuals have, if they're, have these zones
of behavior. So they will be, they will avoid other individuals that are very, very close to them.
They will be attracted to individuals who are much further apart from them. And then
individuals that are at some middling distance, they will kind of tend to align with. So that's
sort of the basics of some of the earliest versions of these models. And so we, we took that same
basic model and several other extensions, and added a goal direction, and a dead end
obstacle. So added a challenging obstacle that require, require them to move backwards.
And so we, the other stuff we added was just, they're not going to collide with obstacles. So we
extended the model to include collision avoidance. But we did not add in any other specialized
behaviors for dealing with obstacles. We were planning on it. But then what happened surprised
us. So we ended up not. So, so the individuals don't have any, any rules for wall following.
They don't have any, you know, any of the kind of, you know, I thought we were going to take what
I learned about the ant strategy and maybe apply it here. But, but this is not even that complex.
So no, no obstacle navigation behavior, other than just don't run into the obstacle.
And we explored a large parameter space for, for this model. We also explored different versions
of this model that are not based on these zones. So there are, and the individual parameters are
things like, you know, how big is your zone of avoidance versus your zone of alignment versus
your zone of attraction? And how much are you kind of waiting those, those three different
possible behaviors? And how fast are you moving? How fast are you turning? How many are in the
group? How many are informed about the direction of the goal, etc. And what we found, which was
surprising to us at the time anyway, was that flocking escapes, this is what we call them,
emerge when you have high alignment when the individuals are waiting the aligning with others
just moving in the same direction of others. If individuals are waiting that behavior high,
then, you know, they will, they will escape. I've been waiting for them to escape and I forgot
that that was the example when they don't escape. So this, so over here on the left, that's when
they, they have low alignment and on the right is high alignment. So, and, and one of the reasons
this was surprising is that there has been research in the maybe last five to 10 years where
showing that that alignment behavior is not itself necessary for the kinds of movement to emerge
in the absence of obstacles. So, so when you, when you do simulations, you don't necessarily do
simulations in the absence of obstacles, you're looking for behavior that is qualitatively similar
to what these swarms do in nature, you don't need the alignment to get there. But we found that with
the alignment in, in these simple models, these, these individuals are just like spontaneously
escaping. Okay, so a few more things about this, we explored this in a lot of detail. So solitary
agents never escape, except that they do if they have an extremely low turn rate, a turn rate where
they can't, you know, they'll hit the obstacle and they can't just turn around and go backwards,
they're kind of forced, they're forced to wall follow because they can't turn fast enough,
that's the only situation where solitary agents were able to escape. And that's why we started
calling it a flocking escape. So let's look a little more carefully at, yes. Can I ask you
something? So is this a like kind of a mathematical physical consequence of the fact that if, if they
are aligned, they can, you know, walk longer distances without, you know, random fluctuation
or random walk. So your radius is increased. Yeah, yeah, you, I mean, that's the punchline. Yeah,
we, we did get a mechanism and that's, that's pretty much it. So yeah, I mean, I, I could just
say, let's say end of talk now, but no, I mean, there's perhaps some more interesting stuff,
but absolutely, yeah, you, you, yeah, you, you have higher directional persistence, you're more
likely to move in the same direction for longer. Yeah. Yeah. And so we see that really quickly.
So, you know, we looked at a wide range of values for alignment weight. So on the left here,
it's showing just the proportion of simulations that had flocking escapes. And you very quickly go
from no flocking escapes to you're always doing flocking escapes. And then this over here on
the right is showing you how long it takes to get to the goal. So if you get to the goal at all, so
in many of the cases with low alignment weight, they never reached the goal, right? But if they
did reach the goal, you know, as their aligned weight increased, they got to the goal faster and
faster until the fact that they had that high directional persistence meant that even once
though they escaped the obstacle, they were taking really circuitous routes back, they were sort of
like took them a long time to arc back to the to the goal. So, so there is such there's certainly
quickly such a thing as too high an alignment weight when it comes to just getting to the goal
faster. Let me ask a quick question. So, yeah, yeah, yeah. So how many of these agents know
what the target direction is? In the results I'm showing you right now, it's 100% of them.
As I'll show you later on, that is so if you have many fewer that know it that that does affect
things for sure. So I'll show you that in a minute. In a in a small way. Yeah, so but right now 100%
no. And so what we found is across the full parameter space. In general, this high alignment
weight was necessary and sufficient for flocking escapes. So we played with a lot of parameters
as you saw, or you didn't see but as I mentioned, and pretty much regardless of the parameter parameters
of a particular simulation, if it had high alignment, they succeeded. If it didn't, they failed.
There are exceptions where it was either not necessary or not sufficient. So but just to
show you what this looks like. So every panel here is a different parameter that we varied.
And the orange dots are the average of a bunch of simulations in terms of proportion of escape
where they had high alignment. The green is that same parameter set but with low alignment.
And you can see in general, when they had low alignment, they didn't succeed when they had
high alignment, they did. And yes, there are exceptions. And I'll go into some of the exceptions
in a bit more detail. Happy to talk about the others as well. So here's, you know, some more
parameters. And yes, fraction informed. So if if instead of having everybody informed, it's a lot
less informed, you can you can see some escape from those obstacles, even without high alignment.
So we'll talk more about that. When the other one I wanted to point out here. So these are these
are the cases when high alignment weight is not necessary. That's what I'm focusing on here.
Low, really, really low turn rate, you can also get some escape without without alignment. I'm
not going to focus on the cases where high alignment is not sufficient. In most of these,
most of these parameters, there's some threshold above which you see the expected pattern of
of high, high escape with high alignment. All right. So we wanted to know is I'll talk more
in a moment about about the sort of low fraction formed and low turn rate. But I wanted to kind of
pause and and and talk about what we did to to think about whether this flocking escape is just
an artifact of the way we coded the model. So or the way we implemented the model or or maybe
it happens with this zonal model where you have the discrete radii of different behaviors. But
but that's not very realistic for real animals. We don't think so maybe it fails under more
realistic situations. So we we like I said, we built initially built the model with that zonal
zonal behavior. We also tested this with continuous zone boundaries where the
the different weights for avoidance, alignment and attraction are not there aren't these discrete
boundaries where you just have your you're you're changing instead of changing your behavior and
only doing one thing at a time, you're waiting the three possible behaviors depending on the
distance to the to the other individuals. And so yeah, I'm not don't worry too much about
understanding the precise details of this of this. But the point still held that even with
a very, very different way of implementing the same model that was based on some work by Daniel
Daniel Colovey on on real fish. So even in that scenario, we have low alignment weight,
no escape high alignment weight, you still see this escape. We also looked at a model
with bursting coast movement instead of continuous a continuous velocity. So this is also more
realistic for many fish species that that move in short bursts. We found the same general pattern
with escaping with high alignment, not escaping with low alignment. We wondered whether there
was something about the shape of our obstacle that was maybe increasing the likelihood of having
this behavior, because it's curved, maybe they're kind of reflecting off it in a funny way. So we
looked at different shapes of obstacles as well. And we were not we were not able to kind of
prevent our flocking escapes from happening. So again, with high alignment, we saw flocking
escapes basically all the time. And again, with low alignment, we did not see a lot of flocking
escapes. I don't completely understand how your model translates to to the actual experiment,
because the ants are connected through this tuner that they're holding on. So they're
absolutely aligned, right? It's not like the individual ants moving around. Yeah, yeah, yeah.
So we didn't want to we were not trying to connect directly to that experiment at all. We said,
okay, we learned some stuff. It was inspired by that. But actually, you know, a totally separate
thing. We, we looked at that. I, you know, did that did that project with the ants got me really
interested in obstacle navigation. And initially, the plan was to say, okay, what do those rules that
the ants were following or might have been following? What do those mean when you're not
tethered? But because we saw this flocking escape without even having to add any obstacle
navigation rules, we got really interested in that. So but but the whole point, indeed,
was to look at groups where there is no tether now. So so we're, yeah, so you're right, there's no
connection. I mean, there's a historical connection. And it's the same similar thing. But but yeah,
that's that was sort of providing context. So they answer your question.
Yeah, thank you. Thank you. Yeah, great. Great. So, okay. So, point being, we just we kind of,
we tried to break this and and we're not able to with with the specific ways that we tried to.
So I want to kind of recap what we found about flocking escapes in terms of describing them
before looking a bit more at mechanism. So the these flocking escapes, as we called them,
they happen without any specialized rules for navigation. They are nearly ubiquitous when you
do have high alignment weight. The cases where you don't need high alignment weight to get them are
when you have a low proportion of individuals being informed about the goal and a low turn rate.
And they never happen with solitary agents. So again, except that unless the solitary agents
have extremely low turn rate. So the social aspect is key. And we did explore the mechanism. Some of
you have already asked questions. You're already thinking about the mechanism. This is obviously
a great group to talk about this kind of thing with. And if you're if you think you might have
some intuition about the mechanism, you are probably right. So yeah, so once again, we have
three parameters that enable escapes, high alignment, low fraction informed, low turn rate.
And I just thought I'd show you a bit, a few more examples of what this behavior looks like
with each of these. So that was a case of high alignment. This is a different case of high
alignment. They don't always move completely together as one group, they do sometimes split.
But the high alignment, they always get there. When you have fewer individuals informed. So in
this case, the individuals that are in red are informed about the goal, you're also able to
get this escape. And then this is what it looks like when it's low turn rate, they're a little less
aligned, right? They don't have high alignment here. But they're still able to escape. All right.
So we and I'm sorry, I don't remember who who it was that mentioned this, but
we as as someone mentioned, turn radius is something we got really interested in.
So sort of how their directional persistence and another way of thinking about that is
how tightly are they able to turn. So we implemented an individual one of our model
parameters was individual turn rate, the maximum rate that individuals could turn at. But what's
the actual turn radius that you get when you have this group of agents that that have behavioral
rules that they have. So we measured that by doing separate simulations without any without any
goal without any obstacle and where they're there were their goal was really just to turn
as tightly as they could while following their rules. And we measured their turn radius. And so
here, this panel shows you the turn radius as a function of each of those three parameters
that we saw affect flocking escapes. So so on the bottom here, this is turn radius as a function
of a line weight. And you can see that, you know, as we expected, the groups with a higher alignment
weight have a higher turn radius. And likewise, turn radius is also strongly affected by the turn
rate. That's pretty intuitive. And the fraction informed. So when both of those cases, the higher
that parameter is the lower the turn radius. So if you you can think about for fraction formed,
which is perhaps the less intuitive of the two, you can think about that like if fewer individuals
are informed about the direction of the goal, then collectively, they're kind of waiting that
lower, their perhaps their their collective behavior would be, you know, carrying a little
bit less about getting to the goal, or would have that effect. And so, so then they're kind of
relative weight of how how much they want to align are usually would be higher if you if you're
just thinking about relative weights. But either way, we have now we have this information about
how turn radius is affected by each of these parameters. So here in this last graph on the
right, I'm showing you turn radius as a function or sorry, proportion of flocking escapes versus
turn radius. So for the for the three different parameters, the what was the x, the sorry, the
y axis here in this middle panel now has become the x axis here. And the point of this is just to
show you that, indeed, you know, regardless of what parameter it is that's leading to a higher
turn radius, unexpectedly, with high turn radius, you're more likely to get to get flocking escapes,
but also the shapes of these curves, you know, we didn't have there's not a lot of data here,
we didn't have a lot of we didn't test a ton of different levels. But these look relatively
similar, they're they're not they're not wholly different. So I'm going to try to just wrap up
here. So overall, we found that low effective turning rate is is leading to these flocking
escapes. So that happens with high alignment, because agents are prioritizing pointing in
the same direction as their neighbors. It happens with low fraction formed, because low effective
turn rate. Sorry, it happens with low fraction form, because the drive to turn back towards the
goal is lower. And it happens with low turn rate, because it's low turn rate. And and the last thing
I want to say about this project is that whether you're able so so having this low turn rate is
is helpful potentially in the context of obstacles. But whether you're doing that through alignment
versus having a low fraction informed versus having a low turn rate in the first place,
individual turn rate matters with respect to the larger context. So having groups that had a low
fraction informed, those groups did escape, but they took a lot longer to reach the goal
overall than the groups that that escaped because they had high alignment. And low turn rate also
in low individual turn rate also led to longer total navigation times. And if we think about
downsides to having a low turn rate or a low fraction informed, you know, negative possible
consequences of that outside of the context of obstacle navigation, just if you're like a school
a fish in the wild, it makes sense that, you know, you you would want to be able to be individually
agile and turn on a dime to escape a predator, predator, let's say, or you would want to know
where your goal is. We can imagine pretty pretty intuitive downsides to those. Whereas, you know,
there are also there's a downside to having a really high alignment weight. In the sense it
takes you a bit longer to get to the goal. But there's less obvious, I would argue less
obvious downside to that in the context of, you know, other behaviors.
So we think that this really high alignment weight could potentially be a sweet spot where you
you in the context of obstacle navigation, it allows you to navigate around those obstacles,
but perhaps when you're avoiding a predator, you're still able to do that with some agility.
Yeah, so with high alignment weight groups can rapidly escape the obstacle,
still pretty quickly reach the goal, and maintains the individual's ability to turn quickly and be
informed. All right, just to wrap. Oh, yeah, sorry. So flocking escapes emerge with high alignment
weight. It's necessary and sufficient with few exceptions. And regardless of our model
implementation, so we do think it's possible that this is something that really happens for
some species. And it's, yeah, it's, it's kind of, we think it allows you to get some quote,
unquote free obstacle navigation capabilities without sacrificing agility or speed.
I'll move on to kind of an overall recap. I think there's something, you know,
it makes sense. This is obstacle navigation into really different contexts. In the case of cooperative
transport in ants, we are finding that they prioritize coordination over efficiency. So
they are really good at maintaining consensus. And that I think is a really important aspect
of their success of why that species is so good at this. And in that case, they start with a simple
strategy and they add complexity only if they need to. Whereas in the case of untethered groups,
doing a very similar behavior, similar obstacle navigation task, they, I would argue, having
high alignment weight is also prioritizing coordination over efficiency, prioritizing
alignment in this case, over efficiency of movement. And in this case, we didn't find that
they actually had to have that added complexity. So, you know, even without changing the behavior
over the course of the simulation over the course of the time that they were stuck in the obstacle,
they did escape much of the time. So that was all I wanted to mention. Lots of, lots of great
collaborators who were part of these projects. And also the bridge project that I'm sorry,
I ended up just teasing you about and not talking about at all. Oh, I wanted to also give
another shout out to Albert Cowell since he's local, if you're curious about chatting with
anyone else about collective behavior, he's done some really interesting stuff on that front. So,
yeah, happy to take any more questions.
