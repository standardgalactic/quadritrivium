go through it and I'd love to talk about eruption theory
and the thing you were saying the other day
about the information that's not lost and all that stuff.
Yeah.
Right, right, yeah.
And we can also, if we have time,
we can also talk about this issue
of how far down it goes and all that.
Yeah, ideally we want to have a measure, right?
Like a operationalized criterion for that.
So this is exactly what this is about.
Let me just see what's the best way of sharing this.
So I think,
is it okay if I put out my second screen?
I will be a little absent looking to the side.
Maybe if I record it better,
like if I have it in the background.
Well, it's mostly gonna be the, I mean,
just to share this, I don't even know
that we're gonna see you,
we're just gonna see the slide, so it's fine.
Just share that.
Okay, okay, all right.
Yeah, because I can see you basically,
it's easier that way.
That's fine.
Okay.
All right, Safari into game share.
How's that looking?
Perfect, yeah, I can see it, great.
Okay, let's put this over here.
Yeah, great.
Okay, so this is the new paper that just recently came out
and it's a more mature version of the eruption theory
that now both consider is not just the mental causation
or like the agency part,
but also the other direction,
like how does something non-mental become part of the mental,
part of subjective experience,
part of mental content.
And so now it has these both classic problems,
which, you know, come in many varieties.
But I think now in this paper,
for the first time I see a way in which we can do science
with them, which is getting me very excited.
So I'm gonna take us through like the main figures
because they kind of encapsulate
the different stages of the argument.
So we start here.
Okay, so the human version of the mind-body problem.
So, you know, if you're asking here the big questions,
how is the mind related to matter and vice versa?
And, you know, analytic philosophers have been banging
their head against this problem for a long time.
And if you read Kim's kind of like final book account of this,
I quite enjoyed it for its clarity of showing that
even if we solve the problem of mental causation
by going kind of a reductionist route
and just basically saying that, you know,
the mental is the physical
and therefore the physical can cause the physical, you know.
You lose a lot of what is nice about thinking about the mind
in terms of its qualities and teleology
and, you know, your intentions and free will.
Everything goes out the window,
but you might save causality, right?
So you still might get mental causation saved that way.
But the problem is that if some of our things that we do
depend on conscious experience,
then the problem is not fully solved.
Because that would mean that you also have to have an account
to solve the hard problem of consciousness,
to have a full account of mental causation.
And so right from the start,
I want to say, I want to be realist about this
in the sense that, you know,
I do think that our experiences make a difference
for how we behave, right?
And if someone wants to say that our experience
don't make a difference to how we behave,
we've kind of like have two different premises.
And like the conversation really kind of stops there,
but to my mind, you know, it's a very hard sell
to try to argue that our experiences
don't make a difference.
We basically lose most of the population of this planet,
basically just, you know, exits the conversation, right?
So we should do our best not to go down that route.
But what that means is that we also have to solve
the problem of consciousness.
So these are interlocked, right?
And this is the big problem.
It gets worse, because you might think,
well, that's just for people, you know,
because that's the problem of consciousness, you know,
but if you talk about rats or, you know,
even more basal cognition,
then this might not be an issue.
But what it proposes that actually there's a more general
mind-body problem working in the background.
So on the left hand side,
I call this the hard problem of efficacy,
which is that for any mental property,
let's say a representation, a goal state,
or whatever you have,
there's a problem explaining how that state as such
as being a mental state makes a difference
to the physical state.
So it's a generalization of the problem of mental causation.
So it's not good enough to say
there's a supervenience relationship or something like that,
but the causality at the bottom level maintains.
You know, what I want to say is,
how do we say that the goal as being a goal,
as being an intention, as having normativity conditions,
as being able to succeed or to fail,
or to be better or worse and things like that,
the whole normativity of it,
that also somehow needs to be able to account it
for in this kind of account, right?
And that's the hard problem of efficacy.
And then we have the hard problem of content,
which is how does anything even become part
of the mind in the first place?
And so representationism, for example,
just kind of rushes this away a little bit,
but let's say, even if we gave representationist
half of this and said, okay, let's don't worry
about how to naturalize content in terms of its origins.
Let's say some future point, we have a story
of how you go from something purely physical
to something that has semantic content,
that has mental content,
that has about these conditions or normativity.
Let's assume that problem is solved,
then we still have the problem
of how does that even make a difference
to something physical?
Take a thing like, I don't know,
like a neuron in the brain that's supposed to represent,
I don't know, your place in a maze or something like that,
your classic place cell stuff.
Well, the fact that it's representational,
that it has representational content,
which is kind of like Nobel Prize winning material, right?
So this is exciting stuff.
We find the correlation,
but then where in our analysis of the neural activity itself
does the content enter the picture?
All right, so when we look into the brain and say,
here's this neuron and we know it's correlated
with this, you know, content outside of the rat,
like being in its position in the maze,
but hey, you know, like the rest of what we're seeing here
is just physics, it's just biochemistry,
it's electrical potentials, right?
It's like, you know, membranes opening and closing
and molecules floating around, there's no content there,
there's no normativity, it's just physics, right?
So there's a kind of sense of disconnect here
where how do we even work across this gap?
And my feeling is that this is not,
we can't just, you know, talk it away.
My feeling is that we should face it head on and say,
yes, there is a big gap here, right?
On the one hand, we can talk about content
and consciousness and the mental and intentions
and norms, health, you know, being, you know,
worse or better and so on,
terms that have no frame of reference
in the purely physical sciences,
but they do have an existence
and we know they make a difference,
so we're realist about it.
So why don't they show up when we do our best science,
you know, and one of the things that, you know,
already should come out of this is that
just because they don't show up as such
doesn't mean that they don't make any difference, okay?
So that there are two different things here.
One would be a demand for observability
and even maybe intelligibility.
So I observe something and it makes sense as a content.
And the other one is to say,
well, maybe that's not what I can do here,
but I noticed there's something else that's happening
that wouldn't happen otherwise, you know,
if the system wouldn't be in such a state and so on.
So, you know, so far, most people have demanded
that the mechanism should be observable and intelligible,
but why should we assume that, right?
There's a big gap here.
And we know already from other fields,
quantum physics, a prime example,
that demanding intelligibility and observability
can be a big stumbling block, right?
Sometimes you just have to get in and say, yeah, you know,
we don't understand why it's happening,
but something's happening and we can measure that
and we can work with that, you know?
