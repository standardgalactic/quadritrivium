So this is Mike Levin on Wednesday, May 8th.
From home, it looks like.
I'm at home today.
Yeah.
Me too.
Me too.
Well, I thought this Selb's piece was absolutely fascinating.
Just.
Oh, thank you.
Fireworks of ideas coming off it.
Just very rich.
So I'd love to ask you a few questions about it just to unpack it, and then we can make
it from there.
First of all, connect this thinking and this piece to your lab work.
What brought you to this?
These thoughts and what were you seeing that made you want to answer the questions you answer
in this piece?
Yeah.
Great question.
Let's see.
A couple of things.
First, I am really interested in information and how information is used by different
components of the living body.
So Josh Bongard and I have been developing this notion of polycomputing, which is this
idea that basically every subcomponent is hacking every other subcomponent in the sense
that it doesn't know or care what the original intent of the message was.
It's going to interpret it as best as it can, however it can.
When you say it, are you talking about organisms?
What are you talking about?
Well, every level.
So cells, subcellular protein networks, pathways, organs, tissues, antels, everything.
Right.
I think this is a fundamental feature of biology that it's a hacker in that sense that you
have no allegiance to how something was intended to be used.
You're going to do the best you can in interpreting.
And that comes from working with Josh Bongard with his discoveries that the exact same physical
mechanism can be seen by one observer to be computing one function and another observer
to be computing a different function.
So that when you ask, what is this physical process computing?
Somebody might say, well, I know what it is.
I wrote the algorithm so I can tell you what it is, but in biology, nobody cares who wrote
the algorithm.
Well, I don't care what you say, I'm interpreting your algorithm, your novel, your message in
my own way.
It doesn't matter to me what you think you meant by it.
Whatever I get out of it is what I get out of it.
So it starts with that and attempts to understand how different biological systems interpret
information.
And I was thinking, OK, so that's one thing.
The second thing is I really think that there's a lot of important work to be done to break
binary categories that we naively think exist, but actually are just hiding a lot of limits
on our imagination.
And so this notion of data versus the machine that operates on the data and this idea that
information is passive and then you have this active cognitive being whatever it is
that's going to operate on that data, remember it, store it, change it, whatever.
And so I was thinking about ways that we could break that and really make that into a continuum.
And I was thinking about the whole caterpillar butterfly thing.
And I thought about this for many, many years.
And originally, the thing you might think is cool about it is the question of where's
the information because the brain gets mostly refactored.
OK, but then it hit me.
I was I was literally I was taking a walk with my dad and it and I was thinking about this
and it hit me that that isn't the most interesting part here.
What's interesting is that the actual the details of the information that the butterfly
that the caterpillar learns are actually quite useless to the butterfly because it's going
to have to remap all of it onto a completely different body with different priorities.
It doesn't care about leaves anymore.
You know, it lives in three dimensional where like all of that has to get remapped.
And so immediately, I sort of I sort of realized that what's going on here is is
is what's preserved across lifetimes from from that caterpillar to that butterfly
is not the fidelity of the information.
It's the it's a kind of inferred salience.
It's it's what does this mean to me and that what's actually passed on physically
some sort of n-gram.
We don't know what it is.
It could be an RNA like the Glantzman says.
What's an n-gram?
Would you define that term for me?
Yeah, an n-gram is just a it's a it's a physical embodiment of a memory.
So so it's it's anything in your brain or body that stores information.
And all that means is that there is some observer later on, meaning a cell, a tissue,
the whole animal or or a scientist or somebody else who's going to then look at that physical
object and say, oh, look, I know what this means.
This is and they're going to interpret this as as as as a memory.
And so, you know, and ants is DNA and n-gram are not.
Yeah, I think so. Yeah, yeah, I think so.
But now now again, that that requires that requires a real shift.
I mean, think most biologists would say no, but I think it is because I think
that all memories are just messages from your past self and that what's happening
with DNA is that previous previous basically there's this giant lineage agent
that's the scale of an evolutionary lineage and the DNA are it's n-grams
where that information is being passed on the way that any memory would and much
like these other memories, it's up for interpretation, which is why you have
this this incredible flexibility of forms.
Yeah, you've got the same DNA, but if you're a salamander and I change
the number of cells or the size of cells or or do all this other crazy stuff,
you can still make things work because you don't interpret you take it seriously,
but not literally that information, right?
So yeah, so so going back to the butterfly.
Yes. Yeah, yeah.
So so the n-grams, right?
That that are left there are to be interpreted and that leads to this
this question of and again, the reason.
So get back to your original question.
Well, what does it mean for our lab work?
Because because what we would like to do is communicate with effectively
communicate with the different parts of the biology.
I mean, what we do is we communicate with cells, tissues and organs for
regenerative medicine applications.
Some people are going to want to communicate with ecosystems.
Somebody else is going to want to communicate with, you know, social
structures or or financial structures, I don't know what.
And so so we're interested in asking how does, you know, by understanding
how does a persistent agent, a self maintain itself over time?
You can learn something about how do we communicate with it?
So we would like to rewrite those memories and we would like to say if
there's a birth defect or there's some kind of traumatic injury or something
and we want the cells to build something else.
We really need to understand how these memories are interpreted.
So that's why yeah, that's that's that's why this this is of relevance to us.
So in the butterfly case.
Would you say there is a self that's continuous from from caterpillar to butterfly?
So so here's what I think we ought to do with this.
And this is by no means a new a new idea.
This is this is kind of just process philosophy and many made made
made more practical in many ways.
You know, there's a there's an old paradox and I'm trying to figure out
who first said it, I thought it was Bateson, but I could be wrong.
But but somebody had this paradox that said if a species fails to change,
then it will no doubt eventually go extinct.
If it does change, then again, it's not the same species.
And so again, it's gone. So what do you do? What do you do?
What's the right? What can you do? That's the paradox.
And that same paradox is it's it's it's it's the same thing with with us.
Because in a certain sense, if you if you insist on a definition
of the self that is a permanent structure, it's a thing, then you've got
the same paradox. Because if I mature, if I learn, if I expand,
if I, you know, any of those things, I'm no longer me.
And that's scary. And at some point, you know, is the child that you once
were still here? I mean, in many ways, no, right?
So that's a that's a problem.
But I think I think the answer both on the personal case and the evolutionary
case is that what we need to do is define the self as a continuous construction
of sense making. So it's a process.
It's not a single thing. It says so. So that part is a new plenty,
plenty of people have said that. But but I think the new thing is to
understand exactly what it's doing. What I think it's doing is constantly
trying to make sense of its own memories. So every and I don't know what
300 milliseconds out in a human, I don't know what it would be exactly.
But you don't have access to your past.
What you have access to is the ingrams left by your past.
You have the messages from your past self.
So this constant process of trying to make sense of what do my what do these
chemical messengers mean, if it's RNA or it's protein, whatever, synaptic
structures, whatever it's going to be, what do they mean?
Can I can I cobble together a coherent story of myself, my past,
my environment and be creative about it?
The thing the other thing that hit me that's I think really cool about this
is that we can talk later about this this bowtie business.
But but in any case, what's happening is you have you have a bunch of
experiences and you don't memorize the details.
You have to squeeze them down.
You have to compress them into some sort of inference, a generative,
you know, a model of everything that happened, right?
So when it when it comes time to to interpret this thing,
to recall the memory, because because it's compressed, you have to sort of
reinflate it and you have to make it make sense for your new environment.
Maybe you're physically you've changed or whatever you have to have to reinflate it.
But the thing is that good compression always looks like randomness, you know,
this is something that the SETI people point out that that a really advanced
signal is going to look maximally random because because when you compress
lots of particulars into a general rule, you the whole point of compression
is to throw out all the correlations.
Anything that's correlated, you can get rid of it because you can you know,
you can compress it out.
But once you've done all of that, what you have looks really random.
And so that means that on the interpretation end, when you look at these
molecules or synaptic structures or whatever it is, in order to figure out
what they mean, you can't deduce it in a deductive algorithm because the information
isn't there. It's been it's been stripped off.
You have to be creative.
It's it's more it's more creativity and, you know, maybe what people call intuition.
I don't know. But it's but it's much more about you.
You have to bring something to it.
You can't just read exactly what it says because it's sparse.
There's not there's very little there.
Why tell me exactly why do you have to compress?
You have to compress and with question or.
Well, because because if you don't compress all learning is about compression
because because if you don't compress, then what you've done is what the what
the machine science machine learning folks call over training.
You've you've you've memorized a bunch of particulars.
And if and if you're a very simple organism in a very simplified environment,
that might even be OK.
But but normally the whole point of learning is you learn a rule.
You don't remember there were these pixels on my retina,
then there were those pixels on my retina.
You don't remember that.
What you remember is this general thing leads to this other general thing, right?
You remember these these connections.
