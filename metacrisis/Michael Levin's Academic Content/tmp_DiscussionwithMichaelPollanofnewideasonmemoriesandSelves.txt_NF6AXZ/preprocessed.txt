So this is Mike Levin on Wednesday, May 8th.
From home, it looks like.
I'm at home today.
Yeah.
Me too.
Me too.
Well, I thought this Selb's piece was absolutely fascinating.
Just.
Oh, thank you.
Fireworks of ideas coming off it.
Just very rich.
So I'd love to ask you a few questions about it just to unpack it, and then we can make
it from there.
First of all, connect this thinking and this piece to your lab work.
What brought you to this?
These thoughts and what were you seeing that made you want to answer the questions you answer
in this piece?
Yeah.
Great question.
Let's see.
A couple of things.
First, I am really interested in information and how information is used by different
components of the living body.
So Josh Bongard and I have been developing this notion of polycomputing, which is this
idea that basically every subcomponent is hacking every other subcomponent in the sense
that it doesn't know or care what the original intent of the message was.
It's going to interpret it as best as it can, however it can.
When you say it, are you talking about organisms?
What are you talking about?
Well, every level.
So cells, subcellular protein networks, pathways, organs, tissues, antels, everything.
Right.
I think this is a fundamental feature of biology that it's a hacker in that sense that you
have no allegiance to how something was intended to be used.
You're going to do the best you can in interpreting.
And that comes from working with Josh Bongard with his discoveries that the exact same physical
mechanism can be seen by one observer to be computing one function and another observer
to be computing a different function.
So that when you ask, what is this physical process computing?
Somebody might say, well, I know what it is.
I wrote the algorithm so I can tell you what it is, but in biology, nobody cares who wrote
the algorithm.
Well, I don't care what you say, I'm interpreting your algorithm, your novel, your message in
my own way.
It doesn't matter to me what you think you meant by it.
Whatever I get out of it is what I get out of it.
So it starts with that and attempts to understand how different biological systems interpret
information.
And I was thinking, OK, so that's one thing.
The second thing is I really think that there's a lot of important work to be done to break
binary categories that we naively think exist, but actually are just hiding a lot of limits
on our imagination.
And so this notion of data versus the machine that operates on the data and this idea that
information is passive and then you have this active cognitive being whatever it is
that's going to operate on that data, remember it, store it, change it, whatever.
And so I was thinking about ways that we could break that and really make that into a continuum.
And I was thinking about the whole caterpillar butterfly thing.
And I thought about this for many, many years.
And originally, the thing you might think is cool about it is the question of where's
the information because the brain gets mostly refactored.
OK, but then it hit me.
I was I was literally I was taking a walk with my dad and it and I was thinking about this
and it hit me that that isn't the most interesting part here.
What's interesting is that the actual the details of the information that the butterfly
that the caterpillar learns are actually quite useless to the butterfly because it's going
to have to remap all of it onto a completely different body with different priorities.
It doesn't care about leaves anymore.
You know, it lives in three dimensional where like all of that has to get remapped.
And so immediately, I sort of I sort of realized that what's going on here is is
is what's preserved across lifetimes from from that caterpillar to that butterfly
is not the fidelity of the information.
It's the it's a kind of inferred salience.
It's it's what does this mean to me and that what's actually passed on physically
some sort of n-gram.
We don't know what it is.
It could be an RNA like the Glantzman says.
What's an n-gram?
Would you define that term for me?
Yeah, an n-gram is just a it's a it's a physical embodiment of a memory.
So so it's it's anything in your brain or body that stores information.
And all that means is that there is some observer later on, meaning a cell, a tissue,
the whole animal or or a scientist or somebody else who's going to then look at that physical
object and say, oh, look, I know what this means.
This is and they're going to interpret this as as as as a memory.
And so, you know, and ants is DNA and n-gram are not.
Yeah, I think so. Yeah, yeah, I think so.
But now now again, that that requires that requires a real shift.
I mean, think most biologists would say no, but I think it is because I think
that all memories are just messages from your past self and that what's happening
with DNA is that previous previous basically there's this giant lineage agent
that's the scale of an evolutionary lineage and the DNA are it's n-grams
where that information is being passed on the way that any memory would and much
like these other memories, it's up for interpretation, which is why you have
this this incredible flexibility of forms.
Yeah, you've got the same DNA, but if you're a salamander and I change
the number of cells or the size of cells or or do all this other crazy stuff,
you can still make things work because you don't interpret you take it seriously,
but not literally that information, right?
So yeah, so so going back to the butterfly.
Yes. Yeah, yeah.
So so the n-grams, right?
That that are left there are to be interpreted and that leads to this
this question of and again, the reason.
So get back to your original question.
Well, what does it mean for our lab work?
Because because what we would like to do is communicate with effectively
communicate with the different parts of the biology.
I mean, what we do is we communicate with cells, tissues and organs for
regenerative medicine applications.
Some people are going to want to communicate with ecosystems.
Somebody else is going to want to communicate with, you know, social
structures or or financial structures, I don't know what.
And so so we're interested in asking how does, you know, by understanding
how does a persistent agent, a self maintain itself over time?
You can learn something about how do we communicate with it?
So we would like to rewrite those memories and we would like to say if
there's a birth defect or there's some kind of traumatic injury or something
and we want the cells to build something else.
We really need to understand how these memories are interpreted.
So that's why yeah, that's that's that's why this this is of relevance to us.
So in the butterfly case.
Would you say there is a self that's continuous from from caterpillar to butterfly?
So so here's what I think we ought to do with this.
And this is by no means a new a new idea.
This is this is kind of just process philosophy and many made made
made more practical in many ways.
You know, there's a there's an old paradox and I'm trying to figure out
who first said it, I thought it was Bateson, but I could be wrong.
But but somebody had this paradox that said if a species fails to change,
then it will no doubt eventually go extinct.
If it does change, then again, it's not the same species.
And so again, it's gone. So what do you do? What do you do?
What's the right? What can you do? That's the paradox.
And that same paradox is it's it's it's it's the same thing with with us.
Because in a certain sense, if you if you insist on a definition
of the self that is a permanent structure, it's a thing, then you've got
the same paradox. Because if I mature, if I learn, if I expand,
if I, you know, any of those things, I'm no longer me.
And that's scary. And at some point, you know, is the child that you once
were still here? I mean, in many ways, no, right?
So that's a that's a problem.
But I think I think the answer both on the personal case and the evolutionary
case is that what we need to do is define the self as a continuous construction
of sense making. So it's a process.
It's not a single thing. It says so. So that part is a new plenty,
plenty of people have said that. But but I think the new thing is to
understand exactly what it's doing. What I think it's doing is constantly
trying to make sense of its own memories. So every and I don't know what
300 milliseconds out in a human, I don't know what it would be exactly.
But you don't have access to your past.
What you have access to is the ingrams left by your past.
You have the messages from your past self.
So this constant process of trying to make sense of what do my what do these
chemical messengers mean, if it's RNA or it's protein, whatever, synaptic
structures, whatever it's going to be, what do they mean?
Can I can I cobble together a coherent story of myself, my past,
my environment and be creative about it?
The thing the other thing that hit me that's I think really cool about this
is that we can talk later about this this bowtie business.
But but in any case, what's happening is you have you have a bunch of
experiences and you don't memorize the details.
You have to squeeze them down.
You have to compress them into some sort of inference, a generative,
you know, a model of everything that happened, right?
So when it when it comes time to to interpret this thing,
to recall the memory, because because it's compressed, you have to sort of
reinflate it and you have to make it make sense for your new environment.
Maybe you're physically you've changed or whatever you have to have to reinflate it.
But the thing is that good compression always looks like randomness, you know,
this is something that the SETI people point out that that a really advanced
signal is going to look maximally random because because when you compress
lots of particulars into a general rule, you the whole point of compression
is to throw out all the correlations.
Anything that's correlated, you can get rid of it because you can you know,
you can compress it out.
But once you've done all of that, what you have looks really random.
And so that means that on the interpretation end, when you look at these
molecules or synaptic structures or whatever it is, in order to figure out
what they mean, you can't deduce it in a deductive algorithm because the information
isn't there. It's been it's been stripped off.
You have to be creative.
It's it's more it's more creativity and, you know, maybe what people call intuition.
I don't know. But it's but it's much more about you.
You have to bring something to it.
You can't just read exactly what it says because it's sparse.
There's not there's very little there.
Why tell me exactly why do you have to compress?
You have to compress and with question or.
Well, because because if you don't compress all learning is about compression
because because if you don't compress, then what you've done is what the what
the machine science machine learning folks call over training.
You've you've you've memorized a bunch of particulars.
And if and if you're a very simple organism in a very simplified environment,
that might even be OK.
But but normally the whole point of learning is you learn a rule.
You don't remember there were these pixels on my retina,
then there were those pixels on my retina.
You don't remember that.
What you remember is this general thing leads to this other general thing, right?
You remember these these connections.
So you're abstracting exactly.
That's what it is. It's generalization and abstraction.
That's exactly. And that seems to me what's happened in the caterpillar
butterfly case, right? I mean, so in the experiment that you described,
it wasn't I realized it wasn't yours, though, was somebody else's experiment.
Yeah, it's not it's not my experiment.
It was done. It was first done in the 70s by a bunch of Russian groups
who did larvae to beetle and things like that.
And then it was done by Doug Blackiston,
who is actually a staff scientist in my center.
But but he did this work when he was younger.
And yeah, he did it with moth caterpillar to moths.
And he did it.
There was some training, some operant conditioning going on, right?
To associate food with a certain color.
Yep.
And so the abstraction there or the results of the compression was concept
food, right, rather than specific leaf or nectar.
Well, it's too thick. Right.
It's too. It's actually multiple things because, A, it's yes,
we're not remembering leaves because butterflies don't care about leaves.
But also what do you do because because
the caterpillar is a soft body creature and the way you move a soft body,
you don't have any hard elements to push on.
So you can't do robotics the same way.
You can't do controlling the same way.
So there is a certain set of muscular motions that you need to do
to make your way over to where the where the leaves are.
That isn't going to help the butterfly.
The butterfly doesn't move like that.
It's got a completely different architecture.
And and so so the the the abstraction there is from from from leaves to food
or maybe even we don't know, it might even just be to pleasure or something.
You know, just just positive affectors, you know, who knows, right?
Um, but also but also how do we make use of that
associative learning that this color leads to food or to, you know,
to pleasure or whatever?
How do we remap that on a completely different controller?
And you see this even in vertebrates like like this is and actually this was
Doug's Doug's work, too, is we can make tadpoles with eyes on their tails
and they can see perfectly well.
And so it's like, isn't that amazing that with no extra evolutionary cycles,
no, no adaptation out of the box.
This this thing that for millions of years at the exact, you know,
the brain could rely on getting connection from the visual system
into the optic tectum and all that suddenly it's on your tail.
No problem.
It connects to the spinal cord and you can connect to the brain as it makes it work.
So what's happened there?
Do you think how do you think that what's been remapped?
What's been remembered and forgotten?
I think that all of these and there's tons of these examples
that I go through in various papers is the reason that.
Life is so tolerant to these crazy kind of changes is that it fundamentally
assumes the material is unreliable.
In other words, unlike all of our computer information, the information,
the substrate, it assumes that the substrate is unreliable.
Because look, this is how we build our computer technology.
You make the bottom layer as absolutely rock solid as you possibly can.
So that all of the stuff on top of it can assume that everything
is going to go well at the bottom.
You know, when you write code, you don't think your your your transistors
are going to burn out.
You don't worry about that.
And so so the goal is to change the to to to keep the information from changing.
And this is why actually that whole business of these microchips, right?
How small can you make a microchip?
It's because you don't want the bits floating when they get too close to each
other, they start to fluctuate, you know, the quantum effects start to fluctuate.
You don't want that.
You want every you want all the bits to be exactly what they were before.
You want fidelity of the information.
Biology can't we can't operate that way because everything is going to change.
So on a small time scale, your proteins are going to degrade,
your cells are going to die and be replaced on a larger scale.
You're going to be mutated, right?
Evolution, you know, guaranteed you're going to be mutated and things will things
will change, not just environment, but also your own parts.
So I think that there may be exceptions.
There may be organisms that aren't like that, although I doubt it.
I think at this point, what what survived and what what biology
strongly emphasizes is architectures where you assume the underlying material
is unreliable and what you're going to do is on the fly.
You don't over train on your priors.
You don't assume that the future is going to be like the past.
You don't assume you know what any of your information means.
You are going to try to reinterpret it at the at any given moment on the fly
and do the best you can.
And so that gives rise to these kinds of systems where the eyes in the wrong place.
Well, we can we can do something with that basically, right?
I mean, the detail is it is it's it's hard work to figure out.
OK, so where is the information actually going?
You know, it gets on to the spinal cord, then the brain learns to infer
some connection between what the eye says and what does it even know?
It's an eye. Well, I'm not even sure about that.
So but I but I think that's what's happening here is that
biology commits to a real time sense making process, not to the expectations
of the past, you know, I think I think that's the most interesting part.
And that's what makes the stuff so flexible.
And that's what makes biotechnology possible.
It makes, you know, I'll take my cells and slap them onto some weird
scaffold made out of crazy nanomaterials.
And I'll instrumentize it with electrical signaling and optical, whatever.
And things work because, you know.
So the so the the butterfly has solved this problem of how can I change
and and still can I change and still exist?
Which I think I think we all do.
I think I mean, the butterfly is kind of an egregious case.
But but all of us have the same problem because over time, we are not the same.
And, you know, whether it be the rearrangements of puberty or just the,
you know, the day to day wear and tear on the body, you know, the the whole
ship of thesius thing, right?
And where where your materials are going in and out all the time.
I think, you know, I think I think different species
emphasize this to different extent, for example, plenaria are the champions of this.
We look plenaria, right?
Cancer resistant, incredibly regenerative,
no aging in the asexual forms, no transgenic lines
because they basically ignore new DNA that you put into them.
There are no transgenic.
Yeah, there's no for people have been trying this since I think since the late
eighties, people have been trying to make transgenic plenaria.
There aren't no no mutant lines.
The only the only lines of aberrant plenaria that exist
are our two-headed form and the cryptic form, and they're not genetic.
It's because the only reason it works is because it's not genetic.
What happened in in plenaria, I think, is that
they because because they're they reproduce asexually.
So they, you know, tear themselves in half and regenerate.
That means that they accumulate somatic mutations.
They don't clean the genome the way that that we do with sexual reproduction.
And so they've accumulated so much junk that basically
the only way to to have a proper plenarian is to assume the hardware
is is going to be unreliable and to put all of the effort.
And we've done computational models of this actually.
And you can see evolution doing this when when you get even a little bit of
regulative competency where the creature where the creature can make up
for certain subtle defects immediately.
Evolution, it's hard for selection to now see the genomes, right?
Because if you get an animal that looks pretty good,
you look pretty good because your genome was great or because you actually
terrible, but you know, you fixed it along the way, right?
And so this is like the stuff that we see when we make tackles
with the with the scrambled faces and they see them, they fix them, right?
So so what happens is that then when evolution has a hard time
selecting for good genomes, all the effort goes into selecting
for more competency, which in turn makes it harder to see the genome,
which in turn makes for more kind.
And so you get this, you get this thing where the pressure on the genome
actually flattens out, but the pressure on the competency keeps rising.
And so if you take that all the way, you end up with planaria that basically
everything went into making an algorithm, which is partially bioelectric
and who knows what else that basically says, I already know my hardware,
it can't really be trusted.
Here are all the error correcting codes and everything else that we need
to do to build a good planarian, no matter what happens.
And then of course you're insensitive to trans genes to, you know,
to cancer, all these things, because you're assuming from day one
that all that stuff can't be trusted.
Right, right.
You know, and I think, you know, I think, I think so planaria are kind
of all the way there and then salamanders are pretty good at it,
but not as good as planaria and then the mammals and then maybe something
like C. elegans or Drosophila are on the opposite end and they're just really
pretty, you know, pretty hardwired, maybe.
So you're when you your definition of self, how far down the evolutionary
ladder does it go?
I mean, does it go to single celled creatures?
Are they selves or does it go or does it begin at a certain point in
evolution, the self as an innovation to, to deal with these problems you're
talking about?
Yeah.
Um, I don't, I don't like binary categories for any of these things
because they end up chasing us into these pseudo problems where you can
always come up with these sort of in between cases and then you spend all
your time trying to prop up this binary definition as opposed to, I think,
I think what's what all binary here between having a self and not having
a self.
Correct.
Yeah.
Yeah, exactly.
I think it's on a continuum.
I think all of it will, yes, I think it's on a continuum, but, but the
reason it's on a continuum is that I take all of these terms.
So all of this, you know, having a self intelligent sentient, you know,
cognitive, like all the whatever of these terms you want to use.
I don't think they're about the system itself.
I think what they refer to is your intended interaction with it.
So if you tell me that you think a certain system as an observer, as a
scientist, as a, okay, as, as, as a scientist, as a, as a conspecific, as a
parasite, as a, you know, whatever, whatever, it's, it's every, every agent
with living non-living scientific, you know, natural, whatever, you are going
to take some stance towards whatever you want to interact with.
And if you want to take a mechanical stance and say, all I see is a bunch
of cogs and gears, I'm, you know, my, the tools I have to interact with
you are just hardware rewiring.
Well, you know, that works well for mechanical clocks and things like that.
You try to apply it to a human.
If you're an orthopedic surgeon, not bad.
If you're a psychotherapist, terrible, right?
So, you know, you want, you want to, or, or, or a spouse, you know, terrible.
You want an orthopedic surgeon that thinks you're a mechanical machine.
You do not want to spouse or, or a psychotherapist that thinks you're a
mechanical machine.
So I think all of these things, I think all of these things just, just
indicate the frame that you bring to the interaction and the set of tools
you're going to use.
And so you've got, you know, you got your rewiring, you've got cybernetics, control
theory, you know, behaviorism, you've got, I don't know, psychoanalysis, spirituality,
who know, like I'm just, you know, sort of drawing the, the spectrum, right?
So, so how far down does it go?
So, so, so what that means is, can we get some sort of utility?
And that's why I harp on the engineering side of this, because I think this
should all be tested by, by utility in the, in the real world.
So, so can we get some sort of utility by applying these concepts to single cells?
Absolutely.
I think yes.
Can we apply them to molecular networks?
Yes, within cells, I think so.
We have, we have data on this.
Other people have data on this.
Could we apply them to particles?
Maybe.
So I think Chris Fields and Carl Friston and some other people have done some
really nice work trying to cash out physics as a kind of
proto-cognitive substrate, like active, I mean, they like active inference.
There may be some other things.
So maybe.
So I was going to ask you, too, if you thought this was limited to the realm of biology.
I realize Friston doesn't.
Yeah.
But I don't know.
He doesn't, his, his work makes it better.
Seems to all perform better when you transpose it to the realm of biology.
Then when he starts talking about active inference and rocks and crystals and things,
but I don't see the active piece.
Well, so, okay.
I, you know, I couldn't possibly reproduce the argument the way that he does it.
But, but I think, I think what he's saying is that, and Chris Fields has stories about this,
too, which is basically that there's an equivalency between what is a thing?
You know, what is a rock?
What is a, right?
What the, I mean, I think that's a very important part of the research program.
And this idea that there's the active inference is quite symmetrical when you're
doing something to the environment, the environment is also learning about you and so on.
And I think the claim there is that there is a very simple version of this that just
basically looks like physics to us.
But if you sort of crank up the, the, the relevant parameters, then you end up with
things we call life.
So, so, so here's, here's what I would say about that.
I think when we say biological world, what do we really mean, right?
What, what, what's life?
I think that what we mean by life is anything that is good at scaling up the cognitive
light cone.
That is anything that where the whole has a larger is capable of pursuing larger and
more complex goals than the parts.
That's what we happen to call life.
So, so we don't do that for rocks because the rock has exactly the same cognitive
light cone as the pieces that could go inside the rock.
It hasn't scaled anything.
It's just exactly the same.
It's not more than the sum of its parts in that particular way.
Right.
So, so some people would do it, you know, to know, you would do it off of integrated
information, different people do it different ways.
I think it's all about goal directedness.
And right.
I think it doesn't, it doesn't, you know, you're not going to find larger goals that
help you deal with the rock.
It's basically the same.
It follows least action principle.
That's about all you're going to get out of it.
Right.
So, right.
So, so I think, you know, I think biology is what we roughly call things that are good
at it.
And that, again, is a continuum.
I think we don't need to spend any time arguing whether something is alive or not.
The real question is, so what's, so, so what's your model?
What, what goals do you think this follows?
And how does that help you have a richer interaction with the system?
And what tools can you bring from, from active inference from behavior science?
And then so on.
I mean, look, one, one example.
Okay.
One, one recent example is we showed models of gene regulatory networks, which are just
chemicals.
You can, there might as well be a rocket just to, you know, six or seven chemicals interacting
with each other.
And what we showed is that if you bring tools from, from behavior theory, meaning,
meaning different kinds of learning.
So, associate of conditioning, habituation, sensitization, you can do some really
interesting things with just, with those networks that have lots of biomedical relevance.
And, and, and, you know, it's already there.
You don't, you don't need a cell.
You don't need any, you know, you don't need protoplasma.
You don't need any of that.
Just, just the mathematics of having a few nodes connected by these differential equations
already give you a bunch of stuff that we would call learning.
And that help you, you know, and, and again, my goal, right, remember, you know, my goal
is not to, to do poetry and to sort of paint hopes and dreams onto these things.
And, and, you know, that we could never agree on.
I make a very clear claim that if you know these things,
you will do better in the biomedical arena than if you pretend they don't exist.
And that's, that's a, you know, that's not a philosophical claim.
That's a, that's an empirical claim that we can, you know, that we test.
You mean as a scientist or as a creature?
No, as a, well, both.
So, so first thing is, so, so mostly what I talk about in public is the science, right?
So, so I say as a worker in regenerative medicine, as somebody who wants to discover
new ways to use drugs, you will do better if you are able to use the tools of behavioral
cognitive science on your cells and tissues than somebody who doesn't.
That's, that's the first claim, but you could, you could push it forward and say,
you know, in our personal, and, and I mean, I have no credentials to be,
you know, talking about interpersonal, you know, social stuff.
But, but, but overall, it seems perfectly reasonable to me that we could apply the same
reasoning and say the way that the same pragmatic reasoning to our relationships and say the way
I pick frames for interacting with others is to see how well they work out for me.
So it purely empirically, so, so if I treat you as, as a, you know, as an advanced
metacognitive being, we can have a certain kind of relationship and that elevates me in a certain way.
If I do something else, maybe that doesn't work out as well.
If I take one of the lower, you know, kind of lower framings.
So again, just, just, and it's a way to test.
It's a way to test the environment too, right?
You, we're going to go in on the assumption that this is a cognitive being and we'll see what happens.
And we'll see what happens.
I mean, that's the, you know, you can, you can go the other way.
You can say, you can start and say, okay, I'm going to go on the assumption that it's not
and see what the limitations are.
I mean, I prefer the former, but, but, but as long as, as long as everybody's in agreement that
this is an empirical undertaking, this is not, we can't, we can't just have feelings about this.
And this is not something that we're, you know, we're going to argue about for the next
thousand years and never get anywhere.
No, this, this is getting resolved because, you know, there's, there's clear data on a human scale.
Of course, it takes longer, right?
So it takes maybe years for someone to say, you know what, my framing isn't working out for me.
It's, I'm going to try something different, right?
That, that, that may take many years, but.
Right.
That's kind of what's happening in the whole field of plant intelligence that people are like,
let's, let's, let's see what happens if we assume they are cognitive or they have intelligence.
And some, and some, you know, some people show that they can learn.
Some people show they can't.
So taking selves to the, the, the human dimension, which I've been looking at for this chapter I'm
working on, I've been talking to neuroscientists and, you know, people like Anil Seth, who's
written about selves.
One of the things that's curious is, especially in light of what you've proposed in this piece,
is we're very invested in the idea of the unchanging self.
And it's curious, we don't embrace the idea that this is a completely fungible,
you know, subject to our remaking and our creativity.
Why do you think we're invested in the idea?
It's, it's very hard to conceive of it.
I mean, in the definition of self is some continuity, right?
Why do you think we're so invested in, in the idea of a stable continuous self, which,
you know, we're being told by a lot of different discourses is not true.
I, yeah, I don't know.
I think, you know, I can, I can make some hypotheses.
I suspect that it's, it's firmware left over from our evolutionary past, because
if, if you were not
sort of wired to expect object permanence in the outside world, right?
The, you know, babies acquired very quickly and that they have someone they're born.
If, if, if you don't, if, if, if you're not good at seeking out object permanence,
and if you're not committed to persistence of your local self,
I suspect that on the Savannah and whatever the previous versions that are,
I suspect that doesn't play out very well.
You know, it's, it's not very good to say, go ahead and eat me lion.
You know, my, my patterns will continue in the universe in another form.
Like, great.
But, but, but my future self will be undisturbed.
My future self, yeah, I have, I have much bigger, you know, bigger thoughts than this.
I suppose that doesn't work out too well, right?
So, so I can see why, why evolution left us with some firmware that tries to kind of
dumb it down to this very like basic survival for the same.
And I think, I think that, that firmware has a bunch of other stuff that needs to be
jettisoned, which is, which is hard.
For example, I think a lot of the issues around, you know, one reason people don't
like this kind of work, right?
This kind of a diverse intelligence work is that they worry about false positives.
They worry about too many things being considered as if they were cognitive.
And I mean, clearly you can, you can make mistakes in that, in that realm.
And we have people that are in love with bridges and married to the Eiffel Tower
and stuff like this, right?
You can do that.
I mean, that does happen.
But I think what fundamentally drives this is a real deep seated fear and a,
an assumption that there's not enough love to go around literally like, like,
like that there is a, it's a zero sum game in terms of intelligence.
And that if we consider other things to be, to be cognitive in some way, well,
then mine isn't worth as much, you know.
And, and again, I think that's like ancient scarcity mentality,
firmware from evolution that says, no, there isn't enough of anything to go around.
And there's status and it's a zero sum game.
And if you don't have the status in your group, you know, you're screwed.
And so that's where I think some of this is coming from.
But this is all, you know, that's, that's armchair, you know, armchair of
psychologizing.
I don't know.
Yeah.
Yeah.
Of course, the other reason, I mean, there are, there are variables you want to keep
steady, right?
And one of the things the self does is help us with homeostasis, right?
I mean, if you, if you use the model that Seth talks about or some other people,
um, that we're processed, we're always processing signals from our body and
we're looking not to depart from certain, um, you know, temperature, blood gases.
I mean, there's a whole range of things that we do want to stay in a very narrow range.
Well, yes.
And I think that's the part of this firmware that I'm talking about.
However, um, you know, from the perspective of the child's body, the adult's body is
way off on homeostatic, uh, you know, homeostatic properties, um, from the
perspective of the caterpillar, the butterfly, you know, the butterfly is a terrible
caterpillar, like everything is off, you know, all of the, all of the, and I think
this is true in embryonic development, you know, from the, from, from the
perspective of the, of the, um, you know, gastrolyte, the blastula is a birth defect.
In fact, I think, I actually think that's how development works is a, it's a set of
repairs activated towards a fast moving target morphology, which is encoded in
bioelectrics and various other things that basically what happens is, you know, you're,
you're, and we've done, we've done work on this.
This is going to come out later, later this year.
We have some super, super cool data around this stuff that, but basically development
is a whole bunch of repairs.
I'm not even sure I believe in embryonic development anymore.
I think it's all regeneration.
I think it's all repair that basically what happens is your target is, your target
moves faster than the anatomy is trying to catch up.
So the target information is here.
The anatomy says, oh my God, I'm all wrong.
And so all these repair processes kick in and you make the metamorphosis.
By the time you've done that, guess what?
The pattern has moved on again and, and you're wrong again.
So again, you have to change, right?
So it's a set of repairs.
So you just keep going from stage to stage.
And so you catch up and that's adulthood needs sort of, you know,
maturity and then you sort of catch up.
And then, and then you get a different issue with aging.
But, but, but, you know, keeping steady.
Yes.
But everything is transformation, at least, at least until you hit aging,
everything is supposedly a positive transformation, right?
You're trying to, you know, change into whatever your next form is supposed to be.
Do you think, and I'm asking you to speculate again,
there are advantages to giving up on this idea of a stable self?
I think so.
I think, I think there are major advantages.
Well, let's see.
One advantage is that I think that it actually has implications for, for ethics of behavior.
Because if, if you can, if you, if you can sever that sort of hard wired link between
your current self and your future self, then one of the things that happens quite naturally
is you start to think about other beings' future selves as having similar status.
So, so normally you can be selfish into the future in the sense that, well, that's still
going to be me.
But if you can understand that future self isn't quite the same as your current self anyway,
then you say, well, for the same reasons I care about this future self,
for exactly the same reason, I ought to be caring about other creatures that really exist.
Future selves, right?
Because, because, because your future self and all the hard work you're doing to prop
up your future self in many ways is not as tightly connected to your current self as we think.
And I think breaking that a little bit would be helpful because then it would make it,
it would make it, it would make it seem much more rational to then be, be compassionate to others.
You know, right now, right now, it's very natural to invest everything in your future
self. But once you realize that, you know, your, your, your future, your future self is,
is a different being in many ways.
And it's like, there are, there are a number of crazy ways to,
okay, like, like weird intuition pumps around this stuff.
Like, like, here's, here's, here's a few examples.
One thing that people think about, and I think this was maybe Anthony Flu's argument
about reincarnation, he said, okay, if I don't remember, if I'm not going to remember the current
life, then what's the difference it might, you might as well just tell me that I'll be dead
and some other kid will be running around somewhere on earth and like, good, but there's
plenty of kids running around on earth, what do I care?
And so, so he was trying to say that, that memory is, is what keeps it going, right?
And the continuity of memory is what keeps it going.
But you can imagine things, things like this, if somebody says to your current self,
we're gonna, you need some surgery and you could save some bucks if you, if you instead,
instead of having real anesthesia, which you just have as a paralytic.
So you'll be paralyzed, we can do our thing.
And in fact, I mean, that's a real, like that actually happens to people, right?
That like, it doesn't always work, right?
So, so, so then you can save, you can save some bucks.
The current self is going to go, well, absolutely not.
But, but, but, but the future self, once you come out of it, and they say, oh, by the way,
oh, and the other thing to know is that when you do get the anesthesia part of the components
is a memory wipe, that's a short term memory wipe.
That's also a real thing, right?
Because they don't want to remembering this stuff.
So, so, so you come out of it and somebody says to you, you know what, I think that actually
happened. And, and, you know, when you saved $1,000, but I think you were actually there.
I know you don't remember a bit of it.
But, you know, and at that point, like, all right, I mean, you know,
now, now, realistically, it's an issue because actually the trauma can, can carry forward.
But let's just, let's just imagine that, you know, let's imagine the memory wipe actually works.
The future self of like, yeah, I mean, fine, good deal, right?
So, so there's an interest, so there's an interesting thing here.
And I think to the extent that we kind of understand that our future self
is, is a construction that is going to sort of try to make sense of these memories and whatever,
I think it helps you be, be kinder to others, future selves, because they're in the same boat.
So I think for that, because I think for that reason, it's useful.
I mean, it's also useful more broadly, because to the extent that we understand what we are
and how we, how the biology works and everything, I think it really helps us have a more ethical
relationship with other, other beings. Because right now, a lot of people are walking around
with this very magical view of what, you know, they, they say, the humans, you know, humans do
this and they say, well, which humans, you know, the, the, you know, for a hundred thousand years
ago, you know, a million years ago, like, which, which humans, right? And or during embryogenesis,
where does this magic sort of kick in? So, so I think having a better understanding of the biology
and what's actually going on is going to help us understand that, gee, there can be other minds
that are not the, you know, the conventional modern human, you know, mind and, and help us,
help us have better relationships with other systems, both, both biological and also synthetic,
you know, artificial, all that kind of stuff. Yeah. I mean, it would probably make us better
people. But on the other hand, this idea of the future self being continuous, that's what gets
your work done, right? I mean, this is going to, I'm embarking, I'm writing a book, it's going to
take me X years. It's going to be really hard, painful. But my future self is going to benefit
when it comes out, you know, when I get my advance, whatever it is. It seems to me there's a,
there is some adaptive value. And I mean, as you were pointing out on the Savannah of having a strong
sense of self continuity, even though that might make you a, you know, an asshole.
Yeah. Yeah. No, no, I think, I mean, it's, it's true. There probably is some competitive
survival value to it. I think that, you know, if, okay, I think back to some things I've done in
the past, some, some, let's, you know, so much, let's say some achievements that I've done in the
past. Yeah. I, I, and maybe it's just me, I have a, I find it really hard to, to visualize that
that was me, like really, like, I know, I know historically, like, if I look in the record,
everybody says it was me and everything. So I know it's me. But, but, but thinking back, I'm
like, wow, that's, you know, that's amazing. I don't remember what it was like. I don't really,
you know, it was years ago. So I don't really remember what it was like to do it. And the
feeling between me having done it and somebody else having done it is just a historical record
at this point, just a matter of historical record. You know, I did things before that I
probably couldn't do now. So what does that mean? Do I still keep the credit for it? It's, you know,
in, in, it's just, it helps society to maintain records and to write and to reinforce these
things. But, but really, you know, it's sort of like, it's been a long time. Like, do I really,
you know, do I, is it still me that did that? And I don't know, because I don't think I could do it
again. You know, that, that kind of stuff. So that's so interesting. I mean, to embrace this
idea of selfishness is constructing a creative act based on interpretation and misinterpretation
of memories. It's, I mean, it's a very exhilarating idea, I think, in many ways, in that people are
very stuck on either the positive case for selves, which is a myth, or the case against them, which
is just demystification without any sort of positive benefit.
There's, you know, there's an, there's an even, well, you just, just to put on the radar in case,
in case you want to talk about it. There's an even weirder, if you think all of that was weird,
the bit that I only mentioned in that paper that we could talk about is erasing the distinction
between thoughts and thinkers, because that I think, that I think is even, even more of a, of a
profound sort of trash talk, unpack that a little, because you kind of raced over that idea. And
I think it's really interesting. I mean, I was actually asking this question, I was talking to
Anil, and I was saying, can you have a perception without a perceiver or an inference without an
inferrer? And he was saying, yes, you can. But I had a lot of trouble getting my head around that.
Yeah, yeah, let's, so let's, and so, okay, so, so just to kind of fair, fair warning, these, these
ideas are pretty new. So I'm still kind of chewing all this around. So, you know, to take
everything with a grain of salt. But let's, let's, I'll start, I'll start with a little story,
just a short, this, this is a real science fiction story that I read years ago, and only now I'm
sort of understanding the significance of it. And I wish I could remember who's it was. I don't,
I don't remember. The deal is that down the drain. Yeah, exactly, right? Like I knew at one point,
I don't know. These, these creatures come out of the center of the earth, they're, they're,
they're incredibly dense. Yeah, they come out of the core, they're just incredibly dense, they use
gamma rays for vision, like super dense. So they come up here, and everything that you and I see
here is solid, it's just gas to them. You know, they see, they see because, because they're so dense,
as far as they're concerned, the crust and everything up, everything up here is, is a very
rarefied kind of plasma around, right? And so, and so one of them is, so they have some two,
one of them is a scientist, and he's got some tools, and he says to the others, as you know,
I've been watching this gas that surrounds this planet. And there are some, there's some patterns
in this gas. There's some, there's some persistent patterns in this gas, and they look like they're
doing things. They, they look kind of a gentile. And so the other one, the others of course laugh at
them. And, and they say, no, no, look, we're real, you know, we are actual thinkers, you can patterns
can't be thinkers, the patterns in gas can't be thinkers. And he says, no, I, I'm pretty, like,
it looks like they're doing things. And I've done some experiments, you know, when they look like
they have certain cognitive properties. And, and then they ask, well, how long these patterns last?
Well, they only last about 100 years. Well, that's ridiculous. I mean, 100 years, what could, you
know, what could happen, you know, we live millions of years, what could happen in 100 years, right?
So, okay, so, so, so right away, and you can sort of take this, this further, you right away,
you start to get the idea that the distinction between a temporary but somewhat persistent
pattern and excitable medium, and a real solid thing that we, you know, this is a thing, you
know, this is the cognizer, that's a bit of that's in the eye of the beholder quite a bit.
And people who study metabolic will already say that, of course, we're temporary metabolic patterns
that exist in of there's flux that is sort of self, you know, people who study, you know,
kind of these these emergent self, self-reinforcing energy patterns, right? That's, that's how they
would describe us anyway. So, okay, so, so once you start thinking about that, then you can start
asking about further about the distinction between thoughts as patterns within a cognitive system.
And what does it take to spawn off to have thoughts? What does it mean to have thoughts?
So once you go down that road, you start to think about imagine this continuum. So here's a here's
a continuum. Fleeting thoughts. So these are patterns that come in and they're gone, right?
Persistent intrusive thoughts. So these are thoughts that once you've had them,
they are hard to get rid of. And not only are they hard to get rid of, they do a bit of niche
construction. I'm sure you know all about this is certain kinds of thoughts actually change
the brain to make it easier to keep having those thoughts, right? So, so they're doing a little
bit of niche construction, they're, they're, they're modifying their environment to allow
themselves to persist and multiply and things like that. You go from there and there's, there's
some kind of exotic intermediates, but the next thing we for sure know about is multiple personality
alters. So, so it's not just a single thought that hangs around, it's like a, it's like a bundle of
thoughts that has some dynamics to it and can actually, you know, do some stuff. And then, and then,
of course, there are, you know, things that we call full blown personalities, which are like
really consistent, at least for some period of time, they're consistent sets of thoughts.
So, so the thing about the right side of that continuum is that these are, they've done two
things. One is they've closed the loop in that they reinforce themselves. So they, right, they,
they, they, they, they prop themselves up over time. But the other thing is that they can spawn
off other thoughts. So by the time you get to a, to an altar, you've got a, you've got a cognitive
pattern that's complex enough that can spawn off other simpler patterns.
And so now, now you try to draw a distinction between the thought and the thinker, and it's
real hard now, because, because, okay, all we're talking about is cognitive patterns. And some
of these patterns are, you know, in the language of dissipative systems, right? Some of them are
just, you know, fleeting. Some of them are self perpetuating, like the red spotted Jupiter and
things like this, they sort of keep themselves going. And other patterns,
spawn off smaller patterns, and other patterns hang around for a hundred years, and we give them
names and we, you know, but don't they need the, I mean, but as you suggested, they need the host
of brains, right? I don't think they, well, so, okay, so this is like very speculative stuff,
right? So, so here we go. First of all, I definitely don't think they need brains,
because these kinds of things go on in all sorts of media. So they go on in, in protoplasm,
and nor in cells, in, in, I think, I think there's lots of, lots of media that they can.
They're different substrates, not necessarily just brains. Exactly. Lots of different. Well,
we call the substrate living, because it's a substrate that is capable of hosting
self-reinforcing, goal driven patterns, patterns that have agendas. That's what we call living.
But, but I think you could have, and I'm sure in the, out there in the universe, I'm going to guess
there's all kinds of substrates that are capable of that. I think we're going to end up making a
whole bunch with, with different, you know, both software and material science that people are
working on. I don't think there's anything special about brains per se with, for that aspect. But,
but here's the, here's the craziest thing, and this is just the latest thing I thought of,
that I have, I have zero kind of details to back this up, but I'll just throw this out as a, as a
crazy thing. You know, at the, at the beginning of the 1900s, it was thought that self-perpetuating
electromagnetic waves, so a pattern that perpetuates for long periods of time, required a material to
be waving. You needed, you needed an ether that you could say was something was waving in order
to have a wave. Right. We did, we did away with all that. We don't, you can have a pattern propagating
with nothing waving. You don't need a material. You got rid of the luminiferous ether because,
because you found out that the two components, the magnetic and the electric component, you know,
they, they can, they can sort of reinforce each other and this thing sort of, sort of propagates.
So I wonder, and again, I'm not saying I believe this, I'm just saying this is something I'm toying
with at the moment. I wonder if you could make a move like that, you could get rid of this cognitive
ferrous ether, aka brains or whatever else, and you could have patterns that are actually self-reinforcing
in the absence of all of that. I don't know what specifically what physical model you would have.
I think we need to think more about this. It doesn't seem like you need a physical model.
Correct. The reason, correct. The reason you, well, the first thing that'll happen is people
say, we'll say this is dualism and fair, idealism actually, or idealism. Yeah, fair enough. I, you
know, I think that's true. And I think some of the stuff we talked about before about the practicalities
of Platonic space and those, the patterns that are there, like, I think this is in that same,
in that same vein. And I think yes, those things are not physical. And I think the real in the
sense that they make a huge difference about what happens next and so on. Yeah. The reason you need
some kind of a physical story at some point is that you need to flesh out a story about the
interaction with physical bodies. So what is it that happens when evolution produces or an engineer
produces some kind of physical machine? What's the interaction between those patterns that come to
resonate? And so some people, you know, some somebody will say incarnate, I will say, you know,
Richard Watson will say resonate, who knows, but when it comes to when it comes to these
kind of patterns that are embodied in a physical machine, we need some kind of story about what
happens there because because otherwise, you know, they sort of remain off in this. So they have to
encounter something. They have to, yeah, yeah, and we're actually doing work. So this is again,
this is not published yet. But we're actually doing some stuff on how you could basically basically
at this point, I think that the idea of a of an unchanging permanent sort of platonic space where
everything just is sort of fixed there. I think that I think it's much more it's much more interesting
than that. I think there is a chemistry of these things in that space. And I think we have a
computational way to start doing experiments there. And we have I have a student working on
on some stuff. So stay tuned, there will be that it is it is completely wild.
Looking at looking at agentic properties in sets of logical sentences, just you know, just
sentences, some of them are passive. And some of them are not some of them do things by themselves.
And and it's and it's really interesting. But but that's you know, that's that's that's what I
want to you know, going back to the whole butterfly caterpillar thing. I think that you can you can
think about this thing as you've got the left side of it's it's it's a it's a book, you know,
it's an hourglass slash bowtie where right where you've got you've got the there's intelligence on
the left side that takes all of these different experiences and generalizes and abstracts to
some sort of compressed ngram. You've got the creative intelligent part on the right side that
has to reinflate it into whatever the current context is and figure out what what what the
what the memories mean. But again, all of that that that first way of telling the story assumes
that the information is passive, and that all the intelligence is on the is in the hardware.
What if what if the data itself is not actually passive, what if these are patterns,
as as we were just talking about, and patterns that are using the medium of the physical
process from caterpillar to butterfly, right, to perpetuate to perpetuate and transform themselves.
And what if they're doing a bit of niche construction to make sure that they perpetuate
and actually, you know, do better, right, as a butterfly, you've got some advantages that
that you can have. So, so I don't know, you know, that that goes back to our
the sort of the self sorting data in the algorithms, right, the sorting algorithms,
where the distinction between the data and the and the algorithm is really very much in the
eye of the beholder and and you can vary and if you look for it, you can find the data doing
things, you know, how could you prove that that there's agency in in information?
Well, the way you prove agency in anything, I think, is you show again, and this is this
is kind of an engineering take is you show how doing so helps you do something new.
How how right so so how does it help you, right? It's it's the you know, my argument is that
back in the olden days when people said there's a spirit under every rock versus now,
where the scientists say there isn't any anywhere, but both of those things are wrong
because they're just you have to do experiments and you have to say, here's my theory, here's what
it does for me, you know, I, I, so so what so so here's what we're doing for this for the
for the sorting algorithms thing. What we found, and this was just the first thing we looked for,
so no, I gotta think there's more, but we just haven't found it yet. The first thing we found
is we found these algorithms doing stuff that are with that that are that is not explicitly in
the algorithm. They are they are doing things specifically they've they're doing this clustering
behavior that are not in the algorithm. So there are no steps to do that in the algorithm now now
now you know when you're looking at an algorithm, it has a cost to every computation costs something.
So what so what we see is that there's an algorithm, the computer's carrying out this
algorithm that you pay you pay an energy toll to do all the, but it's also doing something else and
it looks to me like it's doing that for free. So so so here's how I would do it. And I have a
I have a somebody in my lab who's who's who's working on this right now is to harness that
to some other task that's actually useful. Because if you can do that that second task is getting
done for free without paying an energy bill for it. Now I mean obviously that sounds impossible,
I understand that and it may well turn out to be impossible, but that's the kind of thing
you you you have to show an example where okay I took seriously the idea that this thing had its
own goal directed activity. I harness that goal directed activity to you know it's like the donkey
with the carrot on the on the stick right. By understanding what what the drivers of this of
this agent are, I can harness it to do useful work. And if I can do more useful work per unit of
cost for compute than somebody else who doesn't believe in that I mean that's it there's there's
no more to be had than empirical success. So so that's the kind of thing that I think we're gonna
have to do. That's great that's fascinating. So you need memories to have a self yes? Can you
have a self without memory? You can have a you can have a selflet. You can have a you can have a
slice. I you know I do I do think and this is like going beyond anything that I can usefully sort of
show there's just the thoughts there that thin slices are they do have experience and they probably
do have you know some some sort of consciousness associated with them but but but if you don't
have carry through then then you become fleeting thoughts you become a set of fleeting thoughts
basically as opposed to a coherent reinforcing pattern. Right that you could make a story out of
yeah. So you did you just used the C word and you used it several times in this paper
after last time years ago when we met you were like conspicuously avoiding it
and there's a really provocative sentence if maybe you could just unpack a little for me
could consciousness simply be what it feels like to be in charge of constant self-construction
driven to reinterpret all available data in the service of choosing what to do next.
Yeah are you thinking about consciousness? Yeah and so and so I still I still largely
avoided because what I don't have is a full-blown new theory of consciousness that you know I'm
prepared to defend strongly working on it. Nobody does well I mean a lot of people think they do
but exactly right because there's a lot of people who are willing to sort of get up with it get out
with it I'm I don't have anything like that yet but but but but here's here's what did strike me
you know Mark Solmes whose work on this I really like he too has this he has this interesting
point of view that he thinks that he says that consciousness is palpated uncertainty about the
future so the idea is that consciousness is the is what it feels like to have to be in charge of
knowing what to do next this idea that right this so this leads to connected to active inference and
you know what what do these patterns mean what can I expect next how do I minimize my surprise
these things so here's another hypothesis what if yes all that is true but there's an even deeper
problem which is that as a conscious agent not only do you not know what to do next you don't
even know what your own memories mean you have the constant burden of having to reinterpret your
own memories all the time and of course it's subconscious if it was if this is something
we had to do consciously you know we wouldn't we would never make it but it's a little bit like
you know people who um have a brain damage and can't form new memories you know you wake up in
the morning and there's a there's a there's a notepad next to your bed and it says hey guess what
you can't form new memories here's where things stand and by the way before you go to bed tonight
right right you know right right you know write the next note and so right so I mean that's what
all of us do but for for all of us that scratch pad is internal but for ant colonies and certain
kinds of patients you have to externalize you have to externalize those memories somehow so
I think that we're all kind of in that boat in that every so many milliseconds you have to be able
to you have to be you have to reconstruct the story of who you are what you are what your plans
were right and and no and we don't notice it because it's I mean it has to be automatic
otherwise we notice it when we wake up in the morning yeah yeah there's an interesting moment
of reconciliation of self yep yeah there is and I wonder if I wonder if this is the problem with
trying to make sense of our dreams too is that and I'm not I'm a no expert on dreams but but but I
wonder if part of the issue is that at night you don't really do a super good job of memories
in a way that your future self is going to decode them and that that's the the crazy dreams that
way you can't even figure out what what the heck it was it's basically because you're looking at
these zangrams going I can't make heads and tails of this and and it's just it's just more difficult
than than than waking you know waking memories I don't know that that's that's a hypothesis but
I wonder you know for consciousness I think that I think Mark is right but I also think that there's
an even deeper task facing selves you know conscious selves which is that you can't even
really rely on the past it's you know you have to you have to reconstruct it all the time you
have to figure out what you are and you're gonna recommit to being an agent doing things so that
that was that was my hypothesis yeah I think it's a fascinating idea of course and we haven't
talked about the social world but that that is helping us in a funny way and and constraining
us right I mean you're being told who you are all the time by the people around you yeah you know
who who kind of keep you in certain roles and limit that your ability to change
yeah yeah there's a softening of selves that happens when you're not in a social environment
it seems to me so I thought about this too with regard to psychedelics which have interesting
effects on the self and on memory all sorts of stuff comes up people people talk about a period
of ego dissolution a complete loss of sense of self yet they're still conscious
and then this kind of putting things together in a new way you know I mean especially with
the trauma victims who are treated they they take out their memories difficult memories
and when they reconsolidate them they're not the same they've got they've lost the emotional charge
or whatever it is I mean there's a kind of very interesting process of playing with your memories
in psychedelic experience so that you end up being a slightly different self when you come out
if it's working I mean that's kind of the theoretical model is is get you out of your
habitual ways of looking at things and your and and those kind of you know rumination I mean
those sort of the thoughts you were describing the take-up resonance in your brain that you
might not necessarily want that's super interesting and I wonder if there is a clinical path here
by taking seriously the idea that some of those thoughts may not want to leave like literally
right yeah you know and and there may be some that is trauma I mean that's you know part of drama
yeah yeah but but but I wonder if you know taking taking seriously their ability to process information
maybe not in the same way as a full-blown alter but but but still not passive data but actually
a pattern that can you know a a dissipative system that can actually process information
you know it may not I mean I don't I don't know anything about this so so maybe this is totally
nuts but I've heard various kinds of alternative therapists and whatnot you know wanting you to
talk to your different yeah but so that may not be that may not be crazy there may be
right there may be if if they can if these patterns can process information to some extent
there may be stimuli you can give them where where basically you're not you're not just
treating the brain to somehow take care of this although that may work too but you're actually
maybe maybe maybe there is something to be said for communicating well yeah this is now this is
the theory in treating schizophrenia you know yes you are hearing voices why don't you talk to them
or why don't you let me talk to them and if you think about it trauma memories of trauma do process
information because you get you know you hear a gunshot or something now and it's processed as that
or a siren or whatever it is so they are still active in your brain in an interesting way yeah
yeah that's very that's very suggestive um I'm gonna let you go in a second just have
one or two more questions um well this kind of relates to that psychedelic point but
it's interesting that we we cherish ourselves and we talk about um self-esteem and building
up the self you know with our kids um and we're very wedded to the idea of as I said earlier this
unchanging enduring self yet at the same time we spend a lot of effort trying to transcend it
and escape ourselves um whether it's through drugs is one way but also um travel uh experiences of
awe that we know kind of diminish the self religion giving yourself over to the group
why do you think we also want to transcend selves
I think again I don't know but I think that probably there are competing drives so there's
the there's the evolutionary firmware that says uh defend yourself at all costs right that's I think
that's gotta be in there but there may well be an opposing component that says yes but if you stand
still you're also not going to make it so it's like um you know with active inference there's
this thing you you know surprise minimization right so but the easiest way not to be surprised is to
stick your head in the corner and not look at anything and then there will be one final surprise
at the end when somebody eats you but that's it until then you're not surprised so you know so so
there's gotta be I think in biology there's gotta be two competing drives one is surprise
minimization and one is exploration where it says you know if you haven't seen anything new
in a long time you might be stuck in a corner you better do something else right and so so
maybe it's something like that maybe it's like yes defend yourself but also if you're too stuck and
you haven't learned anything new and you haven't improved and you haven't whatever then um and I
don't know if that's something that's uh comes from the biology itself or meaning just you know a
drive with actual selective advantage or whether that's some sort of a consequence of being an
advanced being uh that you know has some sort of semi-spiritual drive to um to improve over time
or something right right you're familiar with the decot this is another binary between exploring
and exploiting yeah um it kind of reminds me that idea that there is a desire I mean we spent a
lot of time in exploit mode as adults um but we also need to do the exploration and that and that's
the exploit mode has the strongest sense of self yes um psychologists would say yeah yeah I think
that makes sense and and I wonder if I wonder if aging on the cellular level if aging is is a part
of that you know as well you chase you chase the the the moving target morphology as an embryo
and eventually you reach your adult form and so sort of that's it you've caught you've caught up
and so now the name of the game is to defend against tiny local um defections of cancer
and degeneration and and so just you know cells getting old and so on but but but if once you've
given up uh once you've given up that you're on a trajectory for some kind of construction project
maybe you know that that's it if you if you if you're stuck in a rut of exploit and you're
really not exploring anything that may be when things start to go to pot I don't know I mean
you know the the the kind of uh familiar folk example is you know the people who who retire
from from their job and then immediately drop dead be right so that's the right that that's just
kind of a but but maybe something like that is going on um on a on a on a cellular level
where basically you know uh when there's nothing pulling you there is no more of that uh the forces
which is what we study during development that pull you from stage to stage at that point then
then then things things start to go downhill I don't know yeah um I noticed in your um
acknowledgments which was a fascinating list I read it um Bernardo Castro was in there yeah
tell me about I'm talking to him tomorrow I've never met him oh yeah yeah we've yeah we've had a
I've had a couple of conversations with with Bernardo online and you know a bunch off uh
yeah super interesting dude um computer science uh kind of background philosophy um you know he's
got this uh kind of idealist model um yeah I think he's very interesting I you know he did a he did a
cool uh session with uh Rupert Spira and they sort of talked about this notion of uh all of us being
dissociative altars of the great cosmic mind and things like that um yeah I think I think you'll
have fun I think he's he's a very smart guy I think you'll have fun I fun I'm reading his book
right now he's a new book uh that he sent me a copy of um the epistemology piece seems very
persuasive I mean the more we learn about active inference and the fact that we're constructing
our perceptions are limited by our cognitive equipment and the world we're seeing is mental
to a greater extent than we realize um but then he goes to the next step that what's really there
is mine and that's I don't understand that he he sort of asserts it without arguing it um well
he's got he's got I think five other books uh that yeah I know he's probably leaning on and I'm
not I'm not going to try to um uh kind of make his argument for him because I think I'll butcher
it he'll he'll do a much better job of it himself you can ask him to just like say it but uh you
know I I think that fundamentally I I like that idealist position in the sense that
I think what actually propagates through evolution through the universe I think the the fundamental
um pieces are perspectives so I don't think it's genes I don't think it's bodies I think it's um
I think it's uh I think it's perspectives and so what what I mean is that that any any agent uh
you can't you can't afford to um you can't you can't afford to try to see the world as it is in the
sense of uh like a Laplacian demon you can't afford to track microstates because if you
if you try to track microstates by the time you figure out what's going on you'll be long dead
any any biological system that in the real world has constraints of energy of time uh
so so what that means is you're going to core screen you're going to decide what am I ignoring
what am I paying attention to I'm going to take all these kinds of observations and I'm just going
to lump them all together and I'm going to call the you know and and I don't mean this is not just
humans doing this is every cell every bacterium everything's doing this so what you really have
there then is a perspective it's a commitment to it's a set of choices that say here's what I'm
paying attention to and here's um uh how I make sense of it here's what I think it means you know
it's a it's a it's an interpretation so so that's what I think is perpetuating through the universe
and being selected on and you know altering with time and all that is is a set of perspectives
a set of a particular vantage point of saying uh here's how I make sense of my world and and
once we understand that that every cognitive being is limited every finite every real being
is finite we're all limited we all have to choose a perspective that ignores all kinds of other
stuff and it's not just about only being able to sense a small um narrow band of the spectrum
it actually I mean that's true too but but it's much more than that it's cognitively not just
perceptually that we're limited uh then I think uh you know then then yeah then it's then it's all
about uh what we're talking about perspectives in the in the in the minds of living things
or are you talking about perspectives at large I'm talking about perspectives I mean I we can
talk about what living things are but I think that any agent that has to whether we would call
it living or not I mean any any kind of robotic thing any any kind of uh uh system that solves
problems in in a world of some sort is going to have to have a perspective on that world
and the more right for a rock you don't worry too much about its perspective although you
with potential energy and things like that you almost kind of get there but but but for most
things things that have a significant inner perspective we call those things living typically
but doesn't have to be uh and and yeah and whatever world they you know you can you can ask like
gene regulatory networks what's the world that they navigate it's not the physical
three-dimensional world it's the it's a high-dimensional transcriptional space that they
live in and I think from that from from uh no pun intended from that perspective
what you put it what what ends up being emphasized a lot more is what choices are you making about
your uh cognitive uh uh framing of your world and a lot less about some uh objective world
existing out there somewhere and uh yeah I think I think that's how you get to idealism is just
is just by recognizing that all um uh real real agents are going to be finite and limited and
therefore what you're really talking about is uh an inner world that you're building for yourself
it's it's your own self model that's that's that's a play here not not some objective thing
and that your self model may or your model of the world may or may not be compatible with mine
um you know yeah so in your view though I'm I'm assuming something but I could be wrong
um the prerequisites of self and the and the process you're describing do you think that
that can be embodied in a computer yes but computer has to I mean again whether something
in order is a computer is in the eye of the beholder what what what we what uh what we mean
when we say something is a computer is that I have a set of uh conceptual tools that I bring
to the table here that come from computer science and I'm claiming that those tools are useful
that that's all that's all it means and um do I think that uh some of those tools are useful to
understand cognition yes you know for example reprogrammability and software I think is extremely
useful uh do I think the von Neumann architecture and the sharp distinction between data and the
machine are particularly useful no I think we'll have to dump those uh do you know do I think that
at some point we could make synthetic uh beings that have the right features absolutely I don't
see any reason why it seems completely backwards to me to say that the the blind meanderings of
the evolutionary process can create real minds but but but intelligent engineers who understand
how minds work can't do it that that seems crazy to me so so I think that that for sure once we
understand and I think we're getting there I think we understand that you know a few of the
key features um I I don't see any reason why we couldn't uh re-implement them in a synthetic substrate
sure yeah but you'd need a substrate that as you've said is not at all like a von Neumann
correct correct I yeah I think you need a number of things and the and the thing is that um
I started I started writing those things down I started writing a paper this was
months ago I started writing a paper to say look these are the things we've learned from
biology if you just do these things you will have uh you know a real a real agent and then
then I stopped and and although I don't think this is going to solve it because somebody else
will of course do it but I didn't want to be responsible for it because I think that to whatever
extent that's on the right track it may or not be but but if it is then what that means is that
it makes it very easy to make trillions of other uh beings that are I have um that have more that
deserve moral consideration and I'm not really interested in being the cause of that but I'm
sure that's where we're going I'm sure I'm sure this will get figured out and this is what will
happen yeah other people are working on oh yeah including including Mark Psalms by the way yes
yes that's that's right and that's right and I would say it's very simplistic and it's and it's
using you know computers as as they now exist yeah I think that um I think of of anybody's
project that uh that I think has a chance of doing something like that I think is at the top
of the list I actually think you could do it yeah amazing amazing well thank you are you writing a
book a general a trade book uh I am uh I'm currently I'm Oney Pagan and I are writing a book on
bioelectricity and uh it doesn't it doesn't have any of this stuff in it it's just straight up bio
electricity uh but the next book if I you know if I get there the next book will be all of this
stuff basically great yeah evolution cognition all that stuff and are you going to do that for a
general audience I don't you know I don't know I I'm I'm still we're still um so Richard Watson
and I are probably going to do it together or or maybe we'll do two books we we haven't been able
to like maybe it'll be two books back to back or something we'll have you know maybe inverted like
the way that um uh that was done for the Plenaria Journal and and and all that uh I don't I don't
know um I'm having a really hard time figuring out what is the best thing to do here because on the
one hand I could do a book for a for a general audience and I think what would happen then is
that a lot of these there will be a set of people from let's say the alternative sort of you know
new age kind of community who would read these things and they say oh yeah no kidding we've
known this for a long time and we they you know they don't they don't need uh you know they don't
need um uh you know scientific uh you know sort of experiments to prove it whatever they they're
already in in for it um and then there will be the science community who will say well there's not
enough uh meet here to convince me of any of these crazy things right so so I so I worry about that
issue for the trade book I you know I it sounds like that could miss uh the impact on the other
hand on the other hand if we do a you know an academic press book where you where you go into
detail on on all of this stuff uh yeah I'm not sure you know I'm not sure I'm not sure which of
my colleagues have time to read something like that uh you know who's gonna read it I don't know
so so I still haven't figured out what the right yeah I mean I think you've got a really interesting
book around some of these ideas and um I think it'd be of interest to a lot more than new age
people um I really do um do you have a literary agent I do yeah I do yeah um I mean it's a conversation
to have with that person is it who is it Brockman's shop it is yeah yeah yeah Dan introduced me to
Brockman yeah yeah yeah we'll have a con I mean I mean he obviously wants a trade book all right so
now the other thing is you know they don't which which is kind of wild they don't like
images and they certainly don't like color I have I have some amazing color illustrations
and I don't know that feels weird to me in this modern day and age with computer like do we even
need a book couldn't I just put it all on a website like why do we need a book I don't
you know and you know and somebody's gonna tell you not to use color I'm like I don't know yeah um
yeah well good luck with that I I just think that these ideas would be of interest to a lot of
people in a lot of different fields they're very interdisciplinary ideas and um so uh I think the
right trade book would reach your colleagues or colleagues and other you know in philosophy and
computer science um anyway it's all it's just fascinating stuff well thank you I appreciate
that I'll I'll be in touch because I will definitely want to pick your brain when it comes to I'm happy
to read a proposal if you do that or whatever yeah I'd love any kind of suggestions um that'd be
super useful thank you good and I'm going to be in Cambridge this fall so uh awesome awesome yeah
you can get together in person definitely yeah we'll hang out
