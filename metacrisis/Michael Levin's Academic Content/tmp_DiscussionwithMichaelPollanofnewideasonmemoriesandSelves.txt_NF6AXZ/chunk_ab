So you're abstracting exactly.
That's what it is. It's generalization and abstraction.
That's exactly. And that seems to me what's happened in the caterpillar
butterfly case, right? I mean, so in the experiment that you described,
it wasn't I realized it wasn't yours, though, was somebody else's experiment.
Yeah, it's not it's not my experiment.
It was done. It was first done in the 70s by a bunch of Russian groups
who did larvae to beetle and things like that.
And then it was done by Doug Blackiston,
who is actually a staff scientist in my center.
But but he did this work when he was younger.
And yeah, he did it with moth caterpillar to moths.
And he did it.
There was some training, some operant conditioning going on, right?
To associate food with a certain color.
Yep.
And so the abstraction there or the results of the compression was concept
food, right, rather than specific leaf or nectar.
Well, it's too thick. Right.
It's too. It's actually multiple things because, A, it's yes,
we're not remembering leaves because butterflies don't care about leaves.
But also what do you do because because
the caterpillar is a soft body creature and the way you move a soft body,
you don't have any hard elements to push on.
So you can't do robotics the same way.
You can't do controlling the same way.
So there is a certain set of muscular motions that you need to do
to make your way over to where the where the leaves are.
That isn't going to help the butterfly.
The butterfly doesn't move like that.
It's got a completely different architecture.
And and so so the the the abstraction there is from from from leaves to food
or maybe even we don't know, it might even just be to pleasure or something.
You know, just just positive affectors, you know, who knows, right?
Um, but also but also how do we make use of that
associative learning that this color leads to food or to, you know,
to pleasure or whatever?
How do we remap that on a completely different controller?
And you see this even in vertebrates like like this is and actually this was
Doug's Doug's work, too, is we can make tadpoles with eyes on their tails
and they can see perfectly well.
And so it's like, isn't that amazing that with no extra evolutionary cycles,
no, no adaptation out of the box.
This this thing that for millions of years at the exact, you know,
the brain could rely on getting connection from the visual system
into the optic tectum and all that suddenly it's on your tail.
No problem.
It connects to the spinal cord and you can connect to the brain as it makes it work.
So what's happened there?
Do you think how do you think that what's been remapped?
What's been remembered and forgotten?
I think that all of these and there's tons of these examples
that I go through in various papers is the reason that.
Life is so tolerant to these crazy kind of changes is that it fundamentally
assumes the material is unreliable.
In other words, unlike all of our computer information, the information,
the substrate, it assumes that the substrate is unreliable.
Because look, this is how we build our computer technology.
You make the bottom layer as absolutely rock solid as you possibly can.
So that all of the stuff on top of it can assume that everything
is going to go well at the bottom.
You know, when you write code, you don't think your your your transistors
are going to burn out.
You don't worry about that.
And so so the goal is to change the to to to keep the information from changing.
And this is why actually that whole business of these microchips, right?
How small can you make a microchip?
It's because you don't want the bits floating when they get too close to each
other, they start to fluctuate, you know, the quantum effects start to fluctuate.
You don't want that.
You want every you want all the bits to be exactly what they were before.
You want fidelity of the information.
Biology can't we can't operate that way because everything is going to change.
So on a small time scale, your proteins are going to degrade,
your cells are going to die and be replaced on a larger scale.
You're going to be mutated, right?
Evolution, you know, guaranteed you're going to be mutated and things will things
will change, not just environment, but also your own parts.
So I think that there may be exceptions.
There may be organisms that aren't like that, although I doubt it.
I think at this point, what what survived and what what biology
strongly emphasizes is architectures where you assume the underlying material
is unreliable and what you're going to do is on the fly.
You don't over train on your priors.
You don't assume that the future is going to be like the past.
You don't assume you know what any of your information means.
You are going to try to reinterpret it at the at any given moment on the fly
and do the best you can.
And so that gives rise to these kinds of systems where the eyes in the wrong place.
Well, we can we can do something with that basically, right?
I mean, the detail is it is it's it's hard work to figure out.
OK, so where is the information actually going?
You know, it gets on to the spinal cord, then the brain learns to infer
some connection between what the eye says and what does it even know?
It's an eye. Well, I'm not even sure about that.
So but I but I think that's what's happening here is that
biology commits to a real time sense making process, not to the expectations
of the past, you know, I think I think that's the most interesting part.
And that's what makes the stuff so flexible.
And that's what makes biotechnology possible.
It makes, you know, I'll take my cells and slap them onto some weird
scaffold made out of crazy nanomaterials.
And I'll instrumentize it with electrical signaling and optical, whatever.
And things work because, you know.
So the so the the butterfly has solved this problem of how can I change
and and still can I change and still exist?
Which I think I think we all do.
I think I mean, the butterfly is kind of an egregious case.
But but all of us have the same problem because over time, we are not the same.
And, you know, whether it be the rearrangements of puberty or just the,
you know, the day to day wear and tear on the body, you know, the the whole
ship of thesius thing, right?
And where where your materials are going in and out all the time.
I think, you know, I think I think different species
emphasize this to different extent, for example, plenaria are the champions of this.
We look plenaria, right?
Cancer resistant, incredibly regenerative,
no aging in the asexual forms, no transgenic lines
because they basically ignore new DNA that you put into them.
There are no transgenic.
Yeah, there's no for people have been trying this since I think since the late
eighties, people have been trying to make transgenic plenaria.
There aren't no no mutant lines.
The only the only lines of aberrant plenaria that exist
are our two-headed form and the cryptic form, and they're not genetic.
It's because the only reason it works is because it's not genetic.
What happened in in plenaria, I think, is that
they because because they're they reproduce asexually.
So they, you know, tear themselves in half and regenerate.
That means that they accumulate somatic mutations.
They don't clean the genome the way that that we do with sexual reproduction.
And so they've accumulated so much junk that basically
the only way to to have a proper plenarian is to assume the hardware
is is going to be unreliable and to put all of the effort.
And we've done computational models of this actually.
And you can see evolution doing this when when you get even a little bit of
regulative competency where the creature where the creature can make up
for certain subtle defects immediately.
Evolution, it's hard for selection to now see the genomes, right?
Because if you get an animal that looks pretty good,
you look pretty good because your genome was great or because you actually
terrible, but you know, you fixed it along the way, right?
And so this is like the stuff that we see when we make tackles
with the with the scrambled faces and they see them, they fix them, right?
So so what happens is that then when evolution has a hard time
selecting for good genomes, all the effort goes into selecting
for more competency, which in turn makes it harder to see the genome,
which in turn makes for more kind.
And so you get this, you get this thing where the pressure on the genome
actually flattens out, but the pressure on the competency keeps rising.
And so if you take that all the way, you end up with planaria that basically
everything went into making an algorithm, which is partially bioelectric
and who knows what else that basically says, I already know my hardware,
it can't really be trusted.
Here are all the error correcting codes and everything else that we need
to do to build a good planarian, no matter what happens.
And then of course you're insensitive to trans genes to, you know,
to cancer, all these things, because you're assuming from day one
that all that stuff can't be trusted.
Right, right.
You know, and I think, you know, I think, I think so planaria are kind
of all the way there and then salamanders are pretty good at it,
but not as good as planaria and then the mammals and then maybe something
like C. elegans or Drosophila are on the opposite end and they're just really
pretty, you know, pretty hardwired, maybe.
So you're when you your definition of self, how far down the evolutionary
ladder does it go?
I mean, does it go to single celled creatures?
Are they selves or does it go or does it begin at a certain point in
evolution, the self as an innovation to, to deal with these problems you're
talking about?
Yeah.
Um, I don't, I don't like binary categories for any of these things
because they end up chasing us into these pseudo problems where you can
always come up with these sort of in between cases and then you spend all
your time trying to prop up this binary definition as opposed to, I think,
I think what's what all binary here between having a self and not having
a self.
Correct.
Yeah.
Yeah, exactly.
I think it's on a continuum.
I think all of it will, yes, I think it's on a continuum, but, but the
reason it's on a continuum is that I take all of these terms.
So all of this, you know, having a self intelligent sentient, you know,
cognitive, like all the whatever of these terms you want to use.
I don't think they're about the system itself.
I think what they refer to is your intended interaction with it.
So if you tell me that you think a certain system as an observer, as a
scientist, as a, okay, as, as, as a scientist, as a, as a conspecific, as a
parasite, as a, you know, whatever, whatever, it's, it's every, every agent
with living non-living scientific, you know, natural, whatever, you are going
to take some stance towards whatever you want to interact with.
And if you want to take a mechanical stance and say, all I see is a bunch
of cogs and gears, I'm, you know, my, the tools I have to interact with
you are just hardware rewiring.
Well, you know, that works well for mechanical clocks and things like that.
You try to apply it to a human.
If you're an orthopedic surgeon, not bad.
If you're a psychotherapist, terrible, right?
