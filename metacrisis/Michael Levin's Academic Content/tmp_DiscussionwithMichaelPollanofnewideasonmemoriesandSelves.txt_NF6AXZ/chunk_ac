So, you know, you want, you want to, or, or, or a spouse, you know, terrible.
You want an orthopedic surgeon that thinks you're a mechanical machine.
You do not want to spouse or, or a psychotherapist that thinks you're a
mechanical machine.
So I think all of these things, I think all of these things just, just
indicate the frame that you bring to the interaction and the set of tools
you're going to use.
And so you've got, you know, you got your rewiring, you've got cybernetics, control
theory, you know, behaviorism, you've got, I don't know, psychoanalysis, spirituality,
who know, like I'm just, you know, sort of drawing the, the spectrum, right?
So, so how far down does it go?
So, so, so what that means is, can we get some sort of utility?
And that's why I harp on the engineering side of this, because I think this
should all be tested by, by utility in the, in the real world.
So, so can we get some sort of utility by applying these concepts to single cells?
Absolutely.
I think yes.
Can we apply them to molecular networks?
Yes, within cells, I think so.
We have, we have data on this.
Other people have data on this.
Could we apply them to particles?
Maybe.
So I think Chris Fields and Carl Friston and some other people have done some
really nice work trying to cash out physics as a kind of
proto-cognitive substrate, like active, I mean, they like active inference.
There may be some other things.
So maybe.
So I was going to ask you, too, if you thought this was limited to the realm of biology.
I realize Friston doesn't.
Yeah.
But I don't know.
He doesn't, his, his work makes it better.
Seems to all perform better when you transpose it to the realm of biology.
Then when he starts talking about active inference and rocks and crystals and things,
but I don't see the active piece.
Well, so, okay.
I, you know, I couldn't possibly reproduce the argument the way that he does it.
But, but I think, I think what he's saying is that, and Chris Fields has stories about this,
too, which is basically that there's an equivalency between what is a thing?
You know, what is a rock?
What is a, right?
What the, I mean, I think that's a very important part of the research program.
And this idea that there's the active inference is quite symmetrical when you're
doing something to the environment, the environment is also learning about you and so on.
And I think the claim there is that there is a very simple version of this that just
basically looks like physics to us.
But if you sort of crank up the, the, the relevant parameters, then you end up with
things we call life.
So, so, so here's, here's what I would say about that.
I think when we say biological world, what do we really mean, right?
What, what, what's life?
I think that what we mean by life is anything that is good at scaling up the cognitive
light cone.
That is anything that where the whole has a larger is capable of pursuing larger and
more complex goals than the parts.
That's what we happen to call life.
So, so we don't do that for rocks because the rock has exactly the same cognitive
light cone as the pieces that could go inside the rock.
It hasn't scaled anything.
It's just exactly the same.
It's not more than the sum of its parts in that particular way.
Right.
So, so some people would do it, you know, to know, you would do it off of integrated
information, different people do it different ways.
I think it's all about goal directedness.
And right.
I think it doesn't, it doesn't, you know, you're not going to find larger goals that
help you deal with the rock.
It's basically the same.
It follows least action principle.
That's about all you're going to get out of it.
Right.
So, right.
So, so I think, you know, I think biology is what we roughly call things that are good
at it.
And that, again, is a continuum.
I think we don't need to spend any time arguing whether something is alive or not.
The real question is, so what's, so, so what's your model?
What, what goals do you think this follows?
And how does that help you have a richer interaction with the system?
And what tools can you bring from, from active inference from behavior science?
And then so on.
I mean, look, one, one example.
Okay.
One, one recent example is we showed models of gene regulatory networks, which are just
chemicals.
You can, there might as well be a rocket just to, you know, six or seven chemicals interacting
with each other.
And what we showed is that if you bring tools from, from behavior theory, meaning,
meaning different kinds of learning.
So, associate of conditioning, habituation, sensitization, you can do some really
interesting things with just, with those networks that have lots of biomedical relevance.
And, and, and, you know, it's already there.
You don't, you don't need a cell.
You don't need any, you know, you don't need protoplasma.
You don't need any of that.
Just, just the mathematics of having a few nodes connected by these differential equations
already give you a bunch of stuff that we would call learning.
And that help you, you know, and, and again, my goal, right, remember, you know, my goal
is not to, to do poetry and to sort of paint hopes and dreams onto these things.
And, and, you know, that we could never agree on.
I make a very clear claim that if you know these things,
you will do better in the biomedical arena than if you pretend they don't exist.
And that's, that's a, you know, that's not a philosophical claim.
That's a, that's an empirical claim that we can, you know, that we test.
You mean as a scientist or as a creature?
No, as a, well, both.
So, so first thing is, so, so mostly what I talk about in public is the science, right?
So, so I say as a worker in regenerative medicine, as somebody who wants to discover
new ways to use drugs, you will do better if you are able to use the tools of behavioral
cognitive science on your cells and tissues than somebody who doesn't.
That's, that's the first claim, but you could, you could push it forward and say,
you know, in our personal, and, and I mean, I have no credentials to be,
you know, talking about interpersonal, you know, social stuff.
But, but, but overall, it seems perfectly reasonable to me that we could apply the same
reasoning and say the way that the same pragmatic reasoning to our relationships and say the way
I pick frames for interacting with others is to see how well they work out for me.
So it purely empirically, so, so if I treat you as, as a, you know, as an advanced
metacognitive being, we can have a certain kind of relationship and that elevates me in a certain way.
If I do something else, maybe that doesn't work out as well.
If I take one of the lower, you know, kind of lower framings.
So again, just, just, and it's a way to test.
It's a way to test the environment too, right?
You, we're going to go in on the assumption that this is a cognitive being and we'll see what happens.
And we'll see what happens.
I mean, that's the, you know, you can, you can go the other way.
You can say, you can start and say, okay, I'm going to go on the assumption that it's not
and see what the limitations are.
I mean, I prefer the former, but, but, but as long as, as long as everybody's in agreement that
this is an empirical undertaking, this is not, we can't, we can't just have feelings about this.
And this is not something that we're, you know, we're going to argue about for the next
thousand years and never get anywhere.
No, this, this is getting resolved because, you know, there's, there's clear data on a human scale.
Of course, it takes longer, right?
So it takes maybe years for someone to say, you know what, my framing isn't working out for me.
It's, I'm going to try something different, right?
That, that, that may take many years, but.
Right.
That's kind of what's happening in the whole field of plant intelligence that people are like,
let's, let's, let's see what happens if we assume they are cognitive or they have intelligence.
And some, and some, you know, some people show that they can learn.
Some people show they can't.
So taking selves to the, the, the human dimension, which I've been looking at for this chapter I'm
working on, I've been talking to neuroscientists and, you know, people like Anil Seth, who's
written about selves.
One of the things that's curious is, especially in light of what you've proposed in this piece,
is we're very invested in the idea of the unchanging self.
And it's curious, we don't embrace the idea that this is a completely fungible,
you know, subject to our remaking and our creativity.
Why do you think we're invested in the idea?
It's, it's very hard to conceive of it.
I mean, in the definition of self is some continuity, right?
Why do you think we're so invested in, in the idea of a stable continuous self, which,
you know, we're being told by a lot of different discourses is not true.
I, yeah, I don't know.
I think, you know, I can, I can make some hypotheses.
I suspect that it's, it's firmware left over from our evolutionary past, because
if, if you were not
sort of wired to expect object permanence in the outside world, right?
The, you know, babies acquired very quickly and that they have someone they're born.
If, if, if you don't, if, if, if you're not good at seeking out object permanence,
and if you're not committed to persistence of your local self,
I suspect that on the Savannah and whatever the previous versions that are,
I suspect that doesn't play out very well.
You know, it's, it's not very good to say, go ahead and eat me lion.
You know, my, my patterns will continue in the universe in another form.
Like, great.
But, but, but my future self will be undisturbed.
My future self, yeah, I have, I have much bigger, you know, bigger thoughts than this.
I suppose that doesn't work out too well, right?
So, so I can see why, why evolution left us with some firmware that tries to kind of
dumb it down to this very like basic survival for the same.
And I think, I think that, that firmware has a bunch of other stuff that needs to be
jettisoned, which is, which is hard.
For example, I think a lot of the issues around, you know, one reason people don't
like this kind of work, right?
This kind of a diverse intelligence work is that they worry about false positives.
They worry about too many things being considered as if they were cognitive.
And I mean, clearly you can, you can make mistakes in that, in that realm.
And we have people that are in love with bridges and married to the Eiffel Tower
and stuff like this, right?
You can do that.
I mean, that does happen.
But I think what fundamentally drives this is a real deep seated fear and a,
an assumption that there's not enough love to go around literally like, like,
like that there is a, it's a zero sum game in terms of intelligence.
And that if we consider other things to be, to be cognitive in some way, well,
then mine isn't worth as much, you know.
And, and again, I think that's like ancient scarcity mentality,
firmware from evolution that says, no, there isn't enough of anything to go around.
And there's status and it's a zero sum game.
And if you don't have the status in your group, you know, you're screwed.
And so that's where I think some of this is coming from.
But this is all, you know, that's, that's armchair, you know, armchair of
psychologizing.
I don't know.
Yeah.
Yeah.
Of course, the other reason, I mean, there are, there are variables you want to keep
