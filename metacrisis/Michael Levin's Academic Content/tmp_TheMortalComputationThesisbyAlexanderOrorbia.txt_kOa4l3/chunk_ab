and ultra stability means it's found an attractor it really likes. So this is a good place for the
system. It's very hard also for it to leave that particular state. So ultra stability is
effectively it's able to maintain its homeostasis. It keeps those variables near its set point. It
has all that it needs to sort of stay in a good configuration. And then of course, there's other
principles like the principle of asymmetric transitions. And these are things that are
characterized deeply in cybernetics system in unstable configurations usually moves to stable
ones, but not the opposite. And again, a system as it rejects fewer states as it reaches more
stable ones, the variety decreases as the system becomes more organized again, it's sort of converged
to a good state. You can equate variety with thermodynamic free energy. But the idea is that
then the system does work or it exerts its variation to reach those stable states. If it
is stable, it's not going to undergo variation. And it's less likely to expend the energy to leave
its current state to state. So then the other aspect or the other pillars you can see on the
right slice of the diagram is growth. And again, we're not going to talk about all little sub
principles again, I recommend reading work to see how they all kind of fit together. But the idea is
that our mortal computer must be morphogenic. It maintains its continuity and integrity by
altering aspects of its organization and structure over time. Morphogenic processes may
also be triggered by environmental conditions. And then of course, we have this principle in
cybernetics of self replication. This is kind of really important, something we don't really have
in artificial intelligence systems today. System behavior is important that it results in copying
or generating copies of itself. We do have some classical work like the von Neumann universal
constructor, you might have heard of Conrad's game of life or Conway's game of life, sorry.
And the idea is that these are models of rules or rule based systems that can show you how you have
death and life in the computational systems. And then another important notion is that
reproduction on a mortal computer would not just be replication, but you would add mutation.
So if we have perturbations to a replicated copy, now we have an offspring. And now that is subject
to the same pressures that the original source computer is subjected to, and it will undergo
selection and try to find its own stable states. Ultimately, then you can think of reproduction
as another means to propagate one's identity through time. And then the last principle or the
last pillar that we organize is cybernetical regulation. I do mention sometimes cybernetical
homeostasis is kind of like implied throughout various principles, but we have the law of
requisite variety. Just very briefly, what these three principles ultimately try to tell you is
that you need to have enough internal variety in order to, or at least in enough equal amount of
internal variety compared to your environment's variety in order to successfully maintain, for
example, homeostasis or block particular variables and stay in a stable state or more, you could
have more variety. That's fine. So it is an inequality. But the idea is that this is important
for a system essentially to try to maximize its internal variety in order to be optimally prepared
for all possible perturbations or things that the environment could throw at you.
The good regulator theorem complements this a bit. And it's just basically saying that every
self-regulating controller of an environment must itself contain a model of that environment.
And this motivates the notion of a generative model that effectively one way you could think of it is
that the mortal computer or entity is a generative model of its own environment. So the mortal
computer ultimately seeks to become a model of the niche that it wishes to control. And then this
motivates aspects of survival. And the principle model control, internal model control, I'm not
going to go into it for sake of time, complements the good regulator theorem. It just basically
talks about things that are how you deem if the system is structurally stable. And I'm going to
move on because I want to make sure that we get through to the actual definition. So then the
last slice that we review and we had a preview of this earlier is aspects of cognitive science.
So effectively, Carl and I sort of generated something that we call a 5e cognitive theory.
You might have heard of 4e cognitive theory, so we slightly extended it. Very briefly, if you
look at the center component, the extended, embedded, inactive, embodied, and elementary,
you'll notice elementary is the new aspect of the new extension to cognitive theory.
Elementary cognition, and I know many of in Mike's group is very familiar with basal cognition,
and is that cognition stands on fundamental functions and structures that enable acting
and tracking aspects of an entity's niche to ensure it survives fine food, avoiding danger,
trying to reproduce. So these are, again, known as basal cognition, and it's a manifestation
manifested through a system's autopoiesis. So this is sort of the base level that you must have as
the starting point, essentially, to build a reasonable or effective, moral computer. And then,
of course, on top of that lives the embodied cognition aspect. And this, again, they all depend
on each other. So if you have one, you're going to start getting the others. If you add these levels
of complexity, so it's kind of organized as the higher up in this chain you go, the more complex
your mortal computer is. The body cognition, as we talked about earlier, is that you can't describe
your cognition or mental processing without a body. The idea is that you must involve the body
or morphology of the living system. And yes, this is a little bit more of the extreme version
of the embodiment thesis. There are a spectrum of different types, but we sort of leaned in more
on the idea that we even offload cognition to aspects of our body. And this is motivated by
like morphological robotics, where, again, we know that if we can offload the physics onto
particular limbs and things of that form, you can reduce the processing of the computational brain
that you build into the computer. We know that inactive cognition lives on top of this is the
idea that you depend on your environment, and you have a meaningful relation, two-way relationship
with it. Again, not only for extracting resources and transmitting waste, but you are essentially
inhabiting and actively shaping your niche construction, as I mentioned earlier.
Then on top of these, we didn't really go into detail. I'm just going to mention that you can get
further and further and more complexity introduced. You have embedded cognition because the idea is
that you live in a system of other mortal computers. So that's kind of what we have there.
On the left, we show some neurorobots as just an example. And the idea is that you are determined.
Your cognition is affected by cultural norms and other social interactions and the behavior of
other entities that are also in this environment undergoing the same forces that you are.
And so, again, the mind extends now beyond boundaries of the individual. And then, of course,
extended cognition is the final one where you offload cognition or the theory of extended mind
into non-biological or non-mortal objects. So if we generalize things to mortal computation,
these are not mortal computers like your pencil or your phone. So essentially, we are using objects
as an extension of our cognitive functionality. And of course, that kind of like pie-sliced circle
is just sort of grouping them in another way. So we have basal cognition as like the biggest
slice. It's more of the foundational component. Morphological cognition deals with anything that
would be bodily kind of cognition or processing. Inactive, of course, you need to account for
the environment. And externalized sort of absorbs extended embedded. So that was another way that
we organized it. So maybe you might have heard of Kirchoff's life-mind continuity thesis. This is
another way of saying like, it's an artificial manifestation of it.
So what now, equipped with all this review of wonderful work of far smarter people than myself,
we get to the mortal computation thesis. So there are a couple of parts that I'll just introduce
briefly. And I have reduced and cut away some of the mathematics. We can talk more about that if
we want later. The Markov blanket is really the central underpinning of a mortal computer
and effectively what this does is this is our interface between what's inside you or the entity
or the mortal computer and what exists outside of it. It is that particular interface and things
are exchanged through that interface will be coupled. We can break it down a little bit further.
You could think of, by the way, Markov blanket like a cell surface, which separates intracellular
from extracellular elements. And then of course, we talk about sets. And again, these can be viewed
as discrete states, but everything's really continuous and it makes things more complicated.
But as you can see in the diagram to the right, we can decompose the Markov blanket into sensory
states and active states. And these are the ways in which the agent actually gets information
from the environment and transmits information to it can do things to it. Always the external
states of the environment and Z is the internal states of the system itself. So these again
are not observable by the environment. And the observable states are not observed by the agent
and must interact through this Markov blanket formalism or this construct. And again, this
motivates again, how you now need to design the body need to account for the morphology
of the agent. And so here we have a little bit of an expansion where again, I told you what
all the different ones are, we have iterators and we talk about them as actual sets of states
and they evolve with time as well. So again, ultimately what we want to take away from this
is that there is a weak coupling and local interactions. And this will motivate the free
energy application of the free energy principle shortly. And the Markov blanket provides that
necessary partitioning non living systems by the way that exhibit persistent local dynamics,
do not maintain a boundary. So you could argue, well, well, this is your framework and the concept
of the free energy principle Markov blankets apply to a campfire. And the answer is no,
because the campfire dissipates rapidly in the flux of the universe, it is extinguished by the
downpour of rain. So this is not going to have persistent dynamics, it just has local dynamics
or you can think of a candle flame as well as an example of a system that would not be a computer.
So now we get to the idea that mortal computation or the mortal computation thesis is really just
another corollary of the free energy principle. And just to briefly review what the free energy
principle at one perspective is, is all centers around what I was already hinting at before,
which is the non equilibrium steady state solution, or the NESS. This is what agents or any mortal
computer really wants to strive to reach. And so the idea is that, according to the free energy
principle or the FEP, entities maintain their structural and functional integrity by changing
their relationship with their eco niche through action. So action is really important because
this is our way of which the system can actually forage for materials. So the free energy principles
about random dynamical systems that actively resist the natural tendency to disorder going
to equilibrium and non equilibrium is bad. That means you have died. And so the kind of the whole
idea of mortality as we act so that we do not talk that we do continue to persist. And then the
free energy principle can then be broken down into kind of two key parts as you can see with
numbers one and two. Mortal computers internal density dynamics are conditionally independent
of its environment. What does that mean? The environment and the mortal computer are weekly
coupled and the mortal computer has states that are distinct from its external or environmental
states. That was again what was ZT versus OFT. And then the second key point or the key aspect
of the FEP is that the mortal computer will continually self-events or self-evidence by
returning to or trying to be as close as possible to its NESS, its NEST state. So the mortal computer
behaves to preserve its functional integrity and its dynamics do not diverge when a perturbation
is applied. So it's trying to gather those resources to continue to survive. It's striving to reach
ultrastability which connects back to the cybernetics back in. And then we talk a little bit about
the formulation of the variational free energy. I removed all the terms for you for simplicity here
again for the sake of time. But really under the hood of the free the F curly F is that an entity
has a morphology queue. This is referring to its actual structural organization. It has a set of
internal states and it has parameters move. And so again ultimately the free energy principle
is following the gradients or the differentials across each of those aspects. And we talk a
bit more detail. But I'm going to shift you to the final piece of the puzzle which is just
and we've seen this again like throughout morphic versus amorphic is an important distinction.
We've talked about biological entities having a 3D physical structure and von Neumann computers do
also have that physical structure. They're designed to maximize heat dissipation and things of that
form. But our programs and our software do not adhere to that structure. They are not
entangled with it. They are not taking advantage of that. And so we have again in a morphic system
we have a thermodynamic cost and we have information coupling. These are very important
constraints that characterize entities in this category. And so the morphology itself is a
computational resource and living entities. We also go on the paper in the free energy
principle about how you'd need to do structural optimization which connects back to morphogenesis.
But our computers are amorphic or sorry our programs are intelligent systems today.
Our software is independent of that substrate. Think of when you if any of you have experience
writing a mathematical model for a deep neural network you can write those equations independently
of any realization of a 3D environment. The execution of that program is possible because of
that computer's architecture but you are not accounting for its morphology. It is amorphic
even though we present it pedagogically as dot scenarios and try to connect them back to
synaptic structure. So ultimately mortal computers follow self-evidencing the same
self-advancing principles as enduring entities. They are inherently morphic thus we can apply
or ground them in the free energy principle. As I mentioned briefly earlier you can see to the far
right those are the gradient flows that you follow and of course we formulated them as
differential equations or differentials that you could essentially traverse as the free energy
sort of gets you back towards or trying to minimize your variational free energy to get back to that
ness. But this is the essentially we talk about the relationship between inference
learning and structure and how there is a circular causality between them and we go at
quite length and I'm not going to go into in this talk because that's going to take a while.
We also talk about mean field approximations and simplifications that give rise to known
structures and neural structures in the brain. But the idea is that a mortal computer is a
dynamics on structure with dynamics was ultimately one conclusion that we lead and we call this
backbone mortal inference and learning or mills for short. This is a key part of the final definition
I'm about to show you and remember that inference changing or altering your internal states or
variables internally depends on learning and of course learning depends on those internal
states and then there is another interesting relationship we point out that the morphology
or the structure depends on the learning or the synaptic parameters if we're thinking about
neuron networks and vice versa. So there are these causal relationships or these circular
dependencies that are necessary and actually important to embrace that a lot of modern day
machine learning or artificial intelligence does not embrace and we should be looking to
biology and neurobiology for those sources of inspiration for design. And I also mentioned
that mortal computers are an instantiation of physically realized Bayesian evidence. Not
only are they going to read to you this entire definition but this is effectively one starting
point an informal definition of mortal computer or mortal computation and what it would mean for
designing is going forward for artificial general intelligence. Very briefly the core agent goal
is to remain in non-equilibrium steady state of stability in the face of a changing environment.
Very briefly from the high level view of this definition you will notice that it
emphasizes strongly you need to have a morphology although we give you sort of a backdoor for those
that do computational modeling perhaps a virtual morphology would be acceptable for now.
And then we obviously need to have accounts for homeostatic homeohedic processes. So a generalized
homeohesis or homeostasis we also need to ensure that we have implementation of various aspects
of mills as I just briefly discussed earlier. And then we end by talking about categories of
different types of mortal computers and we came up with some very broad and these are subject to
change because this is sort of pointing in a completely new direction for artificial general
intelligence research to go into or biomimetic intelligence. So we have homeostatic mortal
computers and they satisfy essentially the core principles of the definition but in a very basic
sense. So it has homeostatic regulation over those essential variables or primitives I mentioned
very early on. You also then have a higher level regulatory processes so allostatic mortal computers
these might evince homeohesis in contextualized by allostatic regulatory processes. Obviously
the ultimate goal is to have a fully auto poetic mortal computer and we actually really have some
of these interesting ones. I'm going to wrap up with those examples some of which Mike's group
definitely knows for sure and of course we need to evince homeostasis allostasis
