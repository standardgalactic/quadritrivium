The question becomes, what do you have to assume to call some of them classical.
And you're making some assumption about thermodynamic, the reversibility to call something classical that I, I actually said these words, not some superposition.
And you actually hear some words, not some superposition.
Which, which gets back to what you were saying at the very early, very early on in the discussion about encountering superpositions but imposing order on the based on
regularities of some sort.
The regularities are classical.
The regularities are kind of what we mean by classical information.
Yeah, the superpositions are not very actionable. You need to figure a focus on those aspects that are not in superposition.
Well, the very notion of action is classical. Right. I did this, not that.
Yeah, exactly. So I think in order to conceptually itself itself as an observer with memories and so on the system needs to be able to maintain a classical model of itself.
And the collapse of the wave function is the point in your past beyond you fail to pretend that the universe is classical.
Listen, I suspect the correct interpretation of Copenhagen, if you want to take that one is not that consciousness is causing the collapse but consciousness can only exist in collapse timelines.
Yeah, what one could say an observer can only be an observer, if it considers itself to be an observer, right, to exist for more than just an instant to have some sort of identity over time.
Yeah, right. Isn't isn't that have a Markov blanket, whatever. Yeah.
So you could fundamentally then what you're what you have to do is define some time time period where if if dirt, you know, during that minimal.
It's like a frame rate or something where during that time, if you had multiple multiple thoughts multiple models multiple whatever you were doing, they sort of are in a superposition, if that whole period is what you're what you're seeing
is not infinitely thin, where you have to say was that was it this or was it that, if, if that time period of yourself is your self let is wide enough, then there might have been multiple different things going on and as far as you're concerned it is a superposition because
you can't cut it any further. Isn't that that what we're saying that there's a, you know whatever goes on within that minimal timeframe those are all superpositions but between timeframes, you've got to settle it was you know it was either this or that.
Yeah.
Yeah, if you think about any sort of model of, of an observed process.
Right, think of, think of digitizing what's going on in your laptop.
Right, we, we observed the laptop at the, you know, basically nanosecond scale.
We don't observe it at the femtosecond scale.
So, between those observations.
We don't care what happens.
We just think of these classical state transitions between effectively nanosecond wide slices.
And within, you know, with between those boundaries that we could look with our resolution.
We don't care some sort of quantum nonsense is going on but we don't care about that.
We don't care about the duration of the event we care about how many events are taking place during a duration that we integrate over to see them as one event.
Right, so even if there was a transistor interaction that one would only take a femtosecond be very much to care if it is affecting the thing that we are going to observe the nanosecond scale or on the second scale.
We didn't care about it theoretically the point that my point was just we can't care about it observation.
I just mean that it depends on how much energy you're moving in that femtosecond.
Right, so if that femtosecond is large enough to let your computer go up and smoke very much care.
That's true, but we can't localize it in time.
Yes.
We can't. I mean, we probably can if you really care so I imagine if you were to live in the universe where all the relevant events are happening in femtoseconds which seconds between to build computers you probably need to figure out equipment to deal with those femtoseconds.
Yeah, I mean if we were protons, then we naturally care about that time scale.
Maybe we are protons, we just forget.
So, have you read Italo Calvino's book Cosmic Comics.
Yeah, but long ago, long ago. It's wonderful. Yeah, he he tells us the story of the evolution of the universe from every point of view from that of a proton or something up.
I haven't I haven't seen it. So it's a wonderful very thin little book you can read it in an hour.
Amazing. So since okay since since since we got there.
Can we talk for a minute about your kind of your view on the status of the sort of smallest components.
What what can or should we say about the kind of how much of this kind of stuff, the sort of the the protocognitive kind of perspectives that we've been using how much of that applies at the at the lowest scale.
What can you say about particles versus their environment and so on.
Are you asking Chris or me. Let's start with you, Josh.
I suspect that the lowest level is not yet exerting interesting control but it's just mechanical in the same way as the vortex that emerges in the bathtub doesn't require intelligence to form it simply what's left over after you look at all the patterns and only retain those that are self propagating.
So it's basically some selection process them evolutionary process if you want that is selecting all the non error correcting patterns from reality.
And only those that are error correcting get to stay around with a certain probability.
And once they are over the threshold you can pretend that they're more less static for a given time and then you build structure above them.
So I suspect that at the lowest level, you don't have intelligence yet.
The intelligence only forms at the level that you have persistent particles that can be linked into symmetry breaking multi stable structures.
And then exploit make entropy gradients. So they're basically what life is doing it performs controlled chemical reactions that out compete dump chemical reactions.
And what's the, you know, give me a ballpark of what what do you think is the first slash simplest thing that was doing that.
That's a very tricky question. I think the smallest structure is the cell.
And it's not necessarily the simplest one because the cell is incredibly complicated. I could imagine that you have could have very, very large systems, say, storm systems on Jupiter, that wake up into general intelligence before the first cell
does because the first cell is so complicated I don't know what the assembly complexity of a cell really is how likely it is for this first cell to randomly emerge.
I could imagine that it's this probability is lower than the probability of a generally intelligent agent to emerge at much much larger scales, of course.
So, in a sense, I don't know whether you will find spontaneously formations of agency at the planetary scales.
You, of course, would miss from our sales and perspective.
But I think that it's probably impossible to build intelligence, simply only form elementary particles this at the subatomic scale, because atoms are the first level or molecules where you break symmetries.
What would you be looking for so let's say the Jupiter spot or something like that. What would you be looking for.
I think that the time scales on Jupiter would be so large that it's almost pointless to figure this out. Ultimately, you would need to simulate it over very, very long time spans.
And basically see the simulation deviates from in system that is energy optimizing in such a way that you need to assume that it has memory and is making models of the future to explain what you're observing.
Gotcha.
Interesting.
I agree that
one needs a certain amount of complexity.
To think about planning for the future.
I don't know where I wouldn't want to try to put a finger on where that complexity actually lives.
I think the kind of characteristic scale for say elementary particles not bound together in atoms that characteristic energy scale is very large.
And so what we at our scale and our observational capabilities call a particle.
Is it at that scale.
Some kind of complicated mess.
Right.
Think of drawing the first several orders of Feynman diagrams or something. There's a lot going on.
And
whether any of that stuff at its own scale could be
interacting with other entities like that at that scale.
It's hard for me to think about.
Certainly it's it's not something that we can observe with any technology that we have.
So we're
doing this business of
calling things objects
at a resolution that we can observe them.
And then building a theory that
maintains that sense of object hood.
Down to arbitrary scales.
And that theory is predictive of what we can observe at our scale.
But
I think it's more dangerous to say it's it's really describing what's going on at this at the scales that are really that are of interest there.
But certainly from the point of view of what can we observe.
What are the kinds of intelligence that
we can get a handle on.
Well there's some set of coupled pathways that are that are bounded in some way is probably the smallest entity that we can think about.
And maybe they're very large entities that have lower complexity.
Again the question is how would we observe such a thing.
There's some really interesting work with minimal matter so like droplets and
things like this that are only only a few chemicals but but they have some pretty rich behaviors and I think we need to we need to start developing
sets of sets of tools and you know kind of criteria for for because you know just just observations doesn't doesn't do the trick well obviously have to do some kind of perturbative experiments but we really need to start trying to understand it because
some certainly look like there's a lot of potential for finding some of these things and we need to we need a suite of tests that can start giving us a clue that that something like that is going on.
And the last the last set you know they were you know the running around a maze and they're coming together in in multi sort of you know in higher order structures, and I asked him how, how long did you have to search there.
It's a total of I believe three chemicals that they're made of, and I said how long did you have to search before before you found the chemicals that do this and he said it's basically the first thing I picked up off the shelf.
So, my guess is that it might not be super rare, this kind of thing.
And, you know, it might be it might be pretty natural but but it's unclear yet.
You know, I think I think the field the field of diverse intelligence still doesn't really have agreed upon criteria like what to look for in these kind of systems, even for the ones that are tractable I mean obviously you know, they talk about the
the economics markets in the spot of Jupiter in the cosmic web and all these things we can't do experiments there but but for some of these these minimal minimal active systems we can.
So, I think we need to.
Yeah, we need to settle on some some some experimental criteria.
No, that's very interesting.
But ultimately, you might have to resort to simulations where you try to figure out the behavior of a system from first principles, and then run the simulation to see how your observations deviate and identify criteria and which you need to ascribe more levels of control to the system that you're
observing.
Yeah, I mean we see this kind of very simple kinds of things in terms of going around barriers and you know kind of delayed gratification where it has to go backwards in the gradient in order to get gains later on and things like this in extremely simple systems.
You know that it's that that that emerges that capacity emerges in even very, you know we we studied it in simple sorting algorithms, you know this ability to go backwards to, to make gains later on you don't have to change anything you know very
simple algorithms have can have that those behaviors. So I think I think we're going to end up with a lot of surprises but we need to we need to start looking for that stuff.
Ideally, one would have a way of looking at the system's ability to operate on its own environment for its own future benefit in some way.
I mean in a sense with your algorithm experiments the environment is us.
Yeah.
Yeah, I mean I mean there are these very minimal.
There's a there's a system which actually kind of mimics what real cells do which is it put it constantly generates a self repellent.
And what that does is if you're traversing a maze and you end up at a dead end, you sort of sit there for a little bit but eventually the self repellent builds up and chases you out of there.
And in practical terms it means that you're never stuck in a dead end for you know for any length of time, it pulls you out of pulls you out of these, these kind of cul-de-sacs where you can't do anything else and it's super simple and you can say that what you've
done is you can, you can look at it as a as a stigmatic effect on the environment because you're basically dumped a bunch of messages that, you know, 10 minutes later are going to say, don't be here go go go somewhere else.
So it is it is a you know kind of a very weak version of niche construction from that in that in that sense.
Yeah, that sounds like a good limit to be pushing.
Well, anyway, it's how to build a self organizing system that is generally intelligence basically what is the, the minimal pattern for this colonizing seed that you observe in our own mind.
So basically I suspect that consciousness is an operator that induces coherence.
And I don't have a proper formalization for coherence that is properly tested.
And I suspect of it currently as minimization of constrained violations across models would think of it as a consensus algorithm that is forming in the mind and that is trying to find one interpretation where basically you maximize the number of simultaneously true statements in your
And out of this would fall the notion that there must be an observer that is in any act of observation but I suspect that the terminology of self reflectivity comes from the fact that consciousness to work needs to be self organizing and to do that it needs to be self stabilizing and
self observing.
And so basically I wonder what is this minimal self observing observer that keeps itself stable and is colonizing the environment what is the invariance and how can we formalize it in the substrate agnostic way.
You want the informational analog of a microbial mat.
No of an organism. I want to have something that is more than a biofilm I want something that imposes structure on itself maybe the microbial mat is the precursor.
Basically it's a sufficient substrate where you have self interested local notes that can attainable into performing the computations that you want.
And they actually are on their way to what you're talking about because in girl so else work he shows that to these some of these biofilms have very brain like potassium waves that ensure that the whole thing can eat.
It synchronizes right the metabolism across the network so that the ones on the outside don't get all the food and then the inside starts it starts it has this like large scale, these large scale potassium waves that look at me one of the papers was called you
brain like signaling and bacteria maps it's it's sort of on its way right it's kind of like they're working an organism. Yeah, yeah they're working up to a whole that's doing something different than the parts would do.
So what is holding systems back.
And right elephants are not able to be creative apparently they don't draw images they only replicate throwing stroke by stroke it seems.
Elephants despite having a long childhood do not achieve the same level of generality as we do is this the result of a need for tuning the system in a particular way that is tricky for evolution, or is there a Goldilocks size to brains that they can only integrate
information up to a certain scale deeply.
I don't know. The only thing I know about elephants is that we had we had a guest speaker once years ago that at my comfort in my seminar series where he said that he makes these giant xylophones and he drops them off in the forest of in the
jungle of I think Thailand he said for wild elephants, and he said that wild elephants when they come across these xylophones immediately figure out what the deal is and they start to play them.
And they just like I mean and I said is it good he said not the music's terrible but but but they like it and they you know and they will just not presumably not having heard it before they they like it and they just start to start playing so I don't know there's some kind of creative
why is it not good they have larger brains than us.
Well it's probably good for them. Exactly right that maybe you just don't like it. And I don't know I would suspect that what we consider to be good or not is not so much a question of cultural habits but it's the question of the sophistication of the structure that is being encoded.
Actually, that's interesting to there's all kinds of videos on YouTube where you can see some guy will take a violin out in the woods and just start playing it and all these wild animals come you know foxes will come and listen and you know these these wild animals will just come and listen I always thought that was really
interesting why why does it sound good to them to you know.
I mean I think part of the answer to your question could have to do just with the form of the body.
But we've, we've got these things that are really interesting.
And they don't.
They have a good good.
Pardon me. They have very good noses. Yeah, the elephant. Yeah, yeah.
So they basically have something that's almost as good as we do.
I mean, maybe that's an equally good toy for the brain to play with in its early development.
But I don't know.
Also people that go up without arms are not necessarily cognitively diminished.
They're growing up in a cognitively rich environment.
It's created by lots of other people for in the same way and build these models so basically the brains are evolved to discover this is we have sophistication and abstract modeling.
So under recently the elephant trunk requires babbling in the just just like, just like, you know, babies when they learn to use their arms at the beginning they have no control over it at the beginning just waves around, you know, crazy.
Eventually they get eventually they get some control over it.
But interesting, but interesting right not the legs. So, so the legs they stand up pretty early. So, so the legs are good to go almost almost immediately, but the one with a lot of degrees of freedom takes a while to get to get going.
