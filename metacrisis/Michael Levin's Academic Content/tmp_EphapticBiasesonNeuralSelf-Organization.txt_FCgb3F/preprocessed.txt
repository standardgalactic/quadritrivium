Yeah, thank you, Mike. It's an honor to be here. So as Mike already just said, I've been
introduced to and through Fred, my supervisor for my philosophy of cognitive science thesis
at the University of Fr√∂dinger with a bachelor's in psychology, a double bachelor together
with a philosophy of cognitive science degree. And now I went on to pursue a master in brain
and cognitive sciences and Amsterdam. We're now met Casper, again, who unfortunately can't
be here today, who had a nice little commentary, which I'll share with you later on whose ideas
we actually built this or built this project and presentation. So this is the content you
can expect today. So first, I'll start talking a bit about connectionism and its fixation on
basically cognition being encoded in synaptic weights and the problems associated with that. And
then I'll continue talking about if optic coupling itself, how electrical fields can
subtly align the phases of neural ensembles. Then I go on to talk about the interactions
between synaptic and if optic coupling, and in that way described by project idea and its
relevance for neural self organization. And finally, I'll be wrapping up with an outlook
also on how could this be relevant for morphogenesis or like non neural self organization or
broadly conceived and summarized. In particular, today, I want to also like give some time. This
won't be like a super long presentation. I want to give some time also for like a proper
discussion and some ideas because this is a disclaimer still in its relatively early stages
of the conception. So I'm happy about any kind of input. So first off, connectionism, I think
you will all be relatively familiar with that. I still like go over briefly, you know, the
basic, basically, all based around the mycolic pits and neuron idea that, yeah, the current
type about is based on that connections per time, weight tuning and backprop are sufficient
for sophisticated cognitive inference. And even the most modern architectures are still kind of
based on that foundational idea. And these, yeah, the rise of AI as we know it today, and
connections and go hand in hand. And, yeah, proponents, I mean, if we think about some
old man, basically calling for seven trillions of funding to collect enough GPUs to party
systems. Yeah, it's the do believe, in fact, that simply adding compute will bring us towards
API. Is there something we might be missing here? So just a little comparison here between
artificial neural networks and real neural networks. We have a global error signal in
artificial neural networks, whereas we have local error connection without backprop in real
neural networks. There we also have a genetic components, which, yeah, as I said, minimize
error locally, and make kind of seemingly a genetic decisions. Whereas we have, quote, quote,
done a passive components and artificial neural networks, which are simply being tweaked by the
last function. And also, they're no spacetime embedding, they're just quote, quote, living in
topological space. Whereas with real neural networks, they are embodied and are that way
also subject to the spatial temporal constraints of metric space. So why should we care about that?
Yeah, there was a physics paper that I have come in from a psychology background, barely
understand, and still mention it. You know, the that spacetime might be an error correcting code,
and Chris Fields made some really interesting ideas based based upon that.
Paper and also other kind of ideas that, yeah, it could be a computationally useful encoding in
this spatial temporal dimension, which could be crucial to cognition harnessing the dimensionalities,
the degrees of freedom that spacetime do give us. I want to show you like two little examples.
Just spiking neural networks will be the first one where basically neurons are modeled to have
as crucial time dependent membrane potential, usually modeled as like recurrent neural networks,
which exploit the spatial temporal dimension of data. So we see there in a diagram is like
basically signals coming in, stimulus is given and that's, you say digitized and sent to the,
I don't know whether you can see my cursor, but here I'm sent to the second neuron, which can
reconstruct given the temporal main, which is crucial, can reconstruct the stimulus relatively
accurately. This gives the advantage of computational efficiency, as well as the asynchronous
processing of inputs. We don't need to multiply it every time step, weights and input, but can
simply add it up. Huge speed up. And then as I mentioned before, I hear I'm going to reference
Hasan's paper we see here today. Weightless spiking neural networks, I found the idea pretty
fascinating. The more extreme explorers encode all information to be processed in
temporal delays. So get rid of weights and everything like all together and we can get
like kind of state-of-the-art performance on the endless task, despite the synaptic strength
of the transmitted signal being entirely omitted. So yeah, the synaptic encoding method was
probably problematic. Like why? Yeah, we mentioned what the role of I think metaphors in general,
here is is like in the past, we used to think of AI in the light of the brain and now AI and
the synaptic weight encoding I was talking about constraints on our conception potentially of the
brain. So if we actually do look at what is happening in the brain is that we do have a
high degree of synaptic overturn while maintaining an overall macroscopic pattern. So on the left
hand side, you see a mouse navigating through a maze and over days, the representations do drift
basically across neurons while the macroscopic pattern is maintained. So how could effective
coupling be relevant here? I'll be coming back to that in a second, but first I want to tell you
a bit more about effective coupling itself. So in that context, it just means like coupling
through neurons, a coupling of neurons that is field mediated. So when a neuron is somewhat
depolarizes, it creates a electromagnetic field surrounded and which travels at roughly around
like 0.1 meters per second due to the resistivity of the extracellular fluid. And that even when
synaptic communication is abolished as we can see there's barely any difference. So yeah, also
keep in mind now that the indulgence field strength of firing depolarizing neuron is about
five millibord per millimeter. So why has this been overlooked? Because to me when I did the
literature, you know, it does seem a bit like it's like you easily can go through the, not easily,
but quickly can get an overview at least of the relevant literature. Why is that bioelectric
part so neglecting comparison to the biochemical one? It's a first of all, it's very subtle impact
that the effective coupling has on the refunctioning because it is usually subthreshold. It's really,
yeah, in the point 1.2, sometimes microvolt range by which a neuron gets modulated. But what it is
important for though is for just aligning the signal to the induced phase. So what we see here
in the top row of the right diagram, we see when no field is applied, these neural bursts are kind
of like, more or less like randomly occurring. Now when the field is applied, we do see that
over time, it synchronizes to the phase of the applied field. And depending on how strong the
field is, of course, the modulation is stronger. The theoretical lower bound actually for these
network effects of point one millivolt per millimeter have been experimentally confirmed
in say one couple neurons in 2003. And yeah, that's really, again, keep in mind five millivolts
per millimeters is thought to be roughly in that range, the endogenous field strength.
And what's also important to mention is that it does not change the average firing rate of the
network, but it does change the temporal entrainment at the network level, which is if we look at the
lower left panel, really quite very strongly actually correlated the period of the field
that's applied to the network period that is then measured. So next I'm going to talk about,
you know, the relationship between the firing frequency and the effect. So what is to be said
is that the higher frequency, generally speaking, the lower the kind of spatial extent of the coupling
is and the lower the depolarization of the neighbors, we can see that here in the top right
hand corner where with increasing frequency on the x axis, we do see a smaller modulation,
but still non zero, even at like 100 hertz of the memory potential. And in that way,
gamma band and that will become relevant later. And why am I talking about gamma band effect
can have, sorry, does someone have a question? Or because I just heard something.
If not, I'll just continue. And yeah, so the in the gamma band, the effective coupling
can have still like especially widespread effect during a progressive entrainment,
despite having on the single neural level, barely noticeable effect.
So coming back to the problem of representational drift. There was a really interesting paper
released in 2023 by Pinosis and Miller at MIT called Beyond Dimension Reduction Stable Electric
Field Merge From and Allow Representational Drift, where they basically claim that these
the effective coupling can guide neural synchrony patterns. So maintaining being responsible for
that microscopic stability, while allowing still the the higher dimensional variable
neural activity. So kind of like acting as like God rails. And that was kind of like an open question,
you know, how it seems to be the circular effect of neural activity, producing electric field,
which in turn feedback has a feedback effect on neural activity itself and so on.
So if we look here at this sort of paper here from Anastasio from 2011, they kind of now
shifting a bit to like how do they interact, they kind of get to where we're going to go now
with our project is. So what they say basically is that the electric fields can change the
correlations in spiking between two synoptically connected neurons, and which kind of through
yeah, heavy emplacidity can affect the synoptic strength and have an indirect impact on synoptic
functioning. So that brings us to the question, how do synoptically mediated external signals
and faptic signals interact to shape spatial space, spatial temporal self-organization
in your own sounds quite a long question. So one second, I'll just give you a second. So
that brings us to the product proposal. So let me just explain what you see there on the right
hand side. So in the center, it's just like a sketch visualization. In the in the center,
you have to imagine like a neuron sending out a signal. And now we have signals traveling at
different speeds. So we have the if faptic signal in red, traveling at point one meters per second
roughly, diffusing through extra spatial space. And then we have the axonal signal right now,
it's circular, of course, it would be in reality, more directed, more direction, but that's that's
not the point. And then you see basically two two action potentials. So one is released now,
and now comes the second crosses where the blue signal, the fast signal kind of hatches up to
the to the fast to the slow diffusing, slowly diffusing red signal at a certain distance.
And if the firing frequency of the neuron is stable, we should expect that distance to
remain stable and have seen some kind of amplification effect at that distance. So
that is the kind of like the core idea. What is a bit more like a background reasoning kind of
behind it is, yeah, again, we have different kinds of speeds, these coinciding signals amplify
at that distance. So if you now overlay these like wavelet functions, that's here from the
paper from from Kospir, on the right hand side, which are just slightly altered, is you have
the source now in the middle and the left plot, you have the source emitting the signal in the
middle. And you have an exponentially decaying so very localized if optic signal, which at a
certain distance, again, given the firing frequency at a certain distance, correlates or
coincides with the axonal signal. And if you now do the extra step of placing additional sources
across the ring, which could maximize bi-directional synchrony, which is kind of like
imperative for neurons to in order to synchronize and kind of network,
you would get this kind of hexagonal like pattern, which seems pretty familiar from, yeah, cortical
from what we know about cortical computations. Important thing is so that there's a minimal
frequency required for the for a given faptic decay length, which is like in the low gamma band,
that yeah, the that's the if optic signal didn't yet decay when the next axonal signal is kind of
sent out. So it needs to be fast firing enough. One clarification question. The spiking signal
is only passing through the synapse and the axons, but the faptic signal is not really limited to
that medium, right? So it's spread all over the place. Yeah, exactly. It's uniformly spreading.
It's of course, and that's one of the questions I'll come to a bit later, is also there is some like
across branches, dendritic branches and so on. There's a kind of like a diffusion effect. It's
not quite as simple, but it's certainly it's more uniformly spreading in a circular kind of
manner throughout space. That's why I said that this this animation here was a bit misleading
because the blue signal should be directed and here it looks like it's uniformly spreading
through space. But that of course doesn't accord with what we know about how accidents
Yeah, good question. Thank you. Yes, so that brings us back to kind of like what was the
inspiration also for that commentary of Cusper's original paper that he talked about.
That was basically a question. How are cortical patterns forming and cortical patches forming
in the absence of external input prenatally, so during embryogenesis? There must be some kind of
biases that allow for cortical columns and so on already to emerge for this like ultra small world
structure to already emerge when there's not yet any external input for these patterns to become
attuned to. And yeah, so there's this imperative for for neurons to minimize the their energy
consumption while maximizing the synchrony with to basically becoming part in because
for instance, terms of inferring that they're part of an ensemble that is synchronized.
And yes, I said already there's equivalent to like free energy minimization as the
authors point out in that paper. So on the top right, you see kind of different instantiations
of like axonal of different kind of two different kind of cell types. So they simplify it a whole
lot. They propose different kinds of like alpha and beta cell types with different
like median axonal lengths and then being distributed in a small world kind of fashion
and then prune these networks for maximal synchrony and while reducing energy consumption
and what you get out of it. So if we look at the bottom at the bottom panel, we get these
yeah, these interweaving networks which interpenetrate at certain points and yet
have can allow for a kind of local within network within their frequency band computations.
And then the bottom right picture where they point towards is then that you can get all kinds
of stuff like ocular dominance columns and color pinwheels and all that fascinating
cortical structure out of this relatively simple physical process. But they propose basically
these like alpha and beta cell types, which are not necessarily like under proposal because
we propose that these like hexagonal structures do emerge and their structure is
fundamentally shaped by the firing frequency. So how should we investigate this? The methodology
follow this. So Franz was so kind to establish the contact there with Wesley, who I think can be
here today, who apparently has this Graves Max 2 setup in vitro setup with like really high fidelity
24 welds where we hope to be able to test all of this. So the idea is then to yeah,
experimentally target like a centrally possession neuron in like half the welds and just others
kind of as control and then have I mean just used like some some on the right hand side data,
which is not the data is not really relevant. I just superimposed this kind of pattern to
get to give you an idea of like okay, if we now in the center stimulate at a certain frequency
that's predetermined a neuron, we should expect these biases to influence how the networks form.
What kind of where do we see synchrony? Where do we expect to find an also effect of the
anti correlation specifically of these of these signals and make some predictions there about
yeah, the entrainment of these networks and in the long run also the long-term potentiation
and the dendritic growth. And yeah, then the idea is to alternate the these like training
phases where we induce the network with that with that given frequency and like rest phases
and monitor it over like a couple of days to see also how long term weather long-term
potentiation does happen. And yeah, we expect to find to find that these these anti or correlations
anti-correlations between the f-aptic and x external signal will bias apoptosis and dendritic
growth in the long run. So evidence that kind of is the justice of this idea is the following.
So first of all, it's been shown that electric fields do guide neural migrations,
which you see in the top right side. We see that they do align the the neurons to align
there dendrites with the electric field if it is imposed and the generally migration
tends to happen in line with the with the electric vector field. And yeah, then also an
important little piece of the puzzle is that the likelihood of survival for in between neurons
populations is like linearly associated with the firing frequency. That's the bottom right
panel there that the percentage of active cells in the neural population was predictive of how
many would survive three days later in a cell culture. So that means that these like gamma
firing neurons could in the absence of experience is also important and could could could form like
this experience independent backbone of neural computation formed by fast-firing sub-networks,
which was kind of like explored in a recent paper from von der Moelen et al.
where a gava A mediated inhibitory neurons are important for producing the global coupling
to localize that to to just a limited area. And how is this all relevant for maybe yeah.
Sorry, I have a question about the likelihood of the survival of the population associated with
the firing frequency. Is this like neuron also grown on the electrodes, on the Maxwell plates,
or on a normal dish? Exactly, it's exactly that same system that they're using. Okay, thank you.
Yeah, and yeah, then finally, the relevance for morphogenetic self-organization. I'm not an expert
in this and yet I feel like there's something to be said about this. So yeah, first of all,
also mainly through like a majorly through through Mike's work as well. It really has become clear
that electric gradients do guide pattern formation. If you look at plenarians and all these other
examples that you are pretty familiar with, they do guide the morphogenetic growth of various beings.
And also, what are some other like relevant examples? So the bidirectional synchrony could be
relevant for, as an example, the successful balancing of wind and the bone morphogenetic protein
during neural relation in order to close the neural tube successfully. If that is
disrupted in some kind of way, as we see it on the right hand side, the neural tube doesn't close
properly. And on the very right, you see just the example of the clock and wavefront model
of somitogenesis, which is really crucial also during embryogenesis to have proper segmentation
of the somites, where we have also a slow signal and a fast signal basically interacting
to yield morphogenetic outcomes. And that brings us now finally to the open questions and like
challenges and all this like to what extent do we find like similar mechanisms like basically
a one source sending out a slower and a faster signal simultaneously that interact with other
sources like around of them, which rely on the same kind of mechanisms to potentially terminate
morphogenetic growth, for example, or are in other ways relevant for developmental biology?
How can we transcend that to non neural cells that be really curious also to hear your group's
inputs there on this? And then another challenge is like the inhomogeneity of neurons that I
kind of alluded to earlier bit before. So what role does this like inhomogeneism,
morphology of neurons play in signal transmission? They here showed like in this paper by Ram
Anadel, which have this little illustration there, that in particular the apical dendrites were
polarized more than than the soma, which is something that you know, if we don't treat
like the in the writing work, the embryogenesis paper there, if we don't treat neurons just as
like point like, yeah, bodies, but actually take into account their complex extension and
aberration. That could significantly kind of like alter our outcomes and that is really something
to be taken into account, something to think about and discuss, I think. And then also the
simulation regime, like what would be kind of the optimal simulation regime that we could apply to
induce these like lasting network changes, and also how to avoid excitotoxicity. Yeah, these are
just like practical questions how to go about the experimental implementation of this. So as a summary,
we started out with the connectionist models, which neglect this like spatial temporal dimension,
and which actual neural networks and core information. We looked at if-aptic coupling and
the very subtle role that it plays, which really seems to be under-investigated, in my opinion,
and was even more so, and investing it as the interaction between synaptic and if-aptic
signals, which should bias according to our predictions then neuroplasticity towards
these hexagonal patterns. And yeah, maybe these, hopefully this proposed in-vitro experiment could
also be relevant in like shining some light on, yeah, sufficiently similar processes. Yeah,
where signal synergy is basically relevant, coinciding signals are relevant for more for
genesis. So, so references, and I first want to thank to my collaborators, Katharine Herez,
Franz, and also Ernst Koster, with whom we kind of like worked on these ideas together.
And yeah, thank you a lot for your attention.
