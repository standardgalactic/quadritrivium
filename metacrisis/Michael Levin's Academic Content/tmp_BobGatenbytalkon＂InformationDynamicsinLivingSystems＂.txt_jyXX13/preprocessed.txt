Yeah, well, thanks for inviting me.
This is not a cancer talk, although I am at the Cancer
Center.
Since I was about 16 and read a Scientific American
article on Maxwell's Demon, I have
been fascinated by information and information theory.
And so this is a bit of a sidelight.
And I work with Roy Frieden, who is an emeritus professor
at the University of Arizona.
And what I'm going to do here is I just
want to talk about three topics.
But the general theme is that living systems are unique
in nature, in that they use information
to maintain a stable low entropy state,
well, far from thermodynamic equilibrium.
And it's, again, a unique property of living systems.
So I want to really talk about three general topics.
How is genetic information converted
to this novel thermodynamic state?
Are the information dynamics in living systems
limited to heritable information in the genome?
And how is information transmitted?
And in particular, it's the current concept
of cytoplasmic diffusion of signaling molecules complete.
So just a brief background.
Crick first denunciated this central dogma of biology,
which is that all information is transferred from DNA to RNA.
And then the proteins.
And that once it gets to a protein, it cannot get out.
That's the end stage of the information transfer process.
Well, the central dogma does not say this explicitly.
Out of it comes a general sense that the nucleus, the genome,
is the center of all information processing
and all information transmission.
And therefore, the nucleus is sometimes
called the cell's command center.
And I've just given you some examples of this.
The nucleus is called the brain of the cell
because it holds the information needed
to conduct most of the cell's function.
This is on the right is from a textbook.
And you can see this idea of the control center of the cell.
And this is very anthropomorphic kind of view of things.
But this idea that the nucleus is kind of the brain of the cell.
And then standard biology is very gene-oriented.
And so all this information somehow
gets processed and moved from one gene to another.
And you have this very complex network of signals.
When you start to think of the reality of this, though,
I think things start to break down.
So on the right, you see this very complicated side,
which is just part of this information network
that occurs in cells.
And the idea is, for one of any other better mechanism,
all of this is driven by thermal motion.
So it's just to move at random and basically impact
each other.
Now, the problem is that the diffusion
is well-known to be both inefficient and wasteful
of time and energy.
And the question that I really started with
is, is this the best evolution to do?
And I have great faith in evolution.
And I think it's a constant optimization process.
And this does not look optimal to me.
So just consider a single pathway.
And this is the MAP-K pathway, which is well-known.
It's mutated at about 80% to 70% of cancers.
And just basically focus this on the right, the EGFR-weighted
binds to the receptor.
And then you get this MAP-K pathway
as it goes from RAS, RAF, MEK, and ERC,
and from there into the nucleus.
So this is called a transduction pathway.
But there's no clear physical mechanism for it.
So for example, when RAS is phosphorylated,
what they say is that RAS recruits RAF to the membrane.
RAF is free in the cytoplasm.
The word recruits has no physical meaning.
All they're saying is that it somehow
magically shows up there.
But there's no physical process that is evoked for that.
The other thing is that these are not drawn to sale.
This looks like it's just a very quick hop,
skip and jump between the cell membrane and nucleus,
when in fact, it's about 1,000 protein diameters.
And there's also a tremendous variation
in the availability of these ions.
This is the relative concentration
of the different components of the MAP-K pathway.
So it seems to me that this is an amplifier.
It's amplifying the message of the ligand binding.
But the diffusion part of this is inevitably
going to be great temporal and spatial information
regarding the location and time of the ligand binding.
So this is a great quote, which I love.
A drunk man will find his way home,
but a drunk bird may get lost forever.
And this is really a reference to the problem
of three-dimensional diffusion.
And we've done modeling of this and looked
at how a signaling molecule would leave the inner surface
of the cell membrane and how it would get to the nucleus.
And in fact, it's a tremendous variation over time and space.
So it's nothing like this kind of direct motion
that they like to show in the textbooks.
Now, biologists like to do this.
And they say, if you go from point A to B,
you take that distance and divide it
by the diffusion coefficient.
And they'll say, see, it'll take 4 1‚ÅÑ10 of a second
to get there.
But of course, that's incorrect use
of the diffusion coefficient.
In fact, it's a random walk.
And it is nowhere near that.
I mean, it could be that fast if every step of the way
went in the same direction.
But that's incredibly improbable.
So I think there's a tendency to ignore this and to use
this kind of diffusion coefficient incorrectly.
And I think that this is not going to occur.
And I think this is a significant problem
to understanding how the cell efficiently goes
about obtaining, processing, and responding
to information in this environment.
So the first thing I'm going to do
is really just to move an aside and talk
about the information in the genome, which is commonly
calculated as Shannon information.
And the question is, how does the Shannon information
in the nucleotide sequence produce a low entropy state
far from thermodynamically equilibrium?
Now, the limitations of the Shannon information
are well known.
And while it can calculate the sort of number
of bits of information, it cannot tell you anything
about the meaning or the underlying information
value, as we pointed out here.
You can say the wall is blue.
You can say the wall is on fire.
They might have the same amount of number of bits
of information, but their meaning and their significance
are very much different.
Land hours limit, though, does provide boundary conditions
because it basically can give you
a estimate of the maximum amount of information
or the maximum amount of energy required
to erase information.
And this has been a done deal, as far as I was concerned.
But there have been some articles published in Nature
that have confirmed this limit.
But I learned from a physics friend recently
that this is, in fact, still a highly controversial concept.
So how do we think about the way of going from information
in the genome to the thermodynamic state of the cell?
And in doing this, we're kind of focused
on the role of enzymes.
Because in non-biological systems,
the reaction rate of any chemical reaction
is described by the Arrhenius equation,
and it's essentially related to the temperature.
In general, the reaction rate increases
as the temperature increases.
The temperatures also link to entropy
through the Boltzmann microstates.
In general, the number of microstates
increases as the temperature increases,
and therefore the entropy tends to increase as well.
But living systems need to accelerate reactions
for optimal fitness, but are constrained
to a narrow temperature range.
So they have to come up with a solution for that,
and that's, of course, enzymes.
So how does this work?
So the enzyme is a protein encoded in the DNA,
and so it results in a string of amino acids.
But these then fold into a low energy state,
and it's that physical confirmation
that allows it to interact with substrate.
And because of that, you can now take the Shannon information
and convert it to Kullback-Webord divergence, which
is really a measure of the spatial matching of the products
or the substrate and the reaction.
But Kullback-Webord is a version of the Shannon information,
so we've converted it to that.
And then from information to thermodynamics.
Now, I've been told by many people that enzymes actually,
they just take the two different products
and bang them together.
Consistent with the concept that the energy of the reactants
of hitting each other is the primary determinant
of whether reaction will proceed.
But in fact, the general opinion is
that enzymes accelerate physical reactions
through a quantum mechanism so that they superimpose
their wave functions in a way that Paul described
as an enhanced transition state.
And so most simply then, the information content
of the enzyme is translated into a thermodynamic energy
by the reduction in the activation energy.
So this is the conceptual model that
is used, the actual activation energy now is lower,
and that's what controls the reaction rate and can accelerate.
The proposal that we've made is that information and enzymes
act really from the bottom up.
We tend to think about the link between thermodynamics
and molecular state pop down.
In other words, you raise the temperature
and the Boltzmann distribution changes.
We propose that enzymes act in the opposite direction.
They actually optimize interactions
at a quantum level that allow the reactions to proceed.
And in the process, change the Boltzmann distribution
of the substrate and the reactants.
Remember that the enzymes can accelerate reactions
up to 15 orders of magnitude.
It's an astonishing number.
And so they can produce a Boltzmann state in which,
essentially, you've consumed the reactants and nothing
but products so that it's a different.
So you have fewer micro states than you
had when it was in equilibrium.
And so here is out of equilibrium state.
It acts as though the temperature is higher.
It produces a Boltzmann distribution
as though the temperature was greater.
And yet it is actually a thermodynamic and unequilibrium
state.
So this, we think, is at least a mechanism
by which genetic information can be transmitted
into the thermodynamic state of the system.
So we start again.
I'll just kind of go through this again.
We started a living system with a temperature
and a certain number of micro states.
If you gave the heat, if you added temperature,
you could increase the temperature
and also increase the number of micro states.
In contrast, an enzyme does not change the temperature.
You could radiate the heat from the reaction
into the environment.
But it does change the number of micro states.
And so there is this.
You may have the same micro state levels
in the two different systems here,
but they will be at a different temperature.
And that's that kind of thermodynamic instability
or thermodynamic non-equilibrium state
that we, I think, talk about.
So topic two is all biological information in the genome.
And I like to give a kind of a story behind this.
Several years ago, as the human genome was being deciphered
and it was known that it was going to be published soon,
GeneSuite was a betting pool that developed
among scientists throughout the world.
And they would each put money down
and they would bet on the number of genes
that were going to be determined by the size that were ongoing.
And the results were very interesting.
There were over 400 scientists that participated.
The average estimate of the genes was 66,000
with a range of 26,000 to 310,000.
Basically, nobody won.
Not a single participant was correct.
In fact, the human genome is about 19,000 genes,
fewer than mycens worms in some cases.
And David Baltimore, this is a quote from about that time,
was very clear.
Unless the human genome contains a lot of genes
that are opaque to our computers,
it is clear that we do not gain our undoubted complexity
of the worms and plants by using more genes.
I think it's currently basically dealt with by ignoring it.
There is kind of a vague sense that somehow our genes do
more than their genes.
And that the complexity of our interaction networks
is somehow makes up for the relatively small number
of genes.
But I think there is another way to think about this.
In the 1950s, Morowitz, who was a biophysicist at Yale,
used two different methods to calculate the information
content of E. coli.
And both of them yielded about the same number, about 2 times
10 to the 11 bits.
Now, he didn't have any knowledge of the E. coli genome
at the time, but it has since been deciphered.
And it contains about 10 to the 7 bits.
Forward is a magnitude lower than its total content.
Now, you can add all of the products of the genome,
so mRNA and proteins.
And those are also known.
But you still cannot get past 3.4 times 10 to the 9 bits.
In other words, this is a small percentage
of the total information content of the cell itself.
So where is all that information?
And basically, it's the membrane.
There are two things about the membrane.
One is that the membrane, although it's always
listed as kind of this monotonous lipid bilayer,
in fact, contains a large number of additional lipids,
it's 200 or so.
And so the membranes themselves are carefully regulated.
And this represents a substantial potential information.
But most information, again, just by Shannon calculation,
is in the transmembrane ion gradients.
And I'm just showing you these here.
And essentially, the membrane pumps out
sodium and in potassium, the chloride levels
are much lower as well as multiple other ions.
And about 30% to 40% of the cell's energy budget
is used to maintain this transmembrane gradient.
And so the question is, why does the cell
use so much energy to generate this transmembrane ion gradient?
It would seem likely that in the old Watergate thing,
they talked about follow the money.
I think that in living systems, you can follow the energy.
And that can tell you a great deal about what's important,
what's not.
So how does the cell use this information?
And so my thought is that the transmembrane ion pumps
that are used and consume a great deal of the energy
are essentially Maxwell's demons.
They are separating ions between the inside and outside
of the cell using energy, but in the process,
making this large transmembrane gradient and maintaining it.
Now, why would you do that?
And my thought was that in addition to the membrane
to the Maxwell's demon, there could be Maxwell's angels.
And these are now transmembrane gates,
transmembrane pores that have gates.
And those gates are open or closed
depending upon information being received at that gate.
So in this case, an angel is looking out, essentially,
getting information from the environment
and opening the different gates, allowing very specific ion
flows along concentration gradients either in or out
of the cell.
So that over time, you can assume that the right is
the intracellular component.
Now, you see this kind of puff of ions coming in
from the outside, actually going in both directions,
creating a local variation in ion concentrations
over time and space.
And how does this work?
So the other thing that tends to not be noticed a lot
is that peripheral membrane proteins
tend to be highly dependent on local cation concentrations
so that they may turn on or off depending
on whether sodium or potassium is
the dominant local cation.
And the reason for this is, at least in part,
because potassium and sodium have the same charge
but are very different in size.
So as you, for example, as they form counter ions
to the negative charges in a pocket, an enzyme pocket,
the enzyme itself can change, that pocket
can change in its shape based on which ion is involved.
And there are others as well.
And so there's two things about this.
One is that the fluctuation in ions
can change the function of peripheral membrane proteins.
They can also change the location.
And the reason is that the interweave of the cell membrane
is typically negatively charged.
And these are going to have a large number of potassium
counter ions, so the biolink will be very small.
If you get a local flux, for example,
of the potassium out of the cell, in that region,
you will at least briefly have a reduction in the cation
shielding of these negative charges,
allowing movement of, let's say, positively charged
macromolecules to the level of the membrane.
And I mentioned, for example, this idea that RAF recruits
RAFs to the membrane, that kind of observation
that people have made, that when KRAF is negatively
charged with phosphorylidations, that you get this rapid movement
of RAF toward it.
It turns out that these ion pores are associated
with EGFR Wiggins.
And when the EGFR Wiggins binds, it
will often open these gates.
And so you could imagine that a flux outward of potassium
could unshield some of the local negative charges.
RAF is carried on a macromolecule that has a large number
of positive charges.
And so this could actually provide a biofiscal mechanism
to allow this kind of rapid movement of certain molecules
to the site of EGFR Wiggins binding.
And so this should probably look familiar,
because it's very much what Hodgkin-Huxley equations
talk about, that these gated ion channels open and close.
And so we propose that the Hodgkin-Huxley dynamics are
really a specialized manifestation of information
processing at the membrane that occurs in all epithelial cells.
And in fact, we could take the dynamics of these fluxes
of ions across the membrane that we think
occur in epithelial cells, and from those information
dynamics derive the Hodgkin-Huxley equations
from first principles.
And then the final thing I'd like to talk about then
is just how is information processed?
If you think about the nucleus as the brain of the cell,
so it's the central process of this idea
that information comes from the cell membrane,
goes to the nucleus, the nucleus kind of processes it,
decides what to do, and then sends information back
to the other points of the cell to act.
This is a very long process.
And that requires diffusion going in two directions.
And it seems that for something that
requires immediate action, that would not
be something the cell could do, that there
needs to be, I think, a more distributive system.
And so the idea here is where this could,
a clear potential distribution system for information
is the cytoskeleton.
The microtubules and microfilaments
are distributed throughout the cell.
And it turns out that they can transmit both electrons
and ions very rapidly.
And so these, in fact, have been described
as electrical nanowires.
And so this transmission is a potential circuit
for very rapid communication.
And you can see the distribution of the microfilaments
and microtubules that really kind of occupy a lot of the cell.
It is very dynamic state.
And so where do they go?
So the microtubules typically converge
on the central cell, which itself is deeply integrated
into the nuclear membrane.
And microtubules, I'm sorry, microfilaments themselves
also tend to interact with components
of the nuclear membrane, which are
known to have roles in terms of both gene transcription
and chromosomal organization.
And so the thought was that this is then
sort of widely distributed network.
And so this is kind of a crude proposal
for how this might work.
When you see the, to connect this with the transmembrane
flow of ions, if there is a small perturbation in which
there is just a few local ion channels that
open and close, those will be very
transient and will be dealt with strictly
by the peripheral membrane proteins.
However, in a perturbation that is either longer or more
extensive, you will then get really widespread fluxes
in the peripheral membrane, in the ion concentrations
in the periphery, which can then potentially
allow for fluxes of ions across the either microtubules
or microfilaments.
In the case of microtubules, which are much larger,
but 40 nanometers or so, this would
allow for relatively coarse grain information to pass.
And the microfilaments, which are about four nanometers
in diameter, though, could actually
have quantum level interactions going on.
And there's a number of physicists
that have been quite interested in whether that
plays a significant role in living systems.
So with that, I think that just to summarize,
I think genetic information, which
can be analyzed in the form of enzyme,
can direct the thermodynamic state of the cell
through a bottom-up approach using quantum interactions
to accelerate reaction rates, which then
alter the Boltzmann distribution,
changing the thermodynamic state that
is without explicit influx of heat or change in temperature,
therefore, a non-equilibrium state.
I think genetic information is the terrible component
of a much broader ensemble of cellular information
dynamics that occur primarily in and around membranes.
Now, remember that, although I've been talking
about the cell membrane, the plasma membrane,
that all the organelles in the cell
have membranes, mitochondria, the interplastic
in particular, nuclear membrane.
All of those also have transmembrane ion
potentials, which could contribute
to this kind of dynamics.
And so the idea, rather than the nucleus
as being the head of the cell or the processor of the cell,
we really think about the information dynamics of cells
as a distributed network, so that essentially all
of the membranes of the cell are contributing
to these interactions.
Where I think then that is important
is that if the genetic information is simply
providing the capability of producing transmembrane
gradients, the interactions between cells
and the interactions that form multicellular organisms
and multicellular tissue largely occur at the membrane level.
And hence, the observation that the human genome
is smaller than the genome of multiple other seemingly
lesser complex organisms misses the point
that the complexity doesn't occur from the genome.
It occurs at the level of the membrane
to membrane interactions.
I think that information, though,
has to be transmitted efficiently and quickly.
And I think that the cytoskeleton
represents a mode of communication that's not
dependent on diffusion and can be far more rapid than what
we expected and can't even include quantum interactions.
And then let's see.
So here is, rather than nucleus as a central processor,
I think the nucleus is simply one component of a broader
and more integrated information system.
And this is kind of the end of this,
is that the multicellular complexity is only loosely
related to genome size.
Rather, the genome generates the natural demons necessary
for these gradients.
But the complexity comes from the information
exchanged between cells through these membrane-based dynamics.
And so with that, I thank you.
