Yeah, well, thanks for inviting me.
This is not a cancer talk, although I am at the Cancer
Center.
Since I was about 16 and read a Scientific American
article on Maxwell's Demon, I have
been fascinated by information and information theory.
And so this is a bit of a sidelight.
And I work with Roy Frieden, who is an emeritus professor
at the University of Arizona.
And what I'm going to do here is I just
want to talk about three topics.
But the general theme is that living systems are unique
in nature, in that they use information
to maintain a stable low entropy state,
well, far from thermodynamic equilibrium.
And it's, again, a unique property of living systems.
So I want to really talk about three general topics.
How is genetic information converted
to this novel thermodynamic state?
Are the information dynamics in living systems
limited to heritable information in the genome?
And how is information transmitted?
And in particular, it's the current concept
of cytoplasmic diffusion of signaling molecules complete.
So just a brief background.
Crick first denunciated this central dogma of biology,
which is that all information is transferred from DNA to RNA.
And then the proteins.
And that once it gets to a protein, it cannot get out.
That's the end stage of the information transfer process.
Well, the central dogma does not say this explicitly.
Out of it comes a general sense that the nucleus, the genome,
is the center of all information processing
and all information transmission.
And therefore, the nucleus is sometimes
called the cell's command center.
And I've just given you some examples of this.
The nucleus is called the brain of the cell
because it holds the information needed
to conduct most of the cell's function.
This is on the right is from a textbook.
And you can see this idea of the control center of the cell.
And this is very anthropomorphic kind of view of things.
But this idea that the nucleus is kind of the brain of the cell.
And then standard biology is very gene-oriented.
And so all this information somehow
gets processed and moved from one gene to another.
And you have this very complex network of signals.
When you start to think of the reality of this, though,
I think things start to break down.
So on the right, you see this very complicated side,
which is just part of this information network
that occurs in cells.
And the idea is, for one of any other better mechanism,
all of this is driven by thermal motion.
So it's just to move at random and basically impact
each other.
Now, the problem is that the diffusion
is well-known to be both inefficient and wasteful
of time and energy.
And the question that I really started with
is, is this the best evolution to do?
And I have great faith in evolution.
And I think it's a constant optimization process.
And this does not look optimal to me.
So just consider a single pathway.
And this is the MAP-K pathway, which is well-known.
It's mutated at about 80% to 70% of cancers.
And just basically focus this on the right, the EGFR-weighted
binds to the receptor.
And then you get this MAP-K pathway
as it goes from RAS, RAF, MEK, and ERC,
and from there into the nucleus.
So this is called a transduction pathway.
But there's no clear physical mechanism for it.
So for example, when RAS is phosphorylated,
what they say is that RAS recruits RAF to the membrane.
RAF is free in the cytoplasm.
The word recruits has no physical meaning.
All they're saying is that it somehow
magically shows up there.
But there's no physical process that is evoked for that.
The other thing is that these are not drawn to sale.
This looks like it's just a very quick hop,
skip and jump between the cell membrane and nucleus,
when in fact, it's about 1,000 protein diameters.
And there's also a tremendous variation
in the availability of these ions.
This is the relative concentration
of the different components of the MAP-K pathway.
So it seems to me that this is an amplifier.
It's amplifying the message of the ligand binding.
But the diffusion part of this is inevitably
going to be great temporal and spatial information
regarding the location and time of the ligand binding.
So this is a great quote, which I love.
A drunk man will find his way home,
but a drunk bird may get lost forever.
And this is really a reference to the problem
of three-dimensional diffusion.
And we've done modeling of this and looked
at how a signaling molecule would leave the inner surface
of the cell membrane and how it would get to the nucleus.
And in fact, it's a tremendous variation over time and space.
So it's nothing like this kind of direct motion
that they like to show in the textbooks.
Now, biologists like to do this.
And they say, if you go from point A to B,
you take that distance and divide it
by the diffusion coefficient.
And they'll say, see, it'll take 4 1‚ÅÑ10 of a second
to get there.
But of course, that's incorrect use
of the diffusion coefficient.
In fact, it's a random walk.
And it is nowhere near that.
I mean, it could be that fast if every step of the way
went in the same direction.
But that's incredibly improbable.
So I think there's a tendency to ignore this and to use
this kind of diffusion coefficient incorrectly.
And I think that this is not going to occur.
And I think this is a significant problem
to understanding how the cell efficiently goes
about obtaining, processing, and responding
to information in this environment.
So the first thing I'm going to do
is really just to move an aside and talk
about the information in the genome, which is commonly
calculated as Shannon information.
And the question is, how does the Shannon information
in the nucleotide sequence produce a low entropy state
far from thermodynamically equilibrium?
Now, the limitations of the Shannon information
are well known.
And while it can calculate the sort of number
of bits of information, it cannot tell you anything
about the meaning or the underlying information
value, as we pointed out here.
You can say the wall is blue.
You can say the wall is on fire.
They might have the same amount of number of bits
of information, but their meaning and their significance
are very much different.
Land hours limit, though, does provide boundary conditions
because it basically can give you
a estimate of the maximum amount of information
or the maximum amount of energy required
to erase information.
And this has been a done deal, as far as I was concerned.
But there have been some articles published in Nature
that have confirmed this limit.
But I learned from a physics friend recently
that this is, in fact, still a highly controversial concept.
So how do we think about the way of going from information
in the genome to the thermodynamic state of the cell?
And in doing this, we're kind of focused
on the role of enzymes.
Because in non-biological systems,
the reaction rate of any chemical reaction
is described by the Arrhenius equation,
and it's essentially related to the temperature.
In general, the reaction rate increases
as the temperature increases.
The temperatures also link to entropy
through the Boltzmann microstates.
In general, the number of microstates
increases as the temperature increases,
and therefore the entropy tends to increase as well.
But living systems need to accelerate reactions
for optimal fitness, but are constrained
to a narrow temperature range.
So they have to come up with a solution for that,
and that's, of course, enzymes.
So how does this work?
So the enzyme is a protein encoded in the DNA,
and so it results in a string of amino acids.
But these then fold into a low energy state,
and it's that physical confirmation
that allows it to interact with substrate.
And because of that, you can now take the Shannon information
and convert it to Kullback-Webord divergence, which
is really a measure of the spatial matching of the products
or the substrate and the reaction.
But Kullback-Webord is a version of the Shannon information,
so we've converted it to that.
And then from information to thermodynamics.
Now, I've been told by many people that enzymes actually,
they just take the two different products
and bang them together.
Consistent with the concept that the energy of the reactants
of hitting each other is the primary determinant
of whether reaction will proceed.
But in fact, the general opinion is
that enzymes accelerate physical reactions
through a quantum mechanism so that they superimpose
their wave functions in a way that Paul described
as an enhanced transition state.
And so most simply then, the information content
of the enzyme is translated into a thermodynamic energy
