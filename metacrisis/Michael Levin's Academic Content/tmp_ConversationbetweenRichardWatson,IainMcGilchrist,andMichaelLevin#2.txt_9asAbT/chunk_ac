there are different, what he calls structures, he calls the distinction he's making
between architective structures and connective structures, and what he means by architective
structures are things that are relatively rigid and static, and when they change,
when they make a change, they make a complete change, and it's exactly where it is a cataclysm,
and there are things that are connected that change by means of flowing change,
and they are more, I mean, I don't know which bits of my book you've had the chance to catch up
with, and I'm extraordinary grateful for being able to, I can't remember what I said, but
in another section on induction and deduction? Okay, yes, yes, that was because of what you
said about that, but yes. But anyway, I think this is an issue of the difference between concatenation
and flow is absolutely essential, and these types of motion where things flow from one
state into another, and these architective states which hold themselves until there's a
break, and they're rather like what Taleb calls fragile states, and the connected ones are
anti-fragile, they make adaptations all the time so that they don't have that cataclysmic
need to change, and the reason I'm mentioning all this is that he suggests that at the very
lowest level, and particularly at the very highest level of magnitude, you only find
connected states, and that the architective states are found more at the intermediate phase
where we happen to be leading our lives and have our experience. I've probably given a very
bad account of that, but I do a better job in the book. Thank you. Whose terms were those,
architective and connective? There are now retired physicists called Mike Abramovich,
but he has a very interesting web, and we've corresponded, and so there we are. That makes a
lot of sense to me, so there's a sense in which the rock in your garden can respond to things
quickly, like if you kick it, it moves, you hit it with a hammer and it moves a little bit,
it moves a little bit across the garden, and in a sense that's a response to the force that's
acted on it, but then the architective structure, if I can use that term already,
isn't changed. It's still the same rock, it's just over here, instead of over there,
it didn't really change its relationship to anything, and so doing it in it didn't change
its internal organization or connective structure in response to that being
hit with a hammer. But there are the minimal example of a physical system
that I've been thinking about recently that has some connection between scales
is resonance in systems that resonate. So like in a tuning fork or a piece of steel,
when you hit that, it doesn't just move, it doesn't just transfer the impulse and say,
well okay, I'll be over here, but when you hit it and it rings, there is a really intimate
connection between the macroscale geometry of the fork as a whole and a micro-scale elasticity
of the molecules of steel holding it together, and one needs an integer multiple of the other
in order for you to get a resonant standing wave in that geometry, and there's an intimate
connection between the whole organizing the parts and the parts organizing the whole,
and I don't think it's any coincidence that we say that the ringing of a bell
feels organic or has lifelike structured to it. I think that's because of its resonance,
and I think this idea of resonance reverberative connectivity is essential to the understanding
of, well, just about everything, but certainly living things. What I think I may have misled you
by saying is what he's referring to is that there are certain kinds of things which are like
chemical inter-offic for the constituent. They lose their qualities completely and become
something else, so an evil smelling greenish yellow gas mixes with some dull metal and it
becomes table salt, and as it were, they've lost what they had before. This is architective change,
he says, but there are other things that mix with one another, add themselves to things,
and work by accretive processes where their existence is not a zero something, they have
to go and something else comes. They are able to cause something to create a bigger
entity out of the smaller elements that will come together, and I think it's all really that one
needs to take on board for that point, I don't want to labor it, but it just seems to be quite
interesting that he spots that that catastrophic scale is above the scale of particles in physics,
but is below the scale of the cosmos, and then the cosmos and in the very subatomic regions,
what you see is not cataclysms in which one thing is wiped out and changes its nature completely,
but that things come together and create as they do in the wider cosmos, it would create
something new, but it's not catastrophic for the constituent parts. Yeah, I get it, I get it.
So the music metaphor for me is when you put two notes together and they're concordant,
both the notes are still there and they created something new, they created the interval.
Yeah, when you put two notes together which are discordant and they just crash,
and it seems to tear apart the two notes that you had.
Yes, that's a good metaphor, but what an extraordinary thing it is that by putting two
completely meaningless bland things together, a note and another note, you suddenly create an event
and an experience, and the more you add, you can do things that are
completely unpredictable from the outside, you can only know them when you hear them.
Yes,
Yes, you can't tell, so when if I give you 469 hertz and 468.9 hertz,
you cannot tell the difference between those separately, played separately, right?
But when I play them together, you can hear the beat, you can hear the beating as they go in and
out of phase. There was something, I'd like to return to the possibility of the hybrids and cyborgs
that Mike was talking about, and what we were just talking about about whether there's multiple
scales involved in the dynamics or the system or the algorithm that's running.
So in computer science, we have this notion of an algorithm being substrate independent
that you can implement the same algorithm in multiple different substrates and it just doesn't
matter because the details of the substrate that you implemented it on just don't matter to the
essentially symbolic and discreet computation that you're doing at the higher level, right?
It was all syntax and no semantics. Right, so by divorcing it of all of the concrete details
of the instances, you get something that you can apply to other instances, you get the generalization,
right? You get, oh, it's the same one, not yet. But you lose that connection to the concrete
instances in a way that the symbols that you're manipulating don't have any meaning,
right? If you treat them abstractly, then they are, as you said, pulled out of
their context in which they had some meaning. So that notion of the substrate independence of
algorithms suggests that you could replace part of an organism with a machine or part of a machine
with an organism and it wouldn't really matter or you would create something that was in between.
But I'm not so sure about that. I think that when we implement an algorithm on a machine in a
conventional sense, we are doing so in a way which is as divorced as possible from the physical
implementation of it so that it doesn't matter what numbers I put into my sorting algorithm,
it never makes my logic gates overheat, right? That getting to the physics of what I implemented
on just doesn't matter, like whatever computation I do on it just doesn't interact with the physical
implementation. But in organisms, it's not just that it does interact with the physical
implementation but that they are organisms because it interacts with the implementation.
So you can get an organism to behave like an AND gate if you put it in the right circumstances
but when you make it do it over and over again, it says fuck this and it crawls out of the dish
and does something else, right? The interaction with the substrate of which it is made matters
and it matters not just because it's an unreliable algorithm then, it wasn't perfectly
abstracted, that wasn't really a good way of implementing an AND gate then. That was the
thing that made it organic was that when you stress one level of function, the
implementational level of function below it begins to show, it begins to show through.
And that's really important for being able to get those responses that you were talking about,
a quick response is by reorganizing the function. It's like, okay, well, I won't do that function
then I'll do this function, right? And a lot of the higher level and lower level integrity,
the higher level and lower level structure is still there but it's been reorganized.
Whereas when you do that with a mechanical device and you push it beyond its limits,
well, first of all, when you push it beyond its limits, it doesn't show you the in-between states
and you need the in-between states because it can't really be adaptive, it can't really learn
unless it's inside show. And when it's inside do show, you just say, oh, shit, I broke it,
right? Because it doesn't degrade gracefully because you went straight from this really,
really high level symbolic stuff to the physics it was made out of, multiple levels below.
And that means that when the insides do show, it just breaks, it doesn't degrade gracefully.
Hmm.
I think, yes, I don't know enough about the systems that you're working with, really, but how they
would, how they would, could be adapted to the way a plant takes in 15 kinds of measures and
synthesizes them and as it were, makes a decision about whether or not it's time to
bud or flower or whatever it may be. I'm sure you could find algorithms that could
make an artificial flower do something like this but I don't know that it would be
anything at all like the flower. I don't know. Yeah, it's like, I'm not a cyberneticist. So, yeah.
How the flower behaves under normal circumstances could probably be extracted into such an algorithm
involving 15 variables in a bit of logic. But what's really interesting about the flower is
what it does when you put it under circumstances that are not quite like that, right? When,
you know, when Mike does an experiment and says, you know, cuts it in half when it was
half, only half when it was just a seedling, how many plants do you get, right? And that's,
you know, now it's making two decisions. This one is deciding differently from that one. How
did it make two, how can, how can one thing make two decisions, right? It's like, because,
that's right. And also, again, correct me if I'm wrong, but I think this situation,
sounds different from the execution of an algorithm where, and I described this in one of the
chapters, but effectively, Monica Galliano has done experiments with pea shoots where they're
deprived of light and the light comes on in a Y shaped structure that is over the bed in which
they are. And it comes on in one or other arm of the Y, entirely at random. So you can't predict
each time which it will be, but sometime before the light comes on, a puff of air is sent down the
arm of the tube out of which the light is going to come. And these pea shoots of the staff of light
benefit from orientating themselves towards where the light is coming from. And I believe that in
only three days they learn to orientate towards where the puffs of light are coming from, puffs
of air are coming from, because that's where the light will come from. And intriguingly, the
reverse case has also been done as a control in which the puff of air comes down the arm
from which the light will not come and the pea shoots appropriately in the other, again,
within a few days learn. Now, that's not something they could conceivably have been,
as it were, programmed by either from their own experience or from any past historical
experience. This seems like intelligent behavior. Yeah, I don't have any problem with that.
Mike's not surprised, right? No, I'm not surprised. Yeah. And I think what we were just
saying about, you don't see what it can do until you stress it is 100%. I mean, this is why
this is one reason why teleology, it's not the biggest reason, but one reason why people aren't
into it is because what they observe most of the time is the default behavior, let's say, of embryos.
And they think it's a purely feedforward emergent system. They say, oh, complexity in
emergence, right? So local rules, we know local rules can give rise to complexity. And look,
it does this thing. Well, there you go. So, and they said, well, you can't just label that as
intelligence, you know, it's like, it's, it's just, it's just, that's what it has to do. And,
and that's true. If all you do is observe the standard default behavior, but once you start
putting barriers in its way, and you start stressing it in various ways, then, then you,
you get pulled out of this false sense of inevitability. And you see that, oh, it actually,
it actually has what some degree, depending on what you're looking at, of what James called
intelligence, which is the ability to reach the same goal, different means. And you start to see
the incredible ingenuity that these things can muster in different problem spaces.
Okay. I apologize. I have to, I have to run. Can we
