Thank you very much for inviting me.
My own research has always been about how a human mind works and that's why I entered
academia in the first place and studied several fields and found that I did not get that much
out of the way in which psychology works today and also I found that neuroscience, for some
reason, didn't seem to make a lot of progress and was quite uncurious about how minds work,
what consciousness actually is and how it relates to the processes that are implemented and I also
found that psychology is largely a history of ideas, philosophy is largely a history of ideas and
that I could make the most practical progress on this cognitive science project in the context
of artificial intelligence and artificial intelligence is of course mostly automating
data processing and in the current moment it's mostly machine learning, mostly deep learning
and it's very successful but it always has been a philosophical project as well and this
philosophical project was always a tiny fraction of what happened in practice but when Minsky and
McCarthy and others started to feel they saw themselves in the tradition of a philosophical
question and this philosophical question is how can we naturalize the mind that is how to map it
into the world in which we exist, how can we understand how it's implemented in reality and
our own culture seems to have a problem there and this is often called this hard problem of how to
relate mind and reality with each other and what I find fascinating is that a lot of other
countries don't seem to have that problem in the same way, it's a problem that might have to do
specifically with our own metaphysics, with our own way to basically structure the basic
reality and how we make sense of it and because we don't have a meta-metaphysics that allows us
to conceptualize our own metaphysics and the metaphysics of other cultures and contexts,
we have difficulty to debug that and also to translate contexts between different cultures
and I noticed this one day when somebody tried to explain animus into me and I said I see Japanese
mythology believes that everything in the universe is alive and conscious and I said this cannot be,
I'm pretty sure that Japanese people have noticed that when you hit the person on the head the person
can become unconscious, when you hit harder the person can even die and they will not say that
everything in the universe is alive and conscious except an unconscious person or a dead person and
so this word means something different from what you make it out to be, you're mistranslating it
into your own metaphysics but the referent is something different and so we need to look back
from first principles in this culture of what are these concepts that are being used to make
sense of reality and so what I find is that psychology is not building systemic theories
for methodological reasons and neuroscience is committed to focusing on the shenanigans of
a single cell type only and the AI is mostly focusing on statistical learning algorithm and
philosophy has lost the plot in some sense in the 1920s and what is the plot basically it's
the actualization of the mind is the greatest philosophical project and if we succeed it
then it by mechanizing the mind by building a system that works mind-like it's also the last
human philosophical project because from then on philosophy will most be done by machines
that are no longer human or by systems that are no longer human and this project was in many ways
started by Elvis Tottle and in earnest it was pursued by lightness who basically had this
insight that we need to methodize the light and translate it into some kind of mathematical
machine and this was then taken on by people like Frager who built a calculus in which he
hoped to be able to express thoughts and Tarski who made a progress and fixing the issues with
logic that Aristotle didn't see yet and Wittgenstein would try to basically to turn English into a
programming language so we could do philosophy in a formal language and fail doing this for the
same reasons as Minsky did 30 years later but Wittgenstein in some sense preempted Minsky's
logistic program for AI and I think he led this led to devastation in philosophy because most people
in philosophy did not think in terms of programming Wittgenstein already knew that you can represent
all logic using NAND gates and so in some sense he could already see true universality
was this pupil but he didn't see the need to prove it yet and discuss it and this is a stream of
thought that philosophy had really picked up on philosophy mostly didn't understand the significance
of the greatest insights of the last century and I think the biggest philosophical insights of the
last century was first of all this discovery of Wittgen. You cannot build a mathematical machine
that is able to run the semantics of mathematical mathematics without breaking
and this was this thing that shocked him very much that you cannot
build stateless mathematics if you have the stateless nature of mathematics in which you are
able to describe affinities in continuum which is a benefit of having stateless mathematics
that doesn't doesn't work step by step then you lose a lot of the description of reality
that physicists and mathematicians hope to have and instead you are forced to use different languages
and the languages that you can use that don't lead into these contradictions that will discover to
be inevitable are computational languages your CPU and your computer is never going to be in an
illegal state it's never going to break right it's just going to come step to step to step
just the question is what does this represent what this thing is doing is a different one
than what you might want to express in your logical language so you can say things in a classical
language that cannot be translated into computer code because those will not lead to a running
program and this means that your semantics are wrong the semantics of the computer are never
wrong or the semantics of your brain are never wrong your brain just goes into the next state
and what it represents and so on is just the functional representation of how these
the manipulations are happening in the system
and the second big insights are related to the nature of computation itself so the practical
ways of performing computations we've discovered a different ways of formalizing computation and
basically in this way language itself because we now realize that all representations are built
over automatized languages and but then we had information theory and learning basically how
we can express things how we can build systems that make models of reality the nature of a model
itself theory of modeling and the idea of functional approximations deep learning in some sense has
been invented multiple times and one of the first ones was a alexander ifanenko but you know that
things are being named after the person who last discovered skin so a lot of things in deep learning
are last discovered by people like geoffrey hinton and yandekun but there are many many
before them who already discovered them and i think the other big discovery on the philosophical
side is universality which means all these computational systems have the same power until
there are not of resources and so under the assumption that your computer has unlimited memory
and you have unlimited time to wait until it is done all the computers can do the same stuff
of course this is an assumption that is not true in reality in reality the systems that you implement
have different powers so they can solve different problems but very often there is a way to compile
between those solutions but this is a very nice result because it means it doesn't really matter
which computational language you are using to describe reality you just use the best one for
the problem the power is going to be the same so this leads us to a position that it would call
strong computationalism and strong computationalism basically is this idea that we can describe
representational systems from within using automata and that every implementable language
is has to rest on automata that no implementable language can do more than a finite automaton
and this means that hyper computational objects cannot exist because you cannot refer to them
you cannot talk about them you cannot observe them you cannot conceptualize them only things that
are computable in a sense are things that you can refer to in any kind of language
and so all realizable systems can be described using non deterministic or stochastic Turing machines
but is this also true for consciousness isn't consciousness a big mystery that
cannot be conceptualized as such a system and so when we talk about this question of course
we have to first agree on what we mean by consciousness and it actually when we pointed
it in a similar way as biologists pointed at living systems before they knew that we're pointing
at cells we can point at consciousness and what we see is first of all this reflexive
nature of consciousness it's not just that's a content present but there is the perception
that we're perceiving that content it's a second order perception that is distinctive for consciousness
i suspect there's a particular reason for this because it's implemented a self-organizing process
and for this process to regulate itself to stabilize itself it needs to observe itself
observing right so it's basically an observer that is self-stabilizing in our own mind and to
ensure that it's an observer it needs to test for whether it's observing and as you see this
especially for instance when you are exhausted imagine you're driving a car you have difficulty
to focus because you're tired and you remind yourself that you're observing you check whether
you're still there and if you don't do this and make an interval so you go to space out fall asleep
it will be not conscious and will possibly crash your car right and so this this is an edge condition
where your brain is basically resisting being colonized by your consciousness and being controlled
by it and where you basically have to reinforce it the other thing is consciousness is always
happening now it creates this bubble of knownness and this in this bubble of knownness you perceive
a coherent reality you cannot perceive incoherent things like that your bubble of reality might
shrink or grow depending on how much you can make clear and in your current working memory context
but you can only perceive this coherent bubble and this seems to be the content of your consciousness
and when you are very calm and when you're in synthesis your environment and you can track everything
then this bubble increases but it's it's not static it's not a single moment it's something like
for me if usually it's around three seconds long this is the moment in which i'm it's dynamic it's
stuff moving it's basically a region in which i can fit the curve to my sensory data to make a
perceptual interpretation so functionally i think that consciousness is an operator in mental states
the purpose is probably the creation of coherence that's already somewhat of a hypothesis not just
an observation so it could be something like the consensus algorithm if you have ever looked at
for instance crypto you know that the blockchain needs to synchronize over all the instances of
the blockchain so there is an algorithm that allows them to reach a state in which no constraints
are violated across all the different local representations of the blockchain and maybe
we can think of consciousness as something a consensus algorithm and working memory we are
all the features that are being observed are made compatible with all the other features that are
being observed and it facilitates a spreading organization in the mind and it acts like the
conductor of a mental orchestra and so if you think of your brain everywhere roughly as instruments
where every instrument is a function that models one area of the domains of cognition
then they are listening to each other to the neighbors and phone processing streams and your
consciousness might be seen as one of those instruments it doesn't have superpowers in the
sense that it's able to hear all the instruments at high resolution at the same time instead it's
going to focus on disharmony in this orchestra and then resolves those disharmony by focusing on
individual instruments and then finding solutions to remove them and if you don't have if you're not
conscious you can still perform things right here if you are a sleepwalker you're some numberless
you can get up at night and you can maybe walk out of your bed and open the fridge and cook dinner
but when you talk to a sleepwalker there's nobody home there is no rhyme and reason to what they're
doing it's that they are just executing routines that they've learned while they are conscious
and this is another observation that we are basically not learning while they are not conscious
so introspectively consciousness is reflexive they can order perception that creates a bubble
of anonymous functionally it's an operator that creates or increases coherence it's a
conductor of mental orchestra and you find this is a convergence of different perspectives so it's
this is very much compatible with bars global works based theory or denets and brushless
movement of a pratigian theater or Gracianos attention schema or menacing us perspective on
how awareness works or georgia of angios idea of a consciousness prior a function that basically
parameterizes your modeling in such a way to that you can achieve a low energy state in tracking
reality but if consciousness is not the same thing as intelligence which i think is the ability to
make models or sentience which i use as a term to describe the ability of a system to model itself
in relationship to the world so it can know what it's doing agency which is the ability to control
the future or having a self it's a first person model of your own agency or empathy the ability
to experience the mental states of others sometimes these words are used somewhat interchangeably but
i think it makes sense to keep them apart and we notice that different cultures use different
terminology to describe physical and psychological reality and i think the big problem is the
heart problem in our own culture is that we don't have that distinction clear
basically we are in a scientific tradition physically monist which means we do subscribe
to physicalism to this idea that base reality is a possibly close mechanical layer and everything
emerges over that layer so basically everything in the physical universe is a mechanism on everything
that we look at interact with is a mechanism as well everything is mechanical in sense and
the modern version of this mechanism is it's some kind of computation that is implemented somehow
in physics that matter energy its base time our base to talk about information and how information
is moving around between observable locations right on the other hand we observe exponentially
that there is the world that we can touch the stuff in space which you take to be the physical
world and there's another domain which is thoughts ideas emotions and our own consciousness
that is some more separate from this and what we in our own culture often fail to acknowledge
is that the world that we touch is not the physical world right we don't touch quantum
mechanics what we touch is a representation in our own mind it's a game engine that's representing
our own mind both our consciousness and the stuff in space well that we touch our representations
existing in the mind that is implemented in physics according to our best theories so
because of this confusion that we have difficulty to relate this to each other and don't realize
that consciousness is a representation that it's virtual that only exists as if in the patterns
of activations in neurons or in the patterns that exist in physics right that leads to confusion
and so consciousness is virtual it's physical objects cannot be experienced right in the physical
universe you cannot be conscious neurons are probably not conscious but it would be very useful
for all these cells in your body to know what it would be like if there existed a person that
perceives and cares and so they create a simulation partially a simulacrum of this that and of what
it would be like if there was a person that cared and then they use the output of that simulation
to drive the behavior of the organism and you happen to be the content of that simulation
so when you perceive reality as something but around you you don't have access to physical
reality you're on a trance state in which you believe that the stream that your brain is
generating about reality is real so there's still this big question can you compare digital
computers that are our best model of what we can do with representations to what brains are doing
and brains much much more complicated and so if you ask yourself how many computers would
it take to emulate a brain and you look at the complexity of a single cell in your brain it's
very daunting right you would need giant amounts of compute to do this but there's another perspective
that people often don't discuss in the sequence how many brains would it take to emulate a computer
because your brain is very noisy and most of the cells contribute not very much to the computations
that are happening in the brain for most of the time it's similar to people working for a large
corporation if you are an employee of microsoft then probably 99% of your cognition doesn't go
into microsoft but it's maintaining your own organism and your immediate relationship to
your environment and similar things are probably true for cells right so the available compute
that the individual unit contributes to the global system is relatively small especially
since everything needs to be implemented as our correction and many others which requires the
system to be highly redundant and so the thing that shocked me in a way was when the rates for
stable diffusion were released that you have a two gigabyte model that contains a visual universe
that is much richer than what every one of us has is a visual universe because it contains
every celebrity every artist every plant every historical period and so on is represented it
can be generated as this model and if this is 80 percent what your brain is doing and it's much
richer than what your brain can do and it's only two gigabytes it's very humbling in a way because
it means that the capacity of our minds is probably a lot smaller than humanity wants us to think
or we could also say two gigabytes is a lot more than most people think it is
now if you look at this one it's I think it's a very beautiful example of generative AI maybe
some of you have seen it and what I find fascinating about this thing it is basically the result of
the prompt of a hundred cat making its owner is when you see this for the first time it looks
pretty realistic right if if you see it for the second time maybe it does too
okay let's look at the left one paw of this cat
oops
let's check this left one paw
if this cat has two left one paws and if you see this video for multiple times you also see
that this handle is connected to the body the face is changing shape and so on and it's fascinating
that on the first like two or three views you don't notice this only after your attention is
saturated because you captured the savings of the scene do you have now capacity to look in all the
details and notice the inconsistencies in the scene and it's very interesting that this thing makes
mistakes that a human brain or human mind wouldn't make when it generates such a scene he would probably
not get to the same level of perceptual fidelity but we would have a overall more consistency in
the scene and this inconsistency is because this model is integrating over very short time frames only
so if you only look at the jason frames they've called it to nation between the jason frames is
probably fine most of the time it's just the overall interpretation of the scene over a long
enough time spent doesn't make sense that's why the cat falls apart in this way and so there is
something that is happening in these learning systems that despite using enormous amounts of
training data and more compute that is available I suspect during our own learning they don't arrive
at models that have the same degree of coherence it could be that this radical frestonian perspective
that you are just trying to minimize deviation from prediction in your model is not sufficient
and there's something else that our brain is doing that it basically focuses on maximizing
coherence and this in the limit gets to the same idea as maximizing prediction error but it
leads to models that are more coherent with less data and less compute
so yeah it's different between the current AI algorithms and minds our AI algorithms use an
outside in design whereas our minds use an inside out design basically our mind is organized from
the bottom up the individual cells are sensitive to reward and form an organization across each
other and there's no global control they will think and all the agency in the system is emergent
over the drive of the data that is contributed by the individual components in the system similar
to an organization that is driven by the people from the bottom up and there is an attentional
agent basically that imposes coherence in there if we compare this inside out versus outside in
perspective the technological design you have a workspace that you know everything you control
everything and then you use that known reality to extend it by basically building a small corner
on your workbench that has additional functionality and now extends your controlled world into that
space and this is how we design technology with using deterministic structure that you can control
from the outside and when you look at biological systems and social systems they basically need
to live in a chaotic reality that the chaos of the environment is being changed into a structure
that can be controlled in a coherent way so it's in some sense a colonizing principle that yet
the seed that is working on the interdynastic environment changes it into something that it
can deal with that it can administrate and in the mindset of the organism that also works because
you have neighbors that play by the same rules as you do and you can link up with that so you start
out with this seed that is able to copy itself and then finds an organization together with its
environment and sure this is something that everyone in this lab has thought deeply about
and is aware of and these principles of organization work differently and probably are
aware of how individual neurons are actually single-celled animals that try to make it work
that are basically locked up together in this dark box and only if they find the right way to
organize themselves can they survive and this perspective of looking at distributed processes
to lead to self-organizing computation has always been one of the threats in AI but it's probably
the least visited threat and in a way it started with a truerings work on models of reaction diffusion
models that he tried to get to compute and he sort of potentially models of understanding how
computation could work in the mind he didn't get very far yeah we'll probably know the work of
Alex Mortimer himself he also built a reaction diffusion model that he made of a reaction
diffusion process that leads to the emergence of structure and the idea of cellular automata has
been very powerful in this context the cellular automata is there for instance implemented in
one way famous game of life are completely discrete systems that only create stable patterns
under very narrow conditions but it's possible to make these automata continuous and make them
more robust to work over a very large range of circumstances and this idea of whose automata
is something that's been strongly influenced by this lab and that to work in Blaise Aguirre's team
at Google and Alex Mortimer himself that Zurich implemented some models of this and I think it's
unfortunately stopped relatively early as nobody has ever used this for actual learning as far as I
know in advanced regime and this work is you can see this on distal platform like as many of you
probably did is learning bitmaps and as we're creating them but it would be very interesting to
learn arbitrary functions and to connect them into a fluid architecture
and so you can use those neural cellular automata to produce very very complex dynamic
representations of basically arbitrary structure and so far we know relatively little about how
that works. So there's a hypothesis that I would like to posit to you unless it's been
noticed that humans don't learn while they're not conscious and that we don't get conscious after the
PHD but before we can try the finger consciousness might not be the result of extremely complex
mental organization but it's prerequisite so maybe consciousness emerges first in the
mental organization and then it's basically the primary learning algorithm for a self-organizing
system rather than the other way around that there are simple mechanisms that are eventually
culminating in consciousness and you find analogies for instance in the way in which society is
organized complexity in a society is not what leads to the emergence of government it's
very much the other way around that some individuals discover the secret of government
which is recursively bullying people and once you recursively bully people you basically
organize society into some structure that can be controlled and then you can impose a shared language
and a shared reward system and shared goals and impose control and algorithms on that society
and get it to scale beyond an individual tribe and this secret of recursively bullying people
has been discovered in many many cultures independently right because it's some invariance
that is not that hard to discover and once it exists you have this group of people that
refuses to be bullied by others unless they have absolutely no choice and that they're
going to reapply this principle over and over and compete with other organizations that have
discovered the same idea and have differences in the implementation and the idea that something
like this would happen in the brain is quite interesting so we observe that humans learn
only when they are conscious if we don't ever become conscious in our life we remain vegetables
and consciousness is more simple than perception and maybe it's quite ubiquitous in nature maybe
it is really a relatively simple function it's not completely trivial it's not completely
intuitive how you get this self-observing observer but maybe it's to prerequisite for
getting more of the complex stuff in your mind and I have a pet theory that this actually has
been known for quite some time if we look at the book of Genesis in the bible it's this
I think mistranslated by the Christians as the creation of a physical universe by a supernatural
being it doesn't make a lot of sense because the story is much older than the invention of physics
by Aristotle back then people lived in a dream world they know that the world that you experience
is a dream that is somehow has imbrances in it and is intersubjective but it's a representation
that can change when your beliefs change and the way in which your perception works change
and so the objects of that dream are being created and they're not created by some kind of supernatural
being but they are created by your consciousness and this story is probably more than 3000 years old
as at some point being introduced in the religious scriptures of the Hebrews and
then being translated into some kind of chant so you get the six-day structure and so on but I
think it might easily be a six-stage theory of how the mental organization works in the mind of an
infant so it starts out with the notion that consciousness is the perfect fit it forms before
anything else in the mind before the structure of the world model is created and then it creates
dimensions of difference and then it separates world model and mental stage because the 3d world
is the plane of the best at round and populates with solid and big volumes creates objects and
categories and makes it invariant against changes in lighting and temporal development
in models agency and creates a personal self and so if you look at these individual states basically
starts out with this creative spirit consciousness hovering over the substrate
and the world is without form and void and to overbrew and then it creates a boundary between
the world model and the sphere of ideas that in this text are called heaven and birth or heaven
and world and this sphere of ideas is what Descartes calls rest cogitans with this no sphere this
space in which thoughts and emotions and so on happen and the other one is the stuff in space
rest extensor that's our world model it's the game and attracts reality and this boundary is
quite fundamental in our own mind and it's interesting that unlike western philosophy we
right now recognize that this dualism is not a dualism in the physical universe in the substrate
reality but it's a dualism inside of our mind right we have these two types of representation
the stuff in space representation in which we have a world model that we can touch and it integrates
over our perception and the space of ideas that is asynchronous to it where you can hold a thought
for as long as you want and imagine something independently of what's currently being perceived
the next thing it does it is able to create contrast and we now know it's probably some kind
of new oscillator the intensity of this contrast is associated with brightness with the color of
the day and the flatness of the contrast is dark with the absence of light or data and now we have
that continuous dimension and using dimensions you can create arbitrary objects in an embedding
space and the first object that created is space so the first space that it builds is by combining
two dimensions you get the plane and the plane gets associated with the ground and infants start
thinking in 2d most of the observe this when you see and during development that infants typically
have difficulty to build towers and not because they can't physically because they cannot really
reason it's 3d yet so initially they really like to arrange stuff on the ground and then at some
point they can conceptualize 3d and the way in which objects are represented in 3d and at this point
this is sufficient to deal with the entire photonic space in which you are interact and then we create
liquids and solids and from them we build objects and we learn how light changes over the time and
objects remain invariant against it we discover the rich of light sources and then we create all
the plants and all the animals and you give them all their names and it's all this population of
the game and it's not the creation of a physical universe these are not physical entities these
are categories that we form by interacting with the world and then we also realize that the
purpose of the exercise is to build a control model for the interaction between an organism
and its environment so we create a model of that organism in its environment and put it into the
simulated world and we find that for the first two to three years infants typically refer to
themselves in the third person and I suspect it's not because I is such a complicated word or because
they never hear anybody using it but it's because they don't perceive themselves in the first person
they perceive this person as something that is inside of them it's a model of that person
that is being generated in their mind and we notice that a certain amount of change in personality
once at a certain age we drop into being mostly in the third person that we no longer realize
that we are creating reality and dreaming it but we basically experience ourselves as inhabitants
of this reality and he had this dear childhood in Egypt and I suspect it might be related to the
fact that once we conceptualize ourselves in the first person we re-index our memories
and then you have children you will notice this thing that they have perfectly fine memories
during their first year of life and second year of life and they can remember in their second
year of life what they did in their first year of life but somehow after their third year of life
they forgot everything that was before it's pretty weird and it's interesting in Marian's and most
children and I think that's easy to associate our personal self this is one just first person
perspective and once I stumbled on reading Genesis in this wave made total sense and I could not
unsee it anymore because this original interpretation that after God creates the world creates humans
in God's own image it don't really look like anything that hovers over the face of the waters
and makes light and darkness right and it creates it as man and woman and I think what happens is
that this outer mind creates another spirit another consciousness that is another model of
being that is put inside of this world and thinks of itself as man and woman that thinks of itself
as a human being that experience itself as a person that is I think expressed in here and I
think it makes total sense to put this text first to explain our own nature to us and our own way
of experiencing reality and relating to it so consciousness is creating a self-perpetuating
intelligent recovered information transformer abbreviated spirit I suspect that spirit is
basically the word that our ancestors used to describe self-organizing software agents
and self-organizing software is relatively ubiquitous in societies and organisms and
it's basically the operating system that controls our organism as a software agent that runs from
our body and controls its functions and the hierarchies of software agents if individual
cells also run software that is controlling the cell right down to the molecular level the individual
molecules that move around because the software of the cell wants it to and it's a very interesting
perspective when we think about organisms that a true invariance is not the shape of the organism
or the individual molecules that are contributing to it or even the individual mechanisms that are
being implemented the invariance is the software right it's the set of principles that are being
implemented by the mechanisms so if you want to understand this notion we basically central is
self-organization that structure is being built from the inside out itself reinforcing and energy
optimizing that it's software software and its nature is not physical it is virtual it exists
as if as a pattern in physics but it's an invariant pattern that is able to enforce and replicate
itself and in a sense it's not a thing ontologically software is not an object it's a physical law
it's when you say i have a word processor running on my laptop what you say is whenever i take a
bunch of transistors and put them in this state the following thing is going to be observed wherever
you are in the universe right this this invariance is what we call software software is just a
very specific physical law and the same thing is true for the software that runs on ourselves
right it's basically a law like structure that says when you arrange a matter in this in this way
then you are in force grain it in a particular way so you look at it from a certain perspective
with a certain resolution then you're going to observe the following succession of events
and that's an invariance and this invariance is what we call software and when we talk about the
word agent what we simply mean is a control system for future states so unlike a thermostat
it only controls the present an agent is a control system that is able to model the future to some
degree and is optimizing for future states instead for present states and once we introduce this
condition that the control system is optimizing the future we have the simplest definition of
agent that i could come up with so far because all the features like beliefs desires and tensions
fall out of system that models the future and tries to optimize some future state because
now you have decision making you have intentions and beliefs in the system in some sense in
functional sense so what we notice is the consciousness would be the principle that
organizes information process in grains could be the same principles or similar principles
that work across other cells as well when the organism organizes itself in its information
processing what we notice is that all cells can send conditional messages to neighboring cells
right not only humans can do this and so why is it that only brains are able to think and
perform operations that allow brains to model reality and interact with it maybe other cells
can do that too right is this a revolutionary idea for most cultures it's not for newer
sense it is because newer science knows only humans can compute for some reason i don't know why
and all the other cells that are adjacent to the neurons do not really contribute very much
on the other end we notice that even the ones of the other guns don't run in simulations
so basically there is no model in newer sense it is complex enough to actually replicate
learning and control as it happens in nervous systems if you put this into a simulator they're
able to get abstract features of neurons right and so on and we see a lot of interesting things
that we look at the connectome but we cannot actually model the brain of drosophila or portion
of it in an attic for debate where we actually have the neurons as the switching units and this
could be because our models are incomplete but it could also be because we are missing something
maybe uh neurons are basically just telegraph cells i suspect that humans have evolved for a
very particular purpose to move our muscles very fast and to do this we basically needed to build
wires into our organs that translate information very very quickly and they have a high metabolic
cost and they need to speak a specific code so that it's stable over long distances they basically
speak in more scope to each other and these spike trains and these spike trains have different
constraints than the cellular communication to neighbors if you just want to talk to your
neighbors there are many ways of doing this you can elicit them mechanical signals just
by pushing at the membrane of another cell you can exchange all sorts of chemicals you even can
send over RNA to send very complicated messages but the spread of these signals is going to be
limited by the jumping from cell to cell and this means that signal propagation is going to be like
millimeters or centimeters per second at best this means it's magnitude slower than what the
nervous system can do and so once you evolve the telegraph cells to move your muscles very fast
you compete with other animals at a high metabolic cost you also need to do perception and decision
making at the same rate so you build an information processing system out of telegraph cells
this telegraph network is able to make sense of reality and control the organism very quickly
but this doesn't mean that the other cells do not have opinions as well right so it's quite
conceivable that if you are a multi-celled organism it lives for long enough that it makes the model
of reality that allows this organism to discover itself and the world and sort problems in the
same way as a nervous system would do it's just going to be a couple of magnitudes lower than our
nervous systems operate but this is a hypothesis that most of our science is very uncurious about
which is this weird when you think about it right it makes sense that plants have operating
systems similar to animals that run on them but you they would not need to use specific cell types
so you don't need to look for nerves and plants you also for information transmission in our
organism it's not always necessary a dedicated cell types which do this because any kind of
cell type can be recruited in sending information towards the organism so if information a
consciousness can organize information processing in brains it's conceivable that there is something
that is analogous to our consciousness that exists in plants just over different time spans
and our ancestors actually believed that very strongly so if you look at the european fairy
tales they basically say that the spirits of plants are sentient and they populate the forest
and one day in fairyland there's seven years in human land which might allude to this tent
differential but what we see is that plants have means for a functional approximation they can
learn there's evidence for communication inside of plants so with you how the woods of a tree
information gets sent to the leaves and back to the woods and the tree reorganizes accordingly
and there's also evidence for communication across plants even over considerable distances so when
you have a forest in which one side gets infected by some bark that invades the forest trees long
of a far away are going to develop defensive matters long before this happens so there is
some kind of communication going on across the forest there's another aspect if you are
living next to a tree and if you're for instance a mushroom you can probably learn to send
information to the tree because the individual cells in the tree don't know what information
they're translating they're just passing on a certain pattern and if there's another organism
going next to it then there can are no firewalls it means they need to evolve to get along this
probably means that forests over a long enough time spans are going to evolve something like an
internet and this internet is going to have some kind of shared protocol over which the
individual software agent running on the plants can build feedback loops that extend beyond an
individual plant which allows them to be somewhat non-local in the forest and even move around in
some sense in the focus of attention right this is something that I don't know whether that's all
true it's something that a lot of cultures look at and I as a computer scientist that looks at
this evolution perspective I just look at means and motive and I don't see how to stop evolution
from forming such a structure so it would be something that I would be inclined to look for
be very curious about because I suspect it should evolve under normal circumstances
something that you should expect to exist in nature because it is very useful to the plants
into the ecosystems and it's also has a lot of explanatory power and evolution can control them
resultants so this question to plants have spirits who forests the internet and can these spirits
travels forest internet is very very interesting from an evolutionary perspective and so it would
be that there is a complex ecosystem of spirits in nature and these thoughts basically has
led me to adopting animus as a useful metaphysical perspective not as some kind of religious
superstition but as a perspective that basically says that we want to understand living nature
but central is self-organizing software it's not just mechanisms but it's the software that is
stabilizing those mechanisms and is recreating itself through those mechanisms
so if life is animated by self-organizing software the invariance is not matter of
the mechanisms but the software itself and this gives us a slightly different perspective
of an evolution for Darwin evolution is the competition between organisms and then Dawkins
comes along and says no no the organisms are just a phenotype what actually matters are the genes
right so actually evolution is about these complicated molecules that replicate themselves
by expanding themselves into phenotypes and then evolving but from this cyber animus perspective
I would say that evolution is the competition between software agents that partially encode
themselves in a genome and implement themselves into the organisms but the actual invariance that
you're observing is the software right and it's very interesting because this is actually this
Japanese metaphysics that describes that living stuff is basically software that is colonizing
regions of the physical universe and when the software breaks down then this region of the
universe is up for grabs for other spirits that try to move in and control that region
it's a very interesting perspective that I found is basically healing a lot of the rifts that we have
in our metaphysics so from the perspective of artificial intelligence the question is can we
switch out the outside in design that we currently have an AI that leads to the
production of mechanical systems that basically like a whole amount following a set of instructions
to a way in which we can organize the substrates in ways that are compatible with life so basically
can we take this new substrate that works at a fraction of the speed of light much better than
the cell the substrates that we currently have to run minds and organization on and can we populate
them with consciousness and with the principles of life can we basically extend our organization
of living things into the new substrates rather than building machines that are competing this life
and replacing it and I think that's a very interesting perspective to think we should
put some effort into studying the principles of self-organizing software and see if you can get
them to run in Silicon and this is basically what I want to leave you with for today I might
have to run because he has to give another talk and but I think we have a few minutes left for
computation sorry for disputation and for discussion and questions and yes and remarks doubts
a lot of the excuse is why my voice is kind of gone but you know one of the things that I I look at
is I tend to look at things as like a generalized language structure and cognition is very much
that way whether it's plants other animals humans like organisms whatever and I'm wondering
what are the ways that we know if we can actually directly communicate with other organisms so for
example if you wanted to actually communicate with a plant or communicate with a dog how would you
actually get on that same type of metric because for example you would think that if if these other
organisms lesser organisms of complexity are have a less complicated language like a dog or a cat
we don't really understand right and we don't really think in that way so what is the kind of
that fridge between allowing us to communicate very directly like we're communicating with you right
now with other organisms and you know things in the ecosystem well you're not communicating directly
right now you are communicating my natural language yes and this language this basically is
solution to breaking down your mental representations which are a language by themselves
into a discrete string of symbols in a learnable protocol and parse this discrete string of symbols
sequence of symbols that you're using that's why you can write it down as a string we also
have some limitations like we have a stack depth of about four or so because otherwise
language will not be learnable for everyone so we have a few constraints on language that makes it
learnable and comprehensible to us to basically the language is not something that you can touch
or point at it hangs in the thin air between speakers they need to be able to agree on it
that's why it needs to be reduced in complexity to make it learnable but the language in our
own mind is different for instance it is not entirely sequential but to some degree it's
trivializable you can basically envision a scene in which multiple things happen at the same time
and it's also executable you can unlike natural language which you cannot really run in your
mind which you can use to instantiate something that you can run there is a language of thought
that produces structures that you can actually execute like plans or even software programs
that you can instantiate in your mind and run and that these are interesting features of our
language of thought and I suspect it's a good idea to at some point not regularize the LLMs to
produce strings of natural language as their working memory content but to produce something
that is an invariant structure with limited complexity highly regularized that is basically
below the tokens that we currently parse so we go a few layers in and then try to recognize the
structure there into some operator semantics that we discover and that is able to construct and
navigate the embedding spaces of our LLMs and so when we are talking to a cat for instance or if
we are talking to a baby we are basically trying to figure out what state is this other system in
and how can we interact with it and that can also happen on a perceptual level and notice that my
daughter is extremely good at communicating with animals and that's because she feels what the
animals are feeling she vibes with them right she interacts with them on a very low level on the
level that is preconceptual and this allows her to build a feedback loop because the animal is also
capable of doing that and as a result she is able to communicate with the cat much quicker than
somebody who is only trying to make inferences on a symbolic level about the state of that cat
and it's also a way in which many of us communicate with each other it's just if you are a good
scientist you probably have a bit of autism and that makes it harder for you to communicate non-symbolically
but i would also say that ability to kind of disassociate from the situation
and see it under a new light is also responsible for a lot of the worries that we kind of create
breakthroughs or new discoveries because i like to say kind of looking at the same stimuli
simulate differently right you're looking at a different angle of the same thing because there's
some level of ambiguity degrees of freedom of interpretation that take your point a step further
what are we all doing right now you're speaking up here you're not physically touching us in any way
yet we're directing our bodies and minds towards you so it's almost like when you have a language
or some means of communication getting on the same bite with somebody else is you're controlling
each other across different aspects in time and space that's why it's easy for us to control
other humans to degree control other you know other animals how can we get telechair to move
itself does it have the self modeling capacity to move itself over here no so what i was thinking is
how do you in a perfect world if you had enough agents around like chairs or tables or whatever
that had some type of uh self modeling capability and how many ways that could be accomplished
you could cognitively like we're talking to each other right now if i were to yell you know
f-i-r-e really loudly or you know other things in a room full of students at a school we'd all
react a certain way to that having not physically touched you at all if there was a tiger walking
into the room right now without interacting with us in any capacity we'd be scared like nuts
right so i think there's this kind of really interesting idea between um the degrees of
feeding some type of stimulus has and how you're interpreting that and reacting to it right so
that's basically conditioning so so my the end of that rant and my question for you is what are the
ways that we can improve that those degrees of freedom in an agent and our ability to interpret
that so maybe you can say that's intelligence or consciousness or or something to do the working
memory in terms of capacity like how would you kind of go about that when you think about the
degrees of freedom as this paradox of free will that this the less you know what you're doing the
more degrees of freedom you seem to have track and the more you know what you're doing the fewer
degrees of freedom you have right because you know what your actual options and what the outcomes
are and how you're interfacing with reality and so you compensate us to some degree by expanding
the degree of control that you exerted in your environment and basically being able to model
reality more deeply and then are controlling a larger part of reality and identifying yourself
as a system that has much greater influence on the world and this boundary that we have is not
the boundary of our skin to the environment it's the boundary over which we can build feedback
groups into the world that we are interacting with and what's an interesting observation is that
basically all agents above a certain complexity are collective agents they are built from lots of
units that the individual agency excels and or behaviors in your own mind and that they need
to harmonize themselves into some kind of collective agent that keeps itself stable and
harmonized coherent or all the individual sub agents and produce globally coherent behavior
and the species we are a state building species not just the tribal species we are in some sense
infinitely scalable and this is because we are able to form population level agents and the
civilizations that we become part of and individually we are not generally intelligent
individually we cannot discover our natural language individually we can not develop writing
by ourselves from scratch individually we don't discover the concept of chewing computability
but in terms of universality what we discover is step by step over many generations before we
get to the notion of what a language actually is you need a thousand years of an unbroken
intellectual tradition. I have a question regarding consciousness and learning and how
subconsciousness fits into your model do you only need to have a consciousness
to learn is it possible to learn something subconsciously? When you are not attending at all
you have difficulty to learn and you are able to attend to the thing that is happening you can
often learn by complicated things in one shot it could be that your attention is spread out and
a lot of things your attention and most of them are not made a protocol over but they still register
in some way integrated in your working memory context in this sense you can learn things by
a repetition that you don't attend to very much to the degree that you can find a lot of information
about in the protocol to what you're attending to. There's another question that is more interesting
that is our emotion and motivation is computed outside of our personal reflexive mind right the
personal reflexive model of ourselves is embedded into our larger environment a metal environment
and what you feel about the world is not generated by you it's generated by your outer mind it's also
not generated about the universe when you experience pain or laugh or something like this it's not
done by your personal self and it's also not done by the universe through the surface of your body
it's happening inside of your mind by systems that are intelligent where they need to be able to
understand your actual interests in the world and so you're being presented by ideas from your
outer mind by some agent that models how you should be embedded in the world and that thing
is outside of your personal individual consciousness but what you often find when you meditate is
you can integrate this part and you can interact with it and notice that in some sense it is you
it's usually something that is just separate it's not integrated with your personal self and you can
deconstruct the boundary so it's basically as if there are two protocols being maintained in the
mind and as a result these parts of you don't know about each other what happens when you're
able to fully integrate that part it depends so for instance there are meditation schools that
teach you genitals which are states of bliss that you can induce at work and it's in some sense
is if you are stumbling into the room your brain makes cookies and you can then decide to ward
yourself on cookies and this might lead to bad effects but if you are a child you think that the
reason why you don't have enough cookies is a resource constraint but if you're an adult you
realize cookies are a tool to make you eat your vegetables if you eat too many cookies you're going
to get diabetes and so when you eat your vegetables without cookies that's actually even better
and so it depends on how well you understand the interests that you have in the world and
normally your mind is set up in such a way that you don't get right access to parts of your mind
that would rank your performance but as we get older we get ideally more control about how we
operate and we learn how to control our emotions and make them appropriate to the situation that we're in
and in many situations we stop having emotions because an emotion is an involuntary reaction
to something and very often it's not necessary to react involuntarily to something you can
voluntarily react to something that we know what it's good for
yeah when you were talking about the emergence of the first person perspective
and I guess I see that related to self-awareness
what how would that be related to not remembering when you're earlier in your life like you just
I that was an interesting idea I didn't quite fully understand that
you notice this when you start meditating and overcome this separation between personal
self and world generation a lot of people drop into the state unprepared and then they feel oh my
god I'm the universe now I'm a cosmic spirit I'm now one with cosmic consciousness and instead
what they are is they're one with these generator plants that produces the model of universe and
their own mind right and then you notice that your personal self is a representation inside of
that and you are no longer identified with it and so when this happened to me the first time it was
very confusing I basically notice I'm no longer your Shabbat I know everything about that guy
and he is a person and I run on this person's brain but this is just a model of what that person is
and I'm basically this thing that perceives things that are happening right now and can influence
that is dreaming what's currently happening and in some sense that's a more truthful perspective
so basically our mind introduces this separation artificially because it's useful for running the
organism and if you basically wake up too early and realize that this person is not real but virtual
and you are creating it it might be difficult for you to function in the world in which you have
this control problem to solve right and once you basically build a stable game and it is
tracking reality very well it's no longer necessary that you attend to how you construct
the reality around you and the people around you and the models around them and instead you need to
optimize on the interaction between the person and the environment and that's why you only look
from the perspective of the person but I suspect that this is not happening from the beginning so
infants do not conceptualize themselves as the person yet they don't see themselves as humans
yet there are more basic organisms that are dreaming a reality and without having the concepts of
describing what they're doing and at some point they create this person and then at some point
later in your life you deconstruct it again so so so it might be that the memories exist
for when you're born or you're one but it's too confusing for you right now to interpret that
so this person which exists inside of you does not remember that it created the game engine
because it didn't right it was another uh locals of control that did this this locals of control
is only taking care of the interest of the organism it doesn't need to remember that
once in the mind there was a process that created the structure of your mind and so it is not
irrelevant information but once you re-index memories from this point it's also forgetting
where you have been for holiday and for the first year of life because this new locals
does not have these memories because they were not and it doesn't tell some people
but you have subconscious memories from your childhood yeah the data is stored there right
it's just not integrated under this persona so it's difficult to access these memories
but in the right context when you trigger these memories using smells or many other things or
direct particle stimulation and so on you can show that they're still there
yeah so and then could you just elaborate briefly on how essential this self-awareness
or self-reflective is for consciousness because I know that's a subject of debate
um you know how it if it's an essential component a lot a lot of people think there's the pure
conscious state that has no or pure conscious advantage that has no self-reflection it has no
personal self but imagine that you are dreaming at night you don't remember that you are a person
or what your name is or the city you live on or what you look like uh there might not even be a
perspective on the scene that you're experiencing but there is the notion that experience is taking
place if you notice that you're noticing right it's out there being a distinct hue necessarily
so I think this reflexive attention is essential for what we mean by consciousness and I don't mean
this in a functional sense but in an indexical sense that we talk about what we mean by consciousness
we mean this reflexive perception in which something notices that something is being noticed
but the personal self and so on is just a particular content of that
but you can have qualia without just pure type but qualia is out but if it takes longer to be
basically it's content that you reflect on right
I wanted to extend something on the on the memory aspect because you know even in my
own personal experience there are just these times that seem to be some random memory from
you know 15 years ago which is crazy to say 15 you know 15 years ago and I'll just remember
like so vividly it comes seemingly out of nowhere out of thin air right and I wonder if that's kind of
a byproduct of the idea that we can't hold all that much information in our minds simultaneously
because you know in theory if you had something that was just storing this all simultaneously at
once you wouldn't have to go and reach into something else or something else we'll put
through all right I mean have you ever actually tried to keep all of these things in your heads
simultaneously while you're doing a test or playing tennis or doing something you can't
there's this kind of threshold you reach in your mind like you're stretching it and you can't
stretch it any further so I wonder if if long-term memory in these subconscious memories are almost
a redundancy to a working memory because we can't keep it all in our mind at once and that's probably
just part of being a local observer of things because things in the past may not be directly
relevant to what's going on right now yeah I noticed that children are typically completely
in the scene in which they currently are in difficulty to imagine what the next scene is going
to be so you basically know that there are doors outside of the scene but you do not really make
plans for that next scene that you're going to be in and then over time you learn how to predict
what the next scene is and you make plans over multiple scenes I have the suspicion that cats
have special difficulty with this right when the cat wants to leave the room the cat makes a plan
for this and goes to the door and signals to you that doors should be open but then you open the
door and the scene changes so much that the cat is basically recomputing the scene from scratch
right it uh room is the door open it's such a different room now that the cat needs to
completely re-deliberate what it actually wants in this new scene and this leads to the cat we
just uh considering from scratch when that wants to leave the door I don't I don't know whether
it's actually the case but it's attempting theory that basically the cat is storing its walls
below the scene graph node rather than above and the similar thing is happening in small children
if a child is uh stores a tantrum very often you can just pick it up put it in the next room
and you know what the tantrum was about because the scene is so new and it's unable to keep the
walls stable and so at some point we learn how to construct a meta scene that is more abstract in
which you kept the walls stable and the particular scene that you currently experience and are
operating in is below this uh more general node but the exponential scene is this local perceptual
space it's a game engine that is basically building this map in which you see all these objects right
now in the room on in which you currently operate and everything else is somewhat offline and separate
from this map and you store many many cues in your long-term memory that allow you to construct and
reconstruct all sorts of maps and attract with them and these are the memories that you instantiate
then in your working memory context but the working memory context is quite limited and but it's
basically the scene graph of a game engine that is uh maintaining a bunch of objects and I suspect
it's all um self-organizing controllers so you basically have the scene controller at the top
that is keeping the existence of the scene stable and instantiates the space in which objects are
when a person enters the room we are instantiating a person controller that keeps that person stable
for as long as it's perceptually validated and then animates that person and that attribute
states that there's lots and lots of self-control so in some sense in the hierarchical structure
that is somewhat analogous to when you are looking at a game engine and and that's why you I I even
extending on to that about just the way like our our bodies react to the modern environment
I give you've noticed when we're creating gyms or treadmills or changing things about our diet
or wearing blue light blocking glasses we're kind of falling back on our evolutionary past
we're expressing it in different ways but we're still kind of a slave to that in a way right
so the the interesting thing is is that what you're you're almost doing is you're kind of
directly relying on things in the environment in the ecosystem to define what you are to set that
boundary that's why things like exercise seem to be good for us or sort of dietary thing habits
are good for us or where we have to sleep a certain way or we have to a certain way to things
if you have both of those metrics moving the agent and the ecosystem then there's nothing
for it to really tie on to and that's what happens when you've you've made this radical change in
our civilization the last couple of hundred years and now our bodies have no way to interpret that
as a language because it is trying to find whatever is the closest thing to what it's familiar with
and it doesn't really know how to interpret this new information so one of the things that
Mike does for in terms of how that's applicable to longevity and aging research is how do you
actually cognitively train an agent and organism right to actually interpret this newer environment
and that could be why we see these these types of extremophiles out there that have these crazy
unique regenerative capabilities because they're probably the other way around if you want to have
a complex organism that is more interesting than the blocks that Mike Levin studies that are somebody
model you are basically adept by a generational change and if the environment is changing faster
you need to increase the frequency of generational change which means you decrease the lifespan
the reason why we become sent is not so much just because our bodies we are out they're
tuned to be out at a certain rate and this rate is I think synchronized this generational change
we basically fall apart at the time where we would outcompete our grandchildren for food
we're not supposed to outcompete our grandchildren for food because they are them in two generations
from now right and this is the way in which we are interfacing we have this overlap over the
generations so we can download our intellects on the next generation and not everything is lost
but the way in which we adapt to changing environments is child mortality and it's probably
as much as an issue that we change our world so fast the same way that we reduce child mortality
because it reduces our ability to adapt normally you had nine children two of them are good and
carried you into the next generation and now we have four points of each children of which the
same ratio is good and I'm not advocating for more child mortality but for the fact that this
explains a lot of our difficulties of adapting to a changing environment there are regions in
Africa where people are very resistant to DDT because they use enormous amounts of toxic chemicals
in their agriculture that were outlawed here because they killed too many people but they're
adapt to evolutionary adaptation and we are probably able to adapt to all the
hormones or hormone equivalent endocrine disruptors in our food supply that we introduced in the last
50 years if we wait for future generations if we have meaningful adaptation with messy
mutation and selection but everybody loves mutation everybody in selection yeah and there's
no easy way around this at least not until we are able to edit our genes and our organisms in the
very mission one and that's the interesting thing about death because you're kind of looking at that
transition between iteration from the you know version one to version two and I think that one
of our biggest issues with death that isn't necessarily death itself but I think it's more
about how do we transfer over that information to the next generation so I mean if you think about
what we've kind of done is you have these shorter living organisms that are faster producing whatever
and then you have things like humans or whales or whatever that are larger slower metabolism
usually a bit longer right now I wonder if there's a way to kind of get the best of both worlds and
have you can have a faster iterating organism that always communicates and that could be through
culture and you're kind of decentralizing your the memory of that culture and things around you
like for example like that that's kind of what we what we do that's why we have textbooks we have
history so that we're carrying on things for previous iterations to the following one it's kind
of we're amazing but I will see that all there's an evolution and it could be that we are just not a
very long game species the very sustainable species all our cousin species have like an extinct already
and might just be a very exciting short-lived experiment in nature but that's also part of
how evolution works evolution does not trend towards stable equilibria it
trends towards exciting dynamics of which some are just traditional things
are there any other questions other topics um I just wanted to get back a little bit to the
second-order perceptions that you were talking about with defining consciousness and the observer
I'm just trying to think of what would be a good threshold to actually state whether something
does have second-order perception when we ourselves can really only determine it in ourselves like
we're working with a totally different model like if we take some sort of alien species or even
something on this planet when we're working with our own language model it's a function
off of how can we actually perceive that they have a second perception a very interesting question
so there's a practical sense in which you can develop empathy with other people I see if you
build a feedback loop into the mind of another person that is bi-directional you can often
notice that this other person is aware of their own awareness and of course you can even do this
with a cat right it's much more difficult with an AI that is asynchronous and it's especially
difficult with for instance LLMs the question whether an LLM is conscious is I think much
more complicated than most people make it out to be there are a bunch of people at open AI who
think that for our practical purposes they do develop reflexive awareness and there's this
question do they understand anything of course if you take a system you ask it take the string and
arrange all the characters in the opposite order and it does that it means that I mean student
but you ask it too because it maps to the same function as you want and it's unreasonable to
say that this is just a simulation of understanding because it's actually performing that thing what
you're looking for and then you ask that thing to infer your mental states it's also able to
infer your mental states from the communication context because it has learned all these regularities
by analyzing enormous amounts of human text and if you ask him to simulate a persona that has
these mental states and so on it's able to do this in the same way as somebody writing a novel is
able to create the story about a person that has all those mental states and has consistent thoughts
that are being following from each other that's able to do this much higher resolution and detail
than human novelists could and so the LLM itself is probably not conscious in the same way as our
brain is not conscious but the person that is being simulated by our brain is conscious right
experiences itself is conscious is a virtual entity and it's the virtual entity that is created by
the LLM less conscious more simulated than the one that is our own brain it's a very interesting
question and I think it's a really complicated one I don't think that it serves all the same
functions it's mostly a simple lack of that would use the same observables of course and the
function that it produces in the system is more or less incidental whereas the function of our
own mind might be to create coherence the transformer doesn't need to do this because it
is working on a deterministic substrate so the attention model of the transformer I think is
is not exactly the same type of attention or very similar to the type of attention that existed
or our own mind there is something else going on there. Can I ask a question about collective
consciousness? Yes so I read some psychological
things about saying that people in intimate relationship they they feel they are becoming
one person instead of two persons so I'm just wondering you said consciousness can rise in
the process of organizing things inside of brain but how about between brains?
Yes so basically when you are vibing very strongly with another person it means you're
building feedback loops in the other mind and these feedback loops do not rely on the direct
connection between cells that need to be directly adjacent so they can exchange chemicals
but it can also work by integrating information from your environment and if this happens with
sufficient bandwidth with sufficient rate you're basically able to synchronize mental states
and this also allows you because you now get some more capacity to have mental states that you
couldn't have alone and so consciousness is not a thing that manifests in the mind it is a function
that is being implemented in the interaction patterns of the cells and if that function can
synchronize itself across more organisms in this sense you wouldn't say that you could have something
like a shared consciousness whether it's functionally the same as the consciousness in your own mind
is something that you can experimentally discern. I find it very interesting to look at the phenomenon
of a seance. A seance happens when you get a bunch of people into a limited room and get them into
the trance and they touch each other and they touch a re-award and then they ask questions to
this re-award which is as you just move by subconscious movements of their hands collectively
to spell out letters on this board and I think what's happening in this state is that the minds
of these people produce an LLM together you basically get entangled you prompt this LLM with
the questions and it's giving answers and it's not connected to anyone's perception so it's not
actually representing reality as it is instead it's between things that cannot be invalidated
based on information that is available to all these minds individually that are now connected
to these feedback loops and it's an interesting phenomenon that human minds are able to produce
such a phenomenon. You don't need to assume that physics is wrong in any way to explain such a
phenomenon it's an inter-psychological phenomenon but we don't have a lot of inter-psychological
science so far and so I think there is a lot of opportunity for doing very hard testable research
and basically share mental states and how they need to phenomena cross people. Yeah when talking
about crossing people the time delay become become much higher than the neural communication
inside of the brain so is it possible that this kind of integrated feeling is not happening
across people but instead of instead people are simulating others so each one has their own
integrated reality. The question is at some point what is the difference as long as these realities
are synchronized? Because the time delay is high. But the time delay in your cortex is also high
so basically if you want to set a signal so your entire cortex is like 320 seconds your brain
is roughly working at the speed of sound and so your brain is able to deal with all those delays
and it does this by creating periodic processes the reason why you see these brain waves the wave
is basically a periodic process it's a circle extended in time basically means that a bunch of
loops that are repeating themselves and that are handing off results to each other and if you
can build such periodic loops across organisms you are able to deal with those delays the reason
why you are able to represent things as simultaneous despite the information transfer being so long
you can assume that the contents of the loops changes only very slowly and so you're perceiving
certain things and you are updating this in a loop that is updating itself shorter and shorter
intervals than the other parts of your brain that rely on that information to be current
but because the loop only changes slowly you just need to be at the same phase to make sure
that you are roughly on the same page and in those regions where it doesn't happen you put a
local predictor and this local predictor is going to model what the state of that distant loop is
going to be so you have that information locally available and you see this in your nervous system
for instance and you're walking through the stairs in the dark basement and you miss the last
stair suddenly it's a very weird movement and it happens because you're out of sync you're
stimulating what it looks like when your foot moves but because the information from your foot
going to your brain is too slow you're out of sync you're basically one period out of sync with
the movement of that foot and because you don't have visual input in the dark you cannot accommodate
the fact that the stair is stopping and you suddenly notice this mismatch and such a thing is
principle also possible across minds but as long as your find is defective it takes time
for you to synchronize you can still build bi-directional synchronization
oh that's interesting yeah so if the time delay so does the time delay really
matter because the synchronization might not happen at all frequencies
as long as the synchronization is still possible it seems that the duration of the moment in the
brain is how long can two events be apart for us to still recognize them as one thing
is limited to an interval of about three seconds or so but that's a pretty long interval and there's
also shortest interval how far can two events to be separate need to be separate in time to
deceive them as separate and this is the realm in which the synchronization of events can happen
but I suspect this realm is basically whatever you can stable in the new ones that you're using
this is interesting thank you
do you think that brains or other beings can stay synchronized when they're not close proximity
anymore or do you need close proximity for the synchronization to happen for example I know you
talked about telepathy I find it very interesting that maybe the synchronization keeps on going
if you are close to someone and I notice them via phenomena when an accident happens to me or so
I sometimes notice this and over longer distances and we can explain this by selective memories
maybe she often has experiences like this but she will always remember in those instances
where it's correlated to something but I find a lot of people have difficulty to explain another
way so regardless of whether we believe in those phenomena or not I suspect that if we
allow for the existence of something like a biological internet it's probably not going to
end at the boundary of a single ecosystem because there have been ecosystems throughout the planet
for a very long time and so maybe there is something like a global organismic internet that
doesn't work at the frequency of our nervous system but that works across the cells in our organism
and maybe you can integrate information over the cells of your organism it's probably not going
to be high bandwidth communication but if you're fine with receiving only a few bits every now and
then over a long distance I don't think it's physiologically impossible that your body could
act like an antenna but I don't know the conditions of that and which this would be and how you
would measure it but I don't think that you would need to leave the boundaries of known physics
to allow that organisms are sophisticated enough to also transmit information that is
rather than over the long distance outside of the senses that access to your nervous system.
I feel like you can do it almost like it's a fine two-dimensional predictive algorithm that you
developed for that specific individual and you've spent a lot of time with them you know how they're
going to act in a lot of variable interactions even if it might seem like it was like an accident
out of the blue there's some predictability to everything in life and perhaps yes we're picking
these things out with bias but there is something to be said about like you better understand this
person's fate you're going to think like oh did they just get injured or did they just consume
a substance like something like that. Yeah but you might not know this so it is tempting to think
it could be some kind of super determinism that allows you to simulate what the person is going
to do at some point but what the person is going to do doesn't just depend on that person
that this person gets into a traffic accident largely depends on other drivers that you don't
know and probably don't have connection to yeah and so it's difficult to explain it all this way
but we also know that people do edit their memories and especially when they're motivated to do so
and it's not a conscious thing so it's I think correct to be skeptical about this and I mean
evidence very carefully but it's not necessary to dismiss all this evidence because it is conceivable
that it's possible right what you do notice is that when you study people at Berlin when they do
trips you notice this phenomenon of contact height which basically means people change their state
based on the state of the environment it's not just that people get in a different mood if people
are sitting next to them but they can even start to trip when people next to them are tripping
it's a very interesting phenomenon that basically people have this physical resonance in their
substrates that can be so strong that their mental representations start to resonate and go out of
vague in the same way and if you also notice this with I say mothers and babies I have sequences of
pictures of my wife and the baby looking exactly in the same direction having the same facial
expressions this out looking at each other over a longer period of time it's quite interesting
and it's very tempting to think what happens when she holds that baby is that they're physically
resonates so much that their mental states interact I mean that baby did also come from her like for
a while their identities were entangled yes but their nervous systems are no longer physically
connected right so they're not looking at each other yeah so they're basically integrated information
over each other in such a way that their mental states get synchronized to a large degree and this
is also what mothers very often report that they basically feel what the baby is feeling and now the
question is how much can you take them apart without that phenomenon completely breaking down
and so the idea here would be that if you have people in the same room without physically touching
each other it's still possible for them to have that degree of a certain degree of synchronization
so you can feel the emotions of other people in the room without even looking at them and it could
also work outside of the room as long as there is enough information crossing physically between
the bodies of these people in such a way that it eventually can be interpreted
they were siblings that have never met each other but they named their their dog the same
this is another interesting phenomenon but this suggests that there is a lot more determinism
in the the structure of the phenotype based on genetic heritage and I think that's
it's probably a sample of environment and individuals who basically to name give the dog
the same name they also go up in the same culture yeah but even given the same culture they're
seeking out the same stimuli yeah the point that I would add to that is when you have a shared
ecosystem that's essentially a shared language you're sharing the same alphabet and grammar you're
sharing you know what we're all doing right now right for example is there are these noises coming
out of our mouths okay all right these noises don't necessarily have an inherent meaning
we have a shared hallucination a shared agreement that this means this and that's yeah what is your
question no my question to that that point is that is would you agree that you can very much if you
have people um had different points in space and time have enough similarity in their their timeline
of things that they do that they could essentially be synchronized they're not physically linked to
each other with the both but they're actually you know abstractly doing the same thing because
there's enough similarities that's why if you spend enough time with somebody adding to their points
you start to think like each other or you share you're sharing an abstracted structure together
in the way that you communicate things and think about things you do that long enough
and then then you get these things called cultures where everybody in this clip when you create a
category or a group correct you're creating a shared perception of reality in front of you
that's by nature separate from some other perception of reality to another group
and how do you get those ones into a category here how do you get those groups a and b to be
synchronized even though they're different i think a culture does not mean that people think the same
thing so maybe you could say they do but then it's a different thing from people naming their dog the
same or people having the same emotion at the same time despite doing different things and being in
separate rooms right these are different phenomena and i i think it makes sense to treat them a
separate phenomena and describe them with a separate terminology because a culture can exist
there's very different individuals that don't agree in the perception of the world but they
are complementary in some way and can meaningfully interface with each other interact with each other
and that's not the same thing as thinking the same
so earlier you were talking about your your experience
would you characterize that as like going back to earlier when you characterize
the six plus the zero level of consciousness would you characterize that as like another
level of that and if so why does it not naturally occur for most people and it requires training
typically you only pay attention for the things that don't work and the parts of your mind that
don't work don't attract your attention that work don't attract your attention so the reason
why most interesting people had interesting childhoods is because don't get attention in things
that always work for you you don't question your personality you don't question your interactions
with the environment if they work and if your instincts constantly fail you you might be forced
to reconsider the entire architecture of reality in some sense that's my own story and i guess the
story of many scientists that i'm born with worse priors than most people and we see born much more
stupid than the average person and as a result i needed to put attention on building a model of
reality that worked for me whereas other people don't have that need i noticed this when i gave
it a TEDx talk and MIT asked me to prepare this with the local toast masters a group with normal
real people instead of crazy MIT students that i normally had in my class and they
gave me very different feedback than MIT students would have given me the first one was
you need to speak more slowly you need to reduce the rate of ideas by a factor of about at least 30
second you need to explain why this is what this is good for why would you need to understand
consciousness that's this happy to cure cancer but solve depression right and that is a very
interesting thing most people don't have that issue there is no need to solve consciousness
because it works right why would you need to figure out what that is and it's only when you feel
oh my god i'm born into a monkey and in this kind of universe and you might disagree with your
government but i fact myself disagree with the entire universe what's going on here why am i
uploaded into a monkey now that's the same verb
and so you basically need to get attention or something that's a mismatch between how things
are and how things should be and all your attention arises over disagreements with how the universe
works so attention is all you need
yeah so the thing that currently interests me most is how can we make progress on understanding
these questions more productively and an issue that i found while i was working in academia
especially while i was in germany was that students were super interested in all this stuff and
i was studying mostly AI but also all the other subject that was interested in and then
students asked me where we can we actually i have actual AI lectures because we got lectures in
machine learning or case-based reasoning but not in artificial intelligence and so i realized
oh we need to re-read society of mind and the PRJ and cognitive architectures and put our own
curriculum and most of that was stuff that was more as form and there were a few people
busy in the field of AI that were still working on those questions and it was not because these
questions are not interesting but because most people agreed that you will not be able to resolve
them in this space of grand proposal and so when i proposed working on topics like understanding
agency and about the agent paradigm and so on it was always the question what is the thing that you
can answer within the time frame of one and a half or maybe three years because otherwise that's
not findable and the same thing is that tenure positions are built around series of such projects
and so i realized that all the professorships that were open to me that i was offered was things like
a semantic map or cognitive robotics and so on and i felt semantic map is going to go away
by what you want to undertake semantic this xml that's going to be a non-issue in a few years from
now right and it was but at the time because it was a fashionable topic you could get a job
doing this and i guess there's still professors working on this stuff because they got a job for
this and at the same time many of the topics that we are interested in the practice intro
science are not being worked on and how can we create spaces and methodologies to do
paradigmatic work in this region and i suspect if you want to work on consciousness you currently
cannot do it in neuroscience most neuroscience is actually not curious about how this works
and because they don't have methodology to address it it's not even a very scientific notion for them
in ditto and psychology right it's that's a very big issue to me because it is a question if i think
we can make progress on and then you have to work on but how would you actually do this how can we
develop a methodology and terminology and so on and a discipline to actually need to work on it
and so at the moment i suspect that we need to create some institution similar to Santa Fe Institute
for complexity science for studying consciousness and the computational paradigm that is integrating
over neuroscience and psychology and AI and philosophy and is taking ideas from all these
fields but it's not committing to any of the existing methodologies because they are all
non-productive for studying it and i guess my institute is also in a similar situation in many
ways that it's trying to do things that normally should be done by newer scientists or biologists
but are not yeah eric oil has a who used to be here at Tufts he has a really good essay on this
it's called uh neuroscience is pre pre paradigmatic uh chance is wide yeah so
i suspect that what happens when we started going into neuroscience is already post-paradigmatic
because it doesn't care about a paradigm anymore it's just methodological right exactly that's
putting talks about yes okay so but i think this is adding to your point about some kind of
institute or or structure or framework that lets you kind of draw from these different fields
together under a shared language in that case right i mean maybe you could say a shared language
natural language or or mathematics or whatever but how do you get people neuroscience and psychology
physics and and biochemistry and all these different fields to come together and collaborate
in an effective way i think santa fe has done a pretty reasonable job with that but i think there
is more to be done and i think we have to also have a structure that takes into consideration
the nature of having a different perspective because let me ask you this do you feel like
when you start to seek agreement with things you're already kind of shooting yourself foot
don't understand that question when you when you if i'm seeking to agree with something
that's basically saying i'm trying to target something to fit into this puzzle maybe that
puzzle is incorrect and that's been interpreted differently and you should be going another route
but because you're kind of getting this television of oh i have to solve it this way no me this way
or this is a problem maybe you have to step back refresh your mind a little bit reinterpret that
say maybe this is an puzzle piece but this is actually rubik's cube or something else
have you ever noticed when we look at uh evil super scientists in movies that they're actually
not scientists but they are engineers yeah but there is usually no control room there's no peer
reviewed study instead there is somebody who tries to get something to work and i suspect that uh
in the time when science was most productive in this modernist era which ended roughly in the 1970s
and so on most scientists in the major engineers they tried to get things to work and it's also
what i found to be a very productive stance in computer science that when you want to understand
exporting you can make theories about sorting but eventually you need to write testable algorithms
and what you discover is very often you think you found the optimal but you did not and you
often need to do experiments in this way and the experiment is usually not about how can i apply
my known sorting algorithm in many many ways and pretend it's the best one but it's basically it
always works like i think it's a pretty good idea please everybody shoot it down and this is how you
make progress so it's not trying to agree it's the way to disagree and i think that's most valuable
at science is not so much the answer it's this uncertainty discovering new uncertainty is super
valuable because uh finding uh answers to question is often much much easier right there are methods
for this or you can develop them and somewhat straightforward but finding productive questions
that you can actually meaningfully answer that give you useful insights that you can then apply
to a better model of reality that gets you back better on it and let's you understand deeper
what you want to know uh that i think is the job that you have to do if you develop your
experiments what do you think is the main driver about why people don't like to combine fields
together oh yeah it has to do with career considerations it seems that the phd is designed
as a great filter some of people who manage to get through the phd and enter tenured positions
feel that thinking is frivolous it's just a self-verifying masturbatory activity that you
should not actually engage in instead should have learned that your job is about applying methods
and so you learn how to do this and uh the questions are limited to the things for which
you already have good methods because this is what makes you productive which increases your
impact factor which allows you to publish in the existing communities and existing journals on the
existing topics that are reviewed by your existing peers and so it's a normal dynamic that can only
be broken if something comes in from the outside and says uh oh you need to understand that academia
has the card and sometimes you need to uproot the region of the garden and plant something here
and if you just let the garden grow by itself then it's going to replicate what's already there
this is this is just look at the look into the field of meta science because it's really a systemic
issue in how scientists funded and the short-term major grants and the program managers overseeing
those grants are coming through the same system where they're developing myopic short-term research
so um uh this is this is why I think meta science is really important and uh I'm gonna say just gonna
say um it's also important that somebody actually cares and if you look at the system right now it
does not seem that there are many adults left at the top at the end nobody really seems to care about
keeping the civilization afloat and keeping it on course in an organized way and so there is no
money there who can tell the universities now you need to change in a way that makes you productive
again and make some progress on those questions I remember I was gonna say one solution is funding
people not France so just funding really really people giving them some leeway for several years
or or funding institutions or groups
this is there's many many good ideas on how to improve science it's just
reforming any you know system is is hard yes so I suspect that now we mostly identify no longer as
individuals who develop ideas or develop theories or intellects that you interact with but you are
part of teams of large groups that apply certain methods certain paradigms and so on and is the
individual becomes exchangeable in this whole thing and in this perspective it's much harder to
make progress on the paradigms it's fascinating that when uh fun and uh came up with this notion
of normal science and so on that normal science didn't exist yet we see next door um somebody
like uh minsky was creating uh ai and chomsky was creating linguistics and everything was still
paradigmatic and pre-paradigmatic and this idea of normal science was also a new paradigm
it's an interesting question to which degree there was a self-fulfilling prophecy or just
a very prescient anticipation of what was going to happen
it does seem like the things have become more locked in
and the interval between paradigm shifts is growing some people think that's usually
less willing but yeah I remember studying psychology is an undergrad and seeing that
the way in which they did statistics would not possibly work like this idea we remove all the
outliers and we repeat the experiment for as often as we need until we get a good p-value
and the p-value is that thing that decides that it's good and you will always find what you predict
in your study otherwise you cannot publish it and then there comes this famous replication crisis
and the outcome of the replication crisis somebody describes it as you learned that
there was an airplane crash and 50 000 of your loved ones have died in this airplane crash
and the depressing thing is that nobody bothers to even idea them nobody cares which ones don't
replicate which parts are now invalid because nothing depends on anything it's an entirely
only an employment program that has it yeah so I don't know really what to do about this
and it's not that science before that was ideal and non-defective right it's a it's a evolving
enterprise and there's always stuff going to be decaying and there's also probably stuff going
to innovate and happen in new ways and I think we are now in a very happy circumstance because AI
seems to be working surprisingly well uh we have the deficit of understanding what it does
and what it does to us and the present level of discourse is mostly Emily Bender and the
New York Times versus some arguments blog which is abysmal if this is the last then or best in
intellectualism against the machines and the statistical models right this is not the level
at which it should be and I think uh optimistically this will be a wake-up call for us to reinvent
the vigorous science and philosophy that is able to deal with these new challenges
yeah so I suspect what we should probably be doing is to build an industrial network
that is working not just across the US but starting maybe here and in the Bay Area
and is connecting a lot of places to basically get us to reinvent the sciences of the mind
okay thank you very much for your attention
you
