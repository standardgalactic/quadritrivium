so basically there is no model in newer sense it is complex enough to actually replicate
learning and control as it happens in nervous systems if you put this into a simulator they're
able to get abstract features of neurons right and so on and we see a lot of interesting things
that we look at the connectome but we cannot actually model the brain of drosophila or portion
of it in an attic for debate where we actually have the neurons as the switching units and this
could be because our models are incomplete but it could also be because we are missing something
maybe uh neurons are basically just telegraph cells i suspect that humans have evolved for a
very particular purpose to move our muscles very fast and to do this we basically needed to build
wires into our organs that translate information very very quickly and they have a high metabolic
cost and they need to speak a specific code so that it's stable over long distances they basically
speak in more scope to each other and these spike trains and these spike trains have different
constraints than the cellular communication to neighbors if you just want to talk to your
neighbors there are many ways of doing this you can elicit them mechanical signals just
by pushing at the membrane of another cell you can exchange all sorts of chemicals you even can
send over RNA to send very complicated messages but the spread of these signals is going to be
limited by the jumping from cell to cell and this means that signal propagation is going to be like
millimeters or centimeters per second at best this means it's magnitude slower than what the
nervous system can do and so once you evolve the telegraph cells to move your muscles very fast
you compete with other animals at a high metabolic cost you also need to do perception and decision
making at the same rate so you build an information processing system out of telegraph cells
this telegraph network is able to make sense of reality and control the organism very quickly
but this doesn't mean that the other cells do not have opinions as well right so it's quite
conceivable that if you are a multi-celled organism it lives for long enough that it makes the model
of reality that allows this organism to discover itself and the world and sort problems in the
same way as a nervous system would do it's just going to be a couple of magnitudes lower than our
nervous systems operate but this is a hypothesis that most of our science is very uncurious about
which is this weird when you think about it right it makes sense that plants have operating
systems similar to animals that run on them but you they would not need to use specific cell types
so you don't need to look for nerves and plants you also for information transmission in our
organism it's not always necessary a dedicated cell types which do this because any kind of
cell type can be recruited in sending information towards the organism so if information a
consciousness can organize information processing in brains it's conceivable that there is something
that is analogous to our consciousness that exists in plants just over different time spans
and our ancestors actually believed that very strongly so if you look at the european fairy
tales they basically say that the spirits of plants are sentient and they populate the forest
and one day in fairyland there's seven years in human land which might allude to this tent
differential but what we see is that plants have means for a functional approximation they can
learn there's evidence for communication inside of plants so with you how the woods of a tree
information gets sent to the leaves and back to the woods and the tree reorganizes accordingly
and there's also evidence for communication across plants even over considerable distances so when
you have a forest in which one side gets infected by some bark that invades the forest trees long
of a far away are going to develop defensive matters long before this happens so there is
some kind of communication going on across the forest there's another aspect if you are
living next to a tree and if you're for instance a mushroom you can probably learn to send
information to the tree because the individual cells in the tree don't know what information
they're translating they're just passing on a certain pattern and if there's another organism
going next to it then there can are no firewalls it means they need to evolve to get along this
probably means that forests over a long enough time spans are going to evolve something like an
internet and this internet is going to have some kind of shared protocol over which the
individual software agent running on the plants can build feedback loops that extend beyond an
individual plant which allows them to be somewhat non-local in the forest and even move around in
some sense in the focus of attention right this is something that I don't know whether that's all
true it's something that a lot of cultures look at and I as a computer scientist that looks at
this evolution perspective I just look at means and motive and I don't see how to stop evolution
from forming such a structure so it would be something that I would be inclined to look for
be very curious about because I suspect it should evolve under normal circumstances
something that you should expect to exist in nature because it is very useful to the plants
into the ecosystems and it's also has a lot of explanatory power and evolution can control them
resultants so this question to plants have spirits who forests the internet and can these spirits
travels forest internet is very very interesting from an evolutionary perspective and so it would
be that there is a complex ecosystem of spirits in nature and these thoughts basically has
led me to adopting animus as a useful metaphysical perspective not as some kind of religious
superstition but as a perspective that basically says that we want to understand living nature
but central is self-organizing software it's not just mechanisms but it's the software that is
stabilizing those mechanisms and is recreating itself through those mechanisms
so if life is animated by self-organizing software the invariance is not matter of
the mechanisms but the software itself and this gives us a slightly different perspective
of an evolution for Darwin evolution is the competition between organisms and then Dawkins
comes along and says no no the organisms are just a phenotype what actually matters are the genes
right so actually evolution is about these complicated molecules that replicate themselves
by expanding themselves into phenotypes and then evolving but from this cyber animus perspective
I would say that evolution is the competition between software agents that partially encode
themselves in a genome and implement themselves into the organisms but the actual invariance that
you're observing is the software right and it's very interesting because this is actually this
Japanese metaphysics that describes that living stuff is basically software that is colonizing
regions of the physical universe and when the software breaks down then this region of the
universe is up for grabs for other spirits that try to move in and control that region
it's a very interesting perspective that I found is basically healing a lot of the rifts that we have
in our metaphysics so from the perspective of artificial intelligence the question is can we
switch out the outside in design that we currently have an AI that leads to the
production of mechanical systems that basically like a whole amount following a set of instructions
to a way in which we can organize the substrates in ways that are compatible with life so basically
can we take this new substrate that works at a fraction of the speed of light much better than
the cell the substrates that we currently have to run minds and organization on and can we populate
them with consciousness and with the principles of life can we basically extend our organization
of living things into the new substrates rather than building machines that are competing this life
and replacing it and I think that's a very interesting perspective to think we should
put some effort into studying the principles of self-organizing software and see if you can get
them to run in Silicon and this is basically what I want to leave you with for today I might
have to run because he has to give another talk and but I think we have a few minutes left for
computation sorry for disputation and for discussion and questions and yes and remarks doubts
a lot of the excuse is why my voice is kind of gone but you know one of the things that I I look at
is I tend to look at things as like a generalized language structure and cognition is very much
that way whether it's plants other animals humans like organisms whatever and I'm wondering
what are the ways that we know if we can actually directly communicate with other organisms so for
example if you wanted to actually communicate with a plant or communicate with a dog how would you
actually get on that same type of metric because for example you would think that if if these other
organisms lesser organisms of complexity are have a less complicated language like a dog or a cat
we don't really understand right and we don't really think in that way so what is the kind of
that fridge between allowing us to communicate very directly like we're communicating with you right
now with other organisms and you know things in the ecosystem well you're not communicating directly
right now you are communicating my natural language yes and this language this basically is
solution to breaking down your mental representations which are a language by themselves
into a discrete string of symbols in a learnable protocol and parse this discrete string of symbols
sequence of symbols that you're using that's why you can write it down as a string we also
have some limitations like we have a stack depth of about four or so because otherwise
language will not be learnable for everyone so we have a few constraints on language that makes it
learnable and comprehensible to us to basically the language is not something that you can touch
or point at it hangs in the thin air between speakers they need to be able to agree on it
that's why it needs to be reduced in complexity to make it learnable but the language in our
own mind is different for instance it is not entirely sequential but to some degree it's
trivializable you can basically envision a scene in which multiple things happen at the same time
and it's also executable you can unlike natural language which you cannot really run in your
mind which you can use to instantiate something that you can run there is a language of thought
that produces structures that you can actually execute like plans or even software programs
that you can instantiate in your mind and run and that these are interesting features of our
language of thought and I suspect it's a good idea to at some point not regularize the LLMs to
produce strings of natural language as their working memory content but to produce something
that is an invariant structure with limited complexity highly regularized that is basically
below the tokens that we currently parse so we go a few layers in and then try to recognize the
structure there into some operator semantics that we discover and that is able to construct and
navigate the embedding spaces of our LLMs and so when we are talking to a cat for instance or if
we are talking to a baby we are basically trying to figure out what state is this other system in
and how can we interact with it and that can also happen on a perceptual level and notice that my
daughter is extremely good at communicating with animals and that's because she feels what the
animals are feeling she vibes with them right she interacts with them on a very low level on the
level that is preconceptual and this allows her to build a feedback loop because the animal is also
capable of doing that and as a result she is able to communicate with the cat much quicker than
somebody who is only trying to make inferences on a symbolic level about the state of that cat
and it's also a way in which many of us communicate with each other it's just if you are a good
scientist you probably have a bit of autism and that makes it harder for you to communicate non-symbolically
but i would also say that ability to kind of disassociate from the situation
and see it under a new light is also responsible for a lot of the worries that we kind of create
breakthroughs or new discoveries because i like to say kind of looking at the same stimuli
simulate differently right you're looking at a different angle of the same thing because there's
some level of ambiguity degrees of freedom of interpretation that take your point a step further
what are we all doing right now you're speaking up here you're not physically touching us in any way
yet we're directing our bodies and minds towards you so it's almost like when you have a language
or some means of communication getting on the same bite with somebody else is you're controlling
each other across different aspects in time and space that's why it's easy for us to control
other humans to degree control other you know other animals how can we get telechair to move
itself does it have the self modeling capacity to move itself over here no so what i was thinking is
how do you in a perfect world if you had enough agents around like chairs or tables or whatever
that had some type of uh self modeling capability and how many ways that could be accomplished
you could cognitively like we're talking to each other right now if i were to yell you know
f-i-r-e really loudly or you know other things in a room full of students at a school we'd all
react a certain way to that having not physically touched you at all if there was a tiger walking
into the room right now without interacting with us in any capacity we'd be scared like nuts
right so i think there's this kind of really interesting idea between um the degrees of
feeding some type of stimulus has and how you're interpreting that and reacting to it right so
that's basically conditioning so so my the end of that rant and my question for you is what are the
ways that we can improve that those degrees of freedom in an agent and our ability to interpret
that so maybe you can say that's intelligence or consciousness or or something to do the working
memory in terms of capacity like how would you kind of go about that when you think about the
degrees of freedom as this paradox of free will that this the less you know what you're doing the
more degrees of freedom you seem to have track and the more you know what you're doing the fewer
degrees of freedom you have right because you know what your actual options and what the outcomes
are and how you're interfacing with reality and so you compensate us to some degree by expanding
the degree of control that you exerted in your environment and basically being able to model
reality more deeply and then are controlling a larger part of reality and identifying yourself
as a system that has much greater influence on the world and this boundary that we have is not
the boundary of our skin to the environment it's the boundary over which we can build feedback
groups into the world that we are interacting with and what's an interesting observation is that
basically all agents above a certain complexity are collective agents they are built from lots of
units that the individual agency excels and or behaviors in your own mind and that they need
to harmonize themselves into some kind of collective agent that keeps itself stable and
harmonized coherent or all the individual sub agents and produce globally coherent behavior
and the species we are a state building species not just the tribal species we are in some sense
infinitely scalable and this is because we are able to form population level agents and the
civilizations that we become part of and individually we are not generally intelligent
individually we cannot discover our natural language individually we can not develop writing
by ourselves from scratch individually we don't discover the concept of chewing computability
but in terms of universality what we discover is step by step over many generations before we
get to the notion of what a language actually is you need a thousand years of an unbroken
intellectual tradition. I have a question regarding consciousness and learning and how
subconsciousness fits into your model do you only need to have a consciousness
to learn is it possible to learn something subconsciously? When you are not attending at all
you have difficulty to learn and you are able to attend to the thing that is happening you can
often learn by complicated things in one shot it could be that your attention is spread out and
a lot of things your attention and most of them are not made a protocol over but they still register
in some way integrated in your working memory context in this sense you can learn things by
a repetition that you don't attend to very much to the degree that you can find a lot of information
about in the protocol to what you're attending to. There's another question that is more interesting
that is our emotion and motivation is computed outside of our personal reflexive mind right the
personal reflexive model of ourselves is embedded into our larger environment a metal environment
and what you feel about the world is not generated by you it's generated by your outer mind it's also
not generated about the universe when you experience pain or laugh or something like this it's not
done by your personal self and it's also not done by the universe through the surface of your body
it's happening inside of your mind by systems that are intelligent where they need to be able to
understand your actual interests in the world and so you're being presented by ideas from your
outer mind by some agent that models how you should be embedded in the world and that thing
is outside of your personal individual consciousness but what you often find when you meditate is
you can integrate this part and you can interact with it and notice that in some sense it is you
it's usually something that is just separate it's not integrated with your personal self and you can
deconstruct the boundary so it's basically as if there are two protocols being maintained in the
mind and as a result these parts of you don't know about each other what happens when you're
able to fully integrate that part it depends so for instance there are meditation schools that
teach you genitals which are states of bliss that you can induce at work and it's in some sense
is if you are stumbling into the room your brain makes cookies and you can then decide to ward
yourself on cookies and this might lead to bad effects but if you are a child you think that the
