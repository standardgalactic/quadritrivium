Excellent. Well, good to see you guys again.
You too. You too. I enjoyed our previous discussion enormously. I was just saying to Mike before you joined us, Chris, that it's been a very long time since we had that previous discussion.
And I must apologize. Mike said to me that it was my fault that there was such a long delay, apparently, by my assistant could only find this time, which sort of shocks me.
So I'm very sorry about that.
Yeah, no problem at all.
Now, these things happen.
And Mike, Chris and I have seen each other twice since we met, because we were both part of a meeting, at least a couple of meetings arranged by Maxwell Ramstead under the auspices of the computational phenomenology group.
I was surprised that you were not there, Mike, but Chris was very much there. You seem to have been quite pivotal in that project, Chris.
Actually, those are the only two meetings of that group that I've ever been in.
Maxwell just invited me to join those discussions kind of at the last minute.
But yes, they were, they were quite interesting.
So I just wanted to reference that Mike because Chris and I were wearing that couple of meetings and then the other thing I wanted to say is I read.
I watched the recording of our previous meeting because it was so long ago I wanted to remember what it was that we had sent to each other. And I was embarrassed to see how much I spoke.
I hope tonight today to do a little bit more listening and a little bit less talking.
I actually, I mean, I don't know if you guys have other stuff on your agenda. I have a couple of issues that I wanted to get your thoughts on. So I'm looking forward to some of your talking for sure.
Great, tell us what's on your agenda and then maybe Chris will tell us what's on his.
Okay, well, I wanted to get your thoughts on two specific things. One is, I wanted to run by you an idea for a paper that a student of mine and I are doing on the various existing theories of consciousness and how they might apply outside the brain.
So I just want to kind of talk a little bit about what we're doing and have you guys give thoughts on that and see what you think. And then the other kind of thing that I wanted to chat about is see if anybody has thoughts on this idea of
can you, can you, it sort of ties into control and free will and things like this but this idea of, can you decide what your next thought is going to be right this is like it seems to me that one thing we don't really have control over in the short term is, what is my next
sort of is what it is, right it's kind of pushed by whatever was before that but and so I don't know if you if you agree with that and then long term you can sort of think about strategies to control the overall ensemble of your thoughts in the future so maybe
meditation, you know who knows what else one does over the long term to affect it but but this idea of what level of control do we have over the next thought that we have and what's the time scale for that and what do we think about that.
So, those are, those are two things. Oh, and I guess I guess there's a third one the third the third one is.
Why do you suppose it occurred to me that wouldn't it be interesting if we had more control over our, over our preferences, right so somebody does some some quote that somebody said well, you can try to get what you want, but you can't want, you can't decide what you want.
You know, it's sort of like, you know, we have these we have these these goals and it's very hard to rewire your preferences the same way that you that you have control over other things.
And it would seem to me that that would be pretty adaptive right in certain environments if you find that you know your preferences are out of touch with the group or whatever, wouldn't it be nice to be able to change your preferences, you know, but it doesn't seem that we have any ready control
and I'm curious if you have thoughts on why that is, you know, I've often I've just as a stupid example I've often thought there's a lot of, there's a lot of sports being shown on TV right this football all the time on TV.
Now we start wouldn't it be nice if I actually enjoy that would be tremendous like there's all this you know because it's there all the time like that would be great, but I get nothing out of it and I have no, I have no ability to, you know, make a decision that okay from now on, I like that, like we have no, we have no ability to do that so I'm curious why that would be.
So, so before we hear your agenda Chris let's let's tackle Mike's agenda, and then we move to yours.
I'd like, I'd like to start by responding to the second and third of your of your three points.
And then maybe Chris wants to comment on those, and then we can go to your first point about because that's rather a different point about different theories of consciousness, detached from biological constraints.
But the second and third of your points. I think they form a unit, you know the one about how much control do we have the course of our own thought processes, and how much control do we have over the contents of our preferences.
I think that they're linked in the following way starting with the third point preferences are fundamentally rooted in our phenotype.
They're fundamentally rooted. You know there are certain. We prefer a certain blood pressure. We prefer a certain hydration assault sugar, oxygen, carbon dioxide, etc level because we have to, because we are human beings those are our viable ranges those are our preferred ranges.
We are constantly seeking to find ourselves in those states. And that's given by our phenotype. And I think that we do not sufficiently appreciate and I say we I mean, not you guys.
I mean, cognitive neuroscientists do not sufficiently and I don't know how much this applies to, to other, you know, like AI and whatnot, you would be in a better position to know.
But I think that cognitive neuroscientists in particular don't sufficiently appreciate that there is a joint prior preference distribution that goes with your phenotype, and that dictates the whole story.
It dictates the whole story in its entirety. I mean, that is the sort of starting point for the whole story. In other words, the whole of the predictive model is naturally selected.
And most of all, you know, there are certain predictions that we are born with which are called reflexes and instincts. And these are predictions as to what must I do to bring myself back into my viable bounds in other words what must I do to bring myself back into my preferred state.
And then we have an acquired predictive model. In other words, we, we, we, we greatly supplement in a context sensitive way, the innate predictive model.
But the point is that all of this is in the service, ultimately, of meeting our phenotypic needs. And so, to get derivative preferences is just that they derivative they ultimately are, you know, they context specific roots back to how to how to
meet the requirements, the demands of the joint prior preference distribution. And in what I've just said is the answer also to your second question, it's that cognition is not something that, you know, it's, we just sort of have at our disposal, and therefore we can do what we will with it.
Cognition is the predictive work that is demanded by those prior preferences. So you have to satisfy your expectation of a certain temperature, hydration, oxygenation, etc. level.
And so you must perform predictive work. In other words, learning from experience. And that's what cognition is. So it's not something that that's, that's a pre for all, you know that I don't mean that it's entirely determined of course I mean first of all that's
realistically determined in all sorts of ways. But secondly, there are, there are expenses of cognition, where you can in a top down way decide I am now going to recite the multiplication tables and then that determines what your
expectations are going to be for the duration of that recitation or I'm now going to cite Shakespeare's 54th sonnet.
And, but it's, it's a temporary, you know, the extent to which we are not able to impose our will over our thought processes, let alone our preferences.
So this is a really important lesson for cognitive neuroscience about what is calling the shots in the life of the mind. And so that's my answer to your second and third points.
Yeah, I would.
On the second point first and then the third.
We have very limited metaprocessor control over what gets presented to consciousness and probably even more limited conscious metaprocessor control over what gets presented to consciousness.
And for evidence in that regard, I would look to things like Nick Chater's book, which is really all about that question of how much, how much control do we have over the very next item that we are conscious of.
And I think the answer is very, very little.
I mean, we can choose to look in some direction, for example, but we can't choose what we're going to see when we look that way. It could be a tremendous surprise and often is.
I think that's actually in the nature of metaprocessing.
The, the metaprocessor is a set of heuristics that does the best job it can at predicting what's going to come next.
Only if you can predict what's going to come next, can you feel that sense of controlling what's going to come next.
But it's not all that good at doing so.
And it certainly doesn't have a 100% accurate deterministic prediction system.
It just, I think, has very rough and ready heuristics, which basically our minds are a combination of a bunch of rough and ready heuristics.
So to look to the third point, I think, as Mark said, the answers are coupled in that we can learn to like certain things.
And given certain experiences, we can come to dislike certain things sometimes intensely.
You know, a good, a good example is people who come to have very strong food aversions after a very bad experience with some particular kind of food.
But that's kind of very surfacing icing on a very deep cake that has to do with things of the sort that Mark was talking about that have to be satisfied.
And I think a really good question is, to what extent are our affective and reward system driven responses to things, including finding things interesting and the feeling of curiosity, especially.
How closely coupled are those to probably very early learning experiences that had to do with maintaining the more basic kind of homeostasis that Mark was mentioning?
I mean, to what extent is our interest in science, for example, driven by experiences that we had when we were very young?
I don't know.
To what extent is that an outcome of prenatal development or something like that?
I don't think any of that is actually known.
But I think those are interesting questions of how those kinds of affective and reward system processing loops get put into place by experience.
I was thinking of, let's say we were building an agent that was going to go around and maybe live in social groups and something like that.
And so now the design decision, right?
So definitely I take the point that we don't want to give it control over physiological set points because if it decides to like a temperature that's going to kill it, like that's terrible, we don't want that.
But beyond that, kind of all the variable social stuff that gets developed later, wouldn't it be useful in a group setting if you find that you have preferences that are completely out of tune with the rest of the tribe?
And, you know, rather than sort of get kicked out and have all this friction, wouldn't it be nice to be able to say, okay, yeah, you know, from now on, I too like with coconuts and so now we can all, you know, do whatever the tribe does, right?
So I just wonder, is there, is the fact that we don't have control over these, is that one of these vagaries of evolution that just sort of didn't show up and that's it?
Or is that actually a good design decision, you know, would it be better for us if we did have control over, you know, these non-physiological preferences that are extremely wide, right?
Especially in humans, there's an extremely wide range of human preferences and one can't help but think that life would be, some aspects of life would be easier if one had some control over some of those things.
But I wonder if, right, I wonder if our inability to do that is fundamental and, you know, important in some way, or just that just happens to be the architecture we have and we could make a better one.
I think, go ahead, Chris.
I was going to say, I think an interesting example of this is phenotypes like sociopathy in which you have people who have preferences, which in a sense are very different from the rest of us.
And that seems to be maybe not a straightforward genetic variant, but it's certainly some kind of developmental variant, which is very long-lived in the population, right?
The evolution hasn't gotten rid of it.
It has, at least in some individuals, enormous rewards, not only in biological fitness, but in social status, etc., etc.
But it's an enormous misalignment with the preferences of most members of the group up to a point, right?
It's also true that many humans are enormously attracted to that personality, and that's one reason why sociopaths are so successful in many social settings.
So I think it goes both ways, in a sense.
We have these enormous preference variants that are in what kind of, well, I guess they're all variants in what kind of social feedback do I want as an individual?
And the fact that we have these huge variants and they seem to be stable over tens of thousands of years suggests that
if not have a function, they somehow keep societies going in a way, even though they would seem to be disruptive.
So what I would say to this last point of yours, Mike, and this last point of yours, Chris, is the following.
And then I want to go back to what Chris said prior to what he said now.
In other words, his initial response before your follow-up remark, Mike.
So about this point, I think that we must recognize not that there's consensus on this point, but I think the evidence is overwhelming, that there are a multiplicity of phenotypic social emotions.
In other words, social emotions are not by their nature.
Social preferences, therefore, what I mean to say, is that there are social preferences which are people assume these are because they're social, that they are acquired idiosyncratically.
And that by no means the case. There are social emotions like, you know, all mammals play, you know, and their rules that govern mammalian play, and that's very social.
It's got to do with the in-groups, art groups, dominance behaviors, etc.
There's, there's nurtured behavior, which is, which again is something that you see in all mammals.
There's attachment bonding in the sense of looking for a caregiver, and so on, you know, fear and rage are perhaps less obviously social.
So that's the first thing I wanted to say is that there's a range of social preferences that are phenotypically given.
And then we have, and with those come phenotypically given predictions, which as I said earlier are reflexes and instincts as to how does one, how does one remain within this preference distribution.
How does one does that, but they too stereotyped, they too generalized and don't apply in too many contexts.
And so then we have to individualize our predictive model in relation to each one of those preference distributions.
In other words, what else must I do, what must I do in this situation versus this one versus this one, in order to remain within my viable bounds.
So there comes the variability the individualization that depends on what kind of niche you find yourself in.
But even more important than that is that many of these social emotional needs conflict with each other.
So for example, you have an innate prediction in relation to your attachment needs because all mammals need to attach to a caregiver because they can't look after themselves.
The innate prediction is in a state close to keep keep mummy close forever and always. That's the prediction. And then there's another innate preference which is anything that frustrates and impedes me that gets between me and what I want.
I must get rid of that thing.
That's the prediction for aggression for rage for hot aggression.
Now, whose mother never frustrated them. So here you have a conflict.
Oh dear, I've got a prediction that I should attack this very person whose presence I most need in the world.
How do I resolve this. And so the, the, the, many of the ideas and critic preferences that we see, especially in clinical populations or, you know, ways in which people try to get themselves out of these, out of these
political corners. And because there's a range remember I'm saying there's not too social emotions there, there are a range of them.
The permutations that you end up with the possible permutations are enormous.
But to come back to your initial point.
I think the more that it becomes something that you can decide. I'm not, I'm going to do this. That's a, that's a policy, but rather, I'm going to feel good about this outcome.
This outcome will make me feel good. This one will make me feel bad.
So if you're able to actually say, I will feel good about this outcome.
Even though it's not the one that naturally comes to me. The more I think you're no longer talking about real preferences, you know you're actually talking about things which are no longer in the nature of an affective nature.
So that goes back to your, to your initial point.
As I said, I want to go back to what Chris said earlier about the extent to which we in response to your, to your questions, Mike, about the extent to which we have control over the, over the contents of our consciousness was, was the way,
what, what Chris said emphasizes consciousness.
And, and, and I want to pick up on that.
I think that it's a very important point.
I believe that what we become conscious of is to a very large extent determined by where the uncertainty is.
The more certain, the more precise your predictions, the more confident you are in your predictions, the less you need to palpate the error signal.
The more you can, the more you can just have a monotonous course of action which does not require consciousness.
For me consciousness pivots on felt uncertainty. In other words, it's the palpating of the confidence in your prediction over over the error signal.
That constitutes consciousness consciousness is the, the palpating the, the, the, the, the, the modulating of the amplitude of the precision.
So Chris's point which he made sort of.
Without any, if you'll excuse the pun conscious reference to that way of thinking it was like an intuitive response about well, it's got to do with access to consciousness.
I think access to consciousness has everything to do with, with uncertainty, but the less the more precise the prediction is the less you need to modulate the precision in the area signal associated with it the less
the, that the execution of that prediction will be and vice versa.
And then again there's a prioritization of these different needs because you don't only have one, one preference that you have to satisfy you have a joint preference distribution that you have to try to balance them all up so there's a
prioritization of one or the other in time so so so what is most salient, you know, is is also a matter of a matter of uncertainty in relation to which of my homeostatic bounds is the one that I need to prioritize now so that also determines
access to consciousness, but then I want to link that to the other thing that Chris said which was about, although he didn't use the word.
It's about he spoke about novelty and curiosity, and the word I would use there is something like epistemophilia, and you spoke about scientists you know what what is it that make.
And there too, it links up in a very deep way with what with what I just said, building on what you just said Chris, that we, the, the, when things are going okay.
And that is when you're not in the group of an urgent need, like to escape the predator, or to find your, your, your, your caregiving object, when you're a juvenile mammal, etc.
You know, you have an urgent need. What you revert to is is something like explore, rather than exploit you know now I have the luxury of being able to to engage proactively with uncertainty, which is what curiosity is this this is novel this I do not understand
and therefore is interesting, let me, let me engage with this.
And because in the bigger scheme of things, the less uncertainty I have about how the world works, the safer I'm going to be in the future, the less the world is going to bite me in the butt.
And I think that our default, if forgive the phrase because it has all kinds of other meanings but the default mode of consciousness is if I'm not having to attend to a clear and present danger.
And then I just, I just find the world interesting and I engage with it. And so, again, this comes to the question of, what is it that comes to consciousness.
It is the thing that we are least certain about.
In other words, because that's what epistemophilia is is engaging with uncertainty.
So, so it goes against the grain to stick with something boring, that's predictable, you know, I know this I'm staying with this, you really eventually such shit now I don't want to.
There are other things more and so you use the phrase, because you said it might as frequently is something very surprising that that that that captures your consciousness and I think that's no accident.
It is precisely the things that are most surprising that for very good mechanistic reasons are what we tend to it's because that's where the uncertainty is.
And as I said, what's uncertain is what requires consciousness.
So you're beginning to head toward answering your first question, Mike, about what are some of the fundamental mechanistic requirements of a conscious agent.
And, and there again I'm so sorry you weren't at that computational phenomenology meeting because that that was pretty much the topic of those two meetings it was, what are the, the, the, the authors of which.
Which Chris ends up being one of this paper that they're trying to write over a sort of what are the minimal mechanistic requirements for a conscious agent.
They looked at all of the main theories of consciousness within the free and active inference sort of framework, and, and try to come up with the kind of integrated consensual model and Chris played a big part in that so maybe Chris in terms of answering
Mike's question you might want to tell him something of what of the views that that you and that group have been have been developing.
Yeah, tell us what you guys are doing and then and then we'll go back is my my my original aim is slightly slightly different than that but but I'd love to I'd love to hear what what you guys that come up with.
Yeah, this, this was an is it's not quite done yet.
It's an interesting question, I thought, in that the question that was posed is, if we start with the free energy principle.
And then, to what extent can a the term being used in the literature is a minimal unifying model but it's it's really to what extent can have an abstract model.
And I've also stated that with the addition of other assumptions, and these other assumptions may be mutually contradictory, generate some of the, the going neuroscience models of specifically human like consciousness.
This is a very different question than the question that you Mike and Jim and I worked on in that paper where we were trying to think about basal awareness and basal cognitive systems.
And there the free energy principle kind of unadorned with many other assumptions gives you a nice starting point.
But in this case, the other assumptions that get added have to do with the way the nervous system appears to be layered in a hierarchy of peripheral two more central processes, on the one hand, and the
kind of sandwich like picture that one gets.
Oh, when thinking about the arousal and attention systems.
And the emotional systems that we've just been discussing on the one hand, and the kind of heuristic metaprocessor driven kind of choice function on the other hand.
And how those relate to the content generation stuff, which seems in some sense to be in the middle, which determines what kinds of contents one can actually represent as a cognitive system.
That would be in the language that we used, or have been using, which reference frames does one actually have.
What sorts of objects can one actually recognize what kinds of motions can one actually recognize what kinds of attributions can one actually make of agency or whatever.
And in the case of human consciousness that's a very rich set, and we have introspective access to a lot of that stuff which other systems presumably don't have.
So the questions, what has been.
What are the minimal assumptions to be added to the free energy principle to provide a basis for constructing theories of that kind of consciousness as opposed to theories of more basal awareness.
Interesting.
So it's quite, it's quite amusing for me to hear now after the fact from Chris, that there was a certain assumption that I had missed. I didn't know in that group that we were particularly trying to come up with a minimal unifying model of what kinds of mechanisms
would generate human type consciousness.
Because I think that's a horrible constraint on my whole field is that my colleagues are too bound to a model example of themselves.
I'm thinking, this is the best place to start in terms of trying to understand what consciousness is all about and how it works I think that we're the last place we should start because we're complicated example we should rather start with the simpler.
So I didn't even realize that was one of the constraints and what we were doing.
This is this is a constraint that I kind of insisted be making made explicit in this paper because it so it became so obvious that it was the goal, in fact, of most of the theories that were being considered as being sort of interesting theories
developed on the basis of neuroscientific data about humans, for the most part.
And I think that that my interest, as well as Mike's is is much more in this area of basal awareness and very simple systems.
And what sort of things do you have to put into a simple system to make it able to do certain things.
So Mike, as you can imagine, I spent a lot of my time in that those two meetings, not realizing that that constraint was was driving the authors complaining about their corticocentrism.
Why is why is the cortex such a big ticket item.
And now you realize why.
So let's, you said that you had a more specific way that you wanted us to address your question, Mike, so let's come back to it.
So, so this is, this is a student of mine and myself are trying to do this.
What we want to and so we want to start broader than the theories that are focused on active inference so let's just so all of the major theories of consciousness that exist whatever it is that they're that you know that they focus on.
And what we want to do is analyze.
To the extent that any of those theories point out why the brain is normally thought to be the seat of it to ask to what extent do those same criteria are found other places in the body so for example, you've got this to hammer off.
There's a thing which you know talks about microtubules. Well okay there's microtubules everywhere, everywhere in the body, somebody else will say, Well, it's the you know it's the magnetic field of the brain okay there's magnetic fields everywhere in the
area this kind of thing so what we have is we have a table, and the columns are the different theories and there's six or seven different ones and then we sort of try and and they differ greatly to the extent to which they're explicit they all assume it's in the brain, mostly except some of the
they're explicit by referring to specific mechanisms, and then we have on the on the sort of horizontal and we have different things that we work on so body organs, the difference, you know cells different software agents you know all kinds of weird
conventional stuff, and slime molds and whatever and so let's just let's just take the case of body organs for example.
What we want to analyze is, to what extent do these various theories tell you why in fact it's the brain and not your liver that should be considered to be the only conscious thing in the brain right because generally speaking when you when you talk to most
people, and you say, Well, what do you know how about how about your liver and they say no that doesn't do my theories about the brain is okay but why exactly right like what's the, you know, what's the mechanism that rules you know whether that makes the difference.
And a lot of them tend to come down to things that are not brain specific at all so this, this is what we wanted to analyze right is to you know what what to to the extent that somebody is committed to one of these theories are they also then committed to having some distinct type of consciousness
elsewhere in the body that's, you know, so that's that's that's our little that's our little project is to go through these and see what do they say about the first the hardware in and then the dynamics and, you know, yeah, why brain basically that's the
you want to go for it Chris and I'll follow.
Oh, I was just going to say this sounds like a delightful project and I'm glad you're doing it is in an as explicit a way as possible.
Yeah, we'll see how delightful people find it.
You know, right.
Because I just thinking from a free energy principle point of view.
We and also Carl and his group have argued very strongly that here's a principle that applies to everything.
So, certainly any, any organ in the body any collection of cells in the body, etc, etc.
So, if one wants to be brain specific, then one has to add very strong architectural assumptions.
And if you think about something like integrated information theory, then really having positive Phi comes down to having internal feedback loops.
Everything has internal feedback loops.
And so I think in a sense, you're, you're calling a lot of bluffs and that if you start with these general theoretical principles about information processing,
then it's very hard to construct something that's brain specific.
The big, you know, the funny thing is that when I've brought this up to various people, you know, because you want to do their theory justice right then if there's something you know they should give the best case they can for the distinction.
The biggest argument that I get from this, what people say is, well, that can't be right because I don't feel that my liver is conscious.
You don't feel that I'm conscious either. Of course you don't. How would you know?
And so that seems like a terrible, like a terrible argument, but I think that's primarily where people sort of say, okay, we're good.
I know I feel conscious. I don't feel any of the rest of this stuff being conscious good enough.
And I think that that seems like a fundamental, fundamental error to me.
Right. Well, no one says I feel like my brain is conscious. Yeah, yeah.
It's, I agree with Chris. That's a wonderful project, Mike. And I really look forward to, to, to reading. It's what the output is of your deliberations.
So I also have learned from you to, to not think.
I mean that prejudice I shared with all of my colleagues, you know that it just goes without saying that when you talk about consciousness you're talking about the nervous system in general and the brain in particular, and it never crossed my mind that that we would
have the question that you asked, it's just not a question that has any premise. And so are now because of you find that a very interesting question.
Chris's point, let's just take it at the biological level, the free energy principle.
I start with Chris's point at the biological level, although it doesn't apply only biologically that the whole of natural selection is a self organizing complex dynamical self organizing system.
And where there is, where there is an adjustment of the predictive model as to, you know, what needs to be done in order to remain viable for the whole of life for each species, and then ultimately for each of us as individuals.
That comes to the question of what I think a very important part of what the nervous system does and the brain in particular is that it remains plastic that it is massively plastic in terms of its massively amenable to updating of its predictive model.
I think compared to most organizations is there's a hell of a lot more learning from experience going on in the brain.
I don't mean it's exclusive and that's why I started with the statement that I did you know I mean you really have opened my mind to to problematizing this prejudice.
But, but, but I think that remember what I said earlier in our conversation today, when I said that consciousness is about palpating the uncertainties in attaching to the prediction over the error signal.
The error signal of course is what drives the learning process. And so, the learning process is is is pivotal to what consciousness is all about it's learning from experience.
So I think that an a system, I think it's fundamental to a conscious system that it's doing predictive work. In other words, it's updating its predictive model, and in particular, that it's updating its predictive model in a way that is not given by phenotypic innate predictions
In other words, it's feeling its way it's palpating the precision is this going well or is this going badly it's increasing or it's formulating policies on the basis of fluctuating
in those policies. So, so I think an organ that that that, or any mechanism that does that, that's learning by palpating the, the, the precisions in different in competing possible courses of action.
And that means that it's capable of choice. It means it's capable of voluntary action. And I think that's what consciousness is for it's to guide voluntary as opposed to stereotype automatic policies.
I'll just add one or two or two further details. One of them is that if consciousness has qualities, which it does. Then I think an important requirement is that they have to be there has to be categories of need, it's not a system that's just doing the same thing.
I make widgets, I make widgets, I make widgets. It's that well now I'm doing this now I'm doing that now I'm doing the other thing. So, a complex organisms have a multiplicity of needs, and they are categorical variables they have to be satisfied in their own rights they can't be reduced
You can't just say I'm minimizing my free energy. It has to be, I'm minimizing my free energy years but it's factorized across sleep, hydration, you know,
oxygen, etc, etc. Each of those needs has to be met. Therefore, you have to have categorical qualitatively differentiable preferences.
I think that that is a major factor in what gives rise to Qualia in the first place that they that they have to be qualitatively differentiated from each other.
And then the last thing I would say. So, so there, let me come back to your question I think the nervous system has more to do with dealing with the whole bang shoot, rather than dealing with, you know, one or another.
I don't mean that each organ system deals with only one need, but I think that the nervous system deals with the more.
You know, the meta system in that sense and I think that's an important reason why it's not uniquely but especially bound up with consciousness. And then the last point and I'll end here that the predictive hierarchy.
We all know those, you know, the three of us in this room that need to go through why the predictive model is hierarchically organized.
But that's another thing that the nervous system seems to particularly lend itself to it has it has a hierarchical mentality.
So those are my my responses to your to your fabulously interesting question.
So one of the things that so we have a number of other systems that we're testing for all this stuff. And, and one of the one of the things that geopasulo and I are going to be looking at is this this predictive model updating in gene regulatory
So something as simple as, you know, already we we and others you know Richard Watson and others have shown that something is as mechanistic and simple as a gene regulatory network and have it can learn from experience and we've shown it has different six different kinds of learning, just there with no
no other magic added just there. And so now the question is, is there a, is there an active inference version that can be sort of mapped onto it where we can show that as it guides the experience of the cell being the hit with different, you know, different stimuli and
is there a sense in which these these pathways and the molecular networks and pathways are updating their models.
And, and, and, you know, and as you said having these qualitative for differentiated preferences and so on.
So we're looking and then, you know, yeah, then we'll see we'll see what that looks like but but there are many other right so so there are more for genetic systems where we're looking at that there are physiological systems.
Yeah, it would be nice to it would be nice to develop like a panel of, you know, almost like a almost like a panel of tools computational tools that could be applied to a system to, you know, I mean in some sense it was.
Yeah, it was is that right in some in some sense is an attempt at that.
But I think I think, yeah.
Yeah, that's that's fantastic but on your last point I just want to underscore what Chris said about about feedback.
This is the, the, the, the, the, the, that's I don't, I don't find myself particularly persuaded by team maybe I should just say that.
Yeah.
Well, I think it's also interesting, given what Mark just said about qualitatively different categories of requirements.
If we look at any cell, I suppose, even, even a very simple prokaryotic cell.
There are requirements for things like osmolarity and energy transduction and waste removal.
I mean, when could temperature, etc. etc.
All of which have to be met separately.
And there's not one way to regulate all of these things.
And there are gene regulatory networks that are in a sense specialized around those functions.
They're not completely specialized to just one of them, but that are specialized around the idea of, for example,
executing the, or producing the right sets of sugar metabolism genes at the right time and in the right proportions.
And something like E. Coli.
One has this kind of compartmentalization needs and compartmentalization of needs satisfying mechanisms that then have to be wrapped in
by a set of feedback loops that effectively serve as a meta processor that allocate energy to dealing with different needs in real time.
Energy being the basic resource.
One could also think of it in terms of allocating memory resources or computational resources, whatever.
But that meta structure that coordinates the response to different needs and prioritizes which pathways get the energy is,
at least from an information processing perspective, a separate system that has its own requirements for energetic and memory resources.
So it has to keep itself running also.
So you get something that that architecturally looks not a million miles from a brain.
It's hierarchical it's got multiple channels.
It has to satisfy many needs simultaneously.
And bunny up until the last sentence, I followed everything you said but I thought you were going to say, I thought you were going to conclude with a different statement than you did.
I thought you were going to conclude with a statement that this meta control system within the cell, which has to allocate resources and prioritize energy resources that that that sub component of the cells.
Processing is equivalent to the nervous system of that single cell. That's what I thought you were going to say rather, because I, you know, I think that the single cell is like the body at our level.
And then within the body there's the nervous system I thought what you were describing there, because that prioritize when I spoke of the importance.
I want to give you the importance of, of the different needs of the system, having to be treated as categorical variables.
But the reason why that becomes so important in terms of not the reason but a major reason why it becomes so important for why quality exists is because there's a meta system that's having to say okay which one of these things
you know which, which flavor is that issue here. And if you didn't have, if there was a, if there was a fixed pattern of how they get prioritized then the issue wouldn't arise.
It's because there has to be some qualitative prioritization processes, I think that's, so that's why I think that aspect is the important one and then there's the additional thing which is not by any means missing from what you just said, which is the action bottleneck.
It's the energy allocation bottleneck as it were because there's only a finite amount of energy resources, but there's also, you know what am I, we in our allostatic life.
We can, you know, we can't do everything at once. There's so you have to say okay I'm now going to deal with this need then I'm going to do so the prioritization also has to do with the action bottleneck.
But what if, so we've discussed Mike's questions. I don't think that we by any means exhausted the potential answers, but we didn't get to yours at all Chris so we have to yet again we have to have another meeting guys.
And next time we'll start with Chris's questions.
Okay, sounds good. I'm in.
I'll send, I'll send out an email. We'll schedule. We'll schedule your little the next one.
Fabulous. I can't tell you how much I enjoy talking to the two of you so thank you so much yet to get so much thank you.
Yeah, very good discussion long gentlemen. Good to see you.
Bye bye.
Bye.
