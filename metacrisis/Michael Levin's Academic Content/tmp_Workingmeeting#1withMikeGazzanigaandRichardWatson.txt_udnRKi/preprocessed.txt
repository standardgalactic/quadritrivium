I'm super excited to have you both on together.
Do you want to each say a couple of words?
Cause I don't know, I guess that you haven't met before.
So just say who you are.
Sure.
So my background is in computer science
and evolutionary algorithms.
And I've spent a lot of time recently thinking about
the relationship between evolution and learning.
And I have come to the conclusion that evolution is a more
sophisticated learning system than is usually conceived to be.
So I think it's more the case that the relationship between
evolution and learning is that evolution is smarter than we
thought, not that learning is dumber than we thought.
I've been interested in thinking about learning in systems
that we don't usually think of as learning systems.
So learning in gene regulation networks, but also ecological
networks and social networks where there's a distributed
learning process going on in the network as a whole, even
though they're not evolutionary units and not designed for
the purpose of doing learning.
And I've also been thinking about learning in physical
mechanical systems like masses connected by springs, things
like that, where the springs are imperfectly elastic and that
relieves a residual memory in the springs and shown that
that's capable of doing the same kind of learning that a
hot field network does.
So those are some of the things that I've been thinking about.
And I'm excited to talk about things like what do we think
the real limitations are on current deep learning
mechanisms and are there opportunities for relieving those
by the way we're doing it.
So I think that's a good point.
And I think that's a good point.
And I think that's a good point.
Are there opportunities for relieving those by, or how should
we put it, moving to a different way of doing computation
that's much more to do with bays and resonance and
holographic principles and things like that instead of the
current conventional way of thinking about computation
and artificial neural networks based on amplitude.
So that's everything on the table for me.
Well, yeah, I get it.
Well, I came up through neuroscience and testing of
humans with various kinds of neurosurgical procedures.
And from that went into just studying classic lesion cases.
But I've kept my hand in the neurosurgical cases all these
years.
In fact, we have a new series of studies being launched in
Germany as we speak.
There's a series of studies coming out of, well, the
intellectual parts coming out of Cologne and the actual plate
patients are elsewhere.
But what I also do is kind of keep an eye on things at my
age and watch others have the fun.
And one of my colleagues here, man by the name of Scott
Grafton, is one of the real sharp guys in brain imaging.
And he had teamed up with one of his students, I don't know
if you've heard of Danny Bassett, but she's a network
science kind of young guru who's now at Penn and really,
really a superior talent.
And both of them together have studied networks at the level
of fMRI tractography and have ideas about how they can
identify networks that are constantly shifting.
I didn't get that.
Could you try again?
What's Siri coming on for?
I don't know.
That's pretty cool.
So they've captured what they would call the plasticity at
the level of network shifting.
And they can identify networks that when learning is about
to occur, before it occurs by their analysis of these
systems.
Something that would be, I think, relevant and of high
interest to you guys.
So there's, and then, of course, everybody is now inundated
with, and in fact at Santa Barbara, they just concluded
a two-day conference on, well, it's not, it wasn't chat
GP3, but it was the realization of the incredible power of
these learning systems.
And everybody at one level is spooked by it.
At another level, they want more of it.
And I guess the, one of the take-home lessons I got,
there were a lot of the leaders in the field here,
you would know them more than I would, but one of the take-home
lessons certainly was that we don't, we, the people in the
field, do not know how these systems are working.
They take you to that point that it's, they're doing these
things, we're measuring the behavior, and we know, we know
what the algorithms are, they're working on, but we can't
figure out actually how they're doing it.
And I said, well, you're joined the neuroscience community.
We don't either.
But I kind of walked away with the feeling that,
you know, because these things kind of come together to
think, well, let's figure out how the brain does it, if we
can figure out how these neural nets, these artificial
systems, we can get a handle on it, they're not, they don't
have a handle on it.
I'm kind of worried that we're walking down this path holding
hands, and I'm not sure we should be holding hands with
this approach yet.
So anyway, something like that, very, very, very, and then
finally, let me just add in, one of the things I've been
working on for the last few years, and we're just getting
going is to hold these scientific meetings where we try
to examine dogma in a field.
And of course, your wonderful lecture, I listened to Richard
the other day, where you're taking on Darwin kind of
directly up front is, I mean, that's a strong way of
putting it, I realize, but how dogma captures a field and
people won't let other ideas in.
And there's almost an industry involved in keeping it
that way.
As my business friends tell me, the reason regulation exists
is to keep people out.
And the reason these dogmas are far is to keep people out
because the people inside are already doing business,
right, and so forth and so on.
So we've had three or four meetings and we plan three
or four, I'm retiring actually this July, but the system is
set up that we're going to have three or four meetings.
And what I'd like to do is put in the back of both of your
minds that we maybe we organize one, and we're talking,
the whole idea of the meeting is to get five, six, seven
people together.
That's it, and free form, free form discussion, no, the idea
sometimes is also to bring the biggest advocate of the idea
to the meeting.
If they're truly a great scientist, they frequently
know more of the pitfalls than others and then have a full
discussion without any Chatham House rules.
You can talk about the ideas, but done with attribution
as you leave the room.
So we've had a couple and they work.
I mean, they're really, really quite extensive.
I think I mentioned to Mike and earlier,
we had one with the kind of guy that's going five or six
years ago with Randy Gallo still challenging the simple
synaptic idea for storage of memory, and we had five or
six people here and boy, it really ripped.
Let me tell you that the dogma, the simple idea emerging out
of kind of the candle position forward is strong and still
and yet to think of it differently is a hard task
for those guys.
And this was a meeting that achieved that and a little
paper came out and that kind of thing.
Anyway, that's a side story, but if at some point we think
it would be, and the idea in structuring the meeting is
that it is a meeting to have full and free discussions.
That's why you're there.
It's not to not do that.
So there you go.
It's difficult to do that, isn't it?
You have to choose your participants carefully because
you want somebody who's vested enough to defend a position
because otherwise you're just all agreeing with yourselves.
But as you say, you want somebody that's...
whilst they might not be particularly...
I don't know if open-minded is quite the right.
They might not be particularly open-minded.
They are convinced that they're right.
They're convinced that the dogma is right,
but they're willing to talk about the problems, right?
Yeah, and there's a whole other group that are just tired.
They don't want to put the intellectual effort into
rethinking fundamentals.
They just... it's not going to happen on their watch.
You've got to set them aside too.
It's a tough agenda.
Yeah, so Richard and I spent a lot of time thinking about...
it's simple and maybe not so simple,
all kinds of unconventional cognitive systems,
and what does it take to make models of the outside world,
of yourself, of process information, memories, that kind of thing.
So I for one, I mean, we can talk about anything like that,
but I for one would love to hear Mike's overall take on what are we, really, right?
So fundamentally, everything we know from neuroscience
and the history of phylogenetic trees,
so it doesn't have to be human necessarily,
but just given your insights on the bipartite brain and all of that,
what do you think we really are from the inside out,
and then we can sort of expand from there?
Yeah, I can make this short because there's three or four things
that don't get talked about enough that I think are key to thinking about
the mind-brain issue, which is means how does brain generate this
phenomenal thing called consciousness?
And there's a whole lot of talk about this and everybody's jumped in on it,
and they seem to gloss over a few simple clinical facts.
And one of the clinical facts is
it's really hard to say somebody is not acting like a conscious agent,
and that includes people with dementia.
That includes people with massive brain lesions,
and the way I think it, it's almost impossible to stamp out consciousness.
Just think about it.
I mean, if you've all had interacted with demented people,
you wouldn't say they're not conscious,
and yet they have massive pathologies, right?
You wouldn't say a person with global aphasia is not conscious.
You wouldn't say a person with this huge spatial disorder.
You wouldn't say a case HM with massive immediate memory loss.
None of that would you say they're not conscious.
And so you say, well, but wait a minute,
the experimental guys are now building these big models of consciousness
where the information flows from here to there and this and that.
No, I mean, those things are tremendously damaged in a lot of these instances.
So then, you know, in my history, what came along when someone said,
well, let's just disconnect these two hemispheres.
Let's see if there's two conscious systems after that.
Boom, they're incident.
They wake up.
They have two systems separated.
One doesn't know what the other's doing and so forth.
Okay, well, there's two.
That was easy enough.
Now, what about if we start doing more disconnections?
And it turns out they're all over the place, right?
So you can't get rid of this thing.
And that means, well, would that mean,
you know, and for the next little metaphor,
I like to say something my dad said to me once,
he was a physician and aging and he had many strokes.
And so he was into that and I come home one day and I say,
so dad, you know what I do for a living?
I got to ask you this question, you know, what's it like?
What's it like in there?
You know, you've lost vision over here and this over there,
blah, blah, blah, blah.
What's it like?
And he just said, Mike, you work with what you got.
And that's it.
I mean, you don't work with things that you don't have anymore,
but you work with what you got and the story keeps coming,
the capacities keep coming out.
So this gave rise to me with a little idea and I'll shut up.
Now, what we're looking at is I like the bubbling up metaphor
that through time, all parts of the system are up as they were.
They're up at that moment in time.
And it's a constant dynamic system and it's not something
building for that moment.
It's just that the moments are changing through time
and what is more active in the brain at that moment
is what seems to be the content of consciousness.
So if you then take that step back and what do you mean by that?
And I said, well, my view, simple view is consciousness
is a feeling about a specialized capacity.
That's it.
That's what it is.
And there's a bunch of specialized, thousands of specialized systems
in the brain.
And as they come up to the fore, like bubbles in a jar,
at that moment they come out, that's their moment.
That's the instant that we're calling consciousness
and that content can vary through the dynamics,
the underlying dynamics.
But that's just a way of saying what we know to be true.
Things are, we're doing this through time.
They change and then we know the fact that this,
it looks like very local regions are generating this felt state.
So we should be looking at the local circuits.
If we're looking for the neurobiologic underpinnings of this thing.
They all have it.
They all have it.
All parts of the brain seem to have it
because whatever's remaining, they seem conscious of and so forth.
So it's quite a different view.
I had worked it out in my 2018 brain, 2018 book.
But that's kind of how I see the problem.
And it's not where, it's not, it's a minority view.
It's not where I think the field is trying to get to right at this moment.
So you, can I check that I understood you properly?
So you think that the field at this moment thinks that consciousness
is some sort of systemic, some sort of property, systemic property
that requires all of the pieces to be in place.
But it seems more likely the evidence suggests that consciousness is
in every part of the brain at not at all times,
but at the moment that they come to the surface as it were.
And that you could take very small parts of it
and they would still be little consciousnesses.
Rather than something which is a singular thing belonging to the brain as a whole
and requiring all of the parts to be in place.
Did I get you?
Yeah, well, that's kind of the idea.
Now, so, but I invite people just to think about the neurologic reality of this.
And you might come up with a different metaphor that's better for sure.
But it's very one of the most illuminating things
to do is to go on rounds in a neurology ward.
It's just every day it's illuminating.
Because you find something that's just, what?
What's that?
And this basic thing is that if you just have this question in your head,
well, yeah, but what I say this person is not conscious.
No, you wouldn't.
I mean, they may be working at a simpler level.
I mean, it's quite starting to see your first true Alzheimer's patient
who can be sitting there talking to you about life and stuff and past.
And meanwhile, can't put a red dot on a red dot, right?
Their cognitive mechanism has been corrupted.
You wouldn't not call them conscious.
It's crazy.
And so anyway.
If we did have a way of understanding consciousness that belonged in each of the parts,
which we don't.
But if we did, wouldn't that then still leave the problem of why it feels like
we have a singular consciousness?
Yeah, yeah, except that that could be an illusion.
And for sure.
I mean, there's a whole body of philosophers who think that just gets you to that point.
And it's a powerful argument.
I mean, if you if you go back to just look at spend an hour looking at Roger Shepard's illusions,
they're powerful things.
You're looking at it.
You see it and you're experiencing it.
You know, what is that?
And why can't that be the same for this?
So, yeah.
But, you know, that that's that's the puzzle.
Now, the thing that at another level, of course, the the unity comes from it in my mind from
at the level of story.
And we we are storytellers to ourselves all the time constantly telling ourselves the story.
And one of the things we we kind of unearthed in these split brain patients,
there's a part of the brain that will make up a story why they're doing something
that we know we had commanded the silent right hemisphere to do.
And and yet it's coming out of your body and you simply don't let things happen without you
interpreting them, etc.
So, so we're sitting there changing our stories, our feelings go up and down,
we're changing our story.
I mean, just we can appreciate this fact that I was just listening to
someone who's studying the role of bringing maybe decision making or
artificial decision making systems into the law to make judgments of sentencing,
very practical thing.
And there's all kinds of things that they can bias a decision that judge will made by tweaking
this and that.
And because it turns out judges are totally victims to things like
when had they just eaten lunch, is it after lunch, and they do studies on this and a huge
variation that's correlated with these with these physical physiologic states.
And and the idea of bias free decision systems will get rid of that.
And that's how we should make these these calls.
We already know.
And in sentencing hearings for sentencing hearings for payroll,
parole, excuse payroll, parole,
that the juries want to see the Dr. Jones up there in the witness sense,
that either a medic or a psychologist, they're terrible at this.
They're about 35% prediction of whether there's going to be a recidivism.
Right.
If you've got a social scientist up there with their
outcome studies and all their calculations, right now, currently, they make a 55%
prediction rate.
And the notion is if you really had some neuroscience in there, you could get it up to 80%.
Prediction rate.
But the juries don't want any of that, because they think that it's the old Doc Jones
there is the one that's got the wisdom.
And then and then to make that problem kind of just interesting sidelight,
the judges say, well, yeah, I mean, you could get that up to 90%.
But then we have to decide whether to give that defendant that 10% chance.
That's our whole system is built like that.
So anyway, all kinds of fascinating questions on that front.
Yeah.
So in the split brain patients where one hemisphere confabulates a reason to explain
their observations of the behavior of the other hemisphere, that's entirely mutual, right?
It's like, it's not like the other hemisphere says, no, it wasn't.
Why did he say that?
That wasn't what I was doing at all, right?
They're just that the other hemisphere confabulates as well to explain why that
hemisphere just gave that explanation.
That's a question, really.
Yeah, that gets complicated because there are examples where the other hemisphere will.
So some of the some of the patients, the right hemisphere over time evolves to be able to say
simple words so it can react.
And it has reacted to the correct answer.
So there's a whole, there, there is that story that there's a there's a disagreement.
And then there's explicit studies we've done where you ask a patient to value how much they like
a set of words, right?
And on a one to seven scale.
And there's there's two testing days.
Let's take this one one study I'm thinking of where the patient was very calm.
The interactions were very normal low key and everything.
And we put up these words randomly and they have to pull into seven and you distribute them to one
hemisphere or the other.
And their rankings were just in parallel.
I mean, whatever, if one somebody liked this, you got a six, the other hemisphere got a six,
one got five, the other got a five.
And that was kind of a yawn, you know, it's like we couldn't see any differential
liking to the cement.
Then another day, the patient came in and it was kind of agitated and feisty.
This was a 16, 17 year old boy we're talking about.
And he was just kind of, you know, jacked up a little bit and so forth.
And when we ran this test, the scores were completely desperate.
One hemisphere was giving one and one and the other one's giving the six and I would flip this and that.
And you just had, well, if these things were set differently, there's tremendous conflict
and agitation as a result.
So then you can just think that and all the split brain thing is, of course,
it's just a research tool to see how this thing could work.
That's what you're after, you know, and it's just a research tool.
So now you just think, well, what is conflict?
Well, conflict is two different messages being sent to the system to consider and so forth.
Yeah, makes you wonder whether the agitation belongs in, you know, one hemisphere agitated
and the other hemisphere not, or is the agitation caused by the disparity of the hemispheres?
So that's the conflict between the two is the agitation.
Yeah, so it's nating.
You know, it's funny that the storytelling thing sounds so intrinsically critical to being
an agent like us.
And it's one of the things that in the AI community, so many people are, you know,
they see these language models confabulate, basically just come up with whatever they can.
There's, you know, little bearing on the actual causality of it.
And they say, oh, look at this, you know, this thing's making up stories.
And like, yeah, that part tracks a lot.
You know, that's the part that's working.
And I also think about, so we've got this case that you're talking about with the split brains,
but there also, I'd love to hear what you have to say about kind of a more extreme dissociative
identity disorder cases, right, where there's not two coherent inhabitants in there,
but there could be many more.
You know, and I've been reading about these various cases where they're aware of each other
and they sort of talk about each other as they show up and, you know, they have various dynamics.
And that one, you know, for example, I'd love to know like the two that we've been talking about
sort of segregate nicely anatomically, right?
You've got these two hemispheres, but if you've got 29, do they overlap?
Are they all resident on exactly the same hardware in there?
Or are they different regions?
Is there anything known about that?
You know, is there an anatomical correlate to those distinctions?
Don't know. Never looked at that in a serious way.
But how about this experiment?
When your wife picks up the phone to talk to somebody and you're observing this from afar,
the way she responds, I bet you with almost 100% accuracy, you know who's on the other end of the phone
because there's different greeting patterns for each.
Whether it's a friend, a deep friend, a person that kind of everybody's pissed off at or
or a child or you just go right down the laundry, I just know he I don't have to ask.
I know who's on the other end of the phone.
And so that's us.
The idea here is that's us falling into another story.
I mean, or knowing they are, I mean, we're observing the phenomenon.
So now what happens in these clinical cases is these become kind of encapsulated
and insular and available to be sustained states of the others.
I just don't know what the, I don't know what the underlying pathology is on it.
Yeah, the
there's the
I mean, could
could the story be
well,
I tried to play with the idea, could the story be the consciousness?
It's the story that we're constantly updating and feeding and modifying it.
That's what's driving the machine, the story.
But I don't know.
Gavin Gavin, Gavin Gavin, what's Gavin's last name?
I don't know.
Newsom to Gavin Dawson, because anyway, a philosopher was saying
that that doesn't get out of it.
He says, one of the things that we humans have from the get go is the moment you wake up,
you're ready to go and you have new agendas.
You have new, you have a set of goals.
You have things you want to do.
What's that?
That's not, that's just kind of like part of the hardware.
That's not a thing you built up from a story.
It's just, however, what else is going on?
You still have that thing, unless you're deeply depressed, I guess.
That's the reading up agency you're talking about, Mike.
Yeah, yeah.
So there's a connection between two of the topics here that might not be so obvious,
right?
Because you started, you mentioned getting people together to talk about scientific dogma,
which one could interpret as a collective story,
that each of the persons involved in that dogma is trapped by that story,
that they can't see things differently than that story.
And they are dedicated to the continuation of that story.
And that makes the dogma something that doesn't belong to any one of the persons involved.
The dogma belongs to the community, to the collective.
And analogously, the story that the different consciousnesses within potential consciousnesses
or sub-consciousnesses within the brain is committed to is what makes them one thing.
And what makes them part of something rather than separate things.
And they can't get out of it.
They're trapped by the story, like people are trapped by the dogma.
But when we're thinking about scientific dogma, we think that's a bad thing because
they're not seeing the truth.
But when we think about it in terms of ourselves, we think that's what makes it us,
right?
That's what makes it more than the sum of the parts.
That's what makes it something that belongs to the whole and not the parts.
That's what makes it not just each of the parts reacting to the evidence that they have.
Yeah, I mean, this ties exactly into the booting up of business because,
you know, when you look at an early embryo, and it's, you know, let's say on Amnio,
like a human or a bird or something, and you get this flat blasted disc of tens of thousands of cells.
And so you look at this thing and you say, ah, there's an embryo.
What are you counting as what is there one of, right?
When you say that's one embryo, what are you actually counting?
What you're actually counting is commitment to a story.
What you're counting the commitment of all those cells to a very particular journey in anatomical
morpho space.
They are all going to work together to build this thing that has so many fingers and so many eyes
and everything is in the right, you know, location.
And they're all committed to the story.
And this is what you're counting.
You're actually counting morphogenetic stories, right, to sort of shift, right?
So I've kind of twisted this 90 degrees to talk about a more morphological space instead
of behavioral space.
But it's the same thing, right?
They're committed to that story.
And what you can do is you can very easily generate a dissociative state by taking a little needle
and sort of scratching across the blasted room.
So to create one or two different islands.
And in that case, each island will form a new embryo.
They will self-organize and they will all commit to their own story.
And then eventually they heal up and you get conjoined twins or triplets.
I used to make these things in duck embryos, you know, as a grad student.
And then, yeah, and so the question is, you know, right there, you see how many individuals
are in this embryo?
Well, you don't know right away.
Any more than you know from looking at a brain, how many cells are in there from the outside,
right?
So there might be zero, there might be one, there might be two, probably up to half a dozen,
I'm going to guess, in a regular embryo.
So yeah, right?
It's commitment to a particular story.
And then you get interesting things like after they do heal up, you get cells that are sort of
on the border between two embryos.
And they're not quite sure.
So the cases we studied where if you've got two of them that are like this,
you got left-right problems because the cells right here, they're the right side of this guy,
but they're the left side of this guy.
So who are they?
So which genes do they turn on, right?
The left side markers or the right side markers?
And this is why conjoined human twins, one of the twins often has laterality defects.
They'll be mirror-imaged because the cells are very confused about whether they're part of this,
you know, this story or whether they're part of that story.
So I think we can tell some very parallel kinds of frames here about these things.
Yeah.
You know, and one of my favorite stories about this whole dissociative thing was a guy who,
he was a therapist and he practiced integration therapy to help patients get sort of back unified,
right?
And so he had this patient, he was working with the patient.
The patient was unhappy because this other personality would pop up during work and, you know,
this other one was a partier.
And so he would just disrupt the workday and all that.
And so, you know, they were working.
And one day the patient comes into the office and it's the other one.
And he says, hey, to the doctor, he says, hey, what's this I'm hearing about integration therapy?
He says, well, you know, well, we're going to integrate you.
He says, yeah, but when you integrate me, where am I going to be?
He says, well, to be honest, you know, with any luck, you'll be gone.
Excuse me?
He's like, what happened?
You know, and he said, he said, what happened to the Hippocratic Oath?
What do you mean I'm going to be gone?
And then he says, then he says, make the other guy gone.
He's boring.
All he does is want to work all day.
I'm having a much more exciting life.
Have him gone.
I don't want to be gone.
Yeah.
And so this was, this is like a real existential kind of issue, right?
Yeah, it's like you should get your own lawyer there.
You should get your own integration therapist, shouldn't you?
Yeah.
To represent you.
Yeah, that's a real problem.
Yeah.
I'm sorry.
It's the other personality that hired me.
You will have to do this.
That's right.
That's right.
So Richard, in your really great talk where you very generously and kindly set up Richard Dawkins
as you admire him because he's so good at selling this story kind of thing.
And so having run a few of these dogma things now, there's a critical moment there to get
the people to listen, right?
And so I was wondering whether you lose the lead as it were.
So if you were to give, re-give that talk with a question,
I've, I've have some observations.
There's a body of work, however you want to put it,
that it looks like Darwinian theory just can't explain
what everybody would be listening, right?
Because what, come on, you know, what's that?
And then, and what a beautiful meaning it would be if Dawkins was there, right?
And he opened, I don't know him personally, but open to that kind of, that kind of fun
or intellectual challenge or whatever you want to call it.
But, but to, I mean, I think you're so far into this, this story, this, it's all happening.
I mean, after this, after this two days of intense hearing these guys,
they're going to do everything.
This thing's going to do everything.
You know, just sit back and relax, folks, because this, these neural networks and this
is just going to be fully capable of all kinds of stuff.
So it's not doing things in the old traditional Darwinian way.
It's got all kinds of new games and tricks up its sleeve.
And, and we better try to understand this.
And we're being blocked from understanding by hanging on to the simple idea.
That's, I had just heard your talk and I was listening to these guys as I was trying to think
of how to get in, you know, get a conversation going with them almost.
That's very kind of you, but they talk about natural induction.
Yeah, the natural induction.
Yeah.
So it's, it's tricky, right?
Because when you try to point out phenomena that aren't explained by Darwinian evolution,
people just say that they are, right?
Because, because they just, there just isn't any other explanation.
So it must be explained by Darwinian evolution.
It's like, well, that's not really explaining, is it?
That's just faith.
And, and it's really hard to get past that to even see that there's a question there.
Yeah.
I mean, you know, there's another aspect to this, which is looking sort of looking backwards to say,
does this framework explain what we've already seen?
That's one and people do that all the time.
But I'm actually even more interested because that one, that one is hard to do for exactly
the reason that Richard just said, you know, people can tell all kinds of stories and well,
maybe that's plausible.
I don't know.
But to me, the real asset test is looking forwards and say, okay,
how good is your lens on these things at generating new research, new predictions,
new capabilities?
I mean, there's all kinds of things that I think the standard models,
including the kind of the standard Neo Darwinian model is just not going to get us to.
It's just a barrier to research in certain areas.
It's it does not facilitate the discovery of certain types of things that other frameworks
might facilitate better.
And so I think we have to, we have to kind of compliment this idea of explaining past data
which two models may be hard to distinguish from that alone.
But then the next step is, OK, fine.
But how good is it at generating next step, you know, the next advance?
How good is it at opening new, you know, new, you don't just mean testable predictions?
No, I don't mean just testable predictions, although that's part of it.
I mean, we'll just just kind of a, you know, kind of a dumb example in the case of,
you know, the game of life, right?
The cellular automaton, you know, you got you got these very simple rules
and the little cells turn on and off.
OK, so so you could say, OK, I have a very reductionist view of this,
and I don't believe that anything exists.
For example, these gliders, these patterns that move around.
I don't believe any of that exists.
What I believe in are the little elements and they each have an on and off state.
That's it.
That's what I believe in.
So the so the thing there is it's not that that framework is not usable
to explain everything that's ever happened in the game of life,
because you can explain everything that's ever happened that way.
But the thing you're not going to do with that view is to do what people have done,
which is to make a Turing machine out of gliders in the game of life,
because you don't believe in gliders.
And if your frame doesn't help you think about, oh, wait, there are these these these higher
level permanent entities that propagate from here to there and maybe they carry information.
And oh, I can engineer this thing.
If they sort of cross, I can make a logic.
You're not going to think of any of that, right?
If if if all if your entire view.
And so so that's what that's what I mean, right?
It's not just about predictions.
It's about how good is it to get you to invent the next?
And I don't mean technologically invent, but you know, to see the possibilities of other things,
even if your framework is really good at just sort of saying, well, I could have, you know,
like it's a micro reductionist that I could have any story you tell me.
Well, it's it's consistent with with my worldview.
Yeah, it's consistent.
But how fruitful is your worldview for new stuff, right?
That's, you know, that's kind of that's what that's that's what I mean.
Yes, it's slippery, isn't it?
Because in my experience, even when you get even when you get an audience to put their hands up
at the beginning of the talk and say, what do you think will happen next?
Yeah, right.
And then you show them something that they didn't expect.
And then you say, so what do you make of that?
And they did say, well, you didn't ask the question right.
Or, you know, something like that is like, what in what sense did I not ask the question right?
You were completely wrong about what you thought would happen here.
But they just like, they just they'll just make up a reason for their answer,
having been reasonable, given the way that I posed the question or something.
It's like, no.
But now that you know, now that you've told us how it works, I mean, of course,
that would happen.
It's like, yeah, I know, right after I've explained it.
That's exactly right.
That's exactly right.
Yeah, yeah, that can always be done.
You know, this looking backwards, almost anything can be can be shoehorned into your story.
But the question is, yeah, but why didn't you do that experiment?
Right.
There's a reason why somebody else did it and you didn't do it.
It's because there are different frames and gender, different types of research programs.
I'm curious what you guys think about.
We were just talking about the link between evolution and these these language models and
all that.
So my dad asked me a really interesting question the other way the other day.
And I wonder what what you guys think, is there a plausible evolutionary path?
You know, could you imagine a possible earth somewhere a possible world
where the thing to evolve would have been these kinds of an entity that's like these
kind of language models.
So not the thing that's like us that's multi-scaled and it had to go through,
you know, particular self-construction and autopoiesis and all this.
But something literally, right, could we imagine a world where the thing that naturally evolved
is something that runs on exactly these kinds of these kinds of principles that that these
current models do, right?
Is there a path backwards that's natural or does it require us to have evolved first?
And then we engineers sort of engineer this crazy thing that's very different from us.
Is there a natural path to it?
Like I wonder, and another way of saying it is, do you think that the major features of
our cognitive system, right?
So the fact that we are the fact that we feel a unified that we have an innate sense of
action or free will and all this kind of stuff, is that is that inevitable?
Right, meaning any cognitive agent is going to be like that ever?
Or is it possible that we could have evolved in a completely different way?
What do you think about that?
So could we have bypassed all that biology and just gone straight to the
apparently cognitive artifacts?
Yeah, in other words, is there a possible world where we show up on a planet, we look
at it and say, whoa, there are no biological creatures, including engineers that look like us.
It went right to what evolved looks very much like our LLMs.
Like that's what it is.
It's not like there was never a step that's engineers like us.
No.
That's interesting, right?
Because if you think the answer is no, then the claim is that that kind of architecture
that we have is in some way essential, that every living thing is going, every sentient
thing we find is going to be like us, right?
Is that the claim?
Interesting.
So I'm inclined to think that AI systems, as we find them now, couldn't have occurred naturally
because they are, in a sense, a mirror or an imitation of the cognition that we do
that was created by our cognition.
And that's not to say that we couldn't create an artificial one that was like us,
but I don't think the current ones are.
And I think that they are, as we've discussed before, not connected through enough causal
levels to the stuff that they're made out of, right there.
There's, you know, you can have a sort of a thin superficial intelligence that looks
intelligence on the surface.
And when you scratch it a little bit, it's like it immediately shows its naivety.
Or you could have one that was a bit deeper, which, you know, you scratch it a bit,
you can dig a bit deeper before it starts to show its naivety.
But it's still the case that there's a yawning chasm beneath there that it isn't connected to
a substrate that is actually meaningful to it like we are.
Yeah, I have a stronger opinion about that than I realize.
Thanks for asking.
Interesting.
I mean, right, so we can agree.
So for example, we could say that, yes, that's true.
And they fundamentally are lacking, you know, that juice of meaning.
But might there not be a planet somewhere where these minimally meaning agents are running around,
right? There couldn't be some, I mean, we can we can accept that they are, for example,
that they don't have it.
But yet, you know, did they didn't really need to go through us?
I don't know.
I've been I've been thinking about I've been trying to invent some kind of an artificial
selection scenario with with bacteria or something that would be to get them to carry out the,
you know, I don't know, back propagation and whatever, whatever, whatever it is that I don't
know, you know, everything about these things nowadays done.
But it seems like there could be worlds like that, right?
Where you go straight to that.
But I guess, yeah, anyway.
Yeah.
Interesting.
I mean, another yet another way of saying it is, if you do find a world like that,
is your immediate conclusion that, oh, there must have been engineers here and they left or
something.
If you don't see them now, they must have been here at one point.
This this cannot show up on its own.
I think that's a good way to put it, right?
So a natural intelligence would have to be connected all the way down.
Right.
It would have to be it would have to be connected on the cognition of the subatomic
particles on which it was built.
Wow.
So so so that that makes me think of the old Paley's watch argument, right?
Remember this?
So now so now I don't know any rights.
So so so you find this thing and it and it talks to you.
And on the one hand, you would say, well, that's even worse than the watch.
That definitely means there was an engineer here somewhere.
But on the other hand, I'm actually not convinced of that at all that there isn't
the path to something like this that, you know, even if it is shallow, even even if it's a.
Yeah.
So OK, I'm I'm I'm taking your guys class here.
So I got a question.
Why why wouldn't the layered architecture metaphor just.
Absorb all of this.
I mean, there's no way that people who push the layer to John.
Do you know John Doyle's work?
I mean, the way he talks about it, the layers have their own logic and physics to them.
And they they have a protocol between the layer below it and so forth.
But they they have no knowledge of what's going on, nor do they want it.
So if you have that view, I don't see why this is.
I mean, that's just the way systems are built.
Yeah, I can see how, you know, like how many how many layers do I want before?
I think it's a it's a real cognitive thing, right?
Exactly.
You know, if I want 50 of them, can I can I can I have them at layers 100 to 150 instead
of from 0 to 50 is like what if I've got 50 layers.
Then there's a sense in which it becomes substrate independent about what the bottom layer is.
Yeah, maybe I am thinking a little bit too bottom up.
So is it one of the arguments these guys make that the reason we kick things up to the social
layer is that we can't solve it. And we're going to have to have the social idea manage us
because our internal our mental capacities are our feelings about stuff just aren't
are helping us. And so yeah, we think we think things should be fixed.
And therefore we do social structures, etc.
That can move it along faster.
So it's interesting that you mentioned so I'm I'm cool with the idea that a layer can
have its own logic. But it's the protocols of the communication between the layers are vital,
right? Because otherwise you only have a single layer logic and it just it doesn't have any depth
to it, right? And how those yeah. So
I despite the things that I just said in the last 10 minutes, I'm much more
I'm much more top down than I am, than than the average bottom up scientist is, right?
But if I was really scale invariant, I would say, well, it could, you know,
you could start at any scale, and you could build upwards and downwards simultaneously.
Or you could simply acknowledge that all scales are always involved. And there can be
a bulge at a particular scale.
And it's no, there's no sense in which
a cognition is grounded in a physical reality, whichever scale you're at.
I'm going to take this phone calls my wife one second.
We would have known it was your wife by the way you spoke to her anyway.
Oh, okay. Are you are you on your way? Okay.
Sorry, there. Thanks.
So I wonder, so Mike, I wonder like like earlier, earlier, Richard had said,
well, why do I feel like such a unified, you know, being then right if we're made of parts and all
that. And so I wonder if, is there an alternative? Is there a possible cognitive being that would
ever say anything different? You know, I'm just not sure, right? What do you think? Is there a
positive, is there some possible being somewhere that does not feel like a unified or if there was,
could we ever communicate? I mean, with it, I don't know, but what do you think?
So one of the wisdoms out of clinical neurology is the patients
not just the split allows us to study these things that kind of coolly and experimentally,
but any patient with a brain disorder is constantly recrafting who they are to deal with it.
And if it's a motor disorder, sensory disorder, memory disorder, there's constant adjustment.
And so we reflexively, we
change our story, change our feelings about things.
And I think we know we do and we marvel at it and we try to understand, well,
why did yesterday I want to go to Rome, but today I don't?
What's changed there? And it's usually some kind of feeling about all of a sudden you imagine
yourself sitting on a plane for 15 hours. And by the way, I heard the greatest advice on accepting
an invitation. When somebody invites you something a year from now and you say, oh, you know, yeah,
sure, you're from the hell, right? When anybody invites you anywhere in your mind, you say,
would I want to go there next Tuesday? And that really cleans out a lot of
pretty good. It's pretty good.
But anyway,
I mean, you know, we're smart people we know about from human experience, we know these
know all these dimensions of our own personality. And we try to compensate for them and we try to
deal with them. And in doing that, we're trying to tell a different story about ourselves.
I was thinking of your wonderful example there, Richard. I wonder if you could have set that up
in the lecture too. I'm going to show you an example of the storytelling brain. And then you
give the challenge and then the person, you know, fumbles around and you just say, see.
We should be able to set it up so that whatever answer they give, I'm right. I shouldn't know.
But do that right. That'd be fun. So Mike and I were discussing the other day that
how many voices we have when we write together.
If we write something together, are we writing with one voice? Or do we do we need to write as
one voice? Or can we still write as two so that we're writing a dialogue for other people to
read? So your answer to the question, Mike, is, is there ever a consciousness that feels like
it's not a unified thing? Like, well, I don't, you know, that's, that's what we are, right? I
don't completely feel like I'm, that you and I are one thing.
I, well, haven't we all had this experience, let's say you've co-written a paper with somebody,
and then five years later, you go back and look at it. And you can come across, you know, in the
you know, in the discussion section usually, oh, I would have never said that.
And then you didn't say it.
Yeah, but and vice versa. I've read papers that I know I read that I know I wrote.
I think I don't remember ever thinking that.
Oh, yeah. Yeah. Well, that happens. Yeah. Within increasing frequency, I might point out.
Yeah. But I can also imagine that there's that you come back to a to a bit of text and I think,
like, I really don't know whether I wrote that paragraph or whether the co-author wrote that
paragraph. And if it's a this isn't true in scientific papers, but if it's a book,
and you have a really good editor, the what they bring to it is enormous.
They're skills. And I've noticed that they can really change the lucidity of a paragraph
by a few words, moving around and bingo.
So that's even a third, a third will in there.
Very, very. That's a good question. I want to think about that.
So the truth is, I guess, that in the same way that different personalities might answer the
phone, depending on who was calling, different personalities reside in me all the time. And
when I'm talking to you, you think that's the same me. And each of them would tell you that it
was the same me, but they're not really. And each of them is willing to confabulate.
Well, look, it's quite common that I would think to myself, I don't really know why I did that.
And I just I just sort of live with that, right? We all do. I presume we all do.
It's like, well, they've done a reasonable explanation would be it wasn't me.
You know, in personality researchers, a view that whatever, for what better or worse,
one is described as having a kind of personality, you have personality, a certain type of person.
And what the researchers have found out that by the age of 26, the world you live in has pretty
much decided what they want to think of you. And you start deviating from that model they have
of you, and they beat you back into what you're supposed to be by various district rewards and
punishments and ignoring and this that they don't want you to change because they don't want to
go through the energy of building another model of you. I've spent their time.
And that's kind of that's kind of weird, you know, to be aware of the constraints that
the world is making you react the way you have reacted.
Right. Like one part of ourselves does with another part of ourselves.
Right. That too.
It's amazing, like all of these things, especially like the thing that
what you just said, Mike and what Richie were saying a minute ago about,
you might be actually talking to a different personality even under the so-called normal
conditions. All of these are things that the people who critique these various AIs,
that's exactly what they critique them for is that kind of a thing. Oh, you know,
you're not talking to a single thing underneath, it's different from day to day. And, you know,
it will, you know, it doesn't have a stable core. I mean, all of this stuff is like, you know,
they sort of pretend that that is not true of us. But these are, I think these are important,
you know, all this, the neurological stuff and everything else, I think it's an important body
of work that has not penetrated into the discussions of AIs.
I think I want to revise my answer about how grounded does it need to be or could it exist
just at that level? I think that it's maybe not just how many levels are there. It's not just
how deep can I scratch before it starts to show the wires, right? But that in order to be sufficiently
deep, it would have had to have had sufficient experience that in order to have the depth to it,
it would have had to have had experience that
shaped each of the layers
so that it was their own experience and not just a faint image or facsimile of such experience.
Maybe it's maybe more like that.
And so then the question is, can you tell the difference between something that was
built from real experience and something that's a facsimile of this experience?
Yeah, so
buddy put it the other day, simply, so you take GPT-5, 6, whatever, however
credible they're going to become.
And at the end of the day, though, while they're going to be doing these incredible things,
they won't have had the human experience.
Now, is that a fair constraint? I mean, if you're basically a laptop sitting on a table doing all
the stuff. Yeah, but is that the threat? Well, they won't have had the experience,
but the question is, could they acquire structure equivalent to having had the experience?
That the only way to explain the level of interaction that we have with them at this
level is that they have correctly induced, in a deep way, what the human experience is,
even though they didn't actually have it. And then say it, but they can say about the experience,
but have an experience. That's what writers do all the time, right? Well,
that's the thing, right? And I'm certainly not arguing that GPT, whatever architecture,
is the one you want to be fully agential and all that. I have no commitment to that.
But I do think that two things. One is, when you say we've had an experience,
I don't know that we've had any experience where in an important sense, we're a brain in a vat,
right? You haven't actually had an experience, which you've had is some sensory data that
makes sense to you and that you've told stories about. And that's adaptive enough that you're
still around. You've interpreted it correctly enough that you're still around and about.
So that aspect of it being some sort of an agent that's locked into a certain
really narrow slit of the electromagnetic spectrum, right? This is what I can see,
which is this really thin piece of the spectrum. I'm completely blind to all the other stuff.
And I've got a reach of, I don't know how long, but I really can't contact anything far.
And I really don't know what these senses are connected to out there anyway.
So that I think can be, that situation can certainly be emulated in these things.
And then I also think back of the early days of when you have kids and they're really little,
they go through this phase where, and then the writing, what Mike just said about writing is
exactly right. They go through this phase where they can really talk about, they're talking about
animals they've never seen. And when they talk about what it's like in Africa and all these
things, they have zero experience with any of that. What they have heard is a bunch of stories from
which they've sort of concocted enough syntax so that they don't sound like they're just totally
babbling. So they go through this phase where they can put on a pretty good show, but you know,
they've not had a functional interaction with any of the things they're talking about.
And so as they get older and older, eventually say, ah, well, now he really understands what
this concept is. Well, that was a pretty smooth journey from, you know, sort of putting a bunch
of words together. I just, I still remember my, my, my youngest, um, I spent about a week running
around adding the words.com to everything, you know, he would go sandwich.com. He had no idea
what it was, but he knew that in certain circumstances that it brings up all sorts of
interesting new things that happened. And he would just, he was trying it out. And then
eventually that went away because he realized it's not actually that useful for many things.
And so I feel, right? I feel like when you have kids, you, you, you watch that transition from a
pure syntax engine to, to somebody who knows what they're talking about. And, and even to this,
like I was thinking about this for myself, how many concepts do I think, do I talk about on a
daily basis that I think I know what I'm talking about that actually I've had no experience with
at all. Everything I know comes from the, you know, sort of reading and hearing what other
people have said about it. And we sort of assume, yes, there is a, you know, a milky way
out there. Well, is there? Who knows, right? So I don't know. I'm, I'm, like I said, I don't know,
no, no, no, no commitment to GPT per se, but I'm, I'm skeptical that, that real experience is
that we can get hold of what that actually is.
Like we all live in VR and some, in some sense, we all act to, oh, that's another thing people
say, what if we live in a simulation of something like guaranteed, right? I don't know how, how it
could be any other way. We are constantly sort of building this, this view of what we live in.
We don't have access to actual reality. Anyway, that's my, that's my thought.
Noam Chomsky last week or so has this great quote about GPT three. He says,
it's nothing other than high tech plagiarism.
How are we all?
Yeah, I, you know, I know somebody, somebody said that, somebody said that to me too,
the other day that it's just linear algebra, like, well, I like, okay, but, but we've had
linear algebra for a good couple hundred years, and no one saw this coming really, right? I mean,
I think, and, and you're just ordinary differential equations then. I mean,
right? Like, like fine. Okay, it's linear algebra, but that doesn't just because, and that's another
thing, you know, something, something Mike said, I think at the beginning where just because you
know, or maybe I don't know, maybe Richard, maybe it was you, but he was somebody said,
you know, you know what went in and when and how you made it, but you don't know what it's
capable of, right? And this is people don't feel that either. People, people tell me all the time,
look, I make these things. Don't tell me they're this and that I made the thing I know what it's
capable of. It's just, it's just linear algebra, you know, there's no, I didn't put any magic in
there. Like, yeah, you made it. But like many other things, especially in biology, once you've
made it, that doesn't mean you know what it's going to do. I really, I really think people have this,
this underappreciation of the strong emergence that's, that's, that's going on here. They, you
know, they think they know what the ingredients are, and therefore they know what they have.
I think it's pretty dangerous. Yeah, you know, I mean, you wouldn't say that in chemistry either,
right? That's right. I put these things in the test tube, and therefore I know what it is. It's
like, no, you don't know. Absolutely. You didn't know that gas would be flammable. Yep. Yep. Yep.
Yeah, I think of that the next time you take a new pill from your doctor. Yeah. Yeah. I was looking
at a very local regional thing.
