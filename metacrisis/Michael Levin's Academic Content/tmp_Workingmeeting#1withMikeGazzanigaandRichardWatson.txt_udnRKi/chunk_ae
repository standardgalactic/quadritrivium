I'm much more top down than I am, than than the average bottom up scientist is, right?
But if I was really scale invariant, I would say, well, it could, you know,
you could start at any scale, and you could build upwards and downwards simultaneously.
Or you could simply acknowledge that all scales are always involved. And there can be
a bulge at a particular scale.
And it's no, there's no sense in which
a cognition is grounded in a physical reality, whichever scale you're at.
I'm going to take this phone calls my wife one second.
We would have known it was your wife by the way you spoke to her anyway.
Oh, okay. Are you are you on your way? Okay.
Sorry, there. Thanks.
So I wonder, so Mike, I wonder like like earlier, earlier, Richard had said,
well, why do I feel like such a unified, you know, being then right if we're made of parts and all
that. And so I wonder if, is there an alternative? Is there a possible cognitive being that would
ever say anything different? You know, I'm just not sure, right? What do you think? Is there a
positive, is there some possible being somewhere that does not feel like a unified or if there was,
could we ever communicate? I mean, with it, I don't know, but what do you think?
So one of the wisdoms out of clinical neurology is the patients
not just the split allows us to study these things that kind of coolly and experimentally,
but any patient with a brain disorder is constantly recrafting who they are to deal with it.
And if it's a motor disorder, sensory disorder, memory disorder, there's constant adjustment.
And so we reflexively, we
change our story, change our feelings about things.
And I think we know we do and we marvel at it and we try to understand, well,
why did yesterday I want to go to Rome, but today I don't?
What's changed there? And it's usually some kind of feeling about all of a sudden you imagine
yourself sitting on a plane for 15 hours. And by the way, I heard the greatest advice on accepting
an invitation. When somebody invites you something a year from now and you say, oh, you know, yeah,
sure, you're from the hell, right? When anybody invites you anywhere in your mind, you say,
would I want to go there next Tuesday? And that really cleans out a lot of
pretty good. It's pretty good.
But anyway,
I mean, you know, we're smart people we know about from human experience, we know these
know all these dimensions of our own personality. And we try to compensate for them and we try to
deal with them. And in doing that, we're trying to tell a different story about ourselves.
I was thinking of your wonderful example there, Richard. I wonder if you could have set that up
in the lecture too. I'm going to show you an example of the storytelling brain. And then you
give the challenge and then the person, you know, fumbles around and you just say, see.
We should be able to set it up so that whatever answer they give, I'm right. I shouldn't know.
But do that right. That'd be fun. So Mike and I were discussing the other day that
how many voices we have when we write together.
If we write something together, are we writing with one voice? Or do we do we need to write as
one voice? Or can we still write as two so that we're writing a dialogue for other people to
read? So your answer to the question, Mike, is, is there ever a consciousness that feels like
it's not a unified thing? Like, well, I don't, you know, that's, that's what we are, right? I
don't completely feel like I'm, that you and I are one thing.
I, well, haven't we all had this experience, let's say you've co-written a paper with somebody,
and then five years later, you go back and look at it. And you can come across, you know, in the
you know, in the discussion section usually, oh, I would have never said that.
And then you didn't say it.
Yeah, but and vice versa. I've read papers that I know I read that I know I wrote.
I think I don't remember ever thinking that.
Oh, yeah. Yeah. Well, that happens. Yeah. Within increasing frequency, I might point out.
Yeah. But I can also imagine that there's that you come back to a to a bit of text and I think,
like, I really don't know whether I wrote that paragraph or whether the co-author wrote that
paragraph. And if it's a this isn't true in scientific papers, but if it's a book,
and you have a really good editor, the what they bring to it is enormous.
They're skills. And I've noticed that they can really change the lucidity of a paragraph
by a few words, moving around and bingo.
So that's even a third, a third will in there.
Very, very. That's a good question. I want to think about that.
So the truth is, I guess, that in the same way that different personalities might answer the
phone, depending on who was calling, different personalities reside in me all the time. And
when I'm talking to you, you think that's the same me. And each of them would tell you that it
was the same me, but they're not really. And each of them is willing to confabulate.
Well, look, it's quite common that I would think to myself, I don't really know why I did that.
And I just I just sort of live with that, right? We all do. I presume we all do.
It's like, well, they've done a reasonable explanation would be it wasn't me.
You know, in personality researchers, a view that whatever, for what better or worse,
one is described as having a kind of personality, you have personality, a certain type of person.
And what the researchers have found out that by the age of 26, the world you live in has pretty
much decided what they want to think of you. And you start deviating from that model they have
of you, and they beat you back into what you're supposed to be by various district rewards and
punishments and ignoring and this that they don't want you to change because they don't want to
go through the energy of building another model of you. I've spent their time.
And that's kind of that's kind of weird, you know, to be aware of the constraints that
the world is making you react the way you have reacted.
Right. Like one part of ourselves does with another part of ourselves.
Right. That too.
It's amazing, like all of these things, especially like the thing that
what you just said, Mike and what Richie were saying a minute ago about,
you might be actually talking to a different personality even under the so-called normal
conditions. All of these are things that the people who critique these various AIs,
that's exactly what they critique them for is that kind of a thing. Oh, you know,
you're not talking to a single thing underneath, it's different from day to day. And, you know,
it will, you know, it doesn't have a stable core. I mean, all of this stuff is like, you know,
they sort of pretend that that is not true of us. But these are, I think these are important,
you know, all this, the neurological stuff and everything else, I think it's an important body
of work that has not penetrated into the discussions of AIs.
I think I want to revise my answer about how grounded does it need to be or could it exist
just at that level? I think that it's maybe not just how many levels are there. It's not just
how deep can I scratch before it starts to show the wires, right? But that in order to be sufficiently
deep, it would have had to have had sufficient experience that in order to have the depth to it,
it would have had to have had experience that
shaped each of the layers
so that it was their own experience and not just a faint image or facsimile of such experience.
Maybe it's maybe more like that.
And so then the question is, can you tell the difference between something that was
built from real experience and something that's a facsimile of this experience?
Yeah, so
buddy put it the other day, simply, so you take GPT-5, 6, whatever, however
credible they're going to become.
And at the end of the day, though, while they're going to be doing these incredible things,
they won't have had the human experience.
Now, is that a fair constraint? I mean, if you're basically a laptop sitting on a table doing all
the stuff. Yeah, but is that the threat? Well, they won't have had the experience,
but the question is, could they acquire structure equivalent to having had the experience?
That the only way to explain the level of interaction that we have with them at this
level is that they have correctly induced, in a deep way, what the human experience is,
even though they didn't actually have it. And then say it, but they can say about the experience,
but have an experience. That's what writers do all the time, right? Well,
that's the thing, right? And I'm certainly not arguing that GPT, whatever architecture,
is the one you want to be fully agential and all that. I have no commitment to that.
But I do think that two things. One is, when you say we've had an experience,
I don't know that we've had any experience where in an important sense, we're a brain in a vat,
right? You haven't actually had an experience, which you've had is some sensory data that
makes sense to you and that you've told stories about. And that's adaptive enough that you're
still around. You've interpreted it correctly enough that you're still around and about.
So that aspect of it being some sort of an agent that's locked into a certain
really narrow slit of the electromagnetic spectrum, right? This is what I can see,
which is this really thin piece of the spectrum. I'm completely blind to all the other stuff.
And I've got a reach of, I don't know how long, but I really can't contact anything far.
And I really don't know what these senses are connected to out there anyway.
So that I think can be, that situation can certainly be emulated in these things.
And then I also think back of the early days of when you have kids and they're really little,
they go through this phase where, and then the writing, what Mike just said about writing is
exactly right. They go through this phase where they can really talk about, they're talking about
animals they've never seen. And when they talk about what it's like in Africa and all these
things, they have zero experience with any of that. What they have heard is a bunch of stories from
which they've sort of concocted enough syntax so that they don't sound like they're just totally
babbling. So they go through this phase where they can put on a pretty good show, but you know,
they've not had a functional interaction with any of the things they're talking about.
And so as they get older and older, eventually say, ah, well, now he really understands what
this concept is. Well, that was a pretty smooth journey from, you know, sort of putting a bunch
of words together. I just, I still remember my, my, my youngest, um, I spent about a week running
around adding the words.com to everything, you know, he would go sandwich.com. He had no idea
what it was, but he knew that in certain circumstances that it brings up all sorts of
interesting new things that happened. And he would just, he was trying it out. And then
eventually that went away because he realized it's not actually that useful for many things.
And so I feel, right? I feel like when you have kids, you, you, you watch that transition from a
pure syntax engine to, to somebody who knows what they're talking about. And, and even to this,
like I was thinking about this for myself, how many concepts do I think, do I talk about on a
daily basis that I think I know what I'm talking about that actually I've had no experience with
at all. Everything I know comes from the, you know, sort of reading and hearing what other
people have said about it. And we sort of assume, yes, there is a, you know, a milky way
out there. Well, is there? Who knows, right? So I don't know. I'm, I'm, like I said, I don't know,
no, no, no, no commitment to GPT per se, but I'm, I'm skeptical that, that real experience is
that we can get hold of what that actually is.
Like we all live in VR and some, in some sense, we all act to, oh, that's another thing people
say, what if we live in a simulation of something like guaranteed, right? I don't know how, how it
could be any other way. We are constantly sort of building this, this view of what we live in.
We don't have access to actual reality. Anyway, that's my, that's my thought.
Noam Chomsky last week or so has this great quote about GPT three. He says,
it's nothing other than high tech plagiarism.
How are we all?
Yeah, I, you know, I know somebody, somebody said that, somebody said that to me too,
the other day that it's just linear algebra, like, well, I like, okay, but, but we've had
linear algebra for a good couple hundred years, and no one saw this coming really, right? I mean,
I think, and, and you're just ordinary differential equations then. I mean,
right? Like, like fine. Okay, it's linear algebra, but that doesn't just because, and that's another
thing, you know, something, something Mike said, I think at the beginning where just because you
know, or maybe I don't know, maybe Richard, maybe it was you, but he was somebody said,
you know, you know what went in and when and how you made it, but you don't know what it's
capable of, right? And this is people don't feel that either. People, people tell me all the time,
look, I make these things. Don't tell me they're this and that I made the thing I know what it's
capable of. It's just, it's just linear algebra, you know, there's no, I didn't put any magic in
there. Like, yeah, you made it. But like many other things, especially in biology, once you've
made it, that doesn't mean you know what it's going to do. I really, I really think people have this,
this underappreciation of the strong emergence that's, that's, that's going on here. They, you
know, they think they know what the ingredients are, and therefore they know what they have.
I think it's pretty dangerous. Yeah, you know, I mean, you wouldn't say that in chemistry either,
right? That's right. I put these things in the test tube, and therefore I know what it is. It's
like, no, you don't know. Absolutely. You didn't know that gas would be flammable. Yep. Yep. Yep.
Yeah, I think of that the next time you take a new pill from your doctor. Yeah. Yeah. I was looking
at a very local regional thing.
