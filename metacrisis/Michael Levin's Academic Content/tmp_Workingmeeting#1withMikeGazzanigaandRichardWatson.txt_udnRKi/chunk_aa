I'm super excited to have you both on together.
Do you want to each say a couple of words?
Cause I don't know, I guess that you haven't met before.
So just say who you are.
Sure.
So my background is in computer science
and evolutionary algorithms.
And I've spent a lot of time recently thinking about
the relationship between evolution and learning.
And I have come to the conclusion that evolution is a more
sophisticated learning system than is usually conceived to be.
So I think it's more the case that the relationship between
evolution and learning is that evolution is smarter than we
thought, not that learning is dumber than we thought.
I've been interested in thinking about learning in systems
that we don't usually think of as learning systems.
So learning in gene regulation networks, but also ecological
networks and social networks where there's a distributed
learning process going on in the network as a whole, even
though they're not evolutionary units and not designed for
the purpose of doing learning.
And I've also been thinking about learning in physical
mechanical systems like masses connected by springs, things
like that, where the springs are imperfectly elastic and that
relieves a residual memory in the springs and shown that
that's capable of doing the same kind of learning that a
hot field network does.
So those are some of the things that I've been thinking about.
And I'm excited to talk about things like what do we think
the real limitations are on current deep learning
mechanisms and are there opportunities for relieving those
by the way we're doing it.
So I think that's a good point.
And I think that's a good point.
And I think that's a good point.
Are there opportunities for relieving those by, or how should
we put it, moving to a different way of doing computation
that's much more to do with bays and resonance and
holographic principles and things like that instead of the
current conventional way of thinking about computation
and artificial neural networks based on amplitude.
So that's everything on the table for me.
Well, yeah, I get it.
Well, I came up through neuroscience and testing of
humans with various kinds of neurosurgical procedures.
And from that went into just studying classic lesion cases.
But I've kept my hand in the neurosurgical cases all these
years.
In fact, we have a new series of studies being launched in
Germany as we speak.
There's a series of studies coming out of, well, the
intellectual parts coming out of Cologne and the actual plate
patients are elsewhere.
But what I also do is kind of keep an eye on things at my
age and watch others have the fun.
And one of my colleagues here, man by the name of Scott
Grafton, is one of the real sharp guys in brain imaging.
And he had teamed up with one of his students, I don't know
if you've heard of Danny Bassett, but she's a network
science kind of young guru who's now at Penn and really,
really a superior talent.
And both of them together have studied networks at the level
of fMRI tractography and have ideas about how they can
identify networks that are constantly shifting.
I didn't get that.
Could you try again?
What's Siri coming on for?
I don't know.
That's pretty cool.
So they've captured what they would call the plasticity at
the level of network shifting.
And they can identify networks that when learning is about
to occur, before it occurs by their analysis of these
systems.
Something that would be, I think, relevant and of high
interest to you guys.
So there's, and then, of course, everybody is now inundated
with, and in fact at Santa Barbara, they just concluded
a two-day conference on, well, it's not, it wasn't chat
GP3, but it was the realization of the incredible power of
these learning systems.
And everybody at one level is spooked by it.
At another level, they want more of it.
And I guess the, one of the take-home lessons I got,
there were a lot of the leaders in the field here,
you would know them more than I would, but one of the take-home
lessons certainly was that we don't, we, the people in the
field, do not know how these systems are working.
They take you to that point that it's, they're doing these
things, we're measuring the behavior, and we know, we know
what the algorithms are, they're working on, but we can't
figure out actually how they're doing it.
And I said, well, you're joined the neuroscience community.
We don't either.
But I kind of walked away with the feeling that,
you know, because these things kind of come together to
think, well, let's figure out how the brain does it, if we
can figure out how these neural nets, these artificial
systems, we can get a handle on it, they're not, they don't
have a handle on it.
I'm kind of worried that we're walking down this path holding
hands, and I'm not sure we should be holding hands with
this approach yet.
So anyway, something like that, very, very, very, and then
finally, let me just add in, one of the things I've been
working on for the last few years, and we're just getting
going is to hold these scientific meetings where we try
to examine dogma in a field.
And of course, your wonderful lecture, I listened to Richard
the other day, where you're taking on Darwin kind of
directly up front is, I mean, that's a strong way of
putting it, I realize, but how dogma captures a field and
people won't let other ideas in.
And there's almost an industry involved in keeping it
that way.
As my business friends tell me, the reason regulation exists
is to keep people out.
And the reason these dogmas are far is to keep people out
because the people inside are already doing business,
right, and so forth and so on.
So we've had three or four meetings and we plan three
or four, I'm retiring actually this July, but the system is
set up that we're going to have three or four meetings.
And what I'd like to do is put in the back of both of your
minds that we maybe we organize one, and we're talking,
the whole idea of the meeting is to get five, six, seven
people together.
That's it, and free form, free form discussion, no, the idea
sometimes is also to bring the biggest advocate of the idea
to the meeting.
If they're truly a great scientist, they frequently
know more of the pitfalls than others and then have a full
discussion without any Chatham House rules.
You can talk about the ideas, but done with attribution
as you leave the room.
So we've had a couple and they work.
I mean, they're really, really quite extensive.
I think I mentioned to Mike and earlier,
we had one with the kind of guy that's going five or six
years ago with Randy Gallo still challenging the simple
synaptic idea for storage of memory, and we had five or
six people here and boy, it really ripped.
Let me tell you that the dogma, the simple idea emerging out
of kind of the candle position forward is strong and still
and yet to think of it differently is a hard task
for those guys.
And this was a meeting that achieved that and a little
paper came out and that kind of thing.
Anyway, that's a side story, but if at some point we think
it would be, and the idea in structuring the meeting is
that it is a meeting to have full and free discussions.
That's why you're there.
It's not to not do that.
So there you go.
It's difficult to do that, isn't it?
You have to choose your participants carefully because
you want somebody who's vested enough to defend a position
because otherwise you're just all agreeing with yourselves.
But as you say, you want somebody that's...
whilst they might not be particularly...
I don't know if open-minded is quite the right.
They might not be particularly open-minded.
They are convinced that they're right.
They're convinced that the dogma is right,
but they're willing to talk about the problems, right?
Yeah, and there's a whole other group that are just tired.
They don't want to put the intellectual effort into
rethinking fundamentals.
They just... it's not going to happen on their watch.
You've got to set them aside too.
It's a tough agenda.
Yeah, so Richard and I spent a lot of time thinking about...
it's simple and maybe not so simple,
all kinds of unconventional cognitive systems,
and what does it take to make models of the outside world,
of yourself, of process information, memories, that kind of thing.
So I for one, I mean, we can talk about anything like that,
but I for one would love to hear Mike's overall take on what are we, really, right?
So fundamentally, everything we know from neuroscience
and the history of phylogenetic trees,
so it doesn't have to be human necessarily,
but just given your insights on the bipartite brain and all of that,
what do you think we really are from the inside out,
and then we can sort of expand from there?
Yeah, I can make this short because there's three or four things
that don't get talked about enough that I think are key to thinking about
the mind-brain issue, which is means how does brain generate this
phenomenal thing called consciousness?
And there's a whole lot of talk about this and everybody's jumped in on it,
and they seem to gloss over a few simple clinical facts.
And one of the clinical facts is
it's really hard to say somebody is not acting like a conscious agent,
and that includes people with dementia.
That includes people with massive brain lesions,
and the way I think it, it's almost impossible to stamp out consciousness.
Just think about it.
I mean, if you've all had interacted with demented people,
you wouldn't say they're not conscious,
and yet they have massive pathologies, right?
You wouldn't say a person with global aphasia is not conscious.
