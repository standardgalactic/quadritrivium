But you guys think I don't.
OK.
Cool.
All right.
Got it.
So shall we start?
Maybe I could introduce what I think we have as common ground.
So Roy, Mike is a biologist.
He does very technical work on bioelectricity
and how cells intelligently communicate and self-organize
into complex systems.
And Mike Roy is social psychologist, one
of the world's most famous social psychologists.
So he's written on basically everything.
But most notably, in my mind, he's
got a book on self-control or a book on what
is the nature of the self.
And recently, another book on free will, which you and I
have talked a lot about.
And I see myself somewhere in the middle between you two
doing developmental cognitive neuroscience.
And I think we all have in common these shared
philosophical interests in the self and self-control,
self-organization, and what are the biological evolutionary
mechanisms behind all that.
Cool.
Well, self-organization, I think, is
one of the deep mysteries of the universe,
or one of the most important things by which we get
from electrons floating around in the ether
to the global economy.
Yeah, and people actually, so this is great.
I'd love to hear your take on a few things,
because people ask me all the time,
so I study the journey that we take.
We start life as a single cell, this unfertilized oocyte.
And then you get to be an embryonic blastoderm, which
is this flat disk of, I don't know, 50,000 cells.
And we look at that and we say, that's one embryo.
Well, what are we counting when that's one embryo?
What's going on?
And so I study this slow process of this emergent self
where all the cells are committed to the same goal
and anatomical space and the collective intelligence
of these cells and dealing with novel problems
they haven't seen before and things like that.
And people often ask me, they see this stuff and they ask,
well, what are the implications for social structures?
Can we scale that up?
Because I often talk about scale-free dynamics
that you get in molecular network cells, organs, and so on.
And people naturally will say, what are the implications
for social structure?
So yeah, I'd love to hear your take on the social self,
how much of this collective intelligence stuff
you think is, in fact, multi-scale,
that you can talk about these things,
meaningfully at a higher level.
Yeah, I'd love to hear that.
Well, there's the common process of, again, self-organization
of things lending themselves or taking on parts
of larger systems.
I don't know that the one by which cells become,
single cells become embryos and embryos become babies,
I guess, would be the same as by which people
merge into groups and groups, merge into nations,
and, like I said, nations merge into the global economy.
It's just that, I guess, with the global economy,
they discover advantages.
So globalization is coming whether we like it or not
because it makes the system work better
and ultimately creates more resources
which filters down to individuals benefiting.
If it filters all the way down to the embryos,
I don't know that embryos work any better
because of multinational corporations
or international trade, but maybe they do.
But still, there is the common practice
of moving up toward greater systems.
Yeah, I mean, what we see is that there are certain basic
principles by which these things connect
that allow them to do two interesting things,
that allows them to scale up the goals
that they're able to pursue.
So single cells pursue little tiny local goals,
but cell groups can pursue very large goals
like making limbs.
When I say pursue goals, I don't mean emergent complexity.
I don't mean this open-loop.
Where there are a bunch of simple rules,
they all follow these rules and complex things come out.
I don't mean that.
I mean, beyond that, there's a second-order situation
where what you get is actually a system
that is able to specifically pursue certain goal states.
And if you try to deviate it,
we'll find ways to actually quite clever ways to get there.
And the scale of those goals gets bigger and bigger,
but also in other problem spaces.
So cells, straight lines,
problem spaces.
So cells start off solving problems
in physiological state space,
in gene expression space, and so on.
But embryos, groups of embryos solve problems
in anatomical space.
And then of course, animals with nervous systems
will also solve problems in three-dimensional space
and move around,
and then eventually linguistic space, and so on.
So, yeah.
So, I mean, what are some of the principles
that you think underlie the scaling in your area
when you go from individual people upwards?
What are the kind of,
what are the policies that underlie all that?
Yeah, all right.
I was gonna ask you what are the principles
at the cellular level.
Okay, I mean, there's the obvious point.
If any of us was punked down in the jungle alone,
we'd have a hard time surviving
let alone reproducing or making a comfortable life.
So, there are advantages to the individual person
to being part of a group.
There's safety in numbers, I guess.
Basic communication in the simple herds.
Humans do a lot more with shared information
and division of labor and things like that.
Division of labor improves what the economists
call the efficiency of a system
so that the same amount of work by the same amount of people
can produce more resources.
I would say like, if I had to,
yeah, I'm a professor,
if I had to catch my own food from nature
and build my own shelter,
there'd be an sorry condition, I don't have those skills.
But with division of labor,
everything is done by an expert, a specialist.
And so things get done better.
And then their economies of scale,
which is why the large corporations
can basically out-compete the small ones.
So, again, the same amount of effort work,
the same amount of energy expenditure
produces more resources
in the larger complex system.
Now, is that true at the more basic level also?
Yeah, so far, that all tracks pretty exactly.
You know, I also wonder,
so there's this other phenomenon
that you can call something like a cognitive glue
where imagine you've got this rat
and you train it to push a lever and get a reward, right?
Well, so it forms this associative memory
that pushing the lever is associated with getting a reward,
but there's no individual cell in that rat
had both experiences.
So the cells at the bottom of the foot touched the lever,
the cells in the gut get the reward,
but no individual cell had that experience of both.
Right, yeah.
Right, and so the memory,
that associative memory is owned by the rat.
Well, what's this rat?
This rat means a bag of cells,
but it has a mechanism for doing credit assignment
and memory of things that belong to the collective
and not to any of the individual cells, right?
That's one of the cool things
about being an emergent individual
is that you get to have memories
that none of your parts have.
So I'm curious as to, okay,
and so what that means is that you become trainable
as a collective.
So you can train the collective on things
that no individual in that collective actually knows,
but the collective knows.
So I'm curious if you think that societies,
corporations, whatever, you pick the level,
whether those are trainable.
We did a project once trying to train an ant colony,
not the individual ants, the colony, right?
The collective intelligence of the colony.
And we didn't get to finish it,
it's sort of inconclusive,
but I wonder if anybody's done those experiments
and I wonder what you think prediction would be,
whether collections of humans, not the individuals,
but the group is actually trainable.
I wonder if this connects to Roy's idea of ego depletion,
where he's shown that across a wide variety of tasks,
it's almost like people have this finite pool
of cognitive resources or of effort,
and if there could be some sort of computational
mechanism underlying that,
where say any of your individual neurons,
it's not like they get tired,
but collectively, regardless of what problem
you're working on, there's some generalized pool
of cognitive resources that you're pulling from,
and then over time, it can drain.
Well, we're starting when we talk about the red and so on,
that there is a central nervous system.
You're right that no one cell participates
in both the pressing the button
and the receiving the food reward,
but the brain manages both.
Yeah, but you've got the same problem
when you say the brain, there really isn't any brain, right?
There's a huge collection of cells,
and so for sure, the cells are connected via policies,
and so this is the electrical communication,
and the same thing happens in the rest of the body
that allow the collective to act as though
it was in possession of this associative memory,
but there isn't one of anything, right?
The whole thing is very much a collective,
and you need those policies to make sure
that the collective can know things
that the individual parts don't know.
The brain is particularly good at it,
but there are also creatures that are brainless
that can do it.
There are examples like this in the other body parts.
I mean, it's not just, but yes, of course,
the brain is part of the mechanism of this collective, yeah.
I had a book on the cell last year,
and then it struck me it's the creation of unity.
Usually, the brain uses to process systems
and use that to direct the actions of the body.
The walking would be an obvious one,
that an animal with four legs, the brain has to kind of
understand left and right, front and back,
and coordinate them to move in alternating fashion,
to move forward versus to plant, so the brain gets
the whole body to operate as an integrated system
by sending out separate commands to the separate limbs
based on this integrative system that
organizes the whole thing.
So that is the emergent organization,
of course, it's very adaptive too.
Yeah, I mean, well, a couple of things.
One is, so we study a lot of things that don't have brains,
and so slime molds and the single cell organisms,
and tissues and everything else.
I mean, they all do this stuff, but again,
and again, they're all made of parts, as is the brain,
where it's made of, I mean, they're really,
it's very, once you start thinking about
what a truly centralized controller even means,
it's really hard because everything's made of parts,
right, and it's, I've got this slide where,
that I sometimes show in my talk,
you know, Descartes was really into the pineal gland
because it was, it's the only unitary thing
in the head, right, and he felt that, you know,
our unified experience as humans should have a single,
you know, should have a single locus in the brain.
But if he had had a microscope,
he would have looked in there and said,
my God, there's not one of anything,
this thing's full of cells, right, and still, right,
the hard problem remains is, you know,
understanding how you're going to bind all these things
into a coherent self.
And so, yeah, so I've got this model,
what part, because we deal with cells and tissues
and synthetic organisms, I mean,
we make synthetic life forms and so on.
And we deal with all this kind of stuff.
I've been trying for a framework
that is kind of agnostic about the medium.
So what do all decision-making agents have in common
that need to act in physiological space, right,
in anatomical space and physical space
and financial space, linguistic space, whatever.
Yeah, and so we've been working on this notion
of a cognitive light cone,
which is just the size of the goals
that you're able to work towards.
And then the different, then of course,
there's different competencies in reaching those goals.
But so, yeah, I'm really interested in that,
the social question, because oftentimes,
one of the tricks that we use is,
we try to take things from behavioral science,
tools from behavioral science,
and apply them to things that aren't animals with brains.
So we've shown, for example,
that you can do, you know, sensitization,
associative learning, habituation,
or anticipation, all these things,
you can do them in,
the gene regulatory networks already do this, right?
So molecular pathways already do this stuff.
And so I wonder, and so then people will say,
like, well, that's, you know,
since you're stretching the cognitive spectrum
all the way down, you know,
next, you're gonna say that the weather is intelligent.
And they say, well, I don't know, have we tried training it?
Like, I have no idea, but it's an,
to me, it's an empirical question.
You can't just sort of sit back and make assumptions,
right, Jeff?
So I just wonder, I wonder if the social structures,
if they're amenable to some of the same techniques
that we use in behavior science to probe collectives,
because that's what it is, right?
When you ask if something can do habituation,
or association, or planning, or whatever,
you're probing the competencies of a collective.
And I think we could,
I assume we could probably test that,
but I don't know, right?
I mean, you wouldn't, maybe you know,
if anybody's tried that in social, social circumstances.
I don't, I don't.
We've been talking to Roy a bit about active inference
in these entropy-based predictive processing theories
of consciousness.
We've been talking about it in the context of drive
for exploratory play, sensation seeking,
reward sensitivity, and boredom.
But I'm wondering if that generalizes more
as this underlying, say, computational mechanism
you're talking about that connects between,
whether it's human cognition,
or more basic animal cognition,
or even these higher-order organizational systems,
social systems.
Yeah, yeah, I mean, we study a variety of connection policies,
and one of the, let's see if this rings a bell at all.
One of the policies is a kind of memory wipe.
So if I have two cells sitting next to each other,
there's a very, so if this cell sends a signal,
you know, some chemical signal and goes out
and it hits the cell, that way of communicating,
it's very easy for this cell to know
that that signal came from outside.
That's not my information,
that's somebody else's information.
And so you can choose to believe it,
or ignore it, or whatever.
But there's this magical thing in bioelectricity,
which is there are these electrical synapses
called gap junctions,
and what they do is they connect directly
the internal miliars from one cell to the next.
And so what happens then is that's very different,
because what happens then is if something happens to cell A,
and there's a memory trace of it,
let's say a calcium spike,
or something that's a memory trace of that event,
it propagates directly into cell B,
and it doesn't have any metadata on it that says,
hey, I'm coming from someplace else.
Cell B sees this calcium spike and says,
oh, we've been poked, right?
And so now when you're sharing memories,
if you and I are sharing most of our memories,
it's really hard to keep independent identities.
We start to sort of have this mind meld where,
and now we're bigger,
so we have some bigger computational capacity,
we're physically bigger,
but also we have a joint memory,
and we also are bound to cooperate,
because we can't even physically entertain the thought
of defecting against each other,
because we're sharing the same thought,
and we are the same informationally,
we're the same being to some extent.
So that memory wiping property is one thing
that I think really facilitates this joining into collectives.
Another one is shared stress,
this idea that if one cell is under stress,
what it might do is export some stress molecules
to its neighbors, which then also feel stressed,
they don't know that this is somebody else's stress,
and so my problem becomes their problem.
And so now if I need to get somewhere in there in my way,
now everything sort of gets a little plastic
because they're jiggling around,
because they're not happy either,
whereas otherwise they would have sat there
and not let me pass.
So like the sharing of this globalization of stress,
and there's some other stuff too,
but I don't know, does any of that sound relevant?
It starts to look like pheromones,
and then you get into my world of hormones and development.
Yeah, yeah, yeah.
Somebody said recently, it's funny,
somebody said to me recently,
boy, it's really hard to change your mind
and your priorities, and they said,
I don't know, look at what happens at puberty, right?
Like few hormones and BAMO, everything changes.
All your priorities are upside down,
and things that seemed great are now stupid,
and things that seemed disgusting are now great.
And right, it kind of turns everything out,
so it's not that hard actually.
Well, it's interesting, this collective approach,
this is giving me a different perspective on thinking,
I kind of start from one of my philosophy professors made,
which is that sort of part of the essence of life
is a boundary between inside and outside,
and that every living thing maintains a boundary,
and of course, stuff moves across the boundary,
as we eat, for example, but it's still,
we know the difference between the hamburger we ate
and the one we didn't, it remains outside.
And that's long before the self,
but there is that boundary,
and then the brain presumably evolved within organisms
to take care of the whole self within that boundary.
Not only in space, but in time as well.
Space and time, yeah, well, most animals live pretty much
in the here and now, the integrating across time,
where there are brief expectancies for a few seconds
into the future and so on, but only humans really have
a full narrative sense of self.
Psychologists say that a lot,
that only humans really think about the future.
Does that check from your perspective, Mike,
that other animals are only really focused on the here and now?
No, I don't agree with that.
I mean, I think that, well, it is true
that we are the only ones that have a kind of
a metacognitive, like we know when we are thinking
about the future and so on, but even bacteria and yeast
can anticipate future life,
so memory and anticipation does not require a brain.
Most critters do it.
We've shown a kind of...
They anticipate events how far in the future though,
next year?
No, no, not next year.
So that's right.
So humans have a much bigger cognitive light home.
So that's part of it, is that we have a huge,
and in fact ours is special in another way
because ours is bigger than our lifespan.
So you've been probably a little bit more aware
so you've been probably uniquely, as far as I know,
we are capable of pursuing goals that are for sure longer
than our lifespan, in other words,
not personally attainable goals, right?
Most of these other creatures have much shorter term.
You know, for bacteria and yeast, it might be 20 minutes
or something like that.
That's good, that's good, yeah.
But it's there.
And I also think, you know, your point about the boundary
is really critical.
Yeah, establishing the boundary between self
and outside world is absolutely critical.
I think it happens long before we have a brain,
both evolutionarily and developmentally, right?
Absolutely, yes, yeah, plants clearly.
I mean, you can dig up a plant and wash off the dirt
and move just the plant and nothing else.
So there's the unity there,
but the brain improves your ability to operate that way.
So if we look at the collection of cells as a collective,
they are somehow learning to act or evolving to act
as if they are a unity long before there's a brain.
Yeah, and even in, you know, at the very beginning
of human life, you can actually see,
and this is, yeah, I've done these experiments
in duck and so on, when you have this blastoderm
and you look and you say, ah, there's an embryo
that's going to develop into a human individual.
Well, what you can do is you can take a little needle
and make some scratches in that blastoderm
and for about four or five hours before they heal up again,
every island is going to basically decide
that it's on its own and is going to start making an embryo.
When they do heal, you have conjoined twins, triplets,
whatever, you know, from, so the number of individuals
in a blastoderm is not fixed.
It's not one.
It's anywhere from zero to probably half a dozen, right?
And then you get this interest.
So this like excitable medium just to sort of
generates individuals, right?
And then you get this interesting question
because when you got two embryos sitting next to each other,
the cells, every cell has some other cells neighbor.
And so now the question is, am I part of this embryo
or am I part of that embryo, right?
And sometimes they get confused
and this is why conjoined twins often have laterality defects
because left and right, they can't quite tell what side they're on.
But this issue of deciding, right?
Where do I end and the outside world begins
is like very fundamental.
Yes, it is.
Yeah.
I'm reminded that a baby girl who didn't cry very much,
but one day my wife heard her crying and she worked in
and she was lying there.
Her finger was poking herself in the eye.
Right.
She didn't know it was her own arm yet.
Yeah.
Yeah.
So that's funny too because the plasticity of the body,
you know, if you've ever seen the rubber hand illusion,
you know, you see these videos on YouTube, right?
Where they put a rubber hand next to you
and you watch them pad it with a little brush and stuff
and then somebody takes a hammer and goes to hit it
and the people freak out
because now you think that it only takes 10 minutes to override.
I don't know how many millions of years as a tetrapod,
like your brain knows exactly how many limbs you've had,
but you can override that in just 10 minutes
of watching somebody, you know, pat this rubber hand
and suddenly it's your hand.
Yeah.
It doesn't take very long at all and that's great.
That plasticity, it's why people can have,
people do sensory and motor augmentation.
So crazy prosthetics, right?
You know, this monkey with the third arm that uses it
to eat marshmallows, you know, and humans,
they get prosthetic arms where the wrist goes,
you know, all the way around like your normal wrist doesn't.
They'll do that when they pick up a coffee cup.
They'll go the way that a normal hand would never go.
And so like that plasticity, you know, I think we have to,
embryos have to figure it out from scratch.
What do I have?
What do I, you know, what sensors do I have?
What effectors do I have?
Where's the, where, what do I have control over?
Where is the boundary?
So they all learn that or figure that out.
Yeah. And we can do stuff like in the lab,
we can do stuff like we can make,
we can make a tadpole where the eyes are on his tail
and no problem, they can see.
We can, we can do visual learning tasks at all,
you know, it all gets, it all gets sorted out.
I think it's, we have, we have many examples like this of just
really, oh, we make, we make these Xenobots,
which are frog skin that's given a new life
and it makes this little motile proto organism
that runs around on its own and does all kinds of things.
It's just skin.
Yeah, I think, I think it's because all of these questions
of what am I, what is my structure?
What space do I live in?
All of this gets solved from scratch when every time
it's not hardwired mostly.
There's some type of built in error correction, right?
Like if you put the eyes on the tail,
they slowly begin to migrate towards the head,
even if they don't make it to where they're supposed to.
Now the eyes on the tail don't move.
What, what happens is the eyes stay,
there are things that definitely correct.
So, so if you make, we make these so-called Picasso frogs,
which are all the, all the craniofacial organs are scrambled.
They do correct by the time they get to a frog,
they do correct, but you can also teach them new patterns.
So for example, when you cut a Xenobot,
it heals back to the, to its new Xenobot shape.
And if you have a salamander and you keep chopping off
the one limb after about five or six trials,
it gives up and it's not going to do it anymore.
It's done.
It learns that it's just not going to work.
And they're thinking about that type of self-correction
plus this computational Markov blanket idea of identity
and something like whatever the confidence intervals
or error bounds are.
So on one hand, when we're talking about identity,
you have this kind of almost post-modern,
it could be anything, right?
The boundaries are kind of arbitrary,
only to the extent they're functionally useful across time.
Are they going to be stable?
So the simplest version of this would be,
think about what's a Markov blanket
that can define the scope of the sun.
It can just be a sphere of arbitrary size.
And for the most part, we agree on the boundaries,
but you could keep extending it
and you're going to capture some residual solar flares.
Like you could extend it and define a sphere
that goes all the way out to Mars
and you're going to collect even more of that solar mass,
but it's kind of like a diminishing returns type thing.
So there must be this some optimum point
if you define a function that say on one hand,
you want to maximize the amount of sun you're capturing,
but on the other hand, you want to minimize the amount
of like false positive or empty space.
So you're trying to optimize across those two variables.
And then I'm wondering at the level of the boundaries
of organism, if you have something like that too
where you can have all these philosophical questions
of am I still me if I take away one skin cell?
Yes, or even a hair like,
but you keep removing cell by cell.
Eventually there will be no more of you left.
So it must be something like you do have boundaries,
but they're fuzzy boundaries
and there's something like these confidence interval bands
of how much can you remove before you actually no longer
have the thing.
Yeah.
Yeah, I think that's that's super interesting.
And I think there's a couple of things that feed into this.
One is that people, so I was just reading about this,
the cool example where, you know, blind site
where someone doesn't think they can see,
but in fact, if you ask them to guess what's in front of them,
they guess correctly.
And so they in fact can see,
they just don't know they can see.
There's the original patient that was studied for this
would say that that's not part of him.
It's that vision.
It's something else.
It's something something extra.
You know, he didn't think that was part of him
because he didn't have a direct perception of even though
it was part of a successful part of his behavioral repertoire.
It wasn't something that he had conscious access to
and he didn't feel that was part of the self.
So that's that's asking, but we also have to keep in mind
that's asking his left hemisphere,
presumably the one with speech, right?
Because there's actually another hemisphere in there
that you don't normally hear from.
And there are a whole bunch of other stuff in there
that we don't know how to talk to yet, right?
Other other organs and so on
that might have their own boundaries in different spaces.
And that's also on a practical level.
That's also what we deal with when we work on cancer.
So when we work on cancer,
what you see is that when when individual cells electrically
disconnect from the rest of the body,
they they're cognitive like on shrinks.
They're back to their amoeba, tiny little amoeba goals.
And as far as they're concerned,
the rest of the body is just environment to them, right?
And similarly, when we when we make these Xenobots,
you know, you start with a frog embryo,
you dissociate it into individual cells.
The cells are all alive and you take some of them
and you make this Xenobot, but the but the the the embryo
is gone, right?
The tadpole is gone.
And so where did it go?
And right, because the cells are all alive
and it's exactly what you just said.
You know, you could sort of take one after the other
and then and then eventually you have something else.
You have a collect, you have a bunch of loose cells
or you have a you can make a Xenobot or something,
but the individual is gone.
So yeah, these boundaries are fuzzy indeed.
And then and then in fact, I mean, that's the other the the
end the end point of the story then is that you can actually
go backwards and you can force these.
And this is a this is a cancer approach that we work on,
which is to not to kill those cells,
but to force them to re reconnect to their neighbors.
And when they reconnect to the neighbors,
they once again become part of the collective
that's working on making nice skin, nice muscle.
They stop being metastatic and they they go back to.
Wow.
Yeah.
And yeah, we've done it in frog.
It works great in frog.
We're now moving into, you know, human cells,
but but but it's a different right.
It's a different way of thinking about it
because you you you take advantage of that memory wipe.
You know, they forget about their little local goals
and they start working on whatever the collective goal was.
You know, by the way, I was good.
How far does the cognitive light cone extend?
Because when you when you talk about say humans
are the pinnacle of that like our subjective experience
of being one and then you can go narrower in all of the sub
levels, you know, down to the cellular level within humans
and all of those are narrower versions of that light cone.
But when you expand across humans,
it seems like there's not only a jump to me
and to you and to different selves,
but there's not the same like connecting continuum
with it.
So because on one hand,
I am tempted to say you can look at broad scale social
organization or like network dynamics as an even larger
portion of that light cone,
but it doesn't seem to have the same continuity.
Well, I don't you mean it doesn't like first person continuity.
Like it doesn't like you think it doesn't it isn't like anything
to be that social agent.
Right.
And and we we both are I think sympathetic to panpsychism.
So saying even if we only have conscious access to what it's
like to be us at this higher level,
like it's there's it's possible that there's something that
it's like to be a cell,
but I'm not sure it's possible that there's something that
there's something it's like to be say a country.
There's actually a really good paper about that,
which I will I'll look up in a minute and I'll try to put
on the chat that actually talks about the kind of the the
philosophy of that.
So I sorry.
Sorry.
What is it like to be a bat?
No, no, there's another one that's I'll I'll that's a there's
a different one.
I'll find it.
Okay.
But you know, I don't know.
I think that I think that if we didn't know any cell biology
or neuroscience and somebody said to us,
did you know that here's what I think I think I could take three
and a half pounds of these these little electrically excitable
things and smush them together in this process where the whole
thing kind of folds on itself for for nine months and whatnot.
Did you know that that's going to give rise to an internal
perspective of you know, a human, I would say hell no that
that doesn't sound that doesn't sound plausible at all.
I think we have we have no idea what what kinds of things give
rise to those kind of first person perspectives.
I don't think that necessarily just because you're bigger in
scale, I don't think that necessarily your light cone is
bigger.
So I wouldn't make the claim that necessarily groups of people
have a bigger cognitive capacity than individual people.
In fact, I don't know.
You could you could say what you think about the intelligence
of groups versus versus versus single individuals.
But I don't think there's any reason why it has to be bigger.
But I also don't see.
Yeah, we don't are intuitions, I think for for what is
sufficient to have that that that that inner perspective, I
think are really badly calibrated.
I don't think we have a clue.
I'd be inclined to think you'd need a brain and central nervous
system to have a to have conscious experience.
I mean, that's fine, except that the brain and nervous system
show up very slowly.
So that both both evolutionarily and developmentally.
So that means that we need some sort of a story about when
does it kick in?
And I've never heard a good story about that.
Yeah.
I'm not speculated that the first conscious experience would be
pain that would be adaptive.
And there was a signal that the tissue is being damaged.
That's perfectly reasonable.
And that would be the disruption of a cell membrane in a
microbe because that depolarization that neurons have
when you when you trigger them, which presumably they don't
like and so on.
That is as old as the hills.
That's that's that's pre multicellularity.
Never mind neurons.
And but I agree with you.
Yeah, that that kind of basic that kind of basic basic damage
and that physiological that that delta from from physiological
homeostasis is the origin of it.
But it's really old, you know.
Yeah, good.
Well, to get things.
This is sort of the other side of your example of the rat.
No cell experiencing both the biopress and the food reward.
But with pain, you step on.
Step on, I don't know, fire ants and the brain says,
ouch, and you know, grab onto something and pull yourself away.
That would be the same thing.
It's a whole body response.
And you know, perhaps you could find example of which no,
one cell is involved in both the input and the output,
the input being the signal of pain and the output being the,
the motor movements to escape it.
Yeah.
Want to see something fun?
I'll show you a, show you a quick, a quick video.
Hang on a second.
Yeah, this is cool.
All right.
Can you guys see this thing?
This is, this is the work of postdoc,
a Narosha Murugan in my lab and what this is,
this yellow thing here is a piece of slime mold.
The slime mold, you're going to see it grow,
but the whole thing is one cell.
It really just has one, one, it's one big cell.
This is, is a glass, a very thin glass disc.
It's about five milligrams.
There's no food.
There's no, it's just glass, inner glass.
This is three glass discs.
Okay.
So here's the time lapse.
And so what happens is for the first few hours,
what the slime mold is, is, is grow,
it's growing in all directions, right?
But what it's also doing this during this time,
which you can't see is it's gently tugging on the medium
and reading back the vibrations that it gets from pulling.
It's sitting on a, on a soft agar and it's pulling on the soft agar.
And by this, by a right around by this time,
it's made up its mind about where the bigger mass is.
And how do we know?
Because boom.
Yeah.
And this is reliable.
What it will always do is, but not, not quite always,
but most of the time what it'll do is it'll go to the bigger mass.
We don't know why it likes a bigger mass.
Who knows.
But what it's able to do and the coolest part to me,
the coolest part is, is right here because at this point,
it's already integrated the information about its environment.
It already knows where the bigger masses,
but hasn't done anything yet.
Right.
Up until now, this is all from here.
This is the first, you know, 600 minutes or so. This is all,
this is all pondering time right here.
This is where it's collecting that information.
And, and the whole thing is one cell and it's collecting this
biophysical sort of feedback from its environment.
And then bang at this point, it's, you know, right, right.
Like here, 795, it's still sort of,
it could go in any direction, but boom,
that's it at this point, it's made.
Right.
Very nice.
Yeah.
The whole thing is, the whole thing is one, you know, one cell.
We have tons of, we have tons of experiments looking,
just, you can test it. Oh, and, and other people like Audrey
Disautour has done training. You can train them.
It has memory. You can train it.
You can take a trained one and a naive one and fuse them.
They'll fuse together and then the memory sort of propagates and
the naive one will now remember, you know,
have the memory that, that the other one had.
No nerves. No, no brain.
Single cell.
Yeah.
Mike, we've talked a lot about zooming in down and back on the
evolutionary ladder. Like there's no obvious point at which
intelligence emerges and there's a nice elegance to pan psychism.
Like it's all always there and it's just on a continuum and maybe
there's some bare minimum unit of consciousness.
But if you scale it upwards again, past humans,
even past social networks, at the,
at the most extreme level, you would have, okay,
treat the entire universe as a single system.
You get this kind of pantheist,
cosmosyche mind of God in Spinoza's terms.
What do you think of that?
Yeah, I mean, I, well, first of all, I think though,
I think all of this is an empirical question.
In other words, I don't think we can assume in either direction.
I think you have to do experiments.
So when you, when you, when you have some sort of weird collective
and you want to know if it, in fact, you want to know what kind of
cognitive system it is, you can do experiments like we do with
everything else in behavioral science, you can give it stimuli,
you can see if it has memory, you can see what,
what the kind of attention keeping properties it has.
I don't know how you do experiments on the whole universe,
but for, but you could, for example, you know, I've had,
I've had, I've talked to physicists to try to like,
design a planetary scale synapse.
So you could do it, you could have a system where, you know,
there, there's a gravitational, gravitational system and you can
send objects through a stimuli and it will sort of permanently
change the way that would react to new objects in the future.
So, you know, basically synapses, you could imagine building a,
you know, a gigantic nervous system out of something like this.
I have no idea if we live in one or not.
But, but I think, you know, I think, I think it's not impossible.
And I think that we probably are not going to be able to,
I don't know, I'm sure there's some kind of girdle thing here about
not knowing for sure if that's what we live in.
I had a, I had a, I worked with this, with this amazing graphic
artist, Jeremy Gay, and I've asked them to make a little cartoon.
And it's, and it's a little, it's a, it's a cartoon of two neurons
in a brain and they're talking to each other and one neuron says,
we live in a, in a, in a cold mindless universe.
Nobody cares what we do.
We, you know, there's nothing out there.
And the other one, and the other neurons is, I don't know, you know,
every once in a while I get this idea that there's something,
there's, there's more here.
The universe is sort of, you know, it wants something from us that, you know,
there's got some kind of order to it.
And the first neurons like, ah, you're crazy.
There's nothing, there's no mind out there.
And, you know, they're both part of this big, big brain, right?
And so in that case, the second one is, is, is right, of course,
because they are in fact part of, you know, a larger scale individual.
So are we part of it?
I don't know. I think maybe it's possible. And again, this is maybe very,
maybe Roy can say something about this is,
is it possible for us to gain evidence that we are part of a collective that
has collective dynamics, like learning, like preferences, like attention.
I don't know. I was contacted by some guys who work on the,
the market, what did they call it, the market mind hypothesis or something.
But it's, yeah, it's some kind of, it's some kind of attempt to understand
economics using some tools of behavioral science.
I mean, I don't know, maybe, maybe, maybe some of these concepts like,
like training, like attention, like perceptual illusions, you know,
maybe, maybe they'll, they would work on these larger structures.
You know that ant colonies fall for the same visual illusions that
mammalian nervous systems do, not, not, not the individual ants, the colony.
So, so you can, you can do experiments.
They make the same perceptual mistakes as, as we do.
You can use like say many of the same illusions.
I don't know, maybe, maybe in economics, that thing holds too.
I'm still intrigued by the question.
I think it was Adam brought it up.
Is there something that it's like to be a country.
Yeah, let me find it.
Yeah.
Mike, is the paper you're referring to there?
Does it have the line in it?
What if we all held hands?
I, you know, I don't recall, but, but I will.
There's something, I think it was Ned block and it, it, it might have been in
what it's like to be a batter, a paper in that same space, but, you know, it was,
it was addressing arguments against the possibility of something like that.
And one argument is just like, it has to be physically connected.
So, so that was just like a, a joke.
What if we all held hands, but the, I think the more serious take on that is
something like there needs to be some physical medium for information exchange.
And, you know, back to this like cosmic neuron idea.
I think it's dangerous getting psychologists to comment on quantum physics,
but I'll take that leap there.
I mean, when you hear about things like entanglement where you have what seems
to be like genuine information exchange across large physical distances where
there's, there's no actual contact.
I don't know what to make of that, but then if I start thinking about it in more
of these like treat the universe or just some high level system as some computer
essentially that can transmit information almost like there's again this, this
planetary synapse going on.
I wonder if there's anything there.
Yeah, maybe my, I mean my understanding and I'm no physicist, but my understanding is
that you actually can't use entanglement to pass information faster than light.
It's that that's my understanding that you're not actually passing a signal back
and forth, you're not violating relativity.
But now, nevertheless, there is an interesting notion of synchronicity here.
So, so Pauli and young, right, you might have seen that wrote this book on on the
together on on synchronicity.
And it's this idea that patterns that look like anomalous information transfer at
lower scales are in fact perfectly reasonable cognitive kinds of things at a larger
scale that you're not aware of.
And that's something that I'm working through right now Richard Watson that I
working through some of this stuff right now so I don't know, but check out.
So I put a link on the on the chat.
So this is this is a paper I Eric Schwitz gable.
And it's called if materialism is true, the United States is probably conscious.
And it addresses exactly the the issue that you're talking about.
It's sort of basic basic philosophy.
I like Schwitz gable.
He's sympathetic to panpsychism as well.
I don't know him at all, but I thought I thought this was a pretty good is a pretty
good paper.
But I don't I don't know anything here really, but but the one thing I really
really feel strongly is that our intuitions for what kind of systems are
going to have an inner perspective are not calibrated.
Well, we have an end of one example.
I mean ourselves like we really just have no clue and and I don't know.
Yeah, I don't know about you.
But if somebody if I didn't know what was between my ears and somebody showed
me a brains that look this is this this this this thing is going to have an
inner perspective.
Why would you ever think that right.
I don't know. I don't think I mean the people have tried right so there's you
know it and some other things that try to put down some some constraints
around the kind of architectures that are going to have that metric.
But yeah, I think I think we're very brain focused and and I think that
blinds us to to a lot of things that.
Yeah, I don't know.
Blind brain focus, but it's hard to imagine the United States being
conscious as a.
As a.
As a thing.
Hard to imagine, but but to look you know, are we good at imagining a lot of
things that are true?
I don't know.
And I also think right without without getting you know to to out there,
but I find it very difficult to imagine that in the whole universe, the only
way to be conscious is to have this kind of thing here, right?
Like that strikes me as a priori very improbable.
I would I sort of have this background.
Maybe it's too much Star Trek when I was a kid, but I have this background
expectation that though universe is a very weird place and that there are
going to be minds out there that don't look anything like us.
And if we're expecting to see a frontal cortex with this and that.
We're going to be, you know, badly disappointed.
I just.
I just can't imagine that this is the only way to do, you know, so you can
imagine, right?
I mean, this is a sci-fi has had this for for over a hundred years.
Like, you know, you're you're you're sitting there at home and this thing
lands on your front lawn and some kind of some kind of thing on wheels
trundles out and hands you this poem of like, you know, how happy it is to,
you know, to meet you.
So what are you going to do?
Are you going to assume that who knows what's in it?
And you're going to assume that that it's that it's somehow faking because
you can't find a single neuron in there.
That can't be right.
Yeah, that I don't know.
The idea that the corporation is like a person.
That was a deliberate invention, a cultural invention as a fiction.
Which facilitated trade.
It was a big advance.
And it's one of the reasons that the era of Islamic world fell behind,
even though it was historically ahead for a number of centuries.
But it but it's understood as a fiction.
You don't think the the partnership itself is conscious as a unity.
But it's the key was to protect the individuals involved from liability.
So if three Arabs want to get together to, you know, make an investment and
send out a ship for profit by trade, if it goes bad, their whole fortunes,
their house and everything is forfeit.
And so it made trade very risky.
But the Europeans invented the corporation.
And so if it fails, then assets belong to the corporation can be
accessed by the creditors.
But the homes and the personal savings of the individuals are not at risk.
But it's a it's a legal fiction.
And it's understood as such to say that the the corporation becomes
conscious as a as a unity seems a stretch to me.
But do you know that I mean, that's very interesting what you just said that
that this kind of the that the adoption of a of an agential perspective
makes makes certain relationships easier.
I think that's very interesting.
But you know, there are a lot of philosophers of mind who think that
human consciousness is fiction too.
Right. And basically, I think they would tell exactly the same story that
you just told around primates, you know, sitting around a fire at some point
where where it just basically this idea that we're going to we're going to
assume that each of us has an internal perspective that's like me is just
a lubricating fiction for being a band of cooperating individuals that
there actually is no such thing.
And that that's a pretty common probably the the majority, I guess, view
nowadays in philosophy of mind and then and that that that's exactly that
in fact, exactly that kind of fiction.
That's a fiction that makes it easier to be successful and to do things.
And then eventually it's a fiction that we we turn on ourselves right that
that basically after you tell stories about other agents doing things,
then you say, wait a minute, I'm an agent to I do things I have free will and
I'm a you know, I'm a person and that that that basically is just a user
illusion.
Yeah, you know, there are plenty of plenty of people who write books on
human consciousness where that's the conclusion that you're basically a user
illusion that provides for social lubrication.
I'm not familiar with that perspective, I guess.
I mean, I, you know, I don't want like, yeah, I could I could name a number
of books that would that.
It's a very mainstream. It's a very mainstream thing. I mean, it's it's
you know, I, I, I, yes, it's very hard to sort of internalize that view because
it basically says that you are a walking illusion in many ways.
But but that is I believe the kind of the mainstream perspective.
I read a bunch of things about the self being an illusion and so on and it's
none of them seems very convincing.
I noticed they all put their names on their books.
Yeah, well, that's that's true. And that and that's, you know, that gets back
to the to the issue. I think I think Adam mentioned free will at the
beginning, right? That's that's that's it. I had I had lunch with
with a philosopher once who didn't believe in free will and the waitress
came by and said, well, what do you have? And they and they said, well, let
me see. Are you going to choose a sandwich?
I'd like how come how come you don't sit back and see what the what the big
bang ordained, you know, for it gets impossible for us, right? It's not.
I've never met anybody who can actually, you know, so people say they don't
believe in free will, but I think it's a I think it's a false introspective
report. They don't act as though they don't. And so you would never
would you agree with that? I mean, you would never conclude actually from observing them
in fact, they don't believe it. Yeah.
Yeah, I think I was talking about Medsinger, the German philosopher who wrote
wrote some book or one of them about there's no free will and no moral
responsibility. So I'm going to ask him, OK, is this how you raise your sons? No,
no, no. Of course, you have to learn to behave by the rules.
In these mainstream reductionist views arguing against free will, I mean, I
don't disagree with their logic, but they seem to frame it as all or nothing.
So if you don't have, say, independence from this entire causal chain of the
universe, then there's none as opposed to taking more of this degrees of
freedom approach like Kevin Mitchell or Roy do or this cognitive light cone
approach that can be narrow or broad and give you more freedom. Why would that
even evolve? What would be the advantage of being able to act completely independent
of the environment? Everything else that serves no purpose.
What you want to do is spot multiple possibilities in the environment
and make advantageous decisions on that basis.
Well, that's right. I think a lot of these accounts are very
backwards looking. So it's all about explanations and pointing out that
well, look, there's this whole chain of chemistry going backwards that's
responsible of everything that happens. And that's fine. If you want to take the
micro reductionist perspective and you're content with looking
backwards at what's already happened, but that isn't what we're trying to do
here. I'm not interested in explanation. I'm
interested in invention. I want to know what next, what are you going to do next?
And that kind of framing where you're just looking back and thinking which
Adam, Ziggs and Zach to get you here are completely useless
as a frame for invention. You're not going to do anything new.
In fact, just a couple of days ago, I
had this blog post where I asked GPT
Ford to write a dialogue between
a hiring manager at a software company and a young applicant who
just read one of these books saying there's no free will. So he goes in there and they say,
so are you a good coder? He says, code? The computer
is a physical system. The electrons go where they go. What do you mean, code? There's no
room for this magical code that's going to make the electrons dance. They just, you know, the computer does what it does.
And that's exactly right. If your
perspective is that everything is going to happen
according to the Maxwell's equations where the electrons go, you're not going to code a damn thing.
And, you know, and then you're a terrible candidate for a job that requires
forward-looking creativity. You know, backwards is easy, forward
is where it's at.
You were in the final couple of minutes. Thank you, Michael, for
doing this and thank you, Adam, for setting it up. This has been
very stimulating, giving me a bunch to think about.
Yeah, thank you both. If you have time, I wanted to ask one more question. Mike, you brought up
union synchronicity and we haven't talked about any of this, Roy.
So I'm curious to hear your thoughts, but I'll add one more piece where some of what he says
is very compelling to me. And then on the other
hand, I have Steve Pinker as one of my advisors. So he looks at that
in like very cognitive, rationalist terms of, okay,
this is just one of many biases that we have where chance events occur
all the time. And most of the things that
have no meaning, you just completely dismiss. And then every now and then
it's like type one error, right? Now and then
you're going to get a false positive. And I go back and forth between
thinking, yeah, when these chance encounters happen that
hint at something connected, is that just
me imposing like my predictive processing onto the world? And it's really
just things happen all the time. So there's bound to be coincidences?
Yeah. I really liked Jung when I was young.
I read a whole bunch of his books. I even had plans to go to the Jung Institute
and learn that. And somebody kindly
talked me out of that.
He was certainly brilliant and operating in the
outside the normal range. And that's part of the appeal
to try these things. But the synchronicity
you have to postulate there's some higher
power integrating or organizing
things. It's a variation of that everything happens for a
reason argument. And
in terms of human evolution, a lot of things
happen for a reason. And that's how we learn to relate to each other.
So just looking at each other is like, oh, there's an animal doing something.
How does this affect me? But
I start to infer, well, the person is doing that for a reason
which we can infer. And so we learn to think in terms of
invisible causes behind things.
But the synchronicity
to take random coincidences and see a deeper meaning
is relative. But I guess I believe there's a lot of randomness
in the universe. So I'm not really a believer
in synchronicity as a thing. Now, some things do
happen for a reason. And there are, you know, you can explore coincidences
and some of them will not be coincidences, but a lot of
them are. Right. When it gets all mystical, it seems to fall
on its heels. But when I think about Mike's example of the
comic strip, neurons talking to each other, firing really
in accordance with a whole plan of a higher intelligence
that they can't perceive. And then thinking about how narrow our perception is
and just thinking, is it possible that there's some like large scale
computation that we're all part of? And thinking about, I don't know, this evolutionary
game theory or these sort of natural laws of
selection that are guiding in a certain way. And then other people
say, you know, it's not selecting for some end goal.
It's just selection just is and what survives just is.
Yeah, I think, you know, I think the question
of whether there's a larger pattern is an empirical question. So I
not going to claim an answer to that. But I do think that the concept of
synchronicity, and I've only recently started working on this. I don't have a mature
version of this idea, but I'll just spit this out that I think
the concept of synchronicity goes way beyond our human
tendency to notice patterns. I think that
a proper version of the concept of synchronicity would talk about
a multi scale pattern so that when you're looking at electrons in the computer,
you would say, isn't it amazing that these electrons went over here and those
went over there. But together, that's an AND gate. And by the way, that's
part of this other calculation, like amazing down below all they're doing is
following Maxwell's equations, but looked at it at another level. Wow, they just
computed the weather in Chicago. So I think
it's not about, well, I was going to say it's not
about us and our human tendency to
pick out patterns and things. But actually, I do think it's that too, because
if synchronicity is simply how things look at other
scales, of course, we're going to get good at it. And of course, we're also going to make mistakes.
We're not going to be perfect at it. We're going to be looking for these kinds of things. And sometimes we're going to
overdo it. But that's not to say that there are mundane
explanation, things that look random and
physical and deterministic at one scale.
You're missing a lot if you don't know if there
is a different scale of observation. And it's like,
yeah, you could study your computer using Maxwell's equations,
but you're really better off if you know what a high level programming language is.
And that is total mysticism from the perspective of the electrons.
This idea that there's this giant algorithm that's determining
where we go. It's mystical nonsense. Except that if you don't buy into that,
you're not going to code much. We would still be in the 50s
as far as information technology if we didn't buy into that particular brand of
mysticism. So I feel like there's definitely a revolution
along those lines coming for biomedicine.
And this is our obsession with the biological hardware and with the molecules
instead of the expectations, the memories, the preferences
of our collective cells and so on.
I'm betting a lot of our lab work on that. That's all got to change.
But maybe it goes higher than that. I don't know.
But anyway, yeah, again, same.
Thank you so much for putting us together. A real pleasure.
Please send over if you don't mind. If you have anything
that's relevant to this from your work that I should read, definitely send it over. I'd love to.
All right.
Okay, well, thanks again.
Thanks, Adam. This was super interesting. Thank you both.
Appreciate it. Thanks, guys. Bye. See you later.
