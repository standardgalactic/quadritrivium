Great, thank you for welcoming me to your lab meeting.
I appreciate it.
Oh wait, what am I doing?
I have to share my screen first.
All right, so you should see my slides now.
Oh, perfect.
Great, so yeah, thank you very much for welcoming me.
And I know there's potentially some common interest
in these kind of themes.
I'm just going to talk about one particular project
as the title says.
We're looking at the evolution of neural activity leading up
to a spontaneous voluntary movement.
I have here a case study in Perseverance.
I mentioned that this is work that I
started with Rob Shapire, who is one of the co-developers
of AttaBoost, then at Princeton and his then PhD student,
Mehmet Basbug.
Mehmet has since gone on to, he's working for a startup.
And my PhD student, my current PhD student,
Luca, has taken over leading the project.
But it is something that we literally started.
I think the conception of this goes all the way back to 2012.
We've been working on it for a while.
But I'm happy to say we're finally, I think,
we're under the bent.
And we're getting ready to actually submit this or resubmit
it.
So it was in review at PNES.
And the reviewers asked for more data.
And COVID came.
And then we had other problems.
We found bugs in the software, et cetera.
But I think we've rounded the bend.
So the theme here, when I say impending movement,
I'm really talking about a spontaneous voluntary movement.
And that's the phrase that I tend to use.
Here's an example.
Like you have the diver on the diving board.
And you can say, well, yes, there
are constraints here.
I mean, the diver's not totally free.
And he's on the diving board.
He's clearly expected to dive.
So on, there's this whole context that constrains things.
But at some point, there's a time scale
at which there's a decision to be made, like jump now.
And that's not as constrained.
So there is some room for what you might call a free decision
here that's not constrained in any obvious way
by anything going on locally.
So that brings up questions like, well, why was this movement
initiated exactly when it was and not, say,
500 milliseconds earlier or later?
How do those kinds of decisions get resolved in general
when there aren't any obvious constraints
or imperative to move?
So just to be clear about what we're interested in,
it's something that I refer to as the neural decision to move.
And if such a thing does exist, and I'm not necessarily
saying that it does, but if it does exist,
what we're looking for is this proximal neural event
that commits some part of the body to an imminent movement.
That's sort of what we're after.
And that question is pertinent in a lot of different contexts.
I throw up a few of them here, not least of which
is developing brain-computer interfaces.
So they have made incredible strides, especially now
that people have started to look at invasive methods.
But one of the most challenging, outstanding problems
is not to know what the user intends, but to know when,
to be able to detect in continuous time,
like when the user wants to do something.
That's more of a challenge.
And if you think about it, well, think about a brain-computer
interface, rather than one that's controlling a robotic arm
like in the picture here.
Imagine one that's you're controlling your word
processor on your computer, Microsoft Word.
So if you're an able-bodied person,
you might be sitting at your computer with your hands
like rested on your keyboard, and you're thinking about what
you want to write.
And if you're like me, you might sit there
for a very long time stuck just thinking
about what you want to write.
But you're thinking about what you want to write.
But then at some moment, you start typing.
And so there's the actual fact of, OK, now I'm doing this.
And with a brain-computer interface, which
is driven, as we say, by thought,
how is that interface to know when you're just
thinking about what you want to type versus really
meaning to actually type now?
And that's this streaming problem,
this problem of detection in continuous time,
knowing when a person really intends to do something.
It isn't just thinking about it.
So you may or may not be familiar with this research,
but you've probably heard of the readiness potential.
So research on this general theme arguably
started back in 1965 when Cornhuber and Deka published
this account, published their discovery
of this cortical electrical potential called
the readiness potential or the barite shaft's potential,
that you get when you record using EEG, in their case,
from these central sites, roughly over the motor
cortex.
And you see this very slow buildup
of a scalp electrical potential beginning
like one second or even more before the onset
of a spontaneous movement.
So the people were just instructed
to make a spontaneous movement every so often,
not too precise instructions.
And I think they were told to try to wait at least 10
or 15 seconds, but not too long, not too much more than that,
but to avoid counting time, just kind of wait
and just at some point spontaneously move.
The reel-to-reel tape here in the background, by the way,
that's just a nod to the low-tech methods they had
at the time.
So they had a reel-to-reel, this reel-to-reel tape device
that was recording the EEG.
And then when the person moved, they would stop it.
And then they would flip the tapes over and play it back
in reverse to capture what had happened in the few seconds
before the movement.
So Cornhuber and Deka dubbed this the electrophysiological
sign of planning, preparation, and initiation
of volitional acts, the readiness potential.
And that interpretation has held more or less ever since.
And this, what I call pre-movement buildup,
it really doesn't matter how you measure it.
You can certainly measure it.
It's very reliable, measured with EEG,
but it's also been measured at the level of single neurons,
even in humans.
So these were epilepsy patients.
And they were able to do it.
Itzhak Fried and colleagues did a similar task
with human patients and recorded in many different areas.
Here's in the pre-SMA a slow buildup
preceding the onset of movement.
So it doesn't matter how you measure it.
You get this slow buildup.
And it's not just in humans.
So you get this pre-movement buildup in primates, rodents,
and even invertebrates, even crayfish.
And I think I've heard some recent work in progress
looking at similar slow buildup in fruit flies, I think.
So about what was it?
30 years after Cornhuburn Deka, there
was this famous study by Benjamin Libet, which probably
most of you have heard of.
So he did the same thing.
He recorded the readiness potential
while subjects were making spontaneous voluntary movements.
But then they had to estimate when
they felt the urge to move each time they made a movement using
this fast rotating clock.
And the upshot of that was that the conscious decision,
at least as timed using this clock method that Libet devised,
averaged out.
The variance is quite broad, but it averaged at about 200
milliseconds before movement, whereas you
could see this readiness potential stretching back up
to a second or even more before movement.
And they often talked about the onset of this thing,
even though it really doesn't look very linear.
It looks pretty non-linear.
So if you follow it back in time, it's not clear
that there's any sort of an onset.
But you can say, well, the first point
at which it was detectable above the noise floor, I guess.
So these two studies, so these two findings, the Cornuver
and Deka and then Libet's, led to what I caricature here
as the prevailing view, which is that somewhere far back
in time on neural terms, one whole second or even more
than that, there's this decision.
There's this neural decision to initiate movement.
And then the rest is the outcome of that decision,
so this readiness potential that is
coursing towards an eventual triggering of movement.
And then as an aside, there's this later event,
which is when the self becomes conscious of the decision
to move, which you can really take with a grain of salt.
It's unclear what that really means,
considering that it's a post-talk judgment
that the subject makes a second or two after they move
and so on.
It's difficult to interpret.
But this is, I would say, a caricature of the prevailing view.
I've worked on leading up to the work I'm describing here,
or that I will be describing here,
is a different account of the readiness potential
that is based on there being spontaneous fluctuations,
spontaneous ongoing fluctuations in neural activity
in the motor system, probably in all systems.
And that ongoing activity is arguably just noisy.
It's stochastic, at least, from our relatively uninformed
point of view.
Maybe if we knew more, we could call it something else.
But it seems stochastic.
And noise in neural populations, even
at the single neuron level and at higher levels,
like in the residuals around reaction times
or other behavioral phenomena, even if they are noisy,
the kind of noise, it's not like white noise.
So it's auto-correlated.
It's one of ref noise.
And that kind of noise is primarily
driven by lower frequency fluctuations.
And there's ever less energy in the higher and higher
frequencies.
And so the idea was simple.
It was just, well, what if in a context
where you don't have a very strong imperative
to move it at a particular time, then in that context,
maybe this ongoing ebb and flow of activity in the motor
system actually starts to play a bit of a role
in, at the very least, determining
the precise moment at which a movement is initiated
or triggered.
So if there is a threshold in the system that
leads to triggering the movement, which I have illustrated
here is this red line, you might have an inclination
to move sometime soon, but the precise moment isn't really
fixed, then the noise might help to determine
the precise moment at which the threshold is crossed.
And then if I time lock to that threshold,
it's kind of a no-brainer.
I'm going to see the profile, you might say,
of that one of ref noise.
In fact, it turns out, if you look at this,
carefully, it actually gives you an estimate
of the autocorrelation function if you time lock
to these crossings and average over many of them.
So this led to what I call the stochastic decision model.
The premise is just that when the imperative to produce
a movement is weak, then the precise moment
at which the decision threshold is crossed
is largely determined by spontaneous sub-threshold
fluctuations.
Neural activity and those fluctuations
get caught in the event locked average,
looking like a gradual buildup.
And I modeled this using a simple leaky stochastic
accumulator, which is just basically a drift diffusion
model, but with this leaky term.
And the leak actually makes it more biologically plausible.
And in this case, in the case of my own work,
it ended up being necessary to adequately model
this or to fit the data.
So this is work that we published in back in 2012
that sort of upended the going interpretation
of the readiness potential, and hence
the interpretation of Libit studies and so on.
We could argue then, here we give
offered with this new perspective,
that this slow buildup that we see
maybe is accounted for by spontaneous fluctuations.
And the actual neural decision or the commitment
to initiate a movement doesn't really
happen until quite late in the game.
And we've called this a late decision account contrasted
with Libit's account, which is an early decision account,
saying that the decision happens at the readiness
potential, that's an early decision account.
And here, we're saying that the actual decision
or the commitment to move happens late.
So we distinguish between late and early decision accounts.
So one of the reasons that this even came up
and is even a problem is because of the way
that people do research on spontaneous voluntary movement.
You need epochs, you need to average,
because the data are quite noisy,
even single unit data are pretty noisy.
So you need to average, and so what do you do?
You have to find some events, and then you time lock
to those events, you extract epochs,
and then you average them together.
And of course, the events that you time lock to,
here are these blue arrows, are the movements.
That's when you initiate a movement.
So you have this sample of data epochs
that basically all of them terminate in a movement.
Well, that's a very biased sample.
It's inherently biased because of the nature of the question
and the nature of the way you do the data analysis.
But if you think about it, it's a bit like if you're asking,
well, what's predictive of movement, which is essentially
the question, it's like trying to learn to understand
and predict the onset of rainfall
by looking at just a sample of rainy days.
So that'd be a very biased sample.
You don't know what happens and the degree to which whatever
you see in the data is happening even when it doesn't rain.
So the caveat is that sampling the conditions that are active
when a movement is not about to happen
is integral to being able to reliably predict
and understand what's going on when movement is going to happen.
But this is the way that this kind of research has gone on
for since its inception.
We always just look at epochs that are time-locked
to the movement because that's the event, the only event we
have in the data to time-lock to.
Ideally, ideally, you'd want this.
You'd want some epochs without movement,
epochs with movement, compare, see what's going on.
But we never have that.
One thing that people have done to get around this
is you have just these epochs with movement.
But what you do is you take some time window that's quite early
and you call that the baseline.
And then you can maybe look at other time windows closer
and closer to movement and compare those.
But that's also very biased because the baseline
has a fixed and reliable temporal relationship
with the onset of movement.
So that's problematic as well.
We'll see.
I'll show you that, some of what we've done.
But so this work really started with the desire
to do this, to have these somehow have epochs without movement,
have a proper control condition with the prediction
that if this late decision account is correct,
then distinguishing between these
should be challenging, if not impossible,
well before the decision, the putative decision.
So again, this is work I initially
started with Rob Shapiri and Mehmet.
And then Luca came on board more recently.
We tried to map the time course of neural activity leading up
to a spontaneous voluntary movement using boosting,
using out-of-boost in this case.
I collected some MEG data, simultaneous MEGE data
from subjects.
This is one I was working at Narrow Spin, just near Paris,
France, with the Stan DeHans group.
And I had, I mean, one of the features of out-of-boost
is that it works quite well and provably
so, assuming sufficient amount of data.
So I had a few subjects, a small number of subjects,
but I had them come back for multiple sessions.
So I had a large number of data epochs
for each of a few subjects.
We later added more subjects with fewer sessions,
but that's how we started.
And the paradigm that we developed is quite simple.
What you do is, as a subject, you're
looking at these photographs of nature scenes,
south door scenes, or plants and stuff.
Nothing that has any strong valence to it or anything,
just pretty pictures to keep you engaged.
Except there are two kinds of viewing,
let's call them trials, because what you're really doing
in this task, it's just a slideshow for you to enjoy.
That's it.
It's just that you may or may not
be in charge of when the slide advances to the next one.
So before each slide, you get a Q word,
either manual or automatic.
If you see the Q manual, then that means,
and there's a fixation point on the image.
Because with EEG and MEG, eye movements
introduce big artifacts, so we have a fixation point.
On a manual trial, you're instructed
to just look at the image and enjoy it for a few seconds,
and then when you're ready, you make a movement.
You normally just press a button,
and then that advances to the next slide.
On these automatic trials, the instruction
is just to relax, and the slide will advance by itself
after a few seconds or after a little while.
And crucially, the viewing time on these automatic trials
is drawn from the subject's own viewing time distribution
on their manual trials, so that by the end of the experiment,
these two kinds of epochs are relatively well matched
for how long you were waiting for the slide transition.
So this gives us our matched control condition.
We have one set of data where we align the data now
to the slide transition, and in one case,
that slide transition is accompanied by a movement,
because the movement was what triggered the slide transition,
and then in this other set of data, there is no movement.
So you have movement, no movement.
And then what we do is just build a classifier using
Ataboost that, in a sliding window,
is trying to tell these two apart at each position
of the sliding window over the time period of an epoch that
goes back about three seconds.
And we align everything to the leading edge of the window,
because we want to know what the classifier had access
to before this point in time.
And we are very careful not only to align the leading edge,
but any kind of filtering that we did or anything involving
wavelets or anything like that made sure that it was like,
if we used a higher low pass filter,
we made sure it was causal so that no information in the future
with respect to the leading edge of the window
could leak back in to the window.
So really, the classifier is telling you,
this is up until now, this is what I can tell you.
This is how I can predict between manual and automatic.
For those of you who aren't familiar with Ataboost,
the way Ataboost works in a nutshell
is to take a usually a quite large number of very weak,
simple classifiers, and learn how to combine their output,
or let's call it their opinions, in just the right way
so as to build a very powerful classifier
from the individual opinions of a large number of very weak
classifiers.
That's the essence of boosting.
What we used as features are these HAR wavelets.
Look like this.
And there's one that's missing here, which is just a flat line,
which is just basically an offset.
And that one does actually become important.
So we have basically three kinds.
We have that offset.
We have a monophasic and a biphasic one.
And of course, this represents the window
that we're looking at, the width of the sliding window.
And what Ataboost does is it will just
try every single possible version of each of these kinds
of wavelets, where you can vary the width and position
of this phase, or this square wave.
You can vary every possible combination of the width
or separation of these two phases.
So Ataboost will try all of those.
You take the dot product of this with your signal,
and then you apply a threshold.
And depending on if it's above or below,
you declare that exemplar to be either automatic or manual.
And that's one week classifier.
Because there are so many possible configurations of this,
you end up with many millions, actually, of week classifier.
Because you can apply each one of these
to the data from each sensor and every pairwise combination
or difference, every pairwise difference
between two sensors.
This is what some of these might look like.
So if you apply this monophasic wavelet,
then you get the area under here.
And if you apply this biphasic one,
you're ending up basically what you're getting
is a temporal difference.
And the one I'm not showing is the offset, just the flat line.
And that just gives you the bias, the mean in that time window.
Here's an example feature.
So let's say we're looking at the pairwise difference
between those two sensors.
We apply this, take the dot product of this wavelet
against that within the window.
And then you have a threshold on the output of that,
which is a scalar value.
So in general here, one week classifier is feature plus
threshold.
So these are called decision stumps.
So typically in boosting, you use decision trees.
That's very common.
We're not building a tree.
We're just using one rule.
And then of course, this entire process
is repeated separately at each position of the sliding window
and for every possible combination
or every possible version of the three different kinds
of our wavelet.
And of course, trying this at all different positions,
for example, this particular biphasic wavelet,
trying it at all possible positions within the window,
that just amounts to roughly a convolution operation.
And if you're clever, you can code it right
so that even though you have many millions of features
to try, it can be quite fast to run.
So if we look, these are in the data
from the first three subjects from whom
I got a large quantity of trials.
And this is what the readiness potential looks like
if you just take that time locked average.
And here it's a little more sophisticated
than just recording from a particular sensor.
What I've done is just built a spatial filter
on the temporal difference between what's happening early
and what's happening close to the movement.
Here's what the spatial filter looks like.
And if you project the data onto that filter,
you get this readiness potential.
And this is just to show we get this highly replicable result.
We get this nice readiness potential that stretches back,
arguably even almost up to two seconds prior to the onset
of movement.
So the question is, does this, let's say this point here,
two seconds before the movement, is that
reflected decision to move?
If that does reflect the decision,
and this is certainly we can resolve this quite well
if you go, say, just a second in advance,
you're really far from the noise floor.
So if this reflects a decision, then it should be predictive.
And that's the essence of the question we're asking.
If we do out of boost now in this sliding window,
can we predict?
We should be able to predict, like, a second in advance,
a half a second in advance, and so on.
At least that's what the readiness potential would suggest.
But when we actually do this, and so here's an example of,
so in white here, you have the sliding window.
Let me turn off this laser pointer.
So this white bit here is the sliding window.
So what Atta Boost is seeing in this little,
this is a video animation.
What Atta Boost is actually seeing
is just what's inside this white window here.
And these are just two example features,
an average feature that is negative for movement,
and then in blue here, an average feature
that's positive for movement.
So as I animate this, just pay attention to the ROC curve here,
and you can see how that evolves as the sliding window approaches
time zero here, which is when the movement actually happens.
So here we go.
So I'll pay that again, and you can see it again.
And what you might notice is that as the sliding window is
sliding over the early part of the readiness potential,
you don't seem to be getting any purchase until the sliding
window actually gets to about 150 or so milliseconds before zero.
Let's look at it again.
There's really nothing happening until about now.
And so if we look at the averages,
we look at the results of doing this over.
These were these first three subjects.
You see that Atta Boost is not doing such a great job of telling
them apart far before zero.
But at the roughly the time of movement initiation,
or maybe 100 or 150 milliseconds before,
then it starts to be able to do so.
And just at and after the onset of movement,
it can do it extremely well.
And these two, by the way, I believe the red line is the MEG
data, the blue is the EEG data.
So we've since run a number of more subjects.
Here's 10 more subjects that we've run recently.
This is just EEG data.
But you can see once again, it's not really different
from chance until you get about 150 milliseconds
before movement onset.
And right there and thereafter, it goes up quite high.
So it's not as if the machine learning algorithm isn't
able to perform well on these data right after movement onset.
It performs exceedingly well, upwards of 90% correct.
And you can see even the individual traces here.
And by the way, here in this case,
we're comparing in red a growing window
versus a sliding window.
And performance is about the same.
We expected that, but it was just a sanity check.
So I mentioned before that there is this trick you could use.
If you only had data that was aligned to a movement,
you didn't have any control data.
You can, and this is what others have done in the past.
You can say, well, I'll go way back in time
and call this little window a baseline.
And then I'll look at all these other epochs
of the same width, but getting closer and closer
to the onset of movement and just keep comparing those back
to this baseline.
And asking, for example, with machine learning,
can I tell them apart?
And now, conceptually now, hopefully,
you agree that that's biased.
And it's giving you an unnaturally
optimistic view of how well you can classify or it should.
So what we predicted, and when we did the analysis in this way
and here it's shown in red.
So when we only looked at the movement epochs
and did the machine learning comparing each position
of the window to a remote baseline,
then we end up on average this red curve.
So it looks as if we can classify very, very well,
even very early on.
But we're arguing that that's a false impression,
that that's cheating, so to speak.
And the real difference or the real ability to classify
is given by the blue line, which is the control method, which
is where we compare actual movement plus slide transition
epochs with just the slide transition epochs,
so the manual versus the automatic trials.
Again, this is with a more recent round of 10 subjects
that we recorded using EEG.
And here are the individual traces from those 10 subjects.
So you can see it holds up pretty well for each one.
And we're doing another round of 10, I think we're almost done.
But I have little doubt that we'll
have the same pattern of results for these other 10 subjects.
So the evidence do seem to support this late decision
account more so than an early decision account.
We've been able to show that probably among the reasons
that people thought this was an early decision was just
because this kind of sample where you align
to the onset of a movement is biased.
And so moving forward, what we're trying to do
is to look at this data in a very different way.
And this is a technique that we've been developing,
which is to rather than so that you
can think of every point in time in this readiness
potential where you just take the average time
lock to movement, every point in time at the readiness
potential reflects the distribution of the probability
of the signal now given a movement
at a specific time in the future.
And what we want to do is look at that the other way around.
We want to look at the probability of a movement
at various times in the future given the state of the signal
now or in the recent past.
Something more like building a weather forecast in a sense
or a forecasted trajectory of a hurricane
where you out x number of days in the future,
you're predicting where it's going to be
or what its state is going to be.
And the nature of that distribution
can actually tell you something about the degree to which
the process is still drastic or deterministic.
So that's where we're at right now.
I just wanted to share this work with you
and hopefully start a discussion on these kind
of general topics.
But I do want to point out that I started, at least I
started this work back when I was working in Neurospin
and I had funding from the European Research Commission
and an ERC starting grant.
And I obviously have since continued the work now
here at Chapman at the Brain Institute.
So thanks for your attention and I open it up to discussion.
