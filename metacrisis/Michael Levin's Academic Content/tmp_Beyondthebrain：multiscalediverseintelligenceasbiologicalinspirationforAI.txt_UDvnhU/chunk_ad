What might you want from a from a real agent, you know, this idea that when we make these things
Everything has to be determined on the fly. We can't pre define
What you know a built-in model of what they are or where their boundaries are they have to emerge
Spontaneously through auto polices. They have to figure out where the world starts. Where do they end?
What do they have? What effectors as you saw from from all of these examples, you know, the
Tadpoles with the eyes on their tails and everything they make biological systems make very few assumptions really about what happened before
The whole the the product of the evolutionary process is a problem-solving machine that starts from scratch
Kind of I call it play the hand your dealt, you know, they sort of they do not make too many assumptions about how the world is
I can show you many examples of
Beings that have too many cells too few cells
The wrong kinds of cells and they will always try to figure out something useful to do with that
So that process I think that process of self-construction is really going to be critical for for proper intelligence
So anybody who's interested can kind of dive into some of the details here
So I just want to thank all of the the students and the postdocs who have done the work. Thank our funders
I'll do a disclosure here fauna systems because josh bongar and I have a
startup company around computer designed biorebotics and
Yeah, and and just just you know, my my final message is that I think
That this multi-scale competency architecture, which is made up of these agential materials that basically behavior shape each other
To accomplish
Specific outcomes in in morpho space can really teach us a lot about how collective intelligence works and how we can
Engineer it. So I'll stop here and thank you all for listening
Yeah, thank you
Exploded several times through there. Thank you
So one question regarding the
The the warm and the head and you said that the memory is distributed. So it
built the same head with this
Same functionality and same memory. So if the memory is in the body, why does it need that?
So what's the functionality of the head? Is it that the executive is the memory?
Yeah
It's always great. Well, thank you so much. Thank you
Yeah, so so the thing with planaria is that the brain is actually required for behavior
So when you cut off the head the the remaining body parts really don't do anything. They just sit there
They they don't so you wouldn't know whether it had memory or it didn't have memory because it doesn't do anything
and so in order to to to observe evidence of of the of the memory you have to let it
Regrow the head so that it can actually start to behave
So I think that um
The rest of the body and we don't know exactly where the memory is. We don't know if it's in the neurons
We don't know if it's in every you know, it's in all the tissues. We really don't know
Uh, but I think that the memory outside of the brain is kind of like
Passive it it doesn't it's stored. All right, but it doesn't have the ability to act or to be read out
I think I I personally think that and of course this is extremely controversial
But but I'm not the only person thinking about this way
This idea that to what extent our specific memories actually stored in the neurons versus the neurons being a
Kind of decoding machinery from from other cellular substrates and there's this there's some nice work on that
so so I think I think there's something to that and
But but you definitely need the brain to be able to read out the memories and act in the in the three-dimensional world
This was absolutely spectacular and thank you
Localization in a sense that comes out out of your view, but I want to push that along
so we will often be in this situation where
There's something that could happen that is good for me like if I think about myself as being small
and what I'm gonna do is I
I I want someone over there, which is my direct neighbor to do something for me and some level
What we want is something that's almost like radian descent then like where I tell my neighbor
Hey, can you move out of the way and they are telling me but hey, can you move out of the way?
And so this chaining that we have in radian descent in a high
Should be the case for biology at all levels. If I like
So this is this is really interesting and
I I have a slide I didn't bring it here just for lack of time, but I have a slide that shows almost exactly what you just said
So so think about think about the role of stress, right?
So imagine imagine I'm going to try to describe this this this slide in words here
Imagine that you have a bunch of cells and there's one cell at the bottom
That's not at the right location. It wants to get up here to the top
Now the problem is that all of these other cells are perfectly happy where they are
They're not getting out of the way for this and so this cell is very stressed because because it's not in the right location
What you can do is you can export your stress. You can start to leak your stress to the neighbors
The neighbors also start to feel stressed
They don't know that it's not their stress because all the stress molecules are exactly identical
And so the temperature of the whole system rises
They get so they start to get a little plastic and everybody's kind of willing to move around a little bit
And then you end up, you know, then then you can get to where you can go and then the global
You you reach some kind of global maximum and everybody's happy and it's a way to um
It's a way to to to have this kind of cooperativity without
Really any altruism because all the other cells want to do is minimize their own stress
And and you're stressing them out and the way for them to have lower stresses to have you have lower stress
And so it's it's like this collective again. It's I think it's one of these things that helps the collectivism
So if you want to call that gradient descent, I'd love to talk more because uh, you know, I'm not I'm not an expert in gradient descent
So I'm not sure but if that's what it is, I'd love to know about it
I think it's quite similar. I'd love to okay. That would be great. That would be great. Yeah
Hey, uh, thanks for that talk. That's great. Thank you. And I was also a perfect question
for me to follow up on
So I come from a multi-agent rl background multi-agent systems and
something that
um, I guess the goal of multi-agent systems is to is to model the collection of agents working together
To solve tasks something like that. So like a larger collective intelligence
in multi-agent rl the way we do this is
agents share rewards and so
This could be sharing stress. This could be
sharing food or or whatever like
So this models the group of agents as a as a larger self
Although like there's also
work like recent work in the last few years that like
If the group of the
Agents grows too big
then performance might degrade or
If these agents fully share their rewards performance might degrade. So is there anything like this where?
Between cells they might not fully share their stress or fully share their rewards, but
there's kind of like a
degree there where where
Maybe I don't want to offload all of my reward, but just part part of my reward. Yeah, you kind of help cooperation. Yeah. Yeah
Yeah, yeah, that's great. And uh, sarah marson who who's an rl expert. I'm not
We're we're writing a paper on on this on this topic. There are there are two
I can think of two examples that are similar to what to what you're saying
one is uh, chris chris fields and I had this this idea a while back for for one of the one of the um
Uh drivers of multicellularity might be that if if you you as a as a simple cell
Want to be able to do some kind of active inference and predict your environment
The most predictable thing out there in a very uncertain environment would be a copy of yourself
So the nice thing to do would be to surround yourself with copies of yourself so that you have some prayer of of
You know having a stable environment and knowing what's coming next at which point what you might want to do is
Addict your neighbors to hang out with you
So you might have these kind of autocrine and paracrine loops where you're secreting some sort of goodies
Maybe opioid, you know natural opioids. Maybe maybe nutrients. Who knows but but you know
You might you might try to share some of this to keep the other cells around and kind of um
I maintain this the other the other aspect of what you just said is seen in gap junctions
The magical thing about gap junctions, which are these connections that allow
molecules to pass directly from the inside of one cell to the other is this under traditional
Uh signaling modes one cell will secrete some kind of chemical
It sort of floats over the other cell has receptors and it feels it
The thing with that is that the other the receiving cell is very clear that this is a signal that came from outside
And then you might ignore it. You might learn from it. You know, whatever, but it came from outside
Gap junctions are different because if something happens so cell a and b are connected with gap junctions
Something happens to cell a it triggers some sort of um, um memory trace
Let's say a calcium spike or something like that that immediately propagates into cell b
What these gap junctions do is they kind of erase the ownership on that data
There's no metadata on the calcium about where it came from calcium is calcium
And so whatever else comes across as a signal of that information or a reward or whatever it is
Is shared equally by the two cells or or not equally because the gap junctions can be regulated, right?
So they get they're tunable. And so what happened what that tends to do is um,
I think what goes on here is that it erases the individual
Identities because if if you're if a and b cannot cleanly maintain their individual memories if they share memories
It's kind of like this this this mind meld because now it's not that I have my own memories
And you have your own memories now
There's just we because it's the same pool of molecules right and it also makes it impossible to defect in a game theory sense
Because because if you're connected and I do something nasty to you
Well, guess why it comes back to me immediately. So so it forces this cooperativity. It forces a kind of um sharing of of
You know of of of of our past that that binds us together. And I think in that sense
Uh, no, no, but you know, I to my knowledge, nobody's actually studied this in detail
But I bet exactly what you're saying that that if we were able to track the reward molecules going through these things
we would find some dynamics that are um kind of
of
Understandable under these various frameworks like rl and other things that you guys study
Well, thanks. Thanks
Hi, um, thank you
I would like to challenge you a bit on the notion of ubiquitous intelligence
So from what I see, I really like the idea that it goes through transcriptomic networks to cell-to-cell interaction network
But it sounds to me like you you ascribe
every complex system that's
Interconnected and that the interaction between these individual agents that if there's an adaptive behavior that is somehow
intelligent
But my question is like, where is the boundary? Let's assume the block of metal is not
Because it's not
Sure
In your framework, I mean the weather might be right because you have interacting things and your interactions as a contact system
And and I just wonder
So in your framework, do you think that
From cell-to-cell interaction gene to gene interaction to neuron to neuron interaction. Is it just a slow continuous scale up?
Uh, uh, basically it's just a time scale that's different
Because we have like these learning rules in the rain, which would like to understand
Do you think the same things hold true for the cells? It's just that it's a different time scale and we eventually get there and I think
Uh, let's say IBM
To develop a brain model that's I don't know is able to solve some problems with intelligence, right? So so
In a sense like chat gbt can solve problems or ai has
improved or become more intelligent because it is able actually to solve certain problems and my question is
In your framework, then you would say if you just wire up a bunch of neurons, uh, artificially
Uh, they are doing something and create some kind of dynamic. That's not intelligent. We're interested in, right?
So so do you think there's a qualitative difference
In our brain is doing your intelligence and how cells are doing intelligence?
Okay, great. Yeah, great great question. So so here's here's what I would say first of all
Um, I I do not believe in intelligence as a binary notion
So I don't think we can say yes. It is no it isn't I think the real question is how much and what kind
So I think there's a continuum and we can talk in a minute about whether there's really there are these kind of great transitions
Or it's really a smooth continuum
And the other thing is that I absolutely agree with you in that
Intelligence cannot be be attributed simply on the basis of complexity or
You know some kind of dynamical system the whole point of some degree of intelligence
And and this is so so I don't know if you can see the slide I put up
But but this is this is what we enter and at all we're trying for is they were giving
Functional criteria for assigning certain kinds of intelligence, which by the way you can only assess in experiment
So if you bring me some kind of extremely complex system
You have to and and and we want to make intelligence claims about it. We have to on my framework
We have to do a couple of things. We have to first of all
Pick a problem space. Okay, then we have to pick
some kind of
Some kind of a goal or problem-solving behavior that we think it's doing and then we have to do experiments to see how much
what what kinds of
Competencies some of them are on this chart here
It can muster to and and then and then we have an empirical answer to you know
If two people have a model one person says I think it's just
You know it's just a hard-wired thing that does the same thing somebody else is why I think it's a Brittenberg vehicle of type
Too somebody else is no I think it has metacognition and it knows what it knows
These are all empirical
Questions we have to do the experiment. I'll give you a very simple example
If you look at a gene regulatory network, right?
So these are just it's a it's a mathematical model that literally just says it has you know
Maybe let's say a dozen genes and each one turns another one on and off
So it's a set of coupled ordinary differential equations for example
So you look at this thing. He's okay. This this the traditional view was that look this is clearly
It's an it's a it's a complex dynamical system, but there's no magic here
It's we can see where all the party, you know, what what it's doing
It's this there's no way this thing's intelligent
And what we said what we said was let's do the experiment and what we found out was that it can actually
