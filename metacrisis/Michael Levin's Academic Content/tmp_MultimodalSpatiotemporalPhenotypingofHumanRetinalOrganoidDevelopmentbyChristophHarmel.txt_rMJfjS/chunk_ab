and I mean this is like highly strongly dependent on the gene energy of the fish and also like
the antibody penalty using for the 4I and our conclusion was that mainly we can resolve
major cell types maybe some sub-cell states with both techniques but you don't reach like
the actual resolution you can come and see the cell in the transcripts.
So it's a huge dataset I actually put an app for that so it's bronzable the interwebs
see this is good just connected but in principle like that's our shiny app where you can
process complete imaging data the complete transcriptomics fish data everything is in
here it's hosted by the EDH so feel free to have a look but this would cost too much time now.
Okay and I mean we have five minutes left so should I keep going for more computation stuff
or do you just want to ask questions and discuss a little bit more.
You can keep going for a bit it's okay.
So yet another analysis we did the systems just not like using laminar windows but rather
like focusing more on like nuclei spatial neighborhoods and I mean in that case I thought
okay like we can actually use the same algorithm but not for windows but for circles and then
like our inner outer accesses from the outside of the circle to the inside of the circle and
in the retinal organ actually there's a deficiency you might say so like the ganglion cells which
normally make connections to the brain neurons at some point that die off like after 12 weeks
they're just like vanishing and we thought like maybe we can like learn something about
the neighborhoods and then I basically did the whole laminate analysis but with a nuclear
radio neighborhoods and we've seen that like there is actually like a heterogeneity for
like these RGC cells in the organoids and actually there are empty use which are like
related to apoptosis so like high mitochondrial content, wrinkled api stains stuff like this
we could observe and then we could go back to the single cell data and do like classical
DE gene analysis for like these two clusters here and then we've seen that like in the
major populations of the RGC like an apoptotic signature was enriched so I mean we couldn't
solve the riddle why these are dying off but we can definitely say like by 12 they die
however like these assumptions we make here that is like not actually meeting the stuff
we observe in the tissue right like if you have a circle and then like the averaging
average in the signal like it would assume that you have like kind of like an isotropic
information in the neighborhood but I mean we now all know like tissues can be messy
that's most often not the case so most likely like this method is just like as good as just
averaging the signal in the neighborhood and like these laminar windows in general they
are like highly specific I mean this is really good nice to use it I mean you could also
maybe use it in like brain slices where if there's different regions or something but
it's not in general applicable to the whole thing or any other biological system so what
I now work on is working more with like K&N graphs so like in a tissue you would have like
a segmented nuclei you give like a certain distance threshold and with these graph structures
and then what people nowadays most often just you would do is like they take the information
they get from the nuclei and in order to bring in like spatial information they would average
over neighborhoods or they would do something called message passing in graphs so what this
comes down to in the end is just like taking like in this K&N graphs you can represent them
as a adjacency matrix like for each connection there's a one in the matrix and then in order
to like summarize over neighborhoods they would just do the dot product of the feature matrix
of the adjacency matrix but I mean this approach of who is better than just like castering the
look at themselves but it's missing information in between the cells because it's just like
restricted to the thing itself so what I thought okay why not we just like place the laminar
windows on these edges and average over these taking this information and build up like a
weighted adjacency matrix where we like actually populate the adjacency matrix in the middle
here with the nuclei feature and then the sites we populate with information we gain from
the space in between and then perform this graph passing message passing process on these
and this actually work pretty nicely so I'm just just like an example from 13 organs just
after the submission and maybe like three month old by now I like it because it's like really robust
you can like really see that it's like resolving different layers here in the data that I was
I'm pretty happy and now I try to like really make this computationally efficient for big data sets
so like billions of cells and applied in our latest project we were on tumor data in PDEC
and another thought I had was like okay this still is just like observing tiny tiny neighborhoods
like one hop in the like yeah what about like long range interactions how would I capture
like morphogen gradients and tissues like this and here I thought like okay this data representation
might actually be useful because I mean you can imagine that like we can build paths in these
networks and each path will be described by the laminated laminated windows and we just
concatenate them and then we just have like the same data structure and the same dimensionality
reductions we did before and and this is also just like proof of principle so what you can
then do is like asking like in this KNN graph okay I want to find a structure I want to have
restrictions on my structure so I say like I want to look for a path which has like setup A
linked to setup B then B is like linked to another setup C and and so on so forth so like
you can like make a query and then it goes through the whole graph structure and finds
like motives or in this case just paths which satisfy this stuff so that's what I did here
so I wrote a tiny tiny query and it found me like these two neighborhoods here and then
if you go ahead and just like do all the distance speculations as we did before for the laminated
windows you can see that like a motive versus background which is orange here and the distances
are significantly higher compared to the background motive where I just like take random paths
the tissue and calculate all the distances and like the motive versus itself so that's already
like pretty promising that this could be applied like if you have already like a biological
question in mind and can like cluster your tissue biological meaningful then you can basically
just look for structures I mean and you could also think about this for the graph conclusion
networks running this denoval but that's where I am at now exactly and just to the end
knowledge months to a great camp our trial time and the postdocs involved in this project
and Lucas Parkman, Slap and Zurich who basically taught us like how to do the old
iterative most chemistry stuff and yeah Roche, our group, University of Basel and the band
EtH, yes that's it.
So this is phenomenally cool we do a lot of things not necessarily at the genetic level
but at the physiological level so we you know Pumam is one of the neomeric potentials one of
the big things we care about but also other physiological indicators and so I'm wondering
how hard would it be to port this from genes over to sort of something else like if you're placing
genes in space with V-mime over time or calcium over time?
Yeah I guess it's pretty easy like as soon as you have like a metric representation of your data
like images and it's just a matrix but and yeah and you might have like multi-dimensional
measurements and there's a big approach from.
Great. The problem with this analysis is this is a fixed data constant data.
The V-mime is a time dimension data.
Yeah I mean that would be a problem.
Yeah then it's like adding one dimension more and like the distance calculations and everything
would get more complicated I guess.
Right but also as opposed to having you know 500 genes if we have like five so we probably can
find physiological things over time.
In terms of computational stuff I would guess it's probably equipment simple.
Can you besides your use one of the things that we always struggle with sort of how much is
enough biological data right so you're always like I want more samples more genes.
Can this work in the opposite? Did you do things like drop out individual signals and see like
what's the minimum amount that you need to get right so yeah if we cut our samples down
our number of genes by half we still get 90% even if we think about that might be good for us
for just speed and optimization.
Yeah yeah I mean we haven't done this in this project but in principle we did some of this.
I mean for the like the gene panel design for the fish for example there's like I forgot the
name of the package but it's like there are ways to like really like brute force this
and come up with a like nice panel where you just don't need to test like everything
in the forward just like that's your prediction that's a good panel.
And also I mean we did some stuff where we just like dropped out certain proteins and see how
the whole thing would be changing for sure.
But I mean in the end like it really comes to prior biological knowledge I would say.
I mean in the future it would be very cool just like having like a system like phenotype like this
and then just like go in and say like I want to do this experiment like give me the perfect set of
you know.
The whole thing is variability how many like repeats you need to do so to make sure that
that's actually what you've seen is not just random so you see that it's like robust.
In which regard?
Ah like if you, so many organoes how many repeats you do for each?
I guess in this study it was like 40 organoes.
I mean we have like three replicates per organoid itself in slices.
And I mean that was pretty obvious that it's like highly reproducible.
Like I mean if you wanted you could just like register the images on top of each other
or most perfectly fit because I mean they cut super thin slices like micro.
But from organo to another organo.
