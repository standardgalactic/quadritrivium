Hi guys, my name is Christoph Harle, I'm a PhD student from Switzerland doing computational
biology and right now I'm in the big game of my PhD so like fourth year and I'm going
to tell you something about a multi-mode of spatial temporal phenotyping of human retinal
organoid development so like a lot of punchlines in here like buzzwords and I'm from the group
of Great Camp and there are also like a developmental biology group doing also a lot of
computational biology and we just like two years ago we moved to the Institute of Human
Biology which is a Roche founded institute which is like focusing on developing organoid
systems and like bringing organoids to the point where they can actually be used to farm
for like safety testing, model improvements, drug screens and stuff like this and yeah
today I mainly focus on this paper we published like almost a year ago by now and if I have
time later on I will also like show what I've been doing since then like on the computational
sites like the tools I developed for this stuff here how I like improved it and applied it
to some other data systems but let's see how we go time wise. So maybe just for starters
like a tiny introduction to organoids so what are organoids? So in principle like organoids
allow you like to either from like tissue derived cells or there's like inducible prune
stem cells, take them, seed them in a culture, in a 3D environment like most of them like
using a matrix for example and applying like the right morphogen compositions and chemical
stuff and adding some time then in the end like you have like a self-emergent system
which is like really recapitulating phenotypes of the actual real tissue you derive from
or like you use like certain morphogen to push it into a certain fate of a tissue and
for example here this would just like be a cartoon of a intestinal organoids where you
have like the crypts and the gut and I mean this we basically did for the eye so let's
hear the disclaimer and in addition to this, okay, in addition to this like what we are
aiming to do is like really from the multi-omics perspective look at such developing systems.
So what we are doing mainly in our lab is like we do a lot of single cell sequencing on RNA,
also attack and multi-oomplator and also a lot of multiplex imaging. So mainly in
unistochemistry data sets where we can like reach flexibility of like 60 antibodies or even up to 100
antibodies on every piece. And my main task here was then like to bring like such data sets where
you like have a temporal component and this like multimodal component but from different
experiments together in like one representation so like working on like digital multi-omic
representations of components. So the whole like reaching this like endpoint of multimodal
special temporal integration. So in the case of the retina what we are doing is we take
MIPCCs and then grow them into retinal organoids and keep them in culture over time
course from over 39 weeks so it's pretty long time so congrats to like the retina people there.
So like I have to maybe like quickly notify like I didn't do like any retina myself so like
there were like two postdocs being involved in this like one guy just like optimizing the
whole imaging and sample handling and that was Philip Bali and Giovanna Barcati who did
like all the sequencing which I will be presenting here. And another postdoc she's on Hay who also
had with the computational hotel who was more focused on the single cell data and I was more
focused on the imaging data. But here what you can see like our approach is like we grow these
organoids and we also have like primary tissue sections and then we place them on a 96 wells
structure and then we do this like reiterative round of staining so like we always put three
antibodies on top, we also dabby staining, image the thing, elude, repeat, rinse and repeat
over like a month. And then we come up with this like very beautiful data set where we
really go from like kind of really like millimeter scale to nanometer scale with 40x confocal
imaging with like oil and everything is like really really nice imaging quality and already
like just from the protein stains you can see that like the structure you would normally see
in an eye like having like cones and rods on the outside having the muller glee or the retina
ganglion cells, americant cells, bipolar cells, you all have them like nicely spatially
organized in the same way as you would have them in the adult retina for example. So this
is the primary tissue here and that's a slice from one of our organoids. So in total like
in this data set I guess we had like 45 stains and up to like 30 or so organoid slices so
rather big data set actually. And now just like an overview here like it's a lot of data
so like you cannot really grasp like the all the images and just like making sense of just
creating overlays that's overwhelming to many mutations in there. So what we came up with
is that we perform a multiplex tissue humans analysis and this is kind of like informed
or like inspired by what we do in senus RNA sequencing where like you would have like one cell
in this case it's just a pixel and then like on this like n-dimensional space of features
in this case the protein states in senus RNA it would be like the transcriptome you perform
a clustering, unsupervised clustering. And that's what you see here. So like each color
here would correspond to like one pixel cluster and then if we then like put these colored
pixels regarding for the clusters back into the image we come up with such representations
where we actually get like biological meaningful clustering of the system. So you would have
an MTU which is marking molecular nuclei, one MTU which is marking immigrant cells. You
do see like collagen deposits in the system. You see cones and rods and stuff like this
and the cool thing here is that I mean we have like the complete time course of data right.
Like we have we can actually see like this laminated structure of the retina forming up
over the time course. So like here we start from six weeks it's like a little bit disorganized
and then around like 18 weeks you already start getting a sense of the lamination here over
24 weeks to the final endpoint in our data set which was like 39 weeks. And this data
point is then like super close to the actual like primary system. But I mean after all this
is like just like it's not quantitatively looking at the data it's just like getting it
into another representation and like making sense of it from your like biological knowledge
you have right. But what we actually wanted to do is like really put numbers onto like
the developmental state of the system from week six to week 39. And how we actually did
this is like we thought like okay we have this very stereotypic spatial organization
on the outer layer of the organoids which is corresponding to the privatization that we see.
So and what we're doing now is like that's mainly my part here that I developed this algorithm
called Laminator because we laminated stuff and we on the outline of the organoids we basically
just place rectangles oriented to the center of the organoid. And then we read like along
this axis like the inner outer axis of the laminar windows we read out the intensity
profiles from all the proteins gets together. And from this information then we are able
to reconstruct super time trajectories like falling back to like and diffusion map algorithms
for example. And this allows us then to like reconstruct a trajectory which reflects the
development of the system. And then you can like just show it by making collages of these
MPU images for like different time points for example where you can see like it's nicely
ordered and those structures make sense. Or like having the complete overview by like
creating heat maps over this trajectory and then looking at either MPUs or just like
nuclei states for example like here the first state for the nuclei that's like in the beginning
it's very disorganized and over time it's like really forming this double layer like the
inner and outer place. And then like if you put numbers on this then you can say like
okay we can come up with a maturation score and we show that the later time points of the
organoids are actually like becoming closer in their composition of the laminar structure
with the primary tissue which are like here the red dots.
So PT or not X-axis is time or?
Yeah 2 to time.
Good.
Yeah so like just like ordering and finding a path through the diffusion space and then
ordering the points in there. It's mainly just like yeah that's like the embedding for
the diffusion maps and then you see like the 2 to time which you calculate in this
label.to. This is here now like just like zooming into the algorithm I mean mainly what
you get is like from all these laminar windows you come up with like for each
protein state like you have like this, you can say like a time signal but I mean it's
in space but like just like that and then I mean I do some like processing like I
eat a down sample I smooth the signals and then as you can imagine like in the
case if you want to do this like globally in the complete data set it's becoming big
because in the end what you want to come up with is like a one dense distance matrix
and this is computational intensive so what I found like that like comparing these
signals in n dimensional space it's not very effective if you do it with cross correlation
but rather just like first transforming it into Fourier space and then Fourier space
with receding distances and then use these distance matrices to then run the diffusion
map algorithm for example and then I mean in this space you can also like answer
like twice clustering and I mean this already helps you just like because organoids
can be messy they can be like there's the variability is high so we can already use
this algorithm to like just like assess that which regions of the organoids
should be interesting for us to compare to the primary tissue.
Yeah it is it is but just like computation really it's it's big up because like the Fourier
transform it was like in Python's limit you can see and it was just convenient to use.
Now bringing in like CMOS data so she sang and did this whole...
Before you go on I just want to make sure I understand what you've done so what you're doing
is a slight cross-section of your organoid and then you're looking at the intensive
profiles of the different channels, different stains that you have and then you're quantifying
that and seeing how that changes spatially across that section and that will tell you
whether your organoid is at its final destination.
Exactly, exactly.
There's this diffusion thing that you kind of asked me about.
The diffusion maps it's called it's a dimension reduction method but it's like
comparison to PCA it's non-linear so like yeah you're trying to find an embedding due to like
diffusion processes which describes your data that's not linear but okay cool.
Okay so and next step here would then be like that we have like integrated atlas or
fraternal organoids but from the transcriptomic side so we have like attack data in there
and we have RNA-seq data in there for the complete time course and I mean there like
just from the cell stains you can also construct trajectories that like from the
progenitor cells here like these develop a tumular glia, anion cells,
americans cells, B-polar cells like all the cell types I've already shown you can also see
in the transcriptomic space.
Funnily like the human projection of the whole thing is a dog so I don't know what this
is about vision but so that was now like the data set we wanted to combine with our
spatial data set and sorry and like also like from the attack data here of course
you can like reconstruct gene regulatory networks and then also show like which
gene programs for which cell type are active which certain vectors are there like
getting like a very complete picture of the system.
And now like coming to the actual integration so like our idea was like to use RNA as our
anchor data set because I mean for each protein we pretty much know like which RNA transcript
would be responsible for its production and the attack can be mapped to the RNA because
like you have like certain gene regions you know the gene body corresponds to a certain
transcript so like that's the linkage like the RNA is our perfect point where we can
do like our data integration.
And then for the actual integration we just used like SORRA like a standard processing
pipeline in the single cell world where you mainly like by overlapping features like for
the protein at the RNA you do some KNN graphs and then you by finding mutual neighbors you
can just like transfer our labels over.
But I mean this worked pretty pretty good in our case so like for each time point of our
organized data we put label transfer first like the cell type labels and then also like
bringing over the complete transcript by just like if you apply super high resolution clustering
in the RNA space and then you transfer these labels and then you can just like take the
average expression for each gene in these higher resolution metaclusters and visualize them
then back into the statistics like then you can see that like for certain key regulators
like transcription factors of the retina they like perfectly nicely in the right layer of
the organoid you can see that like the cell type composition of the whole thing is making
sense so we are pretty happy with that.
However some more stuff yeah sorry and so like now I mean I told you that we had all these
windows right and now we also know like the position of each nuclei in each of these windows
so we can actually now like visualize like our map transcriptome or like attacks peaks
or just the cell types in this pseudo temporal space and then you can see that like certain
steps at the beginning are just like everywhere and narrowing down or just like I'm not present
anymore finding the right place in the light in the layers stuff like this so like now we
have like really integrated data set which we can also like analyze in this trajectory
basically.
So and I mean up to then here this was like our first submission and then the reviewers
were like yeah but you make an assumption like RNA and protein and it's not always the same
so for this we went back then and sent some tissue slides to a company called
or what the name but they were doing like basically Merfish's service so we collected
some organoid slices on fresh frozen tissue performed multiplexed fish and then my quest
was like okay now we have to bring like yet another data set into the whole integrated
thing so how we did this is actually we again like we used these like windows again as our
like reference coordinate system where we say okay like first of all I can basically do
the same analysis as I did for the 4I data and then ask which profiles I observe in the
myoscope the transcript stuff is like referring to the predicted RNA profiles I've seen before
and then match these and I mean this is then like what you can see here like I mean in the
fish data we had two time points week 13 and week 32 and week 32 was like most closely
related to week 24 and a little bit better less to week 39 and the week 13 was close to
the week 12 and the fish data so that was already pretty promising then I mean for some
for some key regulators and then you can just like look at these profiles along the window
and see that fish and the 4I these are like very much nicely correlated and then the next
step is that you can actually show that the 4I and the fish integrate as good with the
actual single cell RNA-seq data by basically then in these windows doing like nuclei
matching so like you find like the best two matching windows and then you say like okay
I have a nuclear nucleus from 4I here it's in the upper region okay so like good partners
for this also nuclei in the upper region of fish data you match these and then you just
like do correlation and then you can see that like for transcripts which are high expressed
like the predictions were pretty well for transcripts which are actually low expressed
it's not very good but I mean this is also like if you just integrate the fish data with
the RNA-seq data there like the predictions are also not good if you have like low transcript
counts basically you have a lot of noise and your predictability is just like going down
and in the end we just ask okay like how nicely can each of these datasets like the fish or
the 4I resolve the actual single cell RNA-seq data by just like clustering the single cell
RNA-seq in higher and higher resolution and then letting like the matched nucleus saying
okay like can they still distinguish like this resolution of clustering and the RNA-seq
data and then we've seen that like both the 4I and the fish data perform similarly well
and I mean this is like highly strongly dependent on the gene energy of the fish and also like
the antibody penalty using for the 4I and our conclusion was that mainly we can resolve
major cell types maybe some sub-cell states with both techniques but you don't reach like
the actual resolution you can come and see the cell in the transcripts.
So it's a huge dataset I actually put an app for that so it's bronzable the interwebs
see this is good just connected but in principle like that's our shiny app where you can
process complete imaging data the complete transcriptomics fish data everything is in
here it's hosted by the EDH so feel free to have a look but this would cost too much time now.
Okay and I mean we have five minutes left so should I keep going for more computation stuff
or do you just want to ask questions and discuss a little bit more.
You can keep going for a bit it's okay.
So yet another analysis we did the systems just not like using laminar windows but rather
like focusing more on like nuclei spatial neighborhoods and I mean in that case I thought
okay like we can actually use the same algorithm but not for windows but for circles and then
like our inner outer accesses from the outside of the circle to the inside of the circle and
in the retinal organ actually there's a deficiency you might say so like the ganglion cells which
normally make connections to the brain neurons at some point that die off like after 12 weeks
they're just like vanishing and we thought like maybe we can like learn something about
the neighborhoods and then I basically did the whole laminate analysis but with a nuclear
radio neighborhoods and we've seen that like there is actually like a heterogeneity for
like these RGC cells in the organoids and actually there are empty use which are like
related to apoptosis so like high mitochondrial content, wrinkled api stains stuff like this
we could observe and then we could go back to the single cell data and do like classical
DE gene analysis for like these two clusters here and then we've seen that like in the
major populations of the RGC like an apoptotic signature was enriched so I mean we couldn't
solve the riddle why these are dying off but we can definitely say like by 12 they die
however like these assumptions we make here that is like not actually meeting the stuff
we observe in the tissue right like if you have a circle and then like the averaging
average in the signal like it would assume that you have like kind of like an isotropic
information in the neighborhood but I mean we now all know like tissues can be messy
that's most often not the case so most likely like this method is just like as good as just
averaging the signal in the neighborhood and like these laminar windows in general they
are like highly specific I mean this is really good nice to use it I mean you could also
maybe use it in like brain slices where if there's different regions or something but
it's not in general applicable to the whole thing or any other biological system so what
I now work on is working more with like K&N graphs so like in a tissue you would have like
a segmented nuclei you give like a certain distance threshold and with these graph structures
and then what people nowadays most often just you would do is like they take the information
they get from the nuclei and in order to bring in like spatial information they would average
over neighborhoods or they would do something called message passing in graphs so what this
comes down to in the end is just like taking like in this K&N graphs you can represent them
as a adjacency matrix like for each connection there's a one in the matrix and then in order
to like summarize over neighborhoods they would just do the dot product of the feature matrix
of the adjacency matrix but I mean this approach of who is better than just like castering the
look at themselves but it's missing information in between the cells because it's just like
restricted to the thing itself so what I thought okay why not we just like place the laminar
windows on these edges and average over these taking this information and build up like a
weighted adjacency matrix where we like actually populate the adjacency matrix in the middle
here with the nuclei feature and then the sites we populate with information we gain from
the space in between and then perform this graph passing message passing process on these
and this actually work pretty nicely so I'm just just like an example from 13 organs just
after the submission and maybe like three month old by now I like it because it's like really robust
you can like really see that it's like resolving different layers here in the data that I was
I'm pretty happy and now I try to like really make this computationally efficient for big data sets
so like billions of cells and applied in our latest project we were on tumor data in PDEC
and another thought I had was like okay this still is just like observing tiny tiny neighborhoods
like one hop in the like yeah what about like long range interactions how would I capture
like morphogen gradients and tissues like this and here I thought like okay this data representation
might actually be useful because I mean you can imagine that like we can build paths in these
networks and each path will be described by the laminated laminated windows and we just
concatenate them and then we just have like the same data structure and the same dimensionality
reductions we did before and and this is also just like proof of principle so what you can
then do is like asking like in this KNN graph okay I want to find a structure I want to have
restrictions on my structure so I say like I want to look for a path which has like setup A
linked to setup B then B is like linked to another setup C and and so on so forth so like
you can like make a query and then it goes through the whole graph structure and finds
like motives or in this case just paths which satisfy this stuff so that's what I did here
so I wrote a tiny tiny query and it found me like these two neighborhoods here and then
if you go ahead and just like do all the distance speculations as we did before for the laminated
windows you can see that like a motive versus background which is orange here and the distances
are significantly higher compared to the background motive where I just like take random paths
the tissue and calculate all the distances and like the motive versus itself so that's already
like pretty promising that this could be applied like if you have already like a biological
question in mind and can like cluster your tissue biological meaningful then you can basically
just look for structures I mean and you could also think about this for the graph conclusion
networks running this denoval but that's where I am at now exactly and just to the end
knowledge months to a great camp our trial time and the postdocs involved in this project
and Lucas Parkman, Slap and Zurich who basically taught us like how to do the old
iterative most chemistry stuff and yeah Roche, our group, University of Basel and the band
EtH, yes that's it.
So this is phenomenally cool we do a lot of things not necessarily at the genetic level
but at the physiological level so we you know Pumam is one of the neomeric potentials one of
the big things we care about but also other physiological indicators and so I'm wondering
how hard would it be to port this from genes over to sort of something else like if you're placing
genes in space with V-mime over time or calcium over time?
Yeah I guess it's pretty easy like as soon as you have like a metric representation of your data
like images and it's just a matrix but and yeah and you might have like multi-dimensional
measurements and there's a big approach from.
Great. The problem with this analysis is this is a fixed data constant data.
The V-mime is a time dimension data.
Yeah I mean that would be a problem.
Yeah then it's like adding one dimension more and like the distance calculations and everything
would get more complicated I guess.
Right but also as opposed to having you know 500 genes if we have like five so we probably can
find physiological things over time.
In terms of computational stuff I would guess it's probably equipment simple.
Can you besides your use one of the things that we always struggle with sort of how much is
enough biological data right so you're always like I want more samples more genes.
Can this work in the opposite? Did you do things like drop out individual signals and see like
what's the minimum amount that you need to get right so yeah if we cut our samples down
our number of genes by half we still get 90% even if we think about that might be good for us
for just speed and optimization.
Yeah yeah I mean we haven't done this in this project but in principle we did some of this.
I mean for the like the gene panel design for the fish for example there's like I forgot the
name of the package but it's like there are ways to like really like brute force this
and come up with a like nice panel where you just don't need to test like everything
in the forward just like that's your prediction that's a good panel.
And also I mean we did some stuff where we just like dropped out certain proteins and see how
the whole thing would be changing for sure.
But I mean in the end like it really comes to prior biological knowledge I would say.
I mean in the future it would be very cool just like having like a system like phenotype like this
and then just like go in and say like I want to do this experiment like give me the perfect set of
you know.
The whole thing is variability how many like repeats you need to do so to make sure that
that's actually what you've seen is not just random so you see that it's like robust.
In which regard?
Ah like if you, so many organoes how many repeats you do for each?
I guess in this study it was like 40 organoes.
I mean we have like three replicates per organoid itself in slices.
And I mean that was pretty obvious that it's like highly reproducible.
Like I mean if you wanted you could just like register the images on top of each other
or most perfectly fit because I mean they cut super thin slices like micro.
But from organo to another organo.
