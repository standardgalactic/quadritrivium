to be able to talk to you. Thank you very much for inviting me. And I'm going to basically
tell the same story that Anil and Kevin told yesterday, but using the language of physics
in the first half and neuroscience in the second half. And I should apologize for this
because it's going to be my basic talk or starting from first principles. My hope is
many of the ideas that I heard you discussing yesterday are fully licensed and endorsed by this
rather elemental or basic approach as seen through the lens of a physicist. Furthermore,
the reason that I and my colleagues committed this kind of explanation is if you understand
the underlying mechanics and the physics of what's going on, it allows you to simulate things.
So I'm justifying some of the technical details in this talk on the basis that if you can actually
write down the kinds of processes and phenomena of interest, then you're now in a position to
simulate and provide proof of principle. And my hope is that at some point, the agenda,
the fascinating and challenging agenda that your group is applying itself to may succumb to this
kind of modeling and proof of principle. But I think that's going to be for you to decide.
So this talk is going to be breathless because I have to complete it within 45 minutes.
We're going to cover the statistics of life with a special focus on Markov blankets and how they
induce an interpretation of self-organization in terms of inference and a very basal kind of
belief updating, namely Bayesian belief updating. And then we're going to move on to a rehearsal
of exactly the same story, but from the point of view of neurobiology in terms of predictive coding
and how they play out on neuronal networks. And then if we have time, I want to just speak to the
core notion of selfhood and argue that that may be intimately related to agency.
And then ask, well, where does agency emerge from the formulation that I will have established
in the first two bits of the talk. So I'm going to start with a question posed by
spreading that how can events in space and time, which take place within the spatial boundary
of a living organism, be accounted for by physics and chemistry? Clearly, I'm not going to address
that question. But what I want to do is just pick out this notion of a spatial boundary and
note that in order to talk about anything, a particle or a person or a priest,
you have to be able to distinguish or separate or individuate that thing from everything else
in virtue of it possessing a boundary. And spreading it would be the first to acknowledge
that that boundary is in itself a statistical object. And I'm going to read that boundary
as something called a Markov blanket. So for those of you who don't know what a Markov blanket is,
imagine some little universe. And these are the states of the universe. And these states influence
each other. And these influences are denoted by these areas or edges. And imagine we take some
states, say my states, my internal states. So the Markov blanket is effectively a set of states
that constitute the or constituted by the parents, the children, and the parents of the children,
as defined by this causal coupling. And in brief, the role that the Markov blanket plays
is that it provides all the information that I would need about the universe
to predict how I am going to change or evolve next. Technically, conditioned upon these states here,
the blanket states here, the internal states are conditionally independent of the external states.
And I'm going to make a further move here. I'm going to divide these blanket states
into sensory states and active states, where the sensory states influence but are not influenced
by the internal states, the active states influence but are not influenced by the external states.
And I motivate this particular partition in a moment. I use the word particular partition
deliberately because in effect, we've just described a particle or something more generally
with particular states that constitute or are constituted by the blanket states,
known as sensory and active states, and the internal states. And this partition
universal, in the sense you can see it wherever you look. So here are two of our favorite things.
At the top, there's a brain and the bottom a single cell. We can imagine the internal states,
the brain, everything I need to write down to identify the current state of my brain,
its activity, its connectivity, the internal states, the brain will influence my autonomic
system, my active states, my actuators, which in turn change the external states,
but then couple back to the sensory states, my sensory epithelia,
but then influence my internal states. And so the cycle continues. And exactly the same
partition or sparse coupling can be found say in a single cell with intracellular states
constituting the internal states that influence say the active filaments that support the cell
surface that is pushed into the external states and the external milieu reciprocates by changing
say cell surface receptors that change the intracellular states. And again, establishing this
circular causality that I've read in terms of an action perception cycle in relation to the brain.
So that's the basic setup. What I want to do now is to do a very brief course in physics
and then ask what would happen if we put the Markov blanket back into play.
So I want to start with the basis of nearly all physics that we know, articulated here
classically as a Laungevan equation or a stochastic differential equation. I use the
descriptions to cast it deliberately because yesterday I noticed in the chat, Dennis was
asking about fluctuations, random fluctuations, a kind of itinerance
that is characteristic of biotic self-organization. And those fluctuations are central to this
argument that are noted by omega here. And all we're doing here is just writing down a universe
in which the rate of change of any states of this universe is determined by some flow,
which is a function of where I am, plus these itinerant or random fluctuations. I just
sketched out two states here. So this could be an oscillation in one cell of my brain.
It could be my heartbeat, or it could be me getting up in the morning, doing my emails,
having lunch, watching television, and so on. At any temporal scale, the kind of systems that we
are interested in show this characteristic property that they have characteristic states,
which they keep on revisiting. You can describe this in terms of, in random dynamical systems,
a pullback attractor. You can articulate this in terms of physics, in terms of non-equilibrium
steady state. The key thing is to be something is to have characteristic states that I return to,
or at least the neighborhood of. And thought of like that, we can now read this object as
the probability that you'll find me in any particular state if you sample me at any random
time. And that's important. It's important because we know a lot about the maths of the
relationship between the dynamics, the flow, the amplitude of the random fluctuations,
and this description of the state system in terms of its characteristic states or its pullback
attractor. Don't worry about the equations. I'll just pick out what we need to know. This is a
very generic equation known as the master equation in some contexts, the Schrodinger wave equation,
or the Fokker Planck equation, more simply just a description of how this probability density
changes with time as a function of the amplitude of the random fluctuations, gamma, and the flows
here. But we just said it doesn't change with time because I exist. So to use Kevin's notion of
persistence, I persist in time. So we know that this probability density doesn't change in time,
which affords this solution here known as the Helmholtz decomposition. It may sound very arbitrary,
but this is absolutely fundamental and I repeat underwrites most of physics that we know from
Tascall to quantum. The key thing I want to look at though is that it describes what's known as
a gradient flow on the log of this probability. In other words, in order to counter the random
fluctuations, I have to be flowing towards my characteristic states in order to stop the probability
density changing. And that's the key behavior that I want to pursue for the rest of the talk.
So at this point, let's put the Markov Planck back in play and write down that gradient flow in
terms of the amplitude of the random fluctuations, these things denote circular or solenoidal flows
that give this kind of itinerancy and life cycles and oscillations. And what the Markov Planck tells
you is that it is subject to the same law and it means that the internal states and the active
states will look as if they're trying to increase the log probability of, in this instance, the
sensory part of the Markov Plancket. And I'm going to interpret that in terms of perception
and action respectively and just ask the question, how would I then interpret this quantity here?
Well, we've just said that the states that I'm most likely to occupy are those that are
characteristic of me. They are literally the states that constitute my attracting set to which I am
attracting. So they are valuable for me. They have meaning for me, denoted by M here.
So one could read this log probability just as value and one could spin off reinforcement learning
if you're an engineer, optimal control theory, if you're an economist, expected utility theory.
If you're a free energy theorist, the negative variational free energy is just a way of writing
down this valued function. If I just multiply this by minus one, we have a complementary
perspective that people in information theory will recognize. So this is now known as this
negative log probability that I'm now looking as if I'm trying to minimize is known as self-information,
information theory, or more simply, surprise or surprise. It's just a measure of the implausibility
that I would sense this given I am me. And this is the quantity that is bounded by the free energy
leading to things like the informats principle, principle of minimum redundancy, and indeed
the free energy principle. This is nice because the average of this thing is known as entropy.
So the expected free energy or self-information is entropy. So it'll look as if I'm trying to
resist the second law by minimizing the dispersion or the entropy of my sensed states. And of course,
that's the holy grail of self-organization in physics and synergetics and the kind described by
Herman Haken. And indeed, if I was a physiologist, it would just be a statement of homeostasis. And
I have to exist. I just have to keep my sensed physiological states within some viable
bounds that are existentially consistent and have meaning for me because they are characteristic
states that I occupy. The final interpretation, which is the one I want to pursue, is that which
would be given by a statistician. A statistician would read this not as the probability of some
states given me, but me as a model of how my states were generated. This is known as model
evidence, also known as the marginal likelihood having marginalized out all the external states
that cause my sensations. And therefore, perception and action will look as if it is trying to
accumulate or increase model evidence. And then we can read off things like the Bayesian brain,
evidence accumulation, and indeed predictive coding. So I just want to illustrate now and
try and demystify that last interpretation with a worked example, just to work towards something
which I think may be very, which may be a useful mathematical image of a system that is sort of
self-caring and I'll motivate this using the simulation in the following way. What we've done
here is simulate a lot of little macromolecules with strong repulsion and weak electrochemical
attraction. And their very existence in some metric space means that their coupling is sparse
in that each molecule cannot see molecules a long way away. So because we've written down
the dynamics here, we know the coupling, we can go into this synthetic soup and identify some
internal states on their Markov blanket. In essence, what we're doing is we're asking the question,
is there a little particle or thing living in this soup that is identifiable as something
in virtue of the fact that it has a Markov blanket? And indeed there is in this synthetic soup.
Here the internal states are coded in blue, surrounded by the active states, say the active
filaments, if this was a little viral cell-like structure, that underlie the sensory of the
surface states that protrude into the external states in cyan here. So now we have a simulation
in silico little thing living at non-equilibrium steady state that we've identified because it's
got its Markov blanket. The question is, what does it mean for it to be self-evidencing in the sense
that it has to, on average, increase its Bayesian model evidence or the evidence for its models
of what's causing its sensory inputs? The answer is subtle, simple, and I think very interesting,
simply because of this conditional independence that exists between the internal states
and the external states. It means for any given internal state there must exist a probability
distribution over the external states given the sensory states or the blanket states more generally.
So what that means is there's a lawful relationship, a manifold or a function relating
my internal states to the probability distribution over my external states. And if I read that
conditional distribution as a Bayesian belief, what that means is that these internal states,
in some sense, hold or represent beliefs about the external states. And we can actually go in and
just look at the nature of these beliefs and what I've done here is articulate them in terms of
something called a synchronization manifold where all I've done is just plot some mixture of internal
states along the x-axis and the probability distribution or beliefs about the external
states and the actual external states in terms of their mean on the y-axis to show this synchronization
manifold here, this lawful mapping that just has to exist because there is this Markov blanket,
this separation between the thing and everything else. And in this example what we're doing is
asking the question, can we numerically demonstrate that the internal states hold
Bayesian beliefs about the fluctuations and the flow of patterns in the external states? And indeed
they do. Here are the estimated or the beliefs that are held, Bayesian beliefs that are held by
the internal states and the actual external states show that they lie within the 90% Bayesian
credibility bills. And these look very much like what you'd see in electrophysiology if you just
look at fluctuations of the internal states in response to certain events in the external states
when these molecules leave their little soup and they're pulled back in again here. The point I want
to make with this demonstration is not only that there always exists an interpretation of
self-organized or self-evidencing systems endowed with the Markov blanket in terms of
elite or having a process that looks as if they are tracking the states of the world
generating their sensations. But more generally, this is just a description which I'm sure a lot
of you will be very familiar with of self-organization that can be described in terms of generalized
synchrony or synchronization of chaos. Exactly the thought first noted by Huygens in terms of
clocks that are suspended from the same beam or wall will ultimately come to synchronize
and oscillate in tandem in a synchronous fashion. That's all that's happening here and indeed this
little drawing by Huygens illustrates that from the perspective of the particular partitioning
internal active sensory and external states where the blanket states constitute the beam
that's coupling the two penduli here. So from our point of view all we're seeing here is an inside
out to use Anil's phrase view of a completely symmetrical synchronization of chaos or generalized
synchrony between two sets of states. I've never said this before but what I will say to you I was
just wondering whether now if we replace the external states with something else like me
we now have a mathematical image of the synchrony that characterizes a
dynamic interaction between two people and you can imagine this being many people or many cells
an ensemble of similar kinds of things that are constituted by their Markov blankets
but have some isomorphism in their form will in minimizing their joint free energy necessarily
show this kind of generalized synchrony in this harmony that can always be read as one
particle or person holding the right kind of beliefs about another kind of person having a
mutual understanding and implicitly a mutual predictability a shared narrative in the sense
that all of this can be described in terms of increasing the evidence for my models my narrative
my explanation of what's causing my sensations and of course 99 percent of the time it is you
that is causing my sensations and vice versa. So that's the physics part just to briefly summarize
the existence of a particle implies a partition of systemic states as states of any given system
into internal blanket namely sensory and active and external states that are hidden behind the
Markov blanket from the point of view of the internal states and because active states change
but are not changed by external states they reduce or will on average look as if they are
reducing the entropy of blanket states and effectively this means that action the active
states will appear to maintain the structural and functional integrity of the blanket a very
simple form or basal form of self-assembly and one could argue a very simple form of water
peresis. Internal states appear to infer the hidden causes of sensory states by increasing
basal model evidence and actively influence those causes and in my world we refer to that as active
influence just to highlight the crucial role of actively engaging and establishing and selecting
the right kind of data that is necessary to establish this kind of shared dynamic or synchronization.
I'm going to end now by rehearsing exactly the same story but using language much more
akin to what the first half of Kevin's talk and the second half of Anil's talk yesterday.
So this is the perspective that a psychologist or a neurobiologist might bring to the table
on exactly the same phenomenon and this usually starts with the notion of the brain as a fantastic
organ generating fantasies or hypotheses explanations on the inside that then are thought
to sensory impressions to see whether they are apt to explain what's going on and if they match
that's fine if they don't then you get some kind of Bayesian belief updating. I find this very nicely
demonstrated by this 16th century oil painter fame for doing still lives that when viewed
from a different direction and give you a very different impression oops I got them the wrong
way around so you're meant to see the the bowl of fruit first and then after that the face and
if you do see a face now the point being made here is that you made that face and it's something
that you had on the inside in your internal states that is a good explanation for the sensory
impressions on your retina or your your your epithelia and then this notion you can find
throughout history and philosophy I'm not a scholar but I find beautifully summarized by
Helmholtz for example objects are always imagined as being present in the field of vision as I have
to be there in order to produce the same impression on the nervous mechanism so again what he's saying
is it has to be on the inside before you can explain that sensory impression almost exactly the same
ideas from people like Richard Gregory the notion of perception as an hypothesis testing ideas used
to great effect by people like Jeffrey Hinton and Peter Diane in machine learning who indeed
built a Helmholtz machine based upon the work of or the Bayesian inference and the work of
people like Richard Feynman articulating that mathematically in terms of this minimization
of free energy so from our point of view though let's just come back to this notion of impressions
on the nervous mechanism or sensory impressions on our Markov blanket the sensory part of our
Markov blanket so I've cartooned that here in terms of some sensory shadows and our sensory veil
and if this dynamics if this Bayesian mechanics induced by Markov blanket is true then what that
means is I will look as if I am trying to find expressions for this sensory impression what caused
this particular shadow so what would that look like well we know exactly what it would look like it
has to be written down in this form from the physics so my internal states change in a way
that look as if they are trying to minimize this free energy form of this surprising or
self-information here and it transpires that the functional form of this can be universally interpreted
as a prediction error so what does that mean it means my internal states say my neural activity
is changing as a function of my current neural activity plus a prediction error
um and if you were an engineer you'd recognize these as the equations behind predictive coding
or Kalman filtering usually separated into a prediction what I predict the world will do
given its currents my expectations about its current state and then an update that is informed by
the sensory data that I sample so what's this free energy gradient here this prediction error
well imagine that I had this sensory impression here and I had an expectation a Bayesian belief
that it was caused by a dog and if I had a generative model that could generate what I would see
if I was correct I can then generate the prediction and compare it to the sensation
to form a prediction error which is simply the difference and all this fundamental gradient
flow is saying this predictive coding or Kalman filtering equation is saying is I'm going to change
my mind in the sense of changing my internal states in my neuronal states until the prediction
error has been eliminated and I've minimized my free energy and the gradients have been destroyed
so is that plausible in fact it's very plausible it speaks to a picture which we'll see in a second
where we want to look at I think both Kevin and Anil showed sort of cartoons of this one can look
at the brain as a hierarchical generative model generating predictions so evaluating the quality
of those predictions by evaluating a prediction error the free energy gradients and then revising
beliefs doing Bayesian belief updating on the basis of the mismatch now notice at no point
well I ever know what's going on out there all I'm doing is finding a sufficiently good explanation
in terms of that which minimizes my prediction errors in this instance it was actually a cat
and but that's nice because what it means is forget about all the physics and just summarized
the existential imperative that inherits from the physics in terms of minimizing prediction error
and there are two ways of doing that we can either change our minds to make our predictions more
like sensations or we can act on the world to solicit some more sensations that are closer to
our predictions so we can just realize our predictions actively by changing the configuration
of our body for example or in our internal state we talk about interceptive inference
and autonomic reflexes or we can engage motor reflexes or I can look somewhere else until
I see what I expect to see and thereby minimizing my prediction errors I won't go through this this
is what I would take people through if they did neuroscience in terms of the hierarchical organization
of this kind of scheme the basic message behind this architecture is that say for example visual
input comes in it's a receipt of top-down predictions from the visual part of the brain
it elaborates a prediction error that's then sent forward to revise my beliefs to provide better
elemental descriptions but crucially these expectations are themselves being predicted
in a hierarchical sense with these top-down descending predictions to produce a prediction
error that then drives the high-level expectations more abstract representations to provide an
account of what's going on below this is exactly what Kevin was talking about yesterday in terms of
this layer or level of the hierarchy looking at informing and being informed by the level below
and so on to any hierarchal depth required the particular twist in this graphic though is that
it incorporates action so here there's another kind of prediction error that comes from the
muscles in my eye that I could predict and I could use a prediction error to infer where my eye was
currently pointing but there's a much simpler way that I can minimize these prediction errors
I can just change the stretch of my muscle to match the predictions of the stretch receptors
and what I'm describing here is a classical reflex arc in motor control if I was doing
interceptive inference this would be an autonomic reflex basically actively and reflexively
minimizing prediction errors in relation to deeply hierarchically informed predictions
that are generated by my model that I'm trying to maximize the evidence for
so that's the basic story I just want to finish the story with saying well actually not quite
before I do that let me just illustrate the kind of active inference and the kind of sort of
engagement with the world and the one way of establishing a very simple synchrony with the
world that inherits from the architecture I've just shown you and what we did here is basically
equip a synthetic subject with a generative model that had dynamics autonomy and this kind of
itinerancy that was implicitly referred to yesterday in the form of a central pattern
generator and then map this abstract dynamic to some point in extra personal space and we told
the synthetic subject or part of its generative model was that there was an invisible point that
was moving around and there was an invisible spring that was pulling her finger towards the
moving point so that means that this synthetic subject is now expecting to predicting to feel
her hand being moved around and see her hand being moved around but because she also has reflexes
then she's going to automatically fulfill the addictions of the hand movements and cause the
hand to move thereby fulfilling the visual predictions and with this very simple kind
of reflexive setup we can simulate quite realistic biological kinds of motion and also
by simply removing the proprioceptive or the movement sensing information we can simulate not
just action but what it would be like to observe something very similar performing the same action
but just visually without the proprioceptive input so that's kind of simulation rests upon this sort
of overall architecture that we get some sensations that they are used to do our basing belief updating
by minimizing this variation free energy or what to do next and those predictions are
then used to generate action and this rests on the the markoff blanket that I showed right
at the beginning of the presentation what I'm going to do now is make one very very simple move
and take this sparse coupling that defines the thing from everything else make it slightly
sparser in a very simple but very important way I'm going to remove the influence of my active
states on my internal states and as soon as I do that then from the point of view of the internal
states my active states now become vicarious causes of my sensory states which means that
there now exists an interpretation of my internal states as modeling not just the external states
as causing or using a model of the external states to predict the sensory states but the
external states and the active states now become causes of my sensations so now I have a model
of the causes of my sensations that include my own actions and it's this particular move
that I'm suggesting or from the point of view of simulating these kinds of this kind of self
organization may be a necessary move to introduce agency in the sense that agents will have some
notion some or this can be described as having some sense of their own agency the consequences of
their own action because the their own action is now not directly accessible it can only be
observed by the sensory consequences but therefore have to be modeled and this takes us into a
slightly different and I think richer world where you now have the notion of a model that
incorporates explicitly the consequences of the agent's action I'm not saying at this stage
there's any awareness or sentence of that agency but just it is there that is then used to plan into
the future to evaluate the different consequences of different actions so that you are now implicitly
introducing the notion of planning and a temporal depth into the dynamics that then provide the
predictions of what I'm actually going to do next I won't go through this in any detail but just use
it to make the point that the underlying maths is quite simple and has a telonomy or at least an
interpretation in terms of things that's people's statistics machine learning and economics would
recognize immediately in terms of things like risk and ambiguity or accuracy and complexity
and intrinsic and extrinsic value where it turns out that all of these quantities that underwrite
the planning that ensues from having to have a model of the consequences of my action are well
established in different kinds of literature so for example the intrinsic value is just
the quantity used in visual search known as Bayesian surprise it's also exactly the same
quantity underwrite something I mentioned earlier which is the principle of maximum
neutral information or minimum redundancy principle and it is effectively the thing that
drives our curiosity it's the the thing that minimizes expected surprise by maximizing information
gain and I can sort of strip away various sources of uncertainty and get back to expected utility
but I really want to focus in the final slide on this epistemic affordance that falls out
and is a necessary consequence of just having a model of the consequences of my actions in the
future that I repeat entail a degree of planning and if I'm planning to where am I going to look
next I'm going to look to the I'm going to make the next eye movement that resolves the greatest
amount of uncertainty about the states of affairs out there because that has the greatest intrinsic
value it has the greatest intrinsic motivation it has the greatest epistemic importance it is
salient for me it has meaning for me in terms of what I don't know about the world beyond my
sensorium and you can write this down with particular examples and produce salience maps
that do actually describe quite accurately the empirical behavior of people choosing where to
look next and indeed you can simulate this in terms of a little agent this particular agent
at a very simple universe she was either in universe that where all her sensory input was
being caused by an upright face a sideways face or an inverted face and by carefully choosing
where to look next noting that she could only sample a very small part of the visual field
with her fovea as indicated by these images here and this movie here she can choose the best places
to look to maximize the space in surprise to maximize or respond to these epistemic affordances
and resolve her uncertainty what is she is looking at and she's indeed correctly inferring
she's looking at an upright face so all that can be much more gracefully summarized by Helmholtz
and as follows each element we make by which we alter the appearance of objects should be
thought of as an experiment designed to test whether we've understood correctly the environment
relations of the phenomena before us that is their existence in definite spatial relations
and with that it only remains for me to thank those people whose ideas I've been talking about
and of course to thank you for your attention thank you very much indeed
