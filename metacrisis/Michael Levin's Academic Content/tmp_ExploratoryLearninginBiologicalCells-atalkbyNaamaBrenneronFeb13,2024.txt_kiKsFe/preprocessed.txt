Title is exploratory learning in biological cells.
And what I'm going to do is I want
to talk about one particular type of learning.
And you guys have been thinking, I
think basal cognition is the title
of generalized learning in different embodiments.
One particular type of learning that I've been interested
in is exploratory learning.
And I want to, it has roots in psychology and in neuroscience.
So I don't have to yell, right?
No, no, no.
I feel like you don't have the right response, are you?
You can hear it.
OK, right?
I'm talking too loud.
Yeah, they can hear it.
All right.
So this particular kind of learning
has roots in psychology and in neuroscience.
And I'm going to present it in this context first.
And then I'm going to talk about how we kind of transfer
this, or apply it to cell biology,
in the context of gene regulation right now.
So this is quite old work by now.
And then I'm going to talk time permitting about our efforts
following that to model this type of learning in random networks.
And the bottom line of these modeling studies
can be stated in a way that also resonates with something
of this group's result is that learning is feasible,
but it's not universal.
It doesn't happen with any just random networks.
It depends on certain properties.
But on the other hand, I will argue
that these properties are not so rare,
and they are shared by many real systems.
So this just might be a relevant type of learning
for cell biology.
OK, so I start more than 100 years ago with Soren Dijk's
Animal Behavior, a classic book in animal behavior
with the same title.
And I want to refer to one of his experiments
where he took cats.
He had built these puzzle cages.
And he placed hungry cats inside the puzzle cages,
and they were supposed to find their way outside
to get to the food.
And the cage was built such that there was some lever
or something to be pulled or pressed.
And the animal had to find that in order
to get out and get the food.
And then he repeated this after the animal.
In that, it was repeated many cats.
And what he found was that first for a while,
these animals just tried out many different random motions,
any different ways to move their body and their limbs.
And at some point, they hit upon something successful
that brought them outside to the food.
And his observation was that over long time scales,
after many repetitions, they had associated
this last successful motion with the reward.
And so then they could repeat that much faster.
And we can see here, this blue line below or sort of a little
more here.
So what you can see here below the box
is a graph of the average time required, the escape time,
how much time it took the cat to get out of the box
as a function of trials.
And you can see that there is a decrease.
So this is a type of learning.
The cat has associated successful actions with the reward.
And so, yeah, so this is the behavior that Thorndyke
formulated as behavior leading to a satisfying situation
or avoiding a stressful one are likely to be.
This is a kind of trial and error.
And many years later, I mean, it's like already 20 years ago,
but much later than this original experiment,
Shimon Mahon, who is a member of our center,
decided to take this from the behavioral level
down several levels of organization to an ex vivo network.
And I've heard already this morning
that people are working with or have been working
with such networks, so maybe you know this already.
By the way, I didn't say this, but please start me if you want,
if I'm saying obvious things or if you want to ask.
So here's Shimon's experiment.
There are neurons taken from newborn, usually rats,
and placed on this chip with electrodes.
And you can talk with this system
through stimulation and reporting in any one of the electrodes.
Hanana can say about the system much more than I can.
But here, the thing I want to note I want to point to
is this experiment design that was formulated
in order to put to the test the question
whether such a system of neural substrate,
which has no anatomy and is not embodied in an animal,
can perform in a way similar to drive reduction
as formulated by the law.
So here's the translation.
There is...
The task that was identified for the system
is specific input-output response.
So I choose one electrode as the stimulating electrode,
and then I require the system to respond
in another predefined electrode.
And the assumption which has been studied beforehand
is that electrical stimulation drives the system to be modified,
to modify its connections, to modify its states as a network.
And so when you put in stimulation, you're driving it to change.
And so the idea was that I'm just driving, driving, driving.
Once I get the required response, I shut the driving down.
So this is a closed-loop system with a computer.
And when I read the response that I had anticipated
or I had required, I stopped the stimulation.
So this is the analogy of the cat's hunger that's driving it,
and then when it's already not hungry, it's not searching.
All right.
So here's an example of a measurement.
So this is one electrode.
If I choose this electrode to answer to respond after a predefined time window,
50 milliseconds in this case, a priori before the experiment,
there's not a lot of reaction in this time, not a lot of response.
But after the experiment is finished,
I have a lot of response in this time window.
And the fact that this experiment actually worked
is highly non-trivial results.
So this is an implementation, again, in an ex vivo system
of this animal learning or animal behavior concept.
So here's what the escape times look like.
I have on the x-axis the trial number, like in cats.
And I have in the y-axis the time to the response,
to the required response.
And these are jumping up and down.
Also, the cats do this.
Also, animal behavior does this.
And when you average over many trials, you get this decrease,
a smooth decrease in the response time.
Response time is the time that this takes to get the required response.
And then you will say, the system has learned what I wanted to teach it.
And this is the control.
If you open up the loop and there's no response dependent on the system,
then this time just increases.
So is this, does everybody know this paper?
Is it clear, though?
Yeah, OK, so this was, I think this is a highly influential,
was a highly influential paper, although many people
try to repeat this experiment with not a lot of success.
So experimentally, this has not turned into a paradigm in neuroscience
for reasons that I don't really understand,
but I think conceptually it was very influential.
So let me zoom out for a second and just say things
that I think in this group are going to be quite obvious to all of you
and just kind of make a contrast between two ways of forming a task
or inducing a desired behavior.
One of them is a deterministic algorithm, a series of directed actions.
For example, I could write for you if the cat could read,
I could write for the cat, do this and after that do that
and then give them a series of things.
This has analogs in other areas.
For example, when you think about learning,
what's the algorithm for strengthening the synapse?
There are time-dependent plasticity rules.
So there are microscopic rules, same with gene circuits
when this gene is up, that one turns on.
This is a very, could be an efficient way, but it's very specific.
It has microscopic world-defined goals and it's repeatable on all levels.
And I will call this an instructive way of forming a task.
The problem, of course, is that this is limited,
can only store so much information about a finite list of tasks
that you can work out in this way.
And to contrast that is the other extreme is trial and error
or exploratory learning where you do something, you try something out,
you estimate your error from some feedback
and then you modulate maybe through a random walk.
And this type is inefficient, but could be inefficient,
but it's very, very general.
If this works like we think it does for the neural net or for the cap,
then in principle they can learn anything.
And an important feature of this is that there are,
there is a macroscopic goal,
but I do not instruct the system on a microscopic level how to do this.
And so there could in principle be multiple solutions.
Okay, and this somehow is a selective way
that I would like to fortify or strengthen the correct,
or stabilize the correct trials.
Okay, so what I would like,
what we tried to do and at that point is,
this is a joint work with Eris Brown at the Tech of Neon.
We wanted to take these concepts and apply them to cells, okay?
So we're going even one step below the network
that was composed of live cells and all the other things,
and we're going to the single cell.
And then we were thinking how this relates to gene regulation.
So gene regulation is often thought of as a control system
that has the first type,
this is the instructive type of a structure, right?
It has, you can make a map of the interactions,
this gene drives that gene, et cetera.
And there's a blueprint for a program, in this case,
no, this is the developmental program for C-urchin.
But actually gene regulatory networks do much more than this.
And if you look throughout evolution,
and gene regulatory networks are responsible
for a lot of definitive innovation
that you see throughout evolution.
And this has been studied by observing the animal kingdom,
by observing the natural world
and is known under the name of co-option or gene recruitment.
So what happens is genes sometimes cut and paste themselves
in a way that creates novel structures.
And then you can trace that, for example,
one of the most beautiful examples is the butterfly wings,
how the transcription factors mix and match
to create the different patterns on the wings.
Okay, but this is out in the wild,
and our goal was to bring this somehow into a lab setting
and to design an experiment
that can test whether single cells can, in fact,
learn through exploratory learning
or through something which is analogous to this.
Okay, so when you mix and match or cut and paste
a regulatory system like this, something that is structured,
in principle, nothing, you know,
it cannot revert to this big typical
or the hardwired recipes that it has.
It has to do something different
in order to overcome these perturbations
and to come up with something new.
So here's the experiment that we thought about.
We took yeast cells, single-celled organisms,
and we kind of did a gene recruitment
synthetically in their network.
So yeast is great because we know a lot
about its regulatory system.
You take a metabolic gene, which is essential for growth,
and instead of it being driven by a regulatory system
that reads the correct inputs and responds
like a normal input-output system,
you completely fool it.
You kind of connect it to something completely unrelated
to the function of the gene.
And this is a gene that if you knock it out completely,
that the organism is going to die.
But if you connect it to a foreign regulatory system,
or you can, for example, shut it down completely
by external signals, that creates a frustration
in the system.
But interestingly, in that case,
the organism does not die.
So here's what happens.
These are normal yeast cells.
You plate them on a petri dish,
and after two days, you get these many little colonies.
This is how yeast cells grow.
But after you do this perturbation
and rewiring of the gene regulatory network,
after two days, you see no.
So you might think that these organisms
are just going to give up and not work their way
through this conflict.
But if you're patient, then after 14 days,
which is an enormous amount of time,
you start seeing the colonies grow.
So they look very different than the normal colonies.
It's a dynamic process.
It takes a long and variable time.
Every colony pops up at a different time.
But on the other hand, many, many cells adapt.
Independently, it's not a Darwinian process.
It takes place on the plate.
You can see that between 50% and 70% of them actually
find a way around the challenge to grow.
Do you have a question?
Yeah, this may be very random.
But has anyone looked at P53?
Any of these?
What do you mean looked at?
Yeah, so there's stuff with, like, a cave fish,
where basically, if you put them in a stressful environment,
they will not regulate.
Or sorry, the stress kind of swamps
the protein folding system.
And in particular, that's been kind of linked to P53.
Some work from Susan Lindquist and David.
So I was just wondering, could you say something?
OK, so this experiment has been repeated several times
with different types of rewiring.
I'm getting to this.
Maybe this is going to answer partly.
So this is a physiological description of what they do.
Now, if you go into gene expression,
start measuring expression of particular genes,
then surprisingly, despite the fact that the perturbation
or the rewiring was very local, take one gene
and connect it to a different place, it's a huge response.
Hundreds of genes go up and down in response to this challenge.
It is stress-sensitive.
We have an experimental knob that turns the stress up.
And then the gene expression response becomes larger,
been larger.
And it's not repeatable, which is maybe the most important
feature. So what does it mean non-repeatable?
I have here two experiments.
This is already old stuff.
We measured it with microarrays, like, I don't remember
how many years ago, more than 10.
And so what you're seeing here is the log fold change in genes.
Every point is one gene.
There's 6,400 genes in the yeast.
And some of them go up, some of them go down.
But the interesting thing is the next day,
you do the experiment again, experiment two,
and you see that those genes that were highly upregulated
in the second experiment can be downregulated.
There's no correlation.
Right, this big cloud here says that every gene
has more or less randomly gone up and down.
I cannot find any particular correlation
with what they did in the last experiment.
But still, the both of the experiment
on a physiological level look very similar.
So this tells us that there might
be here multiple solutions to the same challenge,
multiple solutions on the microscopic level
to the same physiological challenge.
OK, and the thing about, you asked about P53.
So at some point after we had these measurements,
we said, OK, let's look for the genes that we know that
are related to something.
So in particular, the yeast cells
have a very well-known universal stress response module
that lights up in certain cases.
And although we were really desperate to look to find,
there was nothing to be found.
And not only that, but the modules
that people have mapped for yeast
are completely broken down in this experiment.
New correlations are built, and typical correlations
are broken.
So it's a completely different type of case.
All right, and I can just say that this experiment was,
at the time, people had a very hard time
accepting yeast results.
And Ayers Brown, with other collaborators from Germany,
took very long time and other experiments
to, for example, convince people that this is not
Darwinian evolution.
But more recently, this has been reproduced and extended
to different types of promoters and different types
of rewiring in another lab.
And qualitatively, the results repeated very much.
OK, so could it be that what we're seeing here
is a form of learning?
This is the question, right?
So we have a complex system, the Gene Regulatory Network.
It's complex, it's multidimensional.
And not only that, we know that gene regulation
is context dependent.
This has been known from the early days of binding
experiments.
People have noted that there's context dependence.
And context dependence means that connections can change.
They have the ability to change.
They have that in them.
And what could, in principle, or potentially support
such changes, there are many, many molecular mechanisms.
Just naming one is the intrinsically disordered
proteins that are recently being rediscovered again
and again.
And being years ago, it was considered something
very esoteric.
But now, we know that, for example, in the human genomes,
two-thirds of the genome has many alternative forms.
And not only that, but this property
is extremely prevalent in transcription factors.
Those that are supposed to be the mediators of interactions,
those have really a lot of random protein domains.
And the one more ingredient, yeah.
So this is a paper by me, class.
It's called Rethinking.
I took the title from his paper, Really Interesting.
Rethinking Regulatory Networks.
And he lists a lot of molecular mechanisms
that could support the modifiability of gene regulation.
And the last thing is we need a global signal.
We need this something that will serve as the drive that
was the hunger for the cat and the electric simulation
from the computer for this neural network.
And we suggest to think about cellular stress, which
is something that is sensed by many mechanisms.
So there are mechanisms in the cell to set stress.
So this cellular stress could serve
as the generator of a drive reduction.
If the cell is feeling or sensing a high stress,
it could mount a type of response that is exploratory.
And once it is hit on a good configuration,
stress would be automatically or spontaneously relieved.
And then stability will be conferred.
OK, and this Rethinking of gene regulation
also has implications for modeling.
Again, I go back to this picture, which has become, for me
at least, this prototype for this blueprint modeling
of gene regulation.
And instead of thinking about mapping out
the interactions very specifically,
perhaps we should move to something more similar
to neuroscience.
Computational neuroscience, basically, in neuroscience,
you don't think that every neuron has a specific role.
So a lot of the modeling is done by random networks.
Actually, also for gene regulatory networks,
people have done modeling by random networks
many years ago already.
But things that I would like to highlight
is in addition to the random network structure
that I'm going to put into the modeling,
two important ingredients are one of them
is the plasticity of the connections.
So now we're getting closer to machine learning.
I have connections that can change, and they're flexible.
And the other thing is the feedback.
Feedback is essential here.
You want to see how the system behaves
under a low-dimensional global feedback signal.
So this just might be sufficient to describe
something similar to what the yeast cell does.
And the great thing about it is that no sophisticated
computation is required.
I don't need to invert matrices like I
need to do in algorithms of learning.
I don't need to store memory necessarily.
And so this might be a type of learning
that has its trade-offs.
It's very simple.
It has little computation.
And it could provide some abilities to set.
Maybe this is a good time to ask a very good question.
So now we're going to do it together.
Were these cells cultured together?
Or could they have learned from each other?
Or is it learning going on?
That's a great question.
That's a great question.
So our measurements were single.
Our measurements of gene expression were bulk.
We didn't have single cell measurements at the time.
I have to say I've been trying.
I hope this is going to help to have a second generation
of this experiment where we can look at single cells.
But certainly, my feeling is that there
is an identity to the population, which
means that they're probably exchanging
some kind of a technology.
That's a great question.
So when you say that the gene expression measurements were
bulk, how did you then produce that plot
where you showed two different experiments having
differing different?
No, these are two different experiments in the sense
of I do the whole thing from the beginning.
I take the new population out of the freezer the next week
or so, and I start the entire experiment again.
And then I get, OK, so the single or those are single genes,
not single cells.
I have, even with the microarray technology,
I have a measurement for every gene,
but it's average of the population.
OK.
Did I answer your question?
Yeah, so the first axis is an average of the population
of the first experiment.
Yes, and every point is a different gene.
But every point has information about any cells.
OK.
All right.
More questions?
Sir, you cannot know the variation of those points.
No, unfortunately, I don't.
It's only average.
It's average over the population,
but the variation appears over repetitions of the same,
you know, nominally the same experiment.
Right.
You repeat the same protocol, and this is what you get.
Do you think in general there's some kind of intermediate
array rules that they follow?
Like, yeah, any of the single genes in and of themselves
may shift up or down, left or right,
any one of the way you think about it.
But in general, there's some kind of like, ah, these genes
and these genes need to have some kind of relationship that's
held.
Yeah, yeah.
I think they create new correlations, this is my feeling.
I think I'll say more about that later.
About the relations between genes.
OK, that's great.
Yeah.
For the scatter plot again, did you do a control where you
had cells that were just happy and not stressed
and compare across two?
Yeah, we did that.
There's much more.
So, OK.
So there is much more correlation when
you have well-defined conditions and just normal cells.
It's not a 100% correlation, but there are good solutions.
And is the cluster taken?
Or?
Sorry?
It's like the cluster taken.
So like in the one you had, it's already been spanned.
Yeah, no.
When you have no perturbation or no stress in the system,
you get this, I didn't put it here, but it's in the paper.
You get a much higher, like 85, for 85 points
between the same system, all the time, if you're experienced.
All right, other questions?
I think Navneet had a question on the chat.
Oh, OK.
I can't read the chat.
OK, so yeah, my question is the faster response times of animals.
Was that based on the same animal's self-learning experience
or observing other cats?
No, no, the same animal did this experiment multiple times.
Same animal.
OK, OK.
So it's a personal experience, we can say,
for exploratory learning.
It's not observing other animals.
In the cat experiment and in the neural network experiment,
it was a repetition.
So the way they did it is they did this experiment
and then waited for a while, both cases,
and then did it again, and then there's
like a sequence of these experiments.
OK.
And the decreasing time is across repetitions of animals.
OK, makes sense.
All right, thank you.
OK, so what I want to do now is to talk a little bit
about our modeling work for this.
And I'm going to get into kind of a shallow, not
a great deal of details.
If there will be interest, I can give more details later.
But I just want to give the general idea first.
OK, so here's the model that we created.
And I'll go through this qualitative description of it.
I have a network.
OK, it's a random network.
And I require something from this network,
just like the neural network experiment.
I require a low-dimensional constraint.
This is important.
I do not require a specific pattern
of its individual elements.
But instead, I require a low-dimensional projection
to be under some constraint that I define.
Right, so this is what I want to teach.
I want to teach the network something
that is a low-dimensional task.
Now, initially, this network is not
going to be in line with the demand, the constraint.
And therefore, my model will return a variable
that I will call stress back to the system.
And this stress variable, as long as it's high,
is going to drive exploration of network connections.
Right?
So imagine this game where you hide something to the kids,
and then they go, you say, hot, cold, hot, cold.
Right, so I give the stress.
When it's far away, the stress depends
on the level of some closeness to the requirement.
And the dynamics goes on and on.
And at some point, just like the cat is going to bump on
or find a configuration that decreases the stress
by complying with this demand.
And at that point, automatically, stress
is going to be relieved.
And then the search is going to be stopped,
stopped, and stabilized.
Because this is all in words I can give equations later.
But why this is a non-trivial model
is the following reason.
In contrast to a two-dimensional room
where you hide something, and you say, hot, cold, hot,
cold, and then finally you find whatever
it is that you are hiding, we're talking here
about a network of order 1,000 dimensions.
So there's order 1,000 dimensions, square connections.
Now imagine 1,000, or even not squared,
just several thousand degrees of freedom,
just random walking through space
and searching for a configuration.
What are the chances that it'll ever find anything beneath?
That's the reason why this is a theoretically interesting
problem.
Right?
The assumption is that the stress function
is a gradual, slightly gradual, right?
Right, but this not, I will say more about this later,
but the answer is that it's not very
sensitive to the way the stress is driven back to the system.
It could be a step function, it could
be a smooth function.
It's a little bit sensitive, but not extremely sensitive
to the way you feedback the stress to the system.
OK, now the short answer is that sometimes this converts.
Then I go through the dynamics.
I simulate these equations.
And then I would like to ask, what
are the chances that this converges to something
that I define?
And the short answer is that sometimes it converges.
And here's an example.
This is a network of size 1,500.
This is a network which is kind of stressed, right?
It has the red or orange color.
It's under stress.
This is the projection.
The projection defines the stress which feeds back.
And here is the dynamics.
So the dynamics goes on and on.
The projection is also changing as a function of time.
And as long as the stress is high,
also the j is the connection matrix.
So the j, these are just four out of, I don't know,
whatever number, larger than 1,500.
I had connections in this one.
And they're slowly changing.
So there's a separation of time scales here, if you notice.
The dynamics is fast.
The little dimensional projection is a little bit slower.
And actually the connections which
are being modified, that's plasticity, is much slower.
But it's enough.
And it doesn't change by that much.
But there are many connections.
So eventually at some point, the system
stays, finds a good configuration.
And at that point, it hits fixed point.
And that fixed point complies with my demand.
And then the system goes, statement, yeah, question.
Is it appropriate to think about what your modeling year
is kind of like a large network of homeostats,
kind of like the Ashby homeostat, where
there are basically random connections
that were allowed to change up or down some, whatever.
You put a fixed point, and they bounce around,
and eventually, we'll find their way.
Yeah, I think that it's a high dimensional.
High dimensional.
I mean, I've read Ashby's model, and I,
that's in the direction.
So it's not bad to use that as a,
yeah, because the system is kind of, you know,
kind of self-fueling something, self-monitoring,
self-modulating until it finds it and attracts.
OK, now, but what I told you is that, you know,
when does this happen?
That's the question.
And the answer is, I have the answer yet.
This is the short version of the answer.
And the result is that it can work,
like in the example that I showed you,
but it doesn't always work.
And this question, whether it works or not,
whether it converges or not,
depends on the network structure, right?
And the short answer is that outgoing hubs
in the network support exploratory, right?
How do we know this?
I'm now getting a little bit deeper
into the mathematical part, into the computational part.
So this is how, this is how we studied this.
So we defined a collection of statistical examples.
So you know that in a network,
there are outgoing connections or incoming connections.
Now, stop me, please, if there's a question.
The network is characterized by some structure.
And in statistical terms, we say there's a distribution
of outgoing connections and a distribution
of incoming connections.
And I created, we created this collection,
where we picked every one of these distributions
from a different, with a different character.
So for example, the simplest network
is one where you have a binomial distribution
of incoming and outgoing.
Is that a question?
No, no, it's someone good coming in or coming out.
Ah, okay.
This is the simplest network over here at the bottom.
You just take a thousand nodes
and then you just, you know,
with some probability you connect
any two of them at complete range.
This network has not converged ever
in our experiments, even for very long times.
It can never learn the thing that we tried to teach.
All right?
Another type of distribution is a scale-free distribution
which has a long tail,
which means that you have some nodes
that are really highly connected.
Right, there's a range,
but some of them are really highly connected.
And okay, so you can see that different topologies
and different structures of network behave very different
from zero to more than 70% learning capacity.
What that means is that if I ran the simulation
for a hundred times,
I get 72 simulations where this network was able to learn.
Question?
For the simple network,
do you think that the stress is too high
so they don't even try it?
They can learn or is it?
I think I can say a little bit more about that later
as this unfolds, okay?
All right, so what you can see is that,
first of all, the different topologies behave differently.
And secondly, the three best ensembles
or the three best types of networks
are those that have scale-free
in their outgoing distributions, right?
So that means they have nodes
that are simultaneously driving many other nodes, okay?
All right, why is this important?
Let me go back to yeast cells for a minute
and try to connect this to gene regulatory networks.
So we know that people have mapped out,
there are more modern papers,
but this goes back 20 years,
and people have mapped the structure
of gene regulatory networks
by different experimental techniques.
And what you're seeing here is a distribution,
experimental distribution from binding experiments
and showing what the distribution of connections are.
So here's the picture for yeast, okay?
If I'm a gene, I have regulated by relatively small number
of genes, not shown here, but if I'm a transcription factor,
right, this is the graph for transcription factors,
a lot of them are regulating one, three, 10 other genes,
but some of them, look at this tail, okay?
I have few genes, here's one, here's two genes,
I have a few of them that are regulating
hundreds of other genes, all right?
And these are exactly these out hoeing,
not scale-free exactly,
but I do have these nodes that are affecting
simultaneously hundreds of other ones, okay?
And this is only like a,
to flash the experimental,
I'm not going into the details of the experiment,
but the experiment shows that out of this collection
of ensembles, the closest one to experiment is this one,
is the one that has a scale-free out distribution
that you can see here and an exponential in distribution,
which I'm not showing, okay?
So this gives me a hint that in networks
that look like gene regulatory networks of the yeast,
which are not completely random, they have structure,
maybe this algorithm of exploratory learning
is indeed feasible, it converges 60% of the time,
okay, also in the experiments, as I showed before,
not, this doesn't work 100% of the time,
but it works a significant fraction of the time, okay?
All right, so the picture that is starting to emerge
that is that maybe what random systems cannot do,
still regulatory systems can't do
because they have, to apologize,
they have structure that supports certain kinds
of statistical learning, all right?
However, you know, if you're, again,
if you're a little bit computation on the incline,
then, you know, people see this and they jump up and say,
this is not a scale-free distribution, right?
If you've worked on these avalanches,
this is a debate that goes on for decades.
You know, there's just like several dozen,
two dozen points here, is this a scale,
is this a power law, is this not a power law?
But still, I can see at the edge,
I can see these large hubs that are affecting
hundreds of other genes, all right?
So my experiment in my model is the following,
I take a look at this, I'm gonna skip this one,
but take a look at this right-hand image,
I'm gonna start from the network, which is very generic
and does not know how to do exploratory learning.
And then I'm gonna add one by one a number of hubs.
And like I said, in the beginning,
when it's a completely random network,
it does not know how to learn at all.
By the time I've added 10 out of 1500, right,
10 outgoing hubs, I get 40% there.
What this comes to tell me is that I don't really need
this mathematical structure of a power law.
I had used this when I wanted to create different topologies
because this is how we think about it in statistical terms,
but we don't really need that.
All we need is a handful of hubs
that control many, many other genes.
And this, I think nobody will argue,
despite the sparsity of this graph,
nobody will argue that there are master regulator genes
that regulate many, many hundreds of other genes.
So this again is a property of gene regulatory networks
that tends to support this in exploratory learning.
All right.
And this is just an illustration from some random paper
that studies biologists,
there are many, many studies on master regulator genes.
Okay, so how does this come about?
How do these hubs, like the small number of hubs, even?
How do they affect this search process that we saw?
And so what you can see here is, okay,
maybe I should go back and say one thing.
I wanna compare this ensemble
that I said is really good in learning, right?
It has outgoing, skill-free distribution
and an incoming exponential distribution.
And the one next to it has the same pattern
except switched, right?
It's just like transforming the matrix of connection.
Now, if you're a theoretical neuroscientist
and you think about eigenvalues of these matrices
and a lot of things, a lot of properties
are actually completely blind to this transformation,
but not this type of learning,
not this type of algorithm that we're performing here.
You can see that if I switch the outgoing and the incoming,
a dramatic change happens here.
It seems, according to this table,
it seems that the output is better,
but the input is not better.
That's right, it's very insensitive
to the incoming distribution.
Outgoing distribution is the most important.
I agree with that, other remarks?
Okay, so what I'm doing now
is I'm taking these two ensembles
whose matrices of interactions
are transformed one with respect to the other
and I'm just running the dynamics without anywhere, okay?
So this is the binomial skill-free,
which means the outgoing is binomial,
the incoming is skill-free, right?
Every gene is the opposite of the gene regulation.
It can be affected by many others,
but affects just kind of randomly.
And what I'm doing is I'm running the dynamics many times
and I'm clustering it.
This is just kind of a standard clustering algorithm
to the time sequences of the dynamics.
And what I wanna show here,
and you can see it by eye without any fancy analysis,
is that these guys are going almost independently.
There's not a lot of correlation.
So the point is that every node in the network
has a different dynamics and they're not very correlated.
On the other hand, this outgoing hub network
has a groups of genes that are highly correlated, okay?
And it is this one which is successful in learning
and this one that fails.
All right?
So remember in the beginning,
we said, look, if we have 1000 degrees of freedom
and there's many, many connections
and what are the chances of everyone
trying to look for a random configuration
and in the end it's finding something.
And now what we see is that those networks
that are successful are actually not doing it.
They're kind of roaming around in the high dimensional space
but on a lower dimensional lens.
They're not filling the entire space.
And that comes about because of their hub structure.
They're still random, they're still,
they're still, even though they have hubs,
they're still pretty high dimensional
but much lower than those that are not.
And indeed you can take from these,
now if you wanna quantify this,
you can compute a participation ratio.
Again, if anybody's familiar,
this is really standard in neuroscience
when you measure many, many neurons
and you get a lot of data in high dimensional space,
you can estimate there are many different ways
to estimate the dimensionality of the dynamics.
This is just one of them.
And I'm plotting here the dimensionality.
Sorry, I'm plotting here the participation ratio
for these three ensembles that we use
in the computational model.
And indeed those that are scale free something, right?
You said that the scale free out is important.
So also for the dimensionality,
these three network ensembles have outgoing scale free
and three different incoming,
but that doesn't really change the dimensionality.
And these guys have exponential outgoing
and something or other incoming.
And these guys have binomial distribution
for outgoing connections and any one of the three for incoming.
And you see that the hierarchy is reflected
also in the dimensionality of the dynamics, right?
So the answer, the qualitative answer is that the existence
of these hubs sort of constrains the dynamics
to a low dimensional manifold while it's searching around
and doing its exploratory thing to find a way of creation.
Okay, now if I go back,
I wanna go back to the learning itself.
This was just free dynamics.
I looked at the network ensembles without any learning.
I just looked at their typical way of performing
the dynamics that I put into the model
and I found this relation with dimensionality question.
Okay, now if I wanna go back to this learning
to exploratory learning,
again, I don't wanna go into a lot of details.
This is a slightly different version
which is a little bit more
schematic than the original ensembles
but it still has one particular hub
that it's a network that has random connections.
And in addition to that,
it has one hub that controls many of the nodes
and it behaves similar to the scale-free out networks.
And within these kind of network ensembles,
I can do the following.
I can change the strength of the hub, okay?
So if the hub is kind of constraining the dynamics,
then I can think maybe the strength of the hub can modulate,
can be a knob to modulate this constraint.
And what I find is the following.
So take a look at one of these graphs.
I have the strength of the hub on one hand on the x-axis
and I have the convergence fractions
which is the ability of this network
to learn on the y-axis.
And what I see here is that there is a trader.
If the hub is very weak,
so in this model, if the hub is zero,
I go back to the networks
that do not know how to learn at all.
Now I gradually increase the strength of this hub
and then I get to a really good 20 or 25% learning ability
but then if I continue to increase the hub,
at some point it's too much
and I'm going to decrease the ability
of this network to learn.
So again, the qualitative conclusion from this
is that the biological networks have hubs
that control a large fraction of the network
but not too much.
If I controlled all of it,
then you would not have enough search power.
So at this end, there's too high dimensionality
and the search is inefficient.
On the other hand, on the other edge,
there's too low dimensionality.
The hub is too strong.
It's not letting the system search enough.
That's what we call this low expressivity.
And somewhere in between
in a very broad kind of maximum region,
then there is coordinated efficient search
that enables this network.
Okay.
Questions, yes.
Just very vaguely.
In general, would you relate this to something like
edge of chaos type things?
If you're too far to the left,
everything's essentially random.
So the search is just like that.
As you wish.
If it's too far to the right,
it's so controlled, it's too ordered.
So nothing can ever,
and you have to, I am not pushing it,
but it's something like-
No, I think it has the flavor
of the trade-off at the edge of chaos.
Cool.
Because over there as well,
you say that one side is too express,
not expressive enough
and the other side is too constrained
or something like that.
It has the same flavor.
Okay.
Yeah.
I'm making sure I attach things
to your song, things I already know
to make sure that I-
No, no, I think, yeah, I think you're right.
I mean, let me just say that
this is unpublished to stuff yet
and not very, I mean, it's quite preliminary.
The last two slides are good preliminary,
but this is the intuition.
Okay, I think I'm gonna finish
with the computational part here.
So is there any other questions
maybe this would be a good time to raise them?
And then I'm just gonna go
and touch base back to biology
for a minute or a minute, okay?
All right, so, one more questions.
Okay, let me say something about
this role for master regulators.
And here's an example.
This is an example of a master regulator
called Z1, which is known to people
who study cancer or epithelial EMT,
epithelial to mesochemical transitions.
It is a repressor of epithelial genes
and it's associated with developmental processes,
of course, but also with aggressive tumor behavior
with metastases, drug resistance,
and it's linked to promoting stem.
This is a really important gene
in the study of cancer.
And it's a repressor.
Surprisingly, quite recently,
people have found as a paper from 2015,
that found that by teaming up
or interacting with another transcription factor
or regulator, this Z1 hub completely changes its character.
From being a repressor, it changes to being an activator.
It interact, the details are not important.
It interacts with another regulator
to control a whole different set of genes
from what it was before.
And the reason why the details are not important
is that if you go through the literature,
this is just one case,
but there are many other cases like this
and people find master regulators
that under certain conditions
completely change their character, their function,
their, the other proteins that they interact with
and their functionality.
So this is a type of rewiring or reprogramming
that these gene regulators are capable of undergoing,
which is consistent with this picture
of exploratory learning or exploratory dynamics
that finds novel types of things.
And so what we think is, you know,
a really powerful tool for cells
is that master regulator plasticity
can organize new patterns of gene expressions
and express new thing types.
All right, so follow-ups on this,
on our work in the direction of cancer,
if anybody's interested,
one group did a computational modeling
that took actual measurements from tumors
and tried to ask whether the gene expression
as a function of time during metastasis progression
can fit into this framework.
Another thing that we did is really,
we went through a whole lot of literature on cancer
and like I said, we found a lot of things
that, you know, qualitatively support this picture
that it's an important process.
And so let me summarize going back to the dichotomy
that I drew in the beginning of the talk
of these instructive versus selective way of learning
or performing a task.
What we think is happening is that gene regulatory networks
have this dual way of working.
On one hand, there's instructive, of course, obviously.
You know, a lot of people have mapped out modules
and parts of networks where we can trace the gene one,
activating gene two, et cetera,
and carrying out a very well concerted function.
And people have done a lot of work on that
and know to understand it and to measure it.
And this is all there.
It's all, this instructive performance happens,
but sometimes, you know, under certain conditions,
maybe under very strong perturbation,
maybe under rewiring or entrusting challenge
or certain stresses, the same structure,
the structure of these master regulators
now carries a new function in the world of search algorithms
where it can reduce dimensionality
and enable a completely different way of responding
where new phenotypes and new configurations can be found.
And it is this dual type of behavior
of gene regulatory networks
that makes them different from hardwired networks
or other artificial networks that we know.
Okay, summarize.
So with routine behavior psychology and experiments
in ex vivo and neural networks, exploratory learning,
I hope I've convinced you that it can be studied
both experimentally and theoretically
and gives a lot of challenges to think about.
The particular model that we developed
is a biased random search
in a high dimensional connectivity space.
And the outcome is highly variable
and sensitive to several details,
not to one by one details,
but in this case, to statistical properties.
And in particular networks with outgoing hubs
do well in this type of learning.
The role of hubs can be mapped onto a feedback system.
I didn't talk about this work.
It's very technical.
And it could be that this is implemented
by an effective dimensionality induction in the search.
And going back to the feasibility,
then I would claim that both feedback and plasticity
and heterogeneous connections are all typical
of these gene regulatory networks,
possibly other cellular networks as well.
And they're not completely generic.
They're not random networks like we use in physics
or something like that.
So let me just acknowledge,
my main collaborators are many over the years.
So the work experiments and these cells
were led by Ares Brown at the Technion.
And these people were very involved.
The model was developed with
you also had the Bitesman Institute
and the main player was Hades Schreyer, PhD student.
And with Omri Barak from Technion
who is a computational neuroscientist,
we are working on the general framework
of the theory of cellular learning.
And in terms of further challenges,
I think understanding the master regulators as hubs
is really still underway.
We don't really understand it.
We have some convincing arguments,
but not enough evidence.
And what is really interesting to me,
and I think in this group,
it's probably resonating with some of your works.
I would really love to understand
how these if and how similar principles
are implemented in other organisms
and other levels of organization,
other embodiments.
And from the practical point of view,
I think it's a nice challenge
to design a specific task to be learned.
But by cells, for example,
many people are trying to teach bacteria
to metabolize plastic or whatever.
And they're doing that mainly by instructive gene
biotechnology.
But perhaps this can also be done
by designing experiments
that are in principle behavioral experiments.
And yeah, and other forms of primitive learning is in one.
All right, thank you very much for listening.
Thank you.
Thank you.
Great.
Any anybody else questions?
I don't have a question if you can hear me.
Yeah.
Okay, cool.
So the idea that having outgoing hubs and networks
will effectively reduce the dimensionality of the system
makes a lot of sense.
But would it also
constrain the variety of problems it can solve?
So in your system specifically,
your fitness function is the low dimensional constraint
that you impose.
Could it also mean that the number of ways
you can formulate that fitness function
is also introduced due to network.
I think you're right.
And I mean, I stated it in some way in the beginning.
I think this kind of primitive learning,
to me it's very appealing
because you need very little for it.
But on the other hand, I agree that it cannot do a lot.
It's just there's a limit to what it can do.
And I totally agree.
Yeah.
Okay, thank you.
Anyone else?
Yeah.
So do you have any idea of what the mechanism could be
for the low dimensional stress detection?
How it knows in this, it's far away from those spaces.
I mean cells have mechanisms to stress different,
to sense different kinds of stress.
For example, protein is for me,
for example, temperature, they have the, I don't know.
I don't have particular mechanisms.
I just kind of rely on the fact that stress causes
a lot of things in cells.
It triggers a lot of behaviors.
So I guess saying that a cell can kind of monitor
its own stress level is not something new.
It's not something very new.
And so I think earlier you said that
there was like an already known established generic
stress response.
Yeah, a universal stress response.
But that is mapped.
That is kind of, there's a group of genes,
I don't remember several thousand genes
in one or something.
And they start, they can read inputs
from several different kinds of stresses.
Yeah, but that's still, that's, I mean,
people have mapped out what this stress module
can respond to.
We have not found evidence that this is the one
that's being used here, although we looked for it.
And, but again, I have to, you know,
there's a caveat again about the measurement.
These measurements are not, you know,
if you don't have single cell, you don't have many,
you know, this was done a while ago
and I would be really interested to begin
with water technologies and tests
to make expression questions.
