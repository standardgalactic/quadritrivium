at least, this prototype for this blueprint modeling
of gene regulation.
And instead of thinking about mapping out
the interactions very specifically,
perhaps we should move to something more similar
to neuroscience.
Computational neuroscience, basically, in neuroscience,
you don't think that every neuron has a specific role.
So a lot of the modeling is done by random networks.
Actually, also for gene regulatory networks,
people have done modeling by random networks
many years ago already.
But things that I would like to highlight
is in addition to the random network structure
that I'm going to put into the modeling,
two important ingredients are one of them
is the plasticity of the connections.
So now we're getting closer to machine learning.
I have connections that can change, and they're flexible.
And the other thing is the feedback.
Feedback is essential here.
You want to see how the system behaves
under a low-dimensional global feedback signal.
So this just might be sufficient to describe
something similar to what the yeast cell does.
And the great thing about it is that no sophisticated
computation is required.
I don't need to invert matrices like I
need to do in algorithms of learning.
I don't need to store memory necessarily.
And so this might be a type of learning
that has its trade-offs.
It's very simple.
It has little computation.
And it could provide some abilities to set.
Maybe this is a good time to ask a very good question.
So now we're going to do it together.
Were these cells cultured together?
Or could they have learned from each other?
Or is it learning going on?
That's a great question.
That's a great question.
So our measurements were single.
Our measurements of gene expression were bulk.
We didn't have single cell measurements at the time.
I have to say I've been trying.
I hope this is going to help to have a second generation
of this experiment where we can look at single cells.
But certainly, my feeling is that there
is an identity to the population, which
means that they're probably exchanging
some kind of a technology.
That's a great question.
So when you say that the gene expression measurements were
bulk, how did you then produce that plot
where you showed two different experiments having
differing different?
No, these are two different experiments in the sense
of I do the whole thing from the beginning.
I take the new population out of the freezer the next week
or so, and I start the entire experiment again.
And then I get, OK, so the single or those are single genes,
not single cells.
I have, even with the microarray technology,
I have a measurement for every gene,
but it's average of the population.
OK.
Did I answer your question?
Yeah, so the first axis is an average of the population
of the first experiment.
Yes, and every point is a different gene.
But every point has information about any cells.
OK.
All right.
More questions?
Sir, you cannot know the variation of those points.
No, unfortunately, I don't.
It's only average.
It's average over the population,
but the variation appears over repetitions of the same,
you know, nominally the same experiment.
Right.
You repeat the same protocol, and this is what you get.
Do you think in general there's some kind of intermediate
array rules that they follow?
Like, yeah, any of the single genes in and of themselves
may shift up or down, left or right,
any one of the way you think about it.
But in general, there's some kind of like, ah, these genes
and these genes need to have some kind of relationship that's
held.
Yeah, yeah.
I think they create new correlations, this is my feeling.
I think I'll say more about that later.
About the relations between genes.
OK, that's great.
Yeah.
For the scatter plot again, did you do a control where you
had cells that were just happy and not stressed
and compare across two?
Yeah, we did that.
There's much more.
So, OK.
So there is much more correlation when
you have well-defined conditions and just normal cells.
It's not a 100% correlation, but there are good solutions.
And is the cluster taken?
Or?
Sorry?
It's like the cluster taken.
So like in the one you had, it's already been spanned.
Yeah, no.
When you have no perturbation or no stress in the system,
you get this, I didn't put it here, but it's in the paper.
You get a much higher, like 85, for 85 points
between the same system, all the time, if you're experienced.
All right, other questions?
I think Navneet had a question on the chat.
Oh, OK.
I can't read the chat.
OK, so yeah, my question is the faster response times of animals.
Was that based on the same animal's self-learning experience
or observing other cats?
No, no, the same animal did this experiment multiple times.
Same animal.
OK, OK.
So it's a personal experience, we can say,
for exploratory learning.
It's not observing other animals.
In the cat experiment and in the neural network experiment,
it was a repetition.
So the way they did it is they did this experiment
and then waited for a while, both cases,
and then did it again, and then there's
like a sequence of these experiments.
OK.
And the decreasing time is across repetitions of animals.
OK, makes sense.
All right, thank you.
OK, so what I want to do now is to talk a little bit
about our modeling work for this.
And I'm going to get into kind of a shallow, not
a great deal of details.
If there will be interest, I can give more details later.
But I just want to give the general idea first.
OK, so here's the model that we created.
And I'll go through this qualitative description of it.
I have a network.
OK, it's a random network.
And I require something from this network,
just like the neural network experiment.
I require a low-dimensional constraint.
This is important.
I do not require a specific pattern
of its individual elements.
But instead, I require a low-dimensional projection
to be under some constraint that I define.
Right, so this is what I want to teach.
I want to teach the network something
that is a low-dimensional task.
Now, initially, this network is not
going to be in line with the demand, the constraint.
And therefore, my model will return a variable
that I will call stress back to the system.
And this stress variable, as long as it's high,
is going to drive exploration of network connections.
Right?
So imagine this game where you hide something to the kids,
and then they go, you say, hot, cold, hot, cold.
Right, so I give the stress.
When it's far away, the stress depends
on the level of some closeness to the requirement.
And the dynamics goes on and on.
And at some point, just like the cat is going to bump on
or find a configuration that decreases the stress
by complying with this demand.
And at that point, automatically, stress
is going to be relieved.
And then the search is going to be stopped,
stopped, and stabilized.
Because this is all in words I can give equations later.
But why this is a non-trivial model
is the following reason.
In contrast to a two-dimensional room
where you hide something, and you say, hot, cold, hot,
cold, and then finally you find whatever
it is that you are hiding, we're talking here
about a network of order 1,000 dimensions.
So there's order 1,000 dimensions, square connections.
Now imagine 1,000, or even not squared,
just several thousand degrees of freedom,
just random walking through space
and searching for a configuration.
What are the chances that it'll ever find anything beneath?
That's the reason why this is a theoretically interesting
problem.
Right?
The assumption is that the stress function
is a gradual, slightly gradual, right?
Right, but this not, I will say more about this later,
