because this is how we think about it in statistical terms,
but we don't really need that.
All we need is a handful of hubs
that control many, many other genes.
And this, I think nobody will argue,
despite the sparsity of this graph,
nobody will argue that there are master regulator genes
that regulate many, many hundreds of other genes.
So this again is a property of gene regulatory networks
that tends to support this in exploratory learning.
All right.
And this is just an illustration from some random paper
that studies biologists,
there are many, many studies on master regulator genes.
Okay, so how does this come about?
How do these hubs, like the small number of hubs, even?
How do they affect this search process that we saw?
And so what you can see here is, okay,
maybe I should go back and say one thing.
I wanna compare this ensemble
that I said is really good in learning, right?
It has outgoing, skill-free distribution
and an incoming exponential distribution.
And the one next to it has the same pattern
except switched, right?
It's just like transforming the matrix of connection.
Now, if you're a theoretical neuroscientist
and you think about eigenvalues of these matrices
and a lot of things, a lot of properties
are actually completely blind to this transformation,
but not this type of learning,
not this type of algorithm that we're performing here.
You can see that if I switch the outgoing and the incoming,
a dramatic change happens here.
It seems, according to this table,
it seems that the output is better,
but the input is not better.
That's right, it's very insensitive
to the incoming distribution.
Outgoing distribution is the most important.
I agree with that, other remarks?
Okay, so what I'm doing now
is I'm taking these two ensembles
whose matrices of interactions
are transformed one with respect to the other
and I'm just running the dynamics without anywhere, okay?
So this is the binomial skill-free,
which means the outgoing is binomial,
the incoming is skill-free, right?
Every gene is the opposite of the gene regulation.
It can be affected by many others,
but affects just kind of randomly.
And what I'm doing is I'm running the dynamics many times
and I'm clustering it.
This is just kind of a standard clustering algorithm
to the time sequences of the dynamics.
And what I wanna show here,
and you can see it by eye without any fancy analysis,
is that these guys are going almost independently.
There's not a lot of correlation.
So the point is that every node in the network
has a different dynamics and they're not very correlated.
On the other hand, this outgoing hub network
has a groups of genes that are highly correlated, okay?
And it is this one which is successful in learning
and this one that fails.
All right?
So remember in the beginning,
we said, look, if we have 1000 degrees of freedom
and there's many, many connections
and what are the chances of everyone
trying to look for a random configuration
and in the end it's finding something.
And now what we see is that those networks
that are successful are actually not doing it.
They're kind of roaming around in the high dimensional space
but on a lower dimensional lens.
They're not filling the entire space.
And that comes about because of their hub structure.
They're still random, they're still,
they're still, even though they have hubs,
they're still pretty high dimensional
but much lower than those that are not.
And indeed you can take from these,
now if you wanna quantify this,
you can compute a participation ratio.
Again, if anybody's familiar,
this is really standard in neuroscience
when you measure many, many neurons
and you get a lot of data in high dimensional space,
you can estimate there are many different ways
to estimate the dimensionality of the dynamics.
This is just one of them.
And I'm plotting here the dimensionality.
Sorry, I'm plotting here the participation ratio
for these three ensembles that we use
in the computational model.
And indeed those that are scale free something, right?
You said that the scale free out is important.
So also for the dimensionality,
these three network ensembles have outgoing scale free
and three different incoming,
but that doesn't really change the dimensionality.
And these guys have exponential outgoing
and something or other incoming.
And these guys have binomial distribution
for outgoing connections and any one of the three for incoming.
And you see that the hierarchy is reflected
also in the dimensionality of the dynamics, right?
So the answer, the qualitative answer is that the existence
of these hubs sort of constrains the dynamics
to a low dimensional manifold while it's searching around
and doing its exploratory thing to find a way of creation.
Okay, now if I go back,
I wanna go back to the learning itself.
This was just free dynamics.
I looked at the network ensembles without any learning.
I just looked at their typical way of performing
the dynamics that I put into the model
and I found this relation with dimensionality question.
Okay, now if I wanna go back to this learning
to exploratory learning,
again, I don't wanna go into a lot of details.
This is a slightly different version
which is a little bit more
schematic than the original ensembles
but it still has one particular hub
that it's a network that has random connections.
And in addition to that,
it has one hub that controls many of the nodes
and it behaves similar to the scale-free out networks.
And within these kind of network ensembles,
I can do the following.
I can change the strength of the hub, okay?
So if the hub is kind of constraining the dynamics,
then I can think maybe the strength of the hub can modulate,
can be a knob to modulate this constraint.
And what I find is the following.
So take a look at one of these graphs.
I have the strength of the hub on one hand on the x-axis
and I have the convergence fractions
which is the ability of this network
to learn on the y-axis.
And what I see here is that there is a trader.
If the hub is very weak,
so in this model, if the hub is zero,
I go back to the networks
that do not know how to learn at all.
Now I gradually increase the strength of this hub
and then I get to a really good 20 or 25% learning ability
but then if I continue to increase the hub,
at some point it's too much
and I'm going to decrease the ability
of this network to learn.
So again, the qualitative conclusion from this
is that the biological networks have hubs
that control a large fraction of the network
but not too much.
If I controlled all of it,
then you would not have enough search power.
So at this end, there's too high dimensionality
and the search is inefficient.
On the other hand, on the other edge,
there's too low dimensionality.
The hub is too strong.
It's not letting the system search enough.
That's what we call this low expressivity.
And somewhere in between
in a very broad kind of maximum region,
then there is coordinated efficient search
that enables this network.
Okay.
Questions, yes.
Just very vaguely.
In general, would you relate this to something like
edge of chaos type things?
If you're too far to the left,
everything's essentially random.
So the search is just like that.
As you wish.
If it's too far to the right,
it's so controlled, it's too ordered.
So nothing can ever,
and you have to, I am not pushing it,
but it's something like-
No, I think it has the flavor
of the trade-off at the edge of chaos.
Cool.
Because over there as well,
you say that one side is too express,
not expressive enough
and the other side is too constrained
or something like that.
It has the same flavor.
Okay.
Yeah.
I'm making sure I attach things
to your song, things I already know
to make sure that I-
No, no, I think, yeah, I think you're right.
