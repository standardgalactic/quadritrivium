I'm Chris Fields. I'm a remote member of the computational team. I actually don't do a whole
lot of computational work. I'm mainly a theorist and so I was going to use my time today to
try to convince you this is sensible.
So I just wanted to talk a little bit about why it even makes sense to use basic physics to study
biology. And in particular, I work in quantum information theory for the most part. So the real
question is why would anyone want to use quantum theory to study biology? And
and through remaining motivations I think for doing this, one of them is that quantum theory
makes many fewer assumptions in classical theory. So
so
so that's a huge assumption in classical physics that quantum theory doesn't make. So one
sorry, Chris. Sorry, what's a huge assumption you're cutting out? Oh, yes, my internet connection
is often not good when I have video on, but I think I have to have it on for this.
The point was that classical physics assumes a space time background.
And so one doesn't necessarily have to assume that and that allows you to ask some questions
that you simply can't ask in classical theory. A second motivation is that the formalism of
quantum theory, because it's so stripped down in terms of assumptions, is actually simpler than
the formalism of classical theory. And if you had a quantum mechanics course, you probably think
that statement is crazy, because the theory is often taught in a way that makes it seem
fiendishly complicated. But the formalism of quantum theory is basically just finite dimensional
linear algebra. And finite dimensional linear algebra is pretty simple, especially compared to
real analysis, multivariate real analysis. And then the third motivation is that when
quantum theory is stripped down to its basics, it's really a theory about information exchange.
And I would say this wasn't really recognized in the first 50 or so years of
physicists working on quantum theory. It wasn't till the 70s that started to be realized and
in the 80s, the realization actually developed that quantum theory was basically about information
exchange. So from that point, from our point of view, it's about communication. And that's nice,
because biology is basically about communication. It's about cells communicating or organisms
communicating or whatever. So from that point of view, the theory is actually about the process
that we're interested in describing. So that motivates using it to study biology. So not only
can we address problems that are hard to even see from a classical perspective,
it also allows us to ask questions that are hard to formulate in English. And
questions that are very vague in English can be asked fairly precisely using the theory.
Can I ask a very naive question? Sure. So is the assumption that sort of the
processes that you're studying are at the quantum level, so like quarks and stuff like that,
or is it applying the sort of theory of quantum things to how cells and stuff like that work?
It's definitely the latter. And we'll talk about the scale issue kind of at the end.
But quantum theory has traditionally been thought of as about some microscopic world,
but that starts at kind of the scale of atoms and goes down. And it again wasn't until the 70s
that it was realized that the quantum theory also applies to very big things. And the first big things
that it was realized had to be characterized as a quantum theory or black holes. And there are
black holes that are much, much larger than the solar system, for example. So the theory itself
is scale free. It makes no assumptions about scale at all. So what I'll show you are ways of
thinking about biological systems at some scale or other using the concepts that are very natural in
quantum theory. So let's just go to some of these examples and start by talking about organism
environment interaction. Many of you have seen the top part of this picture in talks by Franz or
somebody else.
And talking about organism environment interaction in this classical context,
one identifies four different populations of states and a large number of connections.
So
so this is a fairly complicated formal description of what's going on when your organism is
exchanging information with its environment. And several years ago, Mike and Carl and some
other colleagues and I put together a quantum formulation of the free energy principle. And
in that formulation, the picture that one gets is much simpler. We have an organism in an environment
which we don't make any assumptions about at all. And so we just label them A and B or
Alice and Bob or something like that. There's a boundary between them and they interact with
Chris, are you able to repeat that your connections very unstable?
Oh, I'm sorry. We formulated the free energy principle in quantum
theoretic terms. And in those terms, it's actually very simple. We have two systems, A and B,
they interact through some boundary by exchanging information. And we can describe the information
exchanged by an operator, which we call H, because technically it's a Hamiltonian.
But the thing to note about this operator is that it's a linear operator on a vector space.
So unlike a set of partial differential equations in multiple variables,
we have something that's relatively simple, a linear operator on a vector space.
And what we found was that this representation is actually quite powerful. And it's powerful
because it's very symmetrical. As I said, we don't assume anything in particular about A and B.
So this picture looks completely symmetrical. And much of physics is actually driven by noting
similarities in diagrams and milking them for all their worth. So because this picture is symmetrical,
we know we can swap A and B back and forth. And that tells us something. It tells us that
whatever these systems are, A and B, they have to obey the same rules. And that tells us that
if A satisfies the free energy principle, then B has to satisfy it too. And from that,
we can immediately infer that the environment of any active inference agent is also an active
inference agent. And this was new. The free energy principle had been characterized as universal,
as applying to all physical systems. So obviously, it follows from that that it applies
to the environment of any system that you're interested in, that it applies to the environment
of any organism. But that implication was a little bit hidden by the classical formalism,
because to actually do the calculations in the classical formalism, one typically assumes that
the environment is just a noise source. And of course, our environment, the human environment,
is not just a noise source. The human environment's mainly made up of other people. And other people
give you meaningful messages. Other people are active inference agents. So treating the environment
as a noise source is an approximation that makes doing the math easy, but it's not very realistic.
And in this quantum information formalism, the fact that the environment is also an active
inference agent, it just leaps out at you. It's completely obvious. So that illustrates the
simplicity of thinking of these things this way. And Mike and I actually wrote a paper last year
talking about development and evolution from this point of view, and pointing out that if the
environment is an active inference agent, then what it's doing all the time is trying to make the
behavior of some organism more predictable by it. And so this gives a picture of evolution in which
the environment plays a very active role. It's not just weeding out organisms that aren't very
smart. It's actually trying to get the organism to behave in a way that's more predictable
for the environment. And again, we're not making any specific assumptions about what the
computational powers of the environment are. But if you again translate this into human terms or
the terms of any social organism, a social organism's environment is made up of other
social organisms, and they do try to train the system of interest to be more predictable.
And this actually is pretty closely related to what Wes just talked about.
So we can draw pictures like the one that I showed down here that show the situation of,
say, cell division from the perspective of a stem cell, which I've labeled S, or from the
perspective of the environment. From the stem cells perspective, it's creating copies of itself
which it can predict because the copies are much like it is. It's trying to fill the environment
up with those copies, and doing that makes the environment more predictable.
But we can also look at it from the environment's perspective.
And from the environment's perspective, what the stem cell is doing is effectively increasing
the environment's computational power, which gives the environment more ability to predict what
the stem cell is doing. So this dual way of looking at things kind of makes sense biologically.
And again, it's something that the physics kind of forces you to take seriously in this case.
So here are some other implications of these sorts of symmetries of the interaction.
The first symmetry we talked about was just the symmetry between A and B,
their information exchange. Another symmetry of generic interactions is that the bit values
that are encoded on the boundary are also swap symmetric. You can move them around,
and it doesn't make any difference if a system, say, is at equilibrium.
But as you get spontaneous breaking of that symmetry, so that specific bit values start to
have functional roles, they affect what's going on in the inside differently.
I may have lost everybody. No, no, we're still here. We just turned off the video to help your
bandwidth. Okay, great. Thanks. As soon as this symmetry is spontaneously broken,
the FEP will actually amplify the symmetry breaking. So if some bits start to take on
what we would call functional roles in the system, the FEP will drive them to increase
their functionality because that will help the system predict what its environment is doing better.
And if you follow that process through, what it leads you to is a system that's fully compartmentalized
that actually is driven to construct internal boundaries between different parts of its dynamics,
the process, different inputs from its boundary, and construct different outputs on this boundary.
And those internal components will be separated by internal boundaries that enforce classical
communication between them. And again, this just follows from the physics. Now, interestingly enough,
when you run time asymptotically and let this system become a better and better predictor of
its environment, and conversely allow its environment to become a better and better predictor of it,
the two systems will approach quantum entanglement. And that reveals that we can think of the FEP
as actually being a theory of spontaneous symmetry breaking that implements a cycle in which
spontaneous symmetry breakings are amplified and then collapse. And then some other symmetry
breaking is amplified and then collapses. So the system cycles between a separable state where the
two systems where A and B are distinct, and an entangled state in which A and B are no longer
distinct. And we can represent this also as a cycle between two different kinds of entropy,
a classical entropy, and an entanglement entropy. So this is actually a view of the FEP that you
can't have in a classical setting because there is no analog in a classical setting of entanglement,
of the loss of distinguishability between two systems. And the reason for that is that
the classical theory assumes it's based on embedding that keeps the system separate.
So the quantum theory can show you things that the classical theory can't. And interestingly enough,
these kinds of spontaneous symmetry breaking theories are pursued many other places in physics. So
there's now an enormous opportunity to drag in work that's been done by other people to
help us understand what's going on in biology. So I'll just give you another example.
Consider a question like this. Can an observer determine that she has a conditionally independent
state? So can an observer determine that she's actually subject to the free energy principle,
which requires having a conditionally independent state? And when we formulate this question,
and think about classical physics, the question looks philosophical. I mean, it looks like something
you would discuss in the bar after work and be able to argue for against. But in quantum theory,
the question has a very simple answer. The answer is no. And it's not an argument, it's a theorem.
And it's based on the fact that the observer can't measure a certain quantity, the entanglement
entropy across the boundary. So an observer actually can't determine that they're not entangled
with their environment. So this is a case where having a mathematical language that doesn't match
up with English very well, that has a different conceptual scheme from our usual classical
conceptual scheme actually turns some of these vague questions that look philosophical.
And to answerable questions and answers them. So let me go at the,
for this last bit of the talk, into a couple of other features of quantum information theory
that I mentioned earlier. One of them is that the theory is scale independent. And the other is that
it doesn't assume a spacetime background. So scale independence means that the theory applies
in principle to everything from electrons or other subatomic particles to black holes.
In fact, it applies in principle all the way down to the Planck scale and all the way up to the
cosmological scale and we're somewhere in between. So it should apply to us as well.
And the second one is that the theory is consistent at least in principle with spacetime not being
fundamental, but rather being emergent from something else. So a question to ask is where
can we go with this? What insights might these facts give us about biological systems if we
think of them as communicating systems that are described by this very general model of communication?
And so here's one place where this is helpful, I think. Biology is full of scale transitions.
So we know that pathways kind of organize themselves into cells that happen sometime in
evolution at least to give us our last universal common ancestor. We know that cells organize
themselves into tissues and tissues organize themselves into organisms and this is the process
of morphogenesis. We know that organisms organize themselves into niches and this isn't just
monophyletic niches but multi-phyletic niches like our own bodies are full of bacteria and
fungi and other things that are members of different phyla than we are as mammals.
And we know that niches organize themselves into ecosystems and ecosystems are organized into a
biosphere. We can think of each of these organizational steps as a bunch of little things
getting together and working together to create some big thing or bigger thing that itself acts
like an agent. And again, Wes referred to this very issue in talking about
navigating multiple spaces. So here we have a bunch of scale transitions. Can we think of this in
a scale independent theory and put these scale transitions together, develop a theory of how
the scale transitions themselves are related? And physics provides various tools for doing that,
of one of which is the renormalization group which is just a way of defining an operator that
relates these different transition theories to each other. And the simplest hypothesis is that
for biological systems, this operator is trivial, that the transition theories are all
actually exactly the same. I mean, they may be different, but the simplest case would be if they
were exactly the same. And so the question is how can we test this hypothesis? And I think a lot of
the things that we're doing in the lab are trying to test this hypothesis at some scale or other
by working out exactly what the transition theory is, exactly how tissues, for example,
organize themselves or how cells organize themselves. And Wes just mentioned learning
as an algorithm that probably acts on all of these scales. So we may be able to think about
a set of algorithms that actually implement transition theories at each of these scales
and ask about what those algorithms are, if they're the same at every level.
And I suspect that it'll turn out to be that the answer is yes, that this tower of transitions is
actually trivial. So the last thing I wanted to mention was about space time. Space time isn't
fundamental. Then it's generated by something. And in physics, what it's typically thought of as
generated by is communication, information exchange. And in particular, the kind of redundancy that
one can construct with an error correcting code. And so one of the main things that I'm currently
working on is error correcting codes. And the extent to which error correcting codes can generate
the kind of redundancy that allows you to impose a set of coordinates on something
that can represent the positions of systems, the positions of objects.
And we know that organisms do this. We know that organisms implement this cycle
between having some sense of space time, which requires a memory. And memory allows the
representation of objects and object persistence. So it allows the representation of objects as
things that have an identity that's maintained through time, which is a precondition for being
able to detect motion. So memory lets you actually see change in the world, lets you see kinematics
and dynamics. And if you can see change, you can see objects move around. So you can see spatial
redundancy, and that allows you to correct errors. Because you can move an object around,
you can make copies of an object and put copies in different places and access different copies
if one of them is corrupted and so forth. And error correction gives you a more robust
representation of space time. Because it reveals the symmetries of space time, things like
translational invariance and rotational invariance and so on.
So a general question becomes, how does this work? How does this cycle work?
What sorts of systems can implement this cycle? Is it implemented by all living systems in some way?
And that's a large open problem. And if you look at phylogeny, and here I'm just showing
animal phylogeny, which is the tiny little edge of the whole phylogenetic tree, which is mostly
microbial. We only know anything about ontology, so we only know anything about the representation
of space time and objects, as far as I know, in three different parts of this huge phylogenetic
tree of animals. We know about them in the vertebrates. We know about them in the complex
cephalopods, like octopus. And we can know about them in some insects and spiders, for example,
honeybees. But we don't know anything about them, really, in almost all of phylogeny.
So this question of the extent to which living things employ a space time representation and
have some sense of what an object is, even a conspecific, for example, some way of tracking
objects through time, is a very open question. And it's hopefully a question that we can
address experimentally in more systems than just these three classes of systems where it's been
addressed so far. So with that, I think I'm actually close to out of time at least. I'll stop and just
say, if you find these issues interesting, there's the six hour version of this talk,
which is accessible through the Active Inference Institute. They're all on YouTube. Or it's an
explicit list of videos on my website, which is probably the easiest way to get to it. So thank
you very much. And I can answer any questions.
