a sense of, you know, the solar weather, you can do that. If you want to have a sense of the
stock market instead of, you know, smell, you can do that. Like the, all of these things exist. All
of these things already exist. So we're going to have these preachers and then people will have,
you know, there will be, there will be hybrid robotics and, and, and, and, you know, kind of
bioengineered beings that, uh, if you, if you, if you wanted to make, um, a mammal with a third
hemisphere, we can do that. We can, we can graft on the third hemisphere of the brain.
You know, no, no, no problem. We could make that today. So, um, all of these kind of creatures
are going to have, uh, novel bodies and novel embodied minds. And all of these old categories,
it's a, it's a human, it's a machine, it's a robot, it's a living organism, it's intelligent. No, it's
not. It's just, you know, it's just, like all of that stuff is going out the window. I mean,
it was never very good, but it's definitely not going to last the next couple of decades.
Hmm. And I don't think anyone's prepared for that.
Absolutely. They're not prepared for that. They're absolutely not prepared for that.
They're not even prepared. They're not even prepared to think about it. I, I have, I have
constantly, uh, arguments with people who are, who are still using these binary categories.
It's just a cell. It's only chemistry and physics, but I, I am a human, like, okay, let's,
let's follow you backwards and guess what you were just, you know, a few years and nine months
ago, you were a single cell, a little blob of chemistry and physics. So, so there's a smooth,
gradual continuum and there's no magic lightning bolt during any of that time period where somebody
says, boom, now you've gone from physics to mine. That doesn't exist. So you, so, so there's this
continuum and then I can stretch it, right? So, so I've got this slide where I show, okay, so there's
a human in the middle and up here, there's the evolutionary path and you used to be a, a microbe
up here and there's a developmental path and you used to be a unfertilized oversight down here
and then you could go sideways and you can do all kinds of biological modifications. This way
you can do all kinds of technological modifications. This way, all of this stuff is completely
continuous. There are no binary categories anywhere. So, so when people, uh, insist on thinking,
is it intelligent? Is it a machine? You know, it's like, um, it's, it's, I mean, these categories
are, are, are worthless now. Uh, we have to, we have to rejigger all of that. And then, and then
comes the hard part of, uh, making the institutions fit, right? It's sort of like the notion of an
adult, right? We have this notion of an adult. What's an adult? Does anything happen on your 18th
birthday to make you an adult? Nothing. We just, we just have this, this, this binary cutoff to
help, you know, to help the legal system figure out, you know, how are you going to get charged in
court? But that's it. There's no, there's no, you know, there's not really a sharp boundary there.
So, you know, um, I've talked to, I've talked to, uh, legal, uh, you know, kind of legal scholars
and so on about how we're going to figure this out and what, you know, what it means to, um,
to, to, to, to, to, to be a person. And these are not new. I mean, science fiction has been
dealing with this stuff for, you know, 150 years. So this is, these are not new. But I think, I think
now we're definitely getting to the point where we need to be figuring this out. And this, and this
AI stuff is just, just a tip of the iceberg on this. Okay. So yeah. So
yeah. So all these other things would likely, if they're coming from biological material,
would likely have some kind of agency greater than the, the kind of agency that we have for
computers and, uh, uh, so deep learning systems. So, so you're assuming a world that
all these things aren't, are, are autonomous and alive and, um, and, uh,
I guess, uh, have some sort of, um, quote unquote, free will to do whatever they want.
Yeah. I mean, that's a whole other, that's a whole other kettle of fish. Um,
you know, when you look down, I mean, again, the, the continuum is really helpful. Like,
you know, people say, uh, that doesn't have any free will. It's just a machine obeying physics.
Well, if you look at a paramecium, what do you see at a single cell of the organism? What do
you see? You see chemistry and physics. You don't see any magic glow. And so, so some people will
say, you know, so that something you can go to, people go in a couple of directions, right? So
some people say, okay, the paramecium has no free will or whatever. Uh, but I do. And so now
you get a real problem because you were a single cell organism once you, you were a single cell,
right? So, so where did it show up at what point? Nobody has a good story of where it shows up.
That's one way to go. That doesn't work. So, so then some people go the other direction and they
go, uh, okay, fine. The paramecium does have this, this magical, uh, whatever, because it's a living
being and then machines will never, well, if you look inside, right, if you actually look inside
a paramecium, what do you see? You see a bunch of little, little cogs and wheels and things that
grab onto each other and things that obey, you know, the various pieces of physics. And
that's about all you see in there. And there's nothing right now, we can't make one from scratch,
but come on, there's no reason why at some point, right? Usually in the field of active matter and
all of this, it can make things that do that. So, um, I really don't believe that, uh, these
binary categories are helping us. I think for all of these things, the question is,
what kind and how much, right? So, so when somebody says, um, uh, you know, is it intelligent,
is it, is it cognitive, whatever, I don't like the yes or no, I want to say where on the spectrum
is it, how much and what kind, what kind of problems, all the capacities, what, how big is
its cognitive light cone, right? That was the paper before the tape paper talked about, um,
this notion of the cognitive light cone, which is the, the spatiotemporal size of the biggest
goals you can pursue, right? So how big is your attempt, how big is your light cone in what
space is it? What, you know, is it, is it in metabolic space, is it in physiological,
in three-dimensional space? Like, where is it? Um, that's what you really need to know. The
binary categories don't really, you know, don't really, uh, don't really help you much.
But wouldn't, uh, like civilization, I mean, uh, the purpose of civilization is basically to,
uh, ensure, uh, humanity's survival. Wouldn't, wouldn't civilization self basically
legislate that humans would be prioritized over every other, uh, general intelligence?
Um, well, there's more of a legal thing. Yeah. Yeah. Well, the, I mean, right, the legal system
is going to go crazy. I mean, it already has a million problems because of, you know, uh,
the, the, the Twinkie defense and things like this, where if you, if you really follow through
neuroscience, you know, the question is, what, what, what, what does it mean that this person
could have done otherwise? Well, what exactly does that mean? You know, given, given, given
a kind of a material, uh, holistic view of, of the brain. So, so the, the legal system already
has issues, but the human, the issue of having, of prioritizing humans suggests, uh, that we have,
again, uh, this kind of binary category of what a human is. So, so I think to a primitive,
to a primitive, uh, early human, somebody like us, we've got, we've got some glasses,
we've got some hearing aids, we've got some, um, you know, some shoes, we got a toothbrush,
we got maybe an iPhone in our pocket to them. You're not a human. You're, you're a walking,
uh, you know, um, multi system, uh, some kind of a, like, like you're way beyond what a human is.
I don't know what, you know, you got all this other, other stuff. So, so just be, so, so that,
and in the future, plus also a brain implant that gives you direct access to, you know,
to a Google search and some infrared, you know, eyes at the back of your head, like,
so, so what, are you no longer human? So, so that, uh, you know, that's, you know,
of course going to be argued in court. Somebody's going to say, listen, I may have tentacles
and I may have a wheel or two, but what's wrong with me? I, you know, how come I'm not human?
I have the same, you know, so, so that, um, uh, and that, of course, also has been dealt with,
with science fiction a lot. Um, that brings up the question of, so, so what is an essential human?
Like what, what is it to be, to be a human, right? What, what do we want out of that?
So let's run down the list. So is it the genome? I don't really care about the genome per se.
Like that's, you know, some of these things, the thing to me is that like in, in pre, in
pre-scientific times, you could have held the view that we are a, a, the pinnacle of creation,
whatever we have in terms of our bodies, limitations, capabilities, our IQ, our lifespan,
our, um, capacity for, for, for, for, um, compassion, whatever it is, those limits were
set to us, uh, set by, by this like benevolent process and those are the best they're going to be.
Okay. So, so we're out of that garden of Eden now and now we realize that that's just where
evolution left us. That's all. There's nothing, there's nothing magical or, or optimal about
where we are. I don't believe, I think that, uh, evolution is this kind of like meandering,
uh, sort of search process and it happened to, to find that this particular form is good enough
to survive and leave a bunch of offspring. Well, that's great, but I don't see any reason we have
to stay that way, that it's arbitrary. And I, I like this, this notion of morphological freedom.
I think, I think each of us, uh, doesn't, doesn't, it owes no allegiance to this random process that
happened to have dumped you at this particular IQ level with this level of, uh, of, of, you know,
damage or birth defects or whatever, whatever you've got. So, uh, that means, do I care about the,
keeping the genome pure? No, I don't. Do I care about keeping the anatomy pure? We gave that
up when we started using canes and, and glasses and things like that. I don't really care about
that. There's nothing magic about this anatomy. I'm, I'm not, I'm not trying to keep that, um,
preserved. Uh, what I do think we have that's kind of fundamental is, uh, is, is in particular the
cognitive, a minimal cognitive light cone as far as compassion is concerned. So what I mean by that
is the moral ability to actively care about some degree of other, some, some, some quantity of
other beings, uh, well-being, right? And so that I think is what, that level is what makes us human.
Now going up beyond that, fantastic. Bring it on. Going down below that, I don't think that's good,
right? That's, that's, that's what I would argue against. So I would think that modify away, change
whatever you like to, to, to give yourself a better life to do, to fulfill your, um, uh, okay, you
know, fulfill your potential. Uh, just don't reduce your capacity for moral care. In fact,
you should increase it. And this is, this is an argument that we made with, um, a few colleagues
when we wrote that, that, that Buddhism paper. But, but the idea is so, so, so that's, you know,
that's what I'm interested in as far as humans. I'm not interested. I don't care what the genome is.
This is, all of this is completely arbitrary to me. Uh, uh, how, how our genetics ended up,
how our morphology ended up, you know, whatever, let's improve it. But, but, but, but that, that,
that cognitive light cone with respect to the compassion for others, that's gotta,
that should only increase. I don't think we should.
Okay. So your vision of the future of a civilization is that the citizens of that civilization would
have a minimum light cone, so to speak, compassion light tone. Anything below the minimum
compassion light cone disqualifies you from citizenry. So that's what we have. That's kind
of what we have now, right? So, so if you're, you know, if you're a dog or if you're, you know,
whatever, like you have certain protective rights, but you are not a full, uh, sort of member of,
of society, right? And it just so happens with, like, I think, I think one thing is that, uh,
we are, we are kind of special on this planet in the sense that it just so happens that there's
basically one dominant species. Didn't have to be that way. Imagine that there was another
dominant species that was like, I don't know, 40 IQ points lower. Like that would be a really tough
case, right? Because, you know, um, not low, not like, not low enough that you could just say
animals, but also not high enough that you want them running a nuclear power plant or flying
airplanes. What do you do? Like that would be really tough. We're just, we're just fortunate here
that there's such a gulf, right? So we could always say, oh, look, you know, there's this
category, but he didn't have to be that way. So I see, I see a future where we look like,
one of my favorite scenes is, um, the Star Wars cantina scene, you know, where, uh, where, right?
The with is like every kind of alien, every kind of robot that, you know, things are on wheels and
playing instruments, running around. This is, this is what the future looks like to me. I think that
as long as you've got the light cone to, to participate with a degree of responsibility
and compassion for others, you are part of the society. And then whether you've got wheels or,
or you decided to have tentacles or a propeller on your head, that's, you know, that's going to be,
I think those kind of people in the future, right? The future people are going to look back
on us and they're going to look at all of our wrangling about, uh, about gender and skin color
and prosthetics and, and all of this stuff. They're going to laugh at this. This is going to be
like hilarious. There's going to be such, such variety of embodiment at some point where, where
you can pretty much live in whatever body you want to live. You can have more IQ. You can have a
different kind of perceptual system. Um, this is all of our wrangling over this stuff and, and what's
a human and it's going to be laughable. And, uh, you know, that's, that's one reason, um, I really
like, uh, you know, the, the Star Wars, the Star Wars vision is very much like that where,
you know, the friends will all the droids and all this, the, the, in Star Trek, it's kind of,
kind of different at which I find just horrible. They, uh, it's whatever the year is supposed to
be 2,500 or something, 2,400. And they're still, they're still arguing about what commander data
status is. Yeah. This guy, you know, he serves, he serves on the enterprise. They're still arguing
about whether, you know, what his, what his deal is hundreds of years later. I think, I think
that's ridiculous. I think that, uh, you know, within a hundred years from now, maybe sooner,
all of this will seem, assuming we're still alive and we haven't like blown ourselves up. I think
all of this will be, will be hilarious to, to, to people of that time. But to have a civilization
that accepts that kind of diversity, you would have to have some sort of, um, guiding principle
that says, okay, it's not acceptable to have a, just single, uh, general intelligence, but
we're going to accept all these kinds of adversity. I think we're, I mean, I think we're
well on our way, right? I mean, the principle, if I had to boil this down, I would say,
I would say you want to relate ethically to someone no matter what they look like and where
they came from. Does that seem radical nowadays? I mean, it used to seem radical nowadays. That
doesn't sound so radical, right? And when I say where you came from, I mean, were you evolved,
were you engineered, there's some combination of, I think that principle would, would the,
would the young people of today do what you think they, you know, they don't find those two
things. They don't find that particularly weird. This is, I think, I think they just, I just think
people haven't, haven't fully figured out what it means yet, but society's already going that way.
You're not supposed to treat people worse because of what they look like or how they got here. We
already know that. Right. But the fear of AGI is that this other general intelligence, which
could become superintelligence very quickly, would be a threat to our own existence.
I mean, it's not, it's not impossible that we engineer something. I mean, we did it, we, we,
we put, you know, leaded gasoline and all these other horrible chemicals and a hole in the ozone
layer. We did all this stuff to all, you know, that could potentially kill us all off without,
without any agency in any of these things. You know, we, you know, we're all walking around with,
with high levels of lead in our bodies because of all the leaded gasoline. The lead doesn't have
much agency. It wasn't trying to kill us. We were just idiots. We did it to ourselves. And so,
you know, could we, could we engineer software agents and put them, put them in charge of
important things and have failure modes that we never anticipated and that screws us over?
I think it's possible. It isn't going to be because of the intelligence. It's going to be,
it's going to be because of our intelligence, not because of its intelligence. If we, you know, yeah.
