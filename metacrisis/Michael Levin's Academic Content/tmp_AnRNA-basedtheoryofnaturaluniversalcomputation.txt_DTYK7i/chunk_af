is a man-made construction.
But I guess there's something about that that just
doesn't sit well with me.
I completely agree.
But I'm saying maybe universal Turing machine
is a machine that is very, very sensitive in terms
of input and output is not like analog computers, which
analog computers are much more robust in terms
of definition of all the input range and output range.
And you can decompose and compose more parts on that
and which universal Turing machine,
you require lots of definition and a lot of interface
in order to define exactly the input output of each one
of those machines.
So maybe that's why biology is not doing this.
I don't know if my intuition agrees with that.
I feel like my intuition is that digital computation is
much more robust to noise, especially
because it can deal with issues of noise
at the algorithmic level.
Like you can have checksums and stuff like that.
And the nature of a digital computer,
there's discrete attractor points for bits and things
like that.
I don't see the advantage of analog computers,
especially in terms of robustness to noise.
But I agree in terms of complete noise.
But in neurons, for example, there
are sometimes spontaneously spikes.
They create a lot of noise inside the mechanism itself.
That's an assumption, right?
We don't know what those spontaneous spikes are.
They could mean something.
And we just haven't discovered what the code is.
Especially, it doesn't contradict this kind of model
to see spikes that we can't explain.
Right, yeah, I understand your point.
It's not a question.
I just want to hear what you think about it,
unless you're not done, Hannah, now.
I don't know if I have seen anyone directly say this,
but I could be very wrong, because I'm bad at reading.
So often when we search for universal computing systems,
you take a system like this RNA idea and say,
ah, this could do universal computation, so we're fine.
Could it also be, though, or if we go back to the Moore paper,
you have a dynamical system that does not
have structural stability, so this is hard, blah, blah, blah.
But it could be that you have many different subsystems
that then, in and of themselves, as an individual system,
are not that.
But when coupled together, they could be.
So could you build a universal computer?
It's out of pieces that are not universal computers.
Like, you put neural activity on some of these at some point.
So maybe neurons in and of themselves
are not universal computers, nor are LFP fluctuations.
But when you couple the two things together,
when you combine them, they can then
do universal computation.
So instead of looking for one individual system that
can be this thing, maybe it's wiser,
or has anyone thought about this, or have you thought about this?
Could it be that you only find this
when you couple things together?
Like, a tape doesn't have to be a tape.
What if the tape is this, and the head is this,
and then the computation says, if you couple things together,
it might be that system A, when reading from systems B and C,
is all of a sudden universal in a given context.
But in another context, it's not, because it needs to decouple.
So I imagine, in my head, at least,
that you have multiple dynamical systems coupling
and uncoupling from something that, when they're
coupled a certain way, they're universal.
When they're not, they're not.
And what do you think about that?
Is that insane?
Yeah, yeah.
Yeah, I totally get it.
So I don't know of an example of this, where you have,
I don't know, you can put LFPs and something else together,
and then suddenly it becomes universal.
But I think tangential to your point,
you could use neurons to construct
a universal computation system.
It just wouldn't be a traditional neural network.
So for example, to give you an example of how it could work,
you could simulate cellular automaton,
a similar automaton system, with neurons.
And people have come up with models for that.
And if you have the right update rules for your cellular
automaton, you could achieve universal computation,
like Conway's Game of Life.
So it's not that neurons in themselves,
they can't reach this level.
It's just, you have to come up with,
you have to explain what the system is.
The difference between that system
and what we conventionally think of as neural networks
is there, with a cellular automaton simulating model,
when I say my network solves addition
or solves this problem, what I mean by my network
is like an additional activity pattern.
I'd be saying, OK, this on, this on, this on, this off,
this off, this off, this is the solution to addition.
And this can be embedded in a neural substrate
of arbitrary size, or unbounded size, or whatever.
And if it runs out of size, you can embed it in a larger
network, and then it'll compute the problem that you want.
But when people say neural networks,
what they typically mean when they say,
hey, this neural network solves this problem,
is nothing like that.
But what they mean is a set of precise weights,
the actual nodes, and the activation functions to put them
together, create a neural network,
that's the thing that solves an input-output function.
And that's what I'm criticizing here.
That doesn't, as far as we know, that
doesn't arrive at the level of universal computation.
But it's very possible to imagine it happening,
I don't know, with neurons, or even with at the cellular level,
like, you know, implement cellular automaton
using just single cells that aren't neurons.
It's just, it's just, I,
