important point that Chris was was saying about the environment. If it's just you and the desert,
the environment is a very low agency thing, and then you can assume that you're the boss,
you're learning, I'm deciding what I pay attention to, I'm learning. If you're in a social milieu,
and you're learning, it could well be that you're actually being trained, right? The partner on the
other end is a high agency thing, maybe higher than you, and maybe you're, maybe you're being
exploited. And so, right, somebody said, I forget who it was, but somebody gave a talk on how to
give talks. And he said, he said, every act of writing is a violent act, because what you're
hoping to do is to change the listener's cognitive structure, right? Your success means I've reached
in there through my signaling, and I've, you walk away from there altered, you believe things you
didn't believe before, that's a successful talk, right? So, yeah, anyway, so that's what I think.
So, I think that threat from hacking is maybe what drives, I wanted to show you guys a cool
picture. I mean, this is something else I've been obsessed with. Where is the, oh, here it is.
Check this out. So, this is, you see this thing, this is a gall formed on the leaf by,
what happens is this wasp embryo induces the flat green cells of the leaf to form this crazy
thing. This is what we're up against. This is, right, is if you're a cell that's smart enough to
form a leaf, you're also subject to hacking and being made to make something completely different,
right? And that's the arms race you're in. And now every single that comes in, I think,
you now have to decide, is that me changing what I do, or is that somebody changing me?
So, I don't know that that probably has various psychological implications too.
You know, where threat is threat level is somehow proportional to a sense of ego separation,
as I mean, I'm out of my, you know, pay grade here, but there's, you know, something like that.
So, that gets into the thing I was going to raise. Oh, do you want to say something?
Go ahead. Oh, okay. So, I raised this issue of defining a thing, which gets sort of to your
paper about objects. And that was one reason I was so interested in the goal versus attractor thing,
because the goal seemed to me to require an internal representation of some sort. Whereas
the attractor does not. And then Rodney Brooks, for example, with his robots is maintaining
that there isn't any internal representation. And just speaking for myself, I'm pretty sure I do
have internal representation, mental representations. And so, and I think that's a key part of
cognition. I'm happy for Rodney Brooks's computer robots not to be cognitive, but
you know, we're interested in that question. So, then what is it? And so,
Frank Forster got me thinking about things years ago. He had lots of little pieces to the problem,
but I think never put his finger on how to put them together. And the thing that occurs to me
for things, you know, you tend to define a thing you think about the edges and so forth.
And I think what it is is actually a little different. You have a list of properties.
And then you divide that list of properties into two columns, those that are essential,
which I call specified, and those which are allowed to change without you saying it's no
longer the same thing. I call those substitutable. So, that lets me take off my hat or put it on.
It lets an apple to have a drop of water on it, and it's still the same apple. My dog,
my daughter's dog, has trouble with the hat thing. If I put on a hat or if I put on a mask,
I get barked at. But so, I think that's the primordial cognitive distinction
that you make is the separation to specify and substituteable. And then one question I had
for, well, and one place that went is, okay, if you do that, now you can start out with Percepts
and build up this hierarchy of what I call constellations and things which can now change.
Quantum mechanics is full of things that only have one property and so they can only be created
and destroyed. But as long as you have both columns, things can now change, and you can
just build up this whole cognitive thing. And then one day I wondered, gee, I wonder if language
works the same way, you know, in the same hierarchy. And to make a long story short, but I can show you
because it doesn't take too long. If you say, okay, that's how language works. And if you have a
template that's a lot like the genetic reading frame, you know, which, you know, like three codons,
you know, codons to three bases, there's a similar thing for natural language. You can write,
well, I didn't write, a friend of mine wrote,
a three megabyte program that parses human language. I could talk about that in a minute
or show you if you want. But with regard to the thing issue, you're pointing out and you pay,
I have to read your paper a couple of times, Chris, the one on objects. But this issue of
superposition, it seems to me that before you can talk about an external thing, you have to solve
this superposition problem. And I didn't quite understand how it got resolved. But one thing,
again, that Heinz used to emphasize was, you've got two eyes, two ears, they're giving you
conflicting signals. So if you have two measuring instruments, does that solve the superposition
problem? And let you talk about an external object. Well, let's see, let me say several things.
One, your distinction between constant and variable properties of objects
is what we refer to as reference and pointer degrees of freedom in our work.
That's physics language that comes from the pointer on an old voltmeter or something. That's
the thing that moves that you're interested in. And everything else you're not interested in.
It's just what lets you identify the instrument. And physicists tend to ignore the non-pointer
variables, which I think in large part is responsible for the quantum measurement problem.
As a philosophical and theoretical issue,
because if you have to identify the system, it clearly can't be in a superposition of any
of your identifying variables. If I identify my laptop by its position on my desk,
then it can't be in a superposition or I'll never identify it.
That's my criterion. So the superposition has to be in the pointer variables?
You can only see superpositions in the pointer variables
by definition. Yeah, that's nice. So in a sense, as you were pointing out for elementary particles,
you do have to have two measurement instruments or reference frames or concepts or whatever
you want to call them. They do have distinct semantic roles by definition. So they aren't just
syntax. And one of them has to be a reference that you keep fixed
in order to identify the system. And the other one you can allow to be variable to get some
interesting information. I mean, the system having the properties that define it
is not interesting information. The system being identifiable or not is interesting information.
Right. Okay. If you look at things like electrons,
identical particles of any kind, we distinguish them by spatial position,
which if you take a field theoretic perspective is a completely artificial variable.
Now, they're in fact identical things and the fact that we think that one of them's over here
and one of them's over there from a field theoretic perspective, these are just field excitations.
Okay. So there's no such thing as a distinction. You just have two of them.
So, yeah, I think this is all very much on the right track from a physics perspective,
that when one has to include these kinds of distinctions in a description of the physics
itself, or you get things that don't make sense, like the measurement problem.
Is that still considered to be not understood?
Oh, yes. It's very much, I think everything I'm saying is very much a minority position.
Yeah, most people don't talk about system identification in physics at all.
Engineers talk about it every day. Oh, really? Physicists tend not to talk about it at all.
Oh, I see. You mean the engineers saying, okay, here's the one box, here's the other box,
and they talk to each other. And here's how I tell them apart, and here's how they tell each other
apart. Right. And the physicist is saying, well, okay, here's the needle, but never mind the housing
and all the rest of that. Right. Yeah. You'll see papers that say that explicitly.
There's a famous, there are two very well-known papers by Max Tegmark at MIT
that talk about decoherence. And in both of them, he uses exactly the same diagram,
which splits the universe up into three pieces, the part of the observer's mind
that observes the pointer state, the pointer state, and then everything else, which is the
environment. So, that's the whole object identification process just into some feature
of the external environment that we won't talk about.
You know, I love the distinction, things you can change and things you can't change,
and also telling things apart, because in biology, I think what we see is it's like
the ship of Theseus business, right? So, in a body, what varies? Well, all the molecular details
vary all the time. Molecules come and go. In fact, cells come and go. So, you have to have a system
that stays the same. So, what stays the same? The higher level system stays the same. On the
lower level, nothing stays the same. Everything is different within a couple of years. You're
all swapped out, as I understand. So, this leads to a couple of, I think, interesting things. One is
that in a cognitive system, you have a similar scenario where, if you're going to be a coherent
mind, what comes and goes are different thoughts. You don't want to be different every time a new
thought comes in. Well, that's it. Now I'm done. So, you have to have some kind of stable structure
that can persist, despite the fact that new thoughts, new experiences, all of this is going to come.
But something has to stay. There's some kind of higher level structure has to stay. So,
this question of what are we invariant to and how do we tell the difference? So, when I see you,
I'm not a Laplacian demon who says, well, that's not, Doug, because all the atoms are wrong. So,
that's it. I'm fooled. No, I ignore the microstates and they say, no, that's definitely you. And then,
cognitively, this is the same thing. Even though you've had a million thoughts and maybe today's
thoughts are different than yesterday's thoughts, we can still sort of recognize each other.
So, I think that's interesting. And then, going back to the pointer thing, another thought at the
physics instrument, I wonder if the reason why for physicists, everything is sort of bottom up and
low agency or zero agency and mechanical is because all their tools are. And right, the voltmeter
and things like that are very low agency things. So, of course, they only measure the microstates
of things. You need a completely different apparatus like a brain or an artificial neural
network or something to detect these high level invariance like a being whether a body or a
cognitive being that does not change when the parts swap out, right? So, physicists have no,
there is there's no apparatus that you have that will detect these virtual these large scale virtual
governors, right? You don't you don't see that all you ever see is microstates because you can tell
me if I'm if I'm wrong, because because what you're using is apparatus that always looks down at that
level. But but for example, you if you're a biologist, you can use a different apparatus that's
very good at detecting these things, right? So, so the brain is really good at detecting agency in
the environment, it skips over all the details to that extent and right. And so you use a different
anyway, that's that's that's that's where I, you know, my mind went for the stuff.
That's nice for two things. One is, for the physics instruments, they're simple like that so
that you get an unambiguous result. If it measured 10 things, you'd never really know
what you had measured because you got some function, your output is some function of 10 things.
Conversely, I realized as you were speaking, that we never ever, we always say, gee, I had a thought,
we never say my mind changed. So these thoughts are something we project into something external,
even if it's inside our head, it's external to me. Well, that's an interesting question,
right? Can you so so we have a feeling of we all sort of have an innate feeling of free will
normally. But we know you cannot control the next thought that you're going to have.
It, whatever pops up is what pops up, you have some sort of long term control in the sense that
you can undertake practices that will change the statistical distribution of future thoughts you
are likely to have, whether by education or meditation or whatever. So, you know, you sort of
have some hope of long term changing the ensemble of your thoughts, but you have no hope of controlling
what your next thought is going to be. And actually, this goes back to the other thing
about you saying that you had representations. So I also feel like I have representations. But
for example, Nick Chater would tell you, you don't have representations, right? So he wrote this
this interesting book called The Mind is Flat. And so, and Mike Kazanaga has a model of this too,
that where basically, there's a part of your brain that does things. And then there's another part
that tells stories about why they happened. And right. And so he would argue that, and I'm not
saying I go all the way with him, but the argument is that the deep underlying stuff is a
post hoc sort of story. And that basically, you know, and you've got experiments. So here's a
simple experiment. And there's a video of this on YouTube. It's an old experiment. There's an
electrode in the brain of somebody who I think was being treated for epilepsy or something.
And it happens to be in a center that makes him laugh. So when the experimenter pushes the button,
the guy starts laughing. So he's sitting there thinking about something serious,
the experimenter pushes the button, he starts laughing, you ask him, hey, why are you laughing?
The answer is never, I don't know, I was thinking about serious things, then my mouth
starts suddenly laughing. That's never the answer. The answer is, oh, because I thought of something
funny. That's always the answer you get. So this confabulation, right? So we're definitely good
at telling stories, post hoc about stuff that happened, whether that's all there is, I don't
know. But but some of it is, I think some of it is some of that. Daniel Dennett had a little bit
of a story sort of like that, that's making up stories about what your brain's saying. I mean,
I could buy that one thing that the brain top level does have to do with regard to the things
and say that all your agents are down in your joints and the robots or wherever else.
Or even if the various properties that I'm assigning to a thing, one of them comes from
the visual part of the brain, another one comes from the tactile, somebody has to say, oh, well,
I'm going to say those properties all belong to the same thing. Somebody has to do that. Otherwise,
it's just your different joints doing whatever they do. And so that may be what the top level guy up
here is doing. Well, I think Dan would say, I think Dan would say there is no binding problem
because there is no binding. I think he would, I think he would say that it seems like there is.
Now, now that brings up another question of seems to whom, right? So so I don't know, that's that,
that's still I still find that a little tough. But but but but but he's been battling for years,
this idea that there is any executive control that binds it all together. And basically,
basically saying that, yeah, it's a set of parallel processes, which occasionally sync up
with each other long enough to tell a coherent story. But mostly, it's, you know, just independent
modules that do stuff. Hmm. Interesting. I didn't know it was that extreme.
I mean, there is that extreme view that, you know, who knows where the truth is, but
interesting. So there is, there is also a lurking ambiguity in the use of the phrase of the term
representation that that that comes down to the question of representation for whom.
You know, take take a story like shaders, which which I do think he has a lot of it.
Correct. You know, this this meta processor is constantly for some of the time, whatever it
needs to constructing some story about what the brain is actually doing, what the organism is doing.
And it, it does that in some kind of representational language.
For example, self dialogue, in the case of humans.
And nothing in the lower level computations is using that particular representation for anything.
However, the low, the lower level processes are full of representations that they are using.
And so, you know, for example, retinotopic maps in the visual system are representations
that are very straightforward sense. Some matter, sensory systems have representations
of the body in a very straightforward sense. And those representations are never
accessible to the to this meta processor that's telling a representational story about what the
brain is doing. They're only accessible to neuroscientists, for example, or other levels
of the low lying cognitive system itself, right there. The representations that the brain is
using, but they're not representations that we can talk about in our own case.
So, and, and that's what's super interesting. This, this idea of representation to whom
is really interesting. So, Josh, bond guard, and I just wrote this paper on
poly computing. And the idea is, is there an objective story, an objectively true story
about what a given algorithm is computing. And so he's got this really cool data paper where you
can show that he's got some sort of poor, you know, a porous medium that if you look at it one
way, it's computing one logic function. If you look at it a different way, it's compute the
