stimulation evidence, the functional imaging and the pharmacological manipulations.
On the basis of all of that, I think it becomes more reasonable to speak of these structures
actually being where affect is generated.
It doesn't mean that they are the only structures involved in affect because what they are modulating,
what those arousal systems are modulating is everything else, you know, so they are modulator
systems, which means they're modulating something.
But I think that it's, it's not just a matter of critical of a disruption at a critical
site of a complex functional system.
I think it's a little more interesting than that for sure.
I'd love to get your thoughts on, so Richard just asked a really interesting question.
Well, you made the point that the fact that this particular piece of neuroanatomy is required
for it doesn't mean that that's where it lives.
I'd love to dig in and see what, what does it, what would it mean for some to actually
find the place where something like this lives?
I'm not even sure, you know, what does a positive control for that kind of question look like?
Because, you know, the logic, like we understand the logic, that's not, you know, what the
logical issue there is, but what would a proper answer to that look like?
Because I'm increasingly, you know, and here you get into maybe issues of representation
or whatever, but I'm increasingly becoming convinced that we need to change the way we
think about that question entirely.
As people ask me, you know, where does the information for the Zanibat live and things
like this, you know, where.
So this, this, this issue of things being encoded and specified and represented, you
know, I feel like we don't have actually the right framework for this.
And I'm just curious what, what you think a good answer to that would even look like.
Are you asking me that, Mike?
Well, both of you, I'd love to hear you discuss it.
I'm assuming you think it's a question.
I'd love to hear you talk about it.
So I mean, you could go from the, from one extreme, I mean, like the most profound level
of trying to answer that question, which I won't dwell on because it's above my pay
grade would be, you know, the relational interpretation of quantum mechanics.
It's all a matter of interactions of correlations.
But sticking with what I know, I would answer that by, by reference to the, the, the, the
functional architecture that we are building in that artificial consciousness project.
So are we building a thing with, you know, that that's drops with consciousness in a
center or, or, or, or, or something else.
And of course, it's something else.
So it's a, it's a system that has survival means in the sense that it's, if these quantities
are not kept within viable bounds, the system ceases to exist.
So it's a, it's a homeostatic.
It's a system that has to satisfy as it, as it happens in the one we're working on now,
three needs, which are not orthogonal to each other, but which, which conflict with each other.
So there's a need to prioritize these different needs, which importantly means that they are
categorical variables that qualitatively distinguished from each other.
So the way I think about it is these are, these are valenced.
These are, these are system.
This is an intrinsically valenced mechanism in the sense that there is a goodness and
badness from the point of view of the system, that the goodness and badness only applies
for the system to the system.
What I'm referring to by valence here is that increasing free energy just is bad for the
system from its point of view, because the whole purpose of such a self organizing system
is to continue to exist.
And so it's not only a matter of minimizing free energy, it's also a matter of minimizing
free energy across different categories, which are qualitatively distinguished from each
other.
And how does it do that?
How does the system minimize its free energy?
And it does so first of all, by monitoring all three needs states, in other words, prioritizing
them.
And secondly, and more importantly, in relation to your question, what it's modulating, what
it's using the quantity, these free energy or these factorized free energy quantities
to do, is to optimize its confidence in its current policies.
So a policy which is leading to increasing free energy, or as in terms of that formalism
we're using increasing expected free energy, that is a policy in which it loses confidence.
And importantly, given that I'm talking about affect, it's a policy that is bad for the
system.
This is bad for me existentially, the consequences of my current policy unfolding before me.
And so I reduce my confidence, I lower the precision in this policy, and simultaneously
of course increase the precision in the error signals, issuing from it.
And on this basis, it shifts to a new policy.
So although we're talking about affect in an artificial sense, when I say it's balanced
and it's qualitatively distinctive, that is applied to its active and sensory states.
That's, there would be no purpose in feeling that this is going well or badly for me.
By this, you're referring not only to your current state, but to what you can do about it.
So it's the application that if I sort of may anthropomorph or biologize it, it's
affect applied to deception and cognition.
And then of course learning flows from that to come to your area Richard of great interest.
I mean, that's the basis upon which a very important form of learning can occur, namely
learning within your own lifetime rather than by natural selection, what worked stochastically
and didn't a great expense to large numbers of individuals over that period of time.
This type of learning enables you to learn before it's too late and change your mind.
In other words, adjust your policies and formulate new policies.
So it's a system wide thing, Mike, but each component part of the system is of course
playing its own role.
But you can't, it couldn't play that role if it weren't for its place within the system
as a whole.
But maybe I'm answering your question too stupidly because you guys have come here to
scientists and you know, as I keep telling you, not my field, but that's the way I think
about it.
Mike, can you remind me how you formulated the question?
Yeah, so people often when they see a particular outcome or functionality, the number one question
people always ask is, where is this recorded?
So naively, many expect it to be in the DNA somehow or, you know, where it comes up for
me all the time is shape and behavior.
So, you know, we'll make some sort of a crazy looking thing or a Xenobot or something else.
And people say, okay, great, well, where, where was that written down?
And so, and I keep saying, well, DNA, nothing, no anatomy is written down in the DNA ever.
And so they say, okay, fine, well, then where does it come from?
And I think what they're looking for, and to some extent, it's funny because to some
extent, our work actually offered, has answered some of that in a much more traditional sense
than what's been going on, which is, you know, the standard story is emergence, right?
That it, well, it's nothing's written down anywhere that it's emergence that the local
rules, the lots of things obeying simple rules and voila, you know, something complex.
And so, well, nothing's written down.
And so, and so we've actually found that no, actually, there are biological patterns that
literally a presage and encode what's going to happen later, right?
So we've actually found some of these things, but more fundamentally, I think, you know,
this question of where is it, where is the thing encoded?
There's sort of thinking of a traditional representation, you know, some sort of data
storage and then an interpreter that looks at it and sort of, and some of that I think
does actually exist, but kind of more broadly, you know, I wonder if we have frameworks for
thinking about where do some of these things, what's a good answer to that question, you
know, because, because it naturally, it naturally comes up all the time.
And I eventually, I always eventually end up leaning back on, on mathematics and sort
of Platonic businesses, where's the distribution of primes encoded, that kind of stuff.
But, you know, I don't know if there's a better, I want to know if there's a better way to
think about it.
The, it's related to the, it's, it's, there's a pair of questions, perhaps it's like, where
are the symbols, which is like, where is it written down?
And why did the symbols mean anything, which is how are the symbols grounded?
And there's a, there's a back and forth between those two things, which is slippery and annoying.
Right.
So if you say too much about where it's written down, you know, like this is the gene that
codes for this, and this is the gene that codes for that, and this is the neural correlate
that generates this, et cetera, et cetera, then we end up with a sort of mechanistic
explanation, which doesn't explain the thing that we wanted to explain, which was the how
did that have any meaning, how did that produce consciousness, how did that result, how, what
was it that was doing the interpretation, was that some other machine that was looking
at this machine and all sorts of strange loops like that.
I'm just going to use this way I would.
And then, so that's the sort of, you know, let's, let's, I want to, the attempting answer
to the question, where is this written down is to point to some sort of symbol system that
is recording the information that describes how, how to do that, how that's written down
or what the meaning of it was.
But we also need those symbols to be cashed out into, as Mark was saying, something that
actually does something, that's something that's active, something that's connected to
your senses, something that's connected to your actuators, something that actually does
something in the world that matters to you, that matters to your ability to maintain or
sustain whatever behavior it was we were talking about, or your confidence in your understanding
of the world if we're taking a Fristonian position, or a change in policy.
And my, my feeling about that is that the, these are, it's like levels of description
that there are different levels of, of describing something.
But they're not just descriptive, they're also causal, so they're different levels
of causal frames of reference or something.
So there's a, there's a causal process going on at one level of organization.
And you point to that causal process that going on, you say, look, it's doing this.
And then you say, yeah, but why is it doing that?
Where did the information come from?
And you want, you need to, you necessarily need to step down a level to say, well, you
know, because, because what's that, what that's made of, made it do it, right?
You know, that's, that's just the way, that's the way that those components work when you
put them in interaction with one another.
So why did it end up doing this holistic thing and not some other holistic thing?
Or you want to, you, you end up with answers like, well, because those particular parts
in this particular arrangement couldn't have done anything else, and a mechanistic
understanding, but it's, but then you haven't answered the question of, but why were
those particular parts in that particular arrangement?
They could have been in a different arrangement and done something different.
And the, hold on, it's all, so swimming around a bit, which is perhaps appropriate.
My feeling is that to answer these questions, we need to have a framework where there are
multiple levels of organization, each of which is causal, each of which has a, a mechanistic
process going on at that level of description.
But there needs to be multiple levels of those, and they need to be connected to one
another so that they are not, it's not just that the, if they were too connected, then
the reductionist position would be sufficient of just saying, well, the higher level processes
were entirely determined by the lower level processes, and we don't need to talk about
the high level processes, then they're, they're, they're, they're, they're, they're
were entirely determined by the lower level processes, and we don't need to talk about
the high level processes, they're not really a thing.
Organisms aren't really a thing.
Evolutionary units above the level of genes aren't really a thing.
Mines aren't really a thing, et cetera.
But we don't want those.
So we're, I think we're okay in this small audience with thinking about higher levels
of organization have being causal processes in their own right when we think about them in
terms of error correcting codes and such like that there are, there are feedback mechanisms
happening at that level of organization, which are self-sustaining, which don't particularly
depend on the level of organization below.
So that's a, that's an escape from, from explaining away, right?
So we don't want to explain away these high level organizations, high level causal
processes, the high level causal processes are real in their own right at that level of
description, but we don't want them to be disconnected either.
So there's this slippery in between where we have high level causal processes, which happen at that
level of organization in their own right and are not entirely determined by the level below, but
also they're not entirely separate from the level below either.
Because we're interested in things like how the high level processes orchestrates the behaviors
of the lower level processes and how the lower level processes implement the machinery of the
high level processes.
There are connections between them, but they're not one to one.
And I think that as we, as you move between those scales, the level of indirectness increases
that
a bit like in the layers of a deep learning neural network, that the level of description
between one layer and another only has meaning in so much as itself consistent within that
layer and communicate something appropriate to the layer above and the layer below.
And as you go deeper and deeper in those layers, how the stuff that's happening on the output or
the output input feedback loop at that level, massively under determines what's happening in
the deeper layers of the network, but isn't, but what's happening in the deeper layers of the
network isn't completely undetermined or what's happening in the outer layers, it just gets more
and more undetermined as you go down in levels of organization.
