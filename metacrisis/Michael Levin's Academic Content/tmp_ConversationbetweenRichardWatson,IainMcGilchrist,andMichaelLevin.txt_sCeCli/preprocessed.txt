So I began okay. So I began reading the book but I haven't been able to finish that.
No, no, no, look, what can I say except that it's an enormous imposition to to read what I've written
because it's just so long. It's so not. But there we are. Yeah. But um, no, I'm just delighted
that you're interested really. And your interest comes from where exactly, Richard?
Well, I've been working on the relationship between evolution and learning. That's probably
the right place to start. Okay. So there's some old ideas that suggest that they are
sort of interchangeable processes, that that evolution by natural selection is a way of
doing one possible implementation of a sort of trial and error with reinforcement process.
And that what goes on in the head is likewise a kind of natural selection process that we're
trying out hypotheses and reinforcing those which work well. Yeah. But that that level of analogy
suggests that neither way of looking at it causes us to change our understanding of the system.
But actually, no, I think that there is an equivalence there, but there's also a disanalogy
there, which is really important. And not least, because, you know, we think of learning systems
as being clever and natural selection is being done. And at the same time as thinking that the
algorithm of natural selection is done, we observe what clever things it does.
So whereas, you know, with learning systems, we observe what clever things they do. And we
think that's not surprising. So if they're the same mechanism, either they should both be
surprising or neither of them should be surprising. So we need to sort of tease that part a bit.
Yes. I mean, one obvious answer to this would be to say that what we do when we're learning is
not as demanding and intelligent as it looks. But another way of looking at it would be to say
that actually the evolutionary process has intelligence. I mean, I'd be prepared to say that
without, you know, trying myself to the to the mast, to the mast of, you know, intelligent design
or anything like that. But there is some sort of something in this process is, I don't think you
can logically exclude it. Well, great. So we're starting on the same page then. So as per many
conversations with Mike, we often say, but you know, but intelligent systems are magic.
There are, you know, there are intelligent algorithms within machine learning, for example,
that although they might not capture everything that brains do by a long way,
they capture something more intelligent than the process of natural selection, as Darwin described
it. So can biological evolution implement things like that instead of an envariation and selection?
No, if the if if you can capture the principles of an intelligent optimization algorithm
in an algorithm in a step by step process, what are the necessary components of that to implement it
in a in some other substrate? Or I get generalized learning algorithm rather than a
the analog of generalized Darwinism, right, that you can do it in different substrates?
Yes, yes, I see. Yeah. And you're working on on that? Are you working on on finding
machine processes that could replicate this? Is that what? Well, having having as you just suggested
rather quickly come to come to the conclusion that evolution by natural selection wasn't going
to cut it. It wasn't going to explain the patient we observe. And then noticing that, you know,
learning systems do a more intelligent kind of optimization than random variation and selection
does. So we already know that there are adaptive processes smarter than natural selection. The
question is, our brain is the only thing that can do it, right? Or are there other kinds of
systems that can do it? So I've been trying to describe principles of, shall we say, intelligent
optimization, which could arise spontaneously in physical systems, in particular in networks
with connections that are viscoelastic or give way under stress. And that turns out to be enough
for a physical dynamical system to learn in a way which is smarter than natural selection.
That's extraordinary in itself. Yeah. So I was the reason that I was interested in
in some of the things which I heard in your discussion with Mike and the other things of
yours, which I watched later, this difference between the two hemispheres was that there appeared to be
a slight polarization between tendency towards inductive inference and deductive inference.
And from my initial reading, I might have got that the wrong way around between the two hemispheres,
but maybe that doesn't matter. But the thing that makes learning systems different from
our conventional understanding of natural selection is that learning systems do induction.
Learning systems form general rules from specific examples.
They also seem to do, before we come to hemispheres, but they also seem to do something else, don't
they, which is to respond intelligently to a never before seen situation for which they cannot
be as it were programmed. Exactly. I mean, this was first noticed by Barbara McClintock in the 80s
that a single cell could respond in an intelligent way to an insult that it could not naturally have
ever experienced. And yet it responded as a whole organism, not in a kind of an unintelligent series
of chain reactions. So that is itself very interesting. I think that when you come to the,
I mean, I don't want to rush on, but to the hemispheres thing, I think that in a nutshell,
although I've suggested that the right hemisphere does play an important part in deduction, I don't
doubt that the left hemisphere does too. And I think they both also rely on induction, but one
might have thought that induction was more something that the left hemisphere relied on,
because it's so alert to drawing lessons from experience. But it turns out that probably the
weight of the induction is in the left hemisphere, because it likes regularities, it needs regularities,
it is always looking for certainty. And that certainty to it comes from amassing enormous
numbers of instances where this seems to work. Whereas the right hemisphere is what Ramachandran
calls the devil's advocate, it's always going, yeah, but don't jump to conclusions, it may not
be like that. It's role is very strongly a kind of checking and in a productive way, a somewhat
adversarial stance towards just going, well, that swans have always been white, so they always will
be white. Yeah. So that point that you raised about responding appropriately to insults that
were novel, unfamiliar. So that's fundamentally requires induction. If you only need to respond
to things you've seen before, then you just need memory, you don't need to do induction.
But if you're going to extrapolate from things you've seen before to something you haven't seen
before, then you need to form a general rule from those specific examples, and then do something
deductive from that general rule for the new. It needs that element of deduction. And that new
element characteristically comes from the right hemisphere. It's the right hemisphere that tends
to be the one that both understands the new better and is more prepared to engage with a new
strategy than the left hemisphere, which tends to be very conservative. So the
a perspective, so yeah, it's interesting, right, because you can't tell that a system has done
induction until you ask it to use, it's that induced model to do another deduction, right?
You have to induce a model and then you have to use it. When you use it, you get deductively,
not inductively. So that it all gets a bit slippery when you think about things like, well,
if I've got some data and I need a hypothesis to explain that data, and I arrive at a hypothesis
to explain that data, have I done induction or have I done deduction? And the answer sort of depends
on what you think the starting point was. So if I gave you a set of hypotheses and said which ones
of these are consistent with the data, you would deduce which hypothesis was consistent with the
data. Now, you may then subsequently use that hypothesis for responding or classifying a
stimulus you haven't seen before, in which case, because it was a hypothesis that fitted the data,
it actually makes predictions that go beyond the data. But the way that you arrived at that
hypothesis and not some other was just by a process of eliminating the ones that weren't
consistent with the observations so far, right? So for example, if I have two hypotheses, all
swans are white or all swans are black, and from the data I've seen so far, all swans are white,
is the hypothesis which is consistent with the data, right? That's a deductive conclusion that
out of those two hypotheses, that's the one. But if I then use that hypothesis to predict the color
of a new swan, I'm using it in an inductive way. Inductively, yeah. But why wasn't the model,
so that feels like that leads Popper to say we should just do everything with deduction, right?
Even the way that we do everything is we'll eliminate the hypotheses which aren't consistent
with the data and then we'll never make a mistake, right? We'll never do something
wasn't supported by the data because deduction is the only thing I ever want to do and I never
want to do induction, that's bad. Stop it, right? What's missing there is why wasn't the hypothesis,
the first two swans are white, the second two swans are black, the third two swans,
you know, the next two swans are white again. Why wasn't that hypothesis in the set? Why wasn't
the hypothesis all swans are white except at five o'clock when they're pink, right? Why wasn't that
in the set of hypotheses, right? So the the initial set of hypotheses is always biased.
Yes, it doesn't include all possible hypotheses that were consistent with the data
and the set of it can't know it can't and if if even if in principle it could include all
possible hypotheses consistent with the data, that wouldn't have to include all the hypotheses that
predicted the next one to be white and all the hypotheses that predicted the next one to be
black, they're all in there. Though it actually doesn't make any prediction to do that. It has to
be biased in order to make a specific prediction. So that I think that you could you could understand
how it would be very slippery to determine whether a particular hemisphere was biased towards
induction or deduction because of this thing of well, if I was deductively eliminating hypotheses,
I'm doing deduction, but having arrived at a hypothesis from a biased set, ah, now I was
doing induction and those those two things are kind of they're at the very least they're slippery.
So I can see why in the text I was seeing lots of back and forth about well, you might think this
is going to be overdue. That's right. That's right. And that's why if you did have time to read
the chapters on the nature of reason, I think they would be more instructive, but I'm not
suggesting that you do. Sorry, I haven't already. Have to go to bed for a day or two.
But there's more there, but I just thought I'd send that along just really to show that
it doesn't neatly parcel up in some way that one might have thought it does. It's one of the
numerous areas that one finds that. And I think induction and what you've really
exemplified in what you've been talking about is that induction and deduction
are not entirely alien species that they need, they need one another. And it isn't possible to
do without one or the other, in fact, in living. And nor is it actually reason is completely,
this is a very much more important point to me, is somehow entirely devoid of intuition.
Reason cannot actually get above and behind intuition eventually. It has a certain
intuitions of its own. And in reasoning properly, we need to use intuitions and
intuiting correctly. We bring reason to bear. So these things are not these,
as they're often set up nowadays to be these two. And usually reason gets a tick and intuition
gets across. And there's this whole, no doubt, lucrative. Except in Star Trek.
Okay. I don't think it's out that Captain Kirk was right after all and Spock was wrong.
You'll have to educate me on Star Trek, I'm afraid. But no, I mean,
intuitions are bound up with reason, the good ones. And then they're certainly not
any more dangerous than reasoning if it has no intuition in it. I mean, the kind of reasoning
that is done by psychotic patients is absolutely impeccable. And as has been pointed out,
it's not that they've lost their reason, as we say, but they've lost everything but reason,
they can only reason, and therefore come to extraordinarily bizarre conclusions that anyone
who has experience of life will tell you it's not what's happening. So we need very strongly,
both of these things. Anyway, Mike, you've been very quiet. I'm sorry.
Yeah, yeah, no, but I'm greatly enjoying the discussion. The only thing I have to add so far
is that this issue that you guys were just bringing up of where did the models come from,
right? And what are the models before you can go ahead and sort of crank through them mechanically
goes back to the whole evolutionary aspect, which Andreas Wagner raises with this book,
Arrival of the Fittest, right? So once you have them, you can sort through them and pick the ones
that are most fit for a particular environment, and then you're good to go. But you need to make
sure that the good ones are in there somewhere. And so the whole thing has to be seen as some
sort of a generative scheme that is open-ended enough to produce these new solutions. And then
the question becomes, well, are they purely random? Where do they actually come from? Are they biased
towards ones that are actually going to have some utility, right, or the vast majority of them
completely useless? So I think that's a really interesting aspect of this. And back to this
issue of, you know, kind of the intelligence of the evolutionary process, I agree completely. And
I think the thing that is the move that's really important to make here is given to us by the field
of basal cognition, which is that back in the day, you really just had things that were mechanical and
dumb. And then you had humans and angels. And those were your two options, right? And so looking at
those two options, what do you want to say about evolution? Well, the scientists don't want to say
that it's sort of human level or above intelligence. So well, then I guess we'll have to say it's
completely stupid. But now we understand, right, especially through the field of basal cognition
that there's actually many options in between. And cybernetics gives us many different options in
between. And we can say that it doesn't have to be completely blind. It doesn't have to have an IQ
of zero, nor does it have to have some sort of grand superhuman level of intelligence. But it
can have some. And of course, this business of reacting appropriately to things you've never
seen before, yeah, we have many examples of this in developmental biology and cell biology.
And I think where it comes from is this idea that, and maybe it wasn't this way always,
maybe really primitive forms of life weren't like this, I don't know. But the life we have now
does not make too many assumptions. In other words, it's, I think, and this is a controversial view,
but I think that embryos and things like them, they're so plastic and flexible, because they
figure everything out from scratch every single time. In other words, it's not some weird unusual
thing when something novel happens and they somehow, you know, make up for it, every single
time they are, they come into the world, not really knowing how many cells do I have, what size
are my cells, do I have the right complement of genes, you don't know any of that, you have to
solve that. And so that, of course, makes you, if that's the architecture that makes you good
at handling novel things, I think what you actually have in these embryos is a problem
solving intelligent machine with a bunch of prompts. The prompts are maternal gene products
and cytoplasmic, all the stuff you inherit from the egg and your environment that isn't in the DNA.
Those are your prompts. And the prompts, both the prompts and the machine are evolutionarily
sort of shaped so that together they normally do the right thing. So all other things being equal,
acorns make oak trees and frog eggs make frogs and so on. But because of that architecture,
you can put in, and as we've done and other people have done experimentally, you can give
it different prompts and get completely different but coherent behaviors out of it.
And that's what I think, that's what I think gives it the intelligence is that
the assumption from the very beginning that you actually cannot, you don't over train on your
history, you actually don't know that anything you've seen before is going to be true now.
And you just have to figure it out from scratch. Where do my sort of borders end and the outside
world begins? What are the important things to pay attention to? Who is behavior shaping me? Is it
myself? Is it somebody else? Like all of these things have to be solved from scratch. That's
where I think the intelligence comes from. And how long do you think that process of not
knowing goes on? Because very clearly, they must build up stores of likely outcomes to certain
positions and actions pretty fast. Yeah, I mean, it's fast, but I think it remains incredibly
plastic. You know, the thing that strikes me about this, like you've seen this rubber hand
illusion. Yeah, the rubber hand illusion within what seven minutes, it convinces you that you
have an extra limb. How long have you had exactly four limbs, right? We've had exactly four limbs
from millions of years. You well know how many limbs you have. And all it takes is, you know,
a few minutes of experience to convince your brain that, oh, I guess all that was wrong. I've
got something else. And just that plasticity, the ability to override this, we see it all the
time. You know, if I make a tadpole with no eyes in the head, but the eyes on the tail,
they don't need evolutionary adaptation to use that eye. They can see out of the box
immediately. Those embryos can learn in visual assays. You get some weird itchy patch of tissue
on your tail. It's, oh, yeah, that's visual data. We know what to do with that. And by the way,
it doesn't come into the optic tectomy. It comes into the spinal cord at best. Yeah. No problem.
Now that's how we are. And so, yeah, I think they do make models from the start,
but I think they're incredibly plastic models. And even in adulthood with sensory augmentation
and sensory, you know, when they make, you've seen this stuff, when they give people a prosthetic
limb where the wrist goes all the way around, right? They find out that when people go to use it,
they do it that way. Well, you know, the way to touch a coffee cup normally, you know,
whatever. But this thing, yeah, they'll just spin the wrist, you know, a way that your wrist
would normally never go. And, yeah, that's why they can learn to do these things. So, plasticity.
So there's something. It can't be that it's figuring everything out from scratch with no
assumptions in each lifetime. But it also has to be incredibly flexible, as you say.
So, it feels to me like it needs to be a sort of not an answer, but an inductive bias.
No, not an inductive bias, but a meta inductive bias. Not a meta inductive bias and so on,
right? But it's a sort of, it's a really, really deep way of learning how to learn,
how to learn, how to learn, how to learn, that unfolds, you know, as you say, in the normal
conditions, it unfolds the same way. But that it has incredible flexibility as well.
And there are such things as instincts, which are apparently fully formed and operate from
the word go without any need to sort of find out, as it were, that this is what I need to do.
So that's, it's not a, not even, I mean, clearly we're not blank slates, but not even
behaviorally blank slates. So, surely it's a very mixed picture in which some things are
unquestioned and automatic from a very early age and other things must be
learned and adapted to, surely. But the source, where's the source of the,
where's the special source? Where's the source of the, of the bias, right? When you think about
reasoning, deduction and induction in an abstract way, in an algorithmic, logical way,
that's not connected to any particular machinery for implementing it,
then induction seems very mysterious. It's like, why on earth should I prefer the hypothesis that
all those ones are going to be the same color over the hypothesis that all of those ones are
going to be the same color until five o'clock and then they change, right? Why, why, why the
preference for one kind of hypothesis over another? But when you think about the fact that
the inference machinery, deductive and inductive, is machinery in the, in the broad sense.
And what you're asking a system to do is not to remember in a sort of
photographic way, particular instances from the past and recall them, but that you are
deforming that machinery by its experience. That intrinsically gives you some things that the
machinery can do naturally and other things that the machinery can't do naturally. And it gives
you some things which are sort of natural intermediates, sort of natural interpolations
and extrapolations is one example. But even in high dimensional spaces, there are,
there are intermediates that are easy to do with this kind of machinery and intermediates that aren't.
And it's only when we have this idea of logic being substrate independent and divorced from
the implementational machinery, it seems all very mysterious. But when you recognize that,
but whatever we're going to build, it has to be built through a growth process, for example.
And that's, if we're going to do it that way, then there's certain kinds of
hypotheses about what an adaptive phenotype would be that are more likely than others.
And if you've tried this and you've tried that and you need something in between,
as the situation you've never seen before, then there are going to be some in-betweens
which are natural for a developmental process and some in-betweens which are not.
And that's, it's, I guess my headline there is just it's
believing that inference is substrate independent that makes it mysterious.
Yeah. I want to go back for a second to this thing that Ian just said about the
instincts, the inborn instincts. And Aaron Sloman has been really pushing this
for a while, this idea of, you know, we got these birds that are born making these crazy
complicated nests and spider webs and so on. And so people are very sort of taken with this.
Well, how does it know to build a specific spider web? But actually those behaviors in
three-dimensional space are very analogous to, if you're wondering how the spider knows to
build a spider web, it's exactly the same question as how it knew to build a spider in the first
place. I mean, the genome no more encodes the, the genome no more directly encodes the architecture
of the spider web of the bird's nest than it did of the bird or the spider, right? You got exactly
the same thing. It's just, it's just your, you know, your behavior in morpho space as opposed
to behavior in three-dimensional space. But in all of these cases, it's kind of the same thing.
You've got these inborn, in fact, Giovanni Pazzullo and I talked about
developmental, like fixed developmental programs of the kind that you guys were just talking about
that are kind of like, these are the more, you know, sort of assumed things. They are basically
instincts of this, of the cellular collective intelligence. And yeah, it can learn to do some
other stuff, but it has some built-in building blocks that are, that are kind of very robust and,
and, and some of them are hard to overcome and some of them are not. Yeah. And, and, and, and, yeah.
You know, I was just going to say, that's good what you say. And it leads us to,
will it lead me not to a sort of a, an answer to a question. So I see, so it's not really any
different from how the spider's structure comes about. But then this is a huge question. So how
does the, the spider's structure come about? How do the rather intimate three-dimensional
structures, which are so different in every little creature, how, where are they stored? How
are they, where are they found? Where is this enormously complex three-dimensional information
to be found? And behaviors are even more complex because they are, they're, they're, they're in
four dimensions. There are things that occur over time in a certain order and in a certain
geographical space. So once one gets to this level, it seems that it's almost perverse not to say
there is some element here that is either guiding or, or shaping or directing. But, but I personally
don't know what the answer to that thing is. And perhaps you are getting closer to answering that
thing like I do. Yeah. Well, this issue, so people ask this all the time, right? So, so, so where is
the, where is the pattern stored? So, so I think, I think two things, two interesting things about
it. One, one is that the standard, where does it come from, right? So there's two questions. Where
is it stored and where does it come from? The question of where it comes from is also super
interesting because traditionally, people will say, well, evolution, you know, selection forces,
right? So years of, you know, eons of selection to be a good frog gives you, you know, gives you
a frog. But it turns out that actually those exact same cells can do something quite different
that that there was never selection for, you know, kinematic cell for application in, in,
in Xenobots has never been selection for that. This is just something that, that, that they can do
without, without any evidence of, of there being pressure to evolve it. So you get to this, you
get to the same question that I think people who studied mathematics back in the classic,
you know, great days and before that was some of these things. Where do, you know, where do
these laws of math of physics of computation, where do they live? Because things like the
distribution of primes and the, you know, the various interesting properties of, of logic tables
and the, the facts of, of number theory and all that, they don't, they don't depend on the physical,
the, you know, the properties of the physical world, right? The physical facts could have been
different. All those things would be the same. And I think that the, the, the, whatever, whatever
that platonic space is, where these things sort of reside, evolution is really good at exploiting
them. So, you know, a really simplistic way of thinking about it is like, if you, if, if, if,
if you were trying to evolve a triangle, right, you would have to evolve the first two angles,
but you don't need to evolve the third angle, you get that for free. And it's kind of amazing to
think, well, where, how, why do you, like, how can you, as a, as a search process, how can you
save all that time searching for that third angle? It's a free gift from, you know, from, from physics
or, or math or, or somewhere. And it leads to the same question of where is the form encoded.
I've got this, this thing that I always show my students when we talk about this stuff, it's a
Galton board, right? So it's this vertical board, you get a bunch of nails banged into it, and you
take a, you know, a ball of marbles and you sort of dump it on the top and the marbles go every
which way. And then at the end, if you've got enough marbles, you get this beautiful bell curve,
right? So you say, all right, so, so, so, so, so, so where is this, this pattern encoded,
right? And, you know, it's not in the wood and it's not in the distribution of the nails. It's a,
it's kind of a free gift from, from, from calculus or something. And I think that's what biology is.
So I think you've got three inputs, right? I think you've got the, you've got the genetics,
you've got the environment, in some cases, it's instructive, you know, turtle temperature,
determined sex and all that. But also you've got this, but, but you've got a third thing, which
is neither the specificity is neither in the environment nor in the genome. It's this incredible
storehouse of these, these free lunches that you get from, from, from physics, from math, from,
from, you know, computer science or whatever else. And I think evolution exploits them heavily in,
in everything it does. Which is far from satisfying, of course, because, because you said, well,
where are we going to, where is all this stuff, right? But I think we have to, I think what we're
learning is that we have to get beyond the idea that it all has to be tangible and it all has to
be, well, there it is. I, you know, I've sort of got my, my fingers on it. It doesn't all, I don't
think it all works like that. No, but if it's not tangible, what are we, what are we saying? What are
we proposing? Well, I think, I think the mathematicians have been wrestling with this for thousands of
years, right? When you, you know, as mathematics discovered or invented, if it's discovered,
which I think it is, you know, as an amateur, right? Then, then, then you've got this really
fundamental question that transcends biology and evolution, everything else, which is what,
what, what play, you know, what, what space are you exploring when you, when you discover these
things, you know? But isn't that different? Because you can explore ideas in space mentally.
That's fine. But we're talking about a situation where an apparently
simple body of cells is able to create incredibly complex structures with,
with the right types of cells in the right place, with the right connections in the right order,
so that you get the architecture, the very fine architecture of a brain or of the cerebellum.
And I have no clue, and I don't know anybody who has any clue where, where the map for this is,
if you see what I mean, I mean, people gesture towards the DNA sequence. But as we know, there's,
there's nothing like enough information in that to, to give this high level of very detailed,
formal information. And I think it's an interesting question. Well, I think, I think now we're back
to where this conversation started with, which is the idea that if we assume that
intelligent brains are the only things that are able to explore that space,
then we're at an impasse. But I actually think that kind of like what Dennett calls competence
without comprehension, I think you can explore that space without human level understanding
of what you're doing. I think evolution as a non zero, but certainly not human level process,
that's exactly what it's doing. It's, it's searching that space. And the good news, apparently,
is that that space has some kind of a structure to it. Otherwise, you couldn't really search it very
well. So in my head, and this is all, this is all, you know, completely like, you know, sort of
hypothetical and, and of course, controversial, but in my head, you could imagine, you know,
how people make a map of mathematics. So they make this map, you know, and then the entomology's over
here, and then next to it, there's something else that's connected in some way. And then there's
number theory. And I feel like there is a structure like that to the space. So once you've discovered
once you've discovered how to make simple Archimedean machines of a certain type,
the other types are right there next to it. It's not, you know, it's not that hard to sort of,
right. So you've got a lever, well, you can also make this other thing that's sort of close.
And, and when you, when you've the evolutionarily discovered an voltage gated ion channel,
which is a transistor, basically, right, then you can have a couple of them, and then you can
make a logic gate. And if you make a certain kind of logic gate, then you can make many other things.
And, you know, I sort of just in my head, I kind of visualize that there's this like,
space of these, of these free lunches, so to speak, that evolution can, you know,
when you make the right machine. So if you don't have the right machine, you can't make use of it.
But if you make the right machine, suddenly, oh, look, you know, the laws of adhesion now,
right, right. So, so, so, so look, if you, if you discover that you can have two different
proteins, that one is very sticky, one is not so sticky, right. When you have a bunch of balls
that have these proteins on them, and you shake, you shake them at an earn, what you end up with
is all the sticky ones are in the middle, and they're surrounded by the less sticky ones on top.
You didn't have to tell all of them where to go. You see, you get that for free. All you had to do
was come up with the idea of adhesion. That's it. Everything else is kind of, who told them to be
on the outside, right. So, you know, I feel like there's a space, which is the same space that
the mathematicians are going through. And I think evolution can, can make use of that stuff.
It seems that we can find to a rather, I accept what you say about the sticky and the non sticky
and so on. But these examples are, are so simple that it's not necessarily obvious that by putting
together a lot of such things, you will end up with information on a complex structure.
We know complexity brings in its own problems. It's not just a matter of complicating a number
of small ones. And these, these situations, these systems are complex systems. So anyway,
it's very interesting. I, I, well, I think anyway, it encourages us to think, I don't know that
there may be more information of a kind we don't understand us haven't yet grasped how to use it.
Man, I think one of the simplest things that arises early on is a negative feedback loop,
which gives you a kind of little homeostatic, right, a little, a little something, something
that's the, you know, the most basic kind of goal directedness is, you know, some kind of little
homeostatic thing. And what we've been looking at for several years now is the process of scaling.
How do you get from little tiny things that only care about one variable, one scalar,
you know, metabolic rate or something? And how do you add them up into a network that's able to now
care about much bigger things like, Hey, do we have the right shape? Right. So not only,
so, so what happens apparently is that not only do you scale up the kinds of things that a collective
can care about, but it switches actually problem spaces. So whereas before you were only trying
to optimize things, and let's say metabolic space or transcriptional space, the collective now
has these gigantic goals like, Hey, make a hand with five fingers. And so that's, that's a goal
and completely that's a navigational task in a completely different space. So I think, you know,
I think, I think that's where the magic is going to lie that you're talking about. How do we get
from these incredibly simple mechanisms? And I think the trick is, I mean, other people, what
other people would say is, look, it's emergence as in, for example, touring patterns, right? Like
you can, you can encode a very simple chemical signal and you get some cool stuff, you get spots
and stripes and somites and things like that. And that's fine. And that all of that does happen.
But I think the real secret sauce is in the goal directed sits in the feedback. It's in the fact
that you start with little tiny things that care about meaning exert energy to obtain,
to navigate to a region of state space that, you know, little tiny goals. And then there's a
scale up process. And I think, you know, I think we're starting to make some, some headway in that
scale up process. But then of course, you know, which is also the, you know, that's also the,
the, the kind of the holy grail of neuroscience, right? You've got these neurons, we know their
cells, we know they care about certain things. But the collective is, you know, cares about
very different things, right? Yes, exactly. Yes, that was what I was alluding to really. But
anyway, yes. So in, in the way in which, let's say an organism interacts with the physical world,
Ian talks quite a bit about one hemisphere being interested in exerting control over the world.
And relatively, the other hemisphere being interested in seeing the world as it is,
do I paraphrase okay, so far, Ian? No, that's reasonable. Yes. And there's a, there's a,
there's a back and forth there that if you're going to exert control over the world, you sort of need
to be, well, let's just say forceful to start with, in a way that is mutually exclusive with
simultaneously being sensitive to the world. Like, I'm going to exert a force on the world,
I'm going to change the world. And whilst I'm doing that, I'm not really very sensitive to
how the world is right now, because I'm changing it, right? And then there's, there's another thing
sort of, which is more sort of observational, more sort of accepting the world as it is,
seeing the world as it is, allowing information in from the world to change who I am on the inside,
right? That updates my model of the world. And then I apply my model of the world and I push
my ideas about the world back onto the world, right? Do you feel the same, that same sort of
duality in a sort of a pull and a push, right? I'm taking information in, I'm seeing the world
as it is without judgment. Then I'm forming a, making a decision based on hypothesis to then
exert control on the world in a particular way. And whilst I'm doing that, I'm sort of blind to
new information about me being wrong about that. I'm just, no, this is the plan I'm going for,
this is the goal I've got here, I'm going for that. Yeah. If you only did, if you only took
in information from the world and you didn't actually act on it, that wouldn't be an organism,
that would just be a lump of clay. If I only act on the world, and I never take in information,
that's not an organism either. That's just a rock rolling downhill. It's got an idea about
where it wants to go and it's just going to go there and it's not, it's just going to run rough
shod over any imperfections in the landscape. But in order to be an organism, there needs to be a
back and forth between. Absolutely. It at least needs both of those things. And I think the,
I've been trying to build models of mechanical systems built out of springs and connected stuff,
right? And in that kind of a system, you can't do both of those things at the same time.
You can't both be sensitive and be an actor, right? You can, you have to sort of pulse back
and forth between them. You'd be, I'm sensitive for a moment. I allow the springs to be deformed
by their experience. And then I take that pressure off and I allow the system to act
back on the world and it has an experience. And then it observes the consequences of that action
and that observation allows it to change its internal structure and then it pushes forward
again, right? And there are, there are many cycles of activity and inactivity that brains
go through on many, many different timescales, right? We can start with the wake sleep timescale
of 24 hours and then lots of other timescales of much finer ones. I have the feeling
the reason that I got sort of excited when I was first listening to these hemisphere differences
is that I have the feeling that if there was an asymmetry between the hemispheres that enabled
one to be, as you say, more about exerting control and the other one more about taking
in information, seeing the world as it is in an unbiased way, then that would perhaps
enable a more of a sort of a continuous flow of taking information and taking action on the
world instead of having to do it in this pulsed way. And if, if the hemisphere is specialized in
that way, then you get a, you get a flow between the organism and the, and the outside world.
And you also, I'm just making enough as I go along, obviously, but there's also a possibility
of one hemisphere observing the other, right? The one is, one, one has an idea and the other
one critiques it. The other one critiques that idea and the other one critiques the critique,
right? And there's a sort of an oscillation that goes back and forth between two hemispheres.
That you should be if it's working well. Yeah. Yeah, that you couldn't do if you only had one,
if you only had one, yes, trying to do both. Yes, correct. Yeah, that's right. I mean, they,
they wouldn't, it wouldn't carve up in the way that the left hemisphere is the only one that's
interested in shaping experience. They're both interested in doing that. But the, the difference
is in their, their allegiance to a certain goal, their values, and, and the, the particular
attention that they can pay. So if you, it's rather like, if you,
I often compare it actually to somebody who's like yourself, who's doing intelligent scientific
research, and you, you can't sit down and do, you know, a thousand different comparisons in the way
that a statistical package can do in the computer. So you, you put all this data into the computer,
the computer itself has no idea what this data refers to. It could refer to
mentally ill people, or it could refer to the creation of a sludge farm or whatever. It's
not interested. And so it performs procedures on it very, very quickly. But at the end, it produces
a result, which again, it doesn't understand. And the right hemisphere takes that back and
reincorporates it into what it already has understood. And that enriches its understanding
and makes it the best, in the best possible position to make the important next steps to
make the decisions about what we do and where we go. The problem is that when the left hemisphere
with its limited knowledge and limited intelligence, it has limits on both compared with the right
hemisphere decides this is what we need to do. It has a very small repertoire, which is we get this,
we get more of that. We enjoy having power over this and exerting influence on that and getting
this stuff to eat and so on. So it's exactly the way in which if you, if you've lost really all
other values, other than those of getting and grabbing and becoming rich, you would function.
So it's not just that it's the one that should be functioning, it isn't really.
In terms of exerting its influence on what we do, it's the one that
has that value and gathers data on it and processes that data. But then it's always
important that that process doesn't stop there. Now, what I feel happens in the modern,
if one can dignify it with the word philosophical, political, social media medium,
is that it goes through this process where what is extremely subtly involved with its context,
with embodiment, with experience, with, you know, it's taken and abstracted out of everything that
will give it meaning, put into categories. And then that seems to be the end of the process.
But it's not, it's a process that needs to be gone through, but very much transcended.
Mm, nice. So I've been spending some time
thinking about the societal impact of the idea of survival of the fittest.
Okay. And some of what you said there resonated with me a bit about what happens when the left
hemisphere is a bit out of control. So that if one hemisphere is expert at getting and
grabbing and also expert at judging and comparing, but its value system is very simplistic,
its value system is just one of these is best, right? I'm just going to do the one that's best,
right? That's the model that we have of evolution by natural selection and survival of the fittest.
It's like, it's all very, very simple. We just need to figure out which thing is best,
right? What do you mean best? I don't know, survival is best, right? That's it. That's all
there is to it. There's nothing else to think about here, right? So if instead there's a more,
let's begin with nuanced view of the world where understanding of what's important and why is much
more fluid and much more dynamic and much more integrated and much more connected to a depth
of experience and a wealth of values which are multidimensional and not single dimensional.
Then, you know, that's a different way of thinking, a different emphasis and
inferences you say in the difference between the hemispheres. But it's also a different way of
behaving in the world, right? When you think, well, everything is a competition, everything is
about finding the best, everything is about optimizing. It's all very simple, just maximize
it, maximize what, you know, let's just maximize it. If you really thought about what are you
trying to maximize, that doesn't matter. We're maximizing it, right? Exactly. Exactly. And that's,
you know, you can see how that attitude in the world creates this, you know,
discompassion and an attitude of exploitation towards one another that's the root of all of our
problems in the world, right? It logically follows from the need to sustain a system
in which you're maximizing profit and profit is money, effectively. So the value is that of power
and utility. And I've only really come to realize in the last 10 years how important values are,
because I think an awful lot of people think values are a sort of rather airy-fairy thing
that is sort of painted on at the end of, you know, you've got your model, and you sort of paint
a bit of values in there, and it might skew things a little bit. But what values you have
begins to affect the process from the very, very start, because it affects what you're
attending to and why. Because if your value is grabbing, then you pay this very disembodied,
narrowly targeted, committed, focused attention to details that are isolated and taken out of
context, and all the nuance and all the implied implicit meaning is lost, then you really have
a different world. You are now creating a different world, one that has consequences outside for
everyone else, but also your own world, your belief about what kind of a world you live in.
We don't examine this. I mean, I think scientists particularly hardly examine what the values are,
and I'm not sort of talking in some airy-fairy way about, you know,
now fashionable political values, and I'm not saying they should have a mission statement
saying that this is not what I'm talking about. I think what actually matters in this world,
and I think that there's a sort of, I follow Max Schaler, the German phenomenological philosopher
who had this sort of four-tier idea of a pyramid of values with just utility and pleasure at the
bottom, and then above them coming what he called lebensverter, the values of life, which are things
like courage, fidelity, magnanimity, generosity, and all things that I think we could do with a
little bit more of these days, then above them comes an allegiance to beauty, goodness, and truth,
and they're all in the doldrums nowadays as well. And finally, there comes at the top,
Das Heilige, the holy. Well, now a lot of people nowadays would just dismiss that out of hand.
I happen to think it's a very important element in the picture, but however you look at it,
this pyramid has been inverted so that at the bottom there are these airy-fairy things like
the holy, the beautiful, the goodness, and true, which you can more or less forget about,
because really they're only there to help you grab and get. This is chaos, and this produces a
dysfunctional society, projects that are misconceived, and a way of attending and being in the world,
which is the important thing you've said this to, that changes who we are, what we experience,
and what the world is like. I couldn't agree with that. Fantastic, yes. They're not a
fringe thing. They are at the core. The scientific ideal is objectivity, which is another way of
saying there are no values here. We're not exactly talking about anything. I'm just objectively saying
this is bigger than that. That is a value judgment, of course.
It's already chosen what you were attending to, right?
Exactly, exactly, and how you will attend to it, yes, so that you will only see certain things.
We put very simply, when science, quite naturally, this is how it is now thought to progress,
takes all values out and takes out, will not hear, speak of any kind of directional
teleological principles. It then solemnly looks at what it has found and says,
there are no values and there's no purpose, so it's all a meaningless mess. I've spent 30, 40 years
straying a little towards the idea that what happened if we accepted that it's not entirely
absurd that these things could exist and actually make a huge difference. So how we see biology,
life, society, what a human being is, and how we relate to the cosmos.
So anyway, we've gone away from what you were talking about, probably, Michael, but...
No, this is right in the center of what's important.
Yeah, that's really, that notion that the scientific way of looking at the world is
entirely objective and prides itself on being, so without acknowledging that we have to pick a
particular question, pick which things we attended to, pick which... You can objectively say whether
one thing is bigger than another, but you can't say whether it's better than another.
And so it gets bottomed out in really crude utilitarian ways. And so that's really interesting
to draw that together with your understanding of that disparity between the hemispheres and the
inductive, deductive way of thinking about reasoning and new ways of thinking about evolutionary
processes, right? If you think of evolutionary processes as purely maximizing survival and
reproduction, then it ends up not explaining anything about the complex beauty that we actually
wanted to explain about organisms. Yes, and it causes a mystery, because the more complex,
the more conscious, the more interesting and responsive the creature becomes,
the more it's chances of long survival diminish. I mean, we are not very good examples,
not because we do terrible things to ourselves, but even left alone, we have a lifespan of 70 years,
and a tree has some of them have a lifespan of 1000 years, and there is an actinobacterium at
the floor of the ocean, examples of which have survived a million years. They're doing very,
very well at reproducing and surviving, but there's more to this story than that.
If you wanted to maximize reproductive rate, we're not doing that either.
Not doing that? No, no. So, yes, I think these things need to be brought into the pictures
in order to help us see what it is we're looking at. Firstly, I don't know, what do you think,
Michael? Michael thinks it's time to go. Yeah, this is fascinating, and we need to start this up
separately because there's a lot to be said on this. So, could I propose that we wrap up for
today and try again? Absolutely. Yes, please. Fantastic. Okay. Thanks very much, gentlemen.
Very good. Nice to meet you, Andy. Very nice to meet you too, Richard, and good to see you again,
and we'll compare our diaries. Absolutely. All right, see you guys soon. Okay, see you. Bye.
