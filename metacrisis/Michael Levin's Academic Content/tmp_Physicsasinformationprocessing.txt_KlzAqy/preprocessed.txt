So what I'm going to do today is actually preview a talk
that I put together for the fifth session of a physics
of information class that I'm doing online
for the Action Inference Institute.
And this session is on space time.
And I wanted to do this here for a couple of reasons.
Reason number one is this particular session
contains a kind of hypothesis about biological systems
that I wanted to bounce off this group.
And the second one is that the question of where
space time comes from is, I think,
particularly relevant in biology.
And I think we can turn it into a biological question
as well as a developmental biological question
and even a developmental psychological question.
And so I wanted to sort of throw those ideas around
and see what people thought.
So a real grief review of where we've
gotten to in this class that I know Hunter Nell was in
and some of the rest of you are maybe in,
it's a class about quantum information theory.
And this is a super simple model system
for thinking about communication between entities.
We can think of two entities which together comprise
the entire universe of it.
So we can think of these two entities jointly isolated.
And the theory is just a general way
to describe how these entities exchange information
over some mutual value.
So this whole approach to quantum theory
is based on information exchange across boundaries.
And it turns out to be a really kind of powerful thinking
tool for thinking about how communication constrains
the structure of systems.
So we can think of the boundary as an information channel
that has a particular structure.
And since we're using quantum theory,
we can think of the balance as comprising some array of qubits
so quite a bit so it can be measured or prepared
by either system.
And talking about how that happens,
we're doing this in part to understand the free energy
principle better.
And so a couple of years ago, Mike and Paul Friston
and some of the colleagues and I put together a paper,
I think actually it was just Jim Gleisbrook,
reformulating the free energy principle
in quantum theoretic language.
And if you reformulate it that way,
then one can show that the free energy principle is actually
a classical limit of the principle of uniterity, which
is just the principle of conservation and information.
And the principle of uniterity is the fundamental principle
of quantum theory.
So it makes the free energy principle kind of naturally
fall out of just the assumption that you can describe
with quantum theory, which is kind of a nice result
because it makes the free energy principle look less strange.
And Carl's done a lot of work showing
that the free energy principle provides you
with a foundation for all of classical physics.
So relating it to quantum theory kind of closes
an important loop there.
And one thing that it does is automatically
induce compartmentalization in any communicating systems
that are interesting in a very specific sense.
It induces compartmentalization whenever
an agent has multiple ways of interacting with the world
and it can't deploy them simultaneously
for whatever reason.
So maybe it can't deploy them for some kind
of deep physical reason.
You can't measure spin along the z-axis and the x-axis
at the same time because those operations
don't commute mathematically.
But maybe it can't deploy them simultaneously
for a much more prosaic reason.
It doesn't have enough free energy
to thermodynamic free energy in the field to both do this
and this.
So it has to have some attention system.
It says, I can act on the world this way
or I can act on the world this way,
but I don't have the ability to do both.
So even that very classical energy
limitation on whether systems can be deployed simultaneously
induces this kind of compartmentalization.
And as soon as you have compartmentalization
between ways of interacting with the world,
you have to have some way of managing what you can do.
So you kind of automatically induce a metaprocessing system,
an attention system, an energy regulation system,
just by the demands of not being able to do everything
all at once.
So the physics kind of by itself gives you
some interesting and added fuel that one can then
ask, how is that implemented even at the cell biology level?
So it provides a different way of approaching
cell biology that's driven not by the chemistry,
but by the kinds of computations
that the cell was implementing.
We were talking earlier at the lunch table
or whatever it is about.
How do you take this horrible spagetti mess that's
the pathway diagram for a cell that abstracts out
all of the interesting geometric constraints and time
constraints and that sort of thing from the inside of the cell
and turn it into some sort of compartmentalized structure
that tells you where the borders are within that mess,
where the cells have to exchange classical information
in some data structure.
So in effect, where are the APIs inside the cell?
Which is the kind of question that doesn't naturally
arise in other representations.
So just to make sure that I'm on the same page,
the compartmentalization you show here,
like green, orange, red, the green and the red
would be Alice and Bob in your initial example,
where they're two separate.
Green and red are the two compartments or any two
compartments are separate entities
that need to exchange information classically
through your qubit map.
Right, except with respect to the original boundary,
green and red are different compartments in Alice.
And they're both looking at Bob, who's
on the other side of the boundary.
I see.
So actually, the next question.
Could you also reformat such that if green and red were
inside of Alice, could you also think about the Alice of Bob
in this case?
As far as they're talking to somebody else.
So actually, let me show you the next slide.
OK.
OK.
You can reformulate that diagram in a simpler way.
So here, what I've done is green and red are now Q1 and Q2.
These are two quantum processes acting within some overall
quantum computer, but they're distinct quantum processes.
So they have to be compartmentalized in the way
that it was before.
And you can use this kind of picture
to represent two agents interacting
with a common environment that are employing
both a classical channel.
So they're talking to each other in language.
And they're both measuring some shared quantum system.
And this is exactly what happens in all experiments
that detect entanglement.
And in fact, this is the minimal organization
to be able to detect entanglement.
So it's the kind of bottom line comment
is that in order to detect entanglement,
you have to have classical communication.
And so at the very depth of all of quantum information
technology is a requirement for a kind of communication
that isn't quantum communication.
It's classical communication.
So I think of breaking into sort of taking
the big mess of loss of communication
and loss of stuff flowing around inside of a cell
and trying to break it into like you were saying before,
this sort of sonic size APIs that communicate
over a somewhat minimal amount of wire signals.
It doesn't sound like a quantum problem to me.
So how does all the mechanism and formulas
of the quantum mechanics help?
Or am I just totally misunderstanding?
Well, no, I'm using the quantum formalism
as a particularly simple way of talking about communication.
But the other thing it gives to you
is a localization of thermodynamic requirements.
And so localization of thermodynamic free energy
requirements to only the places where you're
encoding classical information.
So one motivation for doing this is this analysis
that Mike and I did a few years ago of to what extent
can you represent the state changes inside a cell,
and in particular protein conformational changes
as classical computation in the way
that they're actually represented in, say,
classical molecular genetic simulations.
Where you think of proteins as sort
of exploring this configuration in state space.
And it turns out that cells lack the free energy resources
to do that by orders of magnitude.
So they have to be using some other resource,
some, you know, concurrence resource that's
energetic and free to do some of this computation.
So one question motivated by that is,
where do they have to store quite an information?
Sorry, where do they have to exchange classical information
that really is energetic for the excursion,
and that they really do have to put a lot of resources into it?
And so they're kind of obvious answers in the cell.
You know, wherever proteins are bound to a membrane,
they're transmitting a classical stage
across the membrane to whatever information
process that's happening on the other side.
But there are probably other boundaries
that we can't see just by looking at, say,
an electron micrograph, where they're classical APIs.
At least it raises that question,
where are the APIs inside the cell?
And how can we cut to something of modules
that we now have to communicate by some sort
of classical information instruction?
Given that it can't be happening, you haven't learned.
So anyway, so that's just a very brief summary of where
we've been in this now multi-month course.
And now we're finally to some of the parts
that's really biologically interesting to do with space.
But before I talk about space, and this
is actually motivated by questions
that were asked after one of the other sessions,
and Mike's seen some of what is immediately
to follow before, because I shared some of the previous
meeting that was the last few days.
I wanted to talk a little bit about explanation,
because it raises an interesting question
about the scale dependence of biological processes.
So let's start by contrasting reductionists
in scale-free theories.
So the sorts of undergraduate approaches
that we've learned in undergraduate school,
in undergraduate physics and chemistry, for example,
there's stuff going on at the molecular level,
and the stuff going out at the cellular level
is just some emergent process from all of that chemistry.
With a scale-free type of theory underlined,
that's underway by the free energy principle, which
is a scale-free description of how
systems of any type communicate with their environments
and build models of their environments
and behave in their environments.
So in any kind of reductionist theory,
the basic idea is the explanation.
All the real, the important stuff handles
happens at some preferred scale.
And whatever's happening at larger scales,
there's emergent, or epiphenol, or something like that.
It either doesn't matter at all, or it's
some sort of packaging of what's happening
at the lower scales.
And so the fundamental assumption
is that there's a fundamental scale at which that's most important.
Whereas in a scale-free theory, the approach
is very different.
A scale-free theory postulates that there's
some kind of dynamics, and that dynamics happens at every scale.
And as you move between scales, what you're seeing
are different implementations of the same theory.
So it's a very different way of thinking about theory.
And I would suggest that a lot of science is actually not
reductionist, even though scientists talk about it
as if it was reductionism, because I think they learn
that's what they should say.
And the scale-free approach is more
difficult to think about in certain sense.
So if we go back to that picture,
and systems targeting each other across the boundary,
and you ask about scale, the way to represent scale
is the density of which information is included.
And we can think about a whole spectrum of scales
that are already given to us by physical theory, for example.
We can do the energy scales, or space spatial scales,
or temporal scales.
And all of those are coupled together
by the basic physics, or basic physical constraints.
So the kind of smallest possible physically definable scale
was the Planck scale, where an energy of about 10
in the 19th GeV, so the 10 in the 19th billion
electron volts, is compressed into a spatial scale of 10
to the minus 35 meters.
So that defines the boundary of a black hole, basically.
Anything that includes information at that scale
is a black hole.
And 10 in the 19th GeV is about 15 orders of magnitude
larger than the energy density that we can get with the large
electron collider.
So it's a very high energy density,
compared to what we could produce in the laboratory.
So the scale about 1 GeV is the scale at which nucleons exist.
And that corresponds to a distance scale
of about 2 minus 50 meters, so 2 nucleons
about a femtometer in size.
And our scale, our natural scale, is about a meter.
And the associated energy is very low.
That's radio frequency energy.
So if you think about white, light's about 10 to the fifth
higher energy than radio waves.
So white feels energetic to us, and radio waves don't.
And that's just a fact about our size.
White seems very energetic compared to the size
of our gradient, which is our natural scale.
So we can think about the boundary
as encoding this information at quite different scales.
So now how do we think about science in this frame?
And we're all familiar with kind of reduction of science,
where we assume a fundamental middle scale.
And this is the best example.
You have some event that happens at some incredibly tiny scale
in space and time at very high energy.
And that sets all the parameters for all the physics
and produces all the organized structure that we see.
I imagine.
And that's called the Big Bang Theory.
So the Big Bang Theory is, in a sense,
the ultimate reductionist theory.
It says that all of the important parameters that
characterize everything are up to the waves and nothing
else fix the plank energy, the plank time, the plank spatial
scale, and everything else just happens.
So what we're looking for is a way
of thinking about science, and it's
something to be able to explain, and it's different from that.
And it's hard to find an example with this sort
of nice illustrated picture.
So we have to draw a picture.
And in the kind of notation we've used here,
the picture looks sort of like this.
We've got this system on the other side of the boundary.
And that system is changing through some kind of god's
eye type parameter.
And we're looking at it.
Our system, Alice, is looking at the boundary,
where Alice can see encodings of different scales.
And let's call those scales 1 and 2.
And what's happening on the boundary
at these different scales is changing.
So if Alice looks at a magnifying glass that
sees scale number 1, then she sees some changing pattern bits.
And if she looks at a different magnifying glass that
sees scale number 2, she sees some changing pattern bits.
And she can construct a theory about how these bits change
over time.
And that could be, for example, some Markov process
that captures that theory.
And then the interesting question is, how do those two
relate?
So can you construct a semantic theory, an embedding
theory that says, OK, bit patterns at this scale
have some correlation.
And there's some part of the correlation structure
of bits at this small scale that matches the behavior
of individual bits at this very large scale.
So I construct some sort of, if you will,
linguistic mapping from the language that
seems natural at this scale to the language that
seems natural at that scale.
And it's how those theories change through time.
It's a really interesting question.
And you like your semantic mapping to stay fixed,
because then you don't want to talk about it
as you progress through time.
They think it's not going to pass your measurements.
So this picture should look familiar,
because this is how computer science works.
And so we can translate all this into the language
of computer science.
Now the scales are different programs,
which may be things like an operating system
versus user interface, versus what
we call the hardware level, which really isn't
the hardware level.
It's a high-level distribution.
What a bunch of stuff is doing.
And we can keep going down the scales
with a laptop or something of our scale,
this kind of user interface scale.
But what we're doing in computer science
is constructing exactly this kind of semantic mapping
between different ways of describing one process.
And we do that by assigning meanings
and mapping those meanings in each other.
So that's what I call semantic mapping.
And with computers, we design them
so that they can't be so constant.
So you know, I start with the relationship between the C
compiler and some HTTP value or something
in a way that doesn't change.
So what we can then ask is, and here's
where we start to get into biology,
what's the actual relationship between these embedding
theories and biology?
You can think about biology in a scale-free way,
which if we think in a free energy principle framework
we're doing, then we can ask what the embedding theories
look like as we go from thinking about how we embed pathways
into cells, cells in the tissues, or tissues in the organs,
or organisms in the social parts of the human body,
all the way up to the biosphere level.
We have all these different embedding theories.
And this gives us a set of scale transitions.
And if we want to represent sets of scale transitions,
we can return to, again, a mathematical formalism
and represent it as a renormalization,
which is just a set of operators that move things
between different scales.
And we can ask, how different are these transitions
between different scales?
And so I'll just put on the table a hypothesis
to think about, which is the hypothesis
in biological systems.
Those scale transitions all look like the same thing.
They're all formula-equivalent.
And I don't know whether that's true.
I don't even know how to approach trying to prove that it's true
or not true.
If it was true, it would be really cool.
Because if you think that the theory is super, super simple,
you have the free energy principle in one scale operator.
And with that, you could do all the embeddings.
So I'll just leave that as something
to think about.
But be that as it may, we've done something really important
to you, which is we've linked physics to computer science.
And we've done it in a way that is not
just reconstructing some God's eye view of physics
of computer science.
We're trying to construct physics from the point of view
of an embedded agent in a way that looks like computer science.
And that immediately raises a problem, which is self-reference.
And we know where that gets into Gerdl's under very, very
general assumptions.
So Gerdl warns us that this theory
is going to end up not being both consistent.
And warns us that that's something we just
have to deliver.
So that's the end of part one.
Now what I want to do is actually talk about space
and do it from this kind of scale-free perspective.
So that's a great question, because on that last slide,
what is the semantics level of the semantic mapping
on a computer?
So we have programs that are actually
basically mapping that out of some interpretation
of the hardware.
Are there semantics and other programs in semantic mapping?
Or was that I was looking at the program board?
Well, the thing about process is variable binding.
As soon as you get up to a language where you can talk
about variable binding, if I have a variable
and I'm binding some structure to it,
and I can also bind that variable to other kinds
of structures, then we can think about what
that structure means to me.
I have some notion of what two means for this number.
But from the point of view of that program,
at least two means something different from three.
Because if I bind a variable with two,
then I do something different if I bind the variable with three.
And the basis of semantics, I'll go back to Gregory Bates,
and if there's a difference that makes a difference to me
that's in some sense actionable, that's
the basis of semantics, that's the basis of meaningfulness.
So you have some, at least minimal, sense of meaningfulness.
As soon as you have variables, a distinction
between variables and constants, and you
have one structure that leads to different actions
and new different circumstances.
So the other way I figure it is when we are describing
what programs are doing, we are naturally
ascribing semantics to the program.
So we're imposing a model theory in formal terms
on this bunch of syntax on this language.
When we look at different kinds of languages,
we put very different model theories on top of them.
So the languages naturally have different structure.
Because the model theories we use are typically very different.
So it's that very stripped-down motion syntax that I'm referring to.
There is some voices in computer science
that don't have distinction between software and hardware.
And I'm asking that because here,
do you require that the hardware should be a universal tuning
machine, or so it can be any.
It can be anything.
So I mean, if we're looking at biology, it's all hardware.
Right.
It's in six.
Yeah, it's just we're describing the hardware
at different scales.
We're building the hardware as we go.
That's even a more strong statement
if the hardware should not necessarily
need to be universal.
Yeah.
In a sense, if you take this information theory
way of thinking about physics seriously,
you get back to the grandfather John Wheeler
and his proclamation that physics is a fraction theory.
So hardware is software.
Right.
And that underlies a lot of that's
much of the underlying philosophy of this whole transition
that's occurred in quantum theory in the last 30 years.
What's that?
What's that?
Like that?
John Archibald Wheeler, who was an associate
at Baltimore and Einstein.
So he kind of combined their different ways
of thinking.
And he was the person who sort of,
I think he came up with the name Black Hole.
He was part of that rebirth and general relativity
in the late 60s and late 60s.
And we go to a sequence of papers
that can be seen as the founding papers of quantum
information that motivated a lot of those people who were
working early on in that area.
OK, so let's talk about spacetime
and really a good place to start,
because one of Wheeler's hitter was
you have to start physics without spacetime,
figure out what spacetime comes from.
So this is a massive departure from the Einsteinian
view that spacetime is a physical phenomenon,
even though Einstein also said from a philosophical point of view,
spacetime is something really extended,
is somehow observatory.
So this notion of spaceminding observer relative
runs deeply through current quantum cosmology.
So let's think about space.
And let's think first about absolutely uniforming
nothing is happening.
So I look at the environment and none of it
looks any different to me.
And nothing is done.
So now I mean nothing is done.
Well, you have boundaries over all the time.
You have boundaries over all the time.
Yeah, well, now you've got to look at this somehow or nothing.
So this is where we start.
And an organism that's living in an environment like this
is obviously not an organism, not living,
because nothing's going on in this environment.
But we can think of this as an abstraction.
OK, how do I build up a meaningful environment from this?
And how do I start putting a spacetime on it?
How do I put some sort of coordinate system
on this environment so that I can tell about what's going on
over there from what's going on?
So the first thing that you've got to do
is somehow segment the environment
into parts that are different.
So let's say that we can start to segment the environment
so that at least different parts of it look different,
even if nothing is happening.
So we have some part of the environment
that looks different from some other part of the environment.
But now we can ask, is there any sense of relationship
between these parts?
And obviously, the way that I've drawn it,
visually to us, there's a relationship.
But I haven't said that there's a relationship.
So right now, actually, I just have an environment
that's a set of two parts, and we can make it a little bit more
explicit by going to four parts.
So at the top, I just have a set of segments.
And I haven't said anything about what segment is next
to what other segments.
Even though visually, I obviously have to think in a way
through what other segments is next to the other segments.
You can just think of this as a heap or a pile.
So I can take this set, and I can add some structure to it
by adding some topology.
And the simplest thing to add to it
is some kind of graph structure.
So I say, OK, this piece is next to this piece.
This piece is next to this piece, et cetera.
So I can take this internal graph,
and I draw the little connections
as if they were gap junctions to suggest something
about planes of cells that can talk to each other.
And they know that they have a neighbor.
There's some cells they can talk to,
and other cells that they can't talk to,
so they don't know anything about.
So now, there's still nothing happening,
even though the environment has a little bit
of topology on structure.
But once you have some topology on structure,
once you have more than just a set of distinctions,
you have the structures of the distinctions,
we can talk about something happening.
So let's talk about something really simple to happen.
There's something happens in part of the environment,
and then something happens in some other part of the environment.
And I can tell these parts of the environment
are distinct, because I've broken this symmetry that
allows me to move the parts of the environment around
by making some things connected and other things not connected.
So we can represent this in a really simple way.
We can say in the top panel there,
a black dot has appeared in the white-green square.
And I represent this by an up arrow and a green subscript
and a black dot.
And this is actually the notation one uses in part of field theory.
So one can think of this as what's
called a raising operator, which just
creates a field excitation in the green part of the field.
And what it creates is this black dot.
And then we can think of a different state
where black dot has disappeared from the green part of the field,
the white-green bit, and has appeared in the dark-blue bit.
So that's a representation of something happening.
And these white dots are now kind of excitations of a kind
of field that can create black dots.
So they're not yet objects in an intuitive sense.
They are objects in the way that say electrons are objects.
Where if an electron appears over here
and an electron appears over there from out of the quantum vacuum,
then the question of, is this the same electron
as that never arises?
It's not even a meaningful question.
They have exactly the same properties of their location.
But when did they count as the very same thing?
This is a meaningless question.
So at this level of description, that's
still a meaningless question.
So we have a space where something's happening that you can't.
There's no sense of there being an object in this situation.
But even in this really very simple, simple system,
you can think about an observer that
has enough memory to keep track of this sort of thing
happening over an extended period of time.
So an extended internal period of time,
because it's with respect to some internal memory
of the consequence.
So if you've got that kind of multi-step memory,
you can see state transitions like this,
where something happens in part of your environment
and then something happens in the other part of your environment.
Something happens in the first part.
Something happens in the second part.
And anytime you have that kind of periodic behavior,
that's a clock in your environment.
And it's a clock because you have enough memory
to see periodic behavior.
So you, to have that much memory,
you have to have the internal counter
that counts experiences and labels them in your memory.
So I can say, oh, I've seen that state before.
So as you can say, I've seen that state before,
and you can watch quite a few of them,
and you've got this kind of periodic behavior in the clock.
So notice what this does, it's just not required.
So you can define a clock in your environment
if you have distinguishable environment sectors that
have some typology that prevents them
from being arbitrarily exchangeable.
So you've got these connections.
You've got this graph structure.
You need some kind of flip-flop that's
implemented on that structure.
And you have to know that it doesn't require object having.
We've implemented it just with this quantum field
theoretic notion of events happening in one place
or happening in another place.
And you don't have to have a metric space.
You don't have to have any sense of distance.
So you've got a really, really minimal structure
on your spatial representation in your environment.
But you now have a nice external time reference
for that you can look at other events with respect to.
So this tells us something really important, I think,
for biology, which is that time is more fundamental in the specs.
We can expect organisms, even single cells,
to be able to measure time in their environments
before we can expect to see them measuring space
within their environments.
And organisms that we know about have things
like diagonal cycles, even bacteria,
that we don't have any real reason
to believe impose a geometric structure on their environments,
even though even bacteria distinguish part of their memory
from the native part of the environment.
That's the whole way that bacteria implement chemotaxis.
Yeah, just what you said.
They want to look towards gradients,
but they're so small that one side of their body
and the other side of their body are
at the same concentration for all practical purposes.
They cannot measure a gradient in space.
They measure it in time because that's what works.
Yeah.
And even before bacteria, movement came later, right?
First organisms didn't move much.
That makes all the sense.
At least I don't know right now.
And truly, you can guess how you would measure space
with that movement.
It's probably possible for some light diffraction patterns.
But without that, you can't move.
It's going to be way easier to measure.
There's a time that you have to come up to a space.
So it makes sense that that what involves much more
logic than you thought that.
I would expect that even that area of the camera,
or even your roll-box, the camera,
may not be representing motion.
So they may not be representing objects.
And if you're not stuck as well,
it's easier to represent than Francis' thesis.
So now let's think about what was in motion.
I'm sorry.
Can I ask a physics-related question?
Sure.
How does this relate to the isotropy of space?
Because if you compartmentalize space
into different cells, it does need
to have certain kind of, well, arrangements
that are light in one direction and in a diagonal direction.
Francis takes the same time to arrive
at a certain distance, right?
Yeah, let's get to that in a little bit.
We can talk about metrics.
OK.
OK.
I think that's really a metric question,
or almost a metric question.
OK, let's think about what do you
need to observe motion?
What do you need to be able to say
that there's some object that's moving around in my mind?
So suppose that I have this black dot,
and it's exchanging its position between light green
and dark blue.
But now I want to see that as motion.
So to see that as motion, I need to add an assumption, which
is this black dot is not just a field
excitation of some quantum field.
It's actually a thing.
And what it means to be a thing is that it persists through time.
It has some identity through time.
So then I can say that when it's in the dark blue square,
it's actually the same thing that
used to be in the white green square.
And that same thing is going to move now again
and be in the white green square.
So object persistence, this idea that I have a thing,
is deeply, deeply related to the notion
of translational invariance, which
is one of the fundamental symmetries that
allows you to define the spacetime of the sort that we have.
So we have to make this extra assumption
that moving something doesn't change its identity.
And similarly, moving something in the space
doesn't change the structure of the space.
So I have to make this assumption,
this is part of translational invariance.
If I move an object from here to there,
I don't change the topology of the spacetime.
We don't have a geometry yet.
So we still have to assume that it
doesn't change the connectivity structure in my space
to move something moving.
So what I want to emphasize here is
that this notion of object persistence is a classical idea.
It's not the idea that arises naturally in quantum filter,
which says simply that something appears and something else
appears, that they have no persistence idea.
And I think we can think about the entire history of 80 years
and interpretations of quantum techniques.
But hundreds of books and thousands of articles
written discussing metaphysics, basically,
has all been really a debate about object persistence
and what meaning of object persistence is.
Because as soon as you have object persistence,
you made the transition from a purely quantum theory
to a theory that's quantum.
Object persistence is what really defines
classical information.
It's I can write a bit, I can write it here,
and I can come back tomorrow and it's going to be good.
And there might be some noise that up to the noise,
it's the same bit when I went there before.
That's a classical idea.
So here's the quantum to classical transition.
It's the assumption of object persistence.
I think it's worth thinking about where
the assumption comes from.
Chris, can I ask a question so you can hear him?
Yeah.
Yeah.
So if you go back to the previous slide,
could we also not, in a sense, think of the sectors,
the green, blue sectors as also as things,
because they persist even though they do not show any motion?
Could we not think of those sectors also as things,
because of persistence?
I represented them this way to have a visual depiction.
But the intuition I'm trying to get across
is an intuition of location or distinction
between different parts of the environment.
So we don't tend to think of this little piece of space
as an object.
Right?
No, some little voxels somewhere between me and the window.
We just tend to think of that as part of our coordinates.
So I've drawn it in this visual way, which suggests object
to it.
But a voxel in my space is really different from something
that I can put into that voxel.
So this thing that I can move around as an object,
whereas the kind of voxel is an abstraction.
So yeah, I don't think that there's something at all.
I guess I'm not an expert in physics or relativity,
but doesn't Einstein's theory of spacetime
say something about how spacetime could be deformed
or not stretched and contracted?
So doesn't it suggest that space is also an object in a way?
Yeah, well, we'll get to that in a couple of slides.
OK.
OK.
Yeah, hold your breath on that one.
So I want to talk a little bit about object persistence more.
And let us think about that from kind of a development
psychology point of view.
This is how we learn about object persistence.
And we get this in about the first three months of infancy.
We do this kind of motor babbling.
And we do it with objects.
And we don't have a handy colorful thing.
We just look at our own lips.
And notice what's happening here.
This picture illustrates really well.
There's visual attention.
And there's also motor attention.
So what we're doing when we're doing this motor babbling
is we're coupling a somatosensory and proprioceptive
representation of our body with a visual representation
of our body.
And visual representation is assigning object
to this thing that's otherwise a motor representation.
So what's a motor representation?
It's a representation, among other things,
of the amount of energy I have to spend.
It's effortful to do this.
And I can sense that effort.
So and this is very indirectly getting
to Santosh's question.
I'm starting to couple the ideas of energy and object
to it by doing this sort of thing.
And I'm also coupling it to the idea
of the persistence of time and manipulability.
So these are deep, deep, deep intuitions that we have.
And I think we can say, just based
on physiological analogy as well as behavioral analogy,
these are deep, deep intuitions that animals have.
And maybe even invertebrates have.
So we can think about space pretty easily
from the point of view of a dog.
And maybe even we can think about space
from the point of view of somewhat a frog or a fish.
But we don't have a good way, at least I
don't have a good way of thinking intuitively
about space from the point of view of something
like an insect that has a super different developmental
process than mine and isn't obviously doing this kind
of process that is the process that taught me what space was.
So I think we need to think about that when
we're thinking about space in terms of biological systems.
So let's just in the final segment here
think about what it takes to start
to impose a geometry on space.
So if I want to build a coordinate system,
I want to build a geometry in our earlier motion,
I need to have a motion with respect to something.
So I need some sort of designated preferred position.
I can say, OK, I'm moving relative to this.
And as soon as I've got that, I can
start to build some other variances.
So I can start to think about, for example,
rotational invariance because now I
can tell I'm rotating because I can say, OK,
this isn't rotating, but this is rotating.
So now I can think about rotational invariance
in the same way I can think about translational invariance.
And if I want to think about three dimensional space,
I can think about kind of size.
So if I move something, it gets smaller.
And if I put it closer to me, it gets bigger.
I learned that when I was three months old.
I hit my rattle when I was moving around
because I had this mother to be in for me.
You can also think of that as a kind of energetic dimension.
So if my object is over here, I have to spend energy
to get to it in a way that I don't have to spend that energy
if it's right here.
So you can think of this building this third dimension
in various ways.
But you always have to have this origin
to build any kind of geometry.
So once I have this, I can also do something really radical,
which is imagine like 20 people.
And I think it's an interesting question
to ask what animals are capable of representing themselves
as well as opposed to representing
their environments as moving.
And I don't know how to answer that question.
I think it's a really interesting question.
So finally, I don't just need an origin
if I want a coordinate system.
I have to have a ruler.
So I have to have a spatial reference
for that consists of this origin and some ruler.
And my ruler has to be translationally and rotationally
invariant up to some transformation.
And here we get to the relationship
between, say, Euclidean space, where the ruler is
invariant to translations and rotations and something
like space and general relativity,
where if I move my ruler around, it changes length.
And if I rotate my ruler, it changes length.
And that length change is a representation of mass
and general relativity is sometimes just pointing out.
So in fact, it's not that the space is a representation
of the object.
It's the change in metric that represents mass
in general relativity.
So it's the way my ruler changes as I move it.
And I think that's a very interesting concept
which we'll talk about again.
So once I have these things, once I
have this spatial reference frame,
now I can talk about objects moving in geometry.
And I have what we consider intuitively in space.
So notice how much more complicated this is than a clock.
Simple to get a clock.
It's really complicated to get this.
Space is a much more complicated notion than external time.
OK, so we're almost done.
I just want to think a little bit abstractly now
and interdisciplinarily now, and think about approaches
to emergent space.
In the physics literature, especially quantum information
and to a somewhat lesser extent, under the rubric
of quantum cosmology, there's a large industry
hundreds, thousands of papers that are working
on emergent space.
And it's all in a deeply technical, difficult language.
And this route involves many, many variants
on starting from some sort of information exchange
and usually entangling.
And working through the idea of error correction
and error correcting codes, and through the idea of lattice-like
discrete network types of topology
to get to some sort of spacetime.
And in particular, by always adding
a bunch of different kinds of assumptions
to get to Einstein's equations, to get to a spacetime that
supports some idea of mass, of gravity, or energy density.
I mean, all of those are important.
So some sets of a metric that changes
when you do certain things.
Now, there's a completely different approach,
which isn't expressed in incredibly complicated mathematics.
It's expressed in the language of developmental psychology.
And that way of thinking about spacetime
starts with perceptual motor capabilities.
So it starts from motor bandwidth.
And it talks about the measurement of effort.
So it assigns an energy coordinate at the top.
And it talks about memory.
And it talks about objects and invariances.
So it talks about the ability to move something around.
So this is the same thing that I'm going to do in a little while.
And from there, it builds this notion of a metric space.
And that metric space has at least an implicit energetic
coordinate that has to do with distance.
And it also has sort of an energetic component
that has to do with mass.
So I know that there are things in my space
that require a lot more effort to manipulate
than other things in my space.
But in this way of thinking about it,
that notion of effort and mass is not really anchored
in the space.
It becomes a different concept because there's
this classical notion of mass.
And the question is, do these routes
eventually produce the same thing?
And the sort of obvious answer is no.
The obvious answer is that the left-hand side,
this very recent two- or three-decade
afternoon theoretical physics that
starts really from string theory produces this very abstract
notion of space that gives you Einstein's equations.
But is that really true?
I mean, one gets general relativity just
by thinking about symmetries in our ordinary conception
of space that people haven't really focused on before.
Einstein really derived general relativity
from the equivalence principle, which
is the idea that acceleration and mass are the same.
You did it with all these thought experiments
of people in elevators and things like that.
So in a sense, general relativity
follows from our classical thinking about space
when you notice some symmetries that you
haven't noticed before.
And you wrap some mathematics that you haven't had before.
So maybe these paths really do converge.
And I think if they do converge, it's really interesting.
Because it tells us something about the relationship
between physics and biology, that I think is important.
And what I hope I've convinced you today
is that there's at least some possibility that maybe
these two paths really are linking to the same thing.
Really, we can't think about constructing space time
from an organism or one of you.
So I'll just leave you with one picture, which
is that organisms and maybe some systems that
are organisms we can manage to construct this cycle from memory
to object persistence to error correction, which I really
haven't talked about much here, to space time.
I'll just make one comment that space is really useful,
because it means that I can correct errors.
I can put things in space and expect them to be there.
And that gives me an external memory.
So I have space.
I have an emerging memory.
I have a whole lot of memory, which I can use my ID card
to remember my name.
So organisms can do this.
And that raises the question, which
I think we can view as a phylogenetic question,
of how did this start?
Where in phylogeny does this cycle get going?
And how does this cycle change in different parts of phylogeny?
How do different parts of phylogeny implement this cycle?
And I think that's a really interesting question,
an evolutionary biology, that's what we're thinking about.
So I'll close with that.
Thank you very much.
I know I had to be a little bit of a diva in once.
So we're basically at 1 o'clock.
So if there are a few questions, that's great.
My next step is to go to the airport.
Do you remember the experiment that's not allowed to do today?
It's a global experiment.
There is another experiment in that kind
that's not in that category.
There was some carousel that the kitten connected with a hinge
together.
One of them is a carousel that is completely closed
and there is stripes in that carousel.
And one kitten is able to use his legs and to move.
But his movement affects the other kitten that they folded
and they're not allowed him to use the legs.
And they put that kitten from the beginning like that.
The result was that that kitten was blind.
And there is nothing wrong with that kitten.
Only because he never used his legs to close the loop
with the environment.
So his movement were completely not connected to him.
They had the other cut.
So they released that cut later on.
I don't remember exactly the time numbers,
how many months they put it there.
But they released him and let him use the legs
and he gets back his eyesight.
So maybe that related to this kind of thing.
I bet no one can do that experiment today.
One can easily think of the experiment should be
incredibly informed and completely adaptable.
I like this because I feel like you get this
at the molecular level.
And I think you can think of space as being
any area with less resistance.
If you were to define what space is in this room,
people would say, well, it's air.
This is your object, whatever.
It has more resistance.
But I think a molecule does this too.
Because as a molecule binds to another atom and it changes,
it has a memory of what it bound to.
And now you have object persistence.
Because now you have a different structure.
It changes the way the thing interacts all the way through.
And it has error correction because it doesn't bind.
It won't bind to a molecule.
It doesn't have the right valence electrons around it.
So once that falls into each other, it will reject it out.
And then it will grab the other one.
So I think you're seeing all of this,
not even the organism level, but at the molecular level.
Great.
Next.
Yeah.
I would love to be able to do psychology.
At the molecular level.
And really think about.
These things as agents that are in substance carbon.
Yeah, absolutely.
Yeah, we're all crystallin lattices.
That's all we are.
You know, all the information that we're transferring and thinking
about all of that is being transferred through crystal lattice.
So what would be the memory in that kind of thing?
The structure.
Yeah, the structural memory.
And.
I think there's, there's in a sense,
bosses can work with them.
And the molecules can.
Write on their environments in ways that are persistent.
And in ways that they can go back to and get information.
At least I would have problems with molecules are doing.
Certainly organisms are doing that all the time.
Yeah.
There's a cool experiment field mice,
or they leave like literal markers on the ground that are visually distinct
from the rest to remember where to go.
Yeah.
And I mean, the word came originally from social insects.
Yeah.
Or memory.
If we, you know,
molecules using stick merging mice would be a super cool result.
But you can really nail it in here.
Makes me wonder if I was paired with Pam and I were talking about valence.
That's like a basic kind of foundation for cognition.
And when you just mentioned, like, basically all of biology,
it's just chemistry.
It's just physics of electric interactions.
Basically mostly valence of electrons.
This might be like a, you know,
no common relationship between those two,
but that's basically all that.
And molecules do a good sense.
Positive and negative charges.
Positive and negative experiences.
There we go.
There we go.
So, so Mike Sir is taking notes to talk to work songs about this.
Yeah.
I think there's also a good example of that you could put together
like systems neuroscience as well,
which is the first point of the scale free stuff, right?
It's probably all the same.
Like I, I'd be more surprised if it wasn't.
Thanks people that I keep up.
Yeah.
I think it's true.
Okay. Here to give this course.
Are you staying around for a bit or do you have to leave like right away
for the airport?
No, I'm glad.
Yeah.
Okay.
Can I ask a last question?
Why is there three special dimensions?
I'm sorry.
Can I ask a naive question?
Why is there three spatial dimensions and not two or one?
For instance, is there a particular reason to that?
Oh.
But there's, there's some mathematical facts about three space that I never
know that are really really interesting.
Yeah.
Like building knots or something like this.
I mean, you cannot do everything in two dimensions or one yet.
But there are also things that you can do in three dimensions that you
can't, for example, do in four dimensions.
So a, you know, four dimensions plus time would be, would not allow
certain symmetries that we depend on to kind of have some coherent notion
of objects.
So, and, you know, I'm sorry.
I don't remember what these things are, but that's a really interesting
question and a lot of people work on it.
And an important part of it is, is why three, not four or more.
And three turns out to have unique, unique geometric properties that are
really cool.
So when people talk about extra dimensions and string theory or something
like that, all the extra spatial dimensions have to be rolled up into
tiny little packages so that they don't interfere with, with doing
anything macroscopically.
Where macroscopic is, you know, above the plank scale.
Yeah.
Yeah, this is really interesting.
Also, if it's about distinguishing between objects, then also this
question if space can be continuous, for instance, because making very,
very small changes in the continuous way won't lead you to different
positions, right?
So, yeah, this is where the limitations imposed by energy density
really make a difference.
Now the, the plank scale is tiny.
But if you, if you try to go to go beyond that, the, the, the energy densities
are so high that it, it sort of feels like you're getting big again.
It's, again, I don't have a good intuitive grasp on that.
But the, the, the existence of this energy distance relationship kind of gives
you a fundamental discretization of space for free.
And when you look at these quantum information types, they're, they're all
based in finite dimensional Hilbert spaces.
And there's been a huge transition way from the kind of old quantum mechanics
where everything was done in continuous Hilbert spaces to the much,
much simpler representation of doing things in finite dimensions.
The downside of that, it means that, that all of continuous mathematics,
like differential equations, becomes an approximation on the dynamics that's
conceptually simpler, but, but from a computational point of view, much more
Yeah, it's, it's really hard to grasp.
When I studied this stuff, I always imagine space time to be some kind of
cellular automaton, where you have like your little space grids and well,
communicating with each other with the speed of light, something like this,
that being the clock time of the, of the automaton.
But it feels like it's much more dynamic and space is really emerging and more
like a property you assign to particles or anything that distinguishes them
from each other and allows you to build correlations on top of other degrees of freedom.
So, yeah.
