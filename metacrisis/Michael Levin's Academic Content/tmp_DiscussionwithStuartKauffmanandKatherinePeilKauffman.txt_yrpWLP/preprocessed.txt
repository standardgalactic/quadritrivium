Can we start with your sorting algorithm paper?
Sure.
Sure.
We keep doing the most amazing things.
Why don't you talk about it for a while?
Kate, maybe you.
I think it ties into a bunch of stuff that I've done to Michael that I hadn't put together.
Also, that if that just is a possible agenda, then other possible things to consider or not
my end and not yet Kate's is I think I recent to the paper on a third transition in science.
Yep.
And the other thing is I've gotten to this very weird stuff that the Neumann's Universal
Constructor Self-Reproducing System is I think fundamentally wrong about life.
It's very strange, but it's an awful lot to talk about.
So why don't you take the lead?
Sure.
Sure.
And I'd love to I'd love to hear your thoughts on all of that.
Well, to the thing and of course I had seen your paper before and I'd I'd also seen the paper that you sent me and
there's a lot in common here that there's there's a there's a fundamental to two fundamental things that that are important that I try to address with that algorithms paper.
One is, I'm interested in extremely basal cognition.
In other words, I want to understand what are the simplest possible systems where already features start to creep in that are basically making the system amenable to the tools of behavioral cognitive
sciences and so on right like where where does it come in and the thing with biology I mean we can do and which we do in the lab we work on simple biologicals, but in biology there's always more mechanism to be discovered
so it's always possible that somebody says wow you just did way long enough you'll find a mechanism for it it's in their evolution baked it in there somewhere.
And so, so I was looking for an extremely simplified minimal model, which is transparent deterministic, and these these sorting algorithms are that that people have been studying them for many
decades every computer science student plays with them. We think we know what they do. There's only six lines of code or so they're transparent they're deterministic there is nowhere to hide.
There is no more explicit mechanism right like the algorithm is what it is that's it. There's no there's no, there's no, there's no more baked in features to be found.
And, and so so the basal cognition is what one angle and the other thing I'm really interested in, which ties into what some of your your two papers were about has to do with the emergence of first of all the emergence of novel agents.
And then the emergence of the goals of these novel agents, because typically when we look at a standard biological system and we say why does it have this structure why does it have this behavior the answer usually as well eons of selection.
Right it's been it's been selected to do specific things. And so my question is okay but but systems that have never been here before.
So where do their goals come from right and the emergence not just the emergence of complexity which is easy as you well know complexity is easy to emerge from simple rules, but the emergence of basal intelligence so goal directedness, some competency in
this definition of intelligence to reach the same goal by different means. So where do those come from where do the goals of novel composite systems come from. And so and so that's what I'm what I'm very interested in and so and so these.
So we have this in the lab with with Zenobots and now with Anthrobots and so on. And with these algorithms we just tried to make it as simple as possible look you have you have this, the standard algorithms.
And we only made two changes, otherwise they're exactly as they always have been the first changes that they are now distributed bottom up, meaning that every cell having a certain number has a has it is following an algorithm based on what the neighbors are about
to do there is no omniscient top down, you know, sort of universal controller that's that's running all of it. So each one has its own local preferences and its own local view of the world.
And, and we also break them, the assumption break the assumption of a, of a reliable medium. In other words, typically with these algorithms, when the algorithm says swap to numbers you they swap, and you assume that they swap and that's it.
In our case we say well, sometimes the cells are broken and sometimes they either don't initiate swaps or they refuse to be swapped or whatever. That's it. We don't give we don't add any code to the algorithm to to test for whether in fact in operation succeeded.
We don't give them any way of knowing how well is the sorting going overall they don't have any of that it's the traditional traditional algorithm.
And in the most important and so I think there are two most important things in that paper.
And the first one is on the basal cognition and which is this one version of competency of navigating some kind of problem space is what I call delayed gratification.
And there's an idea that when you come upon a barrier in your space, in order to sometimes in order to go around that barrier you have to temporarily be doing worse, and and William James is definitely an example is is magnets, two magnets, separated by a piece of wood.
The magnets are not able to go around the piece of wood because in order to do that they would temporarily have to get further from each other and they're not smart enough to do that.
They're always going to be minimizing that distance so all they're ever going to do is sit there pressed with their, you know, pressed up against the way where and then and then he says well now look at Romeo and Juliet they've got physical barriers they've got to social
barriers they have but but they have more skills they have a planning and memory and all these other things so they can temporarily get further from each other to then, you know, get closer afterwards.
So, and so and so your ability to do that your ability to temporarily make things worse in order to later achieve certain gains was so so so I call it delayed gratification so.
So, we simply asked, if you do introduce barriers in these algorithms journey towards being sorted, meaning the what when I say barrier I mean a cell that is broken and it's just not going to move you need to, you need to move it but it isn't going to move.
What we found is that when they come upon these barriers, they actually backtrack the sorting of the whole string gets worse, temporarily, and then eventually they sort of rearrange a bunch of other stuff and they eventually are able to do better.
Now, this is completely emergent this isn't baked into that there's nothing in the algorithm about any of this the algorithm doesn't ask whether the cell whether the cells moved it doesn't ask how you're doing that doesn't say anything about being able to backtrack.
It's the same old traditional algorithm that everybody's been playing with. And it turns out that it has this unexpected capacity to for delayed gratification in its problem space.
So that's so that's one big thing that we found. And then the other thing that we found is because we because we give the algorithms to each cell, as opposed to having one, you know, centralized one.
We get to do the kind of experiments we do in biology which is to make a chimera. So in our lab we make frog a lot of so frog a lot of are some cells from a frog embryo some cells from a Zen from a Zenopus embryo from from from an axolotl.
And each of them have different hardware they have different genetics you smush them together, and you find out that they actually get along perfectly well and they make a they make a new organism.
So that question like baby axolotls have legs, tadpoles don't have legs. If I combine frog and axolotl cells is a frog a lot of gonna have legs or not. We have no, you know, we have all the genetics you have the genome of the frog you have the genome of the axolotl you still can't say whether they're going to have legs or not,
because right you can't directly read the the the collective decision making an anatomical space from the protein level hardware which is what you get from reading the genomes.
So, so we made these chimeric strings and we found out that yeah they still sort perfectly well even if they're made up of different algorithms.
But the amazing thing is that if you ask, during that whole process of sorting, what does the distribution of the two algorithms and Adam Goldstein calls them algotypes I think it's a good word.
What's the distribution of these algotypes within any given string you find something really crazy.
At the beginning. So let's define this notion of clustering clustering just means I looked I look next to me and I asked, what's the probability that the cell next to me is the same algotype as I am.
Keeping in mind that these algorithms do not have any notion of algotype in them. They don't they don't store what algorithm they are they don't know how to check their neighbors there's none of this is explicit.
The algorithm doesn't do any of that this is all completely emergent somehow. And so what it turns out is that, okay, at the beginning of the whole process, it's the clustering is 50% it's at its lowest point.
And we do and it has to be that way because we assign the algotypes randomly to the to the to the numbers in the string fine.
And it's also 50% because by the time you've sorted them according to number.
The assignment is random with just like it was at the beginning so it's 50% at the beginning it's 50% at the end.
But in the middle, it goes like this and in the middle, it's quite a bit higher than that, because during that whole process, so cells with the same algotype try to hang out together, and they spend as much time as they can together.
And we know, and then what happens is and this is like, this is kind of crazy to say but it's it's almost, it's almost a minimal model of the human condition where, you know, you get a certain amount of time to do interesting things, but the laws of the of the world
you know the laws of your universe eventually like, right, like, like, like, yank you, you know, yank you from from where you were trying to be because the sorting algorithm can't be denied for too long it's going to sort the numbers eventually right.
So, but in the middle, they get to they get to hang out together. And we also we also did this thing I said well, let's just see how much what how much effort, how much do they really want to cluster, and the way to test it is to allow numbers to repeat.
So if I allow you to have multiple of every number, then as long as all your fives are in the correct location, you can cluster, you know, half of the fives are one algorithm half of the fives of the other and you don't get pulled apart you can keep that.
And so if you do that if you allow them to have multiple, then then the clustering goes even higher, because it obviously wants to cluster more it's just that the eventually the sorting algorithm takes, you know, can't be can't be resisted anymore.
So, so there's this crazy, there's this crazy innate tendency for them to cluster. I don't know what causes it but I have a I have a hypothesis about it that we're not sure yet I think it has to do with surprise minimization.
I think it's a kind of Firstonian thing where you cluster with with your own algotype because because they're they're the least surprising, they're the most like you basically.
Anyway, yeah, so so so that's the thing and and and this is just it's an it's an extremely minimal model. And it's got this nice feature which I think a lot of systems in this field have which is, you can take the sort of mechanistic reductionistic
to follow all the steps, and you're never going to see a miracle it it it the computer works correctly the algorithm works correctly if you if you insist on the on the, the kind of micro scale walkthrough.
Yeah, everything makes sense. But if you pull back and look at it from a from a larger scale, you see, oh, there's something going on here that it isn't because the laws are violated it isn't because you know at the micro scale these the you know there's any there's
it's because there's a larger scale pattern that's completely not obvious from the explicit algorithm that we put in. And if that dumb six line algorithm has these emerging capacities for novel, novel problem solving behaviors and you know novel
patterns that they try to maintain. Then of course, the more complex ones both in computer science and in biology will have them, you know, through the roof things that we can't even, you know, begin to expect so that's my that's my story of the of the algorithms.
It's really neat. Listen, let me just throw in one thing of Kate you want to go next with Michael.
Your zina butts are fascinating. And so is your axlottal frog chimeras. We can't possibly have time to talk about all of that today.
But I'd certainly love to talk about it and Kate might also some work here. So Katie, do you want to say some things or why do you want to do it.
If you don't mind.
I first I want to thank you for what you're doing because it's.
Oh my God, I've been walking backwards from psychology for well 30 years, wanting to understand what the valence of emotion really is and what it comes from. And when I found stews book the origins of order.
And the first time I've been exposed, you know, having a background in clinical psychology to the whole bottom up emergent self organization story so I was absolutely thrilled by that and me too.
Yeah, I know right. It was so evocative and people saw things in there that student really, but that's just how his genius is. So, I experienced your work as the next level of that, because I've been talking about emotion as a sensory system for
a very long time. And in the paper that I wrote which was the culmination of working alone for like 20 years and so there's a lot of stuff crammed together in there. That's what I did when I was in the Harvard community I wish I'd known about you right up the street at Tufts.
But that the, the chemical level.
I was pointing to ideas about self regulation, the immune system, genetic regulation, epigenetic, all that stuff being balled up in this deep, deep sensory or function of self regulation.
I had, you know, Candice Perts molecules of emotion there, and then I couldn't get any lower than that other than the concepts of feedback, a couple of positive and negative feedback. And now Michael Levin comes along and I can see exactly where using membrane potential is and changes
well either going to polarized or unpolarized and then ultimately being more negative and more positive. That's a very clear one to one relationship of what I've been saying about the value system. And that's where my interest is, is in psychology, you know we follow
physics, I mean we're reductionists and we're still stuck with Cartesian dualism and all that stuff. And sadly, even the best psychological stuff is based on this idea that there's dual processes in the brain right you got to bottom up quick and dirty.
And it is fouled somehow it there's something wrong with that and that you really need a long going through the you know that to that's wrong. There's a really, really deep evaluative system that comes up from these deeper things that that that's the value system.
And a nature is now I mean science supposed to say anything about values at all. And, and I think your work is really the perfect example of how everything is perfectly objective and observable, and yet kind of stays away from the subjective perspective which is taboo.
Of course in psychology, that's what it's all about it's about identity it's about personality free will. I'm seeing implications in what you're doing for the concept of free will that that there's clearly something going on there with the capacity to make decisions at all.
And the fact that all of this is emergent is amazing. The one thing I want to say about.
And you mentioned Mark Psalms and for stun as as where you're heading in this direction. And I, I'm absolutely right there with what they're saying but the one thing I want to pitch at you today is it surprise reduction is only monopolar.
It means that whatever memory system whatever, and whatever memory, there's, there's an internality here whatever, however, sat in the algorithm, it matches the external challenges the environment that all of those that's what that's about and that's definitely part of what I'm talking about.
The signaling system itself that organisms use is bipolar, and that when you're getting that positive feedback signal, it's got a valence to it, that when memory potential is depolarizing it's, it's, it's going up if you will and if it's depolarizing it's going down if you will.
And that the depolarization, then when you get back to positive and negative charge, negative charges associated with healing and regeneration right. Have I got that right, and positive charges associated with damage and degeneration.
So, I'm finding an exact link between what I'm talking about is the source of values and know why we experience feelings in pleasurable or painful categories. You do have to go to subjectivity, but that's, I think, a key part of what basal intelligence is about, because without that valence, you don't really have a decision
making what like, okay, what am I what state am I what what state is my neighbor you have to and then it gets down to the idea of self versus and not self comparison between yourself and the environment. So all of that stuff I tried to wrap into that paper, but
I have to have what you're saying, and please correct me if I'm bastardizing your work in any way, but that it that the implications for, for values and ethics and all of that entire realm of social systems are right buried right here and what you're doing as far as I see.
Yeah, no, I think I think you're absolutely right in the sense that if if when you when you have simple emergence like you get in fractals or you get in cellular automata.
It's free of valence because okay complex things happen you know a glider goes this way glider goes that way it's all sort of equivalent. But as soon as you get emergence of these homeostatic or homeodynamic systems, which expend effort to try to keep specific states.
That's it now you're in the land of valence and values and everything else like Mike, you know micro level, because because not all states are equally preferable they will actively try to reach a specific and sometimes they're quite, you know, they have all kinds of competencies and doing that.
So, so already you start to see and then and then the question that becomes well so so where did, where did those specific preferred states come from why is it that this this is the one they like instead of, you know, instead of instead of that one and, and I really think that's one of the grand mysteries.
And the next that we need to deal with, you know, not just emergence of complexity but but specifically emergence of goal directed intelligence and develop some kind of science to try to guess these goals because we make things all the time is you know find for the swarm robotics and internet of things and
institutions and social institutions and we have an biological chimeras and so on, we have very little ability to guess what the goals of the system are going to be and what the competencies of that system are going to be to implement those goals in the face of resistance.
And we need to develop a science that I think.
Take a turn you guys.
Okay, so a whole bunch of things.
I want to focus on your bottom up, and you're allowing things to crap out and die. Okay. But before that, Michael, and thanks, Kate.
So just briefly, and it's in our third transition and science paper.
I think things focus on living cells and living cells.
The goal of a living cell is to get to continue to exist by its project. That's what gets selected. And the goals that emerge aren't set from the outside, like we do when we're programming it.
It's, it's, you know, it's what useful to it.
That's why your chimeras and your scene about seems so fascinating to me.
But now put that aside, Michael, I realized when I read your paper and thinking about I think that for some years I've been doing things that are cousins of what you've done and there may be something really general going on.
So let me try to tell you, when you take your, your algorithm and you make each, each number an agent. So it's now bottom up.
There's no outside control of the total system.
So they're now in a sense co-evolving with one another, trying to do whatever they're trying to do.
Years ago, I found myself doing something similar, and then similar in another way. You know that I made this NK fitness landscape model.
This rugged landscape. So this is in 1995 at home in the universe.
Yep.
So we just, we just made a big square lattice, you know, N by N, where there's N squared points and each point is a little site is a, and it's just the NK model.
And you can think of that thing as one big patch, which is one thing.
And you implement, you implement a cousin of your letting things die. It's just a finite temperature.
So the system goes downhill and energy, but every now and then it fucks it up, but it goes uphill and energy.
So it's a Monte Carlo.
And we ran this and we asked, all right, how long you go downhill until you get to some minimum.
Then because errors are made, you kind of wander around and you can ask, ask, you know, how low energy do you get to.
Then we took this big patch that's N by N and we broke it up into four quadrants, four patches.
And the rule now becomes your, the move you made each patch, Northwest, Northeast, Southwest, Southeast makes moves that are good for it.
But when it does so, it screws up things for the, the patches on its boundaries.
So the patches are now co-evolving with one another.
So it's becoming separate agents.
Then we made the patches smaller and smaller in size and more and more numerous.
And we asked, well, what happens to the energy you get to the remarkable thing is just what you found the system as the patches get smaller and more numerous.
The total system does better and better and better and better and gets ever lower energies.
So breaking the thing up, do a bunch of co-evolving things, does something really good.
Then it turns out something amazing happens.
There's a phase transition when the patches get too small.
The thing becomes chaotic and it screws it all up.
So the optimal behavior is found right at that boundary.
So hold that.
So what's going on in this case is it's like yours.
There's something about breaking things up so that it's bottom up that allows better behavior to emerge.
It's like yours and the fact that given the Monte Carlo simulation and finite temperature, the things find alternative ways of getting to wherever they're going.
And this led to something just amazing about 12 years ago.
I was at the university.
So this is maybe really important and really general and we're both getting at it and come in too because emotions are all over it.
So I was at the University of Vermont and we were asking, I was talking, I'm a doc and I was talking to a friend who was a doctor and we were thinking about fitness landscapes.
And you know, there's randomized clinical trials, which are the Beall and Endall and they're just big T tests.
So he asked, in the NK model, you can tune the structure of the landscape.
So we asked if you have a single peak landscape like Fujiyama or you have a rugged landscape.
Does randomized clinical trials work well?
That was where we started.
And it works well on a single peak landscape just screws up all over the place on a multi peak landscape.
Well, I expected that the Jeffrey Horbar, my colleague, had a really neat idea that's related to what you just did with the your algorithm, the bottom up.
He said there are quality improvement centers emerging in medicine, where if you have 100 hospitals, they break up into 10, 10 groups of 10 hospitals.
Each one is a quality improvement center.
And within the quality improvement center in real life, the 10 hospitals in the quality improvement center are trying to do something neat like they want to find a good combination of procedures.
Now you can do the procedure or not.
And here's.
So the deal is they try a given procedure with one of these centers.
And if on anecdotal evidence, not statistically, it looks like a good idea.
It's okay, let's do it.
And then if it doesn't look good later on, they just take it back.
So we implemented on a computer, Michael.
Now the anecdotal evidence is incomplete information.
It's noisy information.
It's not quite knowing what you're doing.
It's messing around.
And what we found on a computer is a computer model of it is we did it on a computer and it radically outperforms randomized clinical trials.
We think therefore the large message of your bottom up is if you can connect a large number of people to try to solve a hard problem.
And you break them up into little patches where different groups try things and based on anecdotal evidence say, that looks like a good idea.
Let's try it.
And if not, you say you take it back.
They'll solve really hard combinatorial optimization problems that you'll never do if it's all one big system.
And that's what you're finding too.
There's something really general going on and to finish up this book.
I'm involved in trying to get going on global soil restoration.
And the idea is to try to create a global creative commons computational network for hopefully millions of farmers where people can upload data, share on it, share it with who they want and try to solve whole hard problems.
And the same thing would work in clinical medicine.
So there's something about this bottom up noisy sloppy trying things on anecdotal evidence that actually works.
And the final thing to say about this is if we're 30,000 years ago and you had a toothache and you were in the south of France, you'd go to the medicine woman.
She would say, Michael, you need the following six herbs.
And they basically would work.
Noted it a randomized clinical trial.
How do we learn that.
I think we and I think evolution, something like that too. And now I'm done.
Yeah, yeah, very, very interesting. Well, you know, the, the, the clinical trial thing I've always, I've always wondered, you know, acupuncture, which, which I've benefited from many times.
I was like, how, how long would it take actually to, you know, how many patients would you need from if you were starting from scratch and you needed to know, you know, where the points were for specific disease.
I can't imagine the size of right the data sets you would need. It just seems.
Nobody did a randomized clinical trial and developing acupuncture.
Yeah.
Randomized clinical trials, you know.
Yeah.
You know, we learned key tests. So we thought we were being scientific.
There's a, there's a funny, well, there's, there's two, there's two things. One is experimentally, and this was, we put out the, this, this reprint a while back, and the real, the real paper should be out soon, looking at groups of embryos responding to
teratogens. And it turns out that embryos are actually communicating with each other. And there's a whole, what I think is going to be a kind of
a hyperdevelopmental biology where instead of looking at how a single embryo develops, what you're looking at, how, how, so when standard developmental biology individual cells work together to build a nice embryo.
But in fact, groups of embryos are also working together and we can now track, we can see them communicating with each other. So we have, we have techniques to watch the information go back and forth.
And they literally large groups do, do better than singletons or small groups in resisting certain teratogenic influences.
And they have gene, the group, what larger groups has gene expression that small groups don't have. So, so that, that, that sort of meta embryo has its own transcriptome.
That's distinct from, from the transcriptome of any of its, of any of its members, and they can solve problems.
Now, I don't know as you as in your example, you know, one possibility is that if you had even bigger groups than they wouldn't do as well, right, there may be like a critical, you know, critical range we don't we don't know all we know is that the size groups
that we work on which is about, you know, 300 embryos or so do way better than, than smaller groups.
Amazing. So there are cousins. I'm doing, sorry.
So I'm working with a guy named Jan Dijkster house in Holland, and his colleagues, we're doing the 140 species experiment.
It's underway 70 DNA sequence bacteria, 70 genotyped fungi, it's hard to sequence all things. And we're, and we're mixing that we're, we're in the process of, we have a couple hundred 250,000 euros, make this mix community,
played out aliquots of it on sterilized soil and 50 aliquots and watch it for a year or two.
Well, they're going to do all kinds of things with one another. This is, this is so these guys are going to learn with one another to they're going to solve problems and all kinds of ways.
What, what is the transcript? Don't make that. What are the gene activity patterns would be identical the different 50 aliquots, almost certainly not.
One of the fascinating things is from the, the third transition in science paper, Michael Gates, here we talk about this, we cannot predict what, well, these things in Jan's phrase, an evolving community creates bubbles of new possible ways to exist together.
And we can't predict what they'll be, but we can see the ones that were useful that were seized by heritable variation and natural selection.
So we can ask for the same mutations occur in the 50 aliquots and in the same sequence. Well, of course they won't.
Well, these, this is a co evolutionary assembly, and one can begin to look at the genetics of it. And it feels like without having, I'm just hearing you, what's going on with 300 embryos talking to one another.
What's going on in a tissue, these things are talking to one another. Exactly. You know, and the same things around in, in the evolution of an integrated economy.
If you took random bits of technologies from around the world and stuck them into place, they wouldn't work together. They work together because they came into existence together.
And you're looking at all kinds of Darwinian pre adaptations and your zenebots and stuff, which is so amazing.
Yeah, I mean, one of the things that we've been we've been studying and some of this is out and some of this hasn't hasn't come out yet is how how evolution works when your material is a gentle.
So if you have a right if you have a hardwired material that just sort of does what it does, then we know what evolution does it. Yeah, you know, it's it searches through these rugged spaces and all that.
But when your material is itself an agential material where the it's got a multi scale nature to it where where every every scale has its own agendas and it's solving various problems, then the whole process of evolution is different.
And all kinds of all kinds of things don't look at all classical when and so so you can keep the random mutation the intelligence isn't in the mutations but but when the material is smart, the whole process comes out completely different.
And that's, you know, that's, we've, we've got some some cool computational studies coming out on that.
I don't know what others talk about.
Go ahead.
Yeah, there's so much to talk about.
So when I talk about Conti and holes, right, you're familiar with that concept where you have a well, an organizational closure where you have in stews, you have the bottom up is it so I'm, I want to say that there's both, both top down and bottom up pieces here that we need to
in the, you know, introducing this idea of the condy and whole because that that's how we've talked about it before. So the idea is that there's parts that are doing something that gives rise to a global hole, which then provides the constraints on on those parts to do what they
are doing, and whatever else, you know, so there's the freedom from the bottom up and there's constraint from the top down, which kind of gets at the coupling of positive and negative feedback that I was talking about, you know, the homo homodynamic functions of the
but that the idea of work is something that needs to go in here because intelligent doing is work and when he talks about bottom up work and top down constraints as part of constraint closure.
The idea that well energy release within a few degrees of freedom is how you define work right still, but that when you put agency in there, then the idea of work becomes a self regulatory thing where the parts are doing something and then the hole is doing something
new. So you have this dance of parts and holes that I think is necessary for not only constraint closure, operational closure, organizational closure that's talked about in different ways, but informational closure.
And what you're talking about certainly in the role of bio electricity, being a kind of the glue that works at every different level. So with that idea in mind.
Watch some really beautiful stuff by a friend of yours.
Richard Watson. Oh yeah, his whole business on resonance and and amazing amazing right. Well, not only is it amazing but it's, he's getting at exactly what my emotion thing because there's there's kind of a phase lock loop going on with the three
pair signal cybernetic loop that I've described, because it's there, actually I met a guy in music that was he said have you ever heard of a phase lock loop that's what we use in in music to tip positive feedback and we use it for this we use it for that.
And when I see what you're doing with the electro the bioelectric layer and the signaling is basically that same three step process with the positive feedback signal being either the increase or decrease in membrane potential.
Right, or positive and negative charge so that that would be a manifestation of how phase locking occurs between. Well, well, when you think about electromagnetic field, it's really the same thing as a whole bunch of individual oscillators.
I read that somewhere, but that the idea of sinking them together where the connectivity is the sink the individuals are able to do something simple that matches what their nearest neighbors are doing. So, in that same signal if you have like,
Well, I have an edge of chaos story here that's probably very much like the least energy story as well, in that the resting state is the edge of chaos the home state that one goes back to.
But when since we're non equilibrium systems, we need to be off the edge of chaos on a regular basis, and we're either either going to conserve our energy to preserve our form, or we're going to exploit that that energy that entropy to do something creative and do some growth.
And that's the dance of self preservation and self development that I talk about as this really, really, really deep thing that's going on in networks.
Those two things are being balanced all the time like, you know that like the Dow.
So, with with all that said, the idea of a Kantian hole and the idea of information closure means that like the simple rule for the part would be to get back to the edge of chaos but one went off to exploit to do try new things out like when
in a situation where the stressed environment of a bacterium, their genetics becomes really loose like they're trying new things out. And if whatever sticks gives a new level of global organization which then feeds back down as, as, you know that that
kind of hole. But what I'm suggesting is your, your friend with the story of songs is exactly that, because at the parts, you know, you're, you're, you're exploiting the chaos to either preserve what you're doing and duplicate what you're doing, or you're going to try something
and all of that stuff there's flexibility just in our genetic system for all of that kind of stuff you've got redundancy you've got all kinds of a novelty, but that it's the whole that feeds back down.
So, staying on the edge of chaos is something that is a simple rule for the part to get back to, but that in order to maintain that connection with the whole, there's a harmonic resonance thing going on at the same time.
And then you get into stuff like pink noise and the which is a classic marker for criticality, which is this whole edge of chaos kind of kind of thing so all of that stuff is wrapped into my questions to you about this beautiful layer of
simplicity and how the binary opposites that are interacting, give rise to the value system and valence and I think that there's a pretty clear story there. And if I can articulate it I'll share it.
Yeah, that's great. Yeah, I mean, we so we track this, this business of the parts and the whole from the very beginning of embryogenesis because.
Initially, let's say, let's say you're looking at a blastoderm of a mammal or a bird or something and it's, you know, 50,000 cells. And we all look at it and we say oh there's an embryo.
But what are you counting when you say there's one embryo what is there one of their 50,000 cells what is there one of what there's one of is is actually a kind of alignment like literally a physical alignment of the cells in terms of planar polarity but also
a morphological alignment in that all of them are going to work towards the same journey in the anatomical space they're going to make this particular structure.
Well what you can do is, and this is something I used to do as a grad student in duck duck eggs, you can take a little needle and you can and you can scratch the black put some scratches in that blastoderm.
So it's four to six hours, each of those islands that you've created doesn't feel the presence of the others, and they decided they're alone and they're going to make an embryo and they align to be an embryo and each one of them does it.
And then when they heal up well you've got conjoined twins and triplets and.
So, so the question of how many individuals are in an embryo is not set by the genetics it's not known from the beginning it could be anywhere from zero to probably have you know the half a dozen or more.
And it's a it's a it's a auto poetic process that you know they kind of put themselves together and they have to each one has to decide where because every cell is some other cells neighbor.
So they have to decide where do I end and the outside world begins. And when they do heal up. This is the reason why in human conjoined twins one of the twins often has laterality defects, and that's because the cells that are in between on the border.
They have a hard time deciding am I the left side of this one or am I the right side of that one. And sometimes they make a mistake and you can get organs that that you know they go the wrong way.
And so during that process by electricity but also other modalities are used by the cells to synchronize into a coherent whole that's going to take a particular a particular path in anatomical space and physiological space.
And, and, and it has a self model that tries to demarcate it from from the outside world and everything it does is in the service of maintaining the goals that that new system is going to have and for traditional systems we kind of say well evolution
that they gave us that gave it those goals and then we call it a day but but but that of course doesn't doesn't do the trick because now we can make completely new ones that that have never existed before and they have they have goal states to that they exert lots of effort to try to
maintain, and they have all kinds of competencies to try and maintain it.
Yeah, and I think I think you know this business with the with the with the first the xenobots but now they answer about so the human derived ones is just the is just the beginning of having these these novel systems with a perfectly wild type of genome you know
like the one with the first apians in the one case of Xenopus lavas and the other that have different competencies and different different behavioral repertoires and, and we're just beginning so so you know we don't know what the, what
what their learning capacity is what their actual behavioral goals are we're going to find out all of that we're trying to train them and, you know, do what their preferences are.
Yeah, we'll see but but none of it is easily predictable at all for like nobody nobody saw any of that coming so.
You know, we've tried human skin cells that are made with lung cells right. Yeah, the reason.
Yeah, yeah, I'm sure you can do it with with with lots of different cell types the reason we went with lung is because it because being ciliated they move physically, and it's easy when when people see physical movement they they it's easy for them to understand.
I think that a lot of important behaviors take place in other spaces like transcriptional space and physiological state space and anatomical morpheus space, it just people are not comfortable recognizing that as behavior.
And I suspect that a lot of the what people call organoids that they're making now are basically they basically have locked in syndrome, like they're there they're in there and they're trying to do all kinds of things we can't see it because they're not running around and and that's all where
that tune to is, is movement in three dimensional space I think if we, if we understood how to measure the states of these things properly we would see that they're solving all kinds of problems in other spaces.
Yeah, yeah, that's what I asked about the epithelial cells because that's how we directly encounter our environment and move about in our environment so there's a bioelectric effect.
I mean, I love what you're doing because there's, you know, an alternative healing modalities including acupuncture which you measured there's always this idea of subtle energy.
And some of the new age ideas have gone crazy with it and that I, I, I'm looking for really natural spirituality, and where values come from a divorce from the dogma of religion, but that they do have their thumb on the pulse of something
that's really true and real about human healing, and all of that so the, the, the layer of bioelectricity I mean that that's energy, right, would you say that that's subtle energy would you say what would you call it what would you call it is it
We've had, yeah, we've had a bunch of discussions with those folks and I, you know, I don't know that I don't have any, any evidence to say that the phenomenon they're calling Chi is specifically what what we study as bioelectricity I don't know that those are the same things.
But, but I do think they have a couple things right and one of the things that they were right very early about is this notion of multiple intelligences within the body, this idea that literally not not metaphorically not to, you know, not not to you know
But, but actually literally with a very, with a very specific definition of intelligence as problem solving in various spaces. The fact that our body is full of sub agents that have agendas that have a problem solving competencies, like, so, so they, I think they were 100% on the money about that one.
And the other thing is this notion of persistent physiological states as, as, as objects. So, you know, they'll tell you like if you if you do, yeah, I don't know either massage therapy or something they'll say oh you've got this blockage that you know this thing is sitting here and we're going to try to, we're
going to try to move it or we're going to try to get rid of it or this this this idea that these other spaces like physiological state space and so on.
There are persistent patterns in those spaces that are the equivalent of objects in three dimensional space that are there they have causal they have causal power they do things.
They have their own dynamics and they're persistent over some amount of time and they can be moved and they can be, you know, modified and, you know, and some of them are contributed to disease no doubt that like I think I think that's a that's a that's a very promising direction
we're doing a bunch of, we're starting a bunch of work on on on being able to detect them and developing predictive technologies to then manipulate them. So, so that's yeah I think that's going to be a part of real medicine.
Very cool.
Good question.
Are you interested, Michael and Kate too. I'm running across this very strange thing in which I think von Neumann is wrong in a fundamental and very puzzling way.
It would take a few minutes to talk about and we've been going for a while so we I don't we don't need to bring it up at all or bring it up some other time, or just continue where we are.
Why don't you call it Michael what I'd love. I'd love to hear about it.
I've got till I've got another nine minutes before I have to hop off of it so we could talk about it I'm also very happy to schedule another one of these so I can hear in more detail if I mean I'm guessing it's going to take more than nine minutes to talk about it.
So, I can get the puzzle started. Yeah, let's do it.
So, so von Neumann in 1956 post posthumously published a paper on self reproducing automata, and it's brilliant.
So here he comes and he's, he's helped invent the universal Turing machine called the von Neumann architecture, and he wants to make a machine that can copy itself.
So here's the logical steps. He's going to make a, this is going to work in the real physical world is actually going to build things. It's not going to manipulate bits. So he starts with the universal constructor.
So the universal constructor can construct anything.
If that makes any sense so let it go. But then this is very interesting because for the universal constructor to construct anything in particular, you better have some instructions.
He imagines the instructions as some physical system, like a bunch of steel I beams jointed together in some way for the universal constructor to make anything specific.
You better have access to these instructions.
So you put the instructions or this structure inside the universal constructor. And once you do that something magical happens, the, the information, the instructions now play a dual role.
They are used to direct the universal constructor to construct something specific, namely a copy of itself.
It could have made a, you know, a choo choo train, but it made a rapid. I mean, it made a copy of itself. So now there's this copy of the universal constructor sitting over there.
But it can't make anything until it has inside of it some instructions on what to make.
So von Neumann's move is okay, the universal constructor constructs a physical copy of the instructions.
And sticks the physical copy of the instructions in the second new universal constructor. So that's a lot. Okay, that's the basic idea.
It was hail isn't that wonderful. That's what DNA does a template replicates, and it's used as a code for synthesis of proteins, then the DNA gets replicated by the machinery and stuck in the daughter cell and that's true.
And we've been stuck there, or we've been. So I could, it's entirely wrong for at least some self reproducing molecular systems. So I can get us started Michael Kate certainly a guy named you know I've been thinking about auto
kinetic sets for over 50 years going in Ashkenazi in the Ben Gurion literally has a nine peptide collectively auto kinetic set.
And so let me define more precisely what a Kantian hole is. It's Kant's idea that mine, the parts exist for and by means of the whole.
So you're a Kantian hole you exist for by means of your living your kidney and your spleen, but they exist by means of you.
So all living things are Kantian holes.
So gonon's auto kinetic set of nine peptides is a Kantian hole.
Each peptide catalyzes the formation of a second copy of the next peptide right around a cycle of the nine peptides.
Each peptide gets to exist by virtue of being a member of the nine peptide set.
So the nine peptide sets the Kantian hole and each peptide is the park. So it's true it's Kantian hole.
Two more notions catalytic closure which I had a long time ago.
Every reaction that a last step in the reaction stop making anything is catalyzed by somebody so it's collectively auto catalytic.
And it is, then there's this idea of constraint closure which Kate hid that when I was writing investigations I was wondering so what's work.
And work is the constraints this is Atkins in the second law work is the constrained release of energy into a few degrees of freedom.
So I finally understood that's a cannon with the powder at the base of the cannon and the cannonball.
And the cannon is the constraint on the release of energy.
And it's boundary condition.
So when the powder explodes, you don't get a spherical wave.
You get the powder only can that blast goes down the bore of the cannon and it does thermodynamic work on the cannonball.
Then I being, you know, we're both, you know, Kate's not a Jew but we are I thought so, you know, where the fuck what the cannon come from.
And I realized that it worked to make the cannon.
Oh, no constraints on the release of energy no work.
But at least in some cases no work no constraints on the release of energy.
And I got stuck there Michael except that I realized that the release of energy could construct a new constraint.
So I'm going to give you the brilliant idea. It's transformative that Matteo Mocio in my alma mater bill had in 2015.
So there's a lot to pack into nine minutes but here it is three minutes, three minutes. I'll get it across.
So, I want to get, I want to get some constraint release of energy. So I better have some non equilibrium processes so these two guys say let there be three processes one, two and three.
They're not equilibrium processes, but there better be some constraints on the release of energy so let there be three constraints.
So pause and really hear this a constraints release of energy in process one, and it makes a be be constraints release of energy in process two, and it makes a see see constraints release of energy in process three.
And it makes an egg.
This is an amazing thing Michael, and it's not mine so I can really brag about it. This is a new organization of matter in process. There are a set of constraints the constraints are boundary conditions.
The three boundary condition constraints, constrain the release of energy in three not only putting not equilibrium process to construct the same boundary conditions. The system constructs itself.
This is the heart of life right here. We construct our choo choo trains. They don't construct themselves.
So, going to Ashkenazi set does this and I'll try to say it quickly. Each peptide finds two fragments that are half copies of the next peptide.
By binding them, it orients them in three space so it lowers the activation energy for the reactions.
So there's a constraint release of energy, a peptide bond is formed and work is done when peptide one makes a second copy of peptide to around the cycle.
So this system going on Scott is a Kantian hole that achieves constraint closure and catalytic closure.
I think that is probably Berksons and lampy.
And I think it's like, now look at what the system does Michael and Kate certainly said this system constructs specifically itself.
The nine peptides that constructs itself and so does the cell specifically constructs is it's not a universal constructor. And the amazing thing is,
there's no separate description. There's no instructions in going on Ashkenazi's nine peptide set.
It's nine peptides at each peptide is a boundary condition on the list of energy making the next peptide. That's the whole thing.
There's nothing more to be said. There's no separate description. There's nothing which is acting as instructions that are getting copied and stuck into a second copy.
This is now we are not getting to dinner. It's just not a Celtic peptide set.
So this system specifically constructs itself because it's the constraints on the list of energy that constructs the same constraints.
It's absolutely not by nine ones universal constructor.
And it doesn't change very much when you get DNA into it. So there's something very strange going on.
I have what we mean by information and how can we that there's something that we call information that von Daumann's talking about.
It's really puzzling. Do you see the distinction.
Yeah, yeah, no, I absolutely do and even even even the the story you contrasted with with the DNA story is partly this anyway because DNA is not a description of the organism.
Does not have a description of the anatomy. I mean, it's basically.
Yeah, DNA and an easy way. Yeah, DNA can be thought of as a code because it is it specifies polypeptides.
And Paul, Paul, Paul Davies points out that given the translation apparatus of the code, the DNA is a universal constructor for incodable polypeptides.
Yeah, polypeptides not not an atom, not a cell. Yeah, so you know, if you if you were to take a yeast cell and clone random DNA sequences at all the genes, it'd make a bunch of polypeptides, but the cell would die.
Right.
That whole thing we should. So we should have another talk about what what what level of reprogrammability we see in biology because there's some cool there's some cool examples and it's not about DNA at all but there but there's some interesting examples of
Let's let's do let me I know where to look. Let me just give you one other piece. It's so puzzling.
So we have a notion of what information is. There's a Mondrian painting. And I want to know how much information is in it. I'm asking how many bits.
And this is a take to describe the Mondrian painting. So I break it up into centimeter by centimeter squares. And there's 10,000 of them, because I did you know 100 by 100 or whatever it is.
And then I use four bits and say what colors there.
This 40,000 bits is the description of the Mondrian painting. And it's really true that I could send that over a computer to printing machines all around the world that use totally different machines to make different kind of physically different ways of making copies of the Mondrian
paintings.
So the information really is separable from the goddamn Mondrian painting. And we just did it.
That has nothing to do with how to go to Ashkenazi's peptide set copies. There's no separate description.
There's something funny about our notion. And I've got a loose hunch that I've sort of said to you to Kate. It's something about a description from the outside.
We are giving a description from the outside of the painting. Von Neumann is a giving a description from the outside and sticking that outside description and that is then used in a dual way as a program, and then gets copied.
That's not how that's not how cells build themselves Michael or something fundamentally wrong with that and that means there's something finally fucked up about our notions of information.
It's the wrong work of it's confused. It's really true that we could describe in, you know, 40,000 bits the Mondrian painting, and we can send it over computer wires around the world and make 10 zillion copies of it.
But we're using those machines all over the world to do it. And there's nothing specific. We could have made a copy of anything. Life isn't doing that. It's doing something fundamentally different.
At this point I really get confused.
Yeah, that's a great, that's a great place to take up the next one. That's a very good point and there's some stuff. Yeah, I have to unfortunately I have to run but let's set up another one and keep going because you're on to, I think you're on to something very key.
Well there's all kinds of stuff.
