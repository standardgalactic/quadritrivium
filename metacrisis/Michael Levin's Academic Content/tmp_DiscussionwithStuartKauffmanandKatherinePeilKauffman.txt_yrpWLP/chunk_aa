Can we start with your sorting algorithm paper?
Sure.
Sure.
We keep doing the most amazing things.
Why don't you talk about it for a while?
Kate, maybe you.
I think it ties into a bunch of stuff that I've done to Michael that I hadn't put together.
Also, that if that just is a possible agenda, then other possible things to consider or not
my end and not yet Kate's is I think I recent to the paper on a third transition in science.
Yep.
And the other thing is I've gotten to this very weird stuff that the Neumann's Universal
Constructor Self-Reproducing System is I think fundamentally wrong about life.
It's very strange, but it's an awful lot to talk about.
So why don't you take the lead?
Sure.
Sure.
And I'd love to I'd love to hear your thoughts on all of that.
Well, to the thing and of course I had seen your paper before and I'd I'd also seen the paper that you sent me and
there's a lot in common here that there's there's a there's a fundamental to two fundamental things that that are important that I try to address with that algorithms paper.
One is, I'm interested in extremely basal cognition.
In other words, I want to understand what are the simplest possible systems where already features start to creep in that are basically making the system amenable to the tools of behavioral cognitive
sciences and so on right like where where does it come in and the thing with biology I mean we can do and which we do in the lab we work on simple biologicals, but in biology there's always more mechanism to be discovered
so it's always possible that somebody says wow you just did way long enough you'll find a mechanism for it it's in their evolution baked it in there somewhere.
And so, so I was looking for an extremely simplified minimal model, which is transparent deterministic, and these these sorting algorithms are that that people have been studying them for many
decades every computer science student plays with them. We think we know what they do. There's only six lines of code or so they're transparent they're deterministic there is nowhere to hide.
There is no more explicit mechanism right like the algorithm is what it is that's it. There's no there's no, there's no, there's no more baked in features to be found.
And, and so so the basal cognition is what one angle and the other thing I'm really interested in, which ties into what some of your your two papers were about has to do with the emergence of first of all the emergence of novel agents.
And then the emergence of the goals of these novel agents, because typically when we look at a standard biological system and we say why does it have this structure why does it have this behavior the answer usually as well eons of selection.
Right it's been it's been selected to do specific things. And so my question is okay but but systems that have never been here before.
So where do their goals come from right and the emergence not just the emergence of complexity which is easy as you well know complexity is easy to emerge from simple rules, but the emergence of basal intelligence so goal directedness, some competency in
this definition of intelligence to reach the same goal by different means. So where do those come from where do the goals of novel composite systems come from. And so and so that's what I'm what I'm very interested in and so and so these.
So we have this in the lab with with Zenobots and now with Anthrobots and so on. And with these algorithms we just tried to make it as simple as possible look you have you have this, the standard algorithms.
And we only made two changes, otherwise they're exactly as they always have been the first changes that they are now distributed bottom up, meaning that every cell having a certain number has a has it is following an algorithm based on what the neighbors are about
to do there is no omniscient top down, you know, sort of universal controller that's that's running all of it. So each one has its own local preferences and its own local view of the world.
And, and we also break them, the assumption break the assumption of a, of a reliable medium. In other words, typically with these algorithms, when the algorithm says swap to numbers you they swap, and you assume that they swap and that's it.
In our case we say well, sometimes the cells are broken and sometimes they either don't initiate swaps or they refuse to be swapped or whatever. That's it. We don't give we don't add any code to the algorithm to to test for whether in fact in operation succeeded.
We don't give them any way of knowing how well is the sorting going overall they don't have any of that it's the traditional traditional algorithm.
And in the most important and so I think there are two most important things in that paper.
And the first one is on the basal cognition and which is this one version of competency of navigating some kind of problem space is what I call delayed gratification.
And there's an idea that when you come upon a barrier in your space, in order to sometimes in order to go around that barrier you have to temporarily be doing worse, and and William James is definitely an example is is magnets, two magnets, separated by a piece of wood.
The magnets are not able to go around the piece of wood because in order to do that they would temporarily have to get further from each other and they're not smart enough to do that.
They're always going to be minimizing that distance so all they're ever going to do is sit there pressed with their, you know, pressed up against the way where and then and then he says well now look at Romeo and Juliet they've got physical barriers they've got to social
barriers they have but but they have more skills they have a planning and memory and all these other things so they can temporarily get further from each other to then, you know, get closer afterwards.
So, and so and so your ability to do that your ability to temporarily make things worse in order to later achieve certain gains was so so so I call it delayed gratification so.
So, we simply asked, if you do introduce barriers in these algorithms journey towards being sorted, meaning the what when I say barrier I mean a cell that is broken and it's just not going to move you need to, you need to move it but it isn't going to move.
What we found is that when they come upon these barriers, they actually backtrack the sorting of the whole string gets worse, temporarily, and then eventually they sort of rearrange a bunch of other stuff and they eventually are able to do better.
Now, this is completely emergent this isn't baked into that there's nothing in the algorithm about any of this the algorithm doesn't ask whether the cell whether the cells moved it doesn't ask how you're doing that doesn't say anything about being able to backtrack.
It's the same old traditional algorithm that everybody's been playing with. And it turns out that it has this unexpected capacity to for delayed gratification in its problem space.
So that's so that's one big thing that we found. And then the other thing that we found is because we because we give the algorithms to each cell, as opposed to having one, you know, centralized one.
We get to do the kind of experiments we do in biology which is to make a chimera. So in our lab we make frog a lot of so frog a lot of are some cells from a frog embryo some cells from a Zen from a Zenopus embryo from from from an axolotl.
And each of them have different hardware they have different genetics you smush them together, and you find out that they actually get along perfectly well and they make a they make a new organism.
So that question like baby axolotls have legs, tadpoles don't have legs. If I combine frog and axolotl cells is a frog a lot of gonna have legs or not. We have no, you know, we have all the genetics you have the genome of the frog you have the genome of the axolotl you still can't say whether they're going to have legs or not,
because right you can't directly read the the the collective decision making an anatomical space from the protein level hardware which is what you get from reading the genomes.
So, so we made these chimeric strings and we found out that yeah they still sort perfectly well even if they're made up of different algorithms.
But the amazing thing is that if you ask, during that whole process of sorting, what does the distribution of the two algorithms and Adam Goldstein calls them algotypes I think it's a good word.
What's the distribution of these algotypes within any given string you find something really crazy.
At the beginning. So let's define this notion of clustering clustering just means I looked I look next to me and I asked, what's the probability that the cell next to me is the same algotype as I am.
Keeping in mind that these algorithms do not have any notion of algotype in them. They don't they don't store what algorithm they are they don't know how to check their neighbors there's none of this is explicit.
The algorithm doesn't do any of that this is all completely emergent somehow. And so what it turns out is that, okay, at the beginning of the whole process, it's the clustering is 50% it's at its lowest point.
And we do and it has to be that way because we assign the algotypes randomly to the to the to the numbers in the string fine.
And it's also 50% because by the time you've sorted them according to number.
The assignment is random with just like it was at the beginning so it's 50% at the beginning it's 50% at the end.
But in the middle, it goes like this and in the middle, it's quite a bit higher than that, because during that whole process, so cells with the same algotype try to hang out together, and they spend as much time as they can together.
And we know, and then what happens is and this is like, this is kind of crazy to say but it's it's almost, it's almost a minimal model of the human condition where, you know, you get a certain amount of time to do interesting things, but the laws of the of the world
you know the laws of your universe eventually like, right, like, like, like, yank you, you know, yank you from from where you were trying to be because the sorting algorithm can't be denied for too long it's going to sort the numbers eventually right.
So, but in the middle, they get to they get to hang out together. And we also we also did this thing I said well, let's just see how much what how much effort, how much do they really want to cluster, and the way to test it is to allow numbers to repeat.
So if I allow you to have multiple of every number, then as long as all your fives are in the correct location, you can cluster, you know, half of the fives are one algorithm half of the fives of the other and you don't get pulled apart you can keep that.
And so if you do that if you allow them to have multiple, then then the clustering goes even higher, because it obviously wants to cluster more it's just that the eventually the sorting algorithm takes, you know, can't be can't be resisted anymore.
So, so there's this crazy, there's this crazy innate tendency for them to cluster. I don't know what causes it but I have a I have a hypothesis about it that we're not sure yet I think it has to do with surprise minimization.
I think it's a kind of Firstonian thing where you cluster with with your own algotype because because they're they're the least surprising, they're the most like you basically.
Anyway, yeah, so so so that's the thing and and and this is just it's an it's an extremely minimal model. And it's got this nice feature which I think a lot of systems in this field have which is, you can take the sort of mechanistic reductionistic
to follow all the steps, and you're never going to see a miracle it it it the computer works correctly the algorithm works correctly if you if you insist on the on the, the kind of micro scale walkthrough.
Yeah, everything makes sense. But if you pull back and look at it from a from a larger scale, you see, oh, there's something going on here that it isn't because the laws are violated it isn't because you know at the micro scale these the you know there's any there's
it's because there's a larger scale pattern that's completely not obvious from the explicit algorithm that we put in. And if that dumb six line algorithm has these emerging capacities for novel, novel problem solving behaviors and you know novel
patterns that they try to maintain. Then of course, the more complex ones both in computer science and in biology will have them, you know, through the roof things that we can't even, you know, begin to expect so that's my that's my story of the of the algorithms.
It's really neat. Listen, let me just throw in one thing of Kate you want to go next with Michael.
Your zina butts are fascinating. And so is your axlottal frog chimeras. We can't possibly have time to talk about all of that today.
But I'd certainly love to talk about it and Kate might also some work here. So Katie, do you want to say some things or why do you want to do it.
If you don't mind.
I first I want to thank you for what you're doing because it's.
Oh my God, I've been walking backwards from psychology for well 30 years, wanting to understand what the valence of emotion really is and what it comes from. And when I found stews book the origins of order.
And the first time I've been exposed, you know, having a background in clinical psychology to the whole bottom up emergent self organization story so I was absolutely thrilled by that and me too.
Yeah, I know right. It was so evocative and people saw things in there that student really, but that's just how his genius is. So, I experienced your work as the next level of that, because I've been talking about emotion as a sensory system for
a very long time. And in the paper that I wrote which was the culmination of working alone for like 20 years and so there's a lot of stuff crammed together in there. That's what I did when I was in the Harvard community I wish I'd known about you right up the street at Tufts.
But that the, the chemical level.
I was pointing to ideas about self regulation, the immune system, genetic regulation, epigenetic, all that stuff being balled up in this deep, deep sensory or function of self regulation.
I had, you know, Candice Perts molecules of emotion there, and then I couldn't get any lower than that other than the concepts of feedback, a couple of positive and negative feedback. And now Michael Levin comes along and I can see exactly where using membrane potential is and changes
well either going to polarized or unpolarized and then ultimately being more negative and more positive. That's a very clear one to one relationship of what I've been saying about the value system. And that's where my interest is, is in psychology, you know we follow
physics, I mean we're reductionists and we're still stuck with Cartesian dualism and all that stuff. And sadly, even the best psychological stuff is based on this idea that there's dual processes in the brain right you got to bottom up quick and dirty.
And it is fouled somehow it there's something wrong with that and that you really need a long going through the you know that to that's wrong. There's a really, really deep evaluative system that comes up from these deeper things that that that's the value system.
And a nature is now I mean science supposed to say anything about values at all. And, and I think your work is really the perfect example of how everything is perfectly objective and observable, and yet kind of stays away from the subjective perspective which is taboo.
Of course in psychology, that's what it's all about it's about identity it's about personality free will. I'm seeing implications in what you're doing for the concept of free will that that there's clearly something going on there with the capacity to make decisions at all.
And the fact that all of this is emergent is amazing. The one thing I want to say about.
And you mentioned Mark Psalms and for stun as as where you're heading in this direction. And I, I'm absolutely right there with what they're saying but the one thing I want to pitch at you today is it surprise reduction is only monopolar.
It means that whatever memory system whatever, and whatever memory, there's, there's an internality here whatever, however, sat in the algorithm, it matches the external challenges the environment that all of those that's what that's about and that's definitely part of what I'm talking about.
The signaling system itself that organisms use is bipolar, and that when you're getting that positive feedback signal, it's got a valence to it, that when memory potential is depolarizing it's, it's, it's going up if you will and if it's depolarizing it's going down if you will.
And that the depolarization, then when you get back to positive and negative charge, negative charges associated with healing and regeneration right. Have I got that right, and positive charges associated with damage and degeneration.
So, I'm finding an exact link between what I'm talking about is the source of values and know why we experience feelings in pleasurable or painful categories. You do have to go to subjectivity, but that's, I think, a key part of what basal intelligence is about, because without that valence, you don't really have a decision
making what like, okay, what am I what state am I what what state is my neighbor you have to and then it gets down to the idea of self versus and not self comparison between yourself and the environment. So all of that stuff I tried to wrap into that paper, but
I have to have what you're saying, and please correct me if I'm bastardizing your work in any way, but that it that the implications for, for values and ethics and all of that entire realm of social systems are right buried right here and what you're doing as far as I see.
Yeah, no, I think I think you're absolutely right in the sense that if if when you when you have simple emergence like you get in fractals or you get in cellular automata.
It's free of valence because okay complex things happen you know a glider goes this way glider goes that way it's all sort of equivalent. But as soon as you get emergence of these homeostatic or homeodynamic systems, which expend effort to try to keep specific states.
That's it now you're in the land of valence and values and everything else like Mike, you know micro level, because because not all states are equally preferable they will actively try to reach a specific and sometimes they're quite, you know, they have all kinds of competencies and doing that.
So, so already you start to see and then and then the question that becomes well so so where did, where did those specific preferred states come from why is it that this this is the one they like instead of, you know, instead of instead of that one and, and I really think that's one of the grand mysteries.
And the next that we need to deal with, you know, not just emergence of complexity but but specifically emergence of goal directed intelligence and develop some kind of science to try to guess these goals because we make things all the time is you know find for the swarm robotics and internet of things and
institutions and social institutions and we have an biological chimeras and so on, we have very little ability to guess what the goals of the system are going to be and what the competencies of that system are going to be to implement those goals in the face of resistance.
And we need to develop a science that I think.
Take a turn you guys.
Okay, so a whole bunch of things.
I want to focus on your bottom up, and you're allowing things to crap out and die. Okay. But before that, Michael, and thanks, Kate.
So just briefly, and it's in our third transition and science paper.
I think things focus on living cells and living cells.
The goal of a living cell is to get to continue to exist by its project. That's what gets selected. And the goals that emerge aren't set from the outside, like we do when we're programming it.
It's, it's, you know, it's what useful to it.
That's why your chimeras and your scene about seems so fascinating to me.
But now put that aside, Michael, I realized when I read your paper and thinking about I think that for some years I've been doing things that are cousins of what you've done and there may be something really general going on.
So let me try to tell you, when you take your, your algorithm and you make each, each number an agent. So it's now bottom up.
There's no outside control of the total system.
So they're now in a sense co-evolving with one another, trying to do whatever they're trying to do.
Years ago, I found myself doing something similar, and then similar in another way. You know that I made this NK fitness landscape model.
This rugged landscape. So this is in 1995 at home in the universe.
Yep.
So we just, we just made a big square lattice, you know, N by N, where there's N squared points and each point is a little site is a, and it's just the NK model.
And you can think of that thing as one big patch, which is one thing.
And you implement, you implement a cousin of your letting things die. It's just a finite temperature.
So the system goes downhill and energy, but every now and then it fucks it up, but it goes uphill and energy.
So it's a Monte Carlo.
And we ran this and we asked, all right, how long you go downhill until you get to some minimum.
Then because errors are made, you kind of wander around and you can ask, ask, you know, how low energy do you get to.
Then we took this big patch that's N by N and we broke it up into four quadrants, four patches.
And the rule now becomes your, the move you made each patch, Northwest, Northeast, Southwest, Southeast makes moves that are good for it.
But when it does so, it screws up things for the, the patches on its boundaries.
So the patches are now co-evolving with one another.
So it's becoming separate agents.
Then we made the patches smaller and smaller in size and more and more numerous.
And we asked, well, what happens to the energy you get to the remarkable thing is just what you found the system as the patches get smaller and more numerous.
The total system does better and better and better and better and gets ever lower energies.
So breaking the thing up, do a bunch of co-evolving things, does something really good.
Then it turns out something amazing happens.
There's a phase transition when the patches get too small.
The thing becomes chaotic and it screws it all up.
So the optimal behavior is found right at that boundary.
So hold that.
So what's going on in this case is it's like yours.
There's something about breaking things up so that it's bottom up that allows better behavior to emerge.
It's like yours and the fact that given the Monte Carlo simulation and finite temperature, the things find alternative ways of getting to wherever they're going.
And this led to something just amazing about 12 years ago.
I was at the university.
So this is maybe really important and really general and we're both getting at it and come in too because emotions are all over it.
So I was at the University of Vermont and we were asking, I was talking, I'm a doc and I was talking to a friend who was a doctor and we were thinking about fitness landscapes.
And you know, there's randomized clinical trials, which are the Beall and Endall and they're just big T tests.
So he asked, in the NK model, you can tune the structure of the landscape.
So we asked if you have a single peak landscape like Fujiyama or you have a rugged landscape.
Does randomized clinical trials work well?
That was where we started.
And it works well on a single peak landscape just screws up all over the place on a multi peak landscape.
Well, I expected that the Jeffrey Horbar, my colleague, had a really neat idea that's related to what you just did with the your algorithm, the bottom up.
He said there are quality improvement centers emerging in medicine, where if you have 100 hospitals, they break up into 10, 10 groups of 10 hospitals.
Each one is a quality improvement center.
And within the quality improvement center in real life, the 10 hospitals in the quality improvement center are trying to do something neat like they want to find a good combination of procedures.
Now you can do the procedure or not.
And here's.
So the deal is they try a given procedure with one of these centers.
And if on anecdotal evidence, not statistically, it looks like a good idea.
It's okay, let's do it.
And then if it doesn't look good later on, they just take it back.
So we implemented on a computer, Michael.
Now the anecdotal evidence is incomplete information.
It's noisy information.
It's not quite knowing what you're doing.
It's messing around.
And what we found on a computer is a computer model of it is we did it on a computer and it radically outperforms randomized clinical trials.
We think therefore the large message of your bottom up is if you can connect a large number of people to try to solve a hard problem.
And you break them up into little patches where different groups try things and based on anecdotal evidence say, that looks like a good idea.
Let's try it.
And if not, you say you take it back.
They'll solve really hard combinatorial optimization problems that you'll never do if it's all one big system.
And that's what you're finding too.
There's something really general going on and to finish up this book.
I'm involved in trying to get going on global soil restoration.
And the idea is to try to create a global creative commons computational network for hopefully millions of farmers where people can upload data, share on it, share it with who they want and try to solve whole hard problems.
And the same thing would work in clinical medicine.
So there's something about this bottom up noisy sloppy trying things on anecdotal evidence that actually works.
And the final thing to say about this is if we're 30,000 years ago and you had a toothache and you were in the south of France, you'd go to the medicine woman.
She would say, Michael, you need the following six herbs.
And they basically would work.
Noted it a randomized clinical trial.
How do we learn that.
I think we and I think evolution, something like that too. And now I'm done.
Yeah, yeah, very, very interesting. Well, you know, the, the, the clinical trial thing I've always, I've always wondered, you know, acupuncture, which, which I've benefited from many times.
I was like, how, how long would it take actually to, you know, how many patients would you need from if you were starting from scratch and you needed to know, you know, where the points were for specific disease.
I can't imagine the size of right the data sets you would need. It just seems.
Nobody did a randomized clinical trial and developing acupuncture.
Yeah.
Randomized clinical trials, you know.
Yeah.
You know, we learned key tests. So we thought we were being scientific.
There's a, there's a funny, well, there's, there's two, there's two things. One is experimentally, and this was, we put out the, this, this reprint a while back, and the real, the real paper should be out soon, looking at groups of embryos responding to
teratogens. And it turns out that embryos are actually communicating with each other. And there's a whole, what I think is going to be a kind of
a hyperdevelopmental biology where instead of looking at how a single embryo develops, what you're looking at, how, how, so when standard developmental biology individual cells work together to build a nice embryo.
