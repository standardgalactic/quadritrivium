learning, optimal control theory and an economics expected utility theory. So that's one perspective
an equivalent complementary perspective is on the negative value. So if you did information
theory this would be known as self information or surprise or more simply surprise the negative
log probability, the improbability of finding my blanket states in this state here which means
that we can construe the self organization of internal active states in terms of a suppression
of surprise and this leads to things like the infamax principle, the minimum redundancy principle
and indeed the free energy principle. That's nice because the time average of surprise is
mathematically called entropy which means it looks as if or it will any system that exists
will look as if it's trying to minimize its entropy. So this clearly is the holy grail of
synergetics that tries to understand the imperatives behind self-organization
and if you're a physiologist it's just homeostasis it's just gathering your physiological states within
bounds to preclude an entropic dispersion and wandering into non-viable or highly surprising
physiological states. I'm going to pursue another interpretation which is more statistical in
nature, inferential in nature. In statistics in particular Bayesian statistics the probability
of the blanket states given a Markov blanket or given me can also be interpreted as something
called model evidence or marginal likelihood, Bayesian model evidence. So this is basically saying
the states, the internal active states are changing in a way that appears to be maximizing
model evidence and that finds a nice home when unpacked in terms of the Bayesian brain hypothesis,
evidence accumulation and as we've heard in introduction things like predictive coding.
So if it's the case that anything that exists should look as if it was doing some sort of
prediction or modeling of what's beyond its Markov blanket then we should be able to simulate that
and show its emergence in any self-organizing system that possesses a Markov blanket. So
what I'm going to do is briefly show you some simulations of a little universe that we've
engineered precisely to show or to ask the question can we evince this kind of mechanics,
this kind of synchronization between the inside and the outside. So what we've done here is built
a little world comprised of 128 macromolecules. The details are not important, the same phenomena
emerge irrespective of the differential equations one uses. All we need to know is that they're all
loosely coupled and we can see them bubbling away at the bottom of a potential well here
and you may be asking well why have I done this? What are we going to do next? Well because we've
written down the equations of motion that underwrite the flow that we've been talking about we know
what influences what, we know which molecules, synthetic molecules influence which other
synthetic molecules and we can preclude action to distance and in virtue of that we can now
define the conditional dependencies that define the Markov blanket. So the hope was that we'll be
able to find a little creature living in this synthetic primordial soup defined purely on the
basis of its Markov blankets, the parents, the children and the parents and the children
defined by this adjacency matrix and here indeed is a little viral-like particle
wiggling around in the middle of this synthetic soupy little psyllium or tail here where the
internal states have been color coded with blue. The active states that typically in these simple
simulations usually underlie the sensory states in magenta here pushing them into the external
states externally in cyan here. So this simulation reveals that there is indeed a little creature
living in the middle of this soup that's quite happily attaining and maintaining its visiting,
its attracting sets, maintaining its technically non-equilibrium steady state. But the question now
is can we find any evidence that the internal states are somehow maximizing the evidence for
some implicit model of what's going on on the outside. In other words, do internal states appear
to infer the causes of their sensory states? Some people in philosophy like to call this
self-evidencing, soliciting evidence for your own existence. And it's relatively easy to demonstrate
indeed this process is manifest. This example here is used to illustrate the simulation of
synthetic evaporative potentials used in cognitive neuroscience and electrophysiology.
But just to quickly walk you through it because what I want to get to is this
underlying construct called a synchronization manifold. What we've done here is ask are there
any mixtures of the internal states that will predict the motion of the external states?
So this is a little bit like asking are there any patterns of neuronal activity in the visual brain
that accompany motion, visual motion outside that is registered by our sensory epithelia?
And indeed it is easy to find this. This has to exist and I'll explain why in a second.
Here is an illustration. So what we've done here is take a mixture of motions,
fluxes of the external states shown in cyan. The prediction of those and the 90% confidence
intervals based just upon the internal states. Remembering that the internal states can't see
the external states. All they know is how the external states impress themselves on the sensory
states and the influence of the sensory states by the active states on the internal states.
And we can see there's a remarkable correspondence between the implicit knowledge, the inference
predicated on the internal fluctuations about what's going on on the outside despite the fact
that there is no direct access. And indeed if we gather together little excursions here
and average them we can simulate event-related potentials. Here's an empirical example from
monkey electrophysiology. So you may be asking well how does this happen? Why is it the case?
Well it must be the case in the sense that for any given blanket state there must be
an average internal state and an average external state which means there must exist
for any given blanket state the expected internal mode of activity and an external
mode of activity and all we're seeing is fluctuations on this synchronization manifold.
And I'm using the word synchronization manifold just to bring to closure the first half of this
talk with a nod to what has been understood for centuries and in particular the notion of
generalized synchronization or synchronization of chaos noted by Christian Huygens many many
years ago and most of you will be familiar with this. It's the observation that suspend
two clocks from the same wall or beam and inevitably after a period of time they will
start to oscillate in synchrony. They will become entrained, they will become aligned.
There is no other solution and this is basically just an illustration of this fundamental property
of coupled dynamical systems in this instance we're covering the inside to the outside
vicariously through the blanket states. So here's actually a drawing by Huygens with two
clocks suspended from the same beam so from our point of view one clock or one pendulum
can be the internal states and the other can be the external states and they are coupled through the
beam in terms of the blanket states comprising the active and the sensory states. So I like this
construct because it illustrates the complete symmetry here so if you subscribe to this
interpretation of synchronization where the inside is trying to or you are trying to infer
what's going on in the world then you also have to accept that the world is trying to infer
what you're about and what you're doing and that's not a non-sensible interpretation when it comes
to things like niche construction and the like. However we're going to try to get back to this
notion of synchronization through another route but let me just first of all summarize what we've
done with all the heavy lifting in terms of the physics. What we're saying is that the existence
of a particle or a person anything that exists implies a partition of a system state systemic
states into internal blanket namely sensory and active and external states that are hidden behind
the mark of blanket and because active states changed but are not changed by external states
they're going to reduce the average surprise or the entropy of blanket states and this means that
action will appear to maintain the structural and functional integrity of the blanket and some
people like to discuss this in terms of self-assembly and chemistry or the knife sciences or the
internal states appear to infer the hidden causes of sensory states by increasing their
Bayesian model evidence namely self-evidencing and actively influence those causes
via what is often called in my world active inference. Just one little twist here for
philosophers there is an argument that the internal states in virtue of the existence
of the synchronization manifold parameterized probabilistic beliefs about external states
and one can unpack that in terms of information geometry and complement a Cartesian dualism
with a Markovian monism but we're not telling that story today. Oh so yes this is just a little
interlude this is one of my postdocs went to America to work with Mike Levin at Tufts and
few months after arriving he and his wife had a little baby and his wife bought him a Markov
blanket so here is Keira the little baby with Franz's Markov blanket here is Markov blanket so if
you Markov so if you if you want a Markov blanket they are available in America. So we've done the
statistics of life and what I promised I would do now is just rehearse exactly the same story
but from the point of view of a neuroscientist trying to understand sentience and how we make
sense of the world. So I'm going to unpack this part of the talk in terms of the basics the
fundamentals of the anatomy of inference in terms of particular coding with a brief focus on
chemical microcircuits and in particular sensory tenuation because I think that's a particularly
important aspect of this physics of sentience particularly in psychiatry and indeed mental
health and then conclude with an illustration of all this in action and my fond hope is to get back
to synchronization and what it means for models of the world where the world includes other things
like me and indeed could include me. So the anatomy of inference all of this is predicated on
the underlying notion that can be traced back to the students of Plato I think most best articulated
by Hermholtz as we see it see in a moment. The notion that perception rests upon a constructive act
it's a perspective on perception which is in contrast 20th century sort of outside in filtering
sensory information it rests upon an inside out constructive act where you construct predictions
or hypotheses that best explain the signals and sensations of your sensory states or your
sensory epithelia. So you have to have something in mind as a potential explanation for your
sensations before you can perceive it. I think this is beautifully illustrated by this painter
famed for doing still life oils that when viewed from a different perspective give you a very
different percept. So if previously you saw a bowl of fruit and now you see a face the key thing is
you brought that face to the table that is your explanation it's this inside out act that now
enables you to find a better explanation a simpler explanation for why you're perceiving or sensing
this particular pattern of sensory signals. So Helmholtz would I think in the science and
the life sciences and the physical sciences be the person who first articulated this most clearly
nicely illustrated by this sentence or quote here objects are always imagined as being present
in the field of vision as would have to be there in order to produce the same impression on the
nervous mechanism. So again speaking to the notion that it is the the impressions you get
on the sensory epithelia are explained by what would happen if this was the cause and the cause
has to be imagined in a mindful way and clearly this is very much akin to Richard Gregory and other
seminal psychologists of the 20th century who formulated perception as a hypothesis testing
again this notion that using sensory evidence sensations sensory states as evidence for or
against a perceptual explanation or hypothesis and if confirmed then you commit to that and that
is what you see as opposed to what you are looking at. These ideas have been used to great effect
in a technical arena in particularly machine learning by people like Jeffrey Hinton and in
a slightly more translational setting by people like Peter Diane and indeed they came up with the
notion of a Helmholtz machine as a machine learning or neural network formulation of this basic idea
boring ideas from Thomas Bayes and in particular Richard Feynman's free energy or variational
solution to the problem of this difficult inference problem that we all face when
finding the best explanations for our sensorium. Let's just go back to Helmholtz producing
impressions on the nervous system so this fits very nicely with this Markovian blanket construct.
So what we're talking about here is if it is the case that to be is to perform gradient flows
on evidence model evidence what I am effectively saying is that I will appear to try and explain
the best explanation or causes for the sensory impressions or the shadows on my sensory states
my sensory veil so I will be trying to discern or represent what is causing these sensory shadows
here and using the maths that I presented in the first half one can sketch out how our brains
actually do this in a relatively straightforward way so these equations again may look complicated
but you know once you get used to them they are remarkably simple and yet may explain how our
brains and our neuronal message passing actually implement this fantastic act of being able to
explain what's causing our sensorium to produce those fantasies that are virally endorsed by
the sensory this our sensory evidence that we gather with our eyes and our ears and all other
organs. So let's just come back to this gradient flow and focus on the internal states so here's
our gradient flow on this log probability under some simplifying assumptions Gaussian assumptions
we can write this expression in this form here which is a mixture of two things the rate of change
my internal states so my neuronal activity can be broken into the solenoidal part which is
in engineering known as a prediction so it's a prediction of what I wouldn't the states of the
world in the future without any observing any new information so nothing is actually changing in
terms of the underlying surprise because it's a prediction about things I haven't yet seen and then
a prediction error epsilon which is the difference between what I predicted
and what I actually observe and this gradient flow basically is just saying we're going to minimize
the sum squared error weighted by their precision pi here so just to try and give you an intuition
of what that sort of how that would work in a sort of coarse-grained fashion let's imagine that we
have this sensory impression here this shadow on our sensory epithelia and we had some expectation
or mean explanation new here that the best explanation was of a howling dog and if I had
a generative model g that could generate from this expectation what I would have seen my
sensory states that would have been produced if this was right then I can compare the prediction
generated by the generative model with the actual sensations and elaborate a prediction error and
then I can simply use my prediction error to optimize or change my expectations until the
prediction error has been minimized and at which point I will have a perfectly good explanation
for my sensory impressions and that changing that Bayesian belief updating that evidence
accumulation is just this gradient flow it's just minimizing prediction error notice that the name
of the game here is to minimize prediction error or to maximize the the probability of the sensory
on the blanket states under a particular model of the world that is generating the predictions
will never actually know what caused these sensations but that's not the point if I can get
through my life minimizing both prediction error job done and of course that job is done by this
gradient flow up here so this provides a nice and parsimonious very simple picture of active
sentience and so we can forget about all the Fokker-Pank equations and the gradient flows
and we can say that we can explain everything in terms of minimizing prediction error
which means that we can understand perception as the changing of internal for example brain states
to supply predictions that are as close as possible to the sensations and that would be
a canonical way of minimizing prediction error and we can regard that as perception changing
predictions however there is another way of minimizing prediction error we could actually
go and resample our sensory states our sensations to make them more like the predictions and this
involves actively soliciting new sensations from the environment by looking over there or by touching
this or touching that and that gives a nice explanation for changing sensations to minimize
prediction error so both action and perception are simply there in the service of minimizing
prediction error so what would that look like in a little brain and I've deliberately chosen
a bird brain here because I want to use bird song as a little simulation at the end just to
illustrate and make concrete some of the phenomena that we've been talking about
so imagine this is a piece of neuroanatomy from a bird brain this is the auditory
thalamus of a songbird it receives some sensations so let's assume that the bird is currently
listening to set for something it receives these fluctuating sonogram representations of sensory
input time frequency and in the absence of any top-down predictions there is with sensations
just to become the prediction error they go up to the higher vocal center for example
where they drive through this gradient flow expectations that try to provide predictions
of what's coming in until such point as the predictions match the input and the prediction
error is quenched or resolved however at the same time while these first order predictions
are fluctuating being driven by the ascending prediction errors they are also in receipt of
top-down predictions from a higher area say area x in the in the songbird's brain and the same
