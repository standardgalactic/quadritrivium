Daniel, thank you so much for coming to Shelling Point.
I invited Daniel Schmackenberger to come here to talk about existential risk and catastrophic
risks to civilization.
He's one of the most lucid thinkers that I've ever listened to on the topic and I'm so
excited for this conversation and what the Web3 community can learn from the work that
you've done.
So, thank you for joining us, Daniel.
Amen.
I'm happy to be here.
It's here.
It's all right.
Is AV adjustable?
Maybe we could be closer into the microphone or the AV can boost Daniel's mic.
All right.
Is that better?
All right.
Yes.
So, let's start here.
Daniel, what is the metacrisis and what does that assessment offer in terms of design
considerations for our work in regenerative crypto economics?
Yeah.
I'm going to ask you guys to forgive me.
I'm just going to kind of talk to Kevin because it's easier to deal with the noise that way.
Yeah.
So, the metacrisis is a way of thinking about all of the interconnected catastrophic and
existential risks that the world faces right now, not just the fact they're interconnected
but that they have similar drivers and that if we are to address them, we have to not
just address them all individually but actually look at what the generator functions of them
are.
So, we know that we have existential risk many different ways to artificial intelligence,
whether we're talking about paperclip maximizing issues or AI drone warfare or simply like
AI optimization of an extractive economy.
We know the same thing when it comes to biotech, CRISPR, synthetic bio, existential risks.
When it comes to cyber attacks on infrastructure and drone attacks on infrastructure, the whole
category of exponential tech creates pretty radical fragilities in the world and obviously
in addition to not just climate change but all of the planetary boundary issues that
cumulative industrial tech has created.
Right.
So, you can kind of think about catastrophic risk in two major categories which is the cumulative
effects of industrial tech that have linear supply chains, linear materials economy hitting
limits of growth and so on the extraction of finite resource side and then on the pollution
side.
So, obviously on the pollution side of the energy economy, you have climate change.
On the other side, you have actually an issue that's probably going to hit us even sooner
which is a diminishing return on energy returns on hydrocarbons with hydrocarbons still being
pretty difficult to replace in terms of energy and being pegged to the dollar or being pegged
to like global GDP and global energy being nearly one for one pegged and an exponential
embedded growth obligation on currency that means you have an exponential need to grow
the total amount of energy in the system while having a diminishing return on energy availability.
So we can see like catastrophic risk across trying to run exponential linear materials
economy on a finite planet and then you add the exponential technologies to that.
The exponential technologies basically radically centralized and decentralized power at the
same time.
The decentralization of power looks like decentralized catastrophic capability.
So the ability to build drone weapons, cyber weapons, bioweapons, AI weapons in basements,
non-state actors having that where you can't use UN style mutually assured destruction
to stop it.
So the catastrophe weapons for everyone world, the main solution to solve that is things
like kind of the China model which is ubiquitous surveillance to be able to prevent that.
Which looks like increased centralization using exponential tech that gets dystopic.
So we can say that you have one attractor which is increasing catastrophes and what
it takes to be able to control that are control systems that are in impose central power control
systems that create dystopias.
So we're looking for something that is neither catastrophe or dystopia which would be a third
attractor and I think the thing that's interesting here is obviously underneath all those issues
are patterns of human behavior empowered by technology.
And patterns of human behavior looks like both our governance systems and our incentive
systems.
So the kind of crypto economic world is looking at the intersection of new incentive systems
and new governance systems while also building fundamentally new infrastructure that mediates
those and so what my hope is is that this space understands the design criteria of a
third attractor well so that they can actually work on making sure the systems are developing
meet those design criteria.
So if I could say back to you what you said to me, it sounds like there's one model which
is the China model where you've got a centralized actor that's kind of clamping down on their
society through surveillance and control and then you've got another model which is kind
of where the West has traditionally been where you've got existential technology that creates
more risks and you don't have you've got kind of like decentralization or not a good way
of managing that and that system will collapse because you have those technologies in the
hands of more and more people and then those are the two attractors and then the third
attractor would be how do we get away from those first two attractors?
Is that roughly?
Yeah, the catastrophe model has both mistake theory and conflict theory versions.
The conflict theory is catastrophes that somebody intends, which is the decentralized
catastrophe weapons mediated by exponential tech.
The mistake theory is just increasing externalities and that when your currency system that is
mediating everything market-wise all has externalities built in, exponential externalities
create eventually cascading catastrophes.
So you get catastrophe on both mistake and conflict theory.
You get dystopias both at the nation-state level but also at the web to Metcalf company
level.
The Facebook, Google, Amazon issue is a similar issue because you have corporations that have
more power than most nation-states that still don't have anything like participatory governance
or jurisprudence.
There's no consent to the governed.
So ultimately that's kind of a new feudal oligarchy.
So whether you're talking about the exponential tech empowered nation-state like China or
the exponential tech empowered corporation, those are both basically exponential tech
top-down organizations.
Okay, got it.
So what is our way out of the Metacrisis?
So obviously you've got to look at the generator functions of the Metacrisis and then be able
to understand the design criteria to solve them if you want to solve it categorically
because if you just looked at, let's say we sequester all of the CO2 and solve near term
climate change from anthropogenic CO2, that doesn't deal with dead zones in the ocean
from nitrogen.
It doesn't deal with overfishing and doesn't deal with biodiversity loss or any of the
other environmental issues.
You actually don't buy many years.
If you just deal with one particular kind of AI weapons issue, you don't deal with the
other AI issues or bioweapons.
So if you don't deal with it kind of categorically, you really can't deal with it in an increasing
point.
So it's all or nothing?
Well, it's fundamental redesign.
And I think the thing that's worth pointing out is we had a fundamental redesign of our
global system following World War II, which was the Bretton World's IGO, Mutual Assured
Destruction World, because it was the first time we had tech that could actually cause
an existential risk.
Before the bomb, we just couldn't destroy everything.
And so major empires always warred over power.
This was the first time that you had a war that nobody could win, and so you had to prevent
what all of human history had, all of human civilization history had had, which was war
between the superpowers.
And so that world, the kind of Bretton Woods world, Mutual Assured Destruction works when
you have two superpowers and one catastrophe weapon, or at least a GA, the small number
of superpowers that can monitor each other.
And where the catastrophe weapon is very hard to build, it takes nation-state level capacities
to build nukes.
It doesn't take nation-state level capacities to build bioweapons.
In fact, we're like five years out from tabletop CRISPR being ubiquitous on the current trajectory.
So how do you create a forced Nash equilibrium?
How do you create the equivalent of Mutual Assured Destruction when you have an undefinable
number of non-state actors that are very hard to monitor?
So you can see that that solution doesn't work anymore.
Similarly, one of the other key aspects of that world was globalization and the global
monetary system that said everybody could have more without taking each other's stuff
because you're going to exponentially grow the economy, which also required exponentially
growing the materials economy, which also drove all the planetary boundaries, which
are also catastrophic risks.
So we have to get to how do you make a system that doesn't require exponential growth of
the monetary system, that internalizes externalities and closes loops on supply chains.
So this is where starting to think about fundamentally new economic systems and coordination systems
gets very central and interesting.
Now I've read a little bit about Game B, which is opting out of our current rival risk
games and into something that would bring us towards that third attractor.
Could you talk about what Game B is and what the design criteria for it look like?
Yeah, Game B is a term that I wasn't part of the initial Game B crew right after it
kind of dissolved.
I made friends with Jordan Hall and Jim Rutt and Brett Weinstein and some of the people
who were, that was at Senefe Institute and it was just the recognition that this system
is self-terminating and there's a game theory underneath it's self-termination.
So is there something that transcends game theory that doesn't self-terminate?
There was a general moniker for anything that met those criteria and then there was a bunch
of work on what those criteria must be.
So you have the idea of what would a good system be if it was globally implemented, but
then you also have the enactment problem of what does it take to globally implement it,
to boot it.
If you start with less than everybody, right, so one of the reasons why internalizing externalities
is so hard, like even say a carbon tax, is if everybody doesn't do it then whoever does
it is relatively disadvantaged, whoever does it.
And so the global free rider problem ends up creating inability for nation states to
coordinate on stopping arms races and tragedy of the commons issues.
So that issue, the multi-polar trap, which is anybody does the thing that in the short
term game theoretically wins, everyone else has to race to do that thing faster, which
creates a system that long term everybody loses.
This is one of the design constraints of a game B, is you actually have to be able to
transcend multi-polar traps categorically.
So you've got to be able to say how do we make race to the top scenarios where you make
something that doesn't lose in the short term, but that also doesn't self-terminate in the
long term.
Right.
And so you mentioned that it's hard for nation states to coordinate around this problem.
What if we had a global coordination layer that was transparent and uncorruptible?
And what would you say to a room full of 500 people who could program that coordination
layer?
How can we bootload game B using that coordination layer?
And in case it's not clear to those who can't read between the lines, I'm talking about
Ethereum as a coordination substrate for humanity.
I'll say why transparent is really important is let's say you want to prevent a multi-polar
trap that is an arms race between superpowers that can actually possibly win the arms race.
So far, we almost exclusively fail at this, right?
We didn't really achieve nuclear deproliferation and at the time we tried to do nuclear deproliferation,
there was still an arms race on hypersonics so that someone could win the first strikes.
Only on one vector and not on the other ones.
And you got more countries that had nukes and then more countries that had alliances
with countries that had nukes.
It gets even harder with preventing AI arms races or bio arms races because let's say
we make a UN mediated treaty and you're China and I'm the US or you're Russia or whatever.
How do I know that you aren't defecting on the treaty in some secret deep underground
military base?
I have to assume that you are so I either don't make the treaty or I make the treaty
and I defect on it while lying to you about it and trying to spy.
And so we just don't have a way of getting out of that.
The only way to be able to have the treaties work was if there was some trust that there
was adequate transparency.
Because otherwise the first mover advantage is so powerful in some of these areas that
there will be the race for first mover, which means that then there's an incentive to classify
everything really effectively for secrecy.
I was just talking to the head of cyber security for Sweden and it's very interesting because
Sweden doesn't have a black budget at all.
Everything that their military does is completely transparent and transparent to their own people
so that people can actually democratically participate.
Obviously means transparent to the US, Russia, China and everyone else.
And he said their idea was everybody, Russia already knows, the US already knows, so rather
than invest a bunch of resource in hiding it, let's invest the resource in just doing
better.
I don't believe that works if they aren't backed up by NATO that involves the US having
a bunch of stuff in black projects that can win first mover advantage on arms races against
Russia or China in that case.
And so what you have to make happen is if you want to be able to solve arms races, you
have to be able to ensure that the various sides actually can monitor.
So you either need transparency or you need some kind of zero knowledge proof type phenomena
where then they can make an agreement and trust that the agreement actually has the transparency
needed for enforcement.
Now that means that you have to make the transparent system beat the non-transparent system.
And I think there's a very real possibility because like in the US the special compartmentalized
information classification means that there's such shitty coordination between the departments
that there's a huge amount of waste.
So if you could remove all of, if you could lose the benefits of classification, but the
benefits of transparency were more game theoretically beneficial for that in group relative to the
rival race out group, then you would drive a race to the top on transparency rather than
a race to the bottom on secrecy, then you would have the transparent basis to actually
be able to solve multipolar traps.
I see.
Okay.
So we would say that's, that would be an example of a design constraint for a third
attractor is if you can make your transparent system categorically out compete the non-transparent
system, you're going to drive significant races to the top.
But you have to, the same thing is, like let's say you try to internalize an externality
in your current system, like you're going to try to internalize the cost of carbon in
the environment.
The reason that we externalize it and just price the cost of coal or oil at the price
of extraction plus a margin is because the more of the cost you externalize, the more
profit you make, the profit, the dollars are basically optionality tokens that mean I have
the maximum optionality for, to be able to influence militaries or media or whatever I
want.
Right.
Whoever maximizes the optionality tokens under rigorous competitive environments wins
against those who don't.
And so there's no real competitively effective way to internalize those externalities unless
you bind a whole system that internalizes its externalities, but also out innovates
and you can't invest in the innovation thing without investing in the whole thing.
Right.
And the whole thing, even with the internalized externalities still outcompetes the other
rivalry system, then you can start to get somewhere.
Wow.
What a thread to pull.
We only have two more minutes.
I just got the signal from the stage manager.
So what didn't I ask you that you want to tell us and where should we leave the conversation?
How do we continue the conversation?
Well you and I are going to do a deep version of this.
What are the generator functions of the metacrisis and how do each of those generator functions
give a design constraint for a non-self terminating system, but that also can bootload through
rivalry?
Right.
And we'll take the time to unpack that.
So if people are interested, great.
That's on your podcast.
Yep.
The main pill podcast that we just launched on the Bankless Network, we'll do a long
form portion of this conversation with Daniel Schmockenberger and lay out how we can get
out of the metacrisis.
One thought I would share just in closing here is when you look at Marvin Harris' model
for thinking about civilizations, that any civilization you can think of as the infrastructure
that mediates all the physical needs in relationship with the physical planet, the social structure
that are the kind of collective agreements fields, basically governance and law, and then
the superstructure, which is culture and the ordinating values.
You guys are, the crypto space is building new fundamental infrastructure and fundamentally
new social structure simultaneously.
The critical fucking thing is the culture, the superstructure that is what is the basis
of the law that we use to bind the incentives, because incentive alone will create multipolar
traps and externalities.
You also have to have binding dynamics.
And ultimately, law for jurisprudence has to be bound in culture or cultural values.
So getting the cultural values right and having them informed by metacrisis.
So it says we can debate what a desirable civilization is, but we're all pretty much
in agreement that at minimum it shouldn't self-terminate.
And so if we take the criteria and not self-terminate as a beginning point and then make sure that
those values are encoded in the social structure layer and make sure that the nature of the
infrastructure insofar as that's influencing the social structure and the values is all
moving in the right direction, that's really, really critical piece.
Amazing.
Well, I look forward to being your bridge to the Ethereum space and to the Ethereum space
back to you.
Everyone give it up for Daniel Schmackenberger.
Thanks, Joe.
