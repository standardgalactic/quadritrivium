beliefs over trajectories of actions into the future. And to
what extent is a belief a goal? Because if you have an almost
infinite number of beliefs, so there's a trajectory to this
future state where I'm rich, but there's also an infinitude of
other potential trajectories. And they are of course constrained
by the physical affordances and trajectories that I can take in
my physical environment. That seems different to having an
intention of wanting to be rich or wanting to play tennis,
because I'm constrained in all of these different ways. So yeah,
why don't we just talk about the dichotomy between beliefs and
goals?
I think Karl or Chris would be better equipped to answer the
latter question. Karl in particular has been thinking
about intentional behavior quite deeply recently. I did want to
quickly comment upon ecological psychology. I have been saying
to the eco psych community that Bayesian mechanics and eco
psych are the same discipline. They're really the same thing.
Vicente Raja is one of the cooler, more technically
proficient people in the eco psych community. And after a few
years of back and forth, we've realized that yeah, we're using
exactly the same set of mathematical tools. The only
framing is the only difference is a philosophical framing is, are
you an indirectist or a directist? Right? So and I happen to
think that these are just kind of semantic quibbles. If you look
at the more contemporary eco psych literature, so the eco
psych people are tend to be much more sophisticated, technically
than the inactive people. And one thing that they have in
common is that they don't reject information theory out of
hand. They want the richer notion of information, like
ecological information or semantic information, some kind
of information that has some relevance to the environment,
you know, the organisms like Melia, it's umvelt, it's, it's
world of life. But they're not rejecting information theory. In
fact, Gibson's original ambition was to apply physics to the
study of perception just straight up. You know, so it's
all about like, you know, energy, the, the energy on the
perceptual arrays and all of this stuff. It's essentially, I
think, the same project from a methodological and
mathematical perspective. The main difference is just an
inactive and a an ecological psychologist, sorry, would say
that we perceive things directly. But then they appeal to
this, these notions of like resonance and whatever, which
you know, to us is just synonym for inference. I guess
it's like it, the difference rests in like, are you centering
on the internal perspective of an organism? Or are you looking
at things as a multi scale stack with the organism kind of
carving out one level? So we had a great session actually with
Michael Anderson's Emerge Lab group, based out of Ontario. And
my, my gut tells me that there will be a kind of strategic
alliance, and maybe even just a merging of these two fields,
moving forward. Yeah, and you know, for the more cynical part
of me thinks that the merger of free energy principle and
ecosystem gives you everything that you might want out of
inactivism, but without any of the, you know, heavy, kind of
metaphysical or philosophical baggage that seems to be, you
know, hindering progress in that field. So that's my thing
about eco psych.
Okay, maybe we can bring you Chris in on the goals thing. So
is, is a goal in end state? Is it a trajectory? Is it a
bearing? And is it, is it, does it exist explicitly in the
externalist view of cognition?
Well, so I'm a kind of more of a practical, computational
person. So I'll leave the philosophy to Maxwell. But I
mean, I tend to take the intentional stats, intentional
standards on systems, where if we can, if it makes sense for us
to describe a system as a goal directed, then we should do so.
And if that helps engineers to build those systems, then they
they should do so, right? But there's a nice kind of, there's
a nice parallel between those are kind of ideas and the original
working cybernetics. So there's the, you know, the good
regulator theorem, which this kind of early work by Conan and
Ashby suggests that any, any control system of a given
environment is a good model of the environment that it controls
just by by necessity from first principles, right? Which to me,
which we suggest that we should, in principle, be able to
describe an intentional structure in terms of the kind of
generative model within within a system, we should be able to
find it if it is a good control system, and it should exist. I
think there's also a more practical thing about shifting
from the notion of reward as this kind of potential function
that's kind of dominated the machine learning area, right? So
we have this kind of monolithic thing of reward and everything
is in in service of that reward to a richer notion of beliefs
about dynamics, which which which affords that kind of, you
know, moves away that potential function to a more kind of
dynamical system so we can get more kind of rich beliefs about
future trajectories and so on. And we know that in control
systems, that's really, it's really important, right? If we
want to control a system, we're doing model based control, we
have to have desires on the futures of those systems, we need
to understand the trajectory and the divergence of the
trajectories over through time, right? So I think it's a much
richer picture, practically, to think about, you know, beliefs
about dynamics rather than reward. And I think there's this
nice parallel between the intentional structure and the
good regulator theory, because I think the good regulator
theorem entails that we should find those kind of intentional
dynamics within our systems, right? With just by a priori
first reasoning.
Yeah, I just want to know if he could explain the good
regulator theorem, because I think that
Yes, the good regulator theorem is really strong resonances
with this. And I think, you know, there was a long, there was a
long time, not Carl, the Carl's exclusive. It's a long time
the people who were reading the free energy literature to think
that they're kind of the roots of the free energy principle was
in Helmholtz, Helmholtzian perception, right, this notion
of Bayesian inference and perception. But there's kind of
a much richer reading to see its roots in cybernetics movement,
and particularly by the works of people like Ross Ashby and so
on. So he basically said, he provided this theorem that
showed that if you want to build a regulator for a given
environmental system that optimally regulates that
system, then it necessitates that regulator is a good model of
that system, right? And there's a kind of you can take that in a
strong way and a weak way and we worried about this for a long
time. But just to diffuse that from its representational kind
of implications, which we worried about for a long time, you
can see this in something like even like the Watt-Gubner, which
is used as his classic inactivist system that doesn't is
nonrepresentationalist. But there are kind of there's a sense in
which the dynamics of the Watt-Gubner needs to mirror the
fluctuations of the the sea management regulating and it's
that kind of coupling and that kind of reflection of those
dynamics, which is important for the regulation of that system,
right? So that kind of you can back out that, you know, I think
this is very nice to line with the intentional stance and it
demands an intentional stance. If you if you if you if you if
you're committed to this notion of the good regulator,
Ferriam.
To riff on your point of the intentional son, I think that
that's a fascinating way of looking at it, Chris. And to
bring you in, Professor, Professor Daniel Dennett had
this notion of the intentional stance, that when we, you know,
we essentially have a mental model of the intentions of other
agents. And we use that to understand their behavior. And
an intention is a goal. If you think about it, it's something
I want to do. But in this dynamical systems framework,
it's not explicitly coded anywhere, it kind of emerges. And
of course, it's a subjective state. So we've spoken about
mental phenomenal states being encoded in our generative
model in our in our free energy framework. And those states will
of course have intentional, you know, representations of the
other agents that we're dealing with. So I guess, the question
back to you, Professor, for instance, how do you goals
kind of get encoded in in this dynamics?
Yeah, that's a great question. I know the answer you want,
because you don't like goals, do you?
I don't mind if they're I guess, I guess the answer is they're
emergent, which is, which is
exactly what I was hoping for that. Yes, they have to, you
know, you have to find a physics where it looks as if there are
goals, and they emerge from a particular kind of self
organization. I think that's that's been beautifully
illustrated just in the previous conversations you've had. And
you know, ranging from the work of Ross Ashby on his homey
stat, which I think would be better nowadays called an
alofstat, but it would be to stick with the homey stat. Of
course, you know, does homeostasis have a goal? Does my
physiology have the goal of maintaining my temperature at
37 degrees centigrade? It certainly looks like that. Do I
intend to do that? Well, I think on one reading of intention,
yes, you know, and certainly on an alofstatic reading of
behaviors that have this temporal depth and are the
consequence of plans into the future, you're putting turning
on the thermostat or putting on clothes. I think then you're
getting much closer to this sort of more anthropomorphic notion
of intentionality, whether I think there are girls, there are
there are endpoints. And so I guess that the question then is,
you know, at what point would these different kinds of
intentionality or goal directed behavior emerge from
self organization? And in what particular kinds of systems would
you expect to see this these these these behaviors? I think
there's some fairly straightforward answers from the
point of view of the physicist, not not the philosopher. So if
you just look at the different kinds of systems that you could
apply the free energy principle to, we've talked about one of
them right at the beginning, when considering Markov
blankets that did not have any have any internal states, for
example, a stone. Yeah, so every state of this thing is just a
Markov blanket, and it is in reciprocal exchange with the
external states. So that would be when the internal states are
empty. Well, there are other kinds of systems that you could
have. Well, you could imagine systems that didn't have any
active states. But, you know, most interesting systems do
have active states. And then you ask about the rounded
contribution of these random fluctuations to the dynamics of
you know, the self organization. And if you just follow the
maths through the pathogenical, in particular, maths of the
dynamics that any system at a particular temporal scale must
have, if it's internal or autonomous dynamics, or the
dynamics, the flows of the internal states and the
the blanket states that constitute a particle or a person,
when they become sufficiently precise. So when we become big
enough, and cool enough, so let's assume that we're bigger than
a quantum scale, but not too big to become classical. So we're
not the size of the moon, but we are roughly your size and my
size, or perhaps the size of a mouse or an insect through to an
elephant or a giraffe. Then you have this interesting
situation of these very precise dynamics, and they're precise
