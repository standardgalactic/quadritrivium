parallel and therefore attention uh uh

was at this time much faster than lsdm

uh because of this parallelism and the

second thing was uh you can could

optimize it for the GPU for the hardware

these two things paralysis paralyzing

and Hardware optimization this gave

tension a big Advantage you can uh uh

train on much more date in the same time

and yeah uh and uh LM could not compete

with this technique you mentioned flash

attention as well so can you just

quickly explain that to the audience so

does that mean in certain circumstances

you don't actually need to do the full

quadratic attention uh it's still

quadratic but super highly optimized

right where you uh use this fast memory

ases in in the thing uh you you even use

registers uh of of of the uh uh GPU very

very fast entities memories in the uh

register it still has the same

complexity because it's mathematically

uh quadratic and you cannot uh cheat

math but you can uh do uh it super super

