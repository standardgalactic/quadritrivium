to become more general.
And, you know, it's far more interesting than either extreme,
like either the gray goo or like the, you know, the nothing, you know.
And so as far as definitions go, I think that I don't like
to sit there and pedantically argue forever
about what the definition of intelligence is,
but we need to have enough of a definition
that we can make progress in learning
and kind of doing scientific discoveries.
So things like the beer falls off the table and it's wet.
Well, if a system can't figure that out,
we notice that it can't figure out kind of a class of things.
And that class of things has something in common
and then we give it a name and maybe it's understanding
or whatever, I don't care.
But it's just a way of talking about that class of problems
of things that it's not able to achieve
because then we can try and figure out how to do that.
Yeah, I think that the symbolists, though,
that when they come up with formal arguments,
it's not, that doesn't come first.
They notice that neural networks can't do something,
which is to say they can't fill in the missing gaps.
And then they come up with a formalism to express why that is.
And also, many of these symbolists believe
that there are kind of platonic abstractions
that exist in the universe.
They think that mathematics is discovered, not invented.
So that kind of formal apparatus
is how they understand the world.
Well, I feel like I should try to solidify my attack
on definitions since it's obviously
fairly, again, radical thing to say.
I would acknowledge, like, in the sense that Keith is saying that,
again, like, I don't want to be a prank.
Like, obviously, you need to define some terms sometimes.
Like, that's obviously clear.
That should be completely clear.
I'm not against that.
Like, you know, especially, like, you're gonna derive something
and you're writing a paper or you have a certain set of assumptions
you need to know what they are, like, in order to prove
that it actually is true and not true.
If that's what you're trying to do, like, that makes total sense to me.
So I'm not a blanket saying we shouldn't have definitions.
But I think the thing about definitions that's interesting,
like, a lot of things is that there just isn't solid ground.
Like, in terms of, like, they're just generally good for you.
Like, they can be good for you or they can be bad for you.
They can be a tool of clarification
or they can be a tool of obfuscation.
And it depends how you use them.
And I often find them to be tools of obfuscation.
Like, especially when we're talking about things we don't know,
which is, once again, the problem, which is what I'm interested in.
I want to talk about things that we don't know.
And that seems where people get really passionate about definitions.
So it's like, what does it mean to understand?
We don't know. I don't know.
What I do know, though, I'm confident there's such a thing.
There is understanding.
It might be a continuum, maybe it's not just a binary concept.
Beyond that, I don't really know what it means.
And so I would be interested to talk in depth,
like, what does this really mean?
Like, let's look at this.
But no, we have to, like, we just end up in this, like,
a big argument about the definition.
And I find that in that case, it's obfuscation,
because it's fear.
Because really, like, if your whole pitch is,
like, your thing that you get a lot of traction on
is basically attacking the fact that things don't understand,
then you might be a little uncomfortable
if we really start dissecting what you mean.
And so you should just comment us and just tell us,
like, hey, you're not even being clear in your terms.
And just stop the argument in its tracks.
And that's the kind of definition I don't like.
I mean, I'd rather just, like, look, we agree there's,
I don't know exactly what it is.
You don't know exactly what it is.
Let's talk about it anyway.
It's uncomfortable.
But there is such a thing.
That's what we should agree on.
Do we agree there's understanding?
Like, is there anything that exists?
Well, see, that's a problem is...
Right, but that's a problem is you can run into some folks
that will go that extreme and say,
there's no such thing as intelligence.
It's all just, yeah.
So, but look, I agree with you in principle,
which is, again, I like definitions
insofar as they're necessary to enable communication.
So I'm totally on board with the idea
that we need to be talking about things.
And that's why I kind of like say
the coherence theory of knowledge
because it acknowledges, look,
we're never going to get to the foundation
beyond which there's no other foundation
that we can imagine.
We just need to understand far enough
and define things far enough that we can make progress.
So, I'm a little bit...
I can completely understand where you're coming from, Kenneth.
You think that we have a fundamental fear of the unknown,
and we're hiding behind our formalisms.
And my only worry is that it seems
a little bit anti-intellectual
because you can make an observation
that an AI model is not behaving the way we are.
There's loads of assumptions there.
We assume that we are behaving in a way
and we are doing things the right way.
But then you can say,
oh, let's resist any formalism
to try and break this down analytically.
Do you see the conflict there?
Yeah, absolutely.
I mean, it's a dangerous position
because it's clear that some formalism is necessary,
like I tried to concede.
I mean, I'm walking a tightrope.
So it's not...
Yeah, it can't be...
I can't make this blanket claim
that formalism needs to be completely thrown out the window.
That would just destroy my credibility.
But the point is...
These are just pendulum.
These are pendulum?
What is the plural?
Pendulums.
These are pendulum.
They swing in different directions.
So we become so enamored with this,
which is a useful tool,
but to the point where it actually becomes
like a form of obfuscation.
And I do believe definition is like that.
Definition is not always and it's not everybody.
But a lot of the time when there's an uncomfortable issue,
we immediately jump to definition to obfuscate.
I think consciousness is one of the greatest examples of that.
It's like there's clearly a mystery here.
And I agree there are a few people
who would disagree there's any mystery at all.
But to me, it's clear there's a mystery.
Don't need to have a definition to know there's a mystery.
We could get into why it's mysterious.
That's more interesting to me than what the definition is.
But if you jump at me with this definition stuff,
you're going to stop me from getting into that.
I feel like that's pure obfuscation.
This is one of the greatest unknown things
in the entire scientific world, like consciousness.
It's one of the greatest mysteries of all time.
And like so, are you about definitions?
Is that really where we're going to go with this?
Maybe we don't have a good definition yet
because we don't even know what we're talking about.
That's part of why it's so mysterious.
I think this is quite interesting though
because with consciousness,
we clearly don't have a mental apparatus.
You know, like for example,
if someone just took some hallucinogenics
and they just had a completely crazy visual experience,
they wouldn't have any words
or any mental framework to hang this off.
Whereas when we're talking about an apparatus
to describe intelligent behavior,
we absolutely do have an apparatus to hang things off.
So I guess, is that a spectrum in your mind?
Yeah, there is a spectrum.
I would also concede that with consciousness,
yeah, it's true that it's much worse for us.
It's true because it's ineffable,
which is another way of saying you can't put it into words.
Like all the things we're discussing have no words.
Like the blueness of blue.
Like I can't actually describe it.
You can't break it down into parts or say what it is.
And so that makes it extremely difficult
like to actually get into anything formal about it.
Whereas intelligence, I would grant that you can,
to some extent, like you can actually point to things
that can be reduced to words or symbols or formalism.
And so it's a little bit better on that slippery slope.
It's higher up and less dangerous.
But still, I think it's still on a slippery slope.
Like there's, I don't think we,
although we can talk about intelligence
more easily than consciousness,
I still don't think we really fully grasp this either
or really have the words to really get at what we're talking about.
We don't understand ourselves well enough
