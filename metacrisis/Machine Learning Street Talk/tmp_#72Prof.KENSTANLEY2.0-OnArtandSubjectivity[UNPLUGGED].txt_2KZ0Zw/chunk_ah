And that like seems to get less mind-share,
like that kind of question,
maybe because it's not very practical,
or nobody's really sure what we're even talking about,
like what crazy things you actually want to see.
But I would, that's the kind of thing
where I don't think we're seeing a lot of push or progress.
On the curriculum learning, I do think we see things,
and they are interesting within that context.
Yeah, the curriculum learning thing fascinates me,
because I remember talking about, I think, ICML 2019,
and he was saying, look on poet,
there's an example of an agent,
and we have this curriculum,
and sometimes we need to kind of shift
between a very kind of complex environment,
and then back to a simple environment
in order to solve this particular problem.
But you spoke about generality,
and I would still argue that the kind of program
learned by poet doesn't have generality,
but the process which produced it does.
So Francois Choulet has this measure
of intelligence conception,
and he has this idea of intelligence being a process.
So there's like a meta-learning process,
and then it can produce skill programs,
which can then work in any particular situation.
So I mean, is that similar to your mindset?
So I agree that it doesn't have generality.
That's totally true.
It's totally about hyper-specialization.
This gets to actually the art aspect,
the art discussion we were having before.
To me, that is artistically appealing,
because it's evocative of nature,
where you're not going for a super-generalist in general.
Each niche is basically a hyper-specialized niche,
which interestingly eventually led to extreme generality,
like us, like we have an extreme level of generality
in certain ways.
Like in certain ways, we're not photosynthetics,
we don't have that kind of generality,
but we have intelligent generality,
but it went through hyper-specialization.
If you go back through the ancestry,
you're looking at hyper-specialists,
not generalists that are trying to become
more and more intelligent,
like you're looking at things like flatworms again,
or not generalists in any sense.
Like it's a new reorganization of the body plan.
And so I find, first of all,
just from an artistic perspective,
find the depiction of something that is about,
like continually branching and just interesting aesthetically,
and something that we should create.
Like we should create things that do that.
But what I notice is that always,
people point to that as a weakness,
and say, well, there's a caveat here,
it's very specialist-oriented, you know?
Why not go for generality?
And actually you could.
This is like a fairly intuitive notion,
that like, yeah, we can get divergent curricula,
but try to focus it back down to a centralized point
where we're trying to get generality.
I mean, I'm not gonna give it exact way you can do that,
but this is like an intuitive concept, I think,
to think about doing that.
But the point I wanna make though is that,
look, like some really great kinds of generality,
the stepping stones are through specialists.
What are we gonna do about that?
Like, especially like us.
Like you could claim that like,
we're just gonna go straight to hypergeneralization.
Like that's where we're trying to get our super generalists
or something like that,
by getting more and more and more and more general.
Maybe you're right, like deep learning is magic,
like we just add more data.
It's not that simple though,
because the fact that we're admitting
we need a curriculum means we don't have the data,
so we have to get it somehow.
But you also have to just, there's something interesting,
you have to admit there's something interesting
about when hyper-specialization actually leads to generalization
and this kind of paradoxical stepping stone principle,
that the things that don't resemble what you want
ultimately are the stepping stones that get you to it.
And hyper-specialization is like a really powerful thing,
because it allows you to drop,
it allows you to make assumptions.
Like you can assume something about the environment
you're entering before you entered
because you're a specialist in that environment.
And I think that it can be a disability or a liability,
like if you actually go into environments,
having no assumptions whatsoever,
so you have to be ready for all possible contingencies
under the sun, that's what generalization means
in a super general sense.
Like would you want, you know, airline pilots
to like not be sure whether they're flying a stunt jet
or a passenger jet?
Like they've got to do some checks upfront
to see which scenario they're in.
Like if you're just a passenger pilot,
you don't do those checks.
Like you know what you're doing.
And so I think there's reason to talk more
about this issue of like the specialization of poet
is actually an interesting facet of it
and not necessarily just like a liability
that we have to get around.
I've just thought of an interesting connection
that hadn't occurred to me before,
but there is a link between specialization and divergence.
Because if you think about it at a general age,
and that's the equivalent of the committee
that you hate so much.
And what you were just saying with evolution,
starting with specialization actually allows you
to explore many more interesting stepping stones.
But the thing I want to get to you though
is intelligence must be specialized.
I mean certainly even in conceptions like AIXI,
it's framed in terms of being able to perform tasks
in certain environments.
There's no such thing as general intelligence.
So if you were an alien being
and you came down to planet Earth,
would you really see that much of a difference
between our kind of intelligence and photosynthesis?
So that is really interesting.
It clearly originates from specialization.
I don't think you can deny that.
The explanatory apparatus are through specialization.
Why is it what it is?
It's related to the environment we're in.
I mean, that must be true, obviously.
So it has to do with optimizing within that environment.
But I feel like what's going on is something to do with,
from that specialization has emerged real generality.
I feel like our intelligence is sufficiently general
to move outside of anything in our environment at all.
It gets to this question where people sometimes say
that there are certain things we cannot understand.
Like it's impossible, like as human beings.
It's usually like, well, why can't we,
why would there be things we can't understand?
Well, it's like they're just so far outside
of our environment.
They have nothing to do with anything in the experience.
I think, I don't really fall into that yet, but I think,
I think we have the capacity to understand literally anything.
Well, given enough information,
like obviously we can't know about things
that we can't actually observe at all.
So we don't know those things.
But like if I was given information,
I believe I could understand the concept.
Like I could understand where did the universe come from?
If you told me what happened, like I think there is some,
it has nothing to do with the kind of situation I come from.
But I think I have the capacity to generality.
So I think it's really interesting that,
that like somehow a degree of generality
emerged from this specialization, which goes beyond
just being good in this environment.
Could I distinguish though,
because Jeff Hawkins made this point in his book as well,
what's interesting about humans is for the first time,
knowledge and genes have been separated.
So I completely appreciate what you're saying,
that we can understand the universe and everything in it,
but our behavioral intelligence
is still very much tied to our environment.
I don't know whether you're familiar with James Lovelock
and his Gaia theory.
And he essentially thinks of all life on the planet
as being kind of like an ecosystem or a meta ecosystem.
So could you think of humans as just being a product
of our environment in that same way?
Is our intelligence limited by the environment we're in?
I mean, we are, I do, our intelligence is,
does, it has like some areas where it's more elastic
than others, I guess, because of our environment.
I think that would be true.
Like there's some things that are easier to grok
than other things, because the things that are easier
to grok are more aligned with where we come from.
And so that's like what conceptually we're adapted for.
Like things like the difference between the third dimension
and the fourth dimension.
Like it's easy to reason in three dimensions.
It's quite hard to reason in four dimensions.
