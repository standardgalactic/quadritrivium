but like generally art that we appreciate
like leads you to having some realization
that is generally commonly held
like that people would agree is interesting.
And so artists are exploring that
and that leads to other ideas that might not be art.
You know, I think, yeah, like a scientist
can be inspired by art to think about a phenomenon
or somebody else can be inspired architect,
obviously many times inspired by arts.
There's lots of inspiration that comes out of art
if you feel philosophical as well
like about like how the world works and what matters.
There's plenty of topics to talk about
that aren't falsifiable in a scientific sense.
And, you know, with AI algorithms,
they, I think secretly a lot of the explanation
for what has risen and fallen within AI is that,
not the actual scientific results.
Is that people have resonated.
I like that word because that's really about art.
It's not, it's not about correctness or accuracy.
It's about resonance.
And people have resonated with certain algorithms.
It's like they just felt it.
It got to a point.
Well, this is like an artistic realization,
not a scientific realization.
Like where it resonated with some sense
of what intelligence is for you.
And it's not like the whole thing.
Nobody got the whole deal of intelligence obviously
but some part of it like resonates.
And that can be extremely inspiring.
And I think explains certain like inflection points
in the history of machine learning
where I think it was resonance really that explains it.
Yeah.
And I think it's really interesting what you're saying.
And I think there's a tendency of some
to again dismiss this type of thing as not science,
woo woo, you know, whatever.
But I think that stems from a being insufficiently Darwinian
in the sense that look, whatever's up in our brain,
okay, it's the beneficiary of a billion years
of evolution, okay.
And these insights and intuitions that we have,
even if we're not conscious of them,
maybe they're not happening at a level
that we can analytically break down consciously
and think about could still be extremely useful
and extremely valuable.
And so I have no doubt believing that
when a human mind sees an algorithm even,
it can perceive some connections
to some abstract concepts
that have been proven out through evolution
as being highly, highly useful.
And so you may be seeing those connections.
Is that, I mean, does that capture potentially a fair
and scientific justification of why we should pay attention
to intuition and artistic intuition?
Yeah, I think it's fair.
I think though I wouldn't only couch it
in terms of evolution, I think it's broader
than just from evolution.
Like it's from our experience also,
like experience since you were born,
and that's your memories and the feelings
that you've had over the course of your life
that I think enter into.
Of course, just some evolution explanation
for how you process those experiences,
but the experiences are also part of the background
for what you appreciate and find interesting in your life.
And yeah, I think that that is, as you say,
an important part of the history of ideas,
even in science.
And what I guess, what's actionable about that though,
is that it's interesting to think about the extent to it,
we should actually allow or facilitate discussion
on this level, not at this meta level
that we're talking about, should we do this,
but at the level of here is what resonates to me,
like about the specific thing.
This is why it's interesting, like as a reviewer,
like I don't care if it gets like 5% less accuracy
on this set, it's super interesting
because XYZ, it reminds me of something,
powerfully reminds me, like can we have discussions like this?
We can't right now.
And so it's interesting just to think about that,
like would it help to facilitate progress?
Would it stymie progress?
Because I think most people,
their first good instinct is it's bad for progress,
because it opens the floodgates of sort of like unregulated,
like unempirical type of speculation.
We're all afraid of that.
But I think we should be cautious,
I think we're too afraid of it,
and that like we can handle this,
because like we actually know about
what we're talking about.
Like that's the thing that makes this valid.
Like it's again, like if it was just some random person
on the street, I wouldn't want it to have
an aesthetic discussion of algorithms.
But if it's experts, I don't understand why we're not allowed
to have aesthetic feelings and relating things
in like analogizing, things like that seem perfectly fine.
We should be able to do, I would say,
even if you can't do that, there's a problem.
Like why are you an expert?
Like if you can't make analogies
and actually talk about what's interesting
or inspiring about the work.
Okay.
One thing that I'm wrestling with a little bit here is,
I mean, Douglas Hofstadter, the famous Douglas Hofstadter,
he once said that he was terrified
that AI might be disappointingly simple to mechanize.
And I think a lot of the stuff that we're talking about here
is, I mean, we're talking about subjectivity,
but also we're talking about the externalization
of intelligence.
So rather than it being encapsulated
in an individual brain, a lot of it is emergent
and can be thought of as something completely different.
I'm concerned about the lack of free will
for want of a better, so we've been dealt
with the experiences and the environment
that we have in life.
And to a certain extent, is it still intelligent
if our cards are marked?
If everything has been mapped out in my life
as a function of the environment that I'm in
and my life experiences.
I guess I have this, just as Douglas Hofstadter did,
I have this very fanciful idea in my mind
of what intelligence is, that it's infinitely nuanced.
And we have this phenomenological experience.
And, you know, for example, Hofstadter spoke about Chopin,
this beautiful piece of music
and what the infinite nuance and subtlety
that must have gone through his mind when he created it.
And wouldn't it be horrible if that was just the result
of quite a simple process that you could define using code?
This is an interesting question.
I think, yeah, it's clear that there's a movement
in machine learning towards that kind of perspective
of basically simplicity.
And it goes back before deep learning.
I mean, people were observing that they say, well, like,
you know, cortical circuits like in the brain
all share like a huge amount of similarity.
It's like, it is possible it's all the same algorithm
all throughout and there's just some simple explanation.
And then, like, when we see, like,
things like really large language models
that are basically like uniform architectural structures
that just get bigger, it seems to,
it seems to point in that direction
that like it's not like a bunch of really complex,
rich subtlety like going on through the system.
We don't know, though, yet, we don't know.
I mean, the jury's still out.
We haven't actually gotten to human level.
And I think that, yeah, and I mean,
you can also point to evolutionary processes too.
And they're also simple, like there's a simple thing
and this explains everything,
like it's not really that interesting of a thing
in and of itself.
I don't, I guess to me it's just,
we would like to know the answer to this.
Like, can you actually get these things to work
through very simple processes?
That's probably really important to know,
like just in terms of being able to do machine learning.
But I don't think for me it would be
that disappointing one way or another, I think.
Cause I think the subtlety is still in there.
It just came in through a different channel.
Like, okay, maybe the subtlety is not in the architecture.
I personally think there is subtlety in the architecture.
That's my guess, like it's not gonna be super simple.
But let's say it doesn't have to be,
it could be all like uniform.
But then, like what you do and what you care about
can still be like the constellation of stuff
that you learned, which you learned over your lifetime.
Like what that amount to, you know, in aggregate
can still be, I think, highly rich and subtle
in its connectivity.
It's just a structure that emerged from a simple process
which allowed it to emerge,
but then the structure itself is complex.
So I don't think it would diminish sort of
like the grandiosity of like what we are to me.
