mission is to understand how the brain works and to apply those principles of real intelligence
to create intelligent machines. Neuroscientists were publishing thousands of papers a year,
covering every single detail of the brain. But there was a lack of systemic theories that
tied all of those details together. Numenta decided to first focus on understanding a single
cortical column, right? They knew that cortical columns were doing something physically complex,
and therefore must be doing something complex. Now, last week, we had Ben Goetzel on the show,
and he was convinced that artificial general intelligence must be a hybrid of many underlying
algorithms, not a single learning algorithm. Jeff Hawkins doesn't agree. Hawkins thinks that
all the magic of intelligence could emerge from a single cortical learning algorithm.
Andrew Ng said that as a young professor, and after he read Hawkins' first book on
intelligence, he also became convinced that a simple scaled up learning algorithm could reach
artificial general intelligence. Now, what does seem to really distinguish Hawkins' ideas
is that intelligence must emerge from diverse and strongly multimodal inputs, perhaps that
intelligence is somehow emerging from the nature of physical embodiment. Now, Jeff argues that
we're the first species on Earth to know the age and the size of the universe. He thinks that humans
are the first species to be known by their knowledge and not by their genes. That's the beauty
of this discovery that this guy, Vernon Malcastle, made many, many years ago, which is that there's
a single cortical algorithm underlying everything we're doing. The Mindful Brain is a small book.
It's about 100 pages long and published in 1978, and it contains two essays about the brain
from two prominent scientists. One was written by Vernon Malcastle, a neuroscientist at John
Hopkins University. Now, Jeff Hawkins cites Malcastle as being one of his biggest inspirations.
Jeff says that it remains one of the most iconic and important essays ever written about the brain.
Malcastle proposed a new way of thinking about the brain that is elegant, a hallmark of great
theories. But it's also kind of surprising, and it continues to polarize the neuroscience community.
Now, Malcastle noted that the brain grew really large by adding new brain parts on top of old
brain parts. The older parts control more primitive behaviors, while the newer parts create more
sophisticated ones. However, Malcastle goes on to say that while much of the brain got bigger by
adding new parts on top of old parts, that's not how the neocortex grew to occupy 70% of our brain.
The neocortex got big by making copies of the same basic thing, the same circuit. He says that
every single part of the neocortex is the same basic circuit. Different parts of the neocortex
are different, not in their intrinsic function, but rather in what they are connected to. The
implications of this are huge. If we understand how one part of the neocortex works, we understand
how it all works, and how all aspects of intelligence can emerge from a single cortical
algorithm. Malcastle pointed out that the neocortex grew really quickly given the short
evolutionary time. Now, Darwin's big idea is that the diversity of life emerged from a single algorithm.
Similarly, Malcastle proposed that the diversity of intelligence also emerged from a single basic
algorithm. The difference is that Darwin knew what the algorithm was, random variation and natural
selection. Darwin didn't know where the algorithm was in the body. The discovery of DNA came much
later. Malcastle knew where the algorithm resided, but not what it did. Malcastle said that there's
about 150,000 cortical columns in the neocortex. A bit like 150,000 little pieces of spaghetti
stacked next to each other. Scientists knew that these columns existed because they all
respond to different sensory inputs, be it from a patch of skin or a signal from the retina,
but the columns are wired to different sensory inputs from the body. There's a wonderful anecdote
in Jeff's book about the last time he met Malcastle. Jeff gave a speech at John Hopkins
University, and at the end of the day, he met with Malcastle and the dean of the department.
The time had come for him to leave, and Jeff had a flight to catch, so they said their goodbyes,
and the car was waiting for Jeff outside. As Jeff walked through the office door,
Malcastle intercepted him, put his hand on Jeff's shoulder and said,
in here is some advice for you kind of tone of voice. You should stop talking about hierarchy.
It doesn't really exist. Jeff was stunned. Malcastle was one of the foremost experts on
the neocortex, and he was telling Jeff that one of its largest and most well-documented features
didn't exist. Jeff was surprised, right? It was as if Francis Crick had said to him,
oh, that DNA molecule, it doesn't really encode your genes.
So Jeff didn't know how to respond. He just said nothing. As Jeff sat in the car on his way to the
airport, he tried to make sense of those parting words. Today, Jeff's understanding of hierarchy
in the neocortex has changed dramatically. It's much less hierarchical than he previously thought.
Did Vernon Malcastle know this back then? Did he have a theoretical basis for saying that
hierarchy didn't really exist? Was he thinking about the experimental results that Jeff didn't
know about? He died in 2015, and Jeff will never be able to ask him. After his death,
Jeff took it upon himself to reread many of his books and papers. His thinking and writing
are always very insightful. His 1998 Perceptual Neuroscience, the Cerebral Cortex, is a physically
beautiful book and remains one of Jeff's favorites about the brain. When Jeff thinks back on that day,
he really laments, and he kind of wished that he would have chanceed
missing his flight for that last opportunity to talk with Malcastle further. Even now,
he wishes he could talk to Malcastle about his current ideas. He'd like to believe that
Malcastle would have enjoyed the Thousand Brains Theory of Intelligence.
So if you have many brains, who are you then?
So it's interesting, we have a singular perception, right? You know, we think, oh,
I'm just here, I'm looking at you. But it's, it's composed of all these things. There's sounds,
and there's, and there's vision, and there's touch, and all kinds of inputs. Yet we have
the singular perception. And what the Thousand Brains Theory says, we have these models that
are visual models. We have a lot of models, auditory models, models, octa models, and so on.
But they vote. And so they send, in the cortex, you can think about these columns as that,
like little grains of rice, 150,000 stacked next to each other. And each one is its own
little modeling system. But they have these long range connections that go between them.
And we call those voting connections, or voting neurons. And so the different columns try to
reach a consensus, like, what am I looking at? Okay, you know, each one has some ambiguity,
but they come to a consensus, oh, there's a water bottle, I'm looking at.
Um, we are only consciously able to perceive the voting.
Today, the most common way of thinking about the neocortex is a bit like a flowchart, right?
Information from the senses is just processed sequentially step by step, as it passes from
one region to the next. In this notion, every step of neural processing refines a representation
from the low level to the high level incrementally. Scientists refer to this as a hierarchy of
feature detectors. But as Jeff points out, even basic study of how the brain works will tell you
that cognition is an interactive process, right, depending on movement. For example, to learn
what a new object looks like, we hold it in our hand and we rotate it this way and that way,
and we see what it looks like from different angles. And once learned, we're able to recognize
entire objects from the touch of a single finger or a fleeting glimpse of a small part of the object.
Jeff's proposal of reference frames and cortical columns suggests a different way of
thinking about how the neocortex works, thinking of cortical columns as cognitive
primitives, even in low level sensory regions that are capable of learning and recognizing
complete objects. Jeff's theory explains how a mouse with a mostly one level visual system
can see and recognize objects in the world. But where is the knowledge stored in the brain?
Jeff thinks that our knowledge of objects are distributed over many cortical columns.
So when I pick up a pen, there isn't a single model of this pen, but rather thousands. I have
visual models, I have sensory models, I have auditory models and everything created in between,
right, from a rich topology of reference frames, binding them all together. And every cortical
column models hundreds, if not thousands of complete objects at multiple scales. The long
range connections between the columns and the regions of the neocortex communicate at the
level of classified objects, not features. Jeff thinks that his theory solves the age
old binding problem in artificial intelligence, which is the challenge of mapping sensory input
to discrete mental categories and how these discrete categories can be combined into a
single lived experience. Jeff thinks that the binding problem is a side effect of a flawed
assumption that the connection topology of the brain is convergent rather than divergent.
The solution to the binding problem is that your cortical columns vote. Your perception is
the consensus which has reached from the columns voting on what they recognize. The voting works
across sensory modalities. When you grasp an object in your hand, Jeff believes that the tactile
columns representing your fingers share another piece of information, their relative position to
each other, which makes it even easier to figure out what they're touching. The brain wants to
reach a consensus. Now in Jeff's book, he shows an example of an image, which can appear as either
a vase or two faces. In examples like this, the columns can't decide which is the correct object
because it's ambiguous as if it's as if they have two maps for two different towns, but the
maps, at least in some areas, are identical, vase town and faces town. They're just too similar,
so the voting layer wants to reach a consensus, but it doesn't permit two objects to be the
same simultaneously, so you have to pick one possibility. You can perceive faces or a vase,
but not both at the same time, and the process of cognition allows us to move between the
alternatives to reason interactively over time. In his book, Jeff makes the powerful argument
that thinking is simply traversing a topology of reference and displacement frames in your brain.
Jeff thinks that this reasoning is movement evolved to extend the physical world of spaces
and time to our worlds of abstract thought. The succession of thoughts that we experience when
thinking is analogous to the succession of sensations we experience when moving our finger
over an object or walking around a town. Perhaps the reason why Albert Einstein was so smart was
because of the unique topology of reference frames in his brain. His information architecture,
if you will, must have been arranged as a function of his life experiences, as well as his biology.
Traversing his brain topology allowed him to make powerful abstract inferences
that other people couldn't make. For him, it must have felt a bit like the Borg traversing
their wormhole network in the Delta Quadrant, for those of you who are fans of Star Trek Voyager.
Jeff says that learning conceptual knowledge can be difficult. If I give you 10 historical events
related to democracy, how should you arrange them in your brain? One teacher might show
you the events arranged on a timeline in a one-dimensional reference frame. It's useful
for assigning the temporal order of the events and which events might be causally related by
temporal proximity. But another teacher might arrange the same historical events geographically
on a map of the world. Timelines and geography are both valid ways of organizing historical events,
yet they lead to different ways of thinking about history. They might lead to different
conclusions and different predictions. The best structure for learning about democracy
might even require an entirely different map, a map with multiple abstract dimensions that
correspond to fairness or rights, for example. So what does the Thousand Brains theory tell us
about machine intelligence? Intelligent machines need to learn a model of the world.
Inference, prediction, planning and motor behavior are all based on this model.
The model is distributed among many nearly identical units that vote to reach consensus.
This gives us robust prediction, it scales well and it works with any kind of sensor array and
modality and voting solves the binding problem. In each unit knowledge is stored in a reference
frame and is learned via sensory-motor interaction. This means that we can learn unsupervised,
fast and the motor behavior is integrated. This is Matthew Taylor from Numenta.
This place looks really familiar but I can't remember how I got here. It's almost like someone
severed all of the distal connections between the pyramidal neurons of my neocortex.
Many years ago, Numenta used to refer to their overarching theory as HTM theory,
but now they use the terminology Thousand Brains. The HTM or hierarchical temporal memory algorithm
was a particular implementation of the early ideas of the Thousand Brains theory.
The original guiding principles of HTM were that it was a sequence memory algorithm.
Numenta thinks that every neuron in your brain is learning a pattern of sequences.
It's needed to support continual learning and critically it wasn't an artificial neural
network which they argued were not biologically inspired or at least not in their popular
configuration at the time. The core data structure of the algorithm was called an SDR or a sparse
distributed representation. This was a large bit mask. Think of it as a large ordered collection of
ones and zeros. The representation is sparse which means that it typically only contains about 1%
of ones instead of zeros and the values represented the state of neurons in different regions of
your neocortex. So Numenta really leans into this idea of sparsity in the brain and its necessity
to build any intelligent system. The reason why sparsity is so powerful is that there are
factorially many permutations of values. I mean for example there are about 175 million values
if you had four on bits in an SDR of length 256 right because it's 256 choose four. So this means
that the possibility of getting false positives is negligibly small. It's also space efficient
because those four bits which could represent 175 million things could be stored in a 32 bit
array right which is four times eight bits. The notion of similarity between these SDRs is their
intersection or their hamming distance and again the really clever thing is just how robust these
representations are to noise. You could add about 33% of random noise to both of the SDRs and it
would barely affect the overlap metric. You could also union the SDRs together and not much
information about the patterns would be lost in the mix. So the HTM algorithm needed encoders to
take any data structure and represent it as a sparse distributed representation. Encoding the
information into an SDR is an important consideration for HTM much as it is with any other machine
learning model but I was really excited when I learned about HTM because it seemed so audacious.
And each column has a connection to this input space and it has a receptive field. So each column
is connected to different bits in the input space and these are proximal dendritic connections
feed forward input into the system and each one of the cells within the column shares that
receptive field through its proximal connection. We also have these other connections between cells
within the structure and here's a third cell with another four synapses on its segment. These are
distal connections. So the cell body or the soma has got different areas of receptivity. The feed
forward proximal input comes from below and the contextual information or the distal connections
come laterally from other cells within the structure. We're comparing a biological neuron
to the HTM neuron in software that we're creating. We have the feed forward input which is the proximal
dendritic input from the input space in both sides and then the distal input from lateral
connections to other cells within the space for context. Now this HTM neuron is showing that there's
feed forward input but it's also showing that it can have one or many distal connections. These are
distal segments. Each one of these segments could potentially have one or many synapses or connections
to other cells within the HTM structure. Each one of those cells may be in an on or an off state.
So at any time if a cell wants to decide whether it's going to go into a predictive state or not
it can look at all of its segments and its connections across all of their synapses and if
any one of those summed across all the synapses reach some threshold which is configurable
then that cell goes into a predictive state based upon its connections its contextual connections to
the other cells within the structure. So what I'm doing is I'm feeding in a four note sequence
and then resetting and restarting the sequence over. So every time it sees F sharp the first note
in the sequence it's seeing it for without any context. Nothing came before it. So the algorithm
goes and looks into every cell in every active column. Only cells within active columns become
activated because these activations are completely driven by the proximal segments to the input space.
There is only one segment on the cell because it's one color it's this magenta color and
all of the cells that it's connected to are active in the current time step.
That's why it's predictive because it looked at its segment and it looked it summed up all
the synapses and they were all one apparently and that breached its threshold to become predictive.
So it is in a predictive state. I've never seen another machine learning algorithm quite like
it you know almost all of them are continuous rather than discrete and even the discrete ones
