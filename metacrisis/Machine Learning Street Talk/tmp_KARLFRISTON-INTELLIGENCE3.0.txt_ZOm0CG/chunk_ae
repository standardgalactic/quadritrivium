mean field approximation literally factorizing introducing conditional independences and factorizing
a massive joint distribution at any one level in your hierarchical model into a number of factors
that if you're a neurobiologist would now be functional specialization and modularity of a
fedorian sense you know what aware in the brain would be the the the conical examples so I looked
at that as as a move towards paying more careful attention to the non convolutional aspect you
know those things that that actually deny a translational symmetry and actually celebrate
the conditional independences within any one particular within any one particular scale
so my guess is and I have no idea so I'm talking from a point of view of complete ignorance but
my guess is that if it's an extension of capsule networks then it will have that aspect it'll have
that separability that sort of things that can do stuff and account for attributes that are independent
from other attributes or other objects that are that are conspiring to generate the data and certainly
my world of toy prototypes generative models usually in matlab you know then all the heavy
lifting is done from the the mapping between the levels again so all the interactions you know
big red buses there's bigness as redness as busness these can be factorized but they all
have to conspire literally through interactions and highly non-linear operators
and then generating what I would see if there was a big red bus so you know that puts a lot of pressure
on the the likelihood tensors or the mapping from you know you'll say a sense an input layer to the
the first hidden layer for example and then sort of leads you into all sorts of interesting issues
about you know how do you accommodate that non linearity and do you again as looking at the
evolution of machine learning architectures as an evolutionary process you know at relu or you know
tannate whatever you know that is another aspect of this sort of structural learning I think we'll
be very much finessed I think if we just move to sort of quantum operators and just go to discrete
state spaces in the in the spirit of quantum loop gravity I think sort that out and then we can worry
about what particularly non linearities I've wondered away what was it what was your question my
point well no this this is a wonderful breakpoint so um before we hit record we were talking a little
bit about chat gbt and just before we go there because that's a fun discussion I think one of the
things that really distinguishes your your line of thinking me obviously there's the uncertainty
quantification someone but um also there's this idea of an activism and I wanted to just do a
whistle stop tour of that as a contrast to these more monolithic approaches to AI like like chat
gbt so um an activism contrasts with representationalism which is this idea that I you know I know
everything about the world inside the model and um you said that you can't just think of the brain
as some behaviorist thing it's a dance of dialogue you act in the environment and the environment acts
on you in a cybernetic loop now you also gave the I'm quoting like an interview that you did
previously you gave the example of radical an activism that you can dispense of representationalism
entirely and you gave this beautiful example of this walking robot that kind of fell down a hill
and it did so so gracefully it looked like it was walking it was all in the body um you know if the
body is sufficiently tuned to the environment you don't even need cognition and of course we'll
talk about the decomposition of cognition in a minute um and and you bring in this idea of
circular causality uh so we're causally embedded in the world by directionally essentially now
when we decompose cognition um I think of things like thinking and feeling and knowing and acting
and and the environment and and so on and I think this is one of the key things that distinguishes
your your line of thought so could you give us a bit of a whistle stop tour of an activism
yeah so um an activism is at the heart of the circuit causality that that that um follows from
the very existence of a Markov blanket um and a Markov blanket is the thing that would be it's
certainly in my world necessary for the existence of something that is demarcated or individuated
from something else so just having a separation between thing and nothing or not thing um
having uh that separation requires you now to think about the two-way traffic um the bi-directional
traffic and of course now you've got two directions of travel that can be thought of as um the agent
if you like sensing the environment um on the one hand and on the other hand the agent acting
upon the environment or vice versa um you've got now a circular causality so coming back to sort of
your the the the the notion of a perception action cycle and this notion of a dancing and a
a derdic exchange which is bi-directional two-way traffic between the two so when you apply the
free energy principle in practice to um emulate or simulate sentient behavior behavior that is
predicated on sense making um then you are necessarily simulating action perception cycles
so you're necessarily inactivist and that's called active inference so sometimes just for fun i put
an en in front of it called an active inference i have to say the active inference was really a
nod to active learning it was just it's same idea but um but cast in terms of fast belief updating
as opposed to sort of slow evidence accumulation in terms of learning contingencies um so that use
of inactive is at the heart of applications of the free energy principle and obviously
has been at the heart of i think all right-minded formulations of behavior and self-organization
since Plato probably but certainly you know things like perceptual control theories cybernetics and
all of that good stuff everybody at some point active sensing um well you know what will will
have to commit to this um active aspect um even to a certain extent semiotics i think well
no perhaps we shouldn't gather um but the so that would be one way of um sort of celebrating and
foregrounding the role of action um and what would that look like from the point of view of
machine learning and computer science well it would look like basically smart data mining
and it would change the nature of the game from um big data making sense of big data so having
everything on the inside having access to the entire world um and then making sense of that and
you know you may ask what does that mean by making sense of it well it's certainly doing
something with it like generative AI versus um the the the complementary approach which is much
more in line with this sort of complexity minimization the imperatives for the sustainable
self-organizing self-assembling systems versus smart data um so the job the action now is
this basically what moves do i make on the world to get the right kind of data that will serve my
imperatives what are my imperatives to maximize the evidence from my model of the world and if
i can do that by definition my um i will be there or put it other way around if i you know if i exist
then that is what it looks like i am doing so you know you talk about the or you mentioned this notion
sort of monolithic big systems um versus small agile intelligent little agents that go and get
the smart data that they need or that they think that you need that is exactly um the sort of picture
that underwrites this notion of distributed cognition and that a different kind of network
and a different way of relating to intelligent artifacts and information services and um and
apps uh where it's lots of really small smart things who are actively getting the right kind
of data that they need to um resolve uncertainty about the context in which they find themselves
again that you know the complexity minimization gets in and the things are very i'm sure we've
talked about this before but i can't resist just um mentioning it again from the point of view of
sustainability and climate change you know the direction of travel of these large um say large
language models for example is it's so wrong uh wrong from the point of view of the ideology of
climate change but also wrong from the point of view of landowners principle and the jeniski
equality when read as a thermodynamic corollary of self-organization and non-equilibrium you know
you've got to minimize the complexity minimize um all of the internal machinations so that you
you just need the minimal amount of data um expertly handled every little agents and good
scientists designing the right experiments and get the smart data that resolves uncertainty about
what it doesn't know uh the job done if you if you can do it like that so that would be one um if
you like sort of answer to your question your um the implications and the importance of inactivism
used really just as a euphemism for an agent that can gather its own data the radical inactivism is
i think a more of a philosophical thing and it's more of a fun argument and i don't know any radical
inactivist so i you know i i don't i don't have um i don't have the right sensibilities uh to
just really answer this question but it's for what i understand um they you know they they have um
taken it a little bit too far and uh denying representationalism um uh to the extent that
you know the you can get a kind of um sense making that doesn't actually involve any internal
dynamics um and um you know i'm sure that's true and i'm sure that you're going to sell um uh chat
cheat uh gtp to me as well as one one example of this mindless kind of uh sort of you're inacted
um sense making um it's the opposite i think um i would call chat gbt extreme representationalism
all right yes we'll resist the urge that we'll go there immediately after this i i promise but
um so clearly we we think that intelligence does necessitate embodiment i think that's clear but
i want to just explore this continuum between um inactivism and representationalism um
um this is this is really interesting so um this comes down to grounding to a certain extent so
cognition must be grounded in different domains in in the physical world possibly in language in
acting in affordances in knowledge as well and so this this is a view that that it that it is
grounded let's say in in affordances but if these agents these organisms ground their cognition
in affordances then to what extent could you say they are learning a world model if that model is
with the lens of an affordance i think i think you can sort of do this um reconcile um very rich
representationalism um in the service of inactivism simply by noting that um in the circular exchange
you have to deploy the right kinds of actions and that's going to require um coming back to
what we're talking about before in terms of planning yeah being able to build the right
counterfactuals no and to do to do that in an expert way in an intelligent way you need to
be able to represent the causal contingencies and states affairs in the world at this time
upon which you're predicating your next action so i i'm now just thinking you know
just looking at your your expressions and i now realize that you that you were trying to sell
a dialectic between uh inactivism and representationalism for me um they are the same thing
you to be a good inactivist you have to have the right representations if you want to
to well may i say good i mean um good at a particular scale the big things that survive
so viruses don't need to do much planning um but things like you and me do need to do a lot
quite a lot of planning so as you move up those scales you have to look further into the future
so that we certainly need representations which is what i have which um which is why i'll smile
always smile what i think about radical inactivism um so if there's no space in radical inactivism
for being able to plan to imagine scenarios to have narratives that play out on the inside before
committing and selecting the right way forward yeah and it's not an apt description of certainly
cognition okay it's so interesting because the question to me is we just spoke about this idea
of planning potentially through an information geometry and many of the abstractions that humans
learn are not grounded in the physical world at all and that's very interesting and we can get to
how those abstractions are learned but i guess what i'm saying is let's say one of these agents in
this multi-agent system it's traversing this topology what grounds the states in that topology
well i think that that would be um ultimately it will be the transactions um you know with
with the world the underwrite um at the lowest hierarchal level all the generative models of
this hierarchal sorts of the abstractions are just the coarse-graining simplifications that you know
the the um the products of literally looking at the lower levels of your hierarchy through a
reductionist lens in the right kind of way that enable you to carve up the world in terms of these
in terms of these abstractions which may live in a non-metric space they may still have this
ordinal structure you were referring to before and then what that would mean in the context of
lots of similar artifacts who had done the right kind of coarse-graining would be now
the opportunity for direct belief sharing your brain-to-brain communication speaking to a friend
of mine you heard yesterday talking about the distinction between communicating through um
the through sensory um um exchanges such as language but what we're actually doing is basically
directly exchanging beliefs um of course you could do that directly um in silico you could
actually have messages about what this agent believes at this abstract level of um of representation
very high in a you know hierarchal graphical model it could pass its sufficient statistics to
another partner somewhere else in the world um elsewhere on that on that graph so you do have
the opportunity now for direct belief sharing um and um there are all sorts of interesting questions
about you know how you'd engineer that you know you can't coming back to this fact you have to
have sparsely in the game you have to decide where to to send and receive your beliefs from
then we have this sort of attention and routing problem and then you have do you have peer-to-peer
communication do you go through a server can you write that down in terms of um quantum
information theories a holographic screen and who's you know having all sorts of really interesting
things but what they speak to is that you're now you're sharing beliefs literally basing beliefs
probability distributions as encoded by sufficient statistics that can be passed um as messages uh
on a on a factor graph um you're now talking about the ability for proper communication
of the kind that has evolved in terms of cultural niche construction and evolutionary psychology
that speaks to cultural niche construction uh that we enjoy in terms of you know the words
that we use and the and the exchanges that we use yes yes indeed there are two things to bring in
so knowledge and language and you did invoke Andy Clark in another interview which is the
extended theory of mind so it's one of the five ease in cognitive science and the the communication
substrate could of course it's it's distributed so the two agents could be referring on missing
information that actually exists perhaps in another agent or another another knowledge repository
and then we can also talk to exactly what the role of language is and how it's compressed how it
represents abstract concepts and so on um so i'm very interested in knowledge and language i'm not
sure if you could bring those in right um i'm not sure i can do so expertly but certainly
part of learning new things since my foray into into industry is this notion of knowledge graphs so
if you know if you read a probabilistic graphical model as um at least its structure as being a
knowledge graph then embodied um in the structure and presumably the parameters of the connections
that constitute that graphical model that would be knowledge so for me um in a very non-mysterious
and possibly too simple minded a way knowledge is just the product of um belief updating of a
slow kind which is learning so i know contingencies um in the sense that i have um a suitably configured
optimized structure and parametrically weighted um generative model that can be written down as a
knowledge graph or a graphical model um upon which i do my message passing to do my inference about
the particular context sensitive in the moment kind of thing so i would put knowledge um basically
as an attribute uh that is implicit in a um a graphical description of um uh an implicit
generative model or world model that is um actively um that is used actively to do the
data mining to do the you know do the inference and uh and the sense making and then the language
part of it um would just be that um highest level most coarse grained summary that is conserved over
multiple agents so just by definition um if i want to do belief sharing um i have to um i have to
have a a shared generative model or a commitment to the same narrative so that the meaning of
what i'm emitting is received in the right spirit or the right frame of reference by you
and indeed um there's some lovely rhetoric from quantum information theory of the kind
that Chris Fields and Jim Glacebrook have been pursuing where you literally have to
think about the generative model as a quantum frame of reference and we have to share that in
order to communicate so in this instance the um the Markov blanket ceases to be just a set of states
and see and and adopts the role of a holographic screen and action now is writing to that screen
and sensation is now reading from that screen and there are two agents on either side so you know
whatever is written is an action but can be read by something else and then you're looking at the
entanglement which is the the synchrony of mutual understanding that you know we would aspire to
through through through communication so that that that um but that only works if if the messages
that are written to the screen or written to the Markov blanket um um have the same kind of
interpretation so it speaks again to this um the the fact that you have to have a good model of the
world and the world has um and that really means that there's a kind of entanglement or
generalized synchrony from the point of view of dynamical system theory between the two sides of
your screen or the two sides of your Markov blanket or your server um um which have you know the right
kind of isomorphism so we're talking about you know basically a shared narrative that underwrites
any exchange of signals and again what you know just thinking of of this from the point of view
of generalized synchrony what we are talking about is just the characteristic
or the emergence of characteristic behaviors in any sparsely coupled set or ensemble of
