who else is going to act you know enact those plans I mean I would love to go there slightly
later but there's so much we can say about um agency and the boundaries and also the causal
pressures between agents and also whether you can think of boundaries as being observer relative
but I just really wanted to go to the universal um algorithm thing that you spoke about before
because I think it's delicious so um I think it's fair to call you a universalist and that and that
that's that there are quite a few universalists actually that these are people who think there's
a simple underlying principle and this is in contrast to what we were just talking about
which is that the reality is more complicated than we'll ever understand and we have a truncated
cognitive horizon and we as Chomsky says we just have kind of um simple primitives built into us
that help us frame and and understand a kind of abstraction space within a certain cone
but um I was reading professor Christopher Somerfield's book at Oxford I interviewed him last week
and he said in his book um could it be that the um success of mammalian brains is not due to any
careful crafting into a mosaic of different functional subsystems but instead is merely due
to size we know there's a powerful relationship between the sheer number of neurons and the
complexity of behavior he went on he said researchers and neuroscientists alike such as
Carl Friston and uh Jeff Hawkins and even Andrew Ng have flirted with the idea that there might be
a single algorithm which underpins intelligence with the brain acting like a massive TPU repeating
instructions ad nauseam to generate complex behavior so it's a fascinating idea is that a fair
summation yes what's a TPU in this oh well a tensor pro programming unit it's a very
powerful computer right yeah I learned another new acronym but my world is full of new acronyms
right okay um yeah um so what which his argument there is it's something to do with um scale and
size is is that well not not only that I mean we'll we'll get to there's a guy called Rich Sutton
and he he had this um you know bitter lesson essay and it's a warning against hand crafting um
structures architectures because it bottlenecks it doesn't scale so this universalist idea is that
you know maybe and and Jeff Hawkins says the same thing he's got this thousand brains theory of
intelligence yes and the idea is that there's a very simple underlying algorithm or principle
and you just replicate it you scale it up or out and that produces emergent intelligence right
yes well okay then I am a universalist so um you know but both of those the way you described it
do speak to some I think very pressing issues about um structures and structure learning um
that you know you could either um read from the point of view of machine learning and sort of
graph learning what's the rights you know how many layers does this particular deep learning
architecture need or what kind of factorization are going to put in play
or if you were um you know um radical construct a radical constructivist this you know that that's
where you know I've often heard people like Josh Tenenbaum for example think about sort of structure
learning and um from the point of view of the universalist I've now learned that new word now
that's good so as from as a universalist then you are certainly looking for the one principle
that is redeployed at successive scales and that should be a sufficient explanation for
those things that show emergent behaviors at particular scales so I think that you know
that is absolutely true and again you can read this from the point of view of a mathematician
from the point of view of um the renormalization group and what does that mean what it just means
that you know if I take lots and lots of little things um and I start course training them in a
particular way um then if I want to describe the behavior of all the elements at one um scale of
organization say molecules or cells or people um then if I can write then down their dynamics
in terms of say Lagrangian you know so some way of summarizing their dynamics that um and all the
things that um accompany or ensue from those dynamics um then if I do my course training
um and then look at the collective the average behavior of say lots of cells a place cell or
entire medial temporal or entire person um at a more macroscopic level then I should
be able to recapitulate the same functional form of the dynamics and all the Lagrangian
so from that point of view um you have a particular kind of universalism that is
actually scale free because you get the same principle emerging at every level and that that
is basically um one um one way of looking at the deployment of the free energy principle
is asking what would it look like when deployed at different scales so you can deploy it at the
level of dendritic self-organization you can deploy it at the level um of um your uh neuroscience
you could deploy it at the level of um morphogenesis and cellular pattern formation
we've done that with Mike Levin um the idea being that this the same universal principle
works at every every level then the interesting game comes between the coupling between the levels
how does one level constrain um and inform or contextualize the level below and vice versa
you know and this I think is a really important sort of um issue which is probably well rehearsed
in many different disciplines ranging from say evolution so evolution as a free energy
minimizing process where free energy is literally the um the the negative abound on the negative
log marginal likelihood um I name it the likelihood of finding me this phenotype here
when sampled at random from a population um how does that scale of a free energy self
auto poetic process you know natural selection basic model selection if you're a statistician
how does that provide constraints on the exactly the same principles um of active inference and
learning um in developmental time for any given phenotype and then the that would be the top
down causation the bottom up causation from one scale to the next scale would be you know how does
my behavior my experience experience dependent plasticity my evidence accumulation all my good
Bayesian decisions how does that now um mean I contribute to the gene pool at the at the
evolutionary level yes so you know that that that would be one way of reading it the other way of
reading it of course is just if you're designing um a tpu or deploying a tpu um you've got that
you've got message passing on some graph what is a graph well it only has interesting structure
in virtue of the um the sparsity or the connections that are not there otherwise it's a full graph
and it's not where you saw for anybody speaking to Chris's Christopher's uh uh you know too too big
too many neurons um you can't you you necessarily have to have a sparsity to fit all those neurons
into um I would put it the other way around though I would say that um anything that is adaptive and
has this size uh you know what properties must it possess and I would I would suggest that it has to
comply with the principles of um self-evidencing um where evidence now is the marginal look the
marginal likelihood that can always be read as accuracy minus complexity so as if it exists
and it's big it's got to be minimally complex what does that mean it's going to have the
smallest degrees of freedom uh the minimum number of connections in so you should be
able to predict the sparsity from the first principles at every scale so that sparsity
defines the nature of a graph and indeed if you're talking about anything that's deep
in a hierarchical sense all you're saying is there's a particular kind of graph um that I
have in mind and it you know has a certain sparsity structure but crucially it's a sparsity
structure that allows me to call it a hierarchy it means that there are no connections that transcend
unlike a sort of you know a u-shaped uh no it's still hierarchical to anyway sorry I'm
getting a bit distracted right the choice of graph so I mean I think that's sort of um
the notion of um coupling between different hierarchical scales is absolutely crucial
from many different perspectives renormalization group evolution um you know getting the right
graphical architecture and your method passing scheme and computer science so
yes I wanted to bring that up but I discussed um it's actually the same thing with Levin so
morphogenesis and the rungs of the emergence ladder and the causal pressures between those
rungs and you know philosophers like George Ellis said that you only have causation uh between the
levels and uh Douglas Hofstadter and Gaudalesha Bark and The Strange Loop thinks that there's a
very complex panoply of causal pressures between the scales so like I gave the example to Michael
my mind is an emergent phenomenon and I command my hand to move and he said that at different
scales you get different amounts of work and actually I think if you get into integrated
information theory it's kind of talking to that a little bit and and I think you think of consciousness
as having a lot of um information processing going on because it's at the top of the stack to
to some extent but do you have any intuition on on how that information is kind of partitioned
between the scales and how those causal pressures work between the scale yes I do wonderful you're
very well read aren't you so it's nice that you you mentioned George Ellis I use the word top
down bottom causation exactly in the spirit that he writes about it so I had literally out here had
him in mind but so I was hoping if he ever hears it he'll know that I was talking about him so it's
exactly that and it always makes me a bit queasy when I use the word emergentism which I think
some people say there's no top down causation in emergentism but I I don't fully understand the
philosophy of it but it just acknowledged that sorry yes I've distracted myself from your really
important question which oh yes the um so the the different scales um of a Bayesian mechanic
self-organization viewed through the lens of Bayesian mechanics um I think um what we've just
been talking about and I would imagine with with Mike as well a lot of focus of here in that kind
of work um is um I hesitate to use it but I will use its spatial scales you know how how how to
element how the single cells assemble into multicellular why but you know how on earth can you
envisage the emergence of multicellular organisms as Mike's done some beautiful theoretical work
you know several years ago now just just think about it to be a skin cell to be an epithelium
means you have to sacrifice the ability to reproduce so it's if you like completely
paradoxical from the point of view of natural selection you have to sacrifice yourself with
the greater good so there are you know there's a wonderful questions about about um um cells of
cells and of cells and cells as you build up to different levels of um spatial scale but I think
your question will be better addressed from the point of view of temporal scales um and again you
come back to this um universalism um now I'm getting fluent using that word um where you've
got the same principle playing out yeah exactly the same principle exactly the same mechanics the
same Lagrangian um playing out at different scales that um where each scale contextualizes and has
this circular causality the bottom up and top down um um aspects to it in play so my favorite
example of this is just to um look at a succession of belief updating um processes um from the very
very fast which would be um from the point of view of um you know sentient machines it would
be inference inferring states of the world as they are in the moment so state estimation
Bayesian filtering um um everything that um you know speaks to some kind of situational
awareness on the basis of some smart and hopefully smartly sampled data um and then we move to the
next level I'm going to skip attention and precision but there is an intermediate level which
usually um in in the neurosciences has has a time scale of your your hundreds to just uh
of milliseconds to seconds but I'm going to I'm going to jump straight to learning
so what's learning well it's just slow inference it's just basically um slow belief updating um
where the states that matter now are equipped with another kind of label which we call parameters
or weights in machine learning in neural network but they're just random variables that are
brought to the table to explain uh or part of our world moral generative model but they're special
kinds of parameters because they change very very slowly and then you move well okay
so those are two levels what about turtles all the way down and turtles all the way up
well okay what's the next level well the next level is now the structure so now for any given
graph for example um that is equipped with edges and those edges will have to have some
slowly varying parameters um that describe the you know the nature of the message passing on
those edges um there will be um there will be a you know you are conditioning on upon a particular
structure and you know is there a connection there is it a hierarchical is it heterarchical is it
you know a unit is it um is it a transformer you know it's a convolutional you know you've seen
this wonderful evolution of structures in machine learning over the past few decades as people try
out different structures and you know some work for one kind of application of the work for others
but um from the point of view of your question what we are seeing is a kind of structure learning
that's playing out over years so this but it's exactly the same principle it's this free energy
minimization but just in this instance the free energy now is a pathological it's just the average
over a long period of time which is the um which is the exactly the quantity that people doing
structure learning or Bayesian model selection use when adjudicating between different graphs usually
of complex system models for example um you know and you could argue that now over
several tens of years or hundreds of years that you know exactly the same maths could be
leveraged to provide a formal description of natural selection as Bayesian model selection
exactly the same thing as you're doing now when you're selecting whether to speak or whether not
to speak or trying to infer you're selecting the right hypotheses about you know the narrative that
you have in your head that makes sense of what I'm saying um exactly the same maths and mechanics
is unfolding over the millennia um you know in terms of uh in terms in terms of evolution
so I think that's a nice example of the separation of temporal scales but the conservation of exactly
the same principles that have this information geometry and implicitly intelligence uh in of
a basal sort I use the word basal because that's what Mike Levin and Chris Fields and
Jim Place were at like using this it's this notion that um basal cognition and basal intelligence
transcends physics psychology and biology um it's all the same thing this is a line from
Chris Fields as a friend of Mike Levin yes yes and I think that's a great notion um and I think
you one can do that very gracefully by being a universalist and just by finding the right principle
the right sort of um reading of dynamics and you know that reading you know for me
is the information geometry that um that supports the belief updating I was going to do Markov
blankets later but it feels relevant now and maybe we should bring a bit of continuous versus
discreet in so a few things came to my mind when you were talking about that first of all we think
of um emergence over time and self-organization over space and I guess it just occurred to me
that are we only interested in time and space when we talk about this kind of structural learning
and then um with these Markov boundaries I had only thought of them um in at one point in time
but you could actually think of a kind of three-dimensional Markov boundary over time as well
now just to remind our audience um blanket states facilitate the interaction between
the internal and the external conditional independencies the external states are independent
from the um the internal states as long as we know the intermediate blanket states now um
to get to the uh to a core issue that we'd be modeling in complex systems you know like where
do you draw these boundaries and is it boundaries all the way down yes um so I think you're absolutely
right this is the perfect time to bring up this sort of uh I hadn't really thought about a notion
of boundaries in time and sort of um that's intriguing so but you're distracting me I well
I'll think about I'll think about that after our conversation and but no certainly so um there's
certainly a lot of current interest in um taking the notion of Markov blankets which is foundational
in this sort of reductionist lens of the free energy principle as a Bayesian mechanics um you know
the one could could summarize but the Bayesian mechanics of the free energy principle is simply
just another kind of uh quantum mechanics or statistical mechanics that inherits just from
this partition that is the Markov blanket that separates the the inside from the outside yes um
now um and of course there are lots of vexed issues about one how do you identify those Markov
blankets and how long do they endure for um so there's lots of interest in that at the moment
but one very simple approach to um um the question how long do they endure for is to say well that's
not the right question because we've just talked about separation of temporal scales
so you have to say at what temporal scale well you operationally define the Markov blanket
as the time over which it exists and what would that look like then when you certainly now think
about um this situating that temporal scale within the context of a larger temporal scale
so what you now have is a a picture where big Markov blankets blankets and blankets things
that define say you you and me or cultures or um um nation states or institutions that um out live
say species um these big ones are last for a long time but they contextualize and provide
constraints on uh Markov blankets at this at a smaller scale that last for very uh for much
much shorter periods of time and so on all the way down so that at some level say at the molecular
level from your perspective these Markov blankets may only exist for nanoseconds or your
milliseconds um but from the perspective of the molecule thank you you know this this is a lifetime
and it's well happy complying with or can be understood as um you know doing its own basal
