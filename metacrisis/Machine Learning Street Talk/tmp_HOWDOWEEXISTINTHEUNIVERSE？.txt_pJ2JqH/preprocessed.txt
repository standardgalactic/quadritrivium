For much of human history, we were kind of like the LLMs,
figuring things out by kind of matching patterns in our minds.
But then came more systematic formalization and eventually computation.
And with that, we got a whole other level of power
to truly create new things and to in effect go wherever we want in the Ruliad.
But the challenge is to do that in a way that connects with what we humans
and our AIs understand.
You know, I know that you make a big thing about the way that we
measure and observe the universe rests upon that sort of notion of
things having temporal persistence.
I guess that the same kind of commitment is inherent
in assuming that there is a non-equilibrium steady-state solution
to the dynamics in a classical formulation.
Human language, mathematics, logic, these are all ways to formalize the world.
And in our century, there's a new and yet more powerful one,
computation.
For nearly 50 years, I've had the great privilege of building up
an ever taller tower of science and technology
that's based on that idea of computation.
Is this a fact of physics that the world is predictable enough
that an observer who can sort of continue to exist is possible?
I mean, this is something which I think from my understanding of fundamental physics,
one of the things that is not obvious is that an observer who persists in time
is possible in the universe.
And that very existence, the emergence of an observer is what manifests to us
and indeed does manifest to us as a kind of intelligence,
a kind of sentence that may or may not have some kind of deep planning associated with it.
I've been interested in trying to characterize what our observers like us like.
And the thing in our physics project that's really the kind of the sort of motivation for that
is that there is this thing we call the Ruliad, this kind of entangled limit of all possible
computations, which is in a sense has everything in it.
For me, two critical features of observers like us are that we are computationally bounded,
we have sort of only finite minds, we can't untangle every detail of what might be happening
in the universe, we can only look at sort of aggregated large scale features.
So computation isn't just a possible formalization, it's the ultimate one for our universe.
It all starts from the idea that space, like matter, is made of discrete elements.
And from that structure of space and everything in it, it's defined just by a network of relations
between these elements that we might call atoms of space.
So it's all very elegant, but deeply abstract.
But here's kind of a humanized representation, a version of the very beginning of the universe.
And what we're seeing here is the emergence of space and everything in it
by the successive application of very simple computational rules.
And remember, these dots are not atoms in any existing space, they're atoms of space
that get put together to make space.
The observer thinks they're standing still.
The observer is not zipping around all over the place.
The observer believes they're stuck, they're persistent in time and they're stuck
in more or less the same place in space.
If we didn't have that, we wouldn't be able to make a video that anybody recognizes,
even though the underlying connections in all these hypergraphs are all absolutely correct.
We just wouldn't be able to see that.
So in that sense, we can say that to an observer with those characteristics,
yes, black holes are persistent things.
And yes, if we kept going long enough, we could build our whole universe this way.
So eons later, here's a chunk of space with two little black holes that if we wait a little while,
will eventually merge, generating little ripples of gravitational radiation.
And remember, all of this is built from pure computation.
But like fluid mechanics emerging from molecules, what emerges here is space-time
and Einstein's equations for gravity.
Our computational rules can inevitably be applied in many ways,
each defining a different kind of thread of time, a different path of history,
that can branch and merge.
But as observers embedded in this universe, we're branching and merging too.
And it turns out that quantum mechanics emerges as the story of how branching minds perceive a branching universe.
So the little pink lines you might be able to see here show the structure of what we call branchial space,
the space of quantum branches.
And one of the stunningly beautiful things, at least for physicists like me,
is that the same phenomenon that in physical space gives us gravity,
in branchial space gives us quantum mechanics.
So in the history of science so far, I think we can identify sort of four broad paradigms
that for making models of the world that can be distinguished kind of by how they deal with time.
So in antiquity and in plenty of areas of science even today,
it's all about kind of what are things made of and time doesn't really enter.
But in the 1600s came the idea of modeling things with mathematical formulas in which time enters,
but basically just as a coordinate value.
Then in the 1980s, and this is something in which I was deeply involved,
came the idea of making models by starting with simple computational rules and just letting them run.
So can one predict what will happen?
No. There's what I call computational irreducibility,
in which in effect the passage of time corresponds to an irreducible computation
that we have to run in order to work out how it will turn out.
But now there's kind of something even more.
In our physics project, there's things that become multi-computational
with many threads of time that can only be knitted together by an observer.
I'm remembering when I was like 15 years old or something,
maybe 14 years old or something, I went to some talk by some well-known physicist
and I sort of said, they were talking about black holes and I was like,
is there something similar between electrons and black holes?
And it was like, no, no, no, that's a completely silly idea, you should forget that idea.
So I talked about building up the universe by repeatedly applying a computational rule.
But how is that rule picked?
Well, actually it isn't, because all possible rules are used
and we're building up what I call the rouliad,
the kind of deeply abstract but unique object
that is the entangled limit of all possible computational processes.
Here's a tiny fragment of it shown in terms of Turing machines.
So this rouliad is everything and we as observers are necessarily part of it.
In the rouliad as a whole, in a sense, everything computationally possible can happen.
But observers like us just sample specific slices of the rouliad
and there are two crucial facts about us.
First, we're computationally bounded, our minds are limited.
And second, we believe we're persistent in time,
even though we're made of different atoms of space at every moment.
So then here's the big result.
What observers with those characteristics perceive in the rouliad
necessarily follows certain laws
and those laws turn out to be precisely the three key theories of 20th century physics.
Generativity, quantum mechanics, and statistical mechanics in the second law.
So it's because we're observers like us that we perceive the laws of physics we do.
We can think of sort of different minds as being at different places in rural space.
Human minds who think alike and nearby, animals further away,
and further out we get to kind of alien minds where it's hard to make a translation.
I would suspect that there is something which you are something interesting
which you're effectively taking as axiomatic about observers.
And perhaps that, I mean, in a sense one of the things I'm trying to do right now
is to think about what aspects of observers are in fact there,
but we've always thought they were obvious.
And one of the things that's really dramatic in that simulation
is how much activity there is in the background of space.
That is, that space in order to exist has to have a lot of activity
just to knit together the different pieces of space.
Could we think our way out of it?
I think we possibly could in a sort of science fiction sense.
Simply because we've got the right kinds of models of our lived world,
which is just the physics that you're talking about.
But lots of other observers would not be able to do that
unless they had that right kind of internal model,
that implicit way of modelling the causes of all of my sensations.
I mean, I think you were talking about thinginess, so to speak,
which is a lower bar probably than observance.
I mean, thinginess might just be the ability to maintain an independent object,
maintain something that we can consider to be a persistent object.
Just Chris Fields.
Chris Fields.
So he frames exactly what you were just saying in terms of there being little
pockets of concentrated planning, sort of self-modelling of the kind
that invokes the consequences of one's own agent.
He'd articulate that in terms of a minimal Markov blanket.
So something that cannot be reduced, that has, if you like,
the capacity to be an agent, and then it sees itself enacting its plans
through a hierarchy of subsequent Markov blankets.
So you could say that the, you know, the inclusive Markov blanket
around this little packet or the irreducible Markov blanket was an agent,
but the agency sits at the heart.
And of course, he thinks that's consciousness.
You're both absolutely brilliant.
And I think Tim and I both look up to you quite a bit.
So this is actually a pretty terrifying situation for me.
Let's see what happens next.
So look, there's no real way to order two of one's heroes.
So I just went to the tried and true alphabetical.
So we're just going to, we're going to introduce Dr. Friston and then Dr. Wolfram.
So Dr. Friston, welcome back to the show.
You are an esteemed British scientist who is widely recognized
for groundbreaking quantitative methods to understand the human brain.
A professor at the Institute of Neurology, University College London.
Friston invented statistical parametric mapping and voxel based morphometry
to neuroimaging techniques that have revolutionized the field.
Dr. Friston has published over a thousand papers in scientific journals,
making him one of the most cited scientists.
He is the originator of dynamic causal modeling
and the much acclaimed free energy principle.
A deceptively simple and yet profoundly impactful idea
that has fundamentally reshaped our understanding of the brain and living systems.
More recently, he accepted a role as chief scientist at versus AI,
a company implementing cognitive computing and distributed intelligence.
Welcome back to the show.
It's great to be here.
And can I just say it's a great honor to be here with Stephen Wolfram.
I don't think we've ever actually met and it's, it's lovely to see you.
I'm very nice to meet you too.
Yeah. And Dr. Stephen Wolfram, you are a renowned British American computer scientist,
physicist and business leader known for your considerable contributions to multiple scientific
domains as the founder and CEO of the innovative software company Wolfram Research.
He developed Mathematica, a comprehensive computation environment,
along with the Wolfram language, an original symbolic language that greatly
alters the interaction with computation as an early pioneer in theoretical physics,
cellular automata and complexity theory.
He wrote the best selling book, a new kind of science,
arguing for a fundamental shift in scientific paradigms.
More recently, he launched the Wolfram physics project,
ambitiously aspiring to build up a fundamental theory of all physics from a computational
foundation for his influential work.
He has achieved numerous accolades, including being the youngest MacArthur fellowship winner.
Wolfram's transformative approach continues to impact the landscape
of computational science and beyond.
And welcome back to the show.
You've been on a few times with us now.
Yes, great, great to be back.
And this is, you know, I, I have been meaning to learn what does Carl Friston really do.
So this is my opportunity to do that.
So I'm looking forward to this.
And am I allowed to just jump in and start talking about?
Oh yeah, absolutely.
Yeah, of course.
So I've been, I'm, I'm sort of curious how horribly wrong I am in my sort of
vague idea of, of, of, of Carl and his free energy principle and so on.
So see, let me, let me try my version of this.
And then you can tell me what's, what's horribly wrong with it.
I mean, it's kind of like, if you're a, a brain-like thing, you kind of the concept, I think,
is that you want the world to be as predictable a place as possible.
And that it can be predictable either because you have a great model of what's going to happen,
or because you've organized your world so that it is set up to be predictable.
You know, we, we, we kind of, you know, part of what we try to achieve with technology and things
is to make our lives sort of more predictable.
And I suppose my, my assumption is that, I mean, first of all, am I,
am I roughly right in what the, what the point is here?
Am I totally, totally off base?
No, no, you're perfectly right.
I mean, that's almost word for word, how, how I would portray the sort of
telogical implications of the free energy principle to psychologists and neurobiologists
and other sort of theoreticians in the life sciences.
I should say, if I was talking to a physicist, and now I am,
and just want to say that I'm only an intuitive physicist.
I've forgotten all the physics I did when I was, when I was a young man.
But if I were trying to explain to a physicist, then everything you said is exactly right,
but inverted.
So if things exist and thing-ness is defined in terms of establishing some kind of
synchrony or some kind of non-equilibrium steady state with everything else,
or particularly the local niche in which it finds itself,
then it can always be read as if it is trying to predict what is happening,
and exactly as you say, engineer or design its niche,
so to, as to make things more predictable.
So it's one of, done then, it's strange inversions.
So part of the simplicity of the, the free energy principle lies in that almost
tautological framing of the free energy principle whereby you're just saying
that if something exists in harmony in relation to its environment,
then it will show these kinds of properties that can, on a certain reading,
be interpreted as minimizing surprise, maximizing predictability.
But there are lots of nuances, and I would like to know how this might fit into
what we were talking about before going on air,
the Ruliad and your conception of how the universe unfolds, and what part of that,
what slice of that constitutes the thing, the observer, and how it relates to the context
in which it is evolving.
Yeah, I think that's interesting, but let me see if I can paraphrase what you just said.
You basically said that for an organism to be sort of happily going along,
as you said, in harmony with its environment, it is inevitable, you say, that it must have
achieved this minimization of surprise, this maximization of predictability.
Is that right? I mean, that's some, so in other words, that somehow,
if things were still dynamically changing, and the world was becoming a different place,
for example, and equilibrium of the type you described had not been achieved,
then, as I understand it, you would not expect your sort of, well, I kind of,
the term free energy kind of confuses me a bit because, you know, I'm used to kind of
a physics version of that, which I think is not quite the same as what you're talking about,
but let's say you're, let's talk about, you're saying that, so let me ask, in a situation
where the world is changing, do you anticipate that this minimization of surprise, so to speak,
still is still there, or do you think there's a different thing that might be more like a
non-equilibrium version of thermodynamics as compared to a sort of equilibrium things are
going along with, in the case of thermodynamics, maximization of entropy, in your case, the
minimization of surprise, or did I misunderstand that? Well, no, it's an excellent question. So,
strictly speaking, the free energy principle does assume that there is some steady state,
but it is a non-equipment steady state, so it's certainly as meant to speak to 21st century physics
are not the thermodynamic equilibria that you would have in say a closed system, so it's all about
how something, say an observer, is open to the thing that it is observing, and understanding
the statistics of that exchange with the thing that is, it is open, say for example, a heat
bath, it's understanding how you couple to a heat bath and beyond, and what certain properties would
that coupling and the system, say the observer of that heat bath would possess, if it were the case,
technically, that this joint system had a pullback, it's largely framed around the notion of
random dynamical systems, but it does assume that there exists a pullback attractor to which the
system is being attracted, so most of the free energy principle would really only apply
over the time scale that you are circulating on that attracting set, so if at a certain time scale
there could be reasonably assumed over a period of time an unequilibrium steady state, then you
can apply the free energy principle, so at that level there are assumptions about persistence,
and I know that you make a big thing about the way that we measure and observe the universe,
rests upon that sort of notion of things having temporal persistence, I guess that the same kind
of commitment is inherent in assuming that there is a non-equilibrium steady state solution to the
dynamics in a classical formulation. So you're really talking about if the world isn't changing
too much, this is what brains and things like them are going to be trying to achieve, that is
they're going to be trying to set things up so that they can as well as possible predict what's
going to happen, so I'm kind of curious whether you see that as being an inevitable feature of
sort of our success and the struggle for life in biological evolution and whether you think it's
kind of almost a corollary to kind of a brain-oriented corollary to sort of success in
natural selection or whether you think it has a different kind of origin?
I would look at natural selection as one manifestation of exactly the same kind of
self-organization but at a much slower timescale, so success just is existing and existing is
maintaining yourself in some characteristic states that you can be identified as that kind of thing
over a certain time period, so if that is success then the free energy principle is just
describing the necessary properties from the point of view of sort of a classical physicist or at
least somebody framing things in terms of random dynamical systems, success just is existing for
or persisting for a sufficient amount of time and that could be at a timescale suitable to
understand the organization of a single cell so that the persistence would actually possibly be
in hours to weeks to months or it could be the kind of persistence you might bring to the table
to characterize or define the characteristic coarse grain states that apply to a particular
species for example and then you'd be looking at evolution as a process of effectively finding
those phenotypes that persist, there's a lot of tautologies here which perhaps if you just
indulge me so the surprise we're talking about is just the self-information in a Chalonesque sense
that's just a negative log probability of you know me as something being in a particular state
so in minimizing that self-information I'm also implicitly maximizing the probability
of me occupying this particular state so I'm just maximizing my marginal likelihood
having marginalized out all the environmental or external causes of the exchange with the environment
so read it in that way it's just you could also say it is a statement of adaptive fitness at an
evolutionary set in an evolutionary sense that it is a measure of the probability you'll find
something like me in this particular eco niche so then you can now start to read evolution natural
selection as Bayesian model selection in the sense that a Bayesian statistician would just
select the best hypothesis or the best model of her data on the basis of the marginal likelihood
or the evidence for that model so that leads to a nice picture of evolution is effectively
nature's way of doing Bayesian model selection trying to get the right kind of model for this
kind of eco niche I mean clearly things get a little bit more complicated when the model is
starting to build that eco niche but in essence that you know that that's a sort of the deflationary
aspect of this description you know it's just yeah but I mean so I'm kind of curious in an organism
it's trying to make its world as predictable as possible by by getting smarter as an organism
and by giving itself you know an easier house to live in where it doesn't have to be
subject to the vicissitudes of nature so to speak where it can it can just you know have a predictable
life but I suppose you know maybe it seems very kind of sort of every day to say I mean
if that's kind of like you're setting things up to make things as status quo as possible
because that's that's the case in which things will be as as predictable as possible but yet
some of us perhaps even like you and me like going to explore things where we don't kind of
know what's going to happen and so I'm sort of curious how you see kind of unexpected scientific
discovery in the context of kind of a model of what what in a sense brains try to achieve
in so far as you're you're you're positing that sort of things should be set up to be as predictable
as possible how does kind of going out and finding surprising things in in science or
in nature fit into that I'm sort of curious right well it's interesting you end the question with
curious because that that that would be the answer wouldn't it yeah how would you explain us as
curious creatures so from yep from the the physicist's point of view this rests on the
the picture of the free energy principle as simply a principle of least action so it's
it's you know there is some time integral in play exactly of the kind that's sort of written
fine it's and just to explain where the free energy comes from in this sense it is exactly the
kind of free energy that Richard Feynman used to elude the intractable problem of marginalizing
over all possible paths but providing a variational bound on that marginal that marginal or the log
of the the marginal likelihood which has been used a great effect in statistics and indeed
you know defines a whole field of variational bays so it is purely an information theoretic
probabilistic quantity that bounds the the marginal likelihood but crucially it applies to
trajectories and paths so I think that's the solution to your I think very natural and challenging
question why is it if we are surprised minimizing we act in a way that is information seeking
that responds to novelty to response to sensation and indeed as you say you know both an eye you
and I now are engaging in this sort of uncertain to resolving curiosity driven kind of behavior
and one could also cast both our lives as doing exactly this and our and Keith and Tim yeah that's
the whole raison d'etre of the of these of these interviews to gain information you know celebrate
information seeking behavior you're the the narrative answer to your question that if you're
trying to minimize surprise and you want to use that principle to understand the kinds of paths
that I would choose or elect to take through some state space then I'm going to try to choose those
are I more likely to choose those paths that minimize expected surprise now if you remember
expected for surprise is just expected self-information so that's just uncertainty so entropy so I
will in terms of the paths that I take in terms of my behavior my choices and my actions over time
then I am more likely to choose those actions that reduce the entropy of my beliefs or my measurements
namely reduce my uncertainty so that's that that is if you like the kernel of the application
the free energy principle not just the states of mind but to the way that one can understand
agency in the sense of your how do sentient things or things that could be cast as observing in
some sense how do they behave or how must they behave if they on average minimize the path integral
of their surprise or the bound of a bound upon surprise so read like that it is just a statement
it's just a variation of principle of least action that now acquires an interpretation
you end up saying well I am then if I exist and I am an agent that can act upon that world
and can gather the right kind of data or sample the right the right sensory inputs or sensory
exchanges with that world then it will look as if I am curious and you know perhaps you know we
you know mankind or woman kind is you know the epitome of that kind of self-organizing
realization of that principle of least action does that make sense I'm not quite understanding this
so I mean in in uh in the traditional path integral of physics one has what one is trying to minimize
is the action effectively the relativistically invariant kind of energy
quantity and one one specifically one's trying to you know find well actually it's not necessarily
minimized find the extrema of e to the i times the action where so you're I mean you know there's
there's a there's a fairly specific kind of concept in physics of how that works that rather
spectacularly in our kind of models of fundamental physics we can actually derive from much lower
level computational concepts but I think that's not really where you're going with what you're
thinking about I think instead what you're thinking about is you have a path integral of
if I'm if I'm not mistaken you're saying there is sort of the life of the organism is
the the time variable and the life of the organism is what you're integrating over
and the possible paths correspond to the possible things the organism could do
somehow navigating through what is some kind of distribution space of probabilities
is that is that roughly right or did I did I totally misunderstand that no no I think it is
certainly roughly right the rightness there is that you know well first of all
the sort of formal the pathological formulation the free energy principle he is he is just
exactly finding that path that that minimizes that that the integral of the this variational
free energy but you're also right that the variational free energy is a functional of
a probability distribution so the twist here is that the physical states of an observer
that is somehow identifiable or individual or separable from the thing that is that is being
observed stand in for the sufficient statistics or the parameters of probability distributions
conditional probability distributions you know interpreted or read as Bayesian beliefs of a
very sub-personal sort so this free energy is a function of a function it's a function of
probability distributions that are parameterized by the physical paths that your internal states
internal to the observer would take and so then the game is to try and find or
for certain particles that have very very precise internal dynamics they will follow the paths of
least action in a standard classical physics sense and but in this instance you would be
interpreting that as paths that are described in terms of the smallest variational free energy
functional of the beliefs encoded by those paths so if those if that free energy is now
read in terms of a measure of or representation of the internal states sorry the external states
then what you're saying is that this path of least action is effectively the path of least surprise
about what you think is actually causing the your your exchange with the external states
so the twist here is that your your work you're making a distinction well the move from say
physics or the move which makes the the physics that is described by the free energy principle
distinct from the usual applications of the path integral formulation is that you've got a
distinction between the states and observer and that which is observed which now allows you or
licenses you to interpret the observing states as holding beliefs about the observed states so
under you know what we would normally call a sort of Markov blanket partition where you're
partitioning the all possible states into the states of the thing doing the observation
and the thing and external states being being observed what you're saying is that the internal
states now play the role of the sufficient statistics of beliefs or distributions about
the external states so these are beliefs about something they're not the probability distribution
of the thing itself which is you know what you would apply or how you deploy the principle
deploy the principle least action in the usual sense but it's the same exactly the same math but
now applied to the the conditional distributions or the Bayesian beliefs encoded by or entailed by
the internal states so this is where the sort of the physics of sentence comes in and you can start
to talk about being surprised you know in an anthropomorphic sense but the maths is
is you know there's there's nothing new in the maths it's just it's just what inherits from being
able to distinguish between the inside and the outside does that make sense so you're moving
on let me see if I understand that so so let's take a sort of an initial simplified model where we
don't consider the internal states of the observer at all let's just start with an observer hanging
out in an environment and choosing a path through in a sense through that environment so imagine
that the environment is parametrized by let's say an information amount or an entropy the
environment is parametrized by different let's say we've just got a plane x y plane for example
and at every point in the x y plane we have a certain amount of randomness some places in the
x y plane are very predictable we can just you know there's a road that's just very well defined
and if we go off the road we're in this kind of billowing area where all kinds of random things
are happening so my understanding would be that that in your principle if we don't start talking
about the internal states of the observer that what your principle would say is follow the road
follow the thing that's predictable don't go off into those billowing outside areas where there's
much more randomness in the in the behavior I mean that would be if I understand correctly and that
would sort of minimize that would make things as predictable as possible because you're just going
down the road you're not so you're not subjecting yourself to the to the to the other randomness
in the environment so we start with that now you start to say well I don't just want to talk about
the external environment I want to talk about also the internal states of the observer and how
the observer builds up some view of the environment um and and builds up their own model of what's
going on and let me see if I can untangle that I mean so so first of all am I am I more or less
right in terms of thinking about in the pure fixed observer external environment the observer will
pick the predictable road not the unpredictable areas of randomness is that is that kind of the
right intuition or well I wonder if I can just jump in here for a second if you don't mind and
kind of formulate because I've been thinking about this a lot you know since we've been talking to
professor first and I think this road right so we have this 2d landscape and there's there's really
a narrow path I think is is the idea because hey the universe is complicated life is complicated
there's lots of fire and brimstone you know kind of all over the place and really the path that
leads to you continuing to exist is quite a narrow needle that you need to thread and if I understand
correctly in order to thread that needle in order to even stay on the path you have to be able to
model the landscape a bit at least sufficiently well that you can stay on the path because most
actions actually lead you off into the the billowing chaotic area where you're likely to say
have your cell membrane disrupted you know if you're if you're a cell and so that
therefore if you're going to continue to stay on this path of survival you must in some way at
least partly sufficiently well enough model this landscape in order to stay on the path is this
is this correct I think to me that that that sounds like a clear way to think about it given I mean
particularly if the landscape is changing then it is necessary then then some purely inertial
activity of just I'm going to keep going in a straight line isn't going to cut it and you
know so that sort of necessitates some kind of internal you know learning on the part of the
observer I mean the and I suppose in this thinking about so what attributes does the observer have
to have so that um so that it can be successful for example would you imagine that if the world
was too unpredictable a place if physics was I mean is this a fact of physics that the world
is predictable enough that an observer who can sort of continue to exist is possible I mean this
is something which I think from from my understanding of fundamental physics one of the things that is
not obvious is that an observer who persists in time is possible in the universe that's almost
an assumption of kind of the way that one can derive the laws of physics that we see
from sort of underlying computational foundations is that it is possible to have an observer
who persists in time so I'm curious with your setup Carl what you know could you imagine a world
in which the I mean you might say well whatever the world is like there's always going to be
something which follows this minimum principle of of minimizing maximizing predictability but
you know maybe there is maybe there's a question of whether there could be a world in which you
can never achieve a decent level of predictability and in which I mean perhaps there's a different
thing to ask which is okay you predict what's going to happen but I mean for example you know the
control system that the autopilot that's flying the plane can predict what's going to happen
but if there's a great big vacuum in the air the plane is is toast you know whatever prediction it
might make it might say hey I want to you know move the ailerons in this way and that way but if
the plane's just going to drop by 500 feet it's going to be toast whatever goes on so I'm sort of
curious what you know do you imagine that there's some kind of limit to you know there's there's
some domain of controllability that the world exists in a domain of controllability or do you
think that there's sort of that kind of a brain can learn anything so to speak or I mean I'm curious
how you think about that I think that brains are very privileged and unique and that I would imagine
there are there are parts of the universe all there are universes in which this kind of thing
could not exist so I think that we're very rare things we have attained or some degree of
non-equilibrium steady state with our particular environment which I suspect is a very rare kind
of occurrence and that that very existence the emergence of an observer is would manifest
to us and indeed does manifest to us as a kind of intelligence a kind of sentence that may or
may not have some kind of deep planning associated with it but these I would imagine are very rare
instances and if I you know had to qualify why why are they so rare they depend upon a very very
sparse and structured dependencies amongst amongst the states in question and the states
in question here would be the states of the the universal the niche and in particular that that
subset of states that constitute the observer so the observer cannot is you know very much as I
imagine you know in the way in the or physics project the the observer is part of the system
so we just have a joint distribution or over all possible states and there are certain patterns
of interactions in certain states that you can associate with an observer in some very very
rare instances and then under the free energy principle or at least for me the deep question
then is well how do you then define that subset of states and in so doing can you say anything
about the relationship between the subset of states that constitute the observer and
remaining states that are that are that are being observed the only things you can say
well let's put this another way so that puts pressure on the definition of the subset of
states that constitute something or some some observer and you're at the end of the day you
and I end up or we end up saying well okay we have to be able to identify the states of something
in a way that allows us to disambiguate or not confuse it or let exchange it with the
states of everything else and that usually relies upon in you know in the classical formulation
of the FEP it relies upon specifying sparse coupling sparse dependencies so if one imagines
you know some kind of universe where there are lots of states or locations that can have
occupy different states then you're now talking about a universe that is essentially or parts
of this universe that are essentially empty of connections so you're resting upon the assumption
that there are there are there exists pockets of the universe where there are sufficient sparsity
of dependencies and neighborhood interactions that permit the emergence of this separation between
say the inside of something and the outside of something when that is in play then the free
energy principle principle applies even our in our own universe shortly after the big bang we
wouldn't expect there to be this type of life because the universe wasn't by that point sparse
is that is that essentially what you're saying i think i think that's what's being said i mean i
think i think that you know in a sense what you're saying is the observer is a persistent thing
and in order to be persistent it better not be being bashed too hard by things from the outside
world there better be some way in which the observer is only sparsely coupled to the outside world so
the observer can have a coherent identity that is persistent in some way now obviously there are
things that are persistent you know your average little black hole is fairly persistent and you
know so is your average electron or photon propagating through through you know through empty
space so to speak or the vacuum whatever that term which isn't that empty actually um but uh
so you know this so i think i think what as i understand it your notion of an observer
which by the way is is kind of similar to my notion of an observer would be that um it is
a thing which has a certain coherence and persistence and it has certain internal states
and i think part of what you're describing is the way in which
you know you have a more complicated feedback loop than perhaps uh than i've really thought that much
about a complicated feedback loop where the observer is kind of building their own world
both in terms of their model of what's happening in the outside world and the part of that outside
world in which the observer is choosing to live i mean the observer is hanging out on the surface
of the earth and isn't going and flying to the sun and you know sticking themselves in a um in a
you know 10 million degree furnace so to speak and um that and so there's i mean this question
first question i suppose is and by the way when it comes to physics this question about persistence
is there's even more basic questions like is pure motion possible you know what is motion
motion is you've got a thing and it can move to other places but it's not obvious that when you
move the thing that it is still the same thing and that's something we're very familiar with
because but you know for example if we lived near a spacetime singularity we might not even
believe in pure motion because near a spacetime singularity your average you know coffee cup or
something will be so distorted that it's not clear you would still identify it as that same
coffee cup so to speak so i i think in in um uh it's kind of the nature of of physics that we're
used to is is one where it is possible to have pure motion it's possible to have persistence
at that level but i think what you're i mean you know what i've i've been interested in in trying
to characterize what our observers like us like and the the thing in our physics project that's
really the the kind of the the sort of motivation for that is
that there is this thing we call the rouillade this kind of entangled limit of all possible
computations which is in a sense has everything in it and to know what things we will perceive to
actually be in the universe that we experience we have to kind of know how we're going to
be doing that experiencing and that forces us to understand something about us as observers
and so it is interesting quite interesting as far as i'm concerned to try and get a better
characterization of what observers like us are like and i think for me two critical features of
observers like us are that we are computationally bounded we have sort of only finite minds we
can't untangle every detail of what might be happening in the universe we can only look at
sort of aggregated large-scale features and that's one thing and the second thing is that we at least
believe we're persistent in time we believe that even though we might structurally be made from
different atoms of space at successive moments of time we we can imagine that we have a persistent
experience of the universe so to speak so i think what you're and i'm very those two conditions
are sufficient to allow us to derive second law of thermodynamics general activity and
quantum mechanics which i think is absolutely spectacular because the fact that those things
could be derivable from some underlying principle is really remarkable to me but it's my suspicion
that if we knew more about what we are inevitably like as observers that we will be able to derive
more of the way that we but that the universe seems to us so for example something i was just
realizing today actually in connection we just had a lovely little simulation that we made
of two little black holes in our model of spacetime merging and one of the things that's really
dramatic in that simulation is how much activity there is in the background of space that is that
space in order to exist has to have a lot of activity just to knit together the different
pieces of space independent of having the black hole there and that sort of as as one tries to
think about what one is seeing in that video one realizes that another thing about observers like us
is we kind of believe that we are at a fixed place in space it is not necessary that in other
words in in general activity for example we could have a coordinate system where we're
moving around all over the place in space but one of the things that again is one of our assumptions
i think implicit perhaps assumptions of observers like us is that we think we're at a fixed place
in space i was kind of realizing that that's sort of why Copernicus was so shocking so to speak
because you know we really did believe we were at a fixed place in space because that is our
experience and yet you know if the earth's going around the sun that can't really be what's actually
happening in some sense but but i think so what i'm trying to understand is in your sort of view of
kind of characteristics of observers i think you're you're describing sort of a more nuanced
version of what an observer like us has to be like and this kind of seeking of predictability
is it's an interesting idea i mean it's some uh and the question would be you know to what extent
in this kind of you know unruly really add so to speak of all possible computations
that we are seeking the predictable paths or the predictable sort of seeking predictability in that
is is sort of an interesting principle i mean i suppose i'm curious if you look at it
from the point of view of uh well i think as you say it's a little bit tautological because
um uh you know without predictability if things are sufficiently unpredictable you
don't get to coherently exist if things are sufficiently unpredictable you will be torn
apart by those outside forces that you cannot control so to speak um i i am curious uh you
know when it comes to things like control theory and you know the the whole sort of idea of uh
you know i mean control theory is a is a much more limited way of thinking about what can you
control but i'm sort of curious in um i mean if if i were to try to let's say my environment was
uh some well how unpredictable an environment can i be in and still achieve enough control
to be your kind of observer i guess i would be curious if there's a characterization
of just how unruly can the world be and still allow a a coherent observer of the kind that you're
you're imagining that's um yeah that's a challenging question a superficial answer was
not that unruly there has to be something uh recognizable as time proceeds can i just say
brought so many wonderful issues to the table there all of which i can see through the lens of
my understanding of much simpler and classical physics that um underwrites you know the free
energy principle you know um just very briefly this um these two fundaments that you mentioned the
notion of computational boundedness plus persistence in time underwriting thingness and in particular
you know the capacity to just observe or be an observer um for me um that is immediately reflected
in the uh the two pillars of the free energy principle which is first of all a mark-off boundary
which is the thing that demarcates the observer from from the observed so i know that you were using
bounded in a in a you know sort of bounded rationality possibly a different sense yeah
different sense but um you know i still think it's quite beautiful that in fact the whole
FEP can just be written down from the statement there exists a mark-off boundary that separates the
inside of a thing from the outside of a thing um and if you can i actually can i pick up on that
for a second because i'm really curious about um you know to me for example our sensory organs
are presumably there's a brain inside but it's connected only by certain sort of thin sensory
organs to the outside world and i guess that i'm curious because to me what sensors what our sensors
and our measuring devices typically do is they take a large number of possible things that might
be happening in the world the equivalents a lot of those together so we just get to say
i see a cat even though the details of the pixels in that cat might be very different
and i'm sort of curious to the extent that you talk about this kind of mark-off boundary
mark-off blanket idea um to what extent is the is the sparsification of external stimuli
for that same reason that is that that it seems like measuring devices or our sensors
you know whatever their big purposes take all these different possible states of the world
and equivalents lots of them together so that we can just make a simple summary
is that consistent with your kind of view of how how you get that sparsity of connection between
the outside and the inside so to speak or do you have a different point of view about that
no no i have exactly that point of view and i'd even go further you know the all the internal
machinations on the inside which of course you will never see because it's hidden behind the
mark-off blanket you observing the observer will only actually ever see the behavior the active
states of that mark-off blanket and the impression of the environment on that sensory epithelia or
those sparse sensory sampling those measurement tools but beyond that the whole point so one key
way of reading the maximization of marginal likelihood or the basically the the likelihood
of these sensory impressions under a model of what caused those sensory impressions that is under
the hood is to say what the the most accurate explanation that is as simple as possible so
literally the you know the log marginal likelihood is equal to accuracy minus complexity so you're in
the game of compression you're in the game of coarse-graining that is an emergent property
of maximizing the marginal likelihood of your sensory exchanges with with the with the observed
so this i think notion of coarse-graining is absolutely central here at many many different
levels you know i'm like you know that's that's what i want to ask about is because this is a
connection that Tim and i have been thinking about to the being computationally bound is that
if you're a computationally bound observer you necessarily must compress even if your sensory
organs could perceive every every particle within you know your your your light light cone it still
wouldn't do you any good because you don't have the computational capacity to compute right you to
compute all that you only have a finite amount so therefore you almost necessarily have to do
something like the free energy principle because you've got to compress which implies uncertainty
and inaccuracy and therefore you need to balance out how accurate can i be with the with the amount
of computation that i can do you know with my resources but so there's a there's a little bit
of a difference here because you know you could imagine something where there's lots of randomness
which you just ignore for purposes of your sensory input but i think what's being said about this
free energy principle is that you're you're doing more than just ignoring it you are actively trying
to lead your life so as to minimize it which is a different thing i mean you could say we're going to
observe uh you know there's there's something happening in i don't know uh some
we're exposed to a cloud let's say we're exposed to all kinds of turbulence in the air
and we could say you know we're perfectly happy we're exposed to that but the only thing we're
going to pay attention to is something about how you know light travels through the air or something
but but you're saying that no actually we our way of leading our lives consistent with our
continued existence so to speak is avoid that turbulence go and you know go and you know
go and fly through sort of uh uh unturbulant still air so to speak so that we avoid the places
where we are going to be challenged by not knowing what's going to happen so i think you you're you're
going beyond just saying we sort of throw away uh we throw away information you're saying we actively
seek to build a world or to to organize ourselves to live in a world where where things are as
predictable as possible and and as we were saying i mean you know there might come a time when
sort of things become deeply unpredictable and where there isn't and i assume that that i don't
know whether it's included in your model but you know suddenly something very different happened
if suddenly you know the earth went near a black hole or something and all kinds of crazy things
started happening and we don't know what's going on there's presumably even the process of figuring
out what should we do is is one that could take us a while and i don't know whether that's accounted
for in your in your kind of model of things i mean to say we go to the the thing that minimizes our
surprise maximizes our predictability it still could be there could be a non-equilibrium phase
in which we don't even know it's very hard for us to work out what will be the most predictable
path so to speak radical uncertainty if you're an economist yeah absolutely uh you're bringing
again so many issues and four it's difficult to know what what to pick up on that sorry i'm sorry i'm
just i'm you're getting me to think you know this is you're getting me to do the thing that is uh
precisely seems to be moving away from the predictable path but please go on well it's more
fun yeah um but in fact let's just take that phrase moving away from the predictable path
because it's got moving in and i think that's quite crucial so you know one could um and i have to
confess i'm using the word observer deliberately to try and get you to talk about your notion of the
observer in the context of the rullian and generally i just say something so so a thing um
just exists but if a thing moves and this speaks exactly to what you were talking about before it
is more than just passively um assimilating sensory information sensory samples from the world
and compressing them in some good way as a good statistician would would do and then just forming
the right kind of coarse-grained model or compressed model as people like joker and smithoover would
it would would emphasize or uh indeed um you know the whole um formulation of efficient communication
in terms of minimum message length and minimum description length formulations you know the
the the kind of universal computation you get to from homograph complexity all of this is about
making sense of stuff from the outside coming in but of course when you're moving exactly as you say
you've now got the opportunity to decide what sensory information to go and gather or you can
change your perceived or modeled external states in order to deliver different kinds of information
and i think that's that's the twist that's what makes an observer an observer as opposed to just
you know a sessile object or a passive thing that is not able to actually change the course
can act back upon um use the word feedback and i think that's absolutely crucial so
there's a circular causality here there's certain kinds of things certain an observer i think a true
agential observer has the capacity to act upon the thing that's generating the data and it is in
in that acting that you get the curiosity and as you say ignoring and in fact actively avoiding
that noisy ambiguous potentially boundary destroying um dissipative um part of the universe
and sticking to those paths but in sticking to those paths because you can't see the paths as they
unfold deep into the universe all you have with the sensory impressions that are local
to your local interactions on your sense on your observe you know your measurement um
tools or your sensory receptors so you actually have to have a model of what might be going on
on where the path might be leading in order and of course that's where this resolution
uncertain the curiosity comes in that you're taking all the local cues to build a model of
where you think the path might be so that you can follow the path so to come right back to
your final thing what happens if we went too close to a black hole could we think our way out of it
i think we possibly could in a sort of science fiction sense simply because we've got the right
kinds of models of our lived world which is just the physics that you're talking about
but lots of other observers would not be able to do that unless they had that right
kind of internal model that implicit way of modelling the causes of all of my sensations
maybe maybe we should maybe we should address that point a little bit i mean the question of
what can be an observer i mean i think you were talking about thinginess so to speak
which is a lower bar probably than observance i mean thinginess might just be the ability to
maintain an independent object maintain something that we can consider to be a persistent object
i have to say i think that's a that's a complicated concept right there because
let's say we've got an eddy in a fluid for example is that a persistent object well it seems that way
to us but at the level of molecules it's not a persistent object at the level of molecules
it's different molecules making it up at every moment in time but like the great red spot on
jupiter same thing or the eternal flame or a hurricane all these quite annoying vague boundaries
right but i mean but it's only to a coarse-graining observer-measurer like us
that that thing seems persistent to it itself you know if that thing was if if we were molecules
we would say no it passed us right by it's it's no longer we're no longer part of that thing
so i mean i guess i'm i'm curious in um i mean so i claim thinginess is well i'm wondering to
what extent thinginess is the same as observance and you know to to identify something as a thing
it needs to be perceived as having certain persistence to whatever is observing it and also
i suspect it has to be bounded the the the sort of the amount of stuff in the thing has to be bounded
in other words if the thing is the whole universe you don't get to call it a thing it's only a thing
if it's of limited you know if it's a limited part of the whole so to speak
but i i guess i'm curious you have this point of view that two things i think that are implicit
one is that an observer-like thing has some kind of free will about what it can do
that is the the observer can by choice explore this versus that it's not a question of just
the vortex is moving through the fluid and the laws of motion make it do this or that thing
i mean and i think this is um so so you're attributing to the thing that you are treating
as an observer some degree of possibility of choice and although maybe maybe not maybe
you're saying that your free energy principle is essentially the deterministic physics of what
has to happen and even though the observer may feel that they have a choice they really ultimately
have no choice um because they're really being you know led by the nose so to speak by this free
energy principle to do what they do and even though they might imagine that they could do
something different they necessarily won't do something different i mean i'm curious what
you see as being i mean does does your notion of i mean are you saying that okay so so one point
of view would be that what you're describing is kind of a law of motion for for an observer
and that that law of motion despite the observer feeling that they can choose to do this or that
they really can't any more than you know an object moving inertially through space
can choose to do this or that so like like for example you've got a spacecraft and it's got all
kinds of critters inside it and they're running around and they're saying we got to do this and
that and the other but their spacecraft without any propulsion system is just going to keep going
in this inertial trajectory whatever they might you know they might run around and and have all
kinds of enthusiasm for things it might do but it's not going to do them any good um and so you
might take the point of view that that it's the same thing with our brains and i'm curious whether
whether you do take that point of view well i love that analogy with the you know the spacecraft
with lots of intelligent sentient critters but can't actually control where they're going
um i again you've picked up i think on some key points there um so i would say that to be an observer
is to have the kind of agency that you're implying by the count the choosing or selecting certain
actions to uh to commit to actions on the world that will elicit or solicit different kinds of
measurements that you can then use make sense use to make sense of your model of how um that you
know the world works and your place and the way that you couple to that world so i i'd agree absolutely
entirely that there's there is a bright line between just being a thing being that vortex or um
you know soliton or some something that just persists and um having the kind of agency that
allows you to plan and to make moves and i think planning although it's you're not um perhaps a very
intuitive way of describing it actually captures the notion that you actually spoke to which is
you know having a choice means that you have counterfactual beliefs in your model about
the consequences of your action i think that's quite crucial i think that introduces another
bright line between different kinds of things so there are things that just don't act you know
there's things possibly like the vortex or a stone things that can't um couple back and change their
environment and then there are things that can move back and change their environment and you could
argue this um massive bodies might might fall into this category by exerting um so gravitational
forces just open brackets i agree with you entirely things like space and time these are
fantasies or hypotheses that only come from this coarse grained observation of of the world um
but i think the key line between the kind of observer that you and i are and the kind of
observations that say a thermostat would do is exactly what you're talking about it's you know
imagining counterfactual futures are very simply articulated mathematically by just um
subsuming one's own actions under the inferred causes of your sensations so this slightly
paradoxically says well i can write down mathematically um this free energy functional
of a generative model or a joint distribution over causes and consequences the inside and
the outside oh sorry the other way around the outside and the inside and i i can for certain
kinds of uh systems or things um actually include the things actions in the causes so now you've got
this um mathematical image of from the inside of an observer um of an observer that has beliefs
about what it is doing which are completely separate from what is actually doing because
because it doesn't know what it's doing until it senses the consequences of what it has done
so i think this is this brings you to the you know a better description of things that plan
and it's at this point then you get this information seeking ambiguity avoiding you talked about
control in control theory all of these good behaviors just fall out of naturally the kinds
of behaviors that you would expect if you apply uh literally of the variational principle of least
action to um a a probability distribution over not just the external causes of what you're observing
but also your own cause your sort of um auto poetically expressed causes through through
your actual action and there they must be very special kinds of very very sparsely connected
things because they're unaware of their own action they can't sense their own action
so here's the thing that confuses me so i i i have the impression that you spent lots of your
career trying to understand what happens inside brains and in a sense you know presumably with
you know at some time in the future we'll be able to measure every significant feature of the kind
of neural firings that happen inside brains and i'm curious then when your point of view about
counterfactuals and planning and so on once we can see deterministically this neuron fired it
caused this neuron to fire and so on how does that relate to your distinction between the stone and
the brain then you would be looking for empirical evidence i should say that um there's a slight
22 here because if you just come back to the notion you were you were referring to earlier on
that there has to be some sort of finite bound on the number of degrees of freedom that constitute
the internal states of an observer as distinct from the the channels that are doing the observing or
the the control channels that are you know the outputs as it were that are um mediating the
action of of the observer in terms of gathering her data so you'd be looking for evidence that the
neuronal dynamics were um or the internal dynamics had um could plausibly be explained by a gradient
flow you know a dissipative flow on this sort of free energy landscape and you know what that
landscape is if you could find the right generative model or the joint probability distribution that
stands in for um the beliefs about implicit sub-personal mathematical beliefs um entailed
by the structure and the dynamics of the internal states so in a sense that's what I do as you know
of my day job um and indeed I suspect that's what we all do day to day in terms of trying to infer
the people's intentionality in states of mind you know which want to work out what under what
kind of structure or belief structure or generative model um is the you know are these
behaviors intentions um understandable if I can jump in because I've heard you talk about this
before in a slightly different way which is essentially as soon as you're performing a
computation that's modeling yourself you know as soon as you have inside your brain a humunculus
if you will that's that's able to watch a screen and entertain these counterfactual trajectories
that you could or may or may not take it's at that point once you have that counterfactual
depth I think you referred to both a counterfactual and temporal
depth to your computation that it's at that point that you have this agency or the ability to you
know choose choose actions is that fair yeah and certainly that would be necessary to be sort of
self-aware to have a minimal kind of selfness and to know that you are you are an agent as well
um but you could argue that that you could equip a thermostat with you know a very sophisticated
generative model of the consequences of turning the you know a heating element on or off um and
introduce into that model uncertainty sensitivity initial conditions or some kind of a stochastic
chaos and let it plan you can and indeed we do we build your sort of artifacts that do have
a certain sense of planning they wouldn't be no they wouldn't know they were agents but they
they would have a certain kind of agency that would elude any potential um proactive or
anticipatory dynamics that you might find in a stone so you're looking for um you're looking for
sort of um conservative dynamics you know divergence free dynamics that have a certain
kind of itinerancy um that you know normally expresses itself in terms of oscillations and life
cycles or you know respiratory cycles or you know and the like so you're looking for an itinerant
kind of dynamics that has the requisite variety you know deliberately using Ross Ashby's words
that has the internal degrees of freedom to be a good enough model of the controllable
aspects and the you know the the um the modeled world which is you know the internal the um
the stone or the uh the brain is actually using to act upon the world uh and plan to act upon the world
so I mean I think this is an important potential distinction but I think it's more complicated
than this is my my intuition so I mean let's take you know considering our venue here of machine
learning street talk let's talk about ai's um you know we've got you know we've got some artificial
neural net it's uh you know and then our lamb is a fairly simple has a fairly simple kind of
flow of information but imagine that we have some some neural net imagine that we have taken our
brains and you know we've been so successful at neuro imaging of some kind or whatever it is
that we can really pretty much map our brains onto the the bit patterns of artificial neural nets
now my question is I'm looking at this bit pattern and I'm asking myself does this bit pattern
have a model of itself and one of the things that I think is difficult in that is that any
universal computer is capable in some sense of having a model of itself because any universal
computer is capable of emulating any kind of computational device including in particular
the the very computer that is doing the emulating so I'm curious if if if you're presented with
you know the bit pattern comes from you know sophisticated imaging of brains or whatever
where it comes from an artificial neural net what is the what is the thing that you put that into
to make a decision and and and you can't I think consider you know all of us have an internal
feeling of how we think things work and how we think we work but we can't even other than by
extrapolation we can't even be sure that other people other different human minds have the same
point of view about what's going on and so I'm curious from the outside from a kind of pure
you know data science point of view I've got this bag of bits and it's doing certain things
how do I tell whether this bag of bits is meeting your criterion of having sort of a
counterfactual planning model of the world right and so much like the empirical problem and indeed
the hard problem of consciousness you can't the whole point of the persistence that we were talking
about before read as the persistence of of the boundary of the Markov blanket means you will
never know observing something what's going on behind the Markov blanket it's unknowable because
if it were noble or measurable you'd have to destroy the Markov blanket and the thing in
of itself would not exist and certainly if you wait a minute wait a minute I'm not I'm not assuming
that I let's take let's take the case that in an artificial neural net we can look at every bit
we we don't happen to be yet technologically able to do that for brains but we can imagine I think
a time in which we can non-destructively look at every bit of what's going on in the brain
and then the question is we're seeing this complicated bit pattern we're seeing in an
artificial neural net which is easy to measure we're seeing it in a brain which happens to be
technologically hard to measure right now and then we're asking the question is this pattern of bits
that we're seeing an example of something which is a plausible sort of self-reflecting or you know
counterfactual generating modeling the world internally kind of thing or is it just a bag of
bits that follow certain rules well I mean I think I think my answer would be the same that you will
you will never know you but you could certainly infer that I mean I'm smiling because you're
just describing my day job again my entire life is being built around getting beneath the blanket
using things like brain imaging usually not invasive but sometimes invasive when you have to
implant electrodes you have safe deep brain stimulation like and and and measuring the
internal dynamics the bits the patterns and the computational architectures implicit in the in
the wiring and the and the the neuroanatomy and the connectome and then making a best guess and
trying to infer is this the kind of message passing or pattern or updating or dynamics or
architecture that could be explained in terms of a evidence maximizing free energy minimizing
belief updating process under some kind of generative model and if so what kind of generative
model is you know we get quite a long way with that I mean one of my favorite examples is you know
brains like ours have distilled a fundamental conditional independence between
whatness and awareness into their anatomy so you're the top half of the brain does
all the awareness and does all the the space or metric space your specific pointing activity or
looking activity whereas the bottom streams of the and this is the inferior temporal lobe or the
temporal lobe are much more concerned with the whatness of things and so that you know there
are certain and architectural features of both the dynamics and the the connected sparse to the
coupling that we were just talking about before which give you strong clues as to the kind of
generative model are this kind of person this kind of artifact clearly has a generative model
in which her lived world entails things that are objects that might exist but knowing what
something it doesn't tell you where it is and vice versa and immediately you think well that's
very consistent with my lived world this metric world full of objects your physical or visual
objects that can be in different places speaking to your your very interesting example before about
you know if I move something is it the same thing well no it's clearly not the same thing but
you know if you can sort of coarse grain and factorize the world into whatness and awareness and
have some equivalence or equivalence so well actually this is like the same whatness but just
now in a different awareness so you've partitions statistically in your model and the physical
instantiation of that model that that sort of statistical regularity that thing that persists
even if the molecules of the object don't persist but the regularity the pattern the coarse-grained
explanation for for for the sensory impressions generated by that thing you put that into the
anatomy so you can you pursue that so what would you be looking for if you've got some
kind of agent that has beliefs about the future and then beliefs about itself having beliefs
about the future which I think is what you're implying by the self-modeling and you be looking
for a hierarchical structure you'd be looking for certain Markov blankets or conditional
independences instantiated in the absence of literally neural connections or wires on a bus
literally a sparse coupling that had a hierarchical aspect and then you'd be looking for the
the correlates of the message passing the amount of electricity used for beyond that particular
risk so your view is that it's kind of a a series of the watcher watching the watcher
type thing and that in some sense I mean perhaps your view is that sort of the the higher
cognitive function is literally a you know a series of hierarchical levels where you're
sort of progressively abstracting from the world that is at some lowest level you've got the world
as it is and all those you know all those photons coming in all those neuron firings happening
at the first level and then that you're somehow progressively abstracting compressing reducing
that to eventually come to presumably you know to the to the point where you make a decision
should I do this or should I do that lots of lots of sensory input has come in and you're
kind of filtering it down so I'm curious if you look at you know other animals not humans
um do you imagine that it's the same kind of I mean I mean it's an interesting and and quite
kind of I would say sort of it's a it's a very definite view of of what it means to be a thinking
thing would be that you're always taking all the details of the world and always trying to
crush it down to the point where you make a decision about what to do next and that that
would be a thing where you could imagine observing that there's all that compression happening to
decide what to do next now I will say that I don't think that's specific to brains I mean imagine
that you've got a rock it's perched on some you know uh hilltop or something and lots of things
happen to the rock there's rain there's wind there's all kinds of things and eventually one day the
rock starts rolling down the hill in other words from all of those details from all those details
about what the rocks the environment that the rock was exposed to eventually it makes a definitive
decision and I'm curious what the distinction is between that kind of sort of many things happen
and you know the many things have to take place you know the rock is eroded away and this happens
and that happens and it's a whole hierarchy of actions and then eventually one day the rock rolls
down the hill so how would you distinguish that from from kind of your view of kind of the
the sort of hierarchy of action in brains I mean other than that in that particular case the timescale
might be years in the case of the rock and the timescale for brains might be seconds or something
yes that's a great question a great challenge um so but just to pick up on that that notion
of of timescale um as soon as you have a hierarchical um message passing scheme or dynamics or or
physics of the kind that I think we're talking about here there's a separation of timescales
as you get hierarchically more abstract or deeper if you like um into your observer um
so part of the hierarchy will almost inevitably entail a um the kind of temper persistence that
you spoke about earlier in terms of the observer in reading her world as things that endure over
time including me uh including out your ourselves um that is a gift of the dynamics that usually
supervene at the deepest hierarchical levels of any you imagine say centripetal kind of hierarchy
so I think that's an important observation that you know you can't sort of commit to a single
time frame to understand the contextualization of fast-moving high-dimensional content in the
course of the course-graining that there's also a course-graining over time which we call context
for example um so that would be one important aspect when trying to understand um could you
call a rock eventually being knocked from its perch as a decision I would say probably not
because you haven't got the you know the sort of the you know the scaling brand over time um it's
certainly an event but you'd hardly call it and you know you could hardly um call this uh any kind
of something that it persists over time you know from my point of view it certainly would not be an
expression of a pullback attractor if the rock however um fell down the hill and started walking
back up again that kind of behavior would suggest to me ah there's something going on of interest
under the hood and I when I cracked the rock I'd expect to see some hierarchical architecture
and some itinerant dynamics that would support that kind of separation separation of temporal
scales but before I sliced open the rock or put you in a brain imager I wouldn't know you know I just
have to guess based upon your behavior your active state so your the the the boundary that separates
what's going on in your inside from from me as part of your your outside right but I mean the
problem is this is uh the well one will never know is a reasonable thing to say on the other
hand if one's trying to make a distinction between observer like things well this there's a couple
of levels of distinction here there's the distinction between just everything and things
and then things and observer like things and I think the um and I think several of these
distinctions are kind of complicated and I'm I'm I'm you know in order to have something which seems
like a a kind of a a scientifically progressing kind of set of ideas it seems like one really has
to be able to make a a definite distinction between sort of the you know how do I tell from the bag of
bits that I have a an observer like thing as opposed to just a thing and to to kind of make
that a bit more technological uh you know we've got all these AI systems and we've got everybody
talking about whatever they might mean by AGI which I think is a kind of foolish concept but
that's a different issue um and uh uh you know should one imagine that uh the to make a more
sort of human agency like AI that we necessarily have to have some notion of hierarchy I mean
you know in in your average LLM there is in a sense one level of hierarchy in the sense there's
the feed forward of what the LLM does when it reaches you know when it tries to figure out the
next token and there's the kind of you know big feedback loop of uh you know seeing the previous
tokens and then deciding what to and then uh sort of iterating uh to to to to figure out what the
next token should be so I'm curious whether you see whether you think that it's sort of a fundamental
idea of the way that things like us work that there's a deeper hierarchy and if you think that
that has implications for the sort of the technology very high yes I do I'm very aware you're being
very courteous you're asking me questions all the time which is uh very generous of you uh but yes
I think that that that that hierarchical structure that I'm sorry I'm just you see I'm I'm trying to
live some version of your principle or not as the case may be that I'm I'm doing a you know
seeking the unknown type thing yeah but Keith and I please go ahead well Keith and Tim promised me
I'd learn all about the rouliand which I would I would like to we won't have time now but I would
like to have pressed you on that because you know I find that quite quite intriguing but we've we've
now gone into um um sort of uh you know large language models and the kind of dynamics I think
I think that's absolutely right I think I you know I if I want let me put it this way if I knew
what the generative model was I could actually just simulate belief updating under that generative
model I could basically just integrate under the the principle at least action a free engine
minimizing device and it would look as if it was behaving intentionally and planning and in a base
optimal way it would also do a base optimal KL control it would do everything you wanted
if I could write down the generative model but to write down the generative model I have to know
exactly what kind of world what kind of user what kind of ecosystem is this particular computer
designed for um and furthermore I'd have to be able to explain it you know so immediately you've
got if you give me a computer if you give me a you know a piece of artificial intelligence
that is completely explainable and by which I mean you can write down the generative model
then I will understand this then yes I could tell you exactly this is a stone this is self-aware
this is not self-aware but it hasn't you know it still has a kind of agency of a
perspective so this thing's like a thermostat this thing you know but wait a minute what once
you say you have a model that says everything about what it does the thing has no chance to have
something that anybody would consider to be something like free will because you're basically
saying you're you're you're stipulating that the thing is just acts in a predictable way
yeah I think maybe I'm gonna jump in here and say I don't I don't think you need free will in
order to have agency so I think if I even if I had a machine that was taking in inputs and
conducting an analysis and as a result of that analysis deciding to raise a red flag or you know
walk up a hill I still think that's agency even if tell me what you mean by agency
what yeah so what I mean by that is is literally that it's performing
a computation about sensory inputs and as a result of that computation deciding some
some output but so any old classifier any old machine learning classifier does that
doesn't it's not performing it's not performing an action though right but it could be if you
connected to a robot or something it can perform plenty of actions and as soon as you do then it
then it becomes and then it becomes an agent you know acting acting in the world okay so I mean
the you know image identifying cat flap that decides is it a cat or not that cat flap has
agency in your definition I would I would say it does it has a very simple form of agency but I
think that that's so so your definition of agency is that there is there are a large number of
possible inputs you are sort of you know whittling that down to something about which
a decision can be made and then you are actuating in the world perhaps so for example does it have
agency in some in some environment yeah okay does it have agency if the only thing it does
is to change a bit somewhere inside itself in other words that bit might be the bit
that is on some iobus that causes it to actuate the cat flap but that bit might be at the beginning
just an internal bit inside in a sense the brain of the AI so how would you distinguish those two
things you say it has to have that flow out to the outside world in order to be validly an agent
or to have agency or can it have agency with respect to so for example can there be a notion
of agency if the end result of your thinking is that you think a particular thought is that
enough yeah or does agency require actuation in the real world yeah so I think the way I the way
I would frame it and look this is to both of you to to criticize it or not but the way I would frame
it is if I'm affecting a change in the same environment that I'm perceiving then I'm an agent
so it's like if I'm if I'm taking an inputs from environment a okay and then affecting a change in
environment b and a and b are totally decoupled then I wouldn't call that thing an agent that's
something like a bridge between two different two different environments but as soon as I can
enact changes in the same environment that I'm perceiving I think that that's ordinarily what
what a person would perceive as being an agent you know it could be very simple that a roach
a roach is an agent you know maybe it has a very simple neural circuitry but that assumes that
there's sort of an external environment and I guess this relates to the whole Markov blanket
business of whether you can distinguish the outside environment sparsely connected to your
internal states or whether you are you're merely affecting so you're saying if you've got agency
so let me see if I understand this there's sort of a sparse connection from the outside world
coming in and that is you know there's a lot of detail on the outside world there are sparse
connections coming into you and you're saying you have agency if you can back propagate so to speak
not in the sense of back propagation but if you can if you can go back out through those sparse
connections to affect that big complicated outside world then you say you have agency that it requires
this sort of two-way thing that you're both bringing it in through that sparse connection
and pushing it out through this sparse connection is that correct Carl I'm curious whether that's
whether you would agree disagree change that um that that definition yeah I was just relaxing see
the exchange um yeah I think you'd have to acknowledge that there's a I think two distinct
use of the words agency you know I you know I can certainly argue for Keith's position that simply
being able to couple back and complete that sort of circular causality if I was you're talking to
neurobiologists this would be the action perception cycle just being able to act upon the world
is one very simple definition of an agent and that and that view of thermostat would be
would be you know a kind of agent but the other the other sense I think we've we've been using it
as in a slightly more nuanced sense which is the the ability to actively select a particular course
of action from a number of counterfactual alternatives and that requires a much more
expressive kind of generative model so you know I I think that I'm not sure whether the bright lines
you could argue that they're sort of vague or graded distinctions with one way of thinking
about this is how far into the future do you take your planning so if I'm a thermostat I can just do
that on sort of you know first and second temporal derivatives I can sort of you know like a common
filter all right sorry um like the kind of linear quadratic control that you would get if you
interpret the control or something PID perfect just a few derivatives in the moment um that will give
me um the kind of agency that that is very reflexive and autonomic and automatic and the
kind of thing that we you know you could that could in principle be found in autopilots and
thermostats and you know many things that we use around the house um you could argue that just by
having those um those state estimates and their higher derivatives that there is a sort of future
pointing aspect because you can just sort of project out the path you know you lose uncertainty
very quickly but you can certainly sort of think of those um those higher derivatives of
so the coefficients of a Taylor expansion of a little path into the future but so think you know
what you know at what point though do you do do you go into the future um sufficiently far that
you can call it a plan so what point and perhaps there isn't a hard answer perhaps it's just a
great it's just a question of how tall are you how deep is your temporal horizon um and how
you know deep can you infer it given this anatomy given the structure of the thermostat and the
or the um the time rollouts you know in say um you know all right so I'm curious if you've got
your average AI LLM whatever else and I go and I can probe that system what do I look for to look
for planning and counterfactual the construction of counterfactuals in other words I've got I've
read out a trillion bits from my LLM in action how can I tell if it's thinking counterfactually
right first of all you could just you know do do what a you know any life scientist will do which
is basically either kill it and dissect it and look at it look at its anatomy or ping it in
some way and try to infer its causal architecture or let it run in its natural's environment and
then look at for correlations measuring the functional connect the other do structural
equation model or or what I mean in the case of an LLM you know it's just a bag of bits on my
computer I know what every bit is there's no sort of you know inference by no complicated
inference I know the bits the question is even given those bits you know at the lowest level of
bits I know what it is if you ask me at a coarser level what is it thinking for example I probably
don't have a clue because I don't have a way to uh you know I don't have an you know it seems like
one of the key problems of neuroscience we don't have a way to describe and perhaps this is what
you're working towards you know we don't have a way to describe how brains work at an intermediate
level between kind of the neuron firings and the words that get spoken by the brain type thing in
other words that that um and so in the case of you know the AI the LLM whatever else I'm curious
because that's a case where we don't have any limitation on the underlying data we know what
every bit is and so now my question is can I run what test would I run what kind of correlation
would I measure what kind of what would I do to say hey you're a counterfactually thinking AI
and this one over here you know you could have a a counterfactuality index or something for different
LLMs of how counterfactually can they think how would you measure that I'm sorry I keep on asking
questions but I'm just I'm so curious well I don't know if this is related Carl but I know
you had a recent nature paper I believe it was about rat cortical neurons where you know there
was there was some quantitative analysis by which you determined that it was performing you know
Bayesian um or active inference I don't know if it's it's related and how you quantify that but
that could be a an avenue that's very smart to you because I was actually just thinking about
should I introduce that as an example of how you practically do this you basically reverse engineer
the generative model that could account for this these bits and the anatomy upon which these bits
play that's a very difficult game though unless you've got very very basically what you're saying
so essentially what you're saying there is there is an underlying thing that the LLM or whatever
does and you know all its bits yeah now you try and yourself construct another model like you might
use another LLM to try to construct a model for the first LLM that is explainable it has to be
explainable that that's the other the other one's explainable yeah right I mean that the problem is
I understand that science tends to be about making an explainable narrative for how things work in
the world the problem is I think that that's at odds with some of the things that you will need
to have something where you can genuinely say that has a model of itself because I think that
to have in a sense the itself is doing things which are not explainable at that level if everything
that we did was fully explainable I don't think we would ever consider ourselves to for example have
choice or free will otherwise if we could always explain I don't think that's to be fully explainable
though because there is there is the uncertainty baked into at least the free energy principle so
if I have a generative model of my own actions in the world there's quite a bit of uncertainty
and so I'm computationally bounded maybe I carve off 20% of my computational resources to that to
that activity but it's not going to be a it won't have perfect fidelity okay okay so so then the
question then that I would ask is okay you're saying that even though it's not going to get it
right all the time you're saying that that even getting it right some of the time is and having
kind of a a self model that is an approximation because because you know a very simple approximation
is just to say it's going to generate another token that's a very coarse approximation you're
saying you want a finer approximation but not so fine an approximation that you really actually
capture all of the dynamics it's some intermediate level of sort of coarse-grained approximation
that is sort of you know good enough but not too good I mean I I do think these distinctions are
I mean I think some of these distinctions are sort of core to the notion of what observers like us
can be like and I think it's interesting to try to home in on you know just what is the right level
here because I my own guess is that some of what we perceive about the universe so let me give an
extreme example it'll be interesting to figure out whether the fact that we perceive space to be
roughly three-dimensional is a consequence of some aspect of us as observers it's not obvious to me
I think it's possible that that's the case and in other words that that we could perfectly well
describe the universe as being one-dimensional where you know we have to chase along all these
worms that sort of you know navigate through space so to speak there's sort of space filling curves
arranged through space but that will be a very weird and inefficient way for us for observers like us
to describe the universe and so my my you know this is why I'm curious about kind of what is the
nature of observers because I think that the nature of observers once we understand it better
we're going to say why do we see the universe the way we see it and the answer is going to be
because we happen to be observers like we are just as we can say why do we see the night sky
that we see well it's because we happen to be at this particular place in this particular galaxy
and so on so well this you know this maybe in the spirit of asking you a bit about the ruley ad
is please go ahead and I think this links back because you asked a couple times you know can
you imagine a universe in which it's just not possible for there to be persistent observers
like us that are able to survive because there's not enough you know predictability and I kept
thinking you might be in a very good position to answer that question because one takeaway I took
from a lot of your work on computation and the cellular automaton really a new kind of science
is that look of all the possible calculations out there most of them are pretty boring they're
either very random or just some boring you know line that goes on forever there's this tiny tiny
sliver of computations that have this this chaos this this advanced nonlinear kind of complexity
you know so I'm curious when you're when you're building the ruley ad and you start off with
some type of substrate some type of hypergraph and there's a set of rules from which you know the
laws of physics emerge you know how much fine-tuning has to go in there like of all the possible rules
which what percentage is it a small sliver that produce interesting behavior and what's your
intuition tell you about of that sliver that produces interesting behavior what fraction of
that would allow for observers like us right well so everything happens in the ruley ad so it's not
we don't get to choose or fine-tune anything about the ruley ad itself what we do get to choose and
fine-tune is what part of it we are sampling now when I say choose it's like there is an entity
that is sampling every possible part of it but an entity like us is that there are aspects of
what's going on that we sample now when you say things that are interesting that's a deeply sort
of human-centric thing to say because what's interesting to us is a certain set of things that
well what's interesting to us is what's interesting to us I don't think there's a try as we might
with I don't know you know any kind of you know information theoretic you know algorithmic
information theoretic you know all of these things in the end I think devolve into well it depends
on how you do the coarse-graining it depends on what you think the underlying generative model is
etc etc etc and all that reflects right back on us in other words I don't think there's an absolute
notion of what's you know what's interesting and what's not you know when you talk about compression
for example this question of compression at least is always it's like it's a question of well what's
the machine that is doing the decompression if you say you know you can have if if you're doing
something like you know traditional you know Shannon style information theory you're you're usually
using things like block coding and so on where it's a very definite simple model of what the
compression decompression process can be it's some so I think you know I think this question of
what's interesting it turns right back on us I don't think there's an absolute answer to that
and you know when you ask well what about all the all the alien intelligences that aren't like us
well most of those alien intelligences will be so different from us that we won't recognize them
we won't you know our ai's are perhaps our first really good example of an alien intelligence
that by design we arrange to be quite aligned with us I mean we don't even get that for your
average whale or something we don't know how you know we can't really understand its intelligence
because it wasn't built to be aligned with us so to speak our ai's are built to be aligned with us
so we get to have a much more sort of I think you know it's much more plausible to have sort of a
a communication with that sort of human aligned intelligence or human aligned kind of set of
things that are going on that there's there's a lot of interesting stuff to discuss but unfortunately
I am quite running out of time here so so even though I this seems very unfair because I've I've
been been uh would you like to come back for around 2.0 or were we uh commit or we commit to
exploring more about the rolyard yeah right well I'd be um but but maybe I mean if we have just a
a moment more I mean Carl if you if you uh it sounded like you had sort of a pent-up
set of questions here and I'd be um uh maybe at least a preview of the of the pent-up questions
or something would be it would be interesting okay very briefly because I appreciate you've
got the rest of your day to to to live out in California which is where I presume you are
oh I'm I'm in I'm in the east coast actually so I'm all right three hours okay but I'm but I'm a
late scheduled guy so so I was just really interested in um you're listening to to you
um talk about the rolyard and thinking about us as observers as part or a slice or a slither of
of this um whether there will be any mileage in using the notion um of bounded computation
read as a a mark-off boundary or a mark-off blanket based upon the implicit what I imagine
is some kind of um adjacency matrix that inherits from the sort of hyper-graphical construction of
the rolyard so as I was wondering if there's any way of of sort of um thinking about identifying
certain patterns that do the sort of diverging emerging again and therefore give the impression
at a certain degree of course graining of persistence in the in the sense of there being a
you know like a pullback attractor an attracting set of arrangements and that that could be
operationally defined with a mark-off blanket which is trivial today once you got the adjacency
matrix you can easily identify the mark-off blanket of any given set of states and then you
could call those an observer so I just wanted to know whether that real simple really simply
simple minded view of the rolyard as basically being whose anatomy was described by some neighborhood
relationships at a very very small scale um was was an apt starting point for understanding the
nature of the rolyard right right right so I mean essentially what you're saying is can you separate
off things objects that have sort of sparse connection to other parts of the system yes it's
unfortunately more complicated than that okay so an example of something where you can separate off
aspects of it are black holes where because what makes even the structure of space is there isn't
any notion of space until you have activity in space so you're building up this causal graph
of all the different events that are happening and in order to even have a notion of space
you need a kind of kind of whole ocean of those events that that's that's what makes space so in
a sense there is necessarily connection of some kind between everything in space by virtue of those
many events having happened the only place where you can sort of separate that off is when you have
an event horizon and where you can sort of say no there's really no dependence from this to that
or at least no dependence uh when you when you're not dealing with multi-way systems and quantum
mechanics and so on so I don't think it's quite as simple as that I mean is there a way to kind of
understand the statistics of the Rulliard and ask not whether there is any correlation there certainly
is a correlation because otherwise space wouldn't hang together but whether there is a significant
correlation a correlation at some coarse-grained level I think that's what you have to go for
and that's again just technically vastly more complicated because you have to define
what's a useful coarse-graining procedure the very definition of what a useful coarse-graining
procedure is is going to lead you into questions of observers and so I don't think it's a it's a
vastly more complicated at a technical level it's a vastly more complicated kind of question
but it's I think that's a very reasonable thing to to be going for it just isn't easy to achieve
except in these rather straightforward very space-time oriented cases like event horizons
but I think that that's uh you know I I would love to have a a good characterization of you
know I've got a piece of Rulliard and I can view this piece as being an observer like peace as
opposed to another piece that would be a lovely thing to be able to do um I don't know how to do
that and in a sense in a sense that was what I was pushing you on but the difference between a
you know rock and a brain is is asking for that same kind of thing I think it is yet more difficult
in the case of the Rulliard just because it builds up everything and so you you kind of
you don't get so one of the things to understand and this relates to thinginess and mock-up
blankets and so on perhaps is this notion that is very critical to science as we have as we've
pursued science so far that you can have isolated things in the world that you can have an experiment
you do where you say this is an experiment it's on this thing and nothing else in the world affects
the thing I'm looking at that's a you know that notion of factorizability about the world is something
that I think and I think that's what you're going for with this kind of mock-up blanket idea if I'm
understanding correctly and that notion of factorizability I think in some fundamental sense what
the Rulliard tells us is there isn't ultimate factorizability there never will be the only question
is for the things that we choose to look at is there some effective theory that we can think of
as factorizable at least enough that we can have sort of definite thoughts without always being
affected by other things in that happen in the world and I you know I've well it's interesting
more to think about here I like your I think this notion of observers who kind of actively
pick for themselves the path of predictability I think is interesting I still feel like I need
to untangle that idea a little bit more I feel like there's a there's a bit more and you've
kind of indicated that you see there as being some tautological character to it I kind of feel like
it has a a I I would suspect that there is something which you are something interesting
which you're effectively taking as axiomatic about observers and perhaps perhaps that I mean in a sense
one of the things I'm trying to do right now is to think about what aspects of observers
are in fact there but we've always thought they were obvious in other words the idea
that there could be pure motion you know that's always seemed completely self-evident and obvious
but yet I think it's something one has to derive and so I'm sort of curious about as you
peel back you know what things are there about observers that have always seemed totally obvious
to us but in fact it might not be that way and and trying to understand that and that's
well that's kind of a yeah before you could have pure emotion I guess you even have to have a thing
that that's moving right and it sounds like in the context of the rule we add do we even have a
mechanism of identifying persistent things or not I mean is there well is yeah it's a bit
coarse right now I mean we can identify things like black holes because they have a very definite
structure in their causal graphs right to identify things like electrons is something we are not yet
able to do although I have a this very strong suspicion that which was even really highlighted
by this video that that we just made electrons and black holes are not that different I think
even though that's been a very popular idea for a long time right the the black hole electron
there's so many similarities between between and I think people have told me you know I'm
I'm remembering when I was like 15 years old or something maybe 14 years old something I went to
some talk by some well-known physicist and you know I sort of said they you know they were
talking about black holes and I was like is there something you know similar between electrons
and black holes and it was like no no no that's a completely silly idea you know you should forget
that idea there's so there's so much that's similar and then there's just a little bit that's off
right it's like not quite doesn't quite match well I think the thing that I really enjoy is the
concept of why is that why are all electrons why do they all seem the same and a black hole you
know your average black hole all the different black holes in the universe we imagine they were
made from the crushing of completely different stars but to the outside of the black hole they
look the same and so that leads one to the kind of amusing idea that all those electrons all those
10 to the 80th electrons that there are in our universe that seem to all be the same maybe actually
each of those individual electrons has sort of a crushed civilization inside it that's different
but to the outside of the electron they look the same and that's and now and now we have to start
talking about those to the you know those observers that live inside the crushed civilization
inside the electron how do they feel about sort of how do they how do they kind of
conduct their lives so to speak and are they like those those creatures we were talking about earlier
inside the initially moving spacecraft who are who are like having this whole you know they're
having a whole giant you know that they're giving lots of speeches all inside the electron but
nothing outside the electron can tell that there's that there's anything going on there
well so just real real last quick and Carl I'm sorry if you're taking the time here but for the
for the black holes which you can identify in the Ruliad are they able to experience pure emotion
well ha to observers who have certain characteristics they will appear to have pure
emotion but for example the knitting together one of the things that actually is pretty tricky
it was even tricky in making this video which is kind of an interesting thing
is in order to make the video we had to have we had to it took more effort to constrain the
observer than to work out the underlying dynamics in other words to to render the video required
aligning the sort of different pieces of space at different moments of time and keeping those
coherent and that took vastly more computational effort than it took to do the underlying dynamics
of what was going on and so that's that's kind of highlights the fact that you know we had to
make an assumption about the observer the observer thinks they're standing still the observer is not
zipping around all over the place the observer believes they're stuck they're persistent in
time and they're stuck in more or less the same place in space we didn't have that we wouldn't
be able to make a video that anybody recognizes even though the underlying connections and all
these hypergraphs are all absolutely correct we just wouldn't be able to see that so it's a so in
that sense you know we can say that to an observer with those characteristics yes black holes are
persistent things and and those characteristics by the way this is all reflected in in the in the
traditional treatment of general relativity there are it is you know the this business about aligning
things is if you don't do that even in standard numerical relativity you end up with all these
weird coordinate singularities that kind of that kind of shred your space so anyway that this is
so it's kind of fun that we get to see even in just we're trying to make a video it kind of
forces us to think about these scientific questions about what how observers work and how much effort
it is to be an observer how much effort it is to kind of successfully knit together you know these
these things that that sort of are happening underneath in the universe um well anyway this
has been i i have to run off here i i don't want to but i i'd love to go on and and chat some more
but i i see i'm actually two meetings late so i think i have to go back to my let me um keep maybe
just before we wrap up could you recapitulate some of what we were discussing earlier which is similar
to what you just said now and i don't want to say that you are an agency chauvinist but you
were just saying that there might be one particular way of demonstrating agency and earlier on you
were saying okay well we should look at the overall system and there is a distribution
of agency it's it's it has loci all over the system and you could draw a big boundary and say well that
things has agency but you could be much more efficient and you could draw a smaller boundary
and that smaller boundary would have almost all of the agency of the big boundary because most of
the things in the big boundary are just mimicking or stealing agency from things in the small boundary
so keith you were saying it's really important for us to encapsulate the most agency possible
which is to say the most amount of temporal planning in the smallest space yeah and so what
i had in mind there carl was just that imagine imagine i'm a pilot steering a ship okay and
as somebody looking from the outside looked at the ship they may decide that the ship as a whole
is an agent you know it's planning like obviously it's planning it navigated through you know the
suez canal and some locks and whatever else but but there's a smaller subsystem if we had the
ability to analyze this we could find a smaller subsystem which is the pilot you know this human
being who's sitting at the controls who's actually the the agent right and maybe you could shrink it
down a bit further and say it's really just all his brain that's everything inside of his skull
that's kind of doing the planning but then we realize that agency actually has the two sides
of the coin like it has the planning side of the coin which is only happening up in here but the
inaction side is perhaps different because if you're looking at the all the machinery necessary
to enact the plan it's the pilot's brain and the pilot's body and the ship itself and all its
components so I think you you know you can come up with a different boundary if you look at the
an active piece of agency versus the planning piece of agency but I think you do need to
on the planning side you need to at least shrink it down to that minimal
system that contains the the actual planning
