if you're a computationally bound observer you necessarily must compress even if your sensory
organs could perceive every every particle within you know your your your light light cone it still
wouldn't do you any good because you don't have the computational capacity to compute right you to
compute all that you only have a finite amount so therefore you almost necessarily have to do
something like the free energy principle because you've got to compress which implies uncertainty
and inaccuracy and therefore you need to balance out how accurate can i be with the with the amount
of computation that i can do you know with my resources but so there's a there's a little bit
of a difference here because you know you could imagine something where there's lots of randomness
which you just ignore for purposes of your sensory input but i think what's being said about this
free energy principle is that you're you're doing more than just ignoring it you are actively trying
to lead your life so as to minimize it which is a different thing i mean you could say we're going to
observe uh you know there's there's something happening in i don't know uh some
we're exposed to a cloud let's say we're exposed to all kinds of turbulence in the air
and we could say you know we're perfectly happy we're exposed to that but the only thing we're
going to pay attention to is something about how you know light travels through the air or something
but but you're saying that no actually we our way of leading our lives consistent with our
continued existence so to speak is avoid that turbulence go and you know go and you know
go and fly through sort of uh uh unturbulant still air so to speak so that we avoid the places
where we are going to be challenged by not knowing what's going to happen so i think you you're you're
going beyond just saying we sort of throw away uh we throw away information you're saying we actively
seek to build a world or to to organize ourselves to live in a world where where things are as
predictable as possible and and as we were saying i mean you know there might come a time when
sort of things become deeply unpredictable and where there isn't and i assume that that i don't
know whether it's included in your model but you know suddenly something very different happened
if suddenly you know the earth went near a black hole or something and all kinds of crazy things
started happening and we don't know what's going on there's presumably even the process of figuring
out what should we do is is one that could take us a while and i don't know whether that's accounted
for in your in your kind of model of things i mean to say we go to the the thing that minimizes our
surprise maximizes our predictability it still could be there could be a non-equilibrium phase
in which we don't even know it's very hard for us to work out what will be the most predictable
path so to speak radical uncertainty if you're an economist yeah absolutely uh you're bringing
again so many issues and four it's difficult to know what what to pick up on that sorry i'm sorry i'm
just i'm you're getting me to think you know this is you're getting me to do the thing that is uh
precisely seems to be moving away from the predictable path but please go on well it's more
fun yeah um but in fact let's just take that phrase moving away from the predictable path
because it's got moving in and i think that's quite crucial so you know one could um and i have to
confess i'm using the word observer deliberately to try and get you to talk about your notion of the
observer in the context of the rullian and generally i just say something so so a thing um
just exists but if a thing moves and this speaks exactly to what you were talking about before it
is more than just passively um assimilating sensory information sensory samples from the world
and compressing them in some good way as a good statistician would would do and then just forming
the right kind of coarse-grained model or compressed model as people like joker and smithoover would
it would would emphasize or uh indeed um you know the whole um formulation of efficient communication
in terms of minimum message length and minimum description length formulations you know the
the the kind of universal computation you get to from homograph complexity all of this is about
making sense of stuff from the outside coming in but of course when you're moving exactly as you say
you've now got the opportunity to decide what sensory information to go and gather or you can
change your perceived or modeled external states in order to deliver different kinds of information
and i think that's that's the twist that's what makes an observer an observer as opposed to just
you know a sessile object or a passive thing that is not able to actually change the course
can act back upon um use the word feedback and i think that's absolutely crucial so
there's a circular causality here there's certain kinds of things certain an observer i think a true
agential observer has the capacity to act upon the thing that's generating the data and it is in
in that acting that you get the curiosity and as you say ignoring and in fact actively avoiding
that noisy ambiguous potentially boundary destroying um dissipative um part of the universe
and sticking to those paths but in sticking to those paths because you can't see the paths as they
unfold deep into the universe all you have with the sensory impressions that are local
to your local interactions on your sense on your observe you know your measurement um
tools or your sensory receptors so you actually have to have a model of what might be going on
on where the path might be leading in order and of course that's where this resolution
uncertain the curiosity comes in that you're taking all the local cues to build a model of
where you think the path might be so that you can follow the path so to come right back to
your final thing what happens if we went too close to a black hole could we think our way out of it
i think we possibly could in a sort of science fiction sense simply because we've got the right
kinds of models of our lived world which is just the physics that you're talking about
but lots of other observers would not be able to do that unless they had that right
kind of internal model that implicit way of modelling the causes of all of my sensations
maybe maybe we should maybe we should address that point a little bit i mean the question of
what can be an observer i mean i think you were talking about thinginess so to speak
which is a lower bar probably than observance i mean thinginess might just be the ability to
maintain an independent object maintain something that we can consider to be a persistent object
i have to say i think that's a that's a complicated concept right there because
let's say we've got an eddy in a fluid for example is that a persistent object well it seems that way
to us but at the level of molecules it's not a persistent object at the level of molecules
it's different molecules making it up at every moment in time but like the great red spot on
jupiter same thing or the eternal flame or a hurricane all these quite annoying vague boundaries
right but i mean but it's only to a coarse-graining observer-measurer like us
that that thing seems persistent to it itself you know if that thing was if if we were molecules
we would say no it passed us right by it's it's no longer we're no longer part of that thing
so i mean i guess i'm i'm curious in um i mean so i claim thinginess is well i'm wondering to
what extent thinginess is the same as observance and you know to to identify something as a thing
it needs to be perceived as having certain persistence to whatever is observing it and also
i suspect it has to be bounded the the the sort of the amount of stuff in the thing has to be bounded
in other words if the thing is the whole universe you don't get to call it a thing it's only a thing
if it's of limited you know if it's a limited part of the whole so to speak
but i i guess i'm curious you have this point of view that two things i think that are implicit
one is that an observer-like thing has some kind of free will about what it can do
that is the the observer can by choice explore this versus that it's not a question of just
the vortex is moving through the fluid and the laws of motion make it do this or that thing
i mean and i think this is um so so you're attributing to the thing that you are treating
as an observer some degree of possibility of choice and although maybe maybe not maybe
you're saying that your free energy principle is essentially the deterministic physics of what
has to happen and even though the observer may feel that they have a choice they really ultimately
have no choice um because they're really being you know led by the nose so to speak by this free
energy principle to do what they do and even though they might imagine that they could do
something different they necessarily won't do something different i mean i'm curious what
you see as being i mean does does your notion of i mean are you saying that okay so so one point
of view would be that what you're describing is kind of a law of motion for for an observer
and that that law of motion despite the observer feeling that they can choose to do this or that
they really can't any more than you know an object moving inertially through space
can choose to do this or that so like like for example you've got a spacecraft and it's got all
kinds of critters inside it and they're running around and they're saying we got to do this and
that and the other but their spacecraft without any propulsion system is just going to keep going
in this inertial trajectory whatever they might you know they might run around and and have all
kinds of enthusiasm for things it might do but it's not going to do them any good um and so you
might take the point of view that that it's the same thing with our brains and i'm curious whether
whether you do take that point of view well i love that analogy with the you know the spacecraft
with lots of intelligent sentient critters but can't actually control where they're going
um i again you've picked up i think on some key points there um so i would say that to be an observer
is to have the kind of agency that you're implying by the count the choosing or selecting certain
actions to uh to commit to actions on the world that will elicit or solicit different kinds of
measurements that you can then use make sense use to make sense of your model of how um that you
know the world works and your place and the way that you couple to that world so i i'd agree absolutely
entirely that there's there is a bright line between just being a thing being that vortex or um
you know soliton or some something that just persists and um having the kind of agency that
allows you to plan and to make moves and i think planning although it's you're not um perhaps a very
intuitive way of describing it actually captures the notion that you actually spoke to which is
you know having a choice means that you have counterfactual beliefs in your model about
the consequences of your action i think that's quite crucial i think that introduces another
bright line between different kinds of things so there are things that just don't act you know
there's things possibly like the vortex or a stone things that can't um couple back and change their
environment and then there are things that can move back and change their environment and you could
argue this um massive bodies might might fall into this category by exerting um so gravitational
forces just open brackets i agree with you entirely things like space and time these are
fantasies or hypotheses that only come from this coarse grained observation of of the world um
but i think the key line between the kind of observer that you and i are and the kind of
observations that say a thermostat would do is exactly what you're talking about it's you know
imagining counterfactual futures are very simply articulated mathematically by just um
subsuming one's own actions under the inferred causes of your sensations so this slightly
paradoxically says well i can write down mathematically um this free energy functional
of a generative model or a joint distribution over causes and consequences the inside and
the outside oh sorry the other way around the outside and the inside and i i can for certain
kinds of uh systems or things um actually include the things actions in the causes so now you've got
this um mathematical image of from the inside of an observer um of an observer that has beliefs
about what it is doing which are completely separate from what is actually doing because
because it doesn't know what it's doing until it senses the consequences of what it has done
so i think this is this brings you to the you know a better description of things that plan
and it's at this point then you get this information seeking ambiguity avoiding you talked about
control in control theory all of these good behaviors just fall out of naturally the kinds
of behaviors that you would expect if you apply uh literally of the variational principle of least
action to um a a probability distribution over not just the external causes of what you're observing
but also your own cause your sort of um auto poetically expressed causes through through
your actual action and there they must be very special kinds of very very sparsely connected
things because they're unaware of their own action they can't sense their own action
so here's the thing that confuses me so i i i have the impression that you spent lots of your
career trying to understand what happens inside brains and in a sense you know presumably with
you know at some time in the future we'll be able to measure every significant feature of the kind
of neural firings that happen inside brains and i'm curious then when your point of view about
counterfactuals and planning and so on once we can see deterministically this neuron fired it
caused this neuron to fire and so on how does that relate to your distinction between the stone and
the brain then you would be looking for empirical evidence i should say that um there's a slight
22 here because if you just come back to the notion you were you were referring to earlier on
that there has to be some sort of finite bound on the number of degrees of freedom that constitute
the internal states of an observer as distinct from the the channels that are doing the observing or
the the control channels that are you know the outputs as it were that are um mediating the
action of of the observer in terms of gathering her data so you'd be looking for evidence that the
neuronal dynamics were um or the internal dynamics had um could plausibly be explained by a gradient
flow you know a dissipative flow on this sort of free energy landscape and you know what that
landscape is if you could find the right generative model or the joint probability distribution that
stands in for um the beliefs about implicit sub-personal mathematical beliefs um entailed
by the structure and the dynamics of the internal states so in a sense that's what I do as you know
of my day job um and indeed I suspect that's what we all do day to day in terms of trying to infer
the people's intentionality in states of mind you know which want to work out what under what
kind of structure or belief structure or generative model um is the you know are these
behaviors intentions um understandable if I can jump in because I've heard you talk about this
before in a slightly different way which is essentially as soon as you're performing a
computation that's modeling yourself you know as soon as you have inside your brain a humunculus
if you will that's that's able to watch a screen and entertain these counterfactual trajectories
that you could or may or may not take it's at that point once you have that counterfactual
depth I think you referred to both a counterfactual and temporal
depth to your computation that it's at that point that you have this agency or the ability to you
know choose choose actions is that fair yeah and certainly that would be necessary to be sort of
self-aware to have a minimal kind of selfness and to know that you are you are an agent as well
um but you could argue that that you could equip a thermostat with you know a very sophisticated
generative model of the consequences of turning the you know a heating element on or off um and
introduce into that model uncertainty sensitivity initial conditions or some kind of a stochastic
chaos and let it plan you can and indeed we do we build your sort of artifacts that do have
a certain sense of planning they wouldn't be no they wouldn't know they were agents but they
they would have a certain kind of agency that would elude any potential um proactive or
anticipatory dynamics that you might find in a stone so you're looking for um you're looking for
sort of um conservative dynamics you know divergence free dynamics that have a certain
kind of itinerancy um that you know normally expresses itself in terms of oscillations and life
cycles or you know respiratory cycles or you know and the like so you're looking for an itinerant
kind of dynamics that has the requisite variety you know deliberately using Ross Ashby's words
that has the internal degrees of freedom to be a good enough model of the controllable
aspects and the you know the the um the modeled world which is you know the internal the um
the stone or the uh the brain is actually using to act upon the world uh and plan to act upon the world
so I mean I think this is an important potential distinction but I think it's more complicated
than this is my my intuition so I mean let's take you know considering our venue here of machine
learning street talk let's talk about ai's um you know we've got you know we've got some artificial
neural net it's uh you know and then our lamb is a fairly simple has a fairly simple kind of
flow of information but imagine that we have some some neural net imagine that we have taken our
brains and you know we've been so successful at neuro imaging of some kind or whatever it is
that we can really pretty much map our brains onto the the bit patterns of artificial neural nets
now my question is I'm looking at this bit pattern and I'm asking myself does this bit pattern
have a model of itself and one of the things that I think is difficult in that is that any
universal computer is capable in some sense of having a model of itself because any universal
computer is capable of emulating any kind of computational device including in particular
the the very computer that is doing the emulating so I'm curious if if if you're presented with
you know the bit pattern comes from you know sophisticated imaging of brains or whatever
