ask a question, interrogate the world, perform an experiment on the world to do self-evidence.
If it's doing that, then it has to have a gerative model of the consequences of its moves.
So that's the simple and big move here, that just if you want to talk about sentient behavior,
you are necessarily, if you subscribe to the fact it's all, it all entails a gerative model.
Then you're talking about things that have generative models of the consequences of
their moves, their behaviors, their choices. Because those consequences are in the future,
they are necessarily acquired, that the gerative model necessarily acquires a temporal depth.
So just saying that I have an understanding or internal model with your psychology could be a
simulation model. If you're in motor control, it could be a sort of a forward model.
Most generally, just having a gerative model of the consequences of action means you've
got a very deep gerative model. And notice it's the consequences of your action. So there's an
implicit agency that suddenly comes into focus. So now you can use the word agent. As soon as
your gerative model contains the consequences of action, then you can use the word agent. You
can't do that. Could I just pick up on this a little bit? It sounds a lot like you're saying
it must be a closed loop process. And this rather leads back to, I know you were talking about
things like AIXI and some of the information theoretical conceptions of intelligence. And
those conceptions also rely on this notion of an agent acting in an environment. Does that seem
in any way, I don't know, it feels a bit anthropocentric, doesn't it? To use that notion of
consciousness or even intelligence. Is that a good framing? Yeah, well, I hadn't quite got to
consciousness at this stage, which will be certainly an anthropomorphic or centric notion.
But I think in a way that, if you like, celebrates the anthropomorphic aspect.
All I said at the moment is that if you want to talk about sentient behavior,
before you get to consciousness, you've got to have temporal depth. And crucially,
in having consequences, there can be more than one outcome to any act. So now you necessarily
have a counterpatrial aspect to the things in your gerative model, which brings us to my point
before about perhaps the best thing that David Charmans presents from my point of view is an
existence proof of a sentient creature that can have counterfactuals of a certain kind,
where it's not being able to have a qualitative experience. But this is an example of a
counterfactual hypothesis. This is a gift of very, very sophisticated systems that are probably a
long way down the path to ultimate simplicity in terms of evolution, or a very, very slow type
scale. So it's a real gift to be able to have these counterfactuals. Andy Clark would argue
that just qualitative experience is also another counterfactual. So there will be a grandmother
cell in your prefrontal cortex that fires when it says, Oh, I've had the qualitative experience
of seeing red. And it has to be like that in order for you to be able to be aware of it.
But using words like awareness now are indeed self-awareness. So qualitative experience,
first of all, underpins self-awareness, which would be a qualitative experience of self-hood.
So there are layers upon layers that you're talking about here. Each one of them has to be
manifest in the gerative model. So the first thing is that everything I've said so far,
in terms of agency, could be applied to a thermostat. So is a thermostat conscious?
Probably not. So what kind of system more complicated gerative model would you need to have
in place before you could think, Yes, possibly that could be conscious. Well, the first one is
a depth of planning. So thermostat just does not look beyond the trajectories implied by the
generalized motion. And that's the gradients that are at hand. You can't see half an hour to the
future. It just knows that things are going up or going down in the moment, a very short-term
sort of path, formulational generative model. But things like you and I can go and have much
greater temporal depth. And then we invert the notion of planning. And then I repeat,
selecting amongst a number of different counterfactual outcomes, evaluating them and choosing one,
you get into issues of free will at this stage. But still, you can imagine writing a robot,
writing, equipping a robot with these kinds of generative models that people have done this.
Would you call that such a no? Then you have to have the hypothesis that it's you doing that and
you in different states doing that. Then you have to say, well, why? Sorry, I'm rushing because I
can see your actresses before the excretion. I just wanted to make it. It's a very special kind
of generative model that even has selfhood, let alone aware that it just has selfhood. And even
more rare to actually have somebody who worries about these things and not having the selfhood.
This is fascinating. But you are a computationalist then. You do believe that humans are
independently conscious. So first of all, I think what you're saying, if you are a computationalist,
if we could recreate all of the stuff that you're just talking about, so forward reasoning and
planning, et cetera, that we could recreate consciousness in silico? Yes. I see no reason
why you couldn't create an artifact that was sufficiently similar to you and me that would
qualify as being conscious that I am. That's fascinating. Because the cyber net assists
typically think that it's an emergent property and computation is observer relative, so it
couldn't possibly exist in isolation. And then that leads on to assertions of panpsychism where
consciousness must therefore be in everything. Well, can I ask for a clarification? Because
I think I'm a computationalist as well. So suppose we did create in silico chip and some
software that had the depth of counterfactual planning, of temporal planning that could in
fact evaluate its own actions and could even evaluate at a meta level the computations that
are going into that evaluation. So that's sort of full stack, almost the full recursive stack there.
Would that thing, because a lot of times what I read from Chalmers or others is a question of
feeling, like what does it feel like to be conscious, right? And so would that thing,
in your view, feel like something? Would it have the qualia of experience that we do?
Yes. But you'd have to write it into the genetic model. So you'd actually have to write
the different feeling states as hypotheses about how am I feeling at the moment? And then it would
use or I would use or you would use all the messages and the belief updating and all the
planning and all the estimates of uncertainty that attend that planning. And that's quite key,
actually. The precision or the estimates of uncertainty start to take much, much greater
roles in terms of the heavy lifting of the belief updating the higher you get in the hierarchy.
So I am feeling in this way. I am aware of myself. I am having this quality of experience.
These would all be hypotheses that were recognized in a good old fashioned variation autoencoder way
of everything that's going on below, crucially including interceptive feelings of states of
your battery or blood sugar and all of that good stuff. Okay. So I think if I understand you
correctly, and this is pretty cool. So the feeling is actually a knowledge of
a certain activity or trajectory. That is the feeling is, in fact, a knowledge.
Absolutely. Well, you could even say that the instance of the feeling, the realization of
the feeling is the inference in the context of a knowledge structure that just is the
gerative model that has representations or slots that have a semantics of I feel like a self,
I feel unhappy, I feel anxious, I feel enough, whatever it is. There is the best sense making,
the best hypothesis or explanation in a simple but not too simple way for everything that's
going on. So feelings, including things like pain, and this is quite an important, so this is not
just a philosophical nicety, it really matters in the treatment of chronic pain when you're trying
to identify the locus of pain and what is pain. It seems as if pain is a hypothesis that certain
people bring to the table as a best explanation for all of their interceptive interceptive feelings.
Fascinating. I want to bring in this subject of subjectivity, because when we do try and
formalize things, I know Keith is smiling because we were just speaking with Kenneth Stanley,
and he has a wonderful book called Why Greatness Cannot Be Planned and The Myth of the Objective.
He thinks that formalizing things actually blocks us from discovering interesting stepping stones
in life, and even in the frame of our thinking, it actually stops us from discovering new
interesting knowledge. And this is interesting in your formalism. So there is a chap called Arthur
Eddington, the notorious astronomer and physicist born in the 19th century, and he spoke about
subjectivity and science. And I think his point was that science only tells us a sliver
of what's really happening in the world around us, and we should be a lot less arrogant in our
claims to understand it. And Kenneth Stanley says that we've been too focused on objectives,
and the broader story is that he thinks society and institutions are scared of any subjectivity,
or perhaps you might think of it as system one thinking, so we always try to verbalize
and understand everything. But similarly to what you were just saying about in respect of agents
and the conscious experience and subjectivity, it doesn't feel very objective anymore when
you're talking about emotions. Yes, sorry. The mention of Arthur Eddington was very pressing for
me. So that's how I got started this game with his book, Space-Diving Gravitation,
my father made me read some of that. Oh, wonderful. You know what's fascinating about that? I got
started in philosophy because I read his book, The Philosophy of Physical Science.
If only he knew, his family would be very proud of the impact that he's had on our
a century-new. It is now and always a century-new. Absolutely. But do you think there's a bit of
an interesting contradiction there in yourself that as scientists, we struggle to formalize
everything? You can't even get funding for a grant unless you have a clear hypothesis and a
clear understanding of what you're doing, and your papers have no value unless you have a clear
formalism of what's going on. That was the spirit of the argument, which I certainly
concur with. So I don't see any real debate or dialectic here. I mean, this is simply a problem
that we were talking about before in terms of the good scientist being able to build an apt
hypothesis space where no one else has ever gone before, and then do your self-evidence or
evidence-based science. But clearly the problem of building that hypothesis space,
that, to my mind, is unresolved in the physical sciences. Scoring any particular
hypothesis, absolutely no problem. That's just estimating the marginal likelihood of the model
evidence or some variational bound on it. It can be as difficult a hypothesis space as you want
to consider, but building it in the first place, I think that is the outstanding problem,
both practically and philosophically. And you have to ask, are there any examples where it's
been solved? Well, yes, natural selection solved it. So it's used a particular way of exploring
in a structured way using, but say, bisexual reproduction. And that sort of gives you clues
as to how you might create, and I literally do lateral thinking or inventive thinking,
having ideas and hypotheses that no one has ever had before. So I think that that question,
if I read it properly, just speaks to a really challenging, exciting and practical challenge,
not just for science, but people trying to build sentient artifacts that now have, in a
principal way, the ability to actually have new ideas and to test these new ideas. And I should
just add that one example of these new ideas is that I am a person and I'm happy or in pain.
This is not, I don't think they're typically magical about the kind of constructs we talk about
in philosophy of selfhood and consciousness and self-awareness. And the psychophysics of visual
perception is just having these new kinds of hypotheses, perhaps they're not so new in terms
of selfhood because of the cultureism that we're talking about and the fact that
mum talks about me and it's a very viable hypothesis that explains a lot and actually makes my
data foraging or my epistemic foraging much more efficient. Just to simplify the world,
oh, I am a person, a mum is a person, there are two selves. That hypothesis perfectly fit for
purpose, maybe completely rubbish, I don't know, but it's a hypothesis that seems to work really
well. And when you generalize it, oh, there are other persons of itself, I seem to be the universe
populated by selves. This is a hypothesis, which is reaffirmed through gathering the right kind
of evidence through communication, afforded of course by language and other aspects of a
cultural evolutionary psychology that, again, speak to the sort of separation of temple
scales. But quite within this, quite naturally, selfhood arises. And one could argue, philosophers
also will flourish and we can have conversations about the hard problem, the meta-hard problem,
as you will do. But it all rests upon, at some level, at the highest level, new hypotheses,
simpler, better hypotheses being tested by some artifact or some Markov plug-kits.
The thing that fascinates me though is that with the FEP formalism, you were saying before about
self-evidencing and finding our eco-niche. And when we do talk about, well, when we introduce
subjectivity, it doesn't feel, it feels much more divergent and much more random. And that's what
Kenneth Stanley says, he says that any formalism is convergent. And in order to be divergent, we
need to embrace subjectivity. And it feels like emotions are the human form of subjectivity. So
that kind of, in my mind, that makes this process feel much more random and divergent than perhaps
the formalism would make us think. Again, I can't quite get a sense of a dialect. I don't know who
disagree with that. It certainly is the case that finding your place, and we actually demonstrate
this in silico, using cells that differentiate, finding your place under a shared narrative or
gerative model amongst a population is a free energy minimizing solution. And it necessarily
leverages or relies upon subject-specific realizations that are contextualized by what
the realizations in other subject has. So you can certainly argue that that subjectivity,
that subject-specific expression of your sense-making, active sense-making, is a necessary
part of the minimization of the joint free energy of a number of free energy-minimizing systems.
Even to the extent, I mean, this is basically the Holy Grail and taken as red in things like
computational psychiatry. So if you want to use, let's say the active inference process theory
to understand and phenotype people who might or may not have schizophrenia-formed symptoms,
or may or may not show addictive behaviors, or have this kind of autistic expression,
then what you can do is you can use the complete classroom to say, well, look,
in this game that I go to give you, the complete classroom tells me that your behavior will be
base-optable, whatever you choose, under some prize. And what I want to know is, what are your
prize? So that means for every person, every subject, there is a unique set of prize that
characterize their behavior under ideal-based assumptions that can be read as active inference.
So the job now is to try and identify what are these, what are this person's prize,
and then use that to test hypotheses that you're this kind of person or that kind of person,
so try to find some systematic structure in the belief structures that each subject brings
to the table. Yeah, before we run out of time, I do want to ask you the perennial free will
question. So I think, and correct me if I'm wrong, but I think you believe in a universe
that's unfolding according to these deterministic, albeit stochastic, but deterministic flow
equations, differential equations. And so the universe is deterministic from that perspective.
And so is that correct? Would you agree with that?
Sorry, just technically, you have random fluctuations in a random dynamical system,
so you don't get deterministic cares, but you certainly get stochastic cares, absolutely.
And just interestingly, it is becoming clearer that things like you and me may well have
particular flows that are almost deterministic, even if the outside is a bit random. Sure.
Yeah, and I would even say it's entirely possible that those stochastic fluctuations
are themselves highly chaotic deterministic systems, or even if they are pure chance,
they're of the form of a chance that's not controllable. It's just sort of this
truly random chance. And so in that context, a lot of folks have a lot of trouble imagining
how we can have quote unquote, free will. From my perspective, free will is simply that an agent
evaluates a set of inputs and sensory things and has an algorithm that then determines what actions
it's going to take based upon that. And if you had put in different sensory inputs,
it might have chosen a different pathway. I'm talking about sort of degrees of freedom,
if you will, as free will, almost the same kind of concept I believe that Daniel Dennett espouses.
So I'm curious how you see free will in the context of a universe unfolding either purely
deterministically or deterministically with stochastic variation.
I think I see almost exactly the way that you expressed there. Just to make the point that
the fast stochastic fluctuations, of course, can also be just expressed at a faster timescale
using the renormalization groups. You don't even have to say, I'm committed to stochastic as opposed
to a deterministic chaos with a correlation dimension greater than 10, for example. You don't
even have to do that once you allow for the separation of temporal scales. So you can talk
about a universe that is no longer Markovian because of the separation of temporal scales,
