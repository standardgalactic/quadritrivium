thickness, and in this particular construction, we are defining thickness in terms of sparse
influences that underwrite conditional dependencies. So the zero elements that you
were talking about that are absolutely crucial in defining the thing in a crisp and unabiguous way
via conditional dependencies, just technically for those people who are thinking in these terms,
and zero entries in the Hessian of the system when the Hessian is the curvature or the second order
derivative of the likelihood, effectively. And then the big question comes then,
where do these zero entries come in that define stipulatively thickness in terms of conditional
independence? If it was the case that you could not establish conditional independence between
the inside of something and the outside of something, then there is no way of really separating the
states that are inside and outside. So the game then and the delicate game and the one
that has been receiving attention in the last few years in the purely academic philosophical
literature, but also in the maths literature, is exactly this question. How does sparse
dynamical coupling, mainly, I can't actually influence you because you two are too far away
or you don't have the right kinds of receptors. How does that translate into these zero entries?
And then your question is, well, okay, do we have to commit to exactly zero? Can we actually now
have a little bit of wandering away from these hard constraints? Now, mathematically, I wouldn't
want to do that because, as you say, it's much more convenient just to sort of identify zero
entries in the Hessian and implicit conditional dependencies under some sparse coupling. So what
I would say, I've got two levels to the answer. First of all, the zero, the absence of any
conditional or the presence of a conditional independence is not a terribly restrictive
or magical requirement in the sense that it is just a reflection of sparse coupling. So I think
that you would put the question really not to the dependencies and the Hessian, but really
to the notion of an influence diagram that was predicated on a set of differential equations
you thought was appropriate to describe this universe. Now, if you think universes have all
to all influences, so every state of this universe come in a dynamical sense, simply the sense of
a large run equation or a random dynamical system influence every other system, then you will have
a soup and you will have may have interesting structure with it, but that structure will
not pertain to anything that can be separated from the universe because everything's connected
to everything else. So you start asking, well, can I just can I jump in here because I think
to a degree, much of the universe and just kind of leaving aside, okay, I'm sure there are some,
horizons at which locality, locality horizons, whatever, but I think that on the scales of,
say, human beings, we are in a soup. I mean, we are influenced. It's just those influences may be
very, very small, almost epsilon in a sense. And that's what kind of worried me about it is that,
look, I think I know that at least in terms of physics, there is this soupy influencing of
everything kind of on everything else. And so what happens if we're dealing instead with mathematics
that has these sharp zero boundaries? Is it going to be an accurate reflection of the more
soupy, albeit still exponentially decaying couplings? Perhaps I should just ask you,
I mean, certainly it is the case with six degrees of separation, that there is a
vicarious influence that, you know, will all certainly be nonzero. But did you mean that
those vicarious influences, because for me, of course, the whole notion of a vicarious influence
through something else immediately invokes the notion of something, which means another mark
of blackhead. So certainly there can be indirect influences. And I'm not denying that. I'm just
in terms of the physical, and that's probably a bad word to use, but just in terms of the functional
form of the differential equations, that will evict this vicarious all to all coupling
by other states. Do you think that most universes are sparse or not sparse? So the assumption
is here that it is the sparsity that it dows this retodontical system with structure. And in fact,
the exception is a non-sparse connection. And then the question is, how do you get
soupy, mutual influence amongst all the constituents or states that constitute
that retodontical system? So, you know, if you didn't have that kind of sparsity, you would never
have a hierarchical organization in the sense that a hierarchy just is the lack of an influence that
transcends more than one level, say, the subsumption hierarchy in physics.
Well, let me, before I forget, the other half of your argument is much more accommodating of the
epsilon and the fuzziness, which brings us to some of the notion of wandering sets. And back
to and back to the notion of separation of temple scale. So how long is it nearly zero?
Almost zero. And acknowledging that at some point, it's good to be not zero again, because
things change. So that I've sort of jumped to the second half of the argument, but I've
interested to try and bring the really important, from my perspective, notion of sparsity back into
focus and saying that it is not unremarkable to assume lots of zeros in influence, because we
do that all the time when we write down any differential equations, just by emitting one
variable in a state vector from the function that defines the equation, the motion, the flow operator.
As soon as you emit one of a universe of variables, you've introduced a zero
in that sparsity, in that dynamical coupling. Maybe this is really the heart of abstraction,
which is, even if there are these very tiny, soupy couplings, we can abstract. We can just treat
those all zero, eliminate them. And still that abstracted model reflects emergent behaviors
of the things, if you will, of the universe, really, that we're trying to model. And I think
that's kind of this duality between the fact that we may have a soupy substrate, and yet still
discrete sparse behaviors emerge on top of that soupy substrate. It's probably one of the greatest
mysteries for me. So I don't know the answer, but I just wanted to get your thoughts on it.
Well, I think that's a very important question. I've seen it asked, interestingly enough,
in correspondence with people who are sort of trying to look at the origins of life,
and I try to understand the emergence of biotic self-organization from many different
perspectives, from the kind of approach that people like Kate Jeffries or Jenny England might take
right through to theoreticians, try to reproduce organic self-organization by reproducing the
vents at the bottom of the sea, primordial soups in structured containers afforded by these vent.
One thing which struck me in these arguments was the notion of emergent behavior that had this
self-replicating aspect to it from a dynamical systems perspective. The emergence of attractors
that have a Poincar√© section, you get sort of a cycle of life emerging, was the notion of shielding,
the notion of protecting yourself from the influence of other things.
You know, as a way of understanding enzymes, for example, or ways of understanding the physical
structures that lead to sort of cell-like formations, that notion of shielding comes back to the
possibility that it is the emergence of sparsity and the construction and the self-construction
and the auto-poesis of sparsity, that underwrites a Markov black building system that is necessary
for the kind of structured self-organization that you're asking the question about. So literally,
how do we move from a primordial soup to a set of discernible things? And the answer seems to be
from what I'd read. It's the emergence of certain auto-catalytic structures to actually sequester
and shield certain sort of chemicals or processes from other chemicals that are in the shielding
thereby emerge the, from my point of view, the Markov blankets. So again, we come back to
the notion of sculpting structure by removing stuff. In this instance, it's removing connections,
creating the right kind of sparsity where structure actually emerges from the soup.
Point of interest, Cole. Could you define, I'm really interested in your definition of
self-organization and emergence. And also, do you think it's a useful distinction to have this
notion of strong emergence and weak emergence? Could you just give us your take on that?
I could if I was more of a scholar, but I'm going to have to ask you to define strong
emergence. Well, it's all about reducibility. So I mean, I think weak emergence is a kind of
emergence where the emergent property is amenable to computer simulation or similar forms
of after-the-fact analysis. So like, you know, the formation of a traffic jam. And strong emergence
is this notion that the whole is something more than the sum of its parts. I mean, I was actually
going to ask you a slightly related question about substance dualism, right? Which is that,
you know, some philosophers have this notion of the mind not being reducible to its component
parts. So a materialist, for example, or a physicalist would think that. Do you think
there's a kind of parallel with this notion of strong emergence and the irreducibility of our
mind and consciousness to the constituent components? Right. You're clearly more versed in these
fields than I am. So I'm not going to pretend to give you... I highly doubt it, Karl.
In this instance, you know a little more than I do. However, I get a sense if you wanted to
proper answer that question, I think it would probably come back to this separation of temple
scales and posing that question to the kinds of systems that would constitute a renormalization
group and say, is there anything that emerges at one level that could be abstracted from the
level below? And, you know, if you could find an answer that satisfies you in terms of the
difference between strong and weak emergence by looking at a system that has that renormalization
property with the separation of temple scales, then I can tell you what the answer is. Unfortunately,
I don't know because I'm not sure what the commitments of strong and weak emergence are,
but certainly it would be impossible to understand one temple scale or one level
without writing down or simulating or understanding the level above and the level below. So in that
sense, I suspect there might be a strong emergence in here. The reason I mentioned that is that, of
course, is the get-out and it's the mechanics that you would appeal to to resolve the sparsity or
the Hessian equals zero problem. So it's clearly the case that even in a soup or a soup that
transiently or a collection of well-defined cells where there is this shielding and sparsity of
influence that protects or insulates the internal dynamics of, say, a cell from the external
milliard, at some point there's going to be cell division, at some point there could be some
metamorphosis or transformation or phase transition where it is rendered soupy again,
and you would need a different set of Markov blankets. So how do you go from one cell to two
cells? So you've got this notion now of wandering sets. So the Markov blanket partition was nicely
described into as a partition into internal and external and the intervening active and sensory
states that mediate the bi-directional influence of the outside and the outside. That partition
comprises a subset. So what you're talking now is about the possibility of wandering sets in the
sense of Birkhoff. How on earth can a set wander where it is defined stipulatively in terms of
sparse coupling expressed as a random differential equation or a Langevan equation? Well, it can
change if you say, well, this set of equations of motion is only in play for this amount of time
and then the next jump. We're going to change the parameters of the equation of the motion
and bring it other states. And as soon as you bring it other states into your flow operators
at a slow time scale, you're now destroying the old sparsity structure and replacing it with a
new sparse structure or possibly destroying the sparse structure altogether. So I think that
that would be the way that you put put epsilon back into the game. But actually more than epsilon
actually allowing for the fact that there is a certain scale of organization in space and time
that is superordinary to the microscopic dynamics of your level of inquiry over which
you will now have a reconfiguration of the Markov-Blanket. So things will look as if they're
reorganizing. So at what level is self-organization happening? You can't answer that question. He
said all levels because the context of self-organization at one spatial temporal scale
depends sensitively and critically on the parameters that define the initial conditions
and the flow operators that are inherited from the scale above. And likewise, the scale above
has to conform to exactly the same dynamics. It has to have things in it.
Fascinating. So I think that's how you would get out of the
getting to a more plastic semi-Markovian universe, a biological universe. You'd start to answer the
real questions of orthopoiesis. I feel a little bit naive in saying that the free energy principle
does orthopoiesis in retrospect because orthopoiesis has a lot more to it and is exactly what you've
been talking about. How do you get these self-preserving? How do the fast microscopic dynamics
create the context for there to be a self-assembled Markov-Blanket that entails the faster? These
are really deep questions. Indeed. It's another example. We've spoken to cyber-netesists like
Professor J. Mark Bishop and he introduced us to lots of stuff about orthopoiesis.
I've just got a bit of an eye on the time, so we've got a couple more questions to get through.
But that was absolutely fascinating, Professor Friston. But I'm not sure if you're familiar
with Ilya Sudskever. He's the chief scientist at OpenAI and he became embroiled in a heated
Twitter debate a couple of weeks ago where he asserted that large language models, the likes
of GPT-3, might be slightly conscious. And of course, I'm speaking to an authority on consciousness
here. When you spoke about consciousness actually recently, you said, and I'm quoting,
the proposal on offer here is that the mind comes into being when self-evidencing has a temporal
thickness or counterfactual depth, which grounds inferences about the consequences of my action.
In this view, consciousness is nothing more than inference about my future, namely these
self-evidencing consequences of what I do. I think this is a fascinating way to put it.
And Keith told me earlier that he thinks of consciousness in a very similar way.
But the one thing that is missing from this discussion, in my view, and by the way, we're
speaking with good old David Chalmers in a few weeks' time. But what about the phenomenological
characteristics of consciousness? Right, so we've got a couple of minutes to do that. That'll be
fine. Would you get David to watch this? Give him my very best wishes. Oh, we certainly will.
And by the way, if you have any questions as well for us to ask David on your behalf,
I think that'd be very, very exciting. Well, you should ask him everything you've
just asked me and see what he says. I love David Chalmers, and I also like the way he responds
to some of the more technical questions that he gets. And his response to this one,
I think, would probably loop in the notion of the meta-problem or the meta-hard problem,
which put simply in the words of Andy Clark would be, why is it that certain things,
i.e. philosophers and people like you and me, huzzle so much about our qualitative experience?
And it may sound a strange question, but it's a very revealing question. It simply means that
if you subscribe to the notion that we are inference machines, we are built to actively
self-evidence, then you are saying that we entail a gerative model of our experienced world.
And if we have a gerative model of our experienced world and we can talk about and
puzzle about qualitative experience, we must also have a hypothesis that, first of all,
we are things. Second, we are having a qualitative experience with the alternate that we are not.
Which, of course, then provides a really simple explanation as to why philosophers
love things like brain and vats and the zombie arguments, irrespective of whether they are
useful thoughts. The very fact that you can get some like David Chalmers as a young man,
talking about zombies, or people listening, tells you immediately you've come across a
certain sentient artifact on Earth that has got a gerative model that can entertain the counterfactual
hypothesis that they don't have qualitative experience. Now, you may be asking, well,
why is that so interesting? Well, it's interesting because it tells you immediately that these kinds
of sentient creatures are showing a sentient behavior that necessarily requires the ability
to hold counterfactuals in mind. And I mean, so now I'm trying to work back to your introduction
of the nation of the temporal depth and something that Neil Seth might also complement with
counterfactual richness. So the argument here is very, very simple, which I'm sure you know,
but probably worth rehearsing. So if you had a program that could understand language,
then what would be the requirements of the underlying gerative model that it was using
to infer the, to make sense of the auditory stream to infer the meant word? Well, for it to be
conscious, it would actually have to be able to ask questions. So we'd also have to be able to speak.
So, you know, that's the first inactive move that you see with the triple E since the turn
of the century. So we're talking about systems that are not just sentient in a passive sessile
way, but have sentient behavior. So there has to be behavior. So your language understanding
machine has to be able to do something. It has to be able to move or ask a question. And of course,
then you ask, well, what are the best questions? Well, those are the ones that comply with the
principles of optimum Bayesian design. And then you can trace that right back to things like,
or from my point of view, articulate that as a special wall part of expected free energy.
But the key thing here is that the program, the scheme, the algorithm has to be able to move,
