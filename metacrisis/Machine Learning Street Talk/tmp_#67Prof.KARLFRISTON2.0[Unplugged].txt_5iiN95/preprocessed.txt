in this episode of Street Talk Unplugged.
So the free energy principle
originally emerged from systems neuroscience
as a way, a principled way,
of understanding what the brain does and how it does it.
Subsequently, the principles proved to be so simple
and so powerful that they've been applied
in a variety of contexts now.
So one could almost regard the free energy principle
as an organizing principle for any living system
that shows the characteristics of life.
In this episode, we'll be doing a bit of epistemic foraging
with Professor Carl Friston, legendary neuroscientist
and inventor of the free energy principle.
The basic idea is that our brains are in the game
of predicting sensory inputs to try and infer the causes
that generate sensations and to work out states of the world
so that we can respond adaptively.
Now, long ago in my own personal epistemic journey,
I learned an important truth,
that simple and easy are not the same thing.
Our shared human journey is filled with examples
of simple ideas that were nonetheless hard to discover
and some that even once explained remain hard to comprehend.
Their subtle simplicity belies their far-reaching
and deep consequences.
Examples might include the principle of relativity,
quantum mechanics, the principle of parsimony and entropy.
I think the free energy principle is another example.
Profound and far-reaching, yet belied by its simplicity,
it has on the one hand been dismissed as a triviality
or even a tautology and on the other,
hailed as revolutionary and everything in between.
It has the potential to reshape how we view the connection
between inanimate matter and the living things
and even to answer the question of how and why consciousness
and intelligence might emerge from physical matter and processes.
There are, of course, newer attempts to explain the free energy principle
such as Carl's own recent paper called
The Free Energy Principle Made Simpler but Not Too Simple.
The paper develops by starting from a world modeled
as a stochastic differential equation.
Now, leaving aside the technical jargon, that means a world where all things
from particles to people to the largest systems
all move or evolve according to two processes which combine.
The first is a smooth-flowing evolution.
Think of planets orbiting a star or waves
rippling over water or through quantum fields.
The second is a random process that knocks around the smooth flow
in unpredictable ways. Think of twinkling stars or
audio static. You might think of these two processes as a kind of order
and chaos or yin and yang forever intertwined and enmeshed.
These two very different effects combine into a chaotic flow
which may be entangled in a kind of tropical storm
while still maintaining a semblance of structure and things.
Think about raindrops undulating down to earth
in a state of constant flux yet still droplets or a human being
growing and adapting to the surprises of life
all the while remaining an individual physical entity.
Biology often asks the question, what must things do
in order to exist? Professor Friston has turned that question on its head
and developed perhaps the ultimate existential formalism.
He asks, if things exist, what must they do?
From the foundation of stochastic differential equations,
Friston demonstrates that things which are defined by a Markov blanket
must always move towards a pullback attractor.
A special set of attracting states which maintains the integrity of the Markov
blanket and therefore a thing's coherence
and identity over time. One of the profound consequences of this
is that the dynamics of such a system, its laws of motion,
will manifest a form of flow dynamics which can be interpreted
as Bayesian active inference. In other words, such a thing maintains
an internal equivalent of a generative model
encoding beliefs about the world and itself. The thing
uses the model to decide actions and then performs a Bayesian update
based on the outcomes. For me, the idea that inference,
something widely perceived as purely abstract or mathematical,
the idea that it can be driven by simple laws of motion
dynamically maintaining the boundaries between things,
maintaining order in the face of chaos is frankly astonishing.
What's more, the free energy principle is so general
that it applies at all scales of size and time, leading to an ecosystem of
things interacting across scales. Perhaps in that multi-scale
active inference, we might finally find the keys
to a mathematics of emergence and consciousness.
So, it's so good to see you. It's been what, about a year since
our show and I've been looking forward to chatting with you.
It doesn't seem like a year. Yes, I suppose it has two days.
Yeah, it's been almost about a year actually, a little bit longer.
Time goes very quickly during the coronavirus.
Are you all back up to normal now or still
restricted? Kind of not back up to normal, still some
restrictions and they change very often and
it's a bit confusing but it's more normal than it was, I'll say that.
That's an interesting concept, right?
By the way, I just listened to your Kurt's Theory of Everything podcast.
Was that the four hour one? There was a very long one.
I think it was at least three hours. It was the one where at the end you were
talking about derealisation and depersonalisation and
getting into psychology. Well, almost psychotherapy if I remember
correctly. Yes, psychotherapy, that's a better way to put it.
Quite often, because we do say this about you, Carl, that
you have a burden of knowledge. We mean this in the nicest possible way.
You always know five synonyms for a word in every single
domain of science. You even have a background in
psychotherapy, so it does create a tendency for conversations to
potentially go anywhere. When we listened to Kurt's interview of you
last time, I was really surprised because we
prepared a lot for our session with you, Carl.
Kurt was asking some really open-ended questions that were
on the surface quite naive questions, but they elicited
the most interesting responses from you. It really made us rethink a little bit
how we do everything on our podcast. I suspect that parts of that
free-ranging beauty was a fact. There was no hard limit of the time.
I have no idea. Three hours, but he was a very engaging
young man. I think part of that open-endedness was
deliberate. He was indulging a bit of epistemic foraging.
Well, it's funny you say that because that's the free energy principle in a
nutshell, isn't it? We need to balance the entropy.
Back to this burden of knowledge, because I want to ask you
a little bit about that. I find this is often the case.
Say, for example, a kid comes and shows you a test that they're taking,
and there's a math question on there. When I was their age, I could have
answered it quite easily, but as I learned more about mathematics and
engineering, now I look at the question and I'm sitting there thinking,
yeah, but there's all these assumptions. How do you know this variable is
positive? Maybe it's negative. It could be a real
number. You have all this extra knowledge that's
entering in and impinging, if you will, on the ability to answer that
question. I think a lot of times when you're asked
a deep question, I'm imagining because your depth of
knowledge and breadth of knowledge is so large, you're sitting here thinking,
okay, how can I answer this in a way that's precise
and accurate? Therefore, it requires the use of
technical and accurate and precise terms, but then for the person hearing
that answer, they may not have the requisite knowledge
of those terms, and so it seems as if it's coming across as
obscure or something. Do you run into that often?
Yeah, well, I think we all do, don't we? Looking across disciplines,
you've got to find the narrative that works.
In a sense, if you're taking a re-energy principle approach to this,
you try to establish some kind of generalized synchrony,
so that mind-out-it becomes your narrative, but that mutual understanding
does require a commitment to the same rhetoric, the same calculus.
So you'll often pick up a lot of theory of mind or perspective-taking.
To the extent sometimes you have to sacrifice a degree of precision,
if I wanted to articulate something that I know I could simulate or write down
mathematically, it would just take the kind of
language which was not part of the portfolio the person I was talking to
to go through properly. So you just have to take shortcuts,
heuristics, and the like, which is part of the art.
Back to Einstein, keep everything as simple but as possible, but not too
simple. Well, in a bit, we're going to ask you
about your most recent paper that literally has that title,
almost the free energy principle made simpler, but not too simple. So we're
going to ask you about that later. Indeed, we are.
And it's interesting what you say, Carl, because you're talking about things
which are so alien. It might seem that you're pointing out
the obvious when you talk about self-evidencing or when you talk about
the basics of probability theory. But Keith and I often remark that a lot of
people just don't understand probability theory, a lot of very smart people.
And it might seem that we're reducing it down to the most basic
principles, but they just can't be articulated very clearly.
Yes, and people like me sort of lose sight of that. There are some basics you
assume people do know because it takes years before
you're fluent and have all the right intuitions.
So I think, in part, is an explanation for why people like me
sort of cast as being imperishable or very difficult to understand where
it's not. But it probably reflects, again, a lack of theory of
mind in terms of being able to understand what people
do know and don't know. Wonderful. Well, I'm going to officially
introduce you, Cole. Professor Friston is a British neuroscientist
at University College London and an authority on brain imaging.
In 2016, he was ranked the most influential neuroscientist on Semantic
Scholar. He pioneered and developed the single most
powerful technique for analyzing the results of brain imaging studies,
and he's currently a Wellcome Trust Principal Fellow and Scientific
Director of the Wellcome Trust Center for Neuroimaging.
His main contribution to theoretical neurobiology
is the free energy principle and its Bayesian reinforcement learning
flavor, active inference. The free energy principle
is a formal statement that the existential imperative of any system
which survives in the changing world can be cast as an
inference problem, the probability of existing
as the evidence that you exist, if you will. This is what Carl refers to as
self-evidencing or even autopiosis. Now, the system, of course, could exist
at any scale or time, and as you might well imagine, this will
lead us directly into a discussion on complex systems theory,
self-organization and emergence. Anyway, Professor Friston,
it's an absolute honor to have you back on the show. Welcome.
Thank you very much. It's great to be back talking to you again.
And incidentally, a great summary of the free energy principle.
Was that from Wikipedia or something slightly more learned?
Well, we like to interpolate from multiple sources, Carl.
Yeah. If we can just jump back actually
to what we were talking about with things that are simple,
that may still be hard to understand. If I may, I want to
share an anecdote with you. And this is really, this came to
mind when I was reading a recent paper, the free energy principle made
simpler, but not too simple. And the first
line of the introduction says, it is said that the free energy
principle is difficult to understand. This is ironic on three counts.
First, the free energy principle is so simple
that it is almost tautological. And what occurred to me there was
one of the most valuable life lessons I got in graduate school
was I was in a cryptography and cryptanalysis class.
And it was being taught by Professor Silvio McCauley.
And he's since gone on to quite some fame in the crypto
cryptographic space. And the first day of the course, okay, he puts a secure
communication problem on the board, the very first thing that he does on that
day, puts a secure communication. These are kind of like brain teasers in a way.
You have to come up with a way to solve this problem.
And he goes, okay, does anybody know how to do this?
Somebody raises their hand and gives them an idea. And he goes, no, that won't
work. Here's why. And he shows how to crack that.
A couple minutes later, another student, how about this?
Two random numbers communicate. No, that won't work either. Here's how to crack
that, right? And so after about five or six
attempts from the class, maybe 15 or 20 minutes, nobody could solve it.
And he goes, okay, this is the perfect place to begin this course.
Because I'm going to show you the answer. And when I do, it's going to be so simple
that you're going to say, huh, that's easy. No, something that's easy is easy from
the beginning. If somebody has to tell you the answer, it's only simple, right?
And I think, you know, human history is just full of examples of ideas that are
very, very simple, yet took, you know, the combined intelligence of humanity thousands
of years to discover, they may be very simple ideas, but they're still very
difficult to kind of grok to really internalize and
understand. And I think we have those all over science and the free energy
principle may well be one of those. So even though it may be very simple, it
could be difficult to kind of cognitively
grasp. But I almost, I'm almost starting to think over the last year or so that
human cognition itself, like in the cognitive space, there's
sort of this Markov boundary between an external world of ideas and internal.
And there's a fluctuation there at the boundary where sometimes
the most advanced ideas, they may creep into what's in our sensory range and we
can just grasp them, but then they kind of fly out again.
And they're just always on that cuss of what we can really understand.
Just curious what you think about that. I think that's a very compelling
formulation of the, and I've never heard that before, the distinction between
easy and simple. As you were talking,
I was mindful that everything you said could in one way
be applied to evolution. And indeed, in terms of the
you know, the
evolution of ideas and the scientific process itself
cast as in-cultured evolution, your sort of co-evolution or evolutionary
psychology, as one special case of the evolutionary
process. You could argue that evolution is a really
solving a really difficult problem to disclose a really simple solution.
And that simple solution, of course, is you and me.
Just finding the simplest phenotype artifact
that fits with the eco-niche, that is co-constructed by other
artifacts and simple constructs, Markov-Blockitz, that constitute the
eco-niche. I think that's a wonderful insight.
And the simplicity bit, I think, is really quite crucial
in the sense that, well, let's take the cryptography or cryptanalysis,
a mindful of one of the very first introductions of
variational free energy by David McKay, who just applied the free energy
minimization to the problem of encoding and
cryptographic analysis from the perspective of minimum description
lengths and compression, which speaks to an alternative
view of the imperatives for any
efficient representation or evidence accumulation or data
dissemination scheme or communication scheme.
In the sense, I mean that in the sense that you can either read
the history of this from Richard Feynman and the pathological
formulation of quantum electrodynamics, or you can go right back to
algorithmic complexity, Kolmogorov complexity, Solovov induction,
through to minimum description length, compressibility, and right through to
universal computation. Both at their heart have this notion
of simplification as aspiring to or converging to
a minimum complexity, a minimum description length,
a maximum compressibility. So if you read you and me as the products of
evolution that are the most efficient
installation of all the information that I need
to engage with this equinish, that we have co-constructed,
then exactly the same principle emerges. I guess what you're saying is
and I think you're absolutely right that they, those kinds of principles
not only apply to our structural field of types and
functional architectures that we have in our brain and indeed
our bodies, but also the cultured constructs, what's
people like Cecilia Hayes would call cognitive gadgets.
Things that, beyond a canoe which has evolved, but in a way very
differently from the way that you and I have involved,
beyond that to things like language itself, where did language come from,
how does that simplify our sense making and efficient representation
of causal structures, structure in the world. So I think there's some really
profound common themes, cross-cutting themes
in that description and in a sense, of course, spotting, which is not easy,
but spotting those simple cross-cutting themes is exactly the process that
we're talking about. Right, right. And I often get the feeling that
many of us or many researchers out there are all orbiting this kind of
central truth and it's not just a, there are the cultural constructs, the physical
constructs and some abstract concepts that are somehow
grounded in the core, you know, reality of physics and the universe and
feel like we're all orbiting them and we haven't quite gotten there yet.
I think the free energy principle may be the closest, you know, but there's
still, there's still gaps, there's still things that we don't understand,
there's still missing parts and it'll be really interesting when,
when somebody finally locks them all together and grasp that,
that simple connection of them all. So how will you know when they've done that?
That's a good question. How would they, how would you know when you've done that?
I guess for me, it would be when we really have a mathematics,
when we really have a mathematics of cognition. So it's, it's close, but,
but still far away in a sense. Yeah, I agree entirely. You know, and then that
simple point, having that, I mean, if you're committed to this notion that
there is an evolutionary process in play, which in my world, I would read as
nature's way or natural Bayesian point of selection or optimizing your explanations
for the world with respect to the evidence, the Bayesian model evidence for that.
So I look at natural selection as your, the, the process of Bayesian model selection.
And interestingly, just coming back to your example in your first class with,
with your well-respected professor, he was illustrating there, I think,
the process of Bayesian model selection by putting forward alternative hypotheses,
eliciting them from the audience and then evaluating the evidence for them.
By in this instance, falsifying because that particular strategy was easy to crack.
But illustrating that this is a process of selection and all
evincing a deep problem, which is generating the high policies, the models, the phenotypes,
from which to select. So I think that, that's why I think the evolutionary
evolution perspective is, it is so compelling, you know, speaking to issues, the difficult
problems, which in, I think in radical constructivism would be in a structural learning.
You know, it's easy to score a good structure, a good idea, a good explanation, a good hypothesis,
a good code algorithm. It's easy to score how good it is, but to actually create a portfolio
or an ensemble of alternative to build a hypothesis space in the first place.
That's the uneasy bit, that's the difficult bit, because what we're talking about is just
being a good scientist. It's asking the right questions by having the right kinds of hypotheses
for any good search for evidence. Again, that's a very nice example to bring to the table. Now,
completely lost what we were talking about. What did you bring to the table with your question?
Oh, no, no, it was just a comment that we all should take care that simple concepts
can be very, very hard. And furthermore, simple concepts can be extremely valuable.
So the two lessons I learned there were that simple and easy are not synonyms, and simple
and trivial are not synonyms. And you also highlighted the importance of a precise and
simple way of expressing those ideas in terms of mathematics. I'm tempted to ask you,
but why mathematics and perhaps mathematics is the simplest, most self-consistent calculus
language that you could adopt. Furthermore, it is the kind of language that you could
use to communicate and share in the sense of this cultural approach to co-evolution
with people who don't speak your native language with your Vietnamese colleagues or
people who don't actually communicate it in narrative form. But you can still, in a very
precise and ambiguous, simple way, express those ideas and those hypotheses even mathematically,
and it will still be understood at how meaningful somebody in another culture,
in another world, speaking another language. So on that view, if you had to commit to a
particular language, then it really has to be mathematics, which is actually a bit worrying
in the sense that not everybody is mathematically fluent, which brings us back to, you have to
understand certain simple mathematical fundamentals before you can even start talking.
Yeah, although interestingly, it's a little bit like Tetris, so you don't need to understand
that many fundamentals about maths until it has an extrapolative effect in many different parts
of experience space, if you like. But Professor Friston, I wanted to talk a little bit about
the low road and the high road. You often say that the low road is the mechanistic view of
predictive coding and neurons in the brain and all the low level stuff. The high level road,
being the emergent and the self-organising phenomena, let's just do the low road first.
We want to get to the high road later, but we just had a wonderful conversation with Professor
Yoshua Benjo, the godfather of deep learning, and he's doing something very similar to you.
He's got this invention called G-Flow Nets, and he's using that in place of the variational
inference technique that you're using in active inference to compute the free energy.
G-Flow Nets can be thought of as a drop-in replacement for Markov chain Monte Carlo
for computing unnormalised energy functions, but without the handcrafted priors.
Even if the modes and the energy function are thin and far between and in a high-dimensional
setting, it's a kind of machine-learned version. I think you'd find it very interesting.
But anyway, Benjo is also a huge fan of this distributional reinforcement learning and
balancing entropy in a principled way. When I pointed out the obvious similarities to your
work in active inference, he spoke very positively, so you need to check that episode out.
Lovely. I will do so. Yeah, I've never heard of that, but I have heard him talk before. I do
sense he's certainly becoming more of a physicist as he gets older.
A probabilistic physicist, I should say. Yeah, that's very nice.
So what's changed in the last year for the free energy principle?
Let me think. Well, one thing that, interestingly, that we've been working on is indeed this
communication and trying to sort of get towards a simpler exposition that people
can more readily access and use in their own setting. Part of this is until spotting what
the important simple contributions are and what it can do, what it can't do, what it's
there for, what it's not there for. So trying to pare back the fundamental parts of it from
those secondary auxiliary issues, which are more interpretational in nature. So from a
technical point of view, it's just been staring at the ideas, thinking about the ideas and seeing
what is the absolute essence of this and trying to articulate that mathematically as simply as
possible, but not making it too simple. The one technical aspect here is what is the precise
role of the Markov blanket? And to what extent does that rest upon the notions that you would
inherit from complex dynamical systems theory relative to a more probabilistic construction
of the kind that, say, Judez-Pil's formulation would speak to? Probably more importantly,
how does one relate to the other? So how does a sparse coupling of a dynamical sword lead to
certain forms of conditional independence? Those conditional independences then underwrite
the probabilistic formulation of the coupling between inside and outside of a Markov blanket,
which is at the heart of the high road to thickness and self-evidencing of the free energy
principle. So that's certainly been a focus, I have to say, slightly inspired by skepticism in
not from mathematicians or machine learning or artificial intelligence, but from philosophy.
So the philosophers become very exercised about these things and like to drill down on the
precise implications of anything that they understand when they read the map. And certainly
one thing which has caused puzzlement in that field is how do you constitute or where do you place a
mathematical description in terms of complex dynamical systems theory and in particular the
theory of random dynamical systems? How do you place that in relation to more conventional
conditional independence, sort of Perlian Markov blankets? A lot of work has been
focused on that. And just for your interest, the the upshot of that is possibly going to be a move
away from casting things in terms of non-equilibrium steady states, casting things in terms of the
probability distribution of a system, a Markov blanket system at t equals infinity, as they
underlie, if you like, aspiration, the probability densities that prescribe and shape behavior.
A move back to the much simpler formulation in terms of Lagrangian's path integrals. So this
actually is a nice reflection of this trying to get back to the kernel and the simplicity.
And interestingly, in this instance, right back to the inception of certainly of my reading of history,
of variation of free energy in the context of the path integral formulation. So just getting
right back to what is the Lagrangian? What is the gerative model under the hood? How is that
manifest in the equations of motion? And what does that look like in terms of the implicit
information geometries that come from the probabilistic concomitance of these random dynamical systems?
So I imagine you were talking previously about the most recent attempt to simplify,
demystify the free energy principle. Before that paper was actually put on archives,
there's another one, which is even simpler, much, much simpler, that just excuse all the
delicate issues of non-equilibrium or non-equilibrium instead of state densities,
and just sticks and tries to pursue the whole story from front to end using purely the notion
of a Lagrangian and pathological formulations. So technically, that probably isn't terribly
interesting from your point of view or possibly even your viewers, but mathematically, it's been
a real gain getting back that difficult process of getting it simpler and simpler and simpler.
So that's certainly one thing that's strange. If you're asking me what's happened in terms of
uptake and application of these ideas, then I think things are moving more quickly than they were
a year ago. And I'm talking here about the application of or the corollary in terms of
your process theories or the way things work or the way that you might want to build artifacts
or algorithms, which is the active inference. So certainly there's been a much greater uptake
and interest in active inference that I've seen simply by pressure and number of emails and
conferences and workshops. So literally, I think two or three days ago, there was a wonderful
workshop at the Burlitz School of Mind and Brain, which was just about active inference
and free energy principle and a bit of philosophy at the end, which was an interesting mixture of
cocktail of intellectual challenges. But I was really impressed by work, which I had no idea about,
was ranging from simulations of declarative memory, actually getting little
synthetic subjects in a computer to actually told you why they made a choice. So you're taking
fairly standard economic games or the kind of paradigms of people in reinforcement that might
use, but having an epistemic aspect, so seeking for information to optimize their decisions
and their choices later on, but then taking the active inference framework and then putting on
top of that the ability to declare and explain why these decisions were made, leveraging what
distinguishes active inference from reinforcement learning, which is that under the hood, you have
an explicit representation of beliefs, belief structures. So there is a belief based approach
to any decision or any move that you might make. And you can use that to actually get
certain choices of decisions and actions to disclose the belief state. So essentially,
you can get the computer to tell you why I did that. So that was a wonderful example.
Great stuff going on in robotics and robotics. Well, I say great because of my local,
probably quite narrow view of it, but I'm really impressed with what these people are doing.
What they are doing is just taking us right off the shelf. The particular
objective function that underwrites active inference, which is the expected free energy,
and then thinking, well, okay, how can we scale this up? How can we make this work? And they're
bringing things like amortization and all the latest machinery from deep learning machine
learning to amortize some of the more delicate problems of mapping, say from high dimensional
inputs to the beliefs as qualified by the sufficient statistics of distributions.
Very much in the spirit of a variational autoencoder that actually has, at some level,
a very simple belief structure or posterior belief associated with the values at certain
nodes in certain layers, but taking it into the realm of state space models where you've actually
got an ongoing dynamics and engagement as the robot has to have with the environment,
and of course, the added and beautifully challenging aspect of robotics, which is the
inactive aspect, that it's not just a question of making sense of the data quickly and efficiently
in a belief-based way, but using that kind of data assimilation in order to decide what's the
best next move that will enable you to assimilate your data better under certain constraints,
which of course are particularly prescient in robotics. So that was very interesting.
I've noticed there's been a mood coming back to the original theme of communication and
mutual understanding between disciplines and between people who try to take these
ideas forward and converge on the end point, which we might not know when we've got that,
but the simple practical things like much of, in my world, much of the proof of principle and the
demos that try to unpack and render transparent and accessible, the basic ideas are written in
academic software, usually MATLAB, and I wasn't aware of this, but no one else uses MATLAB anymore.
I'm pre-millennial, but apparently you're meant to use Python and Julia and all sorts of things.
I'm afraid so. Well, actually, you use whatever tool works. Well, first of all,
I'm excited to see that you're seeing more uptake of the free energy principle because I think
both Tim and I, after our show last year, now we're seeing it everywhere. We're seeing the
concept everywhere. It's like everywhere we look, we think, oh, there's a connection here between
what we're talking about now and the free energy principle. I'm certainly a fan of people definitely
thinking about it more, trying to come up with practical systems based off of the principle.
I want to come back a bit to what you first talked about, which is the mathematical developments
or exposition, if you will, of the free energy principle. I did mention the free energy principle
made simpler, but not too simpler, which is apparently yet a less simple version than a
simpler version that you had also published, which I haven't looked at. But what I loved about
the paper that I did look over is the formulation of this as stochastic dynamical systems that are
orbiting around a pullback attractor. They are trying to get to this attractor. Of course,
they're never going to arrive there. And that was a very important point that you made in the paper
that, hey, look, this idea that, let's say, life is conducting and optimization is a bit
technically incorrect. It's not doing a formal optimization over the entire marginal distribution
that it has a set of dynamics that it follows. So there's a dynamical system that's going,
let's say, in a sense downhill towards this optimum, but it's moving around. It's being
perturbed by external variation, et cetera. So you get this kind of wandering around the
attractor. And you said that philosophers get very worried about how do you connect
systems like that to inference or to probable inference. And you give a connection, I believe,
at least if I read correctly in that paper, that you did actually give a mathematical connection
between let's show how you can take the dynamics of the system and map it exactly to inference. So
I believe that connection is provided in there. Is that correct?
No, that's absolutely right. And indeed, it is just that connection that is the free energy
principle that you're that. And in a sense, well, in the sense that we're talking about,
it does not surprise me that you are seeing that very simple construct emerge in many,
many different fields and many guises, because that's the whole point of just
trying to evince something that has this cross cutting aspect that you should for anything that
works in the sense that it persists in the context in which you place it, then it must
possess these properties. So what you've just said, which was a very concise and erudite
summary of the contribution of that paper is just an expression of things that persist or
things that exist. So how would you write that down mathematically? Well, if they exist over
a certain period of time, then they have to have an attracting set. What kind of attracting set
are we interested in? Well, we want the most generic, accommodating mathematical description of
systems that does not, I should just qualify this, that does not go quite as far as a quantum
mechanic background free description, but as close as you can get without going without crossing,
going to the other side. And that's a random dynamical system. So what is the attracting
set in a random dynamical system? It's a pullback attractor. So you're starting off with, well,
okay, so we're talking about things that exist in any given context and any given setting.
Things, thickness has to be defined. That's the Markov black kid. What does, what does that imply
having a Markov black kid? Well, if it exists sufficiently long for you to be able to, for
the conditional dependencies to be expressed so that you can write down there or assert that there
is a Markov black kid, then you have to have a degree of persistence or existence. So thickness
entails persistence over time that entails and necessitates then the pullback attractor.
Just still picking up on the sort of, you know, the possibility of
over interpreting the role of a pullback attractor in the sense that, of course,
the definition of a pullback attractor would really be the attracting set that
attracts all states as ticas to infinity. Is that a really relevant construct when we're
talking about real systems that have an itineracy, a separation of temporal scales,
as soon as you invoke a separation of temporal scales, which you would have to to talk about
the difference between inference and learning, learning and development, development and evolution.
Are you licensed now to restrict yourself to a random dynamical system or the kind that could
be written down by a logical system with an attracting set that may, that requires t equals
infinity for its definition? Clearly not. So you have to, I think, sort of confront the
certain interpretations of how you are using this notion of a pullback attractor. And that's
certainly been something that's been going on in the past year or so. Now,
large in conversation, I repeat, with people who are mathematically fluid, but their primary
agenda is more an interpretation and philosophical interpretation. What's come out of that or
certainly a reflect one motivation for that kind of discussion is this notion of separation of
temporal time scales. So in a nutshell, we've stopped saying talking about self-organization
to non-equilibrium steady state, because that implies that we're waiting until a system has
reached t equals infinity and is at steady state. And that's never what was in mind. We were using
the steady state and the notion of an attractive set simply to say that this set of differential
equations has a solution that is non-trivial in the sense that the states don't go off to
pessimise infinity. So if they don't go off to pessimise infinity as time proceeds, then there
must be an attracting set. There must be a solution, a non-trivial solution. And it so happens what
can interpret that non-trivial solution in terms of a non-equilibrium steady state solution. If
you've got a Markov blanket that endows it with the fingers and you've got solenoidal flow to make
it a non-equilibrium steady state. And then the question comes, okay, so if you're just using
the notion of a pullback attractor in its implicit steady state solution to the density dynamics,
does do the density dynamics in on themselves have any mathematical or theological role in them?
And can they possibly if the only, if this thing object is only defined in the infinite future?
So what you do that says, well, no, all we meant was for a suitable period of time, there are
certain equations of motion, certain dynamics in play that have a solution. And that the way
that you get to a probabilistic understanding of the behaviours and the dynamics that this
set of equations or this dynamics has is just by looking at the underlying Lagrangian
and looking at the dependencies not in terms of the states occupied, but purely from the
point of view of the paths that the system takes for this period of time. And then that
affords the opportunity. And I think this, I should have mentioned this when I asked you
what's what's been happening recently from point of view of the free energy principle.
Then you say, well, what do you mean by a certain period of time? Well,
then you get now to the separation of temporal scales. So you have this notion now,
where you can understand the the path that rejects the dynamics of this thing that is
defined by Markov blanket for this period of time. And then you say, well, let's make the
equations of motion drift at a slower temporal scale. And then let's repeat the game. And how
will we do that formally? Well, we'd use the renormalization group or the apparatus of the
renormalization group. And then what you have is now you've now freed yourself from the Markovic
constraint. So the now the universe as now articulated in terms of these series of random
differential equations, where the random differential equation at any one level supplies
the control practice of the parameters of the equations of motion for the dynamics at the
level below for a period of time, means that you've now have the opportunity to look at how
the realization of a free energy principle, say in terms of active inference, at one level,
is deeply literally contextualized in a hierarchical or renormalized renormalization sense
by exactly the same form and dynamics at the level above. So now we've come back to evolution.
Now we've got a slow process. And perhaps that's a little bit grand. Now we've got let's make it
slightly simpler. Now we've got a nice mathematical distinction between inference and learning.
And I'm focused on that because clearly many of your your viewers will be most machine learning
advances in that field. And what this brings to the table now, this implicit separation of
temporal scales, is quite a fundamental difference between inferring and learning.
And immediately tells you that to optimize the weights of a deep neuron network or the parameters
of variational to encoder or genital to serial network, you have to do it after you've done
some data simulation after you've done some inference. So because you've got the separation
of temporal scale, both at each scale exactly the same principles apply, and can be both
formulated in terms of the free energy principle or self evidence, so just maximizing the marginal
likelihood at that level. But the connection between the two now enables you to think about
how learning can contextualize inference, and how inference supports learning. So
by inference here, I simply mean optimizing beliefs or maximizing the marginal likelihood
of basing more limits or its elbow or its variational free energy atoms. With respect to
belief distributions or probability distributions over things that change quickly,
states of the world. So the kinds of things that you would do, you would need to infer
when doing surveillance or doing your speech understanding, or indeed in an active
inference sense speech production, as opposed to those things that fluctuate slowly,
which are the connection strengths, the weights, the parameters, the laws, the contingencies that
are in this particular context. Now, there's going to be another level above, which is
a slow change in the context that you can learn. And then you can start to understand
right from the Helmholtz machine, right through to amortization, your notions of learning to infer
is optimizing the slow process to make the fast process optimal. And as such,
noting that the way in which you optimize the fast, the slow stuff depends very much on having
some optimal inference scheme or data assimilation scheme at the fast level.
Pursuing the argument, it also tells you, well, the stuff all the way down and stuff all the way
up in terms of separation and table scales, you naturally now start to ask, well, what's the
scale above the learning? And this would bring us back to this more evolution and model selection
and structural learning. How many nodes, how many factors, what's the actual structure,
do I use a convolutional neural network? All of these are structural considerations
that you could use, for example, a genetic algorithm or a launch of an assisted MCMC
at a very, very slow type scale to now optimize the very structure of your variational autoencoder
that's doing the learning to infer that's enabling inference at a very fast timescale.
That leads to an interesting idea. So having different timescales for different levels of
the structural learning, and I don't know if that's been tried out yet, but I think it's
definitely worth trying. I think I have a different question, though, about the paper.
And thank you for that exposition. That was very helpful. One thing that's kind of occurring to
me now is that, again, the concept of the Markov blankets are still fundamental. And one,
like perhaps concern, I don't know if I should say concern, that I had with the paper is the way in
which it formulated the Markov blankets in terms of the curvature of the surprise being zero.
As people may remember, the sensory sets are those sets which the external world
can control, and you can view, but you don't control. And your active states are the ones that
you can control, not the external world, and the external world can view them. And so there are
these sort of four regions. And in the paper, you define ways in which, let's say, you can set
various terms to zero, which mark the boundaries between those regions. What I'm kind of wondering
is, do they have to be zero? What if this is generalized a bit to have a degree of active
stateness and a degree of sensory stateness, and there was kind of a more smooth boundary between
these? What would happen? I mean, would that give us any useful outcomes mathematically,
or would it just get in the way, and it's just more convenient to continue zeroing out certain
elements of the matrix? Has any thought been put into what if it was more of a matter of degree,
and would that be helpful, or just get in the way? Now, that's a very astute question.
I think quite a lot of thought has been directed at that problem, whether there have been any
useful answers, and that is another question. So just if I can paraphrase your question,
I think a really important one. What you are saying is that before we make any moves in terms
of understanding the dynamics of things that persist in any given context, we have to define
thickness, and in this particular construction, we are defining thickness in terms of sparse
influences that underwrite conditional dependencies. So the zero elements that you
were talking about that are absolutely crucial in defining the thing in a crisp and unabiguous way
via conditional dependencies, just technically for those people who are thinking in these terms,
and zero entries in the Hessian of the system when the Hessian is the curvature or the second order
derivative of the likelihood, effectively. And then the big question comes then,
where do these zero entries come in that define stipulatively thickness in terms of conditional
independence? If it was the case that you could not establish conditional independence between
the inside of something and the outside of something, then there is no way of really separating the
states that are inside and outside. So the game then and the delicate game and the one
that has been receiving attention in the last few years in the purely academic philosophical
literature, but also in the maths literature, is exactly this question. How does sparse
dynamical coupling, mainly, I can't actually influence you because you two are too far away
or you don't have the right kinds of receptors. How does that translate into these zero entries?
And then your question is, well, okay, do we have to commit to exactly zero? Can we actually now
have a little bit of wandering away from these hard constraints? Now, mathematically, I wouldn't
want to do that because, as you say, it's much more convenient just to sort of identify zero
entries in the Hessian and implicit conditional dependencies under some sparse coupling. So what
I would say, I've got two levels to the answer. First of all, the zero, the absence of any
conditional or the presence of a conditional independence is not a terribly restrictive
or magical requirement in the sense that it is just a reflection of sparse coupling. So I think
that you would put the question really not to the dependencies and the Hessian, but really
to the notion of an influence diagram that was predicated on a set of differential equations
you thought was appropriate to describe this universe. Now, if you think universes have all
to all influences, so every state of this universe come in a dynamical sense, simply the sense of
a large run equation or a random dynamical system influence every other system, then you will have
a soup and you will have may have interesting structure with it, but that structure will
not pertain to anything that can be separated from the universe because everything's connected
to everything else. So you start asking, well, can I just can I jump in here because I think
to a degree, much of the universe and just kind of leaving aside, okay, I'm sure there are some,
horizons at which locality, locality horizons, whatever, but I think that on the scales of,
say, human beings, we are in a soup. I mean, we are influenced. It's just those influences may be
very, very small, almost epsilon in a sense. And that's what kind of worried me about it is that,
look, I think I know that at least in terms of physics, there is this soupy influencing of
everything kind of on everything else. And so what happens if we're dealing instead with mathematics
that has these sharp zero boundaries? Is it going to be an accurate reflection of the more
soupy, albeit still exponentially decaying couplings? Perhaps I should just ask you,
I mean, certainly it is the case with six degrees of separation, that there is a
vicarious influence that, you know, will all certainly be nonzero. But did you mean that
those vicarious influences, because for me, of course, the whole notion of a vicarious influence
through something else immediately invokes the notion of something, which means another mark
of blackhead. So certainly there can be indirect influences. And I'm not denying that. I'm just
in terms of the physical, and that's probably a bad word to use, but just in terms of the functional
form of the differential equations, that will evict this vicarious all to all coupling
by other states. Do you think that most universes are sparse or not sparse? So the assumption
is here that it is the sparsity that it dows this retodontical system with structure. And in fact,
the exception is a non-sparse connection. And then the question is, how do you get
soupy, mutual influence amongst all the constituents or states that constitute
that retodontical system? So, you know, if you didn't have that kind of sparsity, you would never
have a hierarchical organization in the sense that a hierarchy just is the lack of an influence that
transcends more than one level, say, the subsumption hierarchy in physics.
Well, let me, before I forget, the other half of your argument is much more accommodating of the
epsilon and the fuzziness, which brings us to some of the notion of wandering sets. And back
to and back to the notion of separation of temple scale. So how long is it nearly zero?
Almost zero. And acknowledging that at some point, it's good to be not zero again, because
things change. So that I've sort of jumped to the second half of the argument, but I've
interested to try and bring the really important, from my perspective, notion of sparsity back into
focus and saying that it is not unremarkable to assume lots of zeros in influence, because we
do that all the time when we write down any differential equations, just by emitting one
variable in a state vector from the function that defines the equation, the motion, the flow operator.
As soon as you emit one of a universe of variables, you've introduced a zero
in that sparsity, in that dynamical coupling. Maybe this is really the heart of abstraction,
which is, even if there are these very tiny, soupy couplings, we can abstract. We can just treat
those all zero, eliminate them. And still that abstracted model reflects emergent behaviors
of the things, if you will, of the universe, really, that we're trying to model. And I think
that's kind of this duality between the fact that we may have a soupy substrate, and yet still
discrete sparse behaviors emerge on top of that soupy substrate. It's probably one of the greatest
mysteries for me. So I don't know the answer, but I just wanted to get your thoughts on it.
Well, I think that's a very important question. I've seen it asked, interestingly enough,
in correspondence with people who are sort of trying to look at the origins of life,
and I try to understand the emergence of biotic self-organization from many different
perspectives, from the kind of approach that people like Kate Jeffries or Jenny England might take
right through to theoreticians, try to reproduce organic self-organization by reproducing the
vents at the bottom of the sea, primordial soups in structured containers afforded by these vent.
One thing which struck me in these arguments was the notion of emergent behavior that had this
self-replicating aspect to it from a dynamical systems perspective. The emergence of attractors
that have a Poincaré section, you get sort of a cycle of life emerging, was the notion of shielding,
the notion of protecting yourself from the influence of other things.
You know, as a way of understanding enzymes, for example, or ways of understanding the physical
structures that lead to sort of cell-like formations, that notion of shielding comes back to the
possibility that it is the emergence of sparsity and the construction and the self-construction
and the auto-poesis of sparsity, that underwrites a Markov black building system that is necessary
for the kind of structured self-organization that you're asking the question about. So literally,
how do we move from a primordial soup to a set of discernible things? And the answer seems to be
from what I'd read. It's the emergence of certain auto-catalytic structures to actually sequester
and shield certain sort of chemicals or processes from other chemicals that are in the shielding
thereby emerge the, from my point of view, the Markov blankets. So again, we come back to
the notion of sculpting structure by removing stuff. In this instance, it's removing connections,
creating the right kind of sparsity where structure actually emerges from the soup.
Point of interest, Cole. Could you define, I'm really interested in your definition of
self-organization and emergence. And also, do you think it's a useful distinction to have this
notion of strong emergence and weak emergence? Could you just give us your take on that?
I could if I was more of a scholar, but I'm going to have to ask you to define strong
emergence. Well, it's all about reducibility. So I mean, I think weak emergence is a kind of
emergence where the emergent property is amenable to computer simulation or similar forms
of after-the-fact analysis. So like, you know, the formation of a traffic jam. And strong emergence
is this notion that the whole is something more than the sum of its parts. I mean, I was actually
going to ask you a slightly related question about substance dualism, right? Which is that,
you know, some philosophers have this notion of the mind not being reducible to its component
parts. So a materialist, for example, or a physicalist would think that. Do you think
there's a kind of parallel with this notion of strong emergence and the irreducibility of our
mind and consciousness to the constituent components? Right. You're clearly more versed in these
fields than I am. So I'm not going to pretend to give you... I highly doubt it, Karl.
In this instance, you know a little more than I do. However, I get a sense if you wanted to
proper answer that question, I think it would probably come back to this separation of temple
scales and posing that question to the kinds of systems that would constitute a renormalization
group and say, is there anything that emerges at one level that could be abstracted from the
level below? And, you know, if you could find an answer that satisfies you in terms of the
difference between strong and weak emergence by looking at a system that has that renormalization
property with the separation of temple scales, then I can tell you what the answer is. Unfortunately,
I don't know because I'm not sure what the commitments of strong and weak emergence are,
but certainly it would be impossible to understand one temple scale or one level
without writing down or simulating or understanding the level above and the level below. So in that
sense, I suspect there might be a strong emergence in here. The reason I mentioned that is that, of
course, is the get-out and it's the mechanics that you would appeal to to resolve the sparsity or
the Hessian equals zero problem. So it's clearly the case that even in a soup or a soup that
transiently or a collection of well-defined cells where there is this shielding and sparsity of
influence that protects or insulates the internal dynamics of, say, a cell from the external
milliard, at some point there's going to be cell division, at some point there could be some
metamorphosis or transformation or phase transition where it is rendered soupy again,
and you would need a different set of Markov blankets. So how do you go from one cell to two
cells? So you've got this notion now of wandering sets. So the Markov blanket partition was nicely
described into as a partition into internal and external and the intervening active and sensory
states that mediate the bi-directional influence of the outside and the outside. That partition
comprises a subset. So what you're talking now is about the possibility of wandering sets in the
sense of Birkhoff. How on earth can a set wander where it is defined stipulatively in terms of
sparse coupling expressed as a random differential equation or a Langevan equation? Well, it can
change if you say, well, this set of equations of motion is only in play for this amount of time
and then the next jump. We're going to change the parameters of the equation of the motion
and bring it other states. And as soon as you bring it other states into your flow operators
at a slow time scale, you're now destroying the old sparsity structure and replacing it with a
new sparse structure or possibly destroying the sparse structure altogether. So I think that
that would be the way that you put put epsilon back into the game. But actually more than epsilon
actually allowing for the fact that there is a certain scale of organization in space and time
that is superordinary to the microscopic dynamics of your level of inquiry over which
you will now have a reconfiguration of the Markov-Blanket. So things will look as if they're
reorganizing. So at what level is self-organization happening? You can't answer that question. He
said all levels because the context of self-organization at one spatial temporal scale
depends sensitively and critically on the parameters that define the initial conditions
and the flow operators that are inherited from the scale above. And likewise, the scale above
has to conform to exactly the same dynamics. It has to have things in it.
Fascinating. So I think that's how you would get out of the
getting to a more plastic semi-Markovian universe, a biological universe. You'd start to answer the
real questions of orthopoiesis. I feel a little bit naive in saying that the free energy principle
does orthopoiesis in retrospect because orthopoiesis has a lot more to it and is exactly what you've
been talking about. How do you get these self-preserving? How do the fast microscopic dynamics
create the context for there to be a self-assembled Markov-Blanket that entails the faster? These
are really deep questions. Indeed. It's another example. We've spoken to cyber-netesists like
Professor J. Mark Bishop and he introduced us to lots of stuff about orthopoiesis.
I've just got a bit of an eye on the time, so we've got a couple more questions to get through.
But that was absolutely fascinating, Professor Friston. But I'm not sure if you're familiar
with Ilya Sudskever. He's the chief scientist at OpenAI and he became embroiled in a heated
Twitter debate a couple of weeks ago where he asserted that large language models, the likes
of GPT-3, might be slightly conscious. And of course, I'm speaking to an authority on consciousness
here. When you spoke about consciousness actually recently, you said, and I'm quoting,
the proposal on offer here is that the mind comes into being when self-evidencing has a temporal
thickness or counterfactual depth, which grounds inferences about the consequences of my action.
In this view, consciousness is nothing more than inference about my future, namely these
self-evidencing consequences of what I do. I think this is a fascinating way to put it.
And Keith told me earlier that he thinks of consciousness in a very similar way.
But the one thing that is missing from this discussion, in my view, and by the way, we're
speaking with good old David Chalmers in a few weeks' time. But what about the phenomenological
characteristics of consciousness? Right, so we've got a couple of minutes to do that. That'll be
fine. Would you get David to watch this? Give him my very best wishes. Oh, we certainly will.
And by the way, if you have any questions as well for us to ask David on your behalf,
I think that'd be very, very exciting. Well, you should ask him everything you've
just asked me and see what he says. I love David Chalmers, and I also like the way he responds
to some of the more technical questions that he gets. And his response to this one,
I think, would probably loop in the notion of the meta-problem or the meta-hard problem,
which put simply in the words of Andy Clark would be, why is it that certain things,
i.e. philosophers and people like you and me, huzzle so much about our qualitative experience?
And it may sound a strange question, but it's a very revealing question. It simply means that
if you subscribe to the notion that we are inference machines, we are built to actively
self-evidence, then you are saying that we entail a gerative model of our experienced world.
And if we have a gerative model of our experienced world and we can talk about and
puzzle about qualitative experience, we must also have a hypothesis that, first of all,
we are things. Second, we are having a qualitative experience with the alternate that we are not.
Which, of course, then provides a really simple explanation as to why philosophers
love things like brain and vats and the zombie arguments, irrespective of whether they are
useful thoughts. The very fact that you can get some like David Chalmers as a young man,
talking about zombies, or people listening, tells you immediately you've come across a
certain sentient artifact on Earth that has got a gerative model that can entertain the counterfactual
hypothesis that they don't have qualitative experience. Now, you may be asking, well,
why is that so interesting? Well, it's interesting because it tells you immediately that these kinds
of sentient creatures are showing a sentient behavior that necessarily requires the ability
to hold counterfactuals in mind. And I mean, so now I'm trying to work back to your introduction
of the nation of the temporal depth and something that Neil Seth might also complement with
counterfactual richness. So the argument here is very, very simple, which I'm sure you know,
but probably worth rehearsing. So if you had a program that could understand language,
then what would be the requirements of the underlying gerative model that it was using
to infer the, to make sense of the auditory stream to infer the meant word? Well, for it to be
conscious, it would actually have to be able to ask questions. So we'd also have to be able to speak.
So, you know, that's the first inactive move that you see with the triple E since the turn
of the century. So we're talking about systems that are not just sentient in a passive sessile
way, but have sentient behavior. So there has to be behavior. So your language understanding
machine has to be able to do something. It has to be able to move or ask a question. And of course,
then you ask, well, what are the best questions? Well, those are the ones that comply with the
principles of optimum Bayesian design. And then you can trace that right back to things like,
or from my point of view, articulate that as a special wall part of expected free energy.
But the key thing here is that the program, the scheme, the algorithm has to be able to move,
ask a question, interrogate the world, perform an experiment on the world to do self-evidence.
If it's doing that, then it has to have a gerative model of the consequences of its moves.
So that's the simple and big move here, that just if you want to talk about sentient behavior,
you are necessarily, if you subscribe to the fact it's all, it all entails a gerative model.
Then you're talking about things that have generative models of the consequences of
their moves, their behaviors, their choices. Because those consequences are in the future,
they are necessarily acquired, that the gerative model necessarily acquires a temporal depth.
So just saying that I have an understanding or internal model with your psychology could be a
simulation model. If you're in motor control, it could be a sort of a forward model.
Most generally, just having a gerative model of the consequences of action means you've
got a very deep gerative model. And notice it's the consequences of your action. So there's an
implicit agency that suddenly comes into focus. So now you can use the word agent. As soon as
your gerative model contains the consequences of action, then you can use the word agent. You
can't do that. Could I just pick up on this a little bit? It sounds a lot like you're saying
it must be a closed loop process. And this rather leads back to, I know you were talking about
things like AIXI and some of the information theoretical conceptions of intelligence. And
those conceptions also rely on this notion of an agent acting in an environment. Does that seem
in any way, I don't know, it feels a bit anthropocentric, doesn't it? To use that notion of
consciousness or even intelligence. Is that a good framing? Yeah, well, I hadn't quite got to
consciousness at this stage, which will be certainly an anthropomorphic or centric notion.
But I think in a way that, if you like, celebrates the anthropomorphic aspect.
All I said at the moment is that if you want to talk about sentient behavior,
before you get to consciousness, you've got to have temporal depth. And crucially,
in having consequences, there can be more than one outcome to any act. So now you necessarily
have a counterpatrial aspect to the things in your gerative model, which brings us to my point
before about perhaps the best thing that David Charmans presents from my point of view is an
existence proof of a sentient creature that can have counterfactuals of a certain kind,
where it's not being able to have a qualitative experience. But this is an example of a
counterfactual hypothesis. This is a gift of very, very sophisticated systems that are probably a
long way down the path to ultimate simplicity in terms of evolution, or a very, very slow type
scale. So it's a real gift to be able to have these counterfactuals. Andy Clark would argue
that just qualitative experience is also another counterfactual. So there will be a grandmother
cell in your prefrontal cortex that fires when it says, Oh, I've had the qualitative experience
of seeing red. And it has to be like that in order for you to be able to be aware of it.
But using words like awareness now are indeed self-awareness. So qualitative experience,
first of all, underpins self-awareness, which would be a qualitative experience of self-hood.
So there are layers upon layers that you're talking about here. Each one of them has to be
manifest in the gerative model. So the first thing is that everything I've said so far,
in terms of agency, could be applied to a thermostat. So is a thermostat conscious?
Probably not. So what kind of system more complicated gerative model would you need to have
in place before you could think, Yes, possibly that could be conscious. Well, the first one is
a depth of planning. So thermostat just does not look beyond the trajectories implied by the
generalized motion. And that's the gradients that are at hand. You can't see half an hour to the
future. It just knows that things are going up or going down in the moment, a very short-term
sort of path, formulational generative model. But things like you and I can go and have much
greater temporal depth. And then we invert the notion of planning. And then I repeat,
selecting amongst a number of different counterfactual outcomes, evaluating them and choosing one,
you get into issues of free will at this stage. But still, you can imagine writing a robot,
writing, equipping a robot with these kinds of generative models that people have done this.
Would you call that such a no? Then you have to have the hypothesis that it's you doing that and
you in different states doing that. Then you have to say, well, why? Sorry, I'm rushing because I
can see your actresses before the excretion. I just wanted to make it. It's a very special kind
of generative model that even has selfhood, let alone aware that it just has selfhood. And even
more rare to actually have somebody who worries about these things and not having the selfhood.
This is fascinating. But you are a computationalist then. You do believe that humans are
independently conscious. So first of all, I think what you're saying, if you are a computationalist,
if we could recreate all of the stuff that you're just talking about, so forward reasoning and
planning, et cetera, that we could recreate consciousness in silico? Yes. I see no reason
why you couldn't create an artifact that was sufficiently similar to you and me that would
qualify as being conscious that I am. That's fascinating. Because the cyber net assists
typically think that it's an emergent property and computation is observer relative, so it
couldn't possibly exist in isolation. And then that leads on to assertions of panpsychism where
consciousness must therefore be in everything. Well, can I ask for a clarification? Because
I think I'm a computationalist as well. So suppose we did create in silico chip and some
software that had the depth of counterfactual planning, of temporal planning that could in
fact evaluate its own actions and could even evaluate at a meta level the computations that
are going into that evaluation. So that's sort of full stack, almost the full recursive stack there.
Would that thing, because a lot of times what I read from Chalmers or others is a question of
feeling, like what does it feel like to be conscious, right? And so would that thing,
in your view, feel like something? Would it have the qualia of experience that we do?
Yes. But you'd have to write it into the genetic model. So you'd actually have to write
the different feeling states as hypotheses about how am I feeling at the moment? And then it would
use or I would use or you would use all the messages and the belief updating and all the
planning and all the estimates of uncertainty that attend that planning. And that's quite key,
actually. The precision or the estimates of uncertainty start to take much, much greater
roles in terms of the heavy lifting of the belief updating the higher you get in the hierarchy.
So I am feeling in this way. I am aware of myself. I am having this quality of experience.
These would all be hypotheses that were recognized in a good old fashioned variation autoencoder way
of everything that's going on below, crucially including interceptive feelings of states of
your battery or blood sugar and all of that good stuff. Okay. So I think if I understand you
correctly, and this is pretty cool. So the feeling is actually a knowledge of
a certain activity or trajectory. That is the feeling is, in fact, a knowledge.
Absolutely. Well, you could even say that the instance of the feeling, the realization of
the feeling is the inference in the context of a knowledge structure that just is the
gerative model that has representations or slots that have a semantics of I feel like a self,
I feel unhappy, I feel anxious, I feel enough, whatever it is. There is the best sense making,
the best hypothesis or explanation in a simple but not too simple way for everything that's
going on. So feelings, including things like pain, and this is quite an important, so this is not
just a philosophical nicety, it really matters in the treatment of chronic pain when you're trying
to identify the locus of pain and what is pain. It seems as if pain is a hypothesis that certain
people bring to the table as a best explanation for all of their interceptive interceptive feelings.
Fascinating. I want to bring in this subject of subjectivity, because when we do try and
formalize things, I know Keith is smiling because we were just speaking with Kenneth Stanley,
and he has a wonderful book called Why Greatness Cannot Be Planned and The Myth of the Objective.
He thinks that formalizing things actually blocks us from discovering interesting stepping stones
in life, and even in the frame of our thinking, it actually stops us from discovering new
interesting knowledge. And this is interesting in your formalism. So there is a chap called Arthur
Eddington, the notorious astronomer and physicist born in the 19th century, and he spoke about
subjectivity and science. And I think his point was that science only tells us a sliver
of what's really happening in the world around us, and we should be a lot less arrogant in our
claims to understand it. And Kenneth Stanley says that we've been too focused on objectives,
and the broader story is that he thinks society and institutions are scared of any subjectivity,
or perhaps you might think of it as system one thinking, so we always try to verbalize
and understand everything. But similarly to what you were just saying about in respect of agents
and the conscious experience and subjectivity, it doesn't feel very objective anymore when
you're talking about emotions. Yes, sorry. The mention of Arthur Eddington was very pressing for
me. So that's how I got started this game with his book, Space-Diving Gravitation,
my father made me read some of that. Oh, wonderful. You know what's fascinating about that? I got
started in philosophy because I read his book, The Philosophy of Physical Science.
If only he knew, his family would be very proud of the impact that he's had on our
a century-new. It is now and always a century-new. Absolutely. But do you think there's a bit of
an interesting contradiction there in yourself that as scientists, we struggle to formalize
everything? You can't even get funding for a grant unless you have a clear hypothesis and a
clear understanding of what you're doing, and your papers have no value unless you have a clear
formalism of what's going on. That was the spirit of the argument, which I certainly
concur with. So I don't see any real debate or dialectic here. I mean, this is simply a problem
that we were talking about before in terms of the good scientist being able to build an apt
hypothesis space where no one else has ever gone before, and then do your self-evidence or
evidence-based science. But clearly the problem of building that hypothesis space,
that, to my mind, is unresolved in the physical sciences. Scoring any particular
hypothesis, absolutely no problem. That's just estimating the marginal likelihood of the model
evidence or some variational bound on it. It can be as difficult a hypothesis space as you want
to consider, but building it in the first place, I think that is the outstanding problem,
both practically and philosophically. And you have to ask, are there any examples where it's
been solved? Well, yes, natural selection solved it. So it's used a particular way of exploring
in a structured way using, but say, bisexual reproduction. And that sort of gives you clues
as to how you might create, and I literally do lateral thinking or inventive thinking,
having ideas and hypotheses that no one has ever had before. So I think that that question,
if I read it properly, just speaks to a really challenging, exciting and practical challenge,
not just for science, but people trying to build sentient artifacts that now have, in a
principal way, the ability to actually have new ideas and to test these new ideas. And I should
just add that one example of these new ideas is that I am a person and I'm happy or in pain.
This is not, I don't think they're typically magical about the kind of constructs we talk about
in philosophy of selfhood and consciousness and self-awareness. And the psychophysics of visual
perception is just having these new kinds of hypotheses, perhaps they're not so new in terms
of selfhood because of the cultureism that we're talking about and the fact that
mum talks about me and it's a very viable hypothesis that explains a lot and actually makes my
data foraging or my epistemic foraging much more efficient. Just to simplify the world,
oh, I am a person, a mum is a person, there are two selves. That hypothesis perfectly fit for
purpose, maybe completely rubbish, I don't know, but it's a hypothesis that seems to work really
well. And when you generalize it, oh, there are other persons of itself, I seem to be the universe
populated by selves. This is a hypothesis, which is reaffirmed through gathering the right kind
of evidence through communication, afforded of course by language and other aspects of a
cultural evolutionary psychology that, again, speak to the sort of separation of temple
scales. But quite within this, quite naturally, selfhood arises. And one could argue, philosophers
also will flourish and we can have conversations about the hard problem, the meta-hard problem,
as you will do. But it all rests upon, at some level, at the highest level, new hypotheses,
simpler, better hypotheses being tested by some artifact or some Markov plug-kits.
The thing that fascinates me though is that with the FEP formalism, you were saying before about
self-evidencing and finding our eco-niche. And when we do talk about, well, when we introduce
subjectivity, it doesn't feel, it feels much more divergent and much more random. And that's what
Kenneth Stanley says, he says that any formalism is convergent. And in order to be divergent, we
need to embrace subjectivity. And it feels like emotions are the human form of subjectivity. So
that kind of, in my mind, that makes this process feel much more random and divergent than perhaps
the formalism would make us think. Again, I can't quite get a sense of a dialect. I don't know who
disagree with that. It certainly is the case that finding your place, and we actually demonstrate
this in silico, using cells that differentiate, finding your place under a shared narrative or
gerative model amongst a population is a free energy minimizing solution. And it necessarily
leverages or relies upon subject-specific realizations that are contextualized by what
the realizations in other subject has. So you can certainly argue that that subjectivity,
that subject-specific expression of your sense-making, active sense-making, is a necessary
part of the minimization of the joint free energy of a number of free energy-minimizing systems.
Even to the extent, I mean, this is basically the Holy Grail and taken as red in things like
computational psychiatry. So if you want to use, let's say the active inference process theory
to understand and phenotype people who might or may not have schizophrenia-formed symptoms,
or may or may not show addictive behaviors, or have this kind of autistic expression,
then what you can do is you can use the complete classroom to say, well, look,
in this game that I go to give you, the complete classroom tells me that your behavior will be
base-optable, whatever you choose, under some prize. And what I want to know is, what are your
prize? So that means for every person, every subject, there is a unique set of prize that
characterize their behavior under ideal-based assumptions that can be read as active inference.
So the job now is to try and identify what are these, what are this person's prize,
and then use that to test hypotheses that you're this kind of person or that kind of person,
so try to find some systematic structure in the belief structures that each subject brings
to the table. Yeah, before we run out of time, I do want to ask you the perennial free will
question. So I think, and correct me if I'm wrong, but I think you believe in a universe
that's unfolding according to these deterministic, albeit stochastic, but deterministic flow
equations, differential equations. And so the universe is deterministic from that perspective.
And so is that correct? Would you agree with that?
Sorry, just technically, you have random fluctuations in a random dynamical system,
so you don't get deterministic cares, but you certainly get stochastic cares, absolutely.
And just interestingly, it is becoming clearer that things like you and me may well have
particular flows that are almost deterministic, even if the outside is a bit random. Sure.
Yeah, and I would even say it's entirely possible that those stochastic fluctuations
are themselves highly chaotic deterministic systems, or even if they are pure chance,
they're of the form of a chance that's not controllable. It's just sort of this
truly random chance. And so in that context, a lot of folks have a lot of trouble imagining
how we can have quote unquote, free will. From my perspective, free will is simply that an agent
evaluates a set of inputs and sensory things and has an algorithm that then determines what actions
it's going to take based upon that. And if you had put in different sensory inputs,
it might have chosen a different pathway. I'm talking about sort of degrees of freedom,
if you will, as free will, almost the same kind of concept I believe that Daniel Dennett espouses.
So I'm curious how you see free will in the context of a universe unfolding either purely
deterministically or deterministically with stochastic variation.
I think I see almost exactly the way that you expressed there. Just to make the point that
the fast stochastic fluctuations, of course, can also be just expressed at a faster timescale
using the renormalization groups. You don't even have to say, I'm committed to stochastic as opposed
to a deterministic chaos with a correlation dimension greater than 10, for example. You don't
even have to do that once you allow for the separation of temporal scales. So you can talk
about a universe that is no longer Markovian because of the separation of temporal scales,
but certainly has the opportunity at one given scale to have deterministic chaos. And I think
just in saying that, you're perfectly licensed to talk about free will. In fact, it would be
difficult to imagine anything that plans and selects one of a number of ways forward. Those
counterparts we were talking about before that could not be construed as selecting and thereby
manifesting a pincing at least a minimal kind of wilfulness in the sense it has to do selection.
Well, could argue, well, does that mean that natural selection is selecting you willfully?
Does it make a choice? Does it have free will? I'm not sure about that, but certainly if you
have a genealogy model that sees itself doing its natural selection of the best counterfactuals
about what to do will say next, then that would I think be part of this sort of minimal selfhood
that would be undeniably a representation and an inference and a recognition of my free will.
If I was able to infer that you were sufficiently like me and presumably had the same kind of
genealogy model, I would also infer that you had free will and you would behave as such and I would
secure that evidence by talking to you or just watching you and I would also leverage it. I'd
also use that as theory of mind to infer your intentional stance because I see you behaving
in a way and if I behaved in that way, I would have selected that plan and therefore I would have
made that kind of choice and that would tell me the kind of person you are. So it brings us back
to the priors that characterize all of us in this instance. If I can infer you very accurately,
we share the same prior commitments. We have very, very similar problems.
Okay, thank you.
Amazing. Professor Carl Friston, thank you so much for joining us this afternoon. It's been a
pleasure.
I've enjoyed myself greatly. Thank you very much indeed.
Wonderful.
