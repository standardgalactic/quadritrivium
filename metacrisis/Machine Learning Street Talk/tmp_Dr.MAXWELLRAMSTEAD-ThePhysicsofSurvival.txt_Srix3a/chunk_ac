And they all have this same pattern that repeats and so it really is
Yeah, so and and I think anybody can see that pattern, you know, I mean look around we got we have trees
And they have boundaries and you know, yeah, even higher in scale
You have planets and galaxies and but at the same time if you if you dig down into it and you try to really
Precisely define it then it it slips away. It's like if I zoom into the surface of my skin, you know fine enough
Well, it's no longer a surface
It's this ragged thing with cell membranes and then the cell membranes are molecules with tons of space
You know in between them and heck atoms, you know are mostly empty, right?
Like there's this this weird, you know vagueness and difficulty in defining, you know boundaries
So they're not sharp like how's the concept of of a Markov blanket? How does it evolve to that kind of?
Fuzziness or that's a great set of questions. Your questions are still on point
This is a so I would say the
The first thing to say is that so this is sort of mind physics or brain physics if you want to think about it like that and
One hallmark of explanation in physics is simplification or you know, you might say over simplification
So I'm sure I'm a biologist reading a paper on the free energy principle might look at this and go
But you know, this is way too oversimplified. Where is the biological detail?
I
Think physicists also do this to physical phenomena, right? Like that's that's sort of the joke a physicist would respond
Yeah, but we do that to physics as well, right? Like it's
So, yeah, there is a deliberate idealization going on if you define this Markov blanket strictly as the the set of degrees of
freedom that render some in inside
Independent of the outside, right?
So if conditioned on the blanket states, you can speak of statistical independence between the inside and the outside
Well, that that is too strict to describe most physical systems, right?
So I assume you myself and our listeners. We all had a bit of coffee this morning. We've all used the washroom
So there's clearly a kind of permeability exactly that there's really a kind of permeability at play
and so
Yeah, we we know that there is material turnover in most of the kinds of systems that we find interesting
Especially those that self-organize far from equilibrium. So the mark. I'll blanket is necessarily
an idealization
Having said that there are good reasons to think and we have some results coming out
Later this year. A lot of them are due to our senior mathematician Dalton Shakti Vadi Vell who is an absolute dynamo
So we have seen I've seen some of his papers. Yeah, it's very impressive stuff
He's been working on weak or fuzzy blankets
In precisely this context. So the the idea is can we get really rigorous about the
mathematics of approximate Markov blankets or fuzzy Markov blankets and
The idea in a lot of his work is to construct this this quantity called the blanket index to gloss over some of the
technical details just for in the interest of our
audience
basically
They're in if you consider a given
Dynamical system there exists a Markov blanket in that system if a specific inner product is equal to zero
so in particular, this is the the Hessian of the and the
Solenoid oil flow the the product of those two things being zero what it basically is a way of
Quantifying the the force or the curvature
that a system is subject to and
Yeah, if the entries in the center product are zero then there is a strict Markov blanket
But there's a way of constructing an index or a measure such that you can accumulate the non-zero entries
And basically quantify how far from perfect blanketedness a
system finds itself
and so
Yeah, this blanket index has a number of interesting properties
One of which is that it it it tends to zero as systems increase in size
Hmm, so I know what kind of assumption so
It's very very very general
So I locality assumption or yeah, you get the locality stuff from from the background, right?
So you get the rest of mechanics going, right?
So, okay, okay, so then you already have like, you know relativity in the background
statistical mechanics classical mechanics and all that stuff. So yeah
You do get this kind of nice locality
So that's interesting. So in in a universe like ours that has the the basic physics that the universe like ours has as
The scale of a system gets larger and larger
You you generate Markov blankets, you're bound to with the probability one. Yeah, absolutely
Fascinating and you know, most of the systems that we consider in physics are large in the appropriate sense, right?
So think about how many molecules are in in the drop of water, right? It's 10 to the 26
Some some something times Avogadro's number. Yeah, exactly. Self is 10 to the 23rd. Yeah
Yeah, so the 10 to the 23. Sorry. Yeah, so that's just for a single drop of water
Now as you consider the brain, the brain has like something on the order of a hundred
150 billion neurons
Each of which make thousands of connections if each of those connections can encode a parameter
Then you're talking about like a very large system, right? We're way way way beyond like, you know, 20
51,000 different states that that are coupled together. We're talking about like billions and trillions of different states
So there's reason to think that just due to the physics of the situation
most relevant things that we might want to consider will have Markov blankets and
I mean
So Dalton is going to be releasing a few papers having to do with large fluctuation theorems
Okay, and so this this let's pause for a minute and appreciate this because this to me is a fascinating a
fascinating result so
Okay, so we start from the point of a Markov blanket is kind of this intuitive concept, right?
Like it's you know a boundary and and that sort of thing, but there's no reason to believe that they're
Inevitable and I'm finding it
Fascinating that there's that there's this work, right? That says that as a scale and so we have a measure of blanket
It's kind of between zero and one zero has a blanket one doesn't okay
And and yet as the scale of the system gets larger and larger
Blanketness approaches, you know zero you get blankets no matter what and in the sense there's a sense in which that's
Recapitulating what we see if we just look around like everybody out there listening look around yourself and you're gonna see
Blankets all over the place. You're gonna see things and those things have have boundaries, right?
But it's it's remarkable, right that that there's a mathematical proof that that's inevitable
In this sense, isn't it? Well, I think it's remarkable in part because we have approached
The question of self-organization and emergence from a false starting point
So I've been going around saying recently Aristotle was wrong
That's that's my philosophical start man
Well, the hole is much less than the sum of its parts. It turns out
So yeah, there there are a bunch of things to unpack from that. Well, the first is that
What makes you the kind of thing that you are is the sparsity of your coupling to the rest of the world, right?
If you think of a gas, right?
Everything is coupled to everything else and it's just this fuzz and it's all one system and there's there's no you can't really
Identify particles within the system
Particles or things are defined by their sparse connections to everything else. So I am in some sense what I am not
Or I can be defined in terms of what I'm not connected as opposed to what I am connected to
I mean, if you were to create like a giant adjacency matrix for the entire universe, most of it would be empty
Right. No, I get that you're saying the hole the hole is less than some of the parts
Which is there's more if you if you get rid of the parts you have you have less, right?
and but but there's more
the
So think of an engine right like an engine functions as an organized hole
Because you're constraining its parts to behave in very specific ways
So like, you know, if you think of an engine more specifically like a petrol engine
Well, the the mechanical effect of the engine you get by, you know
Moving these pistons in a specific, you know
Direction up and down and the best way to wreck your engine is to introduce new degrees of freedom into it, right?
I would not want to introduce new degrees of freedom into the pistons
So that's a great way to just tear your engine apart and I would submit to you that this is
You know an accurate way of thinking about all self-organization
We exist as holes because our parts are constrained to behave in very specific ways
So it's not merely that I am what I am because I am not what I am not
Just a nice tautology
It's that the what makes me what I am is the way that I remove degrees of freedom
From my parts such that they conspire to create, you know to generate me as an overall pattern
So, I mean, it's it's counterintuitive from the perspective that we inherited from, you know
traditional Aristotelian
metaphysics, but I
Mean, yeah
It's so exciting
I don't know. I don't know why I get excited but to me it's it's really excited and this I mean
So this is work that's coming out of verses, correct? That's right. Yeah, that's right
Coming out of yeah, I would say
Coming out of Carl Friston's group more generally and let's not forget, you know, Carl proposed the free energy principle in the middle of the
2000 knots
and so yeah, but definitely this is
the the powerhouse behind
Versus AI technologies
So yeah about that for a minute because um, yeah, we generally don't talk about, you know
Companies on the show, but this to me, this is an exception because it's fascinating what you guys are doing. Thank you and
So versus versus technology is trying to operationalize
This understanding really and this is correct as technology and I guess and I'm super excited by
What we've been talking about conceptually, but tell me why shouldn't they care like what does this?
What does this fascinating?
You know view of philosophy and mathematics and the relationship to really I think it's really about understanding
Complex systems and in a new way and new mechanics of complex systems. What does that mean for us?
What does it mean?
technologically
Well, thank you for your excellent question
So I think what one of the things that we want to do at versus is to apply active inference to artificial intelligence
So active inference is basically the kind of machine learning that follows from
Adopting the free energy principle as your kind of core method
Our contention at versus is that active inference will be to the 2020s
What reinforcement learning was the 2010s effectively, so it's going to be we think the way of doing
machine learning
Be ethical scalable if most efficient way of doing machine learning
And there are a lot of different
aspects to that
so
one of the main differences between
Artificial intelligence built on the principles of active inference and more traditional approaches is that we start
From an explicit generative model so-called
So we talked about the Markov blanket
The generative model is another core piece of the free energy principle
puzzle or
Constellation if you will and the generative model is basically
are a
Statistical description of the dependency relations within the system that you're considering
So when we're talking about Markov blankets
Actually, what we're saying is the generative model of the system contains a Markov blanket, right?
So all of these dependency relations that we're writing down
Like once you do write them down you get this nice sparseness structure where some parts of the system do not affect
other parts of the system and
So yeah, this this generative model is really key to the doing of the free energy principle
and so
Yeah, what we do in active inference is write down generative models
Explicitly labeled generative models that then allow us to you know perform inference
They allow us to do that because the
variational free energy that we were discussing earlier
basically the the the
Gradients of the free energy that you're following they come from this generative
basically
so
Yeah, the the model itself is this explicitly labeled structure and this is where you get like a huge
explainability
Advantage we actually have a paper that came out on designing
artificial intelligence
explainable artificial intelligence using active inference and
Yeah, what what you get just immediately from flipping to an active inference framework is a way to write down
Yeah, generative model such that it is explicitly labeled and thereby auditable by human users and stakeholders
So you don't have this
unlabeled, you know 10 trillion
Parameter net as it were right, which you have instead is
Yeah, a model that explicitly represents all of the different factors in the situation that you want to control
So let me dig into this. Let me dig into this a little bit. So
And I because I'm curious there's a connection here to some some work
I used to do a long time ago. So writing down generative models. My experience has been at least is
It's it's actually relatively easy to do that. So for example a long time ago
I was contracted to do some work on mad cow disease. So we could try and figure out
What interventions to do to reduce right the spread of mad cow disease and it was pretty pretty easy to
learn about the
The food system the supply chain the food system to model, you know, the processing of
Cattle and that sort of thing and write down a large simulator
So this would be a generative model can sit there and can generate
Trajectories through this space, right? Like we knew we could do that
We couldn't tell you anything about the large-scale kind of thermodynamics of the system or anything, right?
