Well, it's it's a thrill and an honor to be here with you guys like frankly. I'm just so pleased
Maxwell it's an absolute pleasure to have you here today and I want to thank you for coming on the show because you're one of the
Uncommon type of combinations that I that I love talking to and find, you know, so enlightening which is a
philosopher who's also fluent in mathematics and I think that brings an interesting rigor, you know
To the philosophy and then there's actually like a really cool interplay between
Philosophy and mathematics and science. So I think I think you gain a lot as a philosopher the more
Science and math, you know and vice versa you gain a lot as a scientist and a mathematician the more philosophy, you know
Well, thanks very much for your kind words
I'm inclined to
Agree the philosophy and formal training go
Hand in hand and you know that it is something of a strange historical
Circumstance that we we don't think of philosophy as a very formal discipline anymore
You know, if you went back a hundred years
Some of the there was no separation. No, there was no distinction between science and philosophy, right?
Absolutely think back to the Prince Principia Mathematica, right, you know
Russell and Whitehead
Philosopher mathematicians, you know, it was very common back in the day and
Less so now, but you know, let's hope that the trend is reversing. I'm definitely optimistic about this
I think I increasingly find myself surrounded by a very technical
Colleagues who also have strong philosophical backgrounds
So, yeah
Hopefully things are changing for the better
Yeah, you know, it's interesting
I'm gonna take the time to ask you since you are, you know, a philosopher like by by education and I mean no offense folks that the
philosophers whatsoever because I think
Science has lost out on losing losing philosophy and philosophy has lost out on losing
Science and like the the rigor that you know confirming your thoughts against reality
Can have I mean, do you find that to be the case?
Which is that I find a lot of philosophers, you know, without that grounding kind of in in science and mathematics
They spend a lot of time
Pontificating really about things that just amount to them to the vagaries and ambiguity of like natural language
Rather than than being able to map it to something symbolic something concrete, you know
Well
So I think I think it depends what kind of
Philosophy we're talking about. I mean in in general I think
The ultimate problem is the being a philosopher of science is
difficult because you have to be a philosopher and a scientist
And usually when you're training you can only do one PhD
So, I mean, I think to be like a proper
Philosopher of science, you know, you would have to be familiar with the the history of philosophy and contemporary philosophy of science and also
To get some proper training in the discipline upon upon which you are
Directing your reflections
and so, you know in my case I had to do a lot of
kind of training on my own so my my
Most of my coursework
was in philosophy and cognitive science and so the the the more formal stuff that I wheeled
I've had to teach myself as a kind of side job
So like when I was doing, you know, my master's and my PhD
In philosophy and cogs I I would also be teaching myself math on the side and I think that you know to
to to to
You know
Exists effectively at these intersections. You can't help but
Get some multidisciplinary training and I you know, I think a good philosopher of science is necessarily a polymath
In some sense like you you need. Oh, thank you. Absolutely, right
And I think that's that is what makes it that is what makes it a kind of a rare breed, right? Like, you know, like one of my favorite
Philosophers of mathematics is Eric curiel and he has so much great
You know content on on general relativity and mathematics and philosophy in general
But like you say there are these rare these rare
Combinations and or it takes a lot of self-study, you know to develop that. That's right. Yeah
And I mean, you know topics like the free energy principle and active interference are inherently multidisciplinary
So it's it's beyond just like the philosophy and the math
You know, what if if you're in some sense if you're doing it well
then
Insights from every discipline will wind up making contributions to the way that you're thinking
FEP theoretically, so yeah
but I
This is one of the things that I love the most about our intellectual community
Around the FEP and active inference is the multidisciplinary the multidisciplinary nature of it
And that's sort of unavoidable, right?
So, you know, the free energy principle
Which we'll be discussing today is an explanatory principle that
that its proponents at least report applies to
every scale at which physical systems self-organize and
therefore, you know
Insights from all of the different disciplines working on on all the different kinds of things
Become relevant and the FEP then acts as a kind of like meta-theoretical
architecture to fit these claims together in a way that's tractable
From a physics and from a mathematics perspective. Well, one of my earliest childhood memories is
understanding how Cartesian coordinates work when I was I guess I
Yeah, 11 or 12 years old
Kind of really like understanding the mechanics of that and going like wow, like there are disciplines where there are exact
Answers to the questions that we have
And so yeah, I was always very into the sciences and math, but I've also always been very interested in the big questions
And by the time I was done with high school, I was I was either going into
philosophy
Physics or film and so I ended up deciding to go into philosophy and I
I remained a physics and math geek throughout so I'm self-taught in a lot of ways and
Yeah, I ended up specializing in philosophy in cognitive science the philosophy of cognitive science and
Formal approaches in cognitive science in particular, you know, when I was doing my undergrad
The embodied inactive embedded extended traditions and cognitive science were very hot
And so I learned some dynamical systems theory
And I was very into ecological psychology
Which is a branch of psychology that attempts to apply principles from physics to understand action perception loops
so I was very into all of this cluster of ideas and
Around late 2014 early 2015 I was exposed to the free energy principle and the ideas of Carl Friston
In part by reading this this really wonderful and by now seminal paper of Andy Clark's called whatever next
Which was his famous BBS paper where he kind of reintroduced
the predictive processing framework
and
You know active inference along with the free energy principle
so that
essentially
Combined everything that I had ever found interesting in some sense and I had a real kind of conversion
experience if you want to call it that
and
So yeah, I I had the pleasure and privilege of meeting Carl and the flesh in May
2016
at a decision-making conference in Montreal and
You know, you've spoken to Carl a few times. He was
Very typical of Carl. He was very extremely generous with his time and friendly and insightful
and
at the time I was working on
Sociocultural dynamics and I was wondering whether it was apt to apply the free energy principle to explain this kind of you know
ensemble dynamics and you know Carl
responded with an affirmative answer and
Encouraged me to you know, take this seriously and exchange with a few other people
And what began was a very extensive email correspondence that turned into some papers
Carl then became my PhD supervisor and I spent about
Yeah, the better part of two years in London
With his group at UCL learning the ins and outs of the free energy principle
Yeah, and so
So I guess that's that's sort of my story and how I met Carl
That's interesting, you know and the free energy principle. So you learned about it much earlier than than I did
I wish I didn't know about it earlier
But I didn't come across it until I guess a couple years ago
Whenever the first, you know, the first MLST episodes that we did on it
But I had had quite a bit of Bayesian, you know background up in that point
So when I first saw it I thought wow, this is it's really ingenious, you know
I like I'm fascinated by it and we wanted to learn more and so we've had we've had professor
Friston on the show a couple of times and like you said
Tremendously insightful, you know, one of the most brilliant people I've ever spoken to it's such a joy
To talk to him and I think even though we he's been on the show a few times and talked about we should probably frame up a little bit about
What the free energy principle is absolutely? It'll play a big role in our
Communication going forward here. So let me take a stab at it. Absolutely. That's great. I'm sure the expert like I
Well, you're usually really good at summarizing
well
You know what fast states me about I think is and I want to get to the the crux of this this
Beautiful statement that was made about it being the ultimate
Existential question right because usually we think
What does what does a life form or a thing even for that matter? What does it have to do to survive?
Right like this is kind of the emphasis of you know, are you fit the Darwinian sense?
You know, what kind of fitness does it take to survive?
But this the free energy principle completely inverts that and it says
Okay, if things exist if things survive what must they do?
Right, and it turns it on the head in this way, which is let's assume that there is a thing
You know and it and it continues to survive it continues to exist
Just by knowing that what must it do, you know, what what dynamics what behavior must it have?
Is that a fair framing and what is?
What are those behaviors that things that exist must do?
So, you know, I think the way that you describe things is
Accurate and an insightful way of putting things the free energy principle is not just a
basically a theory
according to which
things that exist
Must be doing this or that as in it's not it's not trying to
to tell you
Here's something that things do in order to exist what it's what it's telling you is we we observe
That things exist in the sense that
there are
there are
systems or
particles or things
That can be reliably re identified that are
separated from but coupled to their environment and given that we
observe these things that exist
What must be true of them? So it's a kind of inversion of the explanation moving to like kind of
first principles account of what what what must necessarily be the case
If you exist and essentially what the free energy principle tells you is that if you exist in
the sense that you are
Separate from but coupled to an embedding environment
Then it will look as if you're tracking the statistical structure of your environment or more precisely
It'll look as if the states or paths that are internal to a given
Your boundary of a given thing track things that are external to that boundary
so in some sense it it explains why
or it provides a
principle allowing us to
Yeah, explain why it looks as if everything that exists is
Yeah, tracking or representing depending on how you want to think about it features that are external to it
and
This this tracking or representing relation is
It is rather weak in some sense, but we're not talking about like necessarily
Contentful representations little images in my head what we're talking about is something I think more fundamental or existential
So for example, I can see from your your camera
Feed that you're wearing a
A button shirt
That tells me something about your environment
So I can read off you from the fact that you know, you're wearing a button shirt that you're probably not in the Arctic somewhere
I mean, I can see your background also that that's kind of cheating
The basically we we can read off anything
Properties of its in that of its embedding environment by virtue of the fact that it exists
Right, right
So, yeah, and there I think there's an interesting point in there
Which is that it isn't this exact one-to-one correspondence and I mean really how could it be right like how could a how could say a
subset of the system precisely represent the entire system, but instead it in a sense it's representing an abstraction
System, you know, and I mean, I think they're even good energetic arguments
Why that would be the case because you know you since you can't maintain total information you maintain an abstraction
Maintain enough in order that you can predict and track, you know behaviors
Because you exist you must continue to exist, but you don't require
Complete information only sufficient sufficient tracking. Absolutely. Yeah, heuristically
You can think of the the free energy principle and this is metaphorical of course, but as they a map of that part of the territory
That behaves like a map
so
it is a
scientific
Principle that we can use to construct models of systems that appear as if they are in turn modeling or tracking aspects of their environment
And I think thinking about modeling for a second is useful here
So if you had a one-to-one scale map, is it Borges who?
Presents that in a in a story at some point. Yeah, I think so. Yeah, so a one-to-one scale map would be completely useless
Right, I mean just imagine the quantity of paper that you would need to
Have a map of say LA right a one-to-one scale map of LA it wouldn't be useful in the generation of
your actions
So the map is necessarily simpler than the territory
But that's okay in some sense right because the implication of that is that using the map you're gonna encounter errors
You're gonna generate errors
But in the active inference and the free energy principle approach those errors are the relevant signal
Basically, so all all you have to do is have a good enough map and act in such a way that you are informed by what your map
Contains in terms of information
And to in real-time course correct based on the errors that you're generating
So it's the these errors in the kind of oversimplified
Character of the model or features rather than bugs
You would need that in order to have a signal at all in some sense
Yeah, and there there is this iterative nature to it that I think is sometimes forgotten because
You know there are these two components and the free energy principle
one is
Fidelity how accurately does it kind of map to?
The environment like so so if you think of the the entity that's surviving the thing that's surviving
You know it has to have a model of the environment
It has to be have some degree of fidelity because if it doesn't it's not accurate enough to maintain its survival
But at the same time it also has to have adaptability because the information is never complete. There's always new
You know phenomenon occurring to it the environment is changing or whatever
So the model has to maintain a degree of flexibility, right?
And that's what this it's kind of entropy term in there is it's saying precisely
You know you need to maintain a certain amount of entropy because that is a form of flexibility. Is that correct?
I mean, that's absolutely correct and you can think of the entropy in a few different ways
and
The entropy term in previous discussions with Carl Friston
You have highlighted that it's technical importance. I mean basically what we are
What we're trying to do when we minimize free energy is
To increase the predictive accuracy of our model
So that is to have a model that
Generates predictions that are as close as possible to the real data that I'm ingesting
But the free energy principle
Allows us to in it in a principle manner
penalize the complexity of the model right because you don't just want an arbitrary
Explanation that as you know, you can construct an arbitrary
Explanation for any data set and you know
Well, you need to be deleterious if it's absolutely income if you have incomplete information and you model it
To accurately accurately in a loose sense, but actually you're just you're you're memorizing spurious
Information that doesn't generalize absolutely. Yeah, absolutely. And so the free energy principle
When you're when you're applying it and you're saying that systems that exist
Minimize this this quantity variational free energy
The variational free energy can be decomposed
Roughly speaking into predictive accuracy minus complexity. And so what you're doing is you're penalizing your gains in predictive accuracy
against
the the complexity cost of your model basically
Penalizing every new degree of freedom that you need to introduce into your model to explain the data
so in some sense the free energy principle is sort of like you can think of it as a
kind of like
Statistical predictive accuracy
But also Occam's razor, right, right, right. So yeah
No, no, it makes sense
I mean and that's it's this interesting balance and the free energy principle
Encodes that balance and I guess the simplest the simplest way possible
Let's say this is a sense in which the free energy free energy principle applies to itself because it's that's right
It's almost the simplest formulation of that of that balance, right? Yeah, and yeah, I mean
There are all sorts of ways to control for complexity that have been introduced in machine learning
But
Those all might seem ad hoc in some sense. What we try to do is to build in this complexity
control
Right into the objective function that we're using right so it's it's at the core of the architecture is that rather than just use reward
Which you could probably cast in terms of like predictive accuracy
So I think we have one more foundational concept that I'd like to kind of get on the table
And that is just a concept of a thing
You know because because a thing the idea of a thing is
Defined in a very certain way in the context of the the free energy principle and it's all about this this Markov blanket
And and we've talked about Markov blankets a few times on the show. They tend to be
Confusing, you know, I I tend to I almost visualize them usually as cells like in the human body
So like, you know, you have a cell and it has stuff inside and then it has the cell membrane
And then there's the stuff outside which is kind of the environment and that membrane in the sense is the Markov blanket
It's the set of stuff and states between, you know, what's inside and outside
But can you talk a bit about, you know, why Markov blankets are important what they are, you know
How they're defined
And maybe some of the edge cases like does an eternal flame have a Markov blanket. Why or why not?
That's those that's a great set of questions. So
you can think of the free energy principle as a
The same kind of thing as the principle of least action in the sense that it's it's a principle that allows you to write down
Mechanical theories or mechanics, right? So
Classical mechanics has the principle of least action and the principle of least action is basically a way of
specifying the
The conservation laws that we want to see our systems conform to in particular the the balance of the potential and kinetic energies
are zero and
The real trajectory of systems physical systems are those for which that balance holds
And maybe I'll just quickly interject here
It's not so much that we want them to conform to that just that they do
And that and that's actually key to the free energy principle too because it's not like
It's not like we want things to obey the free energy principles
They must obey the free principle if if they you know exist, right? Absolutely
I was speaking in the manner of a mathematician
Oh, yeah, no totally totally get it. I just wanted to point this out for our readers
Is it because as we go along like you are almost these are principles that in the case of classical mechanics?
Just are they're just the way
Things behave right and in the case of the free energy principle
If you survive if you exist you're inexorably drawn to this set of dynamics to the set of mechanics
Otherwise you don't exist. Well to get technical for a second
I think there are two issues
That that are both striking and that speak to what you just said so
Things like the principle of least action and the free energy principle and the principle of maximum entropy
They are in some sense true a priori or mathematically. They are mathematical truths
So you wouldn't try to falsify the principle of least action
Empirically any more than you would say try to falsify calculus or probability theory by coming up with an empirical
Counter-example so there's a sense in which like the the truth of these statements is robust and mathematical
Having said that it is a striking empirical fact that the physical universe does in fact seem to conform to these mathematical
Regularities, so it's sort of a one-two punch
in some sense and
Right, right. It's the unreasonable effectiveness of absolutely. Yeah
And it's getting even more unreasonable now with the free energy principle coming into play
So the way I like to think about the free energy principle is like I was saying as introducing a new family of
mechanical theories or mechanics, so
You have classical mechanics
Which follows from the principle of least action
And you have quantum mechanics and you have statistical mechanics
So basically the idea behind the free energy principle is let's get the rest of physics working in the background
So you get you get your classical statistical and quantum mechanics working with all of those
Yeah, all of that mechanics is in play and then you ask a simple question
What does it mean to be a thing in this context?
i.e. what could it possibly mean to?
Reidentify some state as the system as being the same state over time
and so yeah
Unpacking that question leads to a Bayesian mechanics
So Bayesian mechanics is a physics
But it's a it's a physics for the that kind of duly constrains
the system itself the physical system and the beliefs that the system encodes about the things to which it's coupled right and
That I think is really the key
for the kind of underwrites this whole construction
This is also what makes it unique among other
candidates in the cognitive sciences and the biosciences
It's that it is connecting the thermodynamic entropy of the states the system is made of
To the information entropy of the beliefs the probabilistic beliefs that those states encode
so the free energy principle is all about this hinge between the two and
The equations of motion that you write down using the free energy principle are constrained in both of these spaces
And that I think is absolutely the key to understanding what's going on here like the the system trajectories that you get
when you're writing when you're writing down an FEP theoretic
model of the system that you're considering it is
constrained both by the the physics and thermodynamics of the system and
By the physics of the representations if you will that the system is entertaining about the rest of the universe in some sense
And I think it's it's not without precedence in the sense that for example in statistical mechanics
You know back back when we're deriving Boltzmann's
Distribution and there were questions about are these particles do they behave as if they're identical or if they have the same attributes?
Are they are they are they the same particle and the same thing with poly exclusion, you know
It applies to some particles and not others. So there those are examples of where a statistical
Calculation a statistical property
Does map to the actual underlying physics, you know, that's happening as well. This is almost a
Big step up from that. It's like, you know, it's a generalization to a much richer set of
I don't want to say conservation laws, but a much richer set of these
Flow laws, you know, absolutely and dynamics. Yeah, that's exactly the right way to think about it
In fact, it what's transpired over the last few years is that really you can think of the free energy principle as a kind of
generalization of the second law of thermodynamics to open systems
So, you know that the kind of universality that the second law
Has with respect to closed systems
the free energy principle has with respect to systems that are far from equilibrium and as Carl has, you know
Pointed out the Markov blanket is precisely the apparatus that allows you to move from the equilibrium to the non-equilibrium
regime in the sense that you are now specifying the
Interface through which the system is coupling to its environment or the particle. So the word system is a bit ambiguous
Usually, you know, because we could mean, you know, the whole in agent environment system or we could mean
The specific kind of compartments that we're considering is agents
Yeah, so the
You can think of the the free energy principle as applying to
Systems that are not at equilibrium and as giving you the dynamics of like particles within the overall system
If there exist particles in the system, if there are these things that you can poke and re-identify
Over time, right, then the free energy principle will basically tell you how they behave
Yeah, and it's it's interesting because almost the Markov blanket really provides a concept of
stability because when I think about equilibrium, right when when I'm
You know the thermodynamic kind of equilibrium what comes to mind at least visually to me is things that are kind of
Unchanging and just kind of quiescent and they're just sitting there like a goo
You know, that's kind of all thermally stabilized and never never moving around
But that's the point the key point there is stability
I can say it's a stable sort of unchanging system and what the Markov blanket gives you as a way of defining a
Property that's stable about the system and yet the system as a whole may be far from stable
It may be in flux and moving around all the time and jiggling
It's the eternal flame where the boundary is, you know kind of changing all the time
But there's this property that you can map from from time to time that that's still there and so it's the stable
The stable blanket even though it may have a different form
It's still got a boundary between some stuff that's inside and outside that's identifiable
You know from frame to frame if you will yeah
And I'd I'd go even further and say that it's the self identical pattern that you see at all scales of self-organization
So it's got this kind of fractal quality to it where you know the it's blankets of blankets of blankets of blankets
So I mean you can think of the brain for example, so the brain has this nice Markov blanketed structure
At several different scales, so you can start with neurons and neurons have their own
Markov blankets that yeah, they are membrane
Yeah, precisely, and it's probably the most obvious, but you can go downwards in scales and upwards in scales and what you recover
are
You know similarly Markov blanketed structures, you know from the the from the voltage gated channels
on a cell membrane to dendrites
to the you know arbor essences that form up to the the
Neurons Soma and then you know
You could go the other direction to right from neurons to canonical micro circuits
to
More specialized brain regions to brain networks and so on all of these things are things
They can be reliably re identified with their own kind of
Properties and features and connectivity to other things
And they all have this same pattern that repeats and so it really is
Yeah, so and and I think anybody can see that pattern, you know, I mean look around we got we have trees
And they have boundaries and you know, yeah, even higher in scale
You have planets and galaxies and but at the same time if you if you dig down into it and you try to really
Precisely define it then it it slips away. It's like if I zoom into the surface of my skin, you know fine enough
Well, it's no longer a surface
It's this ragged thing with cell membranes and then the cell membranes are molecules with tons of space
You know in between them and heck atoms, you know are mostly empty, right?
Like there's this this weird, you know vagueness and difficulty in defining, you know boundaries
So they're not sharp like how's the concept of of a Markov blanket? How does it evolve to that kind of?
Fuzziness or that's a great set of questions. Your questions are still on point
This is a so I would say the
The first thing to say is that so this is sort of mind physics or brain physics if you want to think about it like that and
One hallmark of explanation in physics is simplification or you know, you might say over simplification
So I'm sure I'm a biologist reading a paper on the free energy principle might look at this and go
But you know, this is way too oversimplified. Where is the biological detail?
I
Think physicists also do this to physical phenomena, right? Like that's that's sort of the joke a physicist would respond
Yeah, but we do that to physics as well, right? Like it's
So, yeah, there is a deliberate idealization going on if you define this Markov blanket strictly as the the set of degrees of
freedom that render some in inside
Independent of the outside, right?
So if conditioned on the blanket states, you can speak of statistical independence between the inside and the outside
Well, that that is too strict to describe most physical systems, right?
So I assume you myself and our listeners. We all had a bit of coffee this morning. We've all used the washroom
So there's clearly a kind of permeability exactly that there's really a kind of permeability at play
and so
Yeah, we we know that there is material turnover in most of the kinds of systems that we find interesting
Especially those that self-organize far from equilibrium. So the mark. I'll blanket is necessarily
an idealization
Having said that there are good reasons to think and we have some results coming out
Later this year. A lot of them are due to our senior mathematician Dalton Shakti Vadi Vell who is an absolute dynamo
So we have seen I've seen some of his papers. Yeah, it's very impressive stuff
He's been working on weak or fuzzy blankets
In precisely this context. So the the idea is can we get really rigorous about the
mathematics of approximate Markov blankets or fuzzy Markov blankets and
The idea in a lot of his work is to construct this this quantity called the blanket index to gloss over some of the
technical details just for in the interest of our
audience
basically
They're in if you consider a given
Dynamical system there exists a Markov blanket in that system if a specific inner product is equal to zero
so in particular, this is the the Hessian of the and the
Solenoid oil flow the the product of those two things being zero what it basically is a way of
Quantifying the the force or the curvature
that a system is subject to and
Yeah, if the entries in the center product are zero then there is a strict Markov blanket
But there's a way of constructing an index or a measure such that you can accumulate the non-zero entries
And basically quantify how far from perfect blanketedness a
system finds itself
and so
Yeah, this blanket index has a number of interesting properties
One of which is that it it it tends to zero as systems increase in size
Hmm, so I know what kind of assumption so
It's very very very general
So I locality assumption or yeah, you get the locality stuff from from the background, right?
So you get the rest of mechanics going, right?
So, okay, okay, so then you already have like, you know relativity in the background
statistical mechanics classical mechanics and all that stuff. So yeah
You do get this kind of nice locality
So that's interesting. So in in a universe like ours that has the the basic physics that the universe like ours has as
The scale of a system gets larger and larger
You you generate Markov blankets, you're bound to with the probability one. Yeah, absolutely
Fascinating and you know, most of the systems that we consider in physics are large in the appropriate sense, right?
So think about how many molecules are in in the drop of water, right? It's 10 to the 26
Some some something times Avogadro's number. Yeah, exactly. Self is 10 to the 23rd. Yeah
Yeah, so the 10 to the 23. Sorry. Yeah, so that's just for a single drop of water
Now as you consider the brain, the brain has like something on the order of a hundred
150 billion neurons
Each of which make thousands of connections if each of those connections can encode a parameter
Then you're talking about like a very large system, right? We're way way way beyond like, you know, 20
51,000 different states that that are coupled together. We're talking about like billions and trillions of different states
So there's reason to think that just due to the physics of the situation
most relevant things that we might want to consider will have Markov blankets and
I mean
So Dalton is going to be releasing a few papers having to do with large fluctuation theorems
Okay, and so this this let's pause for a minute and appreciate this because this to me is a fascinating a
fascinating result so
Okay, so we start from the point of a Markov blanket is kind of this intuitive concept, right?
Like it's you know a boundary and and that sort of thing, but there's no reason to believe that they're
Inevitable and I'm finding it
Fascinating that there's that there's this work, right? That says that as a scale and so we have a measure of blanket
It's kind of between zero and one zero has a blanket one doesn't okay
And and yet as the scale of the system gets larger and larger
Blanketness approaches, you know zero you get blankets no matter what and in the sense there's a sense in which that's
Recapitulating what we see if we just look around like everybody out there listening look around yourself and you're gonna see
Blankets all over the place. You're gonna see things and those things have have boundaries, right?
But it's it's remarkable, right that that there's a mathematical proof that that's inevitable
In this sense, isn't it? Well, I think it's remarkable in part because we have approached
The question of self-organization and emergence from a false starting point
So I've been going around saying recently Aristotle was wrong
That's that's my philosophical start man
Well, the hole is much less than the sum of its parts. It turns out
So yeah, there there are a bunch of things to unpack from that. Well, the first is that
What makes you the kind of thing that you are is the sparsity of your coupling to the rest of the world, right?
If you think of a gas, right?
Everything is coupled to everything else and it's just this fuzz and it's all one system and there's there's no you can't really
Identify particles within the system
Particles or things are defined by their sparse connections to everything else. So I am in some sense what I am not
Or I can be defined in terms of what I'm not connected as opposed to what I am connected to
I mean, if you were to create like a giant adjacency matrix for the entire universe, most of it would be empty
Right. No, I get that you're saying the hole the hole is less than some of the parts
Which is there's more if you if you get rid of the parts you have you have less, right?
and but but there's more
the
So think of an engine right like an engine functions as an organized hole
Because you're constraining its parts to behave in very specific ways
So like, you know, if you think of an engine more specifically like a petrol engine
Well, the the mechanical effect of the engine you get by, you know
Moving these pistons in a specific, you know
Direction up and down and the best way to wreck your engine is to introduce new degrees of freedom into it, right?
I would not want to introduce new degrees of freedom into the pistons
So that's a great way to just tear your engine apart and I would submit to you that this is
You know an accurate way of thinking about all self-organization
We exist as holes because our parts are constrained to behave in very specific ways
So it's not merely that I am what I am because I am not what I am not
Just a nice tautology
It's that the what makes me what I am is the way that I remove degrees of freedom
From my parts such that they conspire to create, you know to generate me as an overall pattern
So, I mean, it's it's counterintuitive from the perspective that we inherited from, you know
traditional Aristotelian
metaphysics, but I
Mean, yeah
It's so exciting
I don't know. I don't know why I get excited but to me it's it's really excited and this I mean
So this is work that's coming out of verses, correct? That's right. Yeah, that's right
Coming out of yeah, I would say
Coming out of Carl Friston's group more generally and let's not forget, you know, Carl proposed the free energy principle in the middle of the
2000 knots
and so yeah, but definitely this is
the the powerhouse behind
Versus AI technologies
So yeah about that for a minute because um, yeah, we generally don't talk about, you know
Companies on the show, but this to me, this is an exception because it's fascinating what you guys are doing. Thank you and
So versus versus technology is trying to operationalize
This understanding really and this is correct as technology and I guess and I'm super excited by
What we've been talking about conceptually, but tell me why shouldn't they care like what does this?
What does this fascinating?
You know view of philosophy and mathematics and the relationship to really I think it's really about understanding
Complex systems and in a new way and new mechanics of complex systems. What does that mean for us?
What does it mean?
technologically
Well, thank you for your excellent question
So I think what one of the things that we want to do at versus is to apply active inference to artificial intelligence
So active inference is basically the kind of machine learning that follows from
Adopting the free energy principle as your kind of core method
Our contention at versus is that active inference will be to the 2020s
What reinforcement learning was the 2010s effectively, so it's going to be we think the way of doing
machine learning
Be ethical scalable if most efficient way of doing machine learning
And there are a lot of different
aspects to that
so
one of the main differences between
Artificial intelligence built on the principles of active inference and more traditional approaches is that we start
From an explicit generative model so-called
So we talked about the Markov blanket
The generative model is another core piece of the free energy principle
puzzle or
Constellation if you will and the generative model is basically
are a
Statistical description of the dependency relations within the system that you're considering
So when we're talking about Markov blankets
Actually, what we're saying is the generative model of the system contains a Markov blanket, right?
So all of these dependency relations that we're writing down
Like once you do write them down you get this nice sparseness structure where some parts of the system do not affect
other parts of the system and
So yeah, this this generative model is really key to the doing of the free energy principle
and so
Yeah, what we do in active inference is write down generative models
Explicitly labeled generative models that then allow us to you know perform inference
They allow us to do that because the
variational free energy that we were discussing earlier
basically the the the
Gradients of the free energy that you're following they come from this generative
basically
so
Yeah, the the model itself is this explicitly labeled structure and this is where you get like a huge
explainability
Advantage we actually have a paper that came out on designing
artificial intelligence
explainable artificial intelligence using active inference and
Yeah, what what you get just immediately from flipping to an active inference framework is a way to write down
Yeah, generative model such that it is explicitly labeled and thereby auditable by human users and stakeholders
So you don't have this
unlabeled, you know 10 trillion
Parameter net as it were right, which you have instead is
Yeah, a model that explicitly represents all of the different factors in the situation that you want to control
So let me dig into this. Let me dig into this a little bit. So
And I because I'm curious there's a connection here to some some work
I used to do a long time ago. So writing down generative models. My experience has been at least is
It's it's actually relatively easy to do that. So for example a long time ago
I was contracted to do some work on mad cow disease. So we could try and figure out
What interventions to do to reduce right the spread of mad cow disease and it was pretty pretty easy to
learn about the
The food system the supply chain the food system to model, you know, the processing of
Cattle and that sort of thing and write down a large simulator
So this would be a generative model can sit there and can generate
Trajectories through this space, right? Like we knew we could do that
We couldn't tell you anything about the large-scale kind of thermodynamics of the system or anything, right?
We could write down this generative model though and then using, you know, various sampling and techniques like that
We could then
Compute statistics from it try out interventions see which of those had had kind of a beneficial effect
But that was all ad hoc, you know, architecture that we we designed and produced by ourselves if I'm understanding you
correctly
What you're doing is producing a technology that one
Formalizes that much more and applies the free energy principle
I think to help guide like the sampling and the optimization and you know, really just the effective use of these kind of generative, you know
simulations and models
Is that
Close to what you're talking about. That's right. So, I mean you can why use active inference
It is demonstrably the most efficient machine learning technique
So it's sort of like, you know, a car no cycle analysis, but for for an engine but for AI
in particular
What the free energy principle
Allows us to formalize is the thermodynamics of information writing on to the boundary
so in in some of the newer work on
The quantum information theoretic formulation of the free energy principle
Which we don't necessarily have to get into in detail, but
There are these kind of new scale free extensions to the free energy principle that have been developed
That appeal to the tools that have been developed on in quantum mechanics, right?
So the theory of very small fast things, but quantum information theory
So the kind of information theory that gets augmented to handle things like probability amplitudes
Which are the the roots of probability densities and so you can get your wave equations moving
in place and all that so the
That formulation of the free energy principle allows us to formulate the computations
Carried out by a system in terms of like a per bit read and write cost
So there's a there's a there's a sense in which like you're you're bringing it down to the like to the
the bare kind of you know
machine elements of
Of your computations and you're you're writing things down in a way that is demonstrably the most efficient way of doing it
So if you if you set up, you know some simulation system using active inference you are
And this kind of brings the conversation full circle in some sense
You are generating a model that is as predictively accurate as possible
But also that expands as little energy as possible due to this, you know, controlling for the
complexity of the model so
Yeah, we we have this
this pre-print up that will be revising soon
Called the map territory fallacy fallacy, which is precisely about the kind of canonical nature of
FEP theoretic modeling
Yeah
you know the
One of the reasons why
The FEP is optimal
Is that it's it's another way of writing down janes's maximum entropy principle
So for our audience
The maximum entropy principle
You can think about it from from the point of view of statistics and also from the point of view of statistical mechanics
From the point of view of statistical mechanics, the maximum entropy principle is the principle according to which things dissipate
Um
So from from the point of view of statistics, it's the principle according to which give me a data set
And a set of models from which I might have sampled that data set
The it says the model with the highest entropy is most likely to be the
The real model from which you sample. So, uh, that's a way of kind of saying like what is the maximum entropy probability density?
It's a flat density
Right and so basically a maximum entropy probability density encodes no information
Because all of the outcomes are equally probable
And in some sense what occum's razor would tell you is that like you would want your model to be as flat as possible
Right, you want to build in as spread out as possible. Exactly
You want to build in as few
Assumptions as possible into your model. This brings it back to the whole keeping your options open thing that you were saying
You were discussing earlier, you know, if you're thinking of a probability density over different courses of action
Unless you're really sure that you want to do this. You probably want to keep things
As non-committal as possible and keep your options open
so
The just to back up then the free energy principle is a is a way of writing down
The principle of maximum entropy
They are effectively the same thing
You can move from the one to the other
And we know that the principle of maximum entropy is is is the principle of parsimonious explanation in some sense, right?
So if the fvp
And maximum entropy are the same principle then all of the epistemic virtues that accrue to maximum entropy also carry over to the fvp
and therefore, uh, yeah a a free energy principle theoretic model
Of the belief updating of a particle can be shown to be the optimal dynamic systems model for the whole system that you're considering
Like there is a kind of canonicity
Uh, what we're calling janes optimality that yeah the basically the fvp
It allows you to write down the best model that you could for your the system that you're considering given your current state of knowledge in that system
It's just the optimal way of writing that down full stop
So that's why we you know care about active inference
Yeah, it might be useful to give you know some examples of um
Of you know maximum entropy distributions to understand so for example
If you have a data set, um, and let's just suppose it's
Continuous, you know data and it's and it's positive only so I know that it's continuous data
It's positive only and I know that it has a particular mean
you know
Then the the distribution that has the maximum entropy under those examples is an exponential distribution
Right like it's it's sort of spread out as much as possible
Um, and yet it has a particular particular mean and and and for example if we go to the case of
It can be a real number anywhere between
Minus infinity and infinity and it has a mean but it also has a finite variance
Then you wind up with the Gaussian, you know distribution as being you know the maximum
So it's really it's it's a distribution that captures what you know about the system
I eat the constraints right and yet is as spread out as it's possible to be
While satisfying those constraints, right? Yeah, absolutely
And and you know, I hope our audience is able to kind of see the pattern
It's starting to form here, you know, uh like all of these connections are non accidental, right?
So the the FEB is all about balancing your predictive accuracy and complexity
So all these things are kind of connected at a deep level
Uh
And yeah, I mean maybe the audience also can see why we're so excited about like this is highly non-trivial
Well, no and and I don't know if this is crazy or not, but it it actually even seems to have implications for
fairness of models because so for example
Suppose I'm trying to train a model that
Does anything of human interest, you know diagnose
Or prescribed medical treatments or you know, give out give out loans or that sort of thing
And and we need to train it on some type of of data whether it's a generative model that we calculate
Or data that we actually observe
Well, we want we want the system we want the machine to learn
Only what's relevant for that particular
Task and like nothing else, you know, we don't want it to to learn kind of
Extraneous things. So for example, if it's deciding to hand out medical diagnoses, we want it to be based solely upon
the medical attributes that are in in the you know, the data set and not some spurious
You know correlation to like a the geography or you know, where you came from or or um
The letters in your name, you know of your file or anything like that. And so in a sense, um
What maximum entropy helps you to do is force out that stuff because
That stuff if it's not useful for the actual prediction
It'll get, you know ironed out because it's smoothed out by the demand of maximum entropy
That's right. And and that brings us back to sparseness
right
How so tell me well in the sense that um, you know, this this even has to do with like situation or task definition
Like situations are sparse
They're not all not everything is connected to everything not everything is relevant to everything else
So there's even like a kind of it's really a kind of a meta
methodology because you you can even define specific situations in terms of their sparseness and then
You know, yeah
so
So it sounds it sounds great, but I'm always the eternal skeptic because I know
A lot of this type of computation, you know, the the generative starting with a generative model doing inference on it
just computationally is
So difficult like what what is the magic?
That versus is found and and how are you so sure that uh, how are you so confident it's going to work?
great question
So, I mean in particular one of the big questions that
Plagues generative model based methods is where do your priors come from right?
So what is the structure of your model?
What are the parameters that you're using? What's the relevant state space all of that?
Is often I mean often you have to hand design this stuff and it's very labor
intensive
So at versus we are a uh a contextual computing company
So we draw inspiration from the architecture of the brain
uh, and uh, basically we're proposing a kind of general
Uh standards based solution to the problem of where do your models? Where do your priors come from?
um, so just to uh, uh, you know do a crash course in neuroscience
um
So, uh, we love neuroscience here. So please do. I'm sure well, so a source of inspiration
I'm sure everyone is familiar with the idea that the brain has a layered or hierarchical structure
So it's not the case that the brain is just a soup of connections where everything connects to everything else
um
To the contrary there are very regular structured patterns of connectivity
In the brain. Um, again, this takes us back to the theme of sparseness, right?
Like the to say that the brain has a hierarchical organization is to say that it evinces a specific
Very special kind of sparseness where connections
Are directed in specific ways where you're connected to layers immediately above and below you but nothing beyond that
um
So we've spoken in the past to jeff hawkins
Like is this related at all to the concepts of cortical columns and like the way in which they're
Connected like it almost has these, you know components that are reused and absolutely in terms of different layers
Uh, yeah, uh, that and not all the layers speak to each other
um from a uh an active inference perspective this layered or uh level
Level involving structure has a specific purpose. Um, so what each level is doing is providing priors
Uh, or expectations to the level below and receiving context from the level above
And uh, what each layer is doing in turn is shuffling prediction errors to the to the level above and receiving prediction errors from the level
below
So what what you have is basically a set of layers that contextualize each other
And the way that each layer contextualizes the next one is essentially coarse-graining
right, so, uh, there's some fast
fast small scale activity
The lower levels are tracking closer to the sensory end and what each successive layer is doing is finding basically the the
Set of hidden states or latent states
That explain variance in the data that it's receiving and and so on in this kind of hierarchical fashion
So the the brain is not one monolithic system
Rather, uh, each layer of the brain is specialized in encoding specific features of the situation pitch that a specific scale
And it functions by kind of providing context. So we like to say that the brain is an organ of context effectively where
Uh, really what it embodies is successive layers of context that are each coarse-graining each other in this kind of fashion
So I know I I know
Our neural network fans out there in the audience are gonna they're gonna be hearing that that's just what a neural network is like it has kind of layers
You know, they're connected. What's what's different about just
Any other, you know, kind of neural network
Architecture, if you will so what we're proposing is an infrastructure project in some sense
We have uh, we're working with the iEEE
In the us and so when I say we
Versus that has a sister
Organization a non-profit called the spatial web foundation, which was uh, to whom we gifted
Uh, the the first massive chunk of research that came out of our group
Um, and what we are developing with the spatial web foundation is a set is a set of public standards
Uh, that people can use to build out
Uh, basically shared knowledge graphs
So we're building an ecosystem where uh, folks can basically
Think of this as sort of like wiki data or wikipedia
But for kind of shared contextual compute context
So, you know, obviously, uh, we are building this out
So we're going to be the first to put things onto this network
But what we're trying to build is basically a spatial web or a hyperspatial web
That kind of in some sense reflects the structure the kind of graph structure
Um of the the various kinds of situations that humans, uh deal
I got it. So it's so it's really an application of of
Interesting, so it's an it's an application of the free energy principle at multiple scales. Absolutely. Okay. Okay
My mind was going in the wrong direction here, which is I was going to like the scale of of uh,
You know the individual thing and and and how it does it's it's modeling its compute, but this is this is more than that
This is well, it is that you're absolutely correct, but it's more than that. It's it's that and it's and it's actually like
a multi-scale
I guess arbitrarily nested really uh framework for communication across absolutely
Not it's it's more than a mesh. It's um, what's the right word for it's a hypergraph. I guess it's it's a hyperspace
a hyperspace we we call this the you know the the name of the
Protocol that we've developed
For modeling is called the hyperspatial modeling language hsml
It's it's meant as a an homage and a nod to uh h html
And uh, what we hope it doesn't use the same syntax, please
No, no, well, um, well what we've also built is a transaction protocol and a querying language that
Live within the hyperspace so so called the hyperspace transaction protocol hstp
and the hyperspace hyperspace querying language hsql
And so yeah, what we are basically in the business of doing is on the one hand building out these graphical models
Of knowledge basically of the knowledge that is involved in specific tasks domains and situations
And then we've developed methods to take these knowledge graphs and to flip them into graphical models of inference
So that's really that's that's kind of where the the the secret sauce and the magic happens
Is that this is a two-step process and the overall versus technology stack combines
active inference based ai with explicit generative models on the one hand and this kind of nested
hyperspatial representation of the problems to be solved on the other
And the the technologies kind of are married
through their kind of reliance on
On graphical techniques basically so it's it's knowledge graphs meets graphical inference
in a nutshell
yeah, and
we
We really are committed to developing these in terms of
You know open publicly available standards
You know, there's a lot of as I'm sure you're acutely aware. There's a lot of um
You know hype and demerism
Going on right now
With regards to ai there's a lot of I think maybe uh over inflammatory
You know demerism and over utopian hype going on
And in terms of you know the different options that we have to
Develop these technologies in a responsible way that there seems to be one call for you know government oversight
Which is interesting that comes with its lot of limitations. For example governments are limited to their jurisdictions
And so, you know, you can't uh, you can't coordinate an international community of research and development in r&d
merely through
national regulation
So that's limited on on the other hand you have, you know, uh markets
And companies that want to you know solve these issues in house
They are maybe faster and more flexible, but there is this necessity of you know, how do you how do you constrain the activities of
Corporations in such a way that we develop these technologies
Responsibly ethically
transparently in a manner that's audible and that's uh, you know
acutely aware of and sensitive to the potential harms that might be caused by these technologies
So what we are, uh proposing is a kind of third path
A middle way not to say that we shouldn't pursue, you know, a private
Development of these technologies and regulation. I think this is all
You know a great idea. Uh, there's some interesting, uh legislation coming out of the eu
Uh, the ai act that everyone is talking about that I think are interesting paths forward
but a to really, um consolidate the international community around these technologies we have proposed a standards based approach
Um, and the the iEEE group, uh where the standards will be housed
Is an open group
Folks from anywhere can join
We have some pretty high-profile corporate partners
But the idea is to build these technologies in a manner, uh, where we avoid silos basically
And where we can kind of coordinate the entire world's
Technological and intellectual prowess towards solving these, uh issues
So I think the um and and yeah, there has been
Definitely, um, uh the threats of ai the the risk of ai have been uh quite quite heavily
Discussed um as I think with good reason listeners
Yeah, well, and you know, I mean recently we had a show about this and I was uh pillory, you know quite a bit
Uh in the comments because my my role is uh
Devil's advocate, but I mean I I mean for me personally I see the damage of of ai
Happening right now. I mean, you know, we have when you have kind of um, let's say social media algorithms that have been highly engineered
And optimized and no small part by by machine learning to suck up everybody's attention, you know, it's
Even before well before we get to the the possible point of
Of super intelligence, you know in in a general sense
Uh, it's already damaging right and so and and I personally think the path forward are
openness and transparency and making sure that that the good guys, um
Uh that it's easy for them to do the right thing and so I think I think like approaches like what you're advocating for
The right way to go. I mean for sure. Thank you. Thank you. I'm going back in the bottle
It isn't and um, I think you know, you you said that all the right words transparency
I think is is more than just um
transparency in the decision making of stakeholders and parties involved in the research and development of ai technologies
In our case, it really means the transparency. In addition, it means the transparency of the models that we're using
Right. Um, so, you know, one approach one approach to training up ai systems might be
You know give ai uh access to extremely curated data sets so that it it learns only the right things
You know in extremely like controlled settings
There's reason to think that that won't generalize easily
Another thing that you can do is to equip your system with the capacity to form inferences about its its own inferences
Uh and to evaluate itself with respect to you know things that we value
So you could for instance design an ai that had an explicit notion of like discriminatory bias
And then train it to identify
discriminatory bias in data sets for example
And you know, uh, you can use active inference technologies to allow the system to access
And report on its own inferences
Well, I mean, it's it's even more general than than that. I think I'm understanding it correctly because for example
You have these nodes right in this in this um hyper space
Yeah, you know, you have you have all these nodes in there and and you can learn for example that say a particular node
Uh is is racist, you know, like it'll it'll give you great answers to a particular question
So long as it doesn't think you have certain, you know
demographic characteristics or whatever and then it gives you like, you know bad answers well, then you can
The network can learn how to mitigate against that it can learn how to you know, compensate for the biases like
Inherent and in nodes so not in particular actual algorithms
Yeah, exactly. And you know, the algorithms that we're using are based on explicitly labeled generative models
So these are systems that can be audited by third parties
Right, right, right because everything is labeled explicitly, right?
So like you you can really calculate the incidence of this or that node on this or that part of the inference
And it gives you a kind of tractable
interpretable
You know auditable method of constructing systems
Such that you understand what went into the decision-making process
I said earlier that my suspicion
Our wager is that active inference will be to the 2020s. What uh reinforcement learning was to the 2010s
My my gut tells me that if legislation the legislation that that they are
You know writing up in the u.s. And in the eu
goes through
It may be that active inference will be the only set of the i technologies that we're allowed to use
in the sense that
you know
Neural nets as they're used right now are black boxes
They're not explicitly labeled and they are built
To be black boxes like the they are not
Built they're not designed to be interpretable the the kind of uh, you know these kind of privacy security
Issues issues around confabulation issues around, you know the the
Uninterpretability of these models. These are not like bugs
In some sense. They are features of the approach that we're using to design the systems
You're not using an explicitly labeled model. There is no way to render this tractable post hoc
Whereas if you start from an
An approach that you know, it's it's explainable. It does what it says on the tin
Then you get around these these uh, these issues
Through your choice of architecture in effect
So, you know, I I think there's
You know tremendous
ethical import
To the the manner in which we're designing these systems
We care a lot about ethics and verses as we discussed my my phd even though most of my publications are in computational
Neuroscience and kind of theoretical biophysics. You might say like my phd is in philosophy
We have a lot of properly trained ethicists really at the core of this team and we take these things really seriously
Adverses so there there's no accident here
And I really think that active inference
Uh
Plus the standards-based approach
Is how you're going to get something like responsible scalable ethical AI
Okay, so and so far i'm on board with everything everything i've heard
I have a question for you though, which is if it's all open
And and ethical and you're trying to do the the right thing
How exactly is that profitable like what you know, what's going to keep the the lights on it versus
Well, so we have our own in-house implementation of hsml
So, you know, we uh, we are providing the standards so that anyone can build a version of hsml
We're providing the kind of core infrastructure
For uh, you know domain registry and this kind of stuff
But we also have you know very advanced highly engineered and developed versions of these things that can actually do things
um, so
Yeah, uh, yeah
I mean, uh, you can think of uh, you know red hat and the linux foundation as a kind of similar
Aspirational model right so, uh, you know red hat do generate a profit from a commercial point of view that
The linux is still open source the linux foundation is the open source custodian of the linux operating system
And yet they are able to operate
Our contention is the our stack is organized in a similar manner where uh, the spatial web foundation is the
custodian of these open standards that we are, uh, you know
distributing
hoping
Everyone will widely adopt them and we are the more kind of hard-nosed
Kind of architects who know how to build things using these tools who for having built them know how they they work
And you know, we are probably at this point
I mean almost certainly the world's premier active inference research and development group. So, uh, there's a whole powerhouse
of you know
Well, there's a lot of great academic papers that
That uh that come out there. I mean, you know, I know tim and I have enjoyed
I'm looking at uh, you know quite a few of them. Um, well, thank you
Yeah, you mentioned uh, Dalton, you know earlier. I mean, you know, there there's an example of some some very refined
And and quite deep philosophically and mathematically, you know papers, right? Well, we have basically hoovered up the kind of core
Uh, luminaries of the active inference tradition as it stands currently. I mean, carl friston himself is our chief scientist and
Joining us, uh in an increasing capacity over the next few years
Uh, yeah
So when you combine that with, you know, I I'm fairly
well known in in the field, uh
Yeah, we have really scooped up like, uh, you know, the lans de costa
Connor hines brennan kline
a mal albarasen
there's a
It's it's it's pretty. Um, sometimes it's a little bit
Uh, I guess the lunches must be must be interesting there, right? Yeah, absolutely. Uh,
Yeah, and I mean, um, this was this was my dream, uh, you know back back in academia to
Have a centralized research group with with all of this talent able to like work together and yeah, uh
We're definitely doing some interesting stuff and at you know, at versus we are committed to uh, continuously also contributing to
The public domain and open scientific
Publication as you said, you know, we're we're a fairly productive
research group, uh
We published a few dozen papers last year, for example, uh, you know, so we uh, I think there's a way of
striking the balance between
Contributing to an open community of development having an open core and this kind of thing on the one hand
And also being able to continue existing as a profit-generating entity on the other
Uh, but really the I think the the key strategy is this open core
Right. So like have the standards open. Yeah, make sure that everyone can contribute to it
Like, uh, you know, and there is a kind of selfish dimension to it as well
Because then we are able to harness the entire power of the the intellectual international community
Uh
To build this uh stuff out. I think that yeah, there there are there are certainly some advantages
Uh, we also, uh, for instance, uh, maintain and contribute to the pi n dp package
Uh, which is a python package to for, uh
Partially observable mark-off decision processes that power a lot of the active inference technology
So we use that as our core
Um, and it's uh, it's on an open, uh, license
So anyone can just, you know, download these packages go to the github
And use it. So we're trying to build these technologies such that
You know, everyone can start to use them. Uh, but we definitely have, uh, you know, some key
Uh, differentiators and I think a pretty, uh
Pretty unshakable market advantage
Uh, well, so so speaking of market advantage, let me, um
Ask you about this question, which is
Uh, as as you know, we've had we've had, uh, professor fristen on the show a couple of times
We talked about the free energy principle a few times and and there seems to be, um
A lot of uh, let's write what I say this, you know
Misunderstanding or even negative press, you know, if you will not, you know around the free energy principle, right?
Like like just kind of push back against it as either
Something of of of trivial trivial interest or, you know
A a tautology that's that's of no value and we talked about some of this too in our in our intros
So like what if any what do you think the biggest misconceptions are
About the free energy principle and or
Act of inference that that really acts, you know, potentially just intellectual barriers to the adoption of the technology
And this is your paper. I believe is, you know, the map fallacy
fallacy, right, which is this
this enduring kind of, um
difficulty in understanding that
A system can can follow these dynamics. Okay, it can it can
It can behave as if it can behave as if
it has
Beliefs right about the world and a model about the world and it can behave
In those ways, um, and it's okay to point that out like it's okay to say yes
This thing is behaving as if it has beliefs. I'm not literally saying that it's like a conscious mind
You know that has has beliefs. What we're saying is that
If it continues to exist, it must have have these behaviors so that it doesn't dissipate into equilibrium
Right, so like your finger on one of the products
Yeah, I think that that's really
Maybe the the the most
Important confusion that people have is they think of the free energy principle as some part of like philosophy or metaphysics
But it's not metaphysics. It's just physics. It's physics physics
Uh, it's mathematical physics in some sense. Uh, so, you know, uh
This isn't really a statement about the way that how how things really are in some kind of deep
Kind of philosophical sense
It's about how we can come to know them given the kind of the kinds of modeling tools that we can deploy
Uh, you know, so it there there is this kind of deflationary aspect to the free energy principle
Like it it is a way of writing down
Canonical models for the dynamics of systems that we find interesting given our state of knowledge about it
It's it's not it's not necessarily going to tell you about the ultimate nature of mind or something like that
Unless you take a super deflationary approach and you think that physics in at the end of the day
We'll be able to tell us everything we need to know about the mind
Uh, so yeah, what what makes this do you think that?
um
Yeah
The the the physicist in me wants to say yes the philosopher in me wants to say there are still a few issues that we
need to sort out
Like, uh, you know, where does consciousness come from but we're working on it again using the free energy principle
I think one of the things that makes this difficult is the the free energy principle
is um
ontological so it's about
things
But it's not
Metaphysical in the sense that it's not about like these fundamental philosophical principles
That tell you about thing this it is a it is a theory of
everything
Without being a theory of everything. Do you see what I mean? Um
Right. Well, I think you hit upon this earlier, which is um, I don't know if it's the only example
I but as far as I know it's the only one I know of an example that directly ties
physics to
To inference or to you know, belief updating like this. This is the first example that
That that I know of so like you just said, you know, it is it is a physics
principle and it just so happens to correspond to
Bayesian updating that's right. Absolutely. Yeah. Yeah, or approximate Bayesian variational stuff
Which is to say basically the same thing. Um, I'm I'm being a bit cautious here because I don't
for those of you who uh
In our audience follow me on twitter. You'll know that I have
To put it diplomatically some reservations about some of the recent literature
That's been published on the free energy principle. I think a lot of the issues with the literature is sociological
um, it's you know, and
It's difficult to talk about this without seeming like
you know
a bit like
deprecating or
negative, but like a lot of this work was
Written, especially the critical work was written by early career researchers
um, who did not necessarily have the
formal
Familiarity with the free energy principle that might have been required. So I mean look
For example, um, I I heard a lot, you know circa 2017 2018 2019
you know, uh
People say well, you know, the free energy principle can't be true because uh, some systems maximize
Their entropy, right? They they move towards more entropic states
uh
Now from the from the perspective of our conversation that might seem nonsensical because we've just spent like, you know
About an hour and a half talking about how the free energy principle is a way to write down maximum entropy
But um, yeah, the the the free energy principle says something very specific
Right, it says that if I maximize the entropy of my beliefs then I can keep the thermodynamic entropy of my physical states at bay
But these kind of sophisticated kind of hinge statements are not necessarily fully appreciated
So it can lead some people to right just say false things about the free energy principle
Um, well, you just you just made another statement that I don't I don't know that it's hinge, but it requires
Paying careful attention. You said something to the effect of you know, the free energy principle
Is a theory of all things, but it's not a theory of everything
And and I think and the way I interpreted you there was to say that like
The free energy principle applies to all things, but it doesn't necessarily tell you everything about all things
That's right. Right. Is that is that what you meant?
Yeah, and um, you know, like, uh, I think that there there are some states in the fairs
uh
That are just not
That are not directly free energy principle adjacent
So I still don't know why you know the so-called hard problem of consciousness, right? Why does
Red feel like red? Why does a middle C sound like a middle C?
But it also seems to act as a kind of lightning rod that can get attracts, you know
multidisciplinary criticism
Let's let's say it that that way and in fact, um
You know, so we we over the course of it's kind of studying up on the free energy principle
You know, we've we've read critiques, right?
Of it, you know, so for example, um those by Beal and and others and I'm wondering like what you think about
The criticisms of it, you know, do you do you find validity in them?
Do you find do you find the quality of the criticisms to be good?
Has has the FEP just moved on from it? Like what's what's kind of the state of the art if you will of
Of criticism of the of the FEP. Well, the first thing to say is that we appreciate
the critical engagement
That the free energy principle has received and you know, like any good scientific framework
It stands to benefit from serious
adversarial engagement
Uh, I think the quality of criticisms varies quite widely in the literature
So to take the example of you know, Beal and colleagues
Uh, I I think the paper you're referring to is a technical critique of some parts of the free energy principle. Yeah
Uh, it it was a very I think important paper when it came out. Uh, it pointed out some of the um inconsistencies
Uh in the way that the free energy principle had been formalized circa
2012 2013 or so
um, and I mean since then, uh, the mathematics has been
Corrected. Um, and I think we've moved uh beyond the criticism. I I have this directly from martin beal himself
He says, you know, my paper the the lesson to draw from this paper is that you should incite
Friston's 2013 paper life as we know it to make claims about the free energy principle, which is fair
Um on the flip side, I would say that we have moved
Beyond the formulation as it was as it stood in 2013
One thing to keep in mind is that uh, so the f.e.p. Is sort of like brain physics or mind physics depending on how you want to think about it
And uh physics and mathematics have a strained relationship
That I think is important to think about so, um
The history of uh, you know developments in physics often, uh goes as follows
A physicist, um, you know borrows some tools from mathematicians more or less, uh, you know rigorously
Applies the tool to explain a bunch of interesting phenomena
Uh, but then that leaves mathematicians wanting. Um, so for example, you know, uh, the dirac delta function
Uh was introduced in the context of quantum mechanics
Uh, and the the delta function is this weird probability function, uh that concentrates all of the probability mass under one outcome
Uh, so you got like basically a probability of one for one outcome and then zero everywhere else
When dirac introduced, uh, this measure into the literature statisticians were not pleased
It just didn't seem to them to be a well behaved object
And it took a couple of decades of work in mathematics and statistics to make sense of and kind of tame, uh
You know the dirac measure
And uh, yeah, you often get this you can think of a lot of recent the history of recent theoretical physics as this kind of back and forth
between like sloppy
Mathematical physics that gets then tightened by uh, some rigorous mathematical work
And I think you know, we're in a kind of similar back and forth here
Um, where you know, the f.e.p. Was effectively developed as a kind of brain physics or math physics
And uh, what we are witnessing now is an attempt to
Rederive all of the core theorems in terms of more well established mathematics
And it effectively recapturing all of the core intuitions
But within a kind of mathematical or receptacle that uh, you know passes the
mathematical smell test as it were
But like what's interesting too about uh, the the dirac delta function and correct me if i'm wrong here
But I think um, I don't know if it was the first but it definitely helped to push along
What later became known as generalized functions, right? So so that at least spurred
Some significant, you know work and research in mathematics, right? Oh, absolutely
And the f.e.p. Is similar in the you know, we're now working out
You know some some cool stuff having to do with you know, generalized coordinates
And uh things like maximum caliber, which are which is like maximum entropy but over paths
And all of this investigation is in effect opened up by the free energy principle
And by the can of worms
So I've never heard I've never heard of maximum caliber, but let me see if I can guess what that is
So if you have paths going through, you know, some state space, I guess it's like the
the you know
The uh, the cross section the cross sectional area the paths that they traverse or or what it's it's more like um
Well, it's similar to that but you're what you're basically doing is uh, you're considering
um
The entropy not of individual states, but of the entire paths throughout the system
So it's it's actually the entropy of the whole path
Okay, and so yeah, uh, it's an extension of uh, you know, james's principle of maximum entropy
But in such a way that uh, we can talk about like the counterfactual histories of the system
That is like all of the different paths that it can take through its state space
In terms of their entropy and then the principle of maximum caliber
Is that the the real path is the one that maximizes entropy?
So it's not just about finding yourself in a in a low entropy configuration
It's about finding yourself along a path that has has the lowest entropy
Yeah, and and this uh turns out to be important
Um, because the the free energy principle, uh
evinces all of these interesting dualities
Uh to the space that james is describing
Um, so in the literature there are roughly speaking two main families of application of the free energy principle
Uh, the so-called density dynamics formulation
Uh, and the uh path based or path integral formulation
In the density dynamics formulation, what you're considering is uh states and how surprising those states
are per se, so uh
When you're trying to talk about that what you do is you appeal to this construct called a generative model
Um, and the generative model is basically a joint probability density and what it describes is the relations of dependence
Uh between the variables
in the flow or dynamics of a system and so in the
density dynamics formulation
What what the surprise is about like I was saying is how implausible is some configuration of states of the system
So this is different from the
From the path based formulation
In the path based formulation you're considering the trajectories of system over time
and given the kind of thing
That uh, you are for example
Then you're going to have an inertial path through your system
Just given the kind of thing that you are, you know
I'm the kind of thing that wakes up at 6 a.m
And has some coffee and then gets progressively more tired and then goes to bed at like 9 or 10 and then you you know me so well
So if you're that kind of thing then there is a characteristic or inertial path that you'll take
And in the path integral formulation the surprise will score is the deviation from the inertial path
So, uh, yeah, these are slightly different objects and you can think about
Dualizing these to an entropy context where you know in in the density dynamics formulation
You would be talking about the entropy of states or configuration of states or indeed of the beliefs encoded by those states
Or the entropy of entire paths
So this caliber notion
But yeah, all of these are kind of uh joined up and as i'm sure we'll discuss a bit later
Yeah, yeah the uh, yeah the the free energy principle turns out to be
a way of writing down the principle of
Uh
Of maximum entropy
Yeah, so all these things are really like deeply connected. I would say now, uh, you know previously
I kind of prodded you about whether or not the physics
Could explain, you know consciousness and you said the physicist in you was really
Really, uh, you know leaning towards hoping it hoping it could so I want to take this
Chance while we have you to ask you about one of our favorite perennial topics on the show here, which is
Emergence, you know weak emergence strong emergence now, um
You know, there's there's different ways of looking at it different definitions of it
I think um what I want to ask you though is that
There are clearly certain behaviors, right that
Are best modeled and talked about and described mathematically at these higher levels
Of um of abstraction like thermodynamics. Okay. I mean, you know, just there are these bizarre
Kind of properties of you know entropy and temperature and free energy not
somewhat related to the free energy we've been talking about
That you can that you can develop these equations on right the first law second law third law of thermodynamics
And they apply to these kind of bulk systems now
like uh
In principle in principle and that's really the the the key word there, which is in principle if you could write down all the you know
details
Appreciating details of every particle and solve, you know wave equations and kind of massive massive dimensions. You may be able to
Uh formulate those laws, right and predict the emergence of those laws
But the fact is nobody ever has like they they they don't do that
We can't do that and and there's even the possibility that in mathematics like mathematically these
Effective theories, right where you try to do that you try to write down all the particles
Calculate integrals and averages they can sometimes end up with these singularities where you can't cross
You know that divide so I guess my question to you is is this which is that and if you couldn't cross a divide
That would be a strongly emergent
Phenomenon versus a weakly emergent one where you could mathematically cross, right? So i'm just curious if you think
um
First of all
If you think there's such a thing is strongly emergent
Phenomenon or if we're always be able to cross that mathematical divide if you will and then secondly
Even if we could is there really any point or is it better just to develop, you know
Descriptions at different levels and and just be happy with that at the end of the day
That's a really great
insightful question
I would be inclined to say that the free energy principle gives you a kind of heuristic or a map to tame
weak emergence
So maybe we could start there for a second. So the free energy principle applies in a kind of
multi-scale manner to
things composed of things composed of things and the kind of key insight
That you get from the study of ensemble dynamics in the free energy principle is that
um
things
Can engage in emergent behavior provided that they have a shared generative model
So if if you and I kind of encode the same dependency structures
Then we are going to react in
characteristically coherent ways to whatever we're experiencing and therefore
We will end up coordinated even if we're not directly communicating
So that there is a story that you can tell and I know you've had mike levin on the call here
On the show here a few times
Yeah, he's he's absolutely amazing. So this kind of like
Yeah, ensemble behavior that mike is interested in explaining has to do with the emergence of a shared generative model
So this again
It's the same core story, you know, you have things interacting
Over time and the the FEP says that if there are boundaries in the system
Between things then they will track each other across the boundaries, right?
So this means that over time things end up sharing a generative model and can then begin to display
Coordinated shared patterns of behavior
So I think that's really key
The you know and we discussed um Aristotle a bit earlier
This is again removing degrees of freedom from the parts, right?
If you and I are aligned on what this or that means it means that we're aligned on what this or that doesn't mean
So we are, you know, coordinating by uh becoming models of each other becoming good predictors of each other
Kind of sparsifying the set of things that we expect each other to do and over time we can arrive at some form of like
You know coordinated behavior and I think the the contention
Is that this explains, you know, biophysical emergence at every scale where we observe it
So there there's an argument to be made that really this is
Really a theory like a formal theory of
Well, I mean the the FEP itself is not a theory as we discussed
It's a principle that it's a formal approach to that begins to give you a grip on how to model
nested systems of systems of systems of systems
The cool thing is that the whole stack operates on the same quantity basically, so you have one objective function
It's the same pattern at every scale. It's the markov blanket that repeats
And it's this free energy minimization behavior
you know and
So that's I think powerful
You know this segues one of the applications of the free energy principle
Adverses is to design
systems that are able to perform inference at different scales using the same
objective function so the the variational free energy and if you introduce this time scale separation
Into the mix then, you know at the bottom of the stack you have state inference, right? So
I have hypotheses about what might be causing my data. I am generating
data through my actions and I end up selecting the hypothesis that accords the best
With the data that i'm generating, but you can do your parameter learning using exactly the same
architecture just on a slower time scale, right?
So you accumulate counts of state estimation and then over time you're able to
You know estimate what the best configuration and value of your parameters are for your model
And then similarly you could do the exact same exercise at the level of the entire model structure
And then you know that's where you get into the natural selection story that the free energy principle brings to the table
I embody a model
In my existence. I am kind of generating evidence for that model good models
persist and leave copies of themselves bad models are destroyed and dissipate
So you can really tell a kind of I think powerful multi-scale story
So yeah, I would say like there's not much that remains in the weak emergence stuff that you can't
You know address in a tractable manner using this kind of approach
Your other question about strong emergence is a bit more vexed
Um, you know thinking about this. I think the only thing that might really be strongly emergent is our conscious experience
Um, and there are reasons to think that that actually isn't strongly emergent, but just weakly emergent
Um, in particular, are you familiar with Andy Clark's notion of basing qualia?
Um
Not not quite. What is it? It's very cool. He cars. He calls this the meta hard problem
um, okay
Yeah, and what what Andy is basically saying is that well, uh, what we experience is qualitative sensations are just further inferences
Namely inferences that I am feeling this
Right, right. Well, that's that's very similar. You know, I really liked, um
Professor Friston's take on this and I'm blanking on on the uh,
On the article where he described this but but he said that, you know
When you when you're doing this free energy principle and you're doing this this inference once your once your inference has reached a sufficient
temporal depth and counterfactual
depth if you will
Then that's when consciousness can emerge because it can start to model itself and its own internal states and
You know this sort of thing. I think it makes a lot of sense. Um, I absolutely yeah, yeah
Well, you know, you're you're preaching to the choir here. Obviously I find that
Kind of explanation extremely compelling
Yeah, and so, you know, we also have some interesting
in my view, uh work on consciousness that we have, uh, you know
In a free energy principle adjacent
Kind of area and putting out for you know, nearly two decades
But more recently we've been looking at the question whether you can
derive a theory of consciousness directly from the free energy principle
Um, and so we believe that we can and the idea there is that, um, consciousness corresponds to something like an inner
Markov blanket so an inner screen. Um, so to back up just a little bit, um, uh, you said inner screen now
Yeah, we're gonna think of the humonculus
Well, so, uh, that's why I want to qualify this carefully. Um, you can think of any markov blanket as a screen
Of sorts. So it is, um, a screen in the and you mean a screen in like a mathematical
Yeah, exactly. Like in the sense of the, uh, holographic principle, uh, in physics, right?
So the holographic principle is a principle, uh, that originated in black hole thermodynamics
And it relates to, uh, our ability to encode information, uh, within a system
And what it basically says is that you can from the perspective of an outside observer
A given system can only contain as much observable information as you can fit onto its boundary
Um, the reason being that if that if that bulk collapsed into a black hole, uh, and there were more information than that, uh,
Then you classical information would be destroyed in the process. Yeah, exactly
And you would violate basically the principle of unitarity in quantum mechanics. So
Uh, you know, I mentioned this quantum information theoretic formulation of the free energy principle that I said I wouldn't get into
But it's probably worth getting into for like two minutes. Um, so
According to this formulation, you can think of the markov blanket as a kind of holographic screen
That separates the inside of a system from its environment
And it's it's a slightly more kind of computational take on what we've been talking about. So, uh,
You know, the active and sensory states of the markov blanket would correspond to
Reading and writing onto the screen, uh, or a measurement in preparation operations in the kind of quantum mechanics
perspective, okay, so the interesting thing about the markov blanket in this formulation is that by definition
Um, because it is constructed
Or contains all of the degrees of freedom that a couple, uh,
You know systems across the boundary, um, all of the classical information that you need to describe the coupling lives on the boundary
in some sense
so, uh, chris fields about three years ago along with mike levin and jim glazebrook
proposed that well, maybe
uh
The core architectural feature of systems that have consciousness
Is an internal markov blanket
Right the the idea being the the classical information that I use and bring to bear in parsing my
You know perceptual streams and deciding how to act has to live somewhere
And so the idea is it probably lives in this kind of internal
Uh screen of markov blanket. Interestingly, uh, there's a way of just taking this stuff that we were saying about, you know, levels
In the brain and just directly translating that into the markov blanket talk
Between any two levels of brain architecture. There is a markov blanket by definition whereby these messages are being passed
So it you can basically according to the model that we're proposing
So you have an external markov blanket, right that separates the
Uh the internal the inside of the organism from its outside
And then if you look at the these internal states, they have this structure of a nested
hologram in some sense, right? We're like, you have a series of screens
That are successively coarse-graining each other and that are therefore kind of resonating with each other
And so there's a whole story that you can tell about. Yeah the the emergence of something like
uh, yeah
Consciousness, uh, just directly from by appealing to the free energy principle
The kind of key to this architecture is that at the very top
Of this nested hierarchy, there is a right only layer that doesn't get further contextualized from by anything else, right?
And so there's a sense in which that layer is constrained to write down
And can only uh kind of infer itself into existence vicariously by acting on the other layers of the network
Um, and so the idea then is that this is where the
Kind of um, well, this is how you resolve the homunculus paradox first of all
Is that there is a layer that that is not observing itself?
It just exists to observe right layers below
Um, yeah, and so yeah, we have a a new paper that was just published
It's in a series of two or three papers that we're articulating
So I say this because like I think if if anything is a candidate for strong emergence
The only really serious one is consciousness
And the the absolutely utopian over uh, confident part of me thinks that like by
Combining, you know, some of the philosophical work that say Andy Clark is done around basing qualia with these
Computational architectures for conscious systems that we're developing based on the free energy principle
Somewhere in the vicinity of this if you if you you know
If you look at it for long enough, there'll be something
That'll emerge to resolve this
Issue so well, I guess uh, David chalmers will at least be happy that um, you've identified consciousness as the only
If there is something strongly emerging, it's only consciousness
I can't think of anything else frankly. Um, and I mean
Consciousness may ultimately be
inexplicable
But it also may not and so, you know, I'm uh
An optimist until I'm I'm proven wrong
And we're we're gonna keep working on this. I think you know
What we're proposing is just the very kind of basics of a sketch of what a
Mechanism for the generation of consciousness might look like
We're very very very very far from like a comprehensive question, but uh, yeah, so, um weak emergence
Oh, yeah, go ahead. Well, I was gonna say we weak emergence
Definitely a cool idea. I think the fvp gives you some tools to handle that strong emergence
I'm not sure. Uh, like if if anything is it's definitely consciousness
But maybe not
Okay, well fair enough and you know, I was gonna say what's funny about the free energy principles
It's this onion that just keeps on giving you can just keep pulling back more and more
Layers and I think we probably have uh, I don't know maybe centuries of mathematics, you know
Uh inspired by it most likely
Well, yeah, I I mean, I I think I think it is one of the
singular most important
discoveries
like
Of the last maybe 200 years like I think, you know
You you you've had long discussions with Carl so
Yeah, you yeah, I mean, I I think this is like, you know the this is physics of mind, you know
We are we are I think this is the same, you know to bring it back to mechanics
um, so Galileo, uh, basically destroyed
Uh, you know, it's the Galilean moment, right?
But like Galileo destroys thousands of years of
Philosophy inherited from the Greeks, right the Greeks thought that there were basically two kinds of stuff
There was the sub lunar stuff
And the super lunar stuff and then the sub lunar stuff was governed according to these four elements where you know like, uh,
things, uh, the
That were uh, earth
Fought fell down and things that were fire rows and stuff like that, right?
And the super lunar, uh, was all about like eternal perfect
secular this cyclical circular
Motions of like planets and so on right and you know, you can if you were
Around 400 bc and you you looked up into the sky
It really would look as if there were two different kinds of things too utterly distinct, you know the the stuff around me
You know rocks fall to the ground and uh smoke rises and water is cold and and so on
Uh, and the stuff out there
That just moves and perfect eternal spirals and so on
What Newton and Galileo, but I mean maybe in particular, uh, Newton
End up doing is to say well, no actually
Uh, it's all one kind of stuff
Like it's it's all, you know subject to the same fundamental laws
It's it's classical mechanics and the Newtonian kind of Galilean Newtonian moment is sort of like the split
Where like, you know the old way of thinking. Yeah, uh started to show
Signs of being incomplete and a new alternative arose
So kind of unifies all of reality under the auspices of classical mechanics
And I think the same kind of thing is at play here where, you know
We used to think that there was physics and then there's biology or maybe, you know, there's an information theory
Yeah, exactly or maybe there's like physics and biology and then there's the mind
But what the f.e.p. Is ultimately telling us and I you've heard this, you know from from mike and carl before
I'm sure is that there really isn't a distinction to make here
Like it's it's all just
You know physics in some sense and biology is just slow physics
And psychology is just even slower physics and culture is just even slower physics
And so yeah, I think we have the same kind of like radical quantum leap in the way that we
You know are able to think about the world that opens up with the free energy principle
Especially when you combine this to like the philosophy of sparseness and emptiness that I was referring to a bit earlier
Like I think what emerges out out of this is like a real
powerful constellation
To to think about the way that intelligence is expressed in physical systems
And you know, that's also why versus has adopted the approach like here is
Finally, we have the physics of intelligence. So let's let's build our ai systems on these bases
I mean, it hits exactly the phrase that that you said that it's so impactful and meaningful
Which is the hole is not greater than the sum of the parts exactly. It's radically less than the some of the park
It's beautiful
Well, listen max well it has been absolutely a pleasure to have you on so thank you so much for uh
Taking the time to join us and um and talk and
You know, I hope you come back on again. It seems like there's so much to discuss
I'd love to and you know, I am a long-standing fan of your podcast. So this was thank you so much
No, really, uh genuinely this was uh a pleasure and also an honor
So thank you very much for having me. Um, this discussion was extremely exciting and fun
And uh, yeah, let's do this again sometime. I I'd love to come back
Absolutely and best of luck at versus. I'm supportive of what you're doing there
Very glad to hear it
