a multi-scale
I guess arbitrarily nested really uh framework for communication across absolutely
Not it's it's more than a mesh. It's um, what's the right word for it's a hypergraph. I guess it's it's a hyperspace
a hyperspace we we call this the you know the the name of the
Protocol that we've developed
For modeling is called the hyperspatial modeling language hsml
It's it's meant as a an homage and a nod to uh h html
And uh, what we hope it doesn't use the same syntax, please
No, no, well, um, well what we've also built is a transaction protocol and a querying language that
Live within the hyperspace so so called the hyperspace transaction protocol hstp
and the hyperspace hyperspace querying language hsql
And so yeah, what we are basically in the business of doing is on the one hand building out these graphical models
Of knowledge basically of the knowledge that is involved in specific tasks domains and situations
And then we've developed methods to take these knowledge graphs and to flip them into graphical models of inference
So that's really that's that's kind of where the the the secret sauce and the magic happens
Is that this is a two-step process and the overall versus technology stack combines
active inference based ai with explicit generative models on the one hand and this kind of nested
hyperspatial representation of the problems to be solved on the other
And the the technologies kind of are married
through their kind of reliance on
On graphical techniques basically so it's it's knowledge graphs meets graphical inference
in a nutshell
yeah, and
we
We really are committed to developing these in terms of
You know open publicly available standards
You know, there's a lot of as I'm sure you're acutely aware. There's a lot of um
You know hype and demerism
Going on right now
With regards to ai there's a lot of I think maybe uh over inflammatory
You know demerism and over utopian hype going on
And in terms of you know the different options that we have to
Develop these technologies in a responsible way that there seems to be one call for you know government oversight
Which is interesting that comes with its lot of limitations. For example governments are limited to their jurisdictions
And so, you know, you can't uh, you can't coordinate an international community of research and development in r&d
merely through
national regulation
So that's limited on on the other hand you have, you know, uh markets
And companies that want to you know solve these issues in house
They are maybe faster and more flexible, but there is this necessity of you know, how do you how do you constrain the activities of
Corporations in such a way that we develop these technologies
Responsibly ethically
transparently in a manner that's audible and that's uh, you know
acutely aware of and sensitive to the potential harms that might be caused by these technologies
So what we are, uh proposing is a kind of third path
A middle way not to say that we shouldn't pursue, you know, a private
Development of these technologies and regulation. I think this is all
You know a great idea. Uh, there's some interesting, uh legislation coming out of the eu
Uh, the ai act that everyone is talking about that I think are interesting paths forward
but a to really, um consolidate the international community around these technologies we have proposed a standards based approach
Um, and the the iEEE group, uh where the standards will be housed
Is an open group
Folks from anywhere can join
We have some pretty high-profile corporate partners
But the idea is to build these technologies in a manner, uh, where we avoid silos basically
And where we can kind of coordinate the entire world's
Technological and intellectual prowess towards solving these, uh issues
So I think the um and and yeah, there has been
Definitely, um, uh the threats of ai the the risk of ai have been uh quite quite heavily
Discussed um as I think with good reason listeners
Yeah, well, and you know, I mean recently we had a show about this and I was uh pillory, you know quite a bit
Uh in the comments because my my role is uh
Devil's advocate, but I mean I I mean for me personally I see the damage of of ai
Happening right now. I mean, you know, we have when you have kind of um, let's say social media algorithms that have been highly engineered
And optimized and no small part by by machine learning to suck up everybody's attention, you know, it's
Even before well before we get to the the possible point of
Of super intelligence, you know in in a general sense
Uh, it's already damaging right and so and and I personally think the path forward are
openness and transparency and making sure that that the good guys, um
Uh that it's easy for them to do the right thing and so I think I think like approaches like what you're advocating for
The right way to go. I mean for sure. Thank you. Thank you. I'm going back in the bottle
It isn't and um, I think you know, you you said that all the right words transparency
I think is is more than just um
transparency in the decision making of stakeholders and parties involved in the research and development of ai technologies
In our case, it really means the transparency. In addition, it means the transparency of the models that we're using
Right. Um, so, you know, one approach one approach to training up ai systems might be
You know give ai uh access to extremely curated data sets so that it it learns only the right things
You know in extremely like controlled settings
There's reason to think that that won't generalize easily
Another thing that you can do is to equip your system with the capacity to form inferences about its its own inferences
Uh and to evaluate itself with respect to you know things that we value
So you could for instance design an ai that had an explicit notion of like discriminatory bias
And then train it to identify
discriminatory bias in data sets for example
And you know, uh, you can use active inference technologies to allow the system to access
And report on its own inferences
Well, I mean, it's it's even more general than than that. I think I'm understanding it correctly because for example
You have these nodes right in this in this um hyper space
Yeah, you know, you have you have all these nodes in there and and you can learn for example that say a particular node
Uh is is racist, you know, like it'll it'll give you great answers to a particular question
So long as it doesn't think you have certain, you know
demographic characteristics or whatever and then it gives you like, you know bad answers well, then you can
The network can learn how to mitigate against that it can learn how to you know, compensate for the biases like
Inherent and in nodes so not in particular actual algorithms
Yeah, exactly. And you know, the algorithms that we're using are based on explicitly labeled generative models
So these are systems that can be audited by third parties
Right, right, right because everything is labeled explicitly, right?
So like you you can really calculate the incidence of this or that node on this or that part of the inference
And it gives you a kind of tractable
interpretable
You know auditable method of constructing systems
Such that you understand what went into the decision-making process
I said earlier that my suspicion
Our wager is that active inference will be to the 2020s. What uh reinforcement learning was to the 2010s
My my gut tells me that if legislation the legislation that that they are
You know writing up in the u.s. And in the eu
goes through
It may be that active inference will be the only set of the i technologies that we're allowed to use
in the sense that
you know
Neural nets as they're used right now are black boxes
They're not explicitly labeled and they are built
To be black boxes like the they are not
Built they're not designed to be interpretable the the kind of uh, you know these kind of privacy security
Issues issues around confabulation issues around, you know the the
Uninterpretability of these models. These are not like bugs
In some sense. They are features of the approach that we're using to design the systems
You're not using an explicitly labeled model. There is no way to render this tractable post hoc
Whereas if you start from an
An approach that you know, it's it's explainable. It does what it says on the tin
Then you get around these these uh, these issues
Through your choice of architecture in effect
So, you know, I I think there's
You know tremendous
ethical import
To the the manner in which we're designing these systems
We care a lot about ethics and verses as we discussed my my phd even though most of my publications are in computational
Neuroscience and kind of theoretical biophysics. You might say like my phd is in philosophy
We have a lot of properly trained ethicists really at the core of this team and we take these things really seriously
Adverses so there there's no accident here
And I really think that active inference
Uh
Plus the standards-based approach
Is how you're going to get something like responsible scalable ethical AI
Okay, so and so far i'm on board with everything everything i've heard
I have a question for you though, which is if it's all open
And and ethical and you're trying to do the the right thing
How exactly is that profitable like what you know, what's going to keep the the lights on it versus
Well, so we have our own in-house implementation of hsml
So, you know, we uh, we are providing the standards so that anyone can build a version of hsml
We're providing the kind of core infrastructure
For uh, you know domain registry and this kind of stuff
But we also have you know very advanced highly engineered and developed versions of these things that can actually do things
um, so
Yeah, uh, yeah
I mean, uh, you can think of uh, you know red hat and the linux foundation as a kind of similar
Aspirational model right so, uh, you know red hat do generate a profit from a commercial point of view that
The linux is still open source the linux foundation is the open source custodian of the linux operating system
And yet they are able to operate
Our contention is the our stack is organized in a similar manner where uh, the spatial web foundation is the
custodian of these open standards that we are, uh, you know
distributing
hoping
Everyone will widely adopt them and we are the more kind of hard-nosed
Kind of architects who know how to build things using these tools who for having built them know how they they work
And you know, we are probably at this point
I mean almost certainly the world's premier active inference research and development group. So, uh, there's a whole powerhouse
of you know
Well, there's a lot of great academic papers that
That uh that come out there. I mean, you know, I know tim and I have enjoyed
I'm looking at uh, you know quite a few of them. Um, well, thank you
Yeah, you mentioned uh, Dalton, you know earlier. I mean, you know, there there's an example of some some very refined
And and quite deep philosophically and mathematically, you know papers, right? Well, we have basically hoovered up the kind of core
Uh, luminaries of the active inference tradition as it stands currently. I mean, carl friston himself is our chief scientist and
Joining us, uh in an increasing capacity over the next few years
Uh, yeah
So when you combine that with, you know, I I'm fairly
well known in in the field, uh
Yeah, we have really scooped up like, uh, you know, the lans de costa
Connor hines brennan kline
a mal albarasen
there's a
It's it's it's pretty. Um, sometimes it's a little bit
Uh, I guess the lunches must be must be interesting there, right? Yeah, absolutely. Uh,
Yeah, and I mean, um, this was this was my dream, uh, you know back back in academia to
Have a centralized research group with with all of this talent able to like work together and yeah, uh
We're definitely doing some interesting stuff and at you know, at versus we are committed to uh, continuously also contributing to
The public domain and open scientific
Publication as you said, you know, we're we're a fairly productive
research group, uh
We published a few dozen papers last year, for example, uh, you know, so we uh, I think there's a way of
striking the balance between
Contributing to an open community of development having an open core and this kind of thing on the one hand
And also being able to continue existing as a profit-generating entity on the other
Uh, but really the I think the the key strategy is this open core
Right. So like have the standards open. Yeah, make sure that everyone can contribute to it
Like, uh, you know, and there is a kind of selfish dimension to it as well
Because then we are able to harness the entire power of the the intellectual international community
Uh
To build this uh stuff out. I think that yeah, there there are there are certainly some advantages
Uh, we also, uh, for instance, uh, maintain and contribute to the pi n dp package
Uh, which is a python package to for, uh
Partially observable mark-off decision processes that power a lot of the active inference technology
So we use that as our core
Um, and it's uh, it's on an open, uh, license
So anyone can just, you know, download these packages go to the github
And use it. So we're trying to build these technologies such that
You know, everyone can start to use them. Uh, but we definitely have, uh, you know, some key
Uh, differentiators and I think a pretty, uh
Pretty unshakable market advantage
