We could write down this generative model though and then using, you know, various sampling and techniques like that
We could then
Compute statistics from it try out interventions see which of those had had kind of a beneficial effect
But that was all ad hoc, you know, architecture that we we designed and produced by ourselves if I'm understanding you
correctly
What you're doing is producing a technology that one
Formalizes that much more and applies the free energy principle
I think to help guide like the sampling and the optimization and you know, really just the effective use of these kind of generative, you know
simulations and models
Is that
Close to what you're talking about. That's right. So, I mean you can why use active inference
It is demonstrably the most efficient machine learning technique
So it's sort of like, you know, a car no cycle analysis, but for for an engine but for AI
in particular
What the free energy principle
Allows us to formalize is the thermodynamics of information writing on to the boundary
so in in some of the newer work on
The quantum information theoretic formulation of the free energy principle
Which we don't necessarily have to get into in detail, but
There are these kind of new scale free extensions to the free energy principle that have been developed
That appeal to the tools that have been developed on in quantum mechanics, right?
So the theory of very small fast things, but quantum information theory
So the kind of information theory that gets augmented to handle things like probability amplitudes
Which are the the roots of probability densities and so you can get your wave equations moving
in place and all that so the
That formulation of the free energy principle allows us to formulate the computations
Carried out by a system in terms of like a per bit read and write cost
So there's a there's a there's a sense in which like you're you're bringing it down to the like to the
the bare kind of you know
machine elements of
Of your computations and you're you're writing things down in a way that is demonstrably the most efficient way of doing it
So if you if you set up, you know some simulation system using active inference you are
And this kind of brings the conversation full circle in some sense
You are generating a model that is as predictively accurate as possible
But also that expands as little energy as possible due to this, you know, controlling for the
complexity of the model so
Yeah, we we have this
this pre-print up that will be revising soon
Called the map territory fallacy fallacy, which is precisely about the kind of canonical nature of
FEP theoretic modeling
Yeah
you know the
One of the reasons why
The FEP is optimal
Is that it's it's another way of writing down janes's maximum entropy principle
So for our audience
The maximum entropy principle
You can think about it from from the point of view of statistics and also from the point of view of statistical mechanics
From the point of view of statistical mechanics, the maximum entropy principle is the principle according to which things dissipate
Um
So from from the point of view of statistics, it's the principle according to which give me a data set
And a set of models from which I might have sampled that data set
The it says the model with the highest entropy is most likely to be the
The real model from which you sample. So, uh, that's a way of kind of saying like what is the maximum entropy probability density?
It's a flat density
Right and so basically a maximum entropy probability density encodes no information
Because all of the outcomes are equally probable
And in some sense what occum's razor would tell you is that like you would want your model to be as flat as possible
Right, you want to build in as spread out as possible. Exactly
You want to build in as few
Assumptions as possible into your model. This brings it back to the whole keeping your options open thing that you were saying
You were discussing earlier, you know, if you're thinking of a probability density over different courses of action
Unless you're really sure that you want to do this. You probably want to keep things
As non-committal as possible and keep your options open
so
The just to back up then the free energy principle is a is a way of writing down
The principle of maximum entropy
They are effectively the same thing
You can move from the one to the other
And we know that the principle of maximum entropy is is is the principle of parsimonious explanation in some sense, right?
So if the fvp
And maximum entropy are the same principle then all of the epistemic virtues that accrue to maximum entropy also carry over to the fvp
and therefore, uh, yeah a a free energy principle theoretic model
Of the belief updating of a particle can be shown to be the optimal dynamic systems model for the whole system that you're considering
Like there is a kind of canonicity
Uh, what we're calling janes optimality that yeah the basically the fvp
It allows you to write down the best model that you could for your the system that you're considering given your current state of knowledge in that system
It's just the optimal way of writing that down full stop
So that's why we you know care about active inference
Yeah, it might be useful to give you know some examples of um
Of you know maximum entropy distributions to understand so for example
If you have a data set, um, and let's just suppose it's
Continuous, you know data and it's and it's positive only so I know that it's continuous data
It's positive only and I know that it has a particular mean
you know
Then the the distribution that has the maximum entropy under those examples is an exponential distribution
Right like it's it's sort of spread out as much as possible
Um, and yet it has a particular particular mean and and and for example if we go to the case of
It can be a real number anywhere between
Minus infinity and infinity and it has a mean but it also has a finite variance
Then you wind up with the Gaussian, you know distribution as being you know the maximum
So it's really it's it's a distribution that captures what you know about the system
I eat the constraints right and yet is as spread out as it's possible to be
While satisfying those constraints, right? Yeah, absolutely
And and you know, I hope our audience is able to kind of see the pattern
It's starting to form here, you know, uh like all of these connections are non accidental, right?
So the the FEB is all about balancing your predictive accuracy and complexity
So all these things are kind of connected at a deep level
Uh
And yeah, I mean maybe the audience also can see why we're so excited about like this is highly non-trivial
Well, no and and I don't know if this is crazy or not, but it it actually even seems to have implications for
fairness of models because so for example
Suppose I'm trying to train a model that
Does anything of human interest, you know diagnose
Or prescribed medical treatments or you know, give out give out loans or that sort of thing
And and we need to train it on some type of of data whether it's a generative model that we calculate
Or data that we actually observe
Well, we want we want the system we want the machine to learn
Only what's relevant for that particular
Task and like nothing else, you know, we don't want it to to learn kind of
Extraneous things. So for example, if it's deciding to hand out medical diagnoses, we want it to be based solely upon
the medical attributes that are in in the you know, the data set and not some spurious
You know correlation to like a the geography or you know, where you came from or or um
The letters in your name, you know of your file or anything like that. And so in a sense, um
What maximum entropy helps you to do is force out that stuff because
That stuff if it's not useful for the actual prediction
It'll get, you know ironed out because it's smoothed out by the demand of maximum entropy
That's right. And and that brings us back to sparseness
right
How so tell me well in the sense that um, you know, this this even has to do with like situation or task definition
Like situations are sparse
They're not all not everything is connected to everything not everything is relevant to everything else
So there's even like a kind of it's really a kind of a meta
methodology because you you can even define specific situations in terms of their sparseness and then
You know, yeah
so
So it sounds it sounds great, but I'm always the eternal skeptic because I know
A lot of this type of computation, you know, the the generative starting with a generative model doing inference on it
just computationally is
So difficult like what what is the magic?
That versus is found and and how are you so sure that uh, how are you so confident it's going to work?
great question
So, I mean in particular one of the big questions that
Plagues generative model based methods is where do your priors come from right?
So what is the structure of your model?
What are the parameters that you're using? What's the relevant state space all of that?
Is often I mean often you have to hand design this stuff and it's very labor
intensive
So at versus we are a uh a contextual computing company
So we draw inspiration from the architecture of the brain
uh, and uh, basically we're proposing a kind of general
Uh standards based solution to the problem of where do your models? Where do your priors come from?
um, so just to uh, uh, you know do a crash course in neuroscience
um
So, uh, we love neuroscience here. So please do. I'm sure well, so a source of inspiration
I'm sure everyone is familiar with the idea that the brain has a layered or hierarchical structure
So it's not the case that the brain is just a soup of connections where everything connects to everything else
um
To the contrary there are very regular structured patterns of connectivity
In the brain. Um, again, this takes us back to the theme of sparseness, right?
Like the to say that the brain has a hierarchical organization is to say that it evinces a specific
Very special kind of sparseness where connections
Are directed in specific ways where you're connected to layers immediately above and below you but nothing beyond that
um
So we've spoken in the past to jeff hawkins
Like is this related at all to the concepts of cortical columns and like the way in which they're
Connected like it almost has these, you know components that are reused and absolutely in terms of different layers
Uh, yeah, uh, that and not all the layers speak to each other
um from a uh an active inference perspective this layered or uh level
Level involving structure has a specific purpose. Um, so what each level is doing is providing priors
Uh, or expectations to the level below and receiving context from the level above
And uh, what each layer is doing in turn is shuffling prediction errors to the to the level above and receiving prediction errors from the level
below
So what what you have is basically a set of layers that contextualize each other
And the way that each layer contextualizes the next one is essentially coarse-graining
right, so, uh, there's some fast
fast small scale activity
The lower levels are tracking closer to the sensory end and what each successive layer is doing is finding basically the the
Set of hidden states or latent states
That explain variance in the data that it's receiving and and so on in this kind of hierarchical fashion
So the the brain is not one monolithic system
Rather, uh, each layer of the brain is specialized in encoding specific features of the situation pitch that a specific scale
And it functions by kind of providing context. So we like to say that the brain is an organ of context effectively where
Uh, really what it embodies is successive layers of context that are each coarse-graining each other in this kind of fashion
So I know I I know
Our neural network fans out there in the audience are gonna they're gonna be hearing that that's just what a neural network is like it has kind of layers
You know, they're connected. What's what's different about just
Any other, you know, kind of neural network
Architecture, if you will so what we're proposing is an infrastructure project in some sense
We have uh, we're working with the iEEE
In the us and so when I say we
Versus that has a sister
Organization a non-profit called the spatial web foundation, which was uh, to whom we gifted
Uh, the the first massive chunk of research that came out of our group
Um, and what we are developing with the spatial web foundation is a set is a set of public standards
Uh, that people can use to build out
Uh, basically shared knowledge graphs
So we're building an ecosystem where uh, folks can basically
Think of this as sort of like wiki data or wikipedia
But for kind of shared contextual compute context
So, you know, obviously, uh, we are building this out
So we're going to be the first to put things onto this network
But what we're trying to build is basically a spatial web or a hyperspatial web
That kind of in some sense reflects the structure the kind of graph structure
Um of the the various kinds of situations that humans, uh deal
I got it. So it's so it's really an application of of
Interesting, so it's an it's an application of the free energy principle at multiple scales. Absolutely. Okay. Okay
My mind was going in the wrong direction here, which is I was going to like the scale of of uh,
You know the individual thing and and and how it does it's it's modeling its compute, but this is this is more than that
This is well, it is that you're absolutely correct, but it's more than that. It's it's that and it's and it's actually like
