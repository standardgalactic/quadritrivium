Do they start dealing with the Bayesian brain, unconscious inference, and Helmholtzian ideas
like that, or do they start from a physics-based perspective and start working their way towards
something that looks like sentience?
And there are lots of different, lots of alternative ways people get into it.
The fact that you become interested via machine learning, the fact that other people
have become interested through biology, I developed an interest through neuroscience
while I was at medical school.
And the high road and the low road was a way of just trying to acknowledge
that difference or that difficulty of knowing where to begin, and saying that that's okay,
there are lots of different roads, but they ultimately end up in the same place.
The idea of the low road was to say, well, let's just take observations and psychology
sort of development of a number of ideas that are built up over time
that come to the idea that we're using internal models to explain our world,
that the brain is using something like Bayesian inference, or at least can be described as using
Bayesian inference, and go from there through the advances that lead you to active inference,
the idea that it's not just a passive process that you're also inferring what I'm going to do.
And furthermore, that when we're doing inference, we're changing our beliefs
to reflect what's in the world around us and to explain our sensory data.
But actually, when we're acting in the world, we can also change the world itself
to better comply with our beliefs. So it's that move from purely changing our beliefs to reflect the
world to also changing the world to reflect our beliefs. And that fascinating move that
actually both can be seen as optimization of exactly the same objective that they have the
same goal, that in both cases, it's really just improving the fit between us and our world.
So that's the sort of low road perspective. The high road perspective was the idea of saying,
well, let's start from the minimum number of assumptions we can, let's start from first
principles. And that takes a much more physics based approach. It says, if you have a creature
that is interacting with its world, then there are a number of things you've already committed to,
and that includes things like the persistence of that creature over a reasonable length of time,
the maintenance of a boundary between that creature and its world, and that sort of
self world distinction. And once you've committed to those things, you can then start to write down
the constraints that those imply in terms of the physical dynamics of that system.
And you can start to interpret those dynamics in terms of the functions they might be
optimizing, much like, much like if you were to write down the equations that underpin Newtonian
dynamics, you can write them down in terms of their flows on Hamiltonian functions. And it's
following the same sort of logic to then get to flows on free energy functions, where free energy
is just a measure of that fit between us and our world. And so both roads ultimately end up leading
to this common endpoint, which is that to be an agent in our worlds, in the sort of worlds we
live in, we have to be able to change our beliefs, to reflect what's going on around us and change
the world through our dynamical flows on a free energy functional, to best fit with the sorts
of creatures we are. When we first started looking at the free energy principle, we were talking
about things. It was known as a theory of every thing, every space thing, which is to say, roughly
speaking, if a thing exists, what must the thing do to continue to exist? And just their continued
existence resisting entropic forces is what defines them, which gets us into the second law
of thermodynamics. Now, that sounds like quite a strange thing to say. Why do things need to
resist entropic forces? And I think there's a development in how a lot of these ideas are
presented over time, which you expect and hope for in science. And I think we've often taken
different perspectives at different points in time as to how we explain these ideas.
And resisting entropic forces is an idea that I think most people find relatively intuitive.
So the idea that the physical systems will tend to increase their entropy over time,
at least close systems, so that over time things will gradually dissipate, things that are highly
structured and highly ordered and can only exist in a very small number of configurations and
more likely to change into something that can exist in many different configurations than they
are to go in the opposite direction. But anything that persists over time and maintains its form
clearly resists that process of decay, at least to some extent, or at least for some period of time.
However, the opposite is also true. We're also not creatures that tend towards a zero entropy
state. We don't end up in a single configuration. We have to be flexible. We have to change in
various ways throughout our lifetime or even throughout our daily routine. So it's not quite
as simple as just saying you have to resist entropic change. It's more to say that entropic
change or the amount of entropy that you expect to develop has to be bounded both from above
and below, that there is a sort of optimum level to be at. And that optimum probably varies from
different, well, from person to person, from creature to creature, from thing to thing.
You could imagine a rock that doesn't need to do much. Its interface with the environment is
quite trivial versus us as agents. We are incredibly sophisticated. So for us to continue to exist,
we have many more ways of interfacing with the environment and we need to plan
many more steps ahead. So is that just a pure continuum between rocks and people?
I mean, in principle, yes. I mean, the notion of that persistence, of that resistance of entropy
will depend very much on what you are. And as you say, you could imagine a whole scale of
things in between. I mean, in a way that as you've highlighted with the rock,
some of the most boring things are the things with the, sorry, I shouldn't say that,
poor geologists who might find rocks very interesting. And I'm sure are very complex, but
from a sort of behavioral perspective, clearly things like us are much more interesting to study
than things like a rock. And part of that is that we actually have a higher degree of entropy in
how we live our daily lives compared to things like, I almost said organisms like rocks,
but things like rocks that are not behaving. The reason I was thinking about this is the
second law of thermodynamics was conceived, I don't know, 150 years ago or something like that.
And many people at the time thought that it was an affront on free will. I think the religious
people at the time were aghast at the idea that things were mapped out in this way.
It's always worth saying in this discussion that obviously the tendency for entropy to increase
from a physical perspective generally relates to closed systems of which we are not. And as soon
as you start talking about different compartments and interactions between them, you also introduce
the idea of several coupled systems. And so you can start to ask questions about the overall entropy
or the entropy of specific parts of that system. And agents and worlds are two compartments and
systems that exchange things with one another. And so are not closed systems almost by definition
that a closed system, again, from a sort of neuroscience standpoint is not necessarily
a very interesting system. So probably that deals with a large part of that. The question of free
will is always an interesting one and always a thorny one that I'm not going to claim to have any
expertise on or be able to answer. But I think it probably tackles a slightly
different thing from a cognitive science perspective, which is whether or not we believe
that the actions we're taking are actions that we've chosen. And that probably comes back into
another aspect of active inference, which is that idea that the way we're regulating our
worlds, the way we're perhaps changing the entropy of our environment depends upon our own
choices about it, our inferences about which one we're going to do next. And that feeds into things
like we've spoken about free energy, that that quantity that we use to both choose our actions,
an act in the world around us while also drawing inferences. But we can also talk about things
like expected free energy, which is a way of evaluating our future state and what would be a
good trajectory or a good way for the world to play out. And their entropy has a completely
different meaning and there are different sorts of entropy. So for instance, if I were choosing
between several different eye movements I could make while looking around this room,
the best eye movements I might choose are those for which I'm least certain about what I would see.
In other words, the highest entropy distribution. So once you start planning in the future and once
you start selecting things to resolve your uncertainty and to be more confident about the
world around you, you actually end up seeking out entropy, which it seems to then very much
contradict some of the other ideas that we were talking about, the idea that we're constantly
resisting it. But actually it's by seeking out the things that we're least certain about that we
can start to resolve that uncertainty and start to become more confident and more certain about the
world around us. Yes, resist entropy by seeking it out. That's a bit of a paradox. But even what
you were saying just a second ago about this description of how agents operate, it's very
principled. We were talking about this balancing epistemic foraging versus sticking with what you
know. And more broadly speaking, thinking of agency as this sophisticated cognition of
having preferences and bending the environment and so on. And I guess where I was going before
is it's tempting to think that this erodes free will. And I think of them quite adjacently in
my mind. If anything, I guess I would call myself a free will compatibilist, which means it doesn't
matter that it's predetermined. For me, free will, I'll try not to use the word free will, but
thinking of agency in this sophisticated way, whether it's predetermined or not is irrelevant.
It's the complex dynamics that distinguishes my agency from somebody else's. So I think agency
is better to think of than free will, if that makes sense. Yeah. And I think that's probably right.
And the experience of and the inference of agency as well, I think is part of that.
There's a potential link that you can draw here also to the idea of chaotic,
dynamical systems of which we essentially are examples. And the idea of chaos in that setting
is that if you start from two ever so slightly different initial conditions, your path and your
future may unfold in a completely different way. And I think that fits very nicely with what you're
saying about distinguishing my agency from somebody else's because you don't see it as if I were,
you know, the time going to behave in exactly the same way somebody else's. And part of the
reason for that is that you end up starting from a slightly different perspective to where they are,
and that might lead to wildly different futures for both of you.
So something I think about a lot is whether agents are ontologically real or whether they
are an instrumental fiction. And I think part of the complexity, especially with active inference
and the free energy principle is this hierarchical nesting. So we can think of agents inside agents
inside agents. And I guess the first question is, are they real and does it matter?
Define real for me.
Well, one argument would be that they are epiphenomenal, that they themselves don't affect
the system that they are. Is this a good way to think about it?
It is a very difficult question to try and contend with, isn't it? Because I think there
are so many words that come up here that are kind of laden with different semantics or different
meanings depending upon who you speak to and which camp they come from in the sort of philosophical
world. And that's why I sort of asked you to define real. And it's really difficult to define
what real means in that setting, isn't it? And I guess coming back to your original question there,
for me, does it matter if they're a sort of real thing or not? Probably not. It matters
whether it's useful. And I guess that sort of brings me to a point about one of the things I
find quite appealing about active inference as a way of doing science. And I think,
you know, having had an interest in things like neuroscience and psychology for some time,
I often found it quite frustrating to understand what people meant and the different language
they used in psychology to understand different aspects of cognitive function.
And I think, you know, it's worth acknowledging that actually lots of people mean completely
different things when they say attention. And some people say attention to mean the sort of
overt process of looking at something and paying attention to it. Other people use it to talk
about that the differences in gain in different sensory channels that they're trying to pay
attention to or not, you know, am I paying attention to colors versus something else?
And that's just turning up the volume of different pathways in your brain.
And I'm sure there are a world of other things that people mean by it as well.
But the idea of then trying to commit to a mathematical description of these things
means that a lot of that ambiguity just disappears, that if you put a word to a
particular mathematical quantity, as long as you define what that mathematical quantity is
and how it interacts with other things, then a lot of that ambiguity just isn't there.
And it forces you to commit to your assumptions in a much more specific way.
And so that's why I come back to say, does it necessarily matter if an agent is real or not?
I don't really know what that means. But if an agent is just a description of something that is
separated from its environment that persists for a certain length of time, that has a dynamical
structure that can be written down and a set of variables that can be partitioned off from another
bit of the world. For me, that's real enough to be useful. And so that's where I'd go with that one.
Yes, yes. This is fascinating. So it's a mathematical theory that carves the world up
in an intelligent way that explains what things do and what they don't do.
And I guess the ontological statement, maybe we can park that to one side,
because as you say, from a semantics point of view, people have very relativistic
understandings of things. And there's always the philosophical turtles all the way down. Well,
is it really real? Is it really real? But one thing that is interesting, though,
about active inference is that it's quite mathematically abstract. So when we were
saying, is it real? It doesn't even designate, is it physical? So for example, a boundary is just
talking about the statistical independence between states. And those don't necessarily
correspond to physical things. So I guess it could be applied to almost anything. It could be applied
to culture or memes or language or something like that. And it has been. Yes, indeed.
Yeah, it's a good point. And then you end up sort of dragged into the questions of what is
physical. What does that mean? Is physical just an expression of dynamics that evolve in time?
Because I mean, even committing to a temporal dimension tells you something about the world
you're living in. Are the boundaries that we're talking about, are the partitions,
are they spatial in nature or not? And, you know, I remember there was an article a little
while back that sort of made a lot of argument about this as to whether the partitions that
divide creatures from their environments are equivalent to statements of conditional independence
of the sort that are seen in machine learning or various other things. And arguing that there's
something inherently different about a physical boundary. For me, I was never completely convinced
by that, but partly because you have to then define what you mean by a physical boundary.
And I suspect it's the same sort of boundary, it's the same sort of conditional
dependencies and independences. But where those have specific semantics, whether those be temporal,
whether they be something where, you know, you can actually define a proper spatial metric
underneath the things that you're separating out. And clearly, that sort of boundary is very
important. But for me, that is just another form of the same sort of boundary. And as you say,
you can apply exactly the same sort of ideas to things that are not spatial, not sort of physical,
whatever that might mean. Yes. Yes. Because when I when I spoke with Carl last time, I was pressing
him on this idea of a non physical agent, and he was quite allergic to the idea. And I suppose,
even though mathematically, you could apply it first to other geometries, that would be
quite easy, because they have certain mathematical properties in terms of like, you know,
being locally connected and measure spaces and all that kind of stuff. But if you did say,
okay, I want to have an agent that represents a meme. How would that act? I don't know,
you get into modeling challenges, don't you? I suppose you do. I think the modeling challenge
is defining the boundary. I think the boundary is a very difficult thing to define sometimes
when you're dealing with something non spatial. That boundary, though, might be reflected in
the interactions between a meme and a community that that engage with it. It might be to do with
the expression of a meme in different parts of, I don't know, a network of some sort or social
network. I don't know how easy it would be. I've not tried to do it in that context. And I think
with many of these things, you never really know until you've had to go at doing it. But
