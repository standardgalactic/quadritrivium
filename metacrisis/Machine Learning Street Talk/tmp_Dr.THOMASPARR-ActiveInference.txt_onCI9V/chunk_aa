So, welcome back to MLST.
Today, we're going to be talking about this book by Dr. Thomas Parr, Giovanni Pazzullo,
and Professor Carl Friston.
Now the book is Active Inference, the free energy principle in mind, brain, and behavior.
So the book, from a pedagogical perspective, it's describing active inference from the
high road and the low road.
And the high road is a little bit kind of helicopter view, so it's saying, OK, we've
got these biological organisms or these living systems, and what do they do in order to be
living systems?
Well, they resist entropic forces acting on them by minimizing their free energy.
So it goes into the how question, but it also goes into the why question from a helicopter
view.
The low road of active inference is far more mechanistic, far more mathematical, and obviously
both all of the roads lead to Rome, if you like.
But the low road is talking about things like Bayesian mechanics, there's a primer
on probability theory, talking about things like variational inference, which is the way
that we solve these intractable optimization problems in active inference, and also talking
about framing active inference as a process theory, which is the latest incarnation of
the description of active inference.
So Professor Carl Friston wrote a preface for the book.
He said, active inference is a way of understanding sentient behavior.
The very fact that you are reading these lines means that you are engaging in active inference,
namely actively sampling the world in a particular way, because you believe you will learn something.
You are palpating.
This is beautiful, by the way.
Friston uses the most beautiful language, it's his signature, if you like, it's his
calling card.
He said, you are palpating this page with your eyes, simply because this is the kind
of action that will resolve uncertainty about what you're going to do next, indeed what
these words convey.
In short, he said, active inference puts action into perception, whereby perception is treated
as perceptual inference or hypothesis testing.
Active inference goes even further and considers planning as inference, that is inferring what
you're going to do next to resolve uncertainty about your lived world.
So I'm about to show you a sneaky clip of Professor Friston that we filmed in January.
I might publish the full show on MLSD in the future, but I just want to take this as an
opportunity to thank you so much for all of our Patreon supporters.
Honestly, it means so much to me because the last few months I've just been, you know,
trying to make this activity of mine, this passion of mine, a full-time job.
And it's not just because you love the show and you want to support me, you get early
access to content, you can join our private Patreon Discord.
We have bi-weekly calls where we, you know, talk about all sorts of random stuff and you
also get early access to lots of our content.
So, you know, please check that out.
But in the meantime, here's a little sneaky clip from Professor Friston.
The neural network is a generative model of the way in which its content work was generated.
And its only job is effectively to learn to be a good model of the content that it has
to assimilate.
If you put agency into the mix, you get to active inference.
And now that we've got a generative model that now has to decide which data to go and
solicit.
And that's actually quite a key move and also quite a thematic move.
So we're moving from perception machines.
We're moving from sort of neural networks in the service of, say, face recognition into
a much more natural science problem of how would you then choose which data in a smart
way you go and solicit in order to build the best models of the causes of the data that
you are in charge of gathering.
Dr. Thomas Parr is a postdoctoral scholar at the Wellcome Centre for Human Neuroimaging
at the Queen Square Institute of Neurology at University College London and a practice
in clinician.
Now, one of the reviews from the book was from Andy Clark.
He said, it should have been impossible.
A unified theory of life and mind laid out in 10 elegant chapters spanning the conceptual
landscape from the formal schemas and some of the neurobiology and then garnished with
practical recipes for active model design.
Philosophically astute and scientifically compelling, this book is essential reading
for anyone interested in minds, brains and action.
Well, I mean, thank you very much for having me on.
So I'm Thomas Parr.
I'm both a clinician and a theoretical neuroscientist.
So I've been working in active inference for a number of years now since I did my PhD
back in 2016 with Carl at the theoretical neurobiology group at Queen Square.
And I'm now based at Oxford where I split my time between research and clinical practice.
So tell me about the first time you met Carl.
The first time I met Carl, I was considering, so I was a medical student at the time at
UCL and I was considering doing a PhD.
And I remember arranging to meet with him and obviously being a relatively nerve-wracking
experience meeting one of the most famous neuroscientists in the world.
I remember discussing with him about it and saying, you know, this is what I'm interested
in.
Would you consider supervising my PhD if I were to get the funding for it?
And I remember he said, yes, all right, then, anything else.
And I asked, do you want to see my CV or anything like that?
And he said, no, I'll only forget it.
Yes.
That was my first encounter with Carl.
But since then, he's always been immensely supportive and has been, you know, exactly
the sort of mentor that I think anybody would want to be able to develop a skill set and
sort of proceed in science.
I come from a machine learning background.
And since discovering active inference and Carl's work, it's really broadened my horizons.
And at the moment, there's an obsession with things like chat GPT.
And I just wondered in your own articulation, how would you kind of pose the work that you
do in relation to that kind of technology?
It's a good question.
And I suppose there are many levels at which it could be answered, aren't there?
I guess thinking about something like chat GPT in that style of technology, it's clearly
been very, very effective at what it does.
But it's worth thinking about what is it that it does?
And I think chat GPT is an excellent example because so many people are familiar with it.
It has such impressive results in terms of being able to simulate very effectively what
it's like to have a conversation.
But ultimately, it is like most deep learning architectures.
It's a form of function approximation.
It's a form of being able to capture very well the output that would be expected under
some set of conditions given some input.
So you give it some text and it knows which text to predict.
And it's very good at that.
But in a sense, that's where it stops.
It doesn't necessarily do anything else.
That's very different to what you and I do when we engage with the world around us, when
we want to learn about the world around us, when we want to form our own beliefs about
what's going on.
And those are the things that I think it doesn't have in the same way.
It certainly can't act and go and seek out specific exchanges, specific conversations
that it might want to learn from.
Whereas you or I might do that if we wanted to know about something specifically, we'd
go and look for information about that thing.
And I think that's where active inference and the idea of having a generative world
model and understanding of what's there in your world that you can alter yourself, that
you can change is very different to a lot of more passive artificial intelligence.
Probably the point where things become closer is in fields like robotics, where you have
to account for both of those things.
You have to model a world that has yourself in it, where your actions affect the data
that you get in.
And I think that's probably where more of the convergence is likely to happen.
Yes.
So you're describing the difference, I guess, between an observational system and an interactive
system.
So in an interactive system, an agent can seek information and change or bend the environment
to suit its will.
Just to linger on this for a second, though, there are folks who do argue that neural networks
are more than hash tables, because I think of them the same way you do.
They essentially learn a function.
And if you densely sample it enough, just like a hash table, it can go and retrieve what
that function says given a certain input.
But there are folks who say, no, no, no, these models learn a world model.
So is given as an example, or with SORA, they say it's learned Navier stokes.
It's a really good question.
And I think there are some open questions here, and I wouldn't claim to have all the answers
to this one.
I think to be able, again, to take chat GPT, to be able to give the answer it does, clearly
it has captured something about the statistics of language.
It's uncovered something about the hidden causes.
So you could argue there is potentially an element of world modeling in there that is
left implicit.
I think it would be very difficult to pull that out or to sort of see that with any transparency
with something like chat GPT.
And so if it does have something of that sort, probably it's the methods that neuroscientists
have been using for years to understand the brain that might help to try and pull out
those same things in those sorts of architectures.
Maybe some sorts of deep learning and neural network models are very good at picking up
regularities in terms of dynamics as well and being able to predict trajectories.
And I think it's important to say that describing something as a function approximator is not
to criticize or belittle it.
It's a very important thing to be able to do.
And it may also be very important in certain types of inference.
So for instance, things like variational autoencoders are based upon often deep learning
neural network architectures.
But the function that is learned is the one that maps from the data I've got coming in
to the posterior beliefs or the parameters of the posterior beliefs that I would arrive
at were I to perform inference of the sort we might do in active inference.
So you've written an absolutely beautiful book on active inference.
And active inference, in my view, it's a theory of agency, which is to say it describes what
an agent does.
And I'm fascinated by agency.
But could you just start by, I mean, from your perspective, could you introduce the
book and tell us about your experience writing it?
Of course.
So the active inference book that we've written is a collaboration between myself, Giovanni
Pazzullo is based in Rome and Carl Friston, who has to take credit for development of
active inference in the first place.
And the book sort of rose out of our sense that there wasn't a unified book out there
or a resource out there to help people learn about what is ultimately a very interdisciplinary
field.
And so we've all had experience with students coming to us asking for resources, asking
what they need to read.
And it may be we refer them to a little bit of neuroscience work, a little bit of machine
learning, textbooks or specific pages on variational inference or whatever else, giving
people introductions to or places they can learn about the maths they need to be able
to do it.
But then also the biology, the underlying psychology, the long sort of tradition of
previous scientists who worked in related areas.
And so the book was an attempt to try and provide a place that people could find all
of that, or at least references to all the relevant things they needed for that, to stick
to the same sort of notation, which is one of the things that's often very difficult,
and the same formalisms and try and introduce everything in a very systematic way to people.
So I'm pleased here that you found it useful, and I hope other people will as well.
The experience of writing it, I mean, so that took place over several years, partly because
the pandemic got in the way in the middle.
So Giovanni and I were passing notes between one another over email and weren't able to
sort of meet in person to discuss it during that time period.
But I think we're all quite proud of the result that we've got out of that, and people seem
to have responded quite well to it.
You start off by talking about what you call a high road and a low road to active inference.
Can you sketch that out?
Yes, and I think this was one of Giovanni's very nice ideas about how to introduce it,
because as I say, it's very multidisciplinary.
There are lots of ways into active inference, and one of the things that's most difficult
for people who are getting into the field for the first time is knowing where to start.
