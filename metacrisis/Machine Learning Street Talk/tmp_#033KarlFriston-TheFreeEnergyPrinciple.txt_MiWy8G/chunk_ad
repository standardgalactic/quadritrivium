He studied natural sciences, physics and psychology
at the University of Cambridge in 1980
and completed his medical studies at King's College Hospital in London.
A strong indicator of Professor Friston's illustrious career
is that he's been cited over 260,000 times with an H index of 239.
In 2016, he was ranked the most influential neuroscientist on Semantic Scholar
and Carl Friston pioneered and developed the single most powerful technique
for analyzing the results of brain imaging studies.
He's currently a Wellcome Trust principle fellow
and scientific director of the Wellcome Trust Centre for Neuroimaging.
His main contribution to theoretical neurobiology
is the variational free energy principle,
also known as active inference in the Bayesian brain.
The free energy principle is a formal statement
that the existential imperative for any system
which survives in the changing world can be cast as an inference problem.
The probability of existing as the evidence that you exist, if you will.
You can always interpret anything which exists
as being separate to the environment it exists in.
Carl asserts that existence is a kind of interface
between the interior and the exterior.
So the free energy principle,
which is closely related to the Bayesian brain hypothesis,
is a simple postulate with complicated implications.
Any adaptive change in the brain,
or indeed any system which exists,
will minimize surprise or free energy as Carl puts it.
This minimization could be on any timescale
or on any system which resists a tendency
to disorder from single cell organisms to social networks.
The Bayesian brain hypothesis states that the brain
is confronted with ambiguous sensory evidence,
which it interprets by making inferences
about the hidden states which caused the sensory data.
So is the brain an inference engine?
The key concept separating Friston's idea
from traditional stochastic reinforcement learning methods
and even Bayesian reinforcement learning methods
is moving away from goal-directed optimization.
Belief-based updating combines the ambiguous information
with prior beliefs about the nature of the world.
The missing information problem is something
which dogs many areas of machine learning
as we discussed on our GPT-3 episode last week.
Implementing the Bayes rule directly
is often computationally intractable,
and computer scientists drew inspiration from the physics world
for creating approximate inference techniques
called variational Bayesian methods,
and Carl's active inference method
uses these techniques to great effect.
Anyway, Professor Friston,
it's an absolute honor to have you on the show.
Welcome, and how did you come up with this exciting principle?
Well, first of all, let me congratulate you
on that beautiful introduction.
You've said everything that I could possibly say
in the next hour and a half.
So I'll just try and recapitulate what you said.
The road to the free energy principle,
as you have just described it,
started really when I was a student,
aspiring to put together maths and psychology.
So in those days, it would have been known
as mathematical psychology.
Nowadays, computational neuroscience
and leading of computational neuroscience
into machine learning.
So from the start, that was the ambition.
More practically though,
as your brief resume indicated,
I got a bit distracted by becoming a doctor
and then a psychiatrist
out of clinical compassion,
but also partly out of an interest
in understanding how the brain works.
And then, inevitably,
one gets back to mathematical formalisms,
the principles that underlie the sentient behaviour
with which we are gifted.
And the product of that was the free energy principle
or active inference
in a more cognitive neuroscience setting.
I'd like to ask you about two related topics
that have interested in machine learning lately.
One is that I was interested if you were familiar
with the work of Jeff Hawkins from Numenta,
who is a unsung hero among machine learning inspirations.
And he had a quote saying,
it is the ability to make predictions
about the future that is the crux of intelligence.
And recently, with machine learning progress,
such as with GPT-3,
which is a better and better predictive model,
and some would argue, including myself,
also becomes more and more intelligent in a meaningful way.
So my question is,
is prediction really all it takes for intelligence,
or is there more to it?
I think prediction figures very centrally
in the sort of dynamics that we're talking about.
I can answer that question from two perspectives,
often cast in terms of the high road and the low road
to a formal understanding of things like active inference.
So the low road would really be a bottom-up approach,
thinking, what does the brain do?
And on that view or on that approach,
the big move in the 21st century
has been towards predictive processing.
It started with predictive coding
as a nice metaphor for message passing in the brain,
now generalized to subsume action and decision making
and choices and epistemic foraging.
So Andy Clarke coined the phrase,
predictive processing to accommodate that.
And in that sort of formulation of sentient behavior,
prediction is absolutely essential at two levels.
And from the point of view of predictive coding,
obviously it's baked into the title
that you're trying to predict what you will see
under some belief about the sort of late in states
generating some data,
or you could formulate that in terms of compression,
minimizing message length,
and efficient making sense of data or unpacking data.
The prediction in that sense is, I think,
not quite the kind of prediction that you're asking about,
which has this sort of temporal aspect,
sort of the forecasting or anticipatory aspect of prediction.
However, once you move predictive coding
into a sort of Bayesian filtering setting,
and you put dynamics in play,
then when you're trying to predict the trajectories
in the moment,
you are implicitly predicting a short-term future.
So I think sort of prediction in the dynamical
or the temporal sense starts to bite a game.
Beyond that, there is in the neurosciences
an appreciation that that's not the end of the game.
You can get a long way on this low road of understanding
in terms of understanding how we act and perceive
and how action is in the service of perception vice versa
through treating motor behaviour responses
of an embodied brain in terms of reflexes.
And this would be very much a predictive coding
explanation of the action perception cycle,
essentially equipping predictive coding with reflexes
of this sort of in-the-moment sort,
that you could write down in terms of differential equations
or a Kalman-Busey filter.
But the more interesting game is,
I think better cast in terms of planning as inference.
So actually including what I'm doing as a random variable
in your inference problem
and enabling you to roll out much further into the future
and ask, well, what would happen if I did that?
What would my beliefs be about the state of the world
in the long-term future?
And that gives a very different aspect to prediction
that you're predicting the consequences of any move on the world
of any data that you might want to sample.
How will that reduce my uncertainty?
What information will I gain?
What relevance does that have
for the kinds of preferred outcomes
that characterise me as a goal-directed creature?
So I think prediction in its full and glorious
anticipatory sense really takes centre stage.
And when people talk about active inference,
it's sort of implicitly they're talking about
this sort of fuller deep temporal approach
to inferring what should I do next?
And then from those inferences,
selecting the next move to make.
So in that sense, the sort of hierarchical temporal models
that Dalip and Jeff Hawkins have been talking about
for decades as well.
And I can remember reviewing as a handling editor
the first publication in plus computational biology
on this work, and it was refreshing.
And I think that that's exactly the kind of
planning as inference in the future,
consequent on or conditioned upon the different kinds
of policies or sequential sequences of actions
that I could entertain, bringing time for centre stage
into the inference problem.
The high road I should just add,
so using a completely different language now
that I would use as a physicist
to promote the importance of prediction,
takes a slightly different view.
It says, well, to understand the first principles
that underlie sentient behaviour,
you have to understand the dynamics of self-organisation
and in particular, self-organisation of systems
that are open to the environment,
to the eco-leash, to the heat bath, the heat reservoir.
And when one does that, you can use dynamics
and random dynamical systems to say the kind of moves
and changes of the systemic states must have this form
