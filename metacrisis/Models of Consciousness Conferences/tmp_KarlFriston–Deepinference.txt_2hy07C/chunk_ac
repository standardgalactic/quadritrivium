or static outcomes to a model of controlled outcomes and then you put on top of that hierarchical
depth and sort of you know an HOT-like or metacognitive or hierarchical inference
that then takes it takes it takes you to the next level. Does that make sense? Yes, thank you very much.
That's great, it's great to still help cashmere cashmere and so it can actually
be. Sorry, you said it very well. Thank you very much for giving me the chance,
Professor Frist and thank you very much for the talk it was very illuminating.
My question might be quite not directly related to the modelling but in several different papers
of yours and people who work on the free energy principles there is this emphasis or there is
the references to the embodiment and inaction and that has been caused certain level of at least to me
confusion when I want to understand free energy principle from the mathematical perspective
and the way that has been taken by let's say inactivism for instance and the embodiment
and I personally feel there is a little bit of a confusion at the same time for fetchness
towards how this embodiment and agency has been actually attributed from that perspective.
Would you please mind to have some words on that? Yeah, I think the simplest thing to say
is that active inference is quintessentially inactive. As soon as you talk about
an agent or a system or anything that's separable from its environment in exchange with the environment
from the physics perspective you have to talk about trajectories and paths and dynamics and that
you're necessarily entails a reciprocal coupling between the agent and the environment and that
from the environment to the agent so that you can't get away from the inactive, the situated
aspect of that exchange that underwrites the belief updating in a sense that's exactly the
distinction that in response to the previous to Johannes' question you know that this is just
taking generative models into the world of actively exchanging with the source of data basically
so then all the mechanics of that of the kind of data that you can solicit what is the world
you're trying to model? Of course 99% of the world you're trying to model from the point of view
of a neonate is going to be your body. Did I cause that? Did mum cause that? The very fact that I
can control things may be a very late hypothesis that can be confirmed that first rests upon building
a generative model of your motor plant in your body and not just the motor aspects but also the
interceptive autonomic, the gut feelings. All of these things have to be have to be modelled so that
they can be suitably predicted so you can roll out into the future under the hypothesis of fantasy
that I'm in control of that or I'm not in control of that. It doesn't matter these are hypotheses
that you will come to learn by optimising the model so I would put this I put active inference
certainly as a corollary of the sort of physics version of the free energy principle
very very clearly in the inactive camp, in the situated camp and you know when you start to get
very practical about it in terms of the actual plant that is the interface between the belief
updating and the thing that your belief updating about that then you have to become very practical
in body and you have to write down very very carefully for example simulating simple things
like eye movements you really have to think very carefully about how quickly can you move your eyes
you know so these things become very much centre stage once you know once is that the kind of
distinction or was there something more philosophical that are you talking about radical inactivism?
That's exactly that makes me quite confused when I think about it I cannot actually have my head
around it. So I won't speak to that because people on both sides of the fence
you know a lot of my friends people like Sean Gallagher and Jacob Howe and they're like this
they try to sort of dissolve that sort of any tension between active inference and inactivism
but they always leave radical activism undone with so certainly I don't radical inactivism would
have no place in this mechanics. There's something quintessentially representational about beliefs
well so you can write down a belief about hidden states of affairs out there generating your data
unfortunately or fortunately you're committing to a mathematical representationalism which radical
inactivists won't let you do so it's very difficult to talk to radical inactivists. Thank you very much
you definitely clarified that at that point that it was actually looking for an answer.
Yeah thank you very much. Yeah that was a great question I was going to ask a similar question.
So Nguyen would you like to ask yours? Yeah thank you very much for your very clear and impressive
talk on the basis of your large work. One question is about metacognition. So you highlighted
that metacognition is a candidate for conscious experiences. From the animal investigations a metacognition
was shown by Hampton and others in chimpanzees which seem to have a very implicit unconscious
sensitivity how good their memory is. It seems to be that a lot of metacognitive processes remain
unconscious. Why do you think that metacognitive processes in your model are closely connected
to conscious processes and if so can you relate that to any evolutionary benefit or how is your
theory related to evolutionary benefits? That's an excellent question which I haven't got time to
answer in completely but just to deal with the evolutionary aspects. From the maths perspective
natural selection is rewritten as Bayesian model selection using exactly the same free energy
function. So the evidence or the free energy now becomes the adaptive fitness. This is the
probability that this model is there or certainly the outcomes, the physical outcomes,
experienced by this model is realised in a population. So evolution is read as
optimising the structure and the form of the genetic model in the sense of structure learning as
you get in say radical constructivism. Why would part of that structure learning entail
different levels of metacognitive like processes? I think the answer is very very simple. It's just
that when you're encoding or parameterising beliefs there are at least two attributes. One is
if you like the sort of the sufficient statistic that locates your probability mass over this content,
you know it's big or small, nice or nasty, fast or slow and then there's another
sufficient statistic which is the uncertainty of the dispersion and to completely optimise your
belief structure you have to do both which brings to the table a whole if you like other anatomy
which is not just about recognising or detecting this edge or this person or this mood. It's actually
also estimating the uncertainty about it and I think it's that operation of estimating the
uncertainty in my world, the inverse uncertainty would be the precision that has to operate at
every hierarchical level and I think you're absolutely right that you know we have to
in indeed in simulations and indeed in terms of analysing data you have to estimate the precision
of the data at very low levels which will be a long long way away from anything that was
personal or conscious and we do that every day again you know when doing a t-stastic. When we
estimate the standard error we are estimating a belief about the amplitude of random effects,
our uncertainty about our inference and our uncertainty about the data. If one takes that
kind of precision prediction or precision estimation so from the predictive processing
point of view we're now talking about not the predictions of content but the predictions of
the precision of the content and if one that takes that up to a particularly high level in a
hierarchy and associates it with an internal hypothesis that it is me estimating the precision
then it is that kind of metacognitive processing that I thought might be a candidate for
possibly not self-awareness but certainly you know there is self-hood implicit in that that might
have a certain kind of consciousness associated with it so that's what I've talked about before
about mental action that you know estimating the precision of various beliefs encoded at low in
the hierarchy means that you're acting on the belief updating lower down to optimise it as you
have to and that that kind of very high level precision optimisation may be the kind of covert
action internal action action upon your belief updating that might be sufficient to house a
conversation about consciousness. Thank you if I'm allowed to make only one remark I think it's
very convincing that this brings in some self-component but this self-component may be separated from the
conscious dimension but that's in a further debate. Thank you very much.
