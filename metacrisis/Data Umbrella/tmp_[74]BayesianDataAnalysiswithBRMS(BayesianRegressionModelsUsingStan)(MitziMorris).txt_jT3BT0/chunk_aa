Hello, everyone. Welcome to Data Umbrella and our collaboration with Our Ladies New York
City webinar today. First of all, we're going to have the Our Ladies introduction, and I'd
like to introduce you all to Dorota Ritzink, and she is going to share a bit about the
Our Ladies community, particularly the New York City chapter. So welcome, Dorota.
Thank you. Yes. Hi, everybody. I'm here to just give a very quick intro to Our Ladies
and what we're about, and I am one of the lead organizers for Our Ladies NYC, the New
York City chapter. So there's Our Ladies Global, which I'll talk about a little bit at first,
and then I'll go into more detail about our specific chapter. So what is Our Ladies? Our
Ladies is a worldwide organization that promotes gender diversity in the art community via
meetups and mentorships in a friendly and a safe environment. And our mission is to
have more women and non-binary coders, developers, speakers, and leaders in the art community.
We believe firmly that more diversity, equity, and inclusion of people developing our packages
and being a part of our community is a fantastic thing, and that's what we strive for. And
Our Ladies Global is huge. We have a ton of chapters all over the world. I am actually not
100% sure when this image was taken, so it's possible for even more chapters at this point,
but we are everywhere. And it's actually not that hard to get involved. If you don't have
a local chapter where you live, there's a way to very easily start one. So I highly recommend
looking into that. To do that, you can just send an email to info at ourladys.org to get
in touch. You can follow Our Ladies on social media, on Twitter, LinkedIn, and yeah, you
can follow all these different chapters from all over the world. It's great. It's a really
wonderful community to be a part of. So more about Our Ladies NYC. We were founded around
2017, so several years after Our Ladies initially began and was already in several different
places, both in the US and beyond. A few fun facts. So we currently have, actually, we're
up to like 2,900 members on Meetup at this point. So it's quite large. That said, we don't always
have a huge turnout at Meetup events. So don't be discouraged by that very large number. We
host events monthly and contacting us is really easy. You can check out our website, OurLadiesNYC.org.
You can find us on Meetup or on Twitter and LinkedIn. And there on the left is a list of our
current board members, our wonderful group of Our Ladies that helps make these monthly events
possible. So join us. We host Meetup events like presenters, giving talks both technical and
professional development talks. We host a book club. We host networking and social events. And
we typically try to attend a few conferences here and there. And it's great. It's wonderful. We
have a wide variety of ways to participate. And speaking of participating, here are a few ways to
get involved. First and foremost, attend our Meetups, follow us on Twitter and other social media
pages. Join our Slack channel and GitHub pages. And ask questions. You could even write a blog
post for our website if you want to try or handle that. We are always encouraging folks who have
not really written or presented about our technical topic before to get involved. So please reach out
if you're interested in either of those options. And like I mentioned earlier, you could also
sponsor a local chapter if you don't have one near you. Or join the board of the New York City
chapter if you're in the area. And most importantly, spread the word and tell your friends. We are
always looking for more our ladies to join our community. Here's some, you know, contact information.
And that is it. That's the end of my presentation.
Okay. So, Reshma, you're muted. Yes, I'm going to do the data umbrella introduction. Hang on.
Sorry. That's okay. Slides. There we go. Okay. Hey, everybody. So I'm going to introduce the
data umbrella part of it. We're really happy to do this co-promotion and co-organization with
our ladies. It's been something we've wanted to do for a while. So I'm going to do a brief
introduction. Mitzi will do a presentation and you can ask any questions in the chat and we will
answer them as good time to stop and answer. This is being recorded and the video will be
available on YouTube typically within 24 hours. Data umbrella is a community for underrepresented
persons in data science and we are a nonprofit organization. This is the team of data umbrella.
We are in a few different countries around the world and there's a bunch of people that make
it happen behind the scenes. We have a code of conduct and we thank you for helping to make this
making a welcoming, friendly, professional environment for everybody.
There are various ways to support data umbrella. One of those ways is to follow our code of conduct.
Another way that you can do it is to ask general questions and share job events and postings.
You can also donate to our nonprofit. We are an open collective and if you work for a company
that uses Benevity, which is company match donations, that's another way to make a donation.
You can subscribe to the data umbrella YouTube channel. We have over 80 videos there on all
different data science topics and we have over 2,000 subscribers. We have a bunch of playlist.
One of them is career advice. We have playlists such as data visualization contributing to open
source, scikit-learn, PMC and NumPy. We also have a monthly newsletter and I will share the link in
the chat to find out about upcoming events and announcements. Our website, which we are in the
process of redesigning at the moment, has a lot of resources on open source conferences,
allyship language. We encourage you to check it out.
We are on all social media platforms as data umbrella. The place to find out about
upcoming events is Meetup. I have mentioned YouTube and the newsletter and Twitter and
LinkedIn are the two platforms where we are the most active. This webinar platform is
Big Marker and on the top you will see a CC for closed captioning. You can have live transcripts
enabled for this presentation if you would like. We have a call for volunteers. For all of our
videos we add timestamps. If you are available to add timestamps, I will share the link to it
for this video or some other videos. You can add those timestamps on GitHub.
We also have a feedback form which you will find in the handout section. I will also share
the link once I am finished speaking. If you have any technical issues or suggestions for
future event topics or any general feedback. We have a couple of upcoming events in March.
The first one is what is a sales engineer from a computer science background. That is going to
be a fascinating talk. On March 21 we have ML Ops from concept to product.
Today's talk is Bayesian data analysis with MRMS with Mitzi Morris who is a returning speaker.
Mitzi is a member of the stand development team and serves on the stand governing body.
Since 2017 she has been a full-time stand developer working for professor Andrew
Gellman at Columbia University where she has contributed to the core stand platform and
developed command stand pie a modern Python interface for stand. She is also an active
stand user developing, publishing and presenting on Bayesian models for disease mapping. Prior
to that she has worked as a software engineer in both academia and industry working on natural
language processing and search applications as well as data analysis pipelines for genomics
and bioinformatics. Feel free to tweet about this event at data umbrella.
And with that I will turn off my mic and video and hand over the screen share to Mitzi.
Thank you so much for that really great introduction and yes I used to do natural language processing
which is what we're not going to talk about today. Today we're going to talk about Bayesian
data analysis with BRMS and yes so I as a stand developer have not really used BRMS but BRMS is
just really I think well it's the most widely used interface of the stand interfaces and it is
absolutely fantastic so why don't I keep going with my slides so we can make this all very
concrete and clear for you. So BRMS stands for Bayesian regression and multi-level modeling
in stand. The developer who started this project is Paul Birkner he's German which I think is why
multi-level modeling is such a one word noun phrase in that particular use of multi-level
modeling and BRMS package uses the R formula syntax which if you're familiar with R and
fitting regression models in R this is the general syntax that's used to fit to describe
model a regression model and so this snippet of code here we're going to go through
and get to see how BRMS works but first some more background.
So the question here is why should I use BRMS if you want to do Bayesian modeling if you want to do
regression modeling you should use BRMS if you're working in R and you're at all if you've heard
you've heard about stand then you should actually learn about BRMS because BRMS simplifies model
development and it uses the extended R formula syntax to specify the likelihood it has a function
set prior to specify the priors on all the parameters and the BRMS package has lots and lots
of checks so that you can make sure that your model is actually fitting your data
and the downstream analysis packages that are also part of the stand ecosystem
baseplot, proj, pred and lu baseplot is the package that base that gives you plotting
lets you visualize everything in your fitted model, proj, pred is used to investigate the
particular parameters of interest in your model and it's helping you see what kinds of predictions
those particular parameters are going to make for you and lu stands for leave one out cross
validation and lu is a tool for comparing different models BRMS generated stand programs are efficient
and robust so if you have a data set and you know how you would like to model your data you have some
idea of the multi-level model that you want which of the predictors are going to be most relevant
which of the predictors have some kind of grouping structure working with BRMS is very nice because
you can quickly try out a lot of different variations on how much of the problem you want
to put into your model and then with BRMS you write a whole bunch of models and you can use
the downstream analysis packages to do the model comparison and this in a nutshell is the Bayesian
workflow the Bayesian workflow a lot of times when you're learning about stand or learning about a
problem set in doing Bayesian data analysis the model is presented to you and you're you're taught
the model the structure of the model how it fits in with the data and how well it works with
your data set but what you need to understand is that model development is the first piece
of the puzzle the second piece of the puzzle is model comparison some models are going to be too
simple they're easy to write simple to understand but they don't really work that well some models
are too complex some models are difficult to fit or some models are going to buy by building in too
much complexity in your model you might build a model that gives you a very very good analysis
for the data set that you have but it might be overfitting because you've just put too much
stuff in it and so you want to do model development you want rapid model development you want to be
able to to specify a lot of models very quickly and then you want to be able to do model comparison
and to do that BRMS package and its friends give you everything you need
and here's just a little bit of modeling terminology and notation because you're going to see these
terms and you're going to see some of this notation everywhere so I feel like we always
have to go through the slide we're talking about data and when we say data why we're talking about
all of the data we're not making a distinction between your outcome and your predictors when we
talk about theta we mean all the parameters in your model and we're building a Bayesian model
so we're building a joint probability distribution over all the data and the parameters and when
you write a stand program stand is solving the joint probability density so it's fitting all of
the parameters all at once now the important things to keep your eye on when you're doing
Bayesian modeling is this notion of the prior probability distribution p of theta this is
what you know about your problem before any data are observed and then p of theta given why the
posterior probability distribution is what you've learned from your data so it's the probability
of the parameters being what you've estimated them to be conditional on the data that you've seen
with that starting point of p of theta what you already knew before you started fitting the
data to the model the thing that we're really talking about though is the probability of why
given theta the probability of the data given the parameters and when you know the data when
you're fitting your model this is the model's likelihood once you've fitted your model and you've
got an estimate for theta which is fixed this is your sampling distribution and you use this
sampling distribution to generate new data I mean to fit new to make predictions for new previously
unseen data so these are our our terms and the things that we're going to be talking about
our prior our posterior probability distribution and our likelihood
multi-level regression I'm quoting here Richard McElrath if you haven't read statistical rethinking
um this is the book that we recommend to absolutely everybody statistical rethinking
is going to make um statistics it's it's designed to make um thinking about statistics far less
confusing than it probably has been in any statistics class that you've taken um so get
statistical rethinking and read it and the argument that McElrath makes is that multi-level
regression is the default form of regression because multi-level regression models handle
structured data and almost all of your data has some structure your observations can sometimes
be repeated from the same source or else they're ordered or there are some group structure in the
data so an example of group structure is a hierarchical model where you have students in
classrooms classrooms are in a school schools are in districts districts are in states states are in
regions and each of those nested areas is going to probably make the data from that particular
um school be of a certain flavor so we expect that when there's a hierarchical structure
we're getting a little bit of information from every node above your your your bottom most your
your leaf node in the in the tree we're getting information from all of those contributing to
your observation or if you have say an auto regressive you have time series data where the
the next item depends on the previous several items possibly spatial data where you have some
observation and we expected to be sort of similar to observations that are neighboring
spatio temporal where we blow the whole thing out into one big 4d it's my neighbor because it
happened in the time slice right before me in the region right next to me in the volume around me
so these are all examples of structured data and multi-level models let you say more about the data
we can estimate the variation on all levels of the model and with the multi-level structure
we can also say well what if I have a new group and then I can say well I don't know what you know
I don't know anything about the the items in this new group but if I know about the items in
other similar groups I can reason about unseen groups and what you what's what you find though
is once we start building these multi-level models your big data suddenly isn't so big
anymore because you've put all of these qualifiers on every data observation and this makes working
with a multi-level model both more interesting and more challenging
so the history of regression models in our from somebody who spends most of her time
programming in c++ and python is like this we have the pre-existing packages by pre-existing I mean
pre-stand which are LM and GLM for linear models and generalized linear models which
handle single-level linear models and these are part of the base our statistics package
and then you have LME4 which is designed to handle hierarchical linear models the goal of the
stand project which was started in 2010 was to build a better LME4. Andrew Gelman and Jennifer
Hill in 2006 2007 put out a really fabulous book multi-level regression regression analysis and
hierarchical models I forget what the exact title is it's in a subsequent slide and what's really
interesting about that book is that in Gelman and Hill they present a lot of data sets with
LME4 syntax and our code actually and the fact with matter is is that those those those models
can't really be fit with LME4 it doesn't really do the right thing on the data and Andrew's point
was that this is what I want LME4 to do so then a few years later he hired some postdocs to build
a better LME4 and the result was the stand probabilistic programming language and the
nuts HMC algorithm which gives you a much more efficient way of doing Monte Carlo Markov chain
Monte Carlo samplers but that's not what this talk is about so we all I can say is we use stand
on the back end and stand fits your model using a back end algorithm which for the best inference
is going to be nuts HMC and this will the the problem is that stand was designed by computer
scientists and so the stand probabilistic programming language while it builds on bugs
has been relatively challenging for statisticians to work with it it's a programming language it
looks a bit verbose and it's difficult to actually code up a model that does what you think it's
going to do it's very easy to put bugs in your bugs bugs by the way BUGS stands for Bayesian
uncertainty under Gibbs sampling and when I tell this to non-statisticians who've never heard of
bugs they think it's really the best name for a programming language ever but bugs basically
really changed the course of Bayesian modeling it made it very easy for people to write down
their models because prior to bugs you had to write not just your model but your Gibbs samplers so
that really set it for a pretty high bar for people who wanted to do Bayesian data analysis
