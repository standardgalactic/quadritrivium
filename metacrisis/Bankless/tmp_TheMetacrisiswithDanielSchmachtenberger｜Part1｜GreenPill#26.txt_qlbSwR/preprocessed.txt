What's up, coordination? How you doing? Today's episode is with Daniel Schmackenberger, who
is a systems thinker with a deep breath of experience in game theory, political history,
economics, social sciences. And I am just so elated to be bringing this, bringing you this
episode. Daniel Schmackenberger is someone I discovered several years ago on the Future
Thinkers podcast where he was discovering and discussing systemic risks to humanity. So beyond
just climate change, but what he calls the metacrisis, which is, well, you're going to have to
listen to the episode to hear what the metacrisis is. Basically, we're looking for the systemic
game theoretic underpinnings behind the metacrisis and all of the coordination failures worldwide.
Daniel is a founding member of the Consilience Project, whose aim at improving public sense
making and dialogue. And you just hear it in his voice when he's talking. He's a deep understanding
articulate-ness and lucidity in which he's talking about systemic risk. And that includes
climate change, AI risks, biodiversity loss, all these sorts of things that are happening
as humanity is running into its planetary boundaries on planet Earth. And I think that this
is probably one of the most important episodes that we've done because Daniel has thought so
much about what he sees as the metacrisis and our ability to solve the metacrisis by creating a
third attractor towards a better world. So this episode is going to be the first part of a
three-part series in which we're going to be discussing what is the metacrisis and what would
a third attractor look like for solving it. The second episode, we're going to talk about criteria
for solving the metacrisis. And the third episode, we're actually going to talk about
Web3, DAOs, what we've seen with the history of Bitcoin, Ethereum, ICOs, DeFi, NFT, DAOs.
We have a global coordination substrate in order to solve coordination failures. And so we're
bringing the Web3 community's technology knowledge, computer science knowledge, and combining that
with game theoretic design and political history knowledge from Daniel Schmockenberger. And we're
going to try to figure out how we can address the metacrisis. So basically, this series of episodes
is very special to me. I think Daniel is extremely lucid, and I'm so thrilled that he decided to
come on the Green Pill podcast to talk about the metacrisis. Without further ado, I give you Daniel
Schmockenberger. The Opera Crypto Browser is the world's first web browser built for the crypto
community with Web3 support and a non-custodial wallet. Opera lets you access DeFi apps quickly
and easily. The Opera Wallet has buy, sell, and swap features. And of course, let's review your
beautiful NFTs. But the browser still lets you use any crypto wallet extension you prefer, giving you
the choice and flexibility for the Web3 world. Opera lets you view and manage all of your assets
across all the blockchains all at once, and offers seamless multi-chain support between Ethereum,
Bitcoin, Polygon, Binance Chain, and other EVMs and Layer 2s. But Opera goes even deeper than that.
Opera has a built-in homepage for crypto natives with the Opera Crypto Corner, with price charts,
news feeds, NFT updates to make sure you are always on top of your game. And it even has Discord
and Telegram integrated natively into the browser. That's crazy. Opera is truly building the battle
station for the crypto world. Check out Opera, both on mobile, with Android and iOS apps, and on
desktop too. ReFi Summer has arrived, and Sello is here for it. Sello is the Layer 1 blockchain for
the regenerative finance movement. It's fast, planet-positive, and built for the real world.
Sello has committed towards producing a sustainable future from the very beginning,
and is the world's first carbon negative EVM-compatible Layer 1 blockchain. Sello has become
much more than a technology, a currency, a community, or even just a Layer 1. Sello is a
movement to create conditions of prosperity for everyone. You can soon engage with all of this
via green asset Uniswap pools on Sello, benefiting reforestation and other regenerative products
through the Toucan protocol, MAS, and more. ReFi is also about the health of communities and resource
network is creating bankless infrastructure for circular trade and mutual credit networks to
benefit small businesses and local economies all on Sello. Follow along on Twitter to learn more
about how Sello is accelerating ReFi Summer for a positive impact on people, communities,
and the planet. If you're attending ECC, visit the Sello Saloon to learn about what's happening on
the front lines of ReFi from industry experts. Daniel, thanks so much for agreeing to do this
podcast episode with me. I'm happy to be here with you, Kevin. Yeah. So let's dive into the deep end.
What is the metacrisis, and how could the third attract or be a way out of it? Yeah, so just for
preface, we're getting into the metacrisis, which is a way of trying to assess the totality of risk
the world faces and the totality of the problem space that can kind of allow us to wrap our heads
around what humanity needs to do in a big picture sense as opposed to all of the separate catastrophes.
Why is this worth talking about? Because it can easily seem like doom porn or something,
or just a way to demotivate people. I do believe that this is actually something
humanity can rise to the occasion of an address. The famous Charles Kettering quote goes,
a problem fully understood is half solved. And the corollary of that is that a problem
not fully understood is probably unsolvable, because you're trying to address something that
is leaving out critical elements. And so this is not to be overwhelmingly catastrophic. It's to
try to understand the problem space well enough that we can really think through the design
criteria of adequate solutions. And obviously, you are a central node in an ecosystem of tool
builders that are trying to work on coordination and governance, which is so like, what are the
coordination needs of the world? What are the governance needs of the world? This is kind of
what we want to share the metacrisis as a frame for. So hopefully, what we do in this first
episode is try to share a picture of the state of the world that gives some constraints on what
has to happen by when. What are some of the underlying things to address? None of this is
obviously very web three specific. But then the future episodes that we do will be informed by.
So with that said, what is the metacrisis?
Most people are aware of climate change as a possibly catastrophic risk through a number of
different vectors. And well before the full like venusification of the planet, you start to get
extreme weather events causing massive human migration. We had extreme weather events affect
Australia massively, but in areas of low population. When that happens in India, Bangladesh,
Pakistan, Iran, extreme weather events in high population areas, high population density,
extreme human migration, resource shortages, hitting political amplifiers,
you start to have things that can lead to breakdowns of supply chains and large scale
war from climate change before climate change is fully catastrophic just via the planet in
hospital. So climate change even isn't one thing. It's a lot of things, right? And it's one of a
lot of other catastrophic risks environmentally. A lot of people are increasingly aware of dead
zones in the ocean from nitrogen runoff as a result of unstable agricultural practices and
total biodiversity loss and pollinator loss and erosion of top soils and biodiversity loss and
overfishing. And it's like, okay, there's the larger frame there is planetary boundaries.
We have been running a linear materials economy that extracts unrenowably from nature and then
turns it into trash and pollution in nature, much faster than nature can reproduce those things
that we need as raw resource or process to waste. And that linear materials economy
is connected to a financial economy requires exponential growth year over year, which means
we're trying to extract and externalize exponentially more every year from a finite
planet while you start to hit boundaries at some point where it's like we're just running out of
stuff to extract and running out of capacity for pollution. So the planetary boundaries model
and the forecasts associated like the MIT limits of growth model are MIT Club of Rome,
limits of growth model are ways of saying there's not just hundreds of different
environmental catastrophes, they're all the results of some deep underlying stuff like
an economic system that requires embedded exponential growth attached to a linear
materials economy that just doesn't work right like at a certain point you got to change that
thing. Right. On top of this, people are aware of from a crisis point of view, because even if
they weren't involved in like forecasting catastrophic risk and reading things like
Nick Bostrom, superintelligence, when people like Elon Musk and Henry Kissinger start talking very
publicly about the artificial intelligence risk being arguably the most catastrophic near-term
pressing risk to the world. It's like, okay, well, that's not climate change or environment,
that's the whole other thing. Right. And that is similarly not one risk, it's a lot of risks.
There's artificial general intelligence doing its own thing risk. There's artificial intelligence
optimizing for the wrong things and causing really powerful externalities like AI algorithms that
already run Facebook's News Feed and Instagram's News Feed and YouTube's that are increasingly
polarizing the population-breaking democracies that's already like causing catastrophe,
let alone happens or whatever. And then you have biotech existential risks because exponential
technology makes exponentially more powerful stuff exponentially cheaper, which means smaller
groups have access to catastrophe capacities. And so exponential tech makes like nuclear level
problems accessible to not just G8 nations, but all kinds of smaller groups over the next
handful of years. That's a big deal. It's very hard for the world to see how we could make it
through with drone weapons and bio weapons and AI weapons and cyber weapons. How does the world
make it through that well? So if we look at all of the environmental issues, all the exponential
tech issues, all of the fragilities of our global supply chains and the escalation pathways to war
at scale where the post-World War II system is breaking down for a bunch of reasons that we can
get into collectively, we can kind of call that the metacrisis. And so the metacrisis is not one
particular catastrophic risk. It's looking at all of them because to make it through, you have to
prevent all of them. To fail, you only have to have one of them happen. So we really have to take
that holistically. And then to think deeper about it is to say, man, is this really like
a thousand different issues that are all separately? We have to think about individually,
or do they all have certain underlying patterns in common? Where if we think about those patterns,
address those, it would address everything else. Is there some way in which these are all symptoms
of underlying issues? Obviously, your audience will be very sympathetic to the idea that coordination
failures are underneath all of these. Part of why we have the environmental issues is because
it's very hard to have any country decide to tax carbon if any other country doesn't,
because it's going to hurt their economy and hurt them geopolitically. And to make an international
agreement where everyone will takes international enforcement that is really hard to do,
that's a coordination failure. It's a good giant prisoner's dilemma.
A multi-polar prisoner's dilemma, multi-agent prisoner's dilemma, which is called a multi-polar
trap. So multi-polar traps, meaning anybody starts overfishing, then nobody has a reason to not
overfish because the fish will all get fucked anyways. And no one has the ability to protect the
fish, only have the ability to exploit it, and might as well be you rather than them if they're
going to use that to grow their population, instead of they're going to beat you in finance and
geopolitics and war with. And the same with if they're going to build the AI weapons, you better
build them faster. If they're going to build the bio weapons, you better build them in the
defense is faster. So you get these races to the bottom in a bunch of ways. So the arms race,
the tragedy of the commons, the first mover market advantage of tech that externalizes
a lot of harm. These are all examples of multi-polar traps. This is one example of
something underneath all of the crises. So the metacrisis has to solve multi-polar traps
metaphorically, not this particular one or that particular one. So the metacrisis frame is actually
quite useful because then we say, trying to solve each one of these issues and every time a new
technology occurs, a new arms race happens. So as we are having the cumulative effects of industrial
tech, hundreds of years of industrial tech bring us near planetary boundaries, and an exponential
rate of the increase in distribution of catastrophic power from exponential tech, it's like, okay,
we're going to have higher probability on more risks each year.
There's no way we can just keep protecting each one in a triage way. We have to get human
coordination to be fundamentally better. And this means things like we have to address
perverse incentives. How do we categorically identify where there are incentives of
institutions or agents or corporations that are deeply misaligned with other agents of the commons?
And how do we correct those or not? Because any problem that you're incentivizing,
you're going to have a hard time solving. How do we fix perverse incentive writ large?
It has to be a core question. Everybody in every institution, every tech designer is
thinking about all the time. How do we identify externalities and internalize them has to be
a core question. How do we identify multi-polar traps and resolve them? These are like generator
dynamics generated from the meta crisis. Got it. So let me just say back to you what
I heard to summarize for the audience. So it sounds like the meta crisis is like
a lot of different crises. It's the dead zones in the oceans. It's climate change. It's pollinator
loss. It's biodiversity loss, but it's not just living capital. It's AI risk and technology
breaking democracy. It can be biotech existential risks. We've got nuclear level technology being
decentralized into the hands of everyday people in a world that has increasing fragility because
our industrial age institutions are breaking down. And on top of that, we've got these planetary
boundaries which are fixed and we're running this linear materials economy with a political system
that has to have exponential growth in order to function like the government's literally forecast
two to four percent growth as a baseline for each of their economies. And so basically your
approach to this problem is we have to solve all these problems. We have to solve more than just
climate change. And you're looking at the systemic generator functions of these problems in order to
solve the giant prisoner's dilemma, multi-polar trap, arms race, tragedy of the commons that's
beneath all of them. And so you're kind of looking at the systemic generator functions
of these existential risk as a means of solving all of these different meta crises. Did I get
that close? That was the best recap I've ever heard, that's when I'm smiling. Great. So I think
that the second question, the first question I asked you is what is the meta crisis? And then the
second one was what is the third attractor as a way out of it? So let's pull that thread.
Yeah, so third attractor obviously indicates that there's two other attractors. Attractor is this idea
of in a very complex system, we might not be able to predict exactly the path something
takes, but you can say it's trending in a certain general direction, like almost a topological
direction. So when you think of attractive basins, think about a watershed. What particular pathway
or raindrop flows down the hillside, impossible to predict, right? Navier-Stokes equations on
fluid dynamics are actually unsolvable. To be able to say if it falls on this side of the mountain
range, it'll end up in this lake is pretty easy, right? Like the water is generally going to be
converging to this lake on this side of the mountain range is going to go to this one. So it's
like, oh, there's an attractor. This entire side of the watershed has an attractive basin. So even
though we can't predict all of the specifics, we can see general directions. So right now we would
say there are two very high level of tractors, the direction of the world and the generator
functions of the metacrisis are heading towards that both suck that we don't want. And one is
increasing catastrophes and breakdown. And the other is dystopic control structures.
So catastrophes and dystopias. At the Consilience Project, we have some papers on
chaos and oppression and stuff like that where we're looking at these models. People want to
turn to it. So catastrophes, we just talked about, right? And the catastrophes don't have to be like
one of the major nations launches a strategic nuclear war. It can be the entire global economy
keeps doing what it has to do. And nobody's trying to cause climate change, but climate change as a
as a externality of the thing that it has to do is the example of the coordination failure.
The distributed collective action is leading to a collective catastrophe that nobody wants,
but nobody feels like they can solve. Because unless everybody agrees to do the other thing,
anybody trying to do the other thing loses in the near term. And so the catastrophes are not the
result of somebody trying to do some done catastrophic thing that the result of the
coordination failures and that kind of attractor dynamic. The same way that it's like with climate
change or any environmental issues, it's very distributed. It's the entire market causing
them because almost every movement of goods or services has an environmental externality, right?
And even digital goods depend upon material supply chains to make semiconductors and transistors
and servers and satellites and shit like that. So the almost every dollar that transacts in the
world, something like $100 trillion a day has environmental externalities. That's a big deal
to get, right? Like, okay, there's some very deep things about our economy that have to change.
So the catastrophes direction is very decentralized. And as tech gets more powerful,
there's this idea that we like of like, oh, exponential tech will like democratize everything.
And democratize everything sounds nice superficially, but the democratization or
giving to everyone catastrophic capabilities, not such a nice idea, right? Like, it's kind of nice
that only the G8 have nukes, it'd be kind of nice if no one had nukes. And if anyone has nukes,
it would be nice that it's not that many people they can monitor each other and do mutually
assured destruction. It's very hard to make nukes, right? There's not that many places
that had uranium enriching uranium is really hard, you can see it being done from satellites.
When we start talking about cyber weapons, that are pretty fucking easy, like small groups of
hackers can do in their basement, but then you can take out infrastructure targets,
they can kill a lot of people, right, mess up a lot of stuff that non state actors can use in
their basement with no exotic materials. That's really tricky. The same with drone weapons, the
same with tabletop crisper, which is coming about the same with GPT three, and more advanced AI that
can make Turing test passing propaganda ubiquitously in the next few years. So decentralized catastrophe
weapons for everyone, not such a good thing, right? Now, how do you prevent that stuff? If people can
make catastrophe weapons in their basement, the first obvious answer for how to prevent it is,
well, you have to know what people are doing in their basement. So surveillance state could prevent
it. And you kind of make sense to have surveillance. If someone can do something so catastrophic,
you don't want to wait till they do it, right? You wait till somebody shoots up the school,
it's really a bummer. But as you go from a knife to a gun to an AR 15, as you go from that to
tabletop crisper, it's way worse. And you kind of can't wait for people to do it,
you got to be able to preempt it. Okay, well, how do you make a surveillance state that can
know what everybody's doing in their basement that is not susceptible to capture or corruption
becoming a totally fucking legal dystopia? And similarly, how do you control all of the markets
to not do it's in market incentive without something that looks like global government?
Because again, if US wants to or Europe wants to price carbon properly, they will price themselves
out of existence relative to China or India if they don't do it also. And if somebody says we
won't make the AI weapon and the other one does, they win. So in order to really be able to solve
those problems, you need something like international agreement, which only means something if you
have international enforcement has that much power. And how is that okay? And so it's like on
one side, we really don't want global government because we don't want dystopias. On the other
side, we really want global government because we don't want multipolar traps. So this is where
the two attractors are catastrophes and dystopias because typically make to prevent the catastrophe
requires a enforced control structure and the control structure that has enough monopoly of
violence or monopoly of enactment or enough power to keep this happening. How do you create checks
and balances on it? So those are the two attractors. So when we talk about a third attractor, it's how
do we make a world that avoids all the catastrophes and isn't dystopic, meaning that the control
structures that prevent the catastrophes have checks and balances on themselves that prevent
them from being corrupt. And so whatever world we want is definitely in that third attractor.
I don't think anybody is like, I want the catastrophes or the dystopias model. So it's
pretty easy to agree on. We want something not those two as a starting place.
Right. So what I heard is that like, you can almost imagine the third attractor,
like in order to define the third attractor, you need to define the first two attractors.
And you can kind of think of these as just like general directions like waters. I'm in Colorado,
so I'll just use the Rocky Mountains, like water going on the west side, the west slope of the
mountains versus the east sides. Those are the two attractors of the water basins in Colorado.
We're talking about a game theoretic incentive gradient in which we have two attractors. The first
attractor is societies moving towards catastrophes, which is having those systemic metacrisis risks
that we talked about earlier. And then increasing dystopias, which is kind of like centralized
control. I want to say China here, but I'm not sure if you'd agree. So like the two axes are
how well are we solving the metacrisis with coordination. And then the other axis is how
centralized and corrupt is the system of surveillance. And we're looking for a third attractor that
allows solving of the metacrisis without dystopic surveillance and governance. Is that fair?
Yes. Okay. And if people haven't watched it, there's a really great YouTube video. It's about
18 minutes from a guy named CDP Gray called Rules for Rulers. And first to just go before that,
if people have not read it, there is a article called Meditations on Molok on Slate Star Codex.
Meditations on Molok is kind of the best article out there describing multi polar traps. So the
thing that we have like a decentralized coordination failure. And I'll go ahead and just try to state
it succinctly because the catastrophes are largely the result of this kind of Molok multi
polar trap side, which is where you have a number of different agents where each agent
doing what is in their own rational like authentic rational best interest in the short term
leads to collective behavior that is in everybody's worst interest in the long term.
And yet where nobody can make the good long-term choice because they lose in the midterm if they
do. So what I think you call a really adaptive tip becomes obligatory because if you want to
keep up in the economy, you have to adapt the sort of defection in order to keep up with everyone
else. Whether it's if they start, if somebody else starts cutting all the trees down and we
don't have some enforcement to stop them, then me not cutting the trees down doesn't protect the
forest. It just means that they get all the advantage that they'll use in war against us. So now we'll
just race to cut the trees down faster or the climate change or the whales or the whatever.
That's a tragedy of the commons. We solve those nationally with a monopoly of violence and law,
so we can say, no, you're allowed to log these areas, but not the national parks. And if you try
to log the national parks, we can send a police force that has enough monopoly of violence that
even if your loggers bring some guns out, they're not going to. But without a monopoly of violence
and rule of law, you can't really solve that thing. And so within a country, law is a way to try to
solve a multipolar trap by centralized capacity, right? Then you start to worry about, oh, does
that centralized capacity get corrupt? Does it actually do the will of the people democratically
or does it get corrupted? Now we get kind of dystopic police state things. And so we can see this
teetering between those. Now, as soon as we deal with international issues, there is no ability to
do rigorous enforcement because now the police state, since you don't have a police state across,
it looks like a war. So we can do sanctions and stuff. But at a certain point, it's like,
the war is going to hit us back hard enough because we don't have monopolistic power that we
have a deterrent against giving them the deterrent. And so, and especially if the other guy has nukes.
So let's say China doesn't want to tax carbon properly because it would hurt their economic
growth too badly. So we really can't because otherwise economically we're fucked. So we say,
okay, well, we're going to do it and we're going to force you to do it. Well, how are we going to
force them? If it's, we can tariff or whatever. But if they're like, no, ultimately, we're just
going to do this and we're going to win. Are we going to bomb them? If they also have nukes? So
this is where the tragedy of the commons gets tricky, right? There's a lot of small scale
tragedy of the commons where Eleanor Ostrom or like local law stuff works. But when you get large
scale with a lot of power invested in it, it gets much trickier. And the arms race, if anybody
builds the weapons and we don't know if they are not because they could be building them in an
underground base and who knows? We have to assume they are and we'll just build them anyways. We
have to race to get there faster. And the market arms race, they're going to get first mover
advantage. If they get first mover advantage, they'll win everything because you're going to get,
especially in tech, that has network dynamics. Whoever network dynamics in Metcast law lead
to natural monopolies, right? You end up getting one Google that's bigger than every other search
engine. You get one Amazon that's bigger than all the other online stores, one Facebook that's
bigger than the other social media. As a result, whoever gets to take away effects, the runway
effects on Metcast law is going to win. So you have the incentive to not avoid externalities. So
just fucking go for it as fast and aggressively as you can. Silicon Valley's move quickly and break
things deal with it later. So anyone who tries to be thoughtful about externalities move slower
just loses. So it's maladaptive to want to solve this problem. So it's maladaptive because ultimately
there is a perverse game theory that orients towards people who are more focused on upside than
avoiding risk. Because if I'm focused on selling the benefits of the AI or the CRISPR or the whatever
and not the risk heavily, then I'll get first mover advantage and I'll win. And all of the risks,
all the externalities, I won't have to pay for my company to have limited liability protection and
I'll socialize the losses. So Facebook didn't have to pay for breaking democracy and polarizing
the left and right and whatever, but it got to privatize trillions of dollars of gain.
And so the incentive is to not take risks seriously. And this is why we actually need
laws because the market does not incentivize long-term thinking appropriately in a lot of these areas.
So Meditations on MOLOC, multi-polar trap, that gives you that side. But the rules for rulers
is another version of the same phenomena, but for centralized coordination, like centralized power
system corruption rather than decentralized poor coordination. And it basically says you can't
really have enlightened dictators long-term. Because let's say to avoid that multi-polar
trap situation, you do create a centralized authority that has a monopoly of violence or
monopoly of enactment. And you put a really enlightened dictator or an enlightened small group
process in there, in oligarchy or whatever. Well, if there are some malevolent people who really
want that position of power and they're willing to do malevolent corruption to get there, they'll
probably win because if they're not constrained by values, they will have more possibilities
available. So for the enlightened dictator to stay in place, they have to be able to deal with the
malevolence aimed at them, which makes them less benevolent and more malevolent. So there,
the race for who can get in the position of power ends up having a corrupting influence. That's what
the ruler thing shares. And so this is why you're like, okay, well, power tends to get corrupt.
This way we don't want a one-rule government. We want something to check it. But if you don't
have a one-rule government, you get this, how do you stop arms races and global tragedy of the
comments? So people should definitely read Mentations on Wallach. Watch rules for rulers
and say, okay, the third attractor has to solve both of those.
Right. So at this point, listeners will probably know, but you may not know this,
that in the 2019 crypto bear market, Meditations on Wallach went viral. It was something that
really meant a lot to us in the Ethereum ecosystem as coordination failures were sort of
given this prominence as the highest thing that the Web3 ecosystem could solve. And there was
actually a DAO that was launched called Bullock DAO that this sort of interesting meant to solve
coordination failure. So I think most of the audience is probably really familiar with Meditations
on Wallach. And we'll put links to that and rules for rulers in the show notes so that they can go
check that out. I don't know the people at Mollach DAO or what it's doing. It's kind of exactly
the wrong name, but like, I get it. Yeah. Yeah, I could see that. Really what you wanted to,
I think Yula was the name of the God of art and softness and all of the kind things in the Meditations
on Wallach piece. And Wallach is the God of coordination failures. They named it after the
thing that they were trying to slay in a funny sort of way. So the tricky thing that's very
interesting is it's like, let's take a small personal example of this large thing. Small
personal example is if someone has grown up with ideals about kindness and honesty and virtue and
turning the other cheek and redemption for everyone and things like that, not everyone did
grow up. A lot of people grew up with just a lot of trauma and shit. But let's say somebody did grow
up. They really try to enact that. Awesome. At a certain point, if they have enough success
and they get enough power, then they become a tractor, a honey trap for people who do not
have those values and go, oh, that looks like a sucker that I can take advantage of. And then
they realize that there's a lot of dark triad personality disorders and pretty fucked up.
Then the naive ideals to cynicism. The cynicism is like, man, the no good deed goes unpunished
and the people that you trust the most end up fucking you and whatever. Well, that's not a
reasonable place to go or to stay. But you also can't go back to naive ideals. You have to move
to this like post cynical, right? There's naive and like a post cynical place that is focused on
how do those virtues actually get enacted knowing that there are some people who don't share them
and will even try to game and play them. So how can I be aware of people who are willing to be
bad actors? Do I deal with that? Well, still working to be a good actor, find other good actors,
coordinate with them and even help the bad actors like help there be more incentive for people to
become good actors, not bad actors. How do I ensure that my life energy is working on the world
moving towards good actors for everyone? Effective requires not being fucked by bad actors. In the
meantime, the reason I bring this up is because when people think about what is the ideal world
they want to create, it doesn't include other people badly motivated trying to fuck it, right?
And it's a world where everyone cares about the comments and cares about each other and are kind
of like virtuously motivated and honest. The transition from this world where people have
been incented not to be that thing and traumatized and conditioned to get ahead game theoretically.
The transition from this world to that world is different than trying to just win at this world,
which will just keep being in service of Moloch. But it's also different than being in a world
where you don't have to protect against Moloch because it's already been defeated.
You're like, okay, I am very committed to not being in service of Moloch. I'm also committed
to not being naively just duped by Moloch and beaten. So that means that I have to be
game theoretically aware and I have to be able to build things that have power,
but they're ultimately really authentically in service to transcending that.
So I just want to, I've been sort of diagramming a little bit as we've been chatting and I just
want to get your reaction to this little diagram that I made right here. So I've got a two by two
matrix on the screen and basically the x-axis is how well are we solving the meta crisis
coordination failures. The top end of this is really well and then the bottom axis is not really
well. And then the other part of the two by two matrix, the y-axis is how centralized and corrupt
is the system of governance and surveillance. And then the bottom left, where we're not solving
the coordination failures, but we've got maybe decentralized, something decentralized or maybe
laissez-faire, you've got catastrophes, which we've learned about the coordination failures that
are created there because of meditations on Molek. In the top right quadrant, we've got dystopias
and those are centralized, but they may have solved the coordination failures and rules for
rulers are kind of the, what we're looking for there. The third attractor is trying to solve for
solving coordination failures, but without a centralized corrupt system of governance. And
so the problems that we have to solve there are how do we solve coordination failures in
slay Molek, but how do we up-level the actors that are good actors and not get fucked by the bad
actors? I'm a pretty visual person and people who are listening to this in audio are just going to
have to forgive me, but I'm curious if this two by two matrix resonates with you at all, Daniel.
Yeah, it's really good. I like it. The one thing I would change about it is, and this is good that
you put it there, is the x-axis, it says how well are we solving for meta crisis coordination failures.
I would not define the meta crisis as the catastrophes. I would define the meta crisis
as being stuck between catastrophes and dystopias where our increasing tech and exponential tech
makes both catastrophes and dystopias more likely. So on the bottom x-axis, I would say,
how well are we solving for catastrophes? I see. And how well we prevent both catastrophes
and dystopias or corruption is how well we're solving the meta crisis.
Right. So the meta crisis is... Yes, correct. Metacrisis is angled like you're doing there,
visually. Okay. And then what that means is your bottom left corner is catastrophes,
your upper right is dystopias, your bottom right is we have a third attractor, your upper left,
which would be the worst of everything, is the one that we're currently doing.
And that's actually worth noting, which is increasing catastrophes and increasing dystopias
at the same time. So let me explain that quickly, because that's actually the most probable thing,
which is you don't get an AGI that kills everything right away and you don't get strategic
nuclear war that kills everything right away. You get increasing catastrophes. So COVID sucked
worse than a lot of things before it. And now the Ukraine-Russia war sucks worse than the wars we've
had before. And the level of polarization in the US sucks worse, but it's not full-blown
civil war. It's not full-blown World War yet, but it's kind of like moving in that direction.
So then with each catastrophe comes control mechanisms to try to deal with it that centralize
power. Those centralized powers either start or get corrupt or at least get captured by
corruption at a certain point, because that's the way it happens. So let's say the first cyber
attack on infrastructure that really fuck stuff up happens, or the first drone attack on infrastructure
really fuck stuff up happens, then we justify a bunch of surveillance and it won't be the good
type of surveillance. It'll be the bad type of surveillance. And already we can see that China
has learned from the US model and other places. And it's like, no, if you just let all the tech
be developed by the private sector, the private sector gets so fucking powerful when you have
trillion-dollar corporations with exponential tech, they're stronger than the nation-state.
The nation-state can't bind them. You stop having rule of law and those new corporations basically
become a feudalism that kills the nation-state. So we actually have to keep all of our corporations
in check. And by the way, since we know how powerful exponential tech is because we're
developing it, you also need sesame credit and an IoT surveillance system. They're not stupid.
They're actually taking the problems of decentralized catastrophe weapons and the
decentralized catastrophic capacity to the nation-state of major corporations seriously.
But they're doing it in a way that we would consider a level of centralized control that
we're not okay with as far as civil liberties go. So what happens right now is you get a little bit
more catastrophe. And then the world says, oh my God, this is so bad, we have to deal with it. And
the response involves something strong enough to deal with it that involves granting more authority
to some agencies. We've already seen this. Like every time you have a 9-11, then you get a
Homeland Security Act and a Patriot Act that creates less oversight and more corruption of
government because they can't share everything because it's national security secrets and the
Constitution can be suspended for some period of time under FEMA or whatever it is. So you have
this play where each catastrophe motivates us to want a solution enough to accept a dystopic one.
And then the dystopia is not a global control system. So now you just have multiple control
systems competing in a more fierce arms race driving other types of catastrophes. So the
upper left quadrant there is catastrophes and dystopia is driving each other. And so one of
the reasons I like to frame this together is, and the reason I like the Metacrisis frame,
and this is not to dissuade anyone from doing anything. It's actually,
at first, that's what it feels like. It's like, fuck, this is too hard to do anything. But that's
just whenever the complexity of the problem assessment goes up and you're not used to it
and your thinking isn't there, of course, you're not going to be able to come up with solutions
at that level of complexity. But once you spend a while and get used to it and get
comfortable with it, then you can start thinking about solutions at the right order of complexity.
You just have to stick with it for a bit. It's quite easy if I take an individual catastrophe
to solve for it in a way that makes another catastrophe. So for instance, can I feed hungry
people in an area where you've been starving with more conventional agriculture with NPK
fertilizer that increases the nitrogen effluent and causes more dead zones and oceans faster?
Yeah, of course. Can I do certain types of geoengineering for climate change that might
cause other really catastrophic effects on the environment? Totally. So can I try to
solve climate change by some global tax on carbon that actually leads to World War III?
Because if all of a sudden GDP goes down rapidly, now each country's need for more stuff means they
have to take it from each other as opposed to a very positive sum situation. So if you're focused
on climate change and you're not focused on how to prevent World War III and economic
relationships, you're going to be a problem. And so you can drive, you can solve one catastrophe
and make other catastrophes more likely, or you can solve catastrophe as a whole and make
dystopias more likely. I also have some friends working on anti-authoritarian tech, how to prevent
the dystopias, and they're making catastrophes more likely. And so what I want is for somebody to be
anyone who's thinking about this to be able to think about all of them and say, how do I
solve for this catastrophe while not driving other ones or dystopias? How do I make sure
that solving for this catastrophe means being able to have some kind of visibility into the
dynamics that would cause it and some type of control mechanisms or enforcement? How do I make
sure that that one doesn't externalize harm to other areas, which means I have to understand the
connected map enough? And how do I make sure that that enforcement mechanism has enough checks and
balances on itself that it isn't corrupt and can't be captured by corruption? And that's just,
okay, now I've got the design constraints to be able to think through it. And of course,
the first lots of ideas will be wrong. But that's the important thing is to hold that there are
dialectics of constraints, where you can easily make something better and make something else
worse. And that is one of the drivers of the metacrisis. One of the underlying drivers of the
metacrisis is that we define problems too narrowly. And then we solve that problem and our solution
drives other problems. And so if you want to stop making some metacrisis worse, you have to make
sure that whatever you're solving isn't making other shit worse, right? Right. Yeah. So it sounds
like basically any attempt to solve for a catastrophe or a dystopia can end up having an
unintended consequence in which you're trying to solve catastrophes, you create more dystopias,
you're trying to solve for dystopias, you create more catastrophes. And what we're looking for is
a tradeoff space in which we're not kicking the can further down the road in order to
make that happen. Is that right? And if so, how do we do it?
I can say that there's a lot we can discuss on how to do it that we will do over this series of
conversations. And nobody myself included knows the whole of that story yet. Like there's a lot
that we have to discover. And that's why a podcast like this makes sense is to
help the parts that we do know to be more widely shared so that we have a higher starting point.
So more people's collective intelligence can be focused on solving parts we don't know yet.
Right. Yeah. So I think we're kind of trying to create a shelling point for more people to be
learning about catastrophes and dystopias. Or I think you want to still be that this is maybe
we're creating a false attractor or an attractor towards people solving that problem. And hopefully
that gets more people thinking on on these problems, which increases the likelihood that
we can solve them. I don't want it to be a false attractor. I want it to be a real attractor.
So like for me, if I see climate change, like climate change
for people who have spent some time thinking about it and studying and caring about it,
see the extinction rebellion movement and groups like that being like, well,
this is so fucking serious, we need to like get all hands on deck and focus on this.
And they realize there's a lot of force against solving it. And it's a tricky thing.
For me, looking at all the other connected issues, I think it's even harder.
You were just watching some of the conversations Nate Hagens and I had together. And if
yeah, great stuff. Maybe that can go in the show notes, but like his work really highlights
that global GDP and global energy use are almost perfectly correlated. They're 99%
where meaning increases in efficiency of tech that can make more dollars per joule
only change the correlation by 1%, which is not enough to even keep up with the increased
demand. So we can pretty much consider them tightly coupled. If GDP and energy use
are tightly coupled and GDP has to go on an exponential curve just to keep up with interest,
which compounds alone death or anything else. That means an exponential demand for energy.
And we're already at a diminishing return on hydrocarbons, meaning it takes more barrels of
oil to get new barrels of oil than it used to be. And that's why we've went to fracking and
tar sands and offshore oil drilling and like, not just the easy stuff is because we've already
tapped a lot of the easy stuff. And so now we're going into the hard stuff and you get
diminishing returns. Well, if you're getting diminishing returns on energy density and energy
investment, at the same time, you're in the verticalizing part of an exponential curve on
GDP and this energy demand, you got a problem that's eminent. And the answer of renewables,
something like from 2019 to 2021, the increase in demand of energy is more than all renewables
ever built. So like, yes, we're doing more renewables, but the demand is going up on an
exponential curve. And the renewables, a lot of fucking energy, right? Like,
it takes a lot of coal and oil to make a solar panel and to make the batteries to back it up. So
if it takes 10 years for the solar panel running to just break even on the oil it took to put into
it, then to try to meet all of the energy needs plus make all that new stuff. It's like, whoa,
this is really tight. Okay, so we understand that it's not just that dollars and energy are coupled,
but pretty tightly dollars and energy from hydrocarbons are coupled because the other solution
just not really totally convergent yet. Well, climate change sounds, it makes sense why it's
so hard because it's not just going up against the oil industry, it's going up against the market
itself, right? Because if you make energy more expensive, you make every fucking industry more
expensive because there's an industry that doesn't need energy. If you make energy, it's real cost,
meaning the cost to pull the CO2 out of the atmosphere and to clean up the oil spills and
to make renewable hydrocarbons, then energies goes up to a million dollars a barrel or whatever
the fuck it is and the entire market collapse, no market works. So you're like, all right,
so we're trying to solve climate change is like going against the entire global economy. It makes
sense why it's so goddamn hard, right? Right. Just one issue, right? That is not the fucking AI
issue or the biotech issue or the, and so then you're, so for me, when I look at each of those
issues and I see how hard they are and I see them as individual issues, if I think of them all as
separate, it's impossible. Like, there's just no way that we can do what it takes. Yeah. A thousand of
them. Death of a thousand cuts. Yeah. When I see that all of those issues are instantiations of a
couple of deep patterns, like the pattern of perverse incentive, the pattern of incentivizing
externality, the pattern of multipolar trap. And like, there's really only a few of those patterns
that account for all of it. That actually moves it from feeling impossible to really, really hard,
but tracking. It's like those few deep coordination things we have to address. And they do require
changing human motives. So that's both external incentive and, you know, judicial systems,
but it's also human values and culture. And it's also the fact that mediates them. So there's like,
there's tech infrastructure stuff we have to do. There's like legal, economic, social stuff we have
to do. And there's totally like cultural value system stuff we have to do. And we have to do some
stuff in each of those three that intersects each other and leads to virtuous cycles in time.
Right. But when I get to see the entirety of the metacrisis, it actually starts to move from
feeling impossible to tractable, really hard to tractable, because like, oh, there are patterns
across all of this. And it's impossible at the level of all the symptoms, but at the level of
underlying drivers, we can at least start to wrap our heads around it.
Immutable X is the Layer 2 platform for crypto gaming. Immutable offers massive scalability with
up to 9,000 transactions per second and instant transaction confirmation. No more gas fees,
no more waiting around for your transaction to clear. Immutable's zero knowledge roll-up
finally unlocks the world of crypto gaming. Immutable X is the only gas-free NFT minting
platform with over 26 million NFTs minted all with zero gas fees. With the power of
Immutable, gaming developers don't also need to become smart contract developers,
they just need to plug into Immutable's API and instantly start unlocking the full potential
of crypto assets inside of games. This is why world-class companies and projects have decided
to deploy on Immutable X, like GameStop, Ember Sword, Planet Quest, Illuvium, TikTok, and many
more behind the scenes. So start building your game on Immutable X today at immutable.com.
Coinshift is a leading treasury management and infrastructure platform for dows and crypto
businesses who need to manage their treasury operations. Every crypto organization manages
their treasury, and Coinshift offers a simple, flexible, and efficient multi-chain treasury
management platform built on top of the extremely secure Gnosisafe. With Coinshift,
your organization can go from primitive single-chain treasuries to expressive,
flexible, multi-change features such as global user management, global contracts,
proposal management, and many other features that can be shared across an entire organization.
Coinshift layers on powerful treasury management tools on top of the proven security of Gnosisafe,
allowing users to save time and reduce operational burdens and gas costs.
Coinshift even has data tools like account reporting across the seven chains on which it
operates. Used by industry powerhouses such as Uniswap Grants, Balancer, Consensus, and Misari,
Coinshift is speeding up the coordination and efficiency of the organizations that use it.
In DeFi, you have to keep up with the frontier, and Coinshift makes that easy. So sign up at
Coinshift.xyz slash bankless. And I think that, you know, one of the things I wanted to make sure
that we got to in this conversation is where your hope comes from, Daniel, because I don't want
listeners to leave this episode thinking, oh, we're all fucked. And I don't think that that's
what you're saying. From the Nate Hagen's podcast, when I listened to that, you all talked about a
lot of bend not break. So basically, what is the aperture through which the humanity could steer
itself through the metacrisis in which these systems bend, but they don't break? The systemic
risk is not realized in systemic downside for humanity. And I want to ask you where your
hope comes from, Daniel. And what is the hope for solving the metacrisis and the future of
humanity on this planet? And how do I look at my kid in the eye and have hope that they're going to
have a non dystopic and non catastrophic life? Let me start with like three or four or five
of quick examples that will be so high level, they might seem hand wavy, but they're real
of specific ways that the tech that is oriented to breaking stuff and either catastrophes or
dystopias currently could also be repurposed to build a third attractor. And I want to just give
a couple of these examples because it is not currently the case that the financial incentive
or the political motive and regulation or whatever or the market incentive is such
that the tech is being built for these purposes. It's totally oriented to the two attractors we
have, but it could be like the tech is definitely new capacities and it could be oriented towards
things that are really in the right direction. So I want to give a couple of these examples
and there's way more like we can pretty much show for each example of technology
how it could be restructured in both the design of the tech and the regulation around it and etc
that it oriented third attractor. Then I want to go to the deeper part about what about human
nature is inspiring for me and then the even deeper part of like relationship to the topic
of hope or faith itself. So tech, there's a group called Planet Labs, a company publicly traded
company, the largest private satellite company, satellite imaging company in the world.
Team over there are friends and we've been in conversation recently because they image the
entire surface of the earth every day. And so their customers are only the very, very large
government and corporations that have the kind of machine learning capability to process 30
terabytes of compressed information into something. But as they get the machine learning capability
to process that and deliver a more usable product to more people and they're getting more satellites
with more sensors, the real time ability to see everything on the surface of the earth
is emerging in a way that is not actually controlled by any government there because of
laws regarding being an international airspace. They actually can show in detail what's in the
military bases of US, China, Russia, everywhere that's happened like it's a wild look. But that
also means they can show where the fishing boats are that shouldn't be and where they came from.
They can show where the logging is happening. They can show where the mining dams are breaking and
the toxic affluent is going out and the and be able to rewind where the affluent and the dead
zones in the ocean are. That's a level of forced global transparency that makes international
agreement much more possible because it makes the transparency to track the agreement possible where
then enforcement mechanisms have a chance. That's a humongously promising thing like that's a big
deal to be able to say like, Oh, actually, you have no plausible deniability on who did that
pollution or who did that illegal fishing like we know exactly where the fuck they came from.
We can press rewind and watch the entire thing. Well, that helps multipolar traps, right? Because
one of the things that makes multipolar traps worse, as you know, in the prisoner's dilemma,
it's that it's a lack of communication that makes coordination. If you can't know what the other
actor is doing, everyone has to assume the worst thing and then just race to do the worst thing.
If you can know what they're doing, right? So if you can force transparency and remove the
opaqueness advantage, then you can make better coordination, right? You can make better Nash
equilibrium. That's one example of many examples. And obviously, blockchain is very oriented to
forced transparency being a net positive thing, right? I think there are many examples of
forced transparency because of tech combined with new solutions where transparency wins
over opaqueness. Obviously, you look between militaries and they try to make all of their
military stuff national security secrets and classified so they can have a upper hand in a
military conflict. So there is strategic advantage on asymmetry of information.
But there's downside too. The downside is you start getting to a place where
everything is classified and or so much of us classified because of national security,
that the integrity of democracy is totally broken down because the population can't actually
know what's going on because if the population knows then China or Russia or whatever can know.
And therefore, the faith in government goes down. Everybody's afraid of corruption,
but they say it's the other side. It gets more partisan. Like the classification is part of
the breakdown of the democratic system, which means that it's driving autocracy movement towards
autocracy. The other thing is that the classification becomes compartmentalized and so you end up
having different departments duplicating each other's shit because they don't know and nobody
being able to do adequate intel across all of them and even some of them competing for who gets a
larger percentage of the black budget. If you could make them transparent and get enough benefit
from the transparency because you can use machine learning to process the data across them and then
help optimize coordination across them, then even if you give up some of your asymmetry of
advantage, asymmetric information advantage, you get new advantages of not having to invest all of
that energy and opaqueness, giving more buy-in of the population and less breakdown of democracy
and way more efficiency, which is what the Swedish government does. And it's actually
prototyped as working in a major nation with a major military. So if you take forced transparency
and you take solutions that make transparency win, can you start to drive increases in transparency
where the game theory orients a race to the top rather than a race to the bottom? Yes.
That's an example. Beautiful. Now, I can give you another example.
Technological automation, both because of robots and AI, portend a loss of enough jobs that the
capitalism is not a viable solution for humanity in the next pretty soon period of time,
whether it's 10 years or 30 years, whatever, it's soon.
Okay. So either this becomes dystopic as can be because at least in feudalism,
you needed people's labor. And so the people couldn't be too terribly treated because you
didn't want violent revolts. If you have a situation where the elites don't even need
the people's labor, they're just useless eaters, that could get really bad.
And the robots and AI can do stuff faster. And so how do we have a situation in which the market
will choose the robots and the AI because they're fucking faster and cheaper? How do we have a
situation in which that is occurring that isn't dystopic? That's a really important question.
And if there's a very deep existential question, if robots are better than us at certain things,
and AI are better than us at certain things, what are we still better at that is what we
should be developing humans to do and or what is intrinsically meaningful to humans?
And what you end up getting is like outside of full AGI, sentient AGI,
things that involve authentic connection are things that you're going to want humans to do
rather than automate. Could we automate? And most of the things that you could automate,
if people didn't need the jobs and money, they'd rather not spend 40 hours every week doing anyways,
because if it's automatable, it's fairly rote and it's not the most engaging thing.
And yet high connection things are intrinsically rewarding, right? Like evolution rewarded high
connection things. So could we have a situation where a much higher percentage of the entire
population are educators? Like one in four people as opposed to one in 40 or whatever,
and a much higher percentage are nurses, but the nurses are trained as much as doctors.
Because, and doctors similarly, doctors aren't going to do the surgeries anymore, the DaVinci
robots, DaVinci machine type robots are going to do, they're going to do a lot of the diagnostics,
so then the role of the nurse and doctor become much more the interface with the AI and the
interface with the patient, it's extremely high touch, extremely high care that gets all the
qualitative stuff that the quantitative thing can't get. Same with the educator, we don't get to have
the world-class minds become educators because they just doesn't work, they go into other areas,
but you can't grow world-class minds with teachers who are not world-class thinkers, right? So
there's a study that showed that the highest statistical correlator for people who became
world-class mathematicians was that they trained with a world-class mathematician young.
Oh, wow. So it's like fractal.
You're not going to learn to think like a world-class mathematician from someone who
doesn't think that way, right? It's like if you're talking to a field's award winner versus your
high school math teacher, they don't think about math the same way, right? And so your brain learning
math is going to learn it, in your mind, is going to learn it really differently,
which is why the aristocratic tutoring model is the thing most known to correlate with super genius,
which was the aristocracy were able to hire the smartest people in the whole land to tutor their
kids. This is why Marcus Aurelius' first chapter of meditations was just dedicated to his tutors,
is when you're, is to be the emperor of Rome, the best mathematician and
philosopher and grammarian are your teachers. Of course, you're going to be way the fuck smarter.
So now this is another question about hope. Can we make a world where GPT-3 can already,
and so now imagine GPT-12, right, can already not just pass the Turing test as a chatbot pretty
well, but do it in the voice of specific people. I can train GPT-3 on Thomas Jefferson enough that
it can answer like Thomas Jefferson. Well, now that gets way better, way more data in it. You
metaverse with that up. Can the kid have Socrates and Confucius and Einstein and von Neumann and
Gertl all as tutors? Yes, that's fucking amazing, right? But also can the kid have real human tutors
who are brilliant and care about them because the AI one doesn't care about them,
or the real human tutors talking to them saying, what do you think is different,
what the AI Einstein said versus the real Einstein might have said, and to be able to
really talk with them about that, they have to say, well, what do you think is different between
artificial intelligence and organic human intelligence? What is intelligence? What is,
what do you think is different about the nature of self-organizing systems versus
design and built systems? The recursion on thinking about what is intelligence and
organic intelligence and sentience will start to lead those qualities way the fuck up. So now
the kid gets a level of human tutoring that is as good as Marcus Aurelius had, but could be
democratized, right? Everybody could have it because of a new economic system,
a level of this AI tutoring thing that nobody ever had. And when we go back and look at
most of the great polymaths, they have this, right? Even all the way down to Einstein and von
Neumann as the last ones had mathematician governances when they were young, the remnant of
the European system. What hope does it bring for me, for humanity? And the Dalai Lama's tutoring,
right? Like you get somebody like the Dalai Lama when you have that kind of tutoring system of the
very best Tibetan monks tutoring you intensely from the time you're tiny. If everybody had that
educational system, and the goal of education was not to prepare you for the market that the robots
in the Azure doing, but was to develop in you what is uniquely human capacities, not automatable
capacities, and then also your unique aptitudes. And you have a economic system that can incent you
to be able to or support you, where it's not even about incense, but support you to do what
you're intrinsically incented to do deeply and really well trained to do. That's really fucking
inspiring. And that would, these same technologies that portend really terrible dystopias, way worse
dystopias than ever before, because dystopias had a limit of how controlling they could be
because the people would revolt. AI-empowered, drone-empowered dystopias are really, really bad,
right? And AI catastrophes are really bad. But AI third attractor-empowered, which is not
disintermediating human intelligence, but facilitating it, not disintermediating human
connection, but facilitating it. And this one of the key things is that all of the tech has to
facilitate what is uniquely human rather than debase or disintermediated. Your online world
should be helping your offline world be richer, not the other way around. Online relationship
should be enriching offline relationships. Anything that's an emergent property of some
more fundamental thing needs to be enriching the fundamental thing that it depends on, right?
That's a general design principle of good tech. Now, these are a couple examples of like
really inspiring tech. I can also give examples of how we can use AI to make democracy actually
work because you can't fit everybody in a town hall. Does the internet make it possible to fit
everybody in a town hall and where we can use GPT-3 like semantic analysis to be able to get
to see the distribution of everybody's values and stack ranking on everybody's values and to then
be able to take all of those values as constraints of proposition crafting and then also help craft
propositions that are better synergistic satisfiers with less unnecessary theory of trade-offs?
Totally. This is not an AI singleton disintermediating humans. This is AI being able to help the scale
issue of collective intelligence. It's like a high resolution democracy. It could be really powerful.
We have to build this. The third attractor needs this, right? It's a decentralized collective
intelligence with central enactment capability, but where the central enactment capability
comes from a bottom-up system that is not captureable, not creptable.
These are a few examples, and I could give a heap more in energy and manufacturing and
waste management, whatever, but these ones are on coordination of things that I find
really hopeful, but that we don't have the incentives to be building them that way yet
because we're starting multi-polar traps, which is why this podcast and stuff like
this is important to me is because more people building things like this is really important.
Next part. What brings me hope at the level of human nature is important.
The real politic assessment, that humans are just too irrational and just too kind of rivalrous
and nasty to be able to make a nice world until we just need an AI singleton or we just need
something like that. It's important to understand the real politic assessment,
but it's also totally gibberish in that it doesn't factor development. If you study
developmental psych, there are higher levels of cognitive capacity, higher levels of
moral capacity, work of Colberg and Lovinger and things like that, and they can be developed
across the whole population, both by building tech that incentivizes them in economic systems
and educational systems and et cetera. If you don't factor development, you just see a Gaussian
distribution of violence or rationality or whatever, and you don't know what makes up the
Gaussian distribution. Well, the people on two standard deviations to the right and two standard
deviations to the left are not just distributions of human nature. There are reasons for that,
and there are reasons that can be changed in societal structure. The reason we know this
is because there are some cultures that are way less violent across the whole culture and some
that are way more violent and it doesn't have to do with the distribution of genetics.
So we can see that the Jains are nonviolent to humans, animals, and bugs across the entire
huge population across a long period of time. And we can see that the John's weed are extremely
fucking violent across the entire population. That's culture affecting the expression of human
nature. Human nature can do either of those. Human nature has radical plasticity.
And then I shared this video a while ago. I don't know if you saw it, but if not,
you should link it as well. It was a really good explainer video on the lead additive in gasoline
and the effect of lead in the environment. Because to just make engines stop knocking,
the fuel companies figured out to add this leaded thing that can busted it and put lead in the
atmosphere. And it turned out that the effect that has on brains dropped the global IQ by about
a billion points and made people about 4x more violent. And you're like, fuck, that's one chemical.
That's one chemical that we made for internal combustion engines to stop knocking. There's
like 50 million chemicals in the American chemical database. They all do weird stuff.
That's not including the zenoestrogens and the DDT and the, you know, whatever else.
The, that one chemical, if we say that the real politic assessment is humans are too
dumb and nasty. And that one chemical made them way dumber and way nastier. We're like, okay, well,
it's not just humans. It's humans under conditioning, both physiological and psychological
effects. We can do things that move it in the other direction too. And so when I look at the
average level of education of the Jewish community, Jewish across a long time of non-violence across
the Buddhist community, it's like, this is not a person. This is a distribution across an entire
population. And they didn't even have tech to move it in the right direction. If we see how fast
Facebook can polarize the population with its AI that curates bias doubling shit in people,
what if Facebook's algorithm was incentivized to do the opposite thing, which was be able to expose
people to stuff that would correct for their biases and to connect them to people that expanded
their network connectivity the most, we would see an enlightenment engine culturally faster than
anything the world has ever imagined. And so this is where it's like, I'm excited about tech builders
understanding this more complete picture because we could build tech and not just tech, but the
combination of tech and the regulation of it and the incentive system and things that could be
really profound. So I'm inspired by actual human nature and the plasticity and potential of it
and the things that the tech can do and with culture and like that. So this is answering your
question about hope just with a few examples. And the last thing I want to say on that is like,
it's very connected to this idea of like this other quality of faith of like having hope where
I don't even know the thing I have hope in yet. And I would say without a religious sensibility,
one can and actually needs to have a particular kind of faith, I believe,
which is, and we can say in a really secular way,
it's easy to say there's no way it can work. Nope, I see the patterns that we only have this many
years, it's getting worse like this, we're fucked. That's assuming and that kind of certainty can
justify us doing some pretty nasty stuff because of utilitarian calculus. All right,
if it's for sure that we're going to destroy the environment in this period of time,
my eco-terrorism is a really good idea. If it's sure AGI is going to take over in this period
of time, my brain chip is a really good idea, whatever it is, even if it's really bad for other
reasons because, but we can't be that certain because the unknown unknown set that could include
solutions, we don't know, we can't even factor how much it is in it. And so it's really easy to get
false certainty that then justifies really bad actions under utilitarian ethics. And so there's
a faith that says, I don't know what the solution is, but I know that the things that I don't know,
and I'm not even aware that I don't know, is a really large incident set. And as a result,
I'm going to not just sit back and say, oh, it'll take care of itself. I'm going to study my ass off
and I'm going to innovate, I'm going to talk to other people, I'm going to work on finding the
solutions that might be in those various parts of the unknown unknown set that I don't currently
know. So there's like a faith in possibility that keeps one actually learning and innovating,
that also requires a humility on not having the wrong kinds of certainty about catastrophism.
Right. So it seems like sort of like studying your ass off and really dedicating to solving
the problem, but knowing that the solution is likely in the unknown unknown set and having
that faith to continue studying the problem without knowing what the goal line is.
And maybe I know criteria and it's like, you know, Edison was a very, very flawed person, but that
kind of famous conversation when Napoleon Hill was interviewing him after the light bulb and he
said, had you, had you never been able to figure out the light bulb, what would you have done?
And Edison said something like, young man, if I, I'd still be in my lab working on it.
Right after all the field times is like, I was going to fucking die on the hill trying because
I knew that the, I had a deep faith that there was some way to run electricity through a wire
in a particular environment that would light up. Like the elements were enough that I didn't
know what the right answer was, but I felt that there was one enough. I was going to keep working
at it. And of course, as a lot of persons might have been in other ways, innovation does,
innovation that requires failing a lot requires that kind of faith to keep working at.
And we need to innovate not just at building a piece of tech, but an entire techno sphere
and social sphere compatible with the biosphere and compatible with human nature.
It's a deep set of things to innovate on and we can, but it does require that commitment,
which also requires that kind of face commitment relationship.
Right. So I think it was really refreshing to spend some time on where you spend your hope,
where you think about hope, because these catastrophes and dystopias are,
it's really bleak when you're staring into that abyss. And so I've gotten my notes here,
the tech inspires you, human nature inspires you and also your relationship to hope
or faith itself. So basically, starting with the tech, the example of surveillance tech,
which allows you to solve for multi-polar traps by having a neutral adjudicator of who's breaking
the laws and no more plausible deniability of people who are defecting, AI enabling tutoring,
enabling education to be like fractal and create more education, which creates more
anti-fragility and better informed citizens, which we could use to plug into higher resolution
democracy. These are all examples of tech that could be used for the public good,
but we have this economic problem where we don't have the incentives to solve it.
And we see the same sort of thing in the human nature area of this. So you're inspired by actual
human nature because we can upregulate human nature to go from being dumb and mean to being
smart and more polite. And I think that you said the Jewish communities and Buddhist communities
are maybe an example of that. If lead and gasoline or Facebook can regulate us down,
what can upregulate us in terms of our ability to solve those problems? And then lastly, hope
and faith itself. It's easy to say it can't be done, but you're not considering the unknown
unknowns. If you study your ass off and commit yourself to solving these problems, then that's
the first step in hope or faith itself. So I don't know. To me, it's just nice to hear
someone who's thought as much about this has hope in all of those places because I think
that the seeds of our next episode are going to be exploring how do we combine the opportunities
in technology with actual incentives to solve public goods problems, commons problems,
multipolar traps, and maybe attempt to start addressing the meta crisis is I think where
we want to take this series of podcasts that we're doing together.
I love the way you recap things. It's really fun and yes, and I would only add one more thing to
this is your community knows a lot about red teaming because you're doing crypto security stuff
and so you'll build a thing and then redeem it. In the age old dialogue between optimism and
pessimism, I think about a commitment to optimism that's attached to solutions and the unknown
unknowns with pessimism red teaming specific propositions and an internal kind of autodidactic
process as well as a group process, an intergroup process that should happen. So I want to see
people commit to bring solutions about even though they don't know how. It was a famous thing with
Gandhi when he first went to South Africa and saw the kind of slavery and racial issue there and
then when he went to India again that he's like, this is unacceptable. I'm going to solve it and
his friends are like how he goes, I don't know, but I'm committing to solve it before I know how.
And then I'm going to just sit here and think and meditate and write and come up with ideas until
I know what to do, but I'm not going to do shit other than think about what to do because I've
already committed. What does it mean to commit to something you don't yet know how to do, right?
So that's a kind of optimism that says there's something in the unknown unknowns
that they can solve this and I have to solve it because I feel morally obligated to solve this,
like it's not okay with my being to not be part of the solution to this thing that I see.
And I'll die on this hill if I have to, right? If I'm working towards
and whether my being is calling me to protect the Amazon or factory farms or coordination itself,
whatever it is, I'm like, fuck, I have to do that harmically.
Being committed, even though you don't know how, which means you will keep figuring out how and
when it fails, you'll find another way rather than just give up, is both what's most likely to make
you succeed and where you can be most at peace if you fail and die, right? In the process because
you're like, I was given, if I'm going to fail, I want to do it this way, right? I want to have been
aligned in this way in the process. But I don't want to fail stupidly. I don't want to fail from
should I could have figured out. So I want to red team my own ideas. And that's a kind of pessimism,
but it's a pessimism in service of effective optimism. My optimism says I'm fucking committed
to find a solution. My pessimism said, I bet that solution has a problem. Not to make me give up,
but to say, oh, you're right, that one does have a problem rather than wait till it just fails in
the world after a lot of money and a lot of years. How about let me just red team it really hard
right now. Let me ask all my smart friends what's wrong with it. Then when they give me what's wrong
with it, I'm not going to give up. I'm going to be like, all right, those are new constraints to a
design problem. Let me keep working on a new design. Then I try to get and eventually you get
something that's hard enough. You're like, this is not perfect, but this is adequate to move the
thing forward. There's a relationship between these two where the optimism is only
realizable because it's hardened by pessimism and pessimism is in service to the optimism.
And this also reconciles a parts conflict in ourselves where those two parts are actually
in service to each other. It's almost like using adversarial thinking in order to get to
a world in which these things are not a problem anymore to general optimism and pessimism of the
red team red teaming specific solutions. And in general, what I'd like to say is for anyone in the
community working on a crypto solution, you're like, okay, this will be good because it will
decentralize this thing that is currently centralized and corrupt. Ask all your friends to
red team where the externalities will be and why it's a bad idea. Oh, fuck, this is centralized
because it's really important to be centralized for these reasons, decentralizing it leads to these
coordination failures or whatever it is or being so much slower that another centralized one that's
worst takes over or whatever it is. Don't be afraid to hear that like speed up the rate at which you
hear why your good idea is a bad idea, because you think it's a good idea because there's something
that it's addressing that's really fucking important. Awesome. Because it's important,
you want to hear where it's going to fail or where it would cause problems somewhere else that you
really don't want to cause problems somewhere else so that you can internalize that into a more
robust and more inclusive design. So I don't want people just red teaming from a cryptography
perspective. I want people teaming from a, is this actually a good idea? And is this causing
problems somewhere else perspective? And then to not give up, but to design better.
So now that we've stuck the landing, maybe we can do a quick recap of the broader series that
we're going to do together. So this was episode one, which is what is the Metacrisis? The next
episode, we're going to talk about considerations of governance of systems that can solve the
Metacrisis. And then we're going to red team some web three proposed solutions to address the
Metacrisis in the remaining episodes for aiming between two and four episodes between this series.
Did I get that mostly right? Yep. Let's just not call it solve the Metacrisis.
That's right. A web three can help address the Metacrisis, right?
One thing I would offer, we were talking about this earlier is
it becomes clear pretty quickly that economy and governance, economics and governance are
fused. You can't separate them because governance issues mostly have to do with allocation of
resources and allocation of resource issues end up requiring things like law and adjudication of
how that stuff works. So you end up getting into the topic of what's usually called political
economy, right? The political economy is the idea of how does an economic and governance system
work together with an infrastructure and culture? I would really like to encourage people in the
web three space who are coming from being technologists and builders to study political
economy more because really fucking smart people put a lot of time into a lot of nuanced stuff
that you don't want to try to reinvent the wheel and realize failures on.
We want to see how having new technological capacities makes new things possible, but we
want to understand the design constraints that have come about so far from very, very harder
and hard one processes. So you and I were mentioning Richard Haas, the president of
council forum relations example of someone thinking about international relations and
political economy and how the current world system works in a very nuanced, detailed way
that I would love if people like him were being studied, that work was being studied by crypto
people more. And he had a famous paper where he said, talks about the difference between
problems and predicaments and that a problem admits a complete solution, a predicament
requires ongoing management. A predicament could also be called a wicked problem,
but anytime you have different interests that are competing with each other or you have trade-offs
where those who care about one side will keep pushing for those on a solution to move more in
that direction, then you don't end up getting a perfect solution. You get an ongoing management
issue. And so the metacrisis does not admit a solution. It admits hopefully, progressively,
more competent partial solutions and management and addressing. And for people who are used to
thinking about tech where you can define the problem in a fairly narrow way and admit a full
solution, this piece of code compiles and does this thing. That's mostly not how humans and
cultural and organic systems work. So we want to get out of solutions and into
managing ongoing complexity maturely, responsibly, effectively.
Beautiful. I think that's a tasty teaser for the episode that we're going to do next
about political theory, what there is to learn from it, and governance that can solve the
metacrisis. Daniel, thank you for taking the time to record this episode with us. I really,
deeply, genuinely believe that there's a ton of upside for political thinkers like you, systemic
risk thinkers like you, to combine with people in the Web 3 and Dow community to design economies
that favor the commons and help solve multipolar traps. And I hope that I hope that I was putting
this out there into the universe creates that attractor for people who want to solve that problem
together. Like you said, more ears, more eyeballs equals more people thinking about this equals more
hope for me. So I really appreciate you setting this up at the time. Yeah, I do too. And I know a
lot of people I think are really brilliant thinkers in the kind of Web 3 Dow decentralized
governance space, some who you should have on your show that know a heap more about this space
specifically than I do. Yeah, Matan Fields would be good. I don't know if you had Drake
training offers on Jordan Hall. There are some of the folks at Hall of Chain. I think they're all
really good thinkers like Arthur Brock and Farinanda. But of the people who I have spoken with,
you are so clearly earnestly motivated to really solve collective action problems and coordination
problems and have figured out how to be pretty central to an ecosystem of people really trying
to do that. That's why I wanted to come do this dialogue series with you because obviously a lot
of people can say they're trying to do that while really trying to drive the bubble on a speculative
token. And I am inspired by what can happen because the people who understand political economy well
are mostly not trying to really innovate fundamentally new models. Some are but it
seems like, okay, at best we can do tiny incremental advancement. And I know the Web 3 space is
might be almost the only space, one of the only spaces really thinking about can we do fundamental
ground up redesign. So I wanted to understand everything that's happened before and think
about redesign. And I really like where your community is positioned. So I'm happy to be here
talking with you. Yeah. Well, GitQuin's mission is to build and fund the public good. And that is a
multipolar trap in global coordination failure. So it's at the heart of what we're trying to do.
And I think that we're committed to solving the problem, but we haven't figured out exactly how.
So I can relate to you in that way. Yeah. So I think that's all there is to say. Thanks again
for being on the show, Daniel. Wonderful talking to you, my friends.
