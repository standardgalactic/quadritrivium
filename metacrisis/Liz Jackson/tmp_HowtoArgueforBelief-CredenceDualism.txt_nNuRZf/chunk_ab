of thinking a little bit more about what we mean by reduction here. Okay, so moving on from that,
we kind of talked at the beginning about these these five views, but then this view reduces to
two views. So we sort of ruled out this view, this view, and then the belief is credence one view.
And so dualism is kind of what we're aiming at, right? But it leaves us with two views,
there's a threshold view, and there's the belief first view. So we're really going to focus on
mainly those two views right now. So what's the belief first view? This is the view that credences
are beliefs with particular contents. So when you have a credence, what that means is you have
a belief about a probability, or it could be a belief about an epistemic modal, I'll explain
what that is. So, you know, maybe you have a point five credence that a coin will end heads.
What that is, is it's a belief, the belief that the probability that the coin will end heads is
point five. Normally, I think the most plausible candidate for the type of probability is epistemic
probability, which is some kind of evidence relative probability, but could also be a belief
with an epistemic modal. So epistemic modals are words like probably, may, can, might. And so,
you know, you might think my high credence it will rain tomorrow. That's an epistemic modal
belief, the belief that it will probably rain tomorrow or probably is an epistemic modal.
And I think the main challenge for the dualists from this belief first view, I'm calling it the
belief first challenge. And Andrew Moon and I actually wrote a paper sort of answering some
objections from the belief first view, I ultimately do reject the belief first view.
But you can think of the challenge like this, if we have beliefs about probabilities, why do we
in addition need deposit credences? It makes much more sense just to say we have beliefs and we
have probability beliefs, and that's it. So that's sort of the challenge I'm going to try to meet in
the next section. Okay, the second view that also presents a challenge to the dualists is called
the threshold view. This is the view that belief reduces to a credence above some threshold,
but that threshold is less than one. So I think I talked about this a little bit already. You
might say like the threshold is a fixed threshold, 0.75, let's say, or someone suggested like the
inverse of the golden ratio, which is like 0.6 something. So there's been various like fixed
thresholds proposed, or you might have a view like a 0.5 could be the threshold. Or again,
the threshold could vary with stakes or context. So it might be that everything that you have at
least a 0.75 credence in or above, you believe. So that's a threshold view and this can capture
the idea that we're more confident in some things that we believe than others. And I think this
view sort of presents this challenge for dualism, which is this, if we have both a belief in P,
and a credence in P, what is the use of the belief? So the credence is much more accurate,
it's more fine grained, it can better sort of capture our attitude towards the proposition.
And this suggests that beliefs are either superfluous or just this extra thing that we don't
really need, or they're inaccurate. And so then we should just trust our credences. And so, you
know, you could maybe try to use this to motivate some kind of belief of limitabism, but I think a
lot of people will take this threshold or this credence first view instead and say, I mean,
we do have beliefs, but what beliefs are are just these threshold passing credences.
So I want to try, that's called, and by the way, that's called the Bayesian challenge. So I want
to try to answer both the belief first and the Bayesian challenge in the rest of this paper.
Okay, so let's start with the belief first. I think actually both of these views
suffer counter examples from certain kinds of irrational thinkers. And the relationship
between belief and credence, it's not a normative claim, it's not a claim about rationality,
it's just a claim about what reduces to what. So it should be able to explain both cases of
rationality and cases of irrationality. But I think the belief first view, you can actually
give counter examples when you think about certain irrational thinkers. So suppose someone's
irrational, it's not at all clear, given that they're irrational, what would prevent them from
having a credence that's different than their beliefs about probability or their epistemic
modal beliefs. So, you know, this person might have a credence of zero in something,
but still think it's possible. Maybe they are engaging in the kind of wishful thinking or
something. Or, alternatively, they might believe something's impossible, but have a non zero
credence in it. So have a credence in that it's above zero. And so yeah, maybe these are irrational
combinations of attitudes, but should we really say they're impossible? And I think especially
if we have kind of infinite space, like probability space is involved, there might even be cases where
you have like a non zero credence in P, but you should believe that P is impossible. So it might
not even always be irrational. You can also think of like other like maybe more real life cases as
well. So think about someone who's paranoid or delusional or just really jealous or something.
And maybe they have like a really high credence, their partner is cheating on them. They're very
confident that their partner is cheating on them. But they know at the same time that they really
don't have good evidence for this. Their evidence doesn't support a high probability that their
partner is cheating on them. And so they believe that the epistemic probability that their partner
is cheating is low. So again, epistemic probability, it's relative to your evidence. They're saying
I don't have good evidence for this. They might even admit I know the probability of this is low,
but I just can't shake this high credence that my partner is cheating on me.
Okay. So those are some example, I think counter examples to believe first you from your
rationality, but I also want to think about rational agents and think about what's the
role for credence that may not be played by a probability belief. Okay. So I think probability
beliefs are useful and we do have probability beliefs and they're useful for a couple of reasons.
I think first of all, when we're undergoing certain kinds of probabilistic reasoning,
so we're trying to start from some probabilities and reason to other probabilities,
it's much easier to reason with probability beliefs. And there's actually been a lot of work on
like whether we could even do that kind of reasoning with credences. So Julia Staffel has
an interesting paper on that. I think it's called Can There Be Reasoning with Degrees of Belief.
So I think probability beliefs because of the way the probability is part of the attitude,
it's not in the content of the credence. I think they're very useful for probabilistic reasoning.
I am also sympathetic to the idea that our credences, when they're rational, they'll probably
closely track our beliefs about epistemic probabilities because then they'll be connected
to our evidence, which is our beliefs about how epistemic probabilities are connected to.
And I also think probability beliefs, they can allow for a certain kind of flexibility.
So it might be sometimes useful to form different beliefs about different conceptions of probability
so you might know the objective probability of P is either one or zero, like in a mathematical case,
you know this theorem's probability is either one or zero, but because you don't know whether the
theorem is true or false, the epistemic probability is 0.5. So probability beliefs allow us this
like kind of flexibility that I think is really useful. However, I think there's a unique role
that credence plays that beliefs about epistemic probability can't play. And there's really like,
it's kind of like this three-fold view. So the first is that creatures who lack certain concepts
or who lack certain cognitive capacities, it seems like they can have credences, but they may not
have the concept of probability or they may not have the cognitive sophistication to form
the probability beliefs, these more complex beliefs. So this objection has actually been
pushed, it was originally pushed by Frankish, who I cite here. And, you know, Andrew Moon and I,
I think we did our best to kind of respond to this and say, well, either they don't have credences at
all or they do have the concept of probability, but I'm not totally, I'm still in the fence about
that. And I mentioned it here because I do think it kind of fits well with this general role for
credence, which is that it's cognitively thinner than a probability belief. And I'll say more about
that soon, but let me just go through these other two really quickly. So there's also creatures who
form a credence in a very complicated proposition. And that proposition is right on the edge of what
they can grasp. So one example I've given is, he said that she said that he knows that he believes
that she said that he's sure that she's mad at him. And it's like, wait, what, you kind of have to
think about that for a second. So you might barely grasp that and form like a 0.5 credence in it or
something. But you can't form the more complicated belief that the probability of is 0.5. And so
again, credences let you, you can form a credence in that because it's cognitively thinner, because
you're not forming a belief out of probability, the 0.5 part of the credence is in the attitude.
And then the only thing you have to grasp is the more, the more simple, I guess, proposition.
So I actually have a paper where I defend this in more detail, but again, I think it fits with
this general rule for credence. And then finally, I think, and then maybe this kind of gets at
the general thought, it allows us to express uncertainty and to be uncertain without having
to represent that uncertainty in the content of what we're, what we're believing. So that lets
us, it helps us represent uncertainty in a less cognitively demanding way. It also enables us
to have a belief in a credence with the same content. So you can believe it will rain tomorrow,
have a 0.5 credence that will rain tomorrow. It's not like you're believing one thing and then
you're believing something with a different content. And so in general, I think this idea that
credences are cognitively thinner in some way, whereas probability beliefs are cognitively
thicker in some way, I think makes good sense of, I mean, the distinction, I think, between
probability belief and credence, but also these various kinds of creatures or people that seem
like they can have credences, but they can't meet this more cognitively demanding thing
that is probably what probability beliefs require. So I do think a belief, first of all,
would probably just say like, this appeals to cognitive thickness is just question begging,
it's my view. I think that, you know, probability beliefs and credences are equally,
equally cognitively thick. And I think, I mean, it kind of just puts us at a difficult point
dialectically, because this is just really fundamental to how I and I think many others
in this debate view beliefs, probability beliefs and credences. And so at some point, I wonder,
like, are we really disagreeing about what credences are? We're just like talking about
different things. I don't know. So I'm not necessarily convinced that this is going to
convince the belief first, but I do think this is kind of explaining again, why Liz is a newest,
right? And I do think there's something to be said for this idea that there's a difference in
cognitive thickness, and that gives credences this unique role that probability beliefs can't play.
Okay, let's move on to section five, which is against the threshold view. So we're called the
threshold view. The threshold view is the view that beliefs, sorry, I'm just adding this to
my notes really quick. It's the view that beliefs are credences above some threshold, and that
threshold is more, or sorry, less than one and often greater than point five, although I don't
think it has to be. So in that, again, that threshold can be fixed or it can vary with context.
So that's a threshold view. I think, first of all, there is, again, a counter example from
irrational thinkers. So I think there are certain cases of, you know, double-mindedness or self-deception
or acracia when you believe or do something that you think you shouldn't. And I think these are
just best explained by the dualist. So suppose that someone has an irrational belief that they
can't shake. Again, maybe maybe they're paranoid that the partner is shooting on them and they
believe their partner is shooting on them, but they kind of acknowledge, like, this is irrational,
and I have a low credence that this is true. So they realize this is poorly supported by their
evidence and their credence kind of fits with their evidence, but they have this belief they can't shake.
An alternative case, maybe a case where someone is convinced that believing something but having a
low credence in it is the right response to their evidence. So some people have actually argued that,
for those of you who are familiar with the preface paradox, that this is actually how we
should view the conjunction of all of the claims in our book. We should believe it, but have a low
credence in it. There's other examples here as well I'm not going to go into. But you might genuinely
believe this, but let's just concede for now that they're mistaken about what rationality requires.
So maybe they are, in fact, irrational or something. So in both of these cases, it seems like they
really do have a low credence. Their credence is not a maximal credence. We already talked about
belief as credence one view. It's also not threshold passing. And so it's not totally clear how the
credence first could explain these cases of belief and low credence. They might try to say
that they have two credences in the same proposition at the same time, but really that possibility
has not been discussed in the literature very much and just seems really weird. And these are
like pretty basic everyday cases of irrationality. So it would be surprising if they had to appeal
to something so extreme to explain these kinds of cases. However, the dualist has a really natural
explanation for what's going on here. Like, look, belief and credence are these distinct and
irreducible attitudes. So of course, especially if the Asian is irrational, they can significantly
come apart. You can believe something and have a low credence in it. So this argument again is
spelled out in more detail in the paper I have with Peter Tan. Okay, so let's talk a little bit more
about how I think we can answer the Bayesian challenge. What is the role that beliefs play
that high credences can't? And I think what that role is, is we can kind of sum it up and that
beliefs close off possibilities. So when you believe P, you're in some sense ruling out or
closing off the possibility of not P. And it's not just in this like pretending way, you're not like,
I'm going to, you know, be an actor, an actress, or I'm just going to concede this for the sake of
argument, but you believe P who represent the world as P is true. So you're kind of ruling out
not P in a mental or representational way. And that's going to come up when I talk about an objection,
maybe briefly at the end. But I think that high credences don't do that. So a high credence in P,
what it does is it represents P as likely, but it nonetheless leaves open the possibility of not P.
There's also, so you might wonder what's the use of closing out possibilities in this way.
And I think there's sort of two main uses for this. The first is just efficiency and reasoning.
So we cannot be considering every error possibility that's always relevant to our
reasoning. And so beliefs, they let us rule out possibilities, which just simplifies our reasoning.
And when the stakes are low, so maybe we have a ton of evidence for P. Of course, it's not perfect,
but it doesn't really matter if not P. So it makes sense to just suppose P for the sake of argument.
Or we just have to make a decision really quickly so we don't have time to think
there are a bunch of alternative possibilities. Then it just makes sense to treat P as true
and represent the world such as P, not just accept that P is true, but take P on board as true.
And so you might think about a soccer goalie and they have to make a quick decision about how to
block something. They might just sort of represent the world such that someone's coming from the left
to kick the ball in a certain way. Instead of thinking about the possibility of error and reasoning
through a decision table, no, they just got to make a quick decision. You could think about another
case of you're in a battle and the enemy is upon you and you need to make a decision. That could
actually be a high stakes case, but because you have to make a quick decision, you might just kind
of represent the world such that P is true. Another example I've given here is if you
walk into your office and see your office meets coat and backpack, you'll probably just represent
the world such that as they're in the office today, you'll believe they're in the office.
If your friend says just so-and-so in the office, you'll say, yeah, of course,
but if the stakes get really high and the police are investigating a crime and they have to know
everyone who's in the office, you're going to move to your credence and instead say, look,
I'm not 100% sure. I don't know for sure. You'll express your non-extreme credence
when answering the cops, moving from the belief reasoning to the credence reasoning. Moving from
the low stakes to the high stakes often will prompt us to consider these alternative possibilities.
That said, though, I don't think that beliefs only play the role of efficiency. I think
intuitively cognitively sophisticated agents, so maybe like an angel or some
agent that really has this extra brain power, I think those kinds of agents that it's not
difficult for them to consider lots of alternative possibilities, I think they would have beliefs
too. I think this kind of ruling out role that beliefs play isn't just for this purpose of
simplification. I think there's another role that beliefs play as well, and that's beliefs,
let us take a stand. They let us have a view of the world and they let us remain steadfast in
our commitments. We might even want to do this when we receive counter evidence against our
commitments that lowers our credence, but if beliefs just are our high credences, it's not
really clear how that amounts to taking a stand. If we are able to close off the possibility of
