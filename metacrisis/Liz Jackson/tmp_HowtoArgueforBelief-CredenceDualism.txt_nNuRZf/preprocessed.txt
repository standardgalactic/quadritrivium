Hello, everyone. So, today I'm actually going to be talking about a topic that is really
at the heart and center of my dissertation. So, if you're interested in my dissertation
and want to know a little bit more about what that argued, then hopefully you'll find this
interesting. It is going to be a little bit more of an academic talk. So, just, you know,
keep that in mind. So, the paper is titled, How to argue for belief credence dualism.
I'm going to explain what that is, but the main point of my dissertation was to defend
belief credence dualism and then also kind of explore different implications of belief
credence dualism. And I did, you know, graduate a couple years ago, but a lot of my research
sense has also really focused on belief credence dualism. So, just a brief background. Many
epistemologists, traditional epistemologists basically see belief as a three-part attitude
you could take towards a proposition or there's three, maybe a better way of putting it, three
different attitudes you can take towards a proposition. You can believe it, effectively
saying it's true, you can withhold belief on it, you're agnostic, you're undecided on
whether it's true. So, you know, I would hold belief on whether there's an even number
of hairs on my head, or you can disbelieve it, which effectively amounts to saying that
it's false. And so, we have these three attitudes, but look, you know, I believe maybe that my
coffee is cold right now, and I believe that it'll be sunny tomorrow. And I also believe
that one plus one equals two, right? But I'm more confident that one plus one equals two
than I am in either of those other things. And so, some epistemologists have said, look,
just saying there's only these three attitudes that we can take towards a new proposition,
that's not going to capture the full story. So, some of you have probably, you know, heard
me say this before, but that's why epistemologists bring in credences. Credences are basically
our confidence level, or you could think about it like a subjective probability, and they're
measured from zero to one. Zero is certainty of propositions false. One is certainty that
a proposition is true. And you can have all these various credences in between. So, my
credence will be sunny tomorrow is probably about 0.9. My credence one plus one equals two is one
or very close to one. My credence that there's an even number of hairs in my head is 0.5, right?
So, we have beliefs, and we have credences. And there's been a lot of questions about the
relationship between these two attitudes, partially because sometimes people will just sort of adopt
one framework or the other and kind of ignore the other one. And, you know, there's this whole
formal epistemology program built up around credences, traditional epistemology program
brought up around beliefs. And I want to see these two different sort of branches of epistemology
talking to each other more. And so that's one reason I think this is a really interesting
question. And sort of just setting things up here. As you can see on the handout, basically five
views of the relationship between belief and credence. And there's these four questions,
and they'll all answer at least some of these questions differently. So, the first few is
belief or limitivism. I'm going to go through these pretty quickly. That's the view that beliefs
don't exist at all. They're just sort of this leftover from folk psychology. And most belief
limitists might say, I mean, some people are limitists about all attitudes, but for our purposes
here, most of the people we're thinking about think we only have credences and not beliefs.
So, beliefs just don't exist. Then there's the credence first view. So, the credence first
view thinks that beliefs and credences both exist. However, they argue that beliefs reduce to
credences. So, there are beliefs. They're just a certain kind of credence. And the credence first
view, as I note here, really splits into two further views. One view says that belief is
credence one. So, when you believe something, what it is to believe something is to have credence one
in it or belief reduces to credence one. And then the threshold view says that belief is credence
above some threshold. But that threshold is less than one. It's often greater than 0.5,
although I guess it doesn't have to be. Some people think the threshold could change with context.
Okay. That's the credence first view. And there's dualism. So, dualism is actually the view that
I'm going to be defending and that I defend in my dissertation. And that's the view that beliefs
and credences both exist. And they're not reducible to each other. They're equally fundamental. So,
we have beliefs. We have credences and neither reduces to the other. Then there's the belief
first view. This is the view that credences reduce to beliefs. So, credences are a kind of belief.
Often, on the belief first view, credences are beliefs about probabilities.
But they could be beliefs. There's ways that that view is tweaked, which we'll get into later.
And then finally, there's the credo limitist view. So, on the credo limitist view, credences don't
exist. Some people that are against this view are like, oh, the formal epistemologist just made
this thing up. Credences, no one actually really has credences. They're totally psychologically
unrealistic. All we have is beliefs. Okay. So, my goal today is to argue for belief credence dualism
based on the functional roles of belief and credence. So, I want to argue that beliefs play
certain functional roles that credences can't. And credences play certain functional roles that
belief can't. Before I get into that, I'll be giving some quick arguments against belief and
credo-eliminivism. But I'm really going to be focusing on this idea that we shouldn't try to
reduce beliefs to credences and we shouldn't try to reduce credences to beliefs. So, I will,
you know, at the beginning kind of be providing some counter examples to the other five views,
but I do want to kind of give a positive case for dualism as well and sort of try to tell a story
about why dualism is true. And that's, again, going to have to do with these different functional
roles that belief and credence play. So, I will note this is kind of a big picture paper and it's
kind of combining a lot of my previous work sort of giving a bird's eye perspective on a lot of my
research. It's actually from the second chapter of my dissertation, which I published like little
parts of. I actually took like sections and like expanded them into papers. But I actually never
really published like the main kind of argument of the chapters. This is probably the paper that's
closest to kind of mimicking that main argument. So, you could see the title of this paper as like
why Liz is a dualist if you wanted to. So, briefly as I wrote ahead, section two will
briefly examine some reasons to reject a limit of us views and also reject the belief is credence one
view. And then in section three, I'll just sort of explain a little bit more about the reductionist
views. Section four will explain why I reject the belief first view and then section five will
explain why I reject the credence first view. And in both of the sections four and five, I'll be
kind of explaining I think there are actually cases of irrational agents that I think actually
serve as counter examples to the belief and credence first view. But I do want to make a positive case
for dualism. And so it's not I'm not just going to be interested on in in rationality and irrationality,
but also, you know, in the roles that belief and credence play in a rational agent as well.
Okay, so let's move on to section two. Whoops. Okay. So I'm just going to kind of briefly talk
about these limit of this views, but I'm not going to spend a ton of time on them. So note,
belief, eliminabism just requires a very extensive erythry about our common sense psychology,
much of our everyday discourse. It's very common to say like I believe this or I don't believe that
or I'm undecided about that. And so it just really just saying there's no beliefs at all.
I think it's just, it's going to be a pretty radical view a pretty radical revision of kind
of our common sense view. And it does kind of seem like there are things that we just
straight up believe it doesn't seem like every single belief is just a credence,
like there's no beliefs at all. So that was super brief, but that's all the time I have to go into
for that. Feel free to comment if you have more questions or want to hear more about why I don't
like belief, eliminabism. I'll spend a little bit more time on credo, eliminabism, but not
too much more. And the thought behind credo, eliminabism is kind of similar to what we already
talked about. If all there is is belief with folding and disbelief, we can't capture this idea
that we're more confident in some things that we believe than others. Beliefs are just super
coarse grain. There's really just three belief like attitudes. And this just seems too coarse
grain to capture all the nuanced things that are going on in our heads are various levels of
confidence, probability judgments, all of that. And I think too, it's easy to see credence in a
very narrow way. It has to be this precisely point valued subjective probability. But I actually think
it's better to interpret credence in a relatively broad way. So credence can include things like
confidence levels, what some philosophers call partial beliefs, you can have fuzzy or fuzzy
credences or interval credences or imprecise credences. So your credences don't always have to
be precise, you could be more confident in A than indeed, even if you're not, you know,
be able to say the exact probability of either one of those. And so I think given this kind of
broader understanding of credence, I think it's pretty plausible that we have credences
and also I don't think actually anyone really defends credo limitivism, because they'll say
we don't have credences, but we have partial beliefs. And then I'm like, okay, well, for my
purposes, that is credence, you know. And I also think some people think we don't have any precise
credences at all. But I think we do have precise credences. And this is often when we have precise
evidence. So you can think about a coin flip, you have a point five credence, the coin will end
heads, rolling a dice, you know, you have a one in six credence, that the dice will land a five.
And then you can also think of cases where you proportion your credence to a specific statistic
that you're given, whether that's, you know, you check Amazon, and there's like an 85% chance
your package arrives today. So you have 0.85 credence or, you know, support sports statistics,
I think there's a lot of examples of cases where we proportion our credences to a specific statistic,
and then we have a relatively precise credence. So I think given this kind of broader understanding
of what a credence is, and this need to have an attitude that's a little more fine grained,
I think it's very plausible that we have credences. Okay, the third view I wanted to address here is
the belief as credence one view. So this is the view that, you know, we do have credences and
beliefs, but beliefs just are credences of one. You know, there's things that people say in favor
of this view, and, you know, belief and credence one are similar in certain ways, they have similar
kind of functional profiles. When you believe something or have credence one in it, you tend to
rule out the alternative possibility. So if I believe it will rain tomorrow, that attitude is
associated with ruling out the possibility that it won't rain tomorrow, similar with credence one.
However, there's a number of standard objections against this view. First of all, I think there's
just some intuitive counter examples to it. So there's lots of things that we believe we're
not 100% sure of. We already talked about some examples of this, that it, you know, will be sunny
tomorrow, that my car is parked in front of my house, that, you know, this number one seed in
this tournament will beat this number 16 seed. You know, there's, there's lots of things like that
that I believe, but there is a chance I'm wrong. I'm not 100% sure. And it also similarly, it just
can't capture this really intuitive idea that we're more confident in some things that we believe
in another. So you can believe two things, but be more confident in one than the other.
The belief is credence one view can't capture that because all beliefs you have the same credence
and them credence one. Furthermore, it does seem to conflict with decision theory. So according
to decision theory, you should have a credence one, if you have a credence one and something,
you should be willing to take any bet on it, no matter what the stakes are. But there's lots of
things we believe that we wouldn't take any bet on, right? So I believe I was born in Kansas,
but I wouldn't take a bet that would give me a dollar. If I was born in Kansas, and I'll be
tortured for the rest of my life, I wasn't born in Kansas. So I believe I was born in Kansas,
that's not changing. But I'm saying I do still believe that, but I'm not taking that bet, right?
The main response that the credence one people give to this is that
there's some kind of context sensitivity about belief. So in the context before I'm offered the
bet, I do believe that and being offered the bet basically changes my belief because I'm
not willing to make that bet anymore. So basically in general, you give up a belief when
you're confronted with certain kinds of bets, even if those bets don't constitute evidence against
that belief. I'm just going to leave that there as a reductio. I know some people like this
contextualist view of belief, but I really am not a big fan of contextualism. So for the sake of time,
I'm going to say I'm not satisfied with that response. But that is a common response that a
lot of people like. It's also maybe worth noting that some people like to have this view in which
belief is certainty, but certainty is different than credence one, saying the subtle distinctions
that they're making. I think two things here. So I think first of all, this view does suffer from
many of the same issues. So there's many things that we believe that we're not certain of, right?
I gave a lot of examples. I think similar examples to the credence one also work for the certainty
thing. And we're more confident in some things that we believe than in others, but you can't
capture that if belief is certainty. But I think furthermore, unless you're really clear about
what the relationship is between certainty and credence, this question, this answer doesn't
really even give us, it doesn't give us an answer about the relationship between belief and credence.
It just tells us something about belief and certainty. But if we don't know what the
relationship between certainty and credence is, other than certainty doesn't credence one,
I don't think this really helps. Okay. Here is a newer objection to the belief is credence one
view. I actually stole this from my paper that I refereed, but I really think this is a really
cool objection. So, and that objection is this, the belief is credence one view. It actually
undermines many of the motivations that are given for positing credences in the first place.
So I started off by saying, we have beliefs, we have credences, both kind of when I was
explaining what those are. And then also when I was kind of arguing against the element of this
views, I was giving these kinds of motivations. And I've given these spills a lot, like look,
we're more confident in some things we believe than in others. You could also think about a case
where you believe P, but then you get some more evidence for P. And then your belief doesn't
change, but something changes presumably like your credence, right? Or you believe P and you get a
little bit of evidence against P, you keep believing P. Again, what changes your credence?
So credence can help us capture these like subtle changes in evidence that don't change our beliefs.
And so I think the thought here is like part of the reason we even say that we want to say that
credences are a thing is because they're this fine-grained attitude that helps us distinguish
between various kinds of beliefs. Beliefs are maximally confident, beliefs are moderately confident
in, etc. But if belief is credence one, we don't need these distinctions, right? We're equally
confident in everything we believe. So, you know, I'm not going to sit here and just write a paper
on why belief is credence one is false. That's not the main point of this video. So I'm going to kind
of leave it at that. I realize this is short, but I really think it's there's something that is a
really big cost to your view. If you're reducing beliefs to something, and then you're undermining
many of the reasons for pausing that thing, you're reducing beliefs to in the first place.
So that's kind of the main reasons I reject the belief is credence one view.
Okay, moving on to section three. This is about just briefly about reductionism and some of the
reductionist views. I probably won't go into this a lot here, but one kind of question is what do
we mean by reduction? We're talking about basically these two views. Credence is reducing to beliefs
or beliefs, reducing the credences. But what does reduce mean? And I think there's there's
really three main options. It could be identity. So a reduces to be if and only if a is numerically
identical to be the main problem here is that identity is symmetrical. So if, you know, I am
identical to the philosophy professor teaching the second certain section of critical thinking this
semester, we're the same person. There's not we're like, like, there's a symmetry right there
between us. But reduction is supposed to be asymmetrical. One thing is reducing to another.
So one is more fundamental than the other. So some people still really want to try to make this
identity thing work. But I do think that's a problem. So two other views that are not symmetrical
would be reduction as supervenience. So a supervenes on B if and only if there's no difference
in a without there being a difference in B. And then there's also grounding, which is supervenience
plus basically. So a reduces to be if and only if a is grounded in B. So it's normally like the
supervenience plus metaphysical fundamentality and explanatory priority. You know, maybe the
grounding option is the best option. I'm not really going to take a stand on this here, but
just sort of note those as options. And if you think there's other good options for how we might
understand reduction, you can let me know in the comments. But yeah, I do think it's worth kind
of thinking a little bit more about what we mean by reduction here. Okay, so moving on from that,
we kind of talked at the beginning about these these five views, but then this view reduces to
two views. So we sort of ruled out this view, this view, and then the belief is credence one view.
And so dualism is kind of what we're aiming at, right? But it leaves us with two views,
there's a threshold view, and there's the belief first view. So we're really going to focus on
mainly those two views right now. So what's the belief first view? This is the view that credences
are beliefs with particular contents. So when you have a credence, what that means is you have
a belief about a probability, or it could be a belief about an epistemic modal, I'll explain
what that is. So, you know, maybe you have a point five credence that a coin will end heads.
What that is, is it's a belief, the belief that the probability that the coin will end heads is
point five. Normally, I think the most plausible candidate for the type of probability is epistemic
probability, which is some kind of evidence relative probability, but could also be a belief
with an epistemic modal. So epistemic modals are words like probably, may, can, might. And so,
you know, you might think my high credence it will rain tomorrow. That's an epistemic modal
belief, the belief that it will probably rain tomorrow or probably is an epistemic modal.
And I think the main challenge for the dualists from this belief first view, I'm calling it the
belief first challenge. And Andrew Moon and I actually wrote a paper sort of answering some
objections from the belief first view, I ultimately do reject the belief first view.
But you can think of the challenge like this, if we have beliefs about probabilities, why do we
in addition need deposit credences? It makes much more sense just to say we have beliefs and we
have probability beliefs, and that's it. So that's sort of the challenge I'm going to try to meet in
the next section. Okay, the second view that also presents a challenge to the dualists is called
the threshold view. This is the view that belief reduces to a credence above some threshold,
but that threshold is less than one. So I think I talked about this a little bit already. You
might say like the threshold is a fixed threshold, 0.75, let's say, or someone suggested like the
inverse of the golden ratio, which is like 0.6 something. So there's been various like fixed
thresholds proposed, or you might have a view like a 0.5 could be the threshold. Or again,
the threshold could vary with stakes or context. So it might be that everything that you have at
least a 0.75 credence in or above, you believe. So that's a threshold view and this can capture
the idea that we're more confident in some things that we believe than others. And I think this
view sort of presents this challenge for dualism, which is this, if we have both a belief in P,
and a credence in P, what is the use of the belief? So the credence is much more accurate,
it's more fine grained, it can better sort of capture our attitude towards the proposition.
And this suggests that beliefs are either superfluous or just this extra thing that we don't
really need, or they're inaccurate. And so then we should just trust our credences. And so, you
know, you could maybe try to use this to motivate some kind of belief of limitabism, but I think a
lot of people will take this threshold or this credence first view instead and say, I mean,
we do have beliefs, but what beliefs are are just these threshold passing credences.
So I want to try, that's called, and by the way, that's called the Bayesian challenge. So I want
to try to answer both the belief first and the Bayesian challenge in the rest of this paper.
Okay, so let's start with the belief first. I think actually both of these views
suffer counter examples from certain kinds of irrational thinkers. And the relationship
between belief and credence, it's not a normative claim, it's not a claim about rationality,
it's just a claim about what reduces to what. So it should be able to explain both cases of
rationality and cases of irrationality. But I think the belief first view, you can actually
give counter examples when you think about certain irrational thinkers. So suppose someone's
irrational, it's not at all clear, given that they're irrational, what would prevent them from
having a credence that's different than their beliefs about probability or their epistemic
modal beliefs. So, you know, this person might have a credence of zero in something,
but still think it's possible. Maybe they are engaging in the kind of wishful thinking or
something. Or, alternatively, they might believe something's impossible, but have a non zero
credence in it. So have a credence in that it's above zero. And so yeah, maybe these are irrational
combinations of attitudes, but should we really say they're impossible? And I think especially
if we have kind of infinite space, like probability space is involved, there might even be cases where
you have like a non zero credence in P, but you should believe that P is impossible. So it might
not even always be irrational. You can also think of like other like maybe more real life cases as
well. So think about someone who's paranoid or delusional or just really jealous or something.
And maybe they have like a really high credence, their partner is cheating on them. They're very
confident that their partner is cheating on them. But they know at the same time that they really
don't have good evidence for this. Their evidence doesn't support a high probability that their
partner is cheating on them. And so they believe that the epistemic probability that their partner
is cheating is low. So again, epistemic probability, it's relative to your evidence. They're saying
I don't have good evidence for this. They might even admit I know the probability of this is low,
but I just can't shake this high credence that my partner is cheating on me.
Okay. So those are some example, I think counter examples to believe first you from your
rationality, but I also want to think about rational agents and think about what's the
role for credence that may not be played by a probability belief. Okay. So I think probability
beliefs are useful and we do have probability beliefs and they're useful for a couple of reasons.
I think first of all, when we're undergoing certain kinds of probabilistic reasoning,
so we're trying to start from some probabilities and reason to other probabilities,
it's much easier to reason with probability beliefs. And there's actually been a lot of work on
like whether we could even do that kind of reasoning with credences. So Julia Staffel has
an interesting paper on that. I think it's called Can There Be Reasoning with Degrees of Belief.
So I think probability beliefs because of the way the probability is part of the attitude,
it's not in the content of the credence. I think they're very useful for probabilistic reasoning.
I am also sympathetic to the idea that our credences, when they're rational, they'll probably
closely track our beliefs about epistemic probabilities because then they'll be connected
to our evidence, which is our beliefs about how epistemic probabilities are connected to.
And I also think probability beliefs, they can allow for a certain kind of flexibility.
So it might be sometimes useful to form different beliefs about different conceptions of probability
so you might know the objective probability of P is either one or zero, like in a mathematical case,
you know this theorem's probability is either one or zero, but because you don't know whether the
theorem is true or false, the epistemic probability is 0.5. So probability beliefs allow us this
like kind of flexibility that I think is really useful. However, I think there's a unique role
that credence plays that beliefs about epistemic probability can't play. And there's really like,
it's kind of like this three-fold view. So the first is that creatures who lack certain concepts
or who lack certain cognitive capacities, it seems like they can have credences, but they may not
have the concept of probability or they may not have the cognitive sophistication to form
the probability beliefs, these more complex beliefs. So this objection has actually been
pushed, it was originally pushed by Frankish, who I cite here. And, you know, Andrew Moon and I,
I think we did our best to kind of respond to this and say, well, either they don't have credences at
all or they do have the concept of probability, but I'm not totally, I'm still in the fence about
that. And I mentioned it here because I do think it kind of fits well with this general role for
credence, which is that it's cognitively thinner than a probability belief. And I'll say more about
that soon, but let me just go through these other two really quickly. So there's also creatures who
form a credence in a very complicated proposition. And that proposition is right on the edge of what
they can grasp. So one example I've given is, he said that she said that he knows that he believes
that she said that he's sure that she's mad at him. And it's like, wait, what, you kind of have to
think about that for a second. So you might barely grasp that and form like a 0.5 credence in it or
something. But you can't form the more complicated belief that the probability of is 0.5. And so
again, credences let you, you can form a credence in that because it's cognitively thinner, because
you're not forming a belief out of probability, the 0.5 part of the credence is in the attitude.
And then the only thing you have to grasp is the more, the more simple, I guess, proposition.
So I actually have a paper where I defend this in more detail, but again, I think it fits with
this general rule for credence. And then finally, I think, and then maybe this kind of gets at
the general thought, it allows us to express uncertainty and to be uncertain without having
to represent that uncertainty in the content of what we're, what we're believing. So that lets
us, it helps us represent uncertainty in a less cognitively demanding way. It also enables us
to have a belief in a credence with the same content. So you can believe it will rain tomorrow,
have a 0.5 credence that will rain tomorrow. It's not like you're believing one thing and then
you're believing something with a different content. And so in general, I think this idea that
credences are cognitively thinner in some way, whereas probability beliefs are cognitively
thicker in some way, I think makes good sense of, I mean, the distinction, I think, between
probability belief and credence, but also these various kinds of creatures or people that seem
like they can have credences, but they can't meet this more cognitively demanding thing
that is probably what probability beliefs require. So I do think a belief, first of all,
would probably just say like, this appeals to cognitive thickness is just question begging,
it's my view. I think that, you know, probability beliefs and credences are equally,
equally cognitively thick. And I think, I mean, it kind of just puts us at a difficult point
dialectically, because this is just really fundamental to how I and I think many others
in this debate view beliefs, probability beliefs and credences. And so at some point, I wonder,
like, are we really disagreeing about what credences are? We're just like talking about
different things. I don't know. So I'm not necessarily convinced that this is going to
convince the belief first, but I do think this is kind of explaining again, why Liz is a newest,
right? And I do think there's something to be said for this idea that there's a difference in
cognitive thickness, and that gives credences this unique role that probability beliefs can't play.
Okay, let's move on to section five, which is against the threshold view. So we're called the
threshold view. The threshold view is the view that beliefs, sorry, I'm just adding this to
my notes really quick. It's the view that beliefs are credences above some threshold, and that
threshold is more, or sorry, less than one and often greater than point five, although I don't
think it has to be. So in that, again, that threshold can be fixed or it can vary with context.
So that's a threshold view. I think, first of all, there is, again, a counter example from
irrational thinkers. So I think there are certain cases of, you know, double-mindedness or self-deception
or acracia when you believe or do something that you think you shouldn't. And I think these are
just best explained by the dualist. So suppose that someone has an irrational belief that they
can't shake. Again, maybe maybe they're paranoid that the partner is shooting on them and they
believe their partner is shooting on them, but they kind of acknowledge, like, this is irrational,
and I have a low credence that this is true. So they realize this is poorly supported by their
evidence and their credence kind of fits with their evidence, but they have this belief they can't shake.
An alternative case, maybe a case where someone is convinced that believing something but having a
low credence in it is the right response to their evidence. So some people have actually argued that,
for those of you who are familiar with the preface paradox, that this is actually how we
should view the conjunction of all of the claims in our book. We should believe it, but have a low
credence in it. There's other examples here as well I'm not going to go into. But you might genuinely
believe this, but let's just concede for now that they're mistaken about what rationality requires.
So maybe they are, in fact, irrational or something. So in both of these cases, it seems like they
really do have a low credence. Their credence is not a maximal credence. We already talked about
belief as credence one view. It's also not threshold passing. And so it's not totally clear how the
credence first could explain these cases of belief and low credence. They might try to say
that they have two credences in the same proposition at the same time, but really that possibility
has not been discussed in the literature very much and just seems really weird. And these are
like pretty basic everyday cases of irrationality. So it would be surprising if they had to appeal
to something so extreme to explain these kinds of cases. However, the dualist has a really natural
explanation for what's going on here. Like, look, belief and credence are these distinct and
irreducible attitudes. So of course, especially if the Asian is irrational, they can significantly
come apart. You can believe something and have a low credence in it. So this argument again is
spelled out in more detail in the paper I have with Peter Tan. Okay, so let's talk a little bit more
about how I think we can answer the Bayesian challenge. What is the role that beliefs play
that high credences can't? And I think what that role is, is we can kind of sum it up and that
beliefs close off possibilities. So when you believe P, you're in some sense ruling out or
closing off the possibility of not P. And it's not just in this like pretending way, you're not like,
I'm going to, you know, be an actor, an actress, or I'm just going to concede this for the sake of
argument, but you believe P who represent the world as P is true. So you're kind of ruling out
not P in a mental or representational way. And that's going to come up when I talk about an objection,
maybe briefly at the end. But I think that high credences don't do that. So a high credence in P,
what it does is it represents P as likely, but it nonetheless leaves open the possibility of not P.
There's also, so you might wonder what's the use of closing out possibilities in this way.
And I think there's sort of two main uses for this. The first is just efficiency and reasoning.
So we cannot be considering every error possibility that's always relevant to our
reasoning. And so beliefs, they let us rule out possibilities, which just simplifies our reasoning.
And when the stakes are low, so maybe we have a ton of evidence for P. Of course, it's not perfect,
but it doesn't really matter if not P. So it makes sense to just suppose P for the sake of argument.
Or we just have to make a decision really quickly so we don't have time to think
there are a bunch of alternative possibilities. Then it just makes sense to treat P as true
and represent the world such as P, not just accept that P is true, but take P on board as true.
And so you might think about a soccer goalie and they have to make a quick decision about how to
block something. They might just sort of represent the world such that someone's coming from the left
to kick the ball in a certain way. Instead of thinking about the possibility of error and reasoning
through a decision table, no, they just got to make a quick decision. You could think about another
case of you're in a battle and the enemy is upon you and you need to make a decision. That could
actually be a high stakes case, but because you have to make a quick decision, you might just kind
of represent the world such that P is true. Another example I've given here is if you
walk into your office and see your office meets coat and backpack, you'll probably just represent
the world such that as they're in the office today, you'll believe they're in the office.
If your friend says just so-and-so in the office, you'll say, yeah, of course,
but if the stakes get really high and the police are investigating a crime and they have to know
everyone who's in the office, you're going to move to your credence and instead say, look,
I'm not 100% sure. I don't know for sure. You'll express your non-extreme credence
when answering the cops, moving from the belief reasoning to the credence reasoning. Moving from
the low stakes to the high stakes often will prompt us to consider these alternative possibilities.
That said, though, I don't think that beliefs only play the role of efficiency. I think
intuitively cognitively sophisticated agents, so maybe like an angel or some
agent that really has this extra brain power, I think those kinds of agents that it's not
difficult for them to consider lots of alternative possibilities, I think they would have beliefs
too. I think this kind of ruling out role that beliefs play isn't just for this purpose of
simplification. I think there's another role that beliefs play as well, and that's beliefs,
let us take a stand. They let us have a view of the world and they let us remain steadfast in
our commitments. We might even want to do this when we receive counter evidence against our
commitments that lowers our credence, but if beliefs just are our high credences, it's not
really clear how that amounts to taking a stand. If we are able to close off the possibility of
not P and hold on to that belief, that lets us represent the world such as P,
not be spineless in the face of disagreement or counter evidence, and again, it can underlie a
commitment. Laura Bouchac argues this. She has a cool recent paper about disagreement, how this fits,
but also in her 2014 paper, she argues that this could also underlie certain kinds of moral or legal
verdicts. So I think beliefs are useful both for this efficiency and simplification role,
but I think also they kind of just let us take a stand, which is important for various reasons,
including keeping our commitments, maybe including underlying moral legal verdicts,
and just being able to have a view of the world, take a stand on the truth of something.
That said, credences are useful as well. Credences give us a precise and accurate representation
of our level of evidence, and when rational, they sort of track our exact level of evidential
support as we kind of update them by conditionalization, and they also help us keep track of
counter evidence. So when we have this commitment and we're like, I believe P, I'm committed to P,
you know, whatever, and then you get some counter evidence, you know, it's good to a certain extent
to keep that belief, but if your counter evidence just keeps going down and down and down and down
at some point, you should give up your belief and your credence can help you track when you
should give up that belief. At the same time, it's nice to be able to continue in your commitment
in light of the non-decisive counter evidence. And so your credence can track that non-decisive
counter evidence, but you can kind of keep that belief. So you can keep something,
even though your credence goes down in light of the non-decisive counter evidence.
Okay, cool. So just to kind of sum up, basically, I have hopefully accomplished or at least begun
to accomplish two goals. And that is to carve out a unique role for credence that beliefs cannot
play, which is a cognitively less demanding way to represent uncertainty. But also,
you know, I think I've sort of discussed these two main answers to the Bayesian
challenge. One has to do with simplification and efficiency. And the other has to do with,
you know, remaining steadfast and having a view of the world. And I've hopefully,
what I want to do is sort of unify both of these camps into this fundamental role for belief,
which is that it closes off the possibility of not P. And so I think this has actually pretty
plausible result, which is that agents that are more cognitively sophisticated than us,
they would have some beliefs, but less beliefs than we have, because they wouldn't need these
beliefs that are only there to just simplify reasoning. There's sort of two outstanding
objections. Maybe I'll just go through them super briefly. So the first is why not acceptance? So
when you accept P, you act as if P is true. And you might wonder, especially for this kind of
efficiency role, why can't we just accept act as if the proposition is true, rather than believe it?
And part of the answer is that I don't think, again, it's not this like pretending thing beliefs
aren't there to just like, let us pretend that P is true, whereas I think acceptance is much more
of this pretending thing. But beliefs have this mental and representational component. So it's
not just I'm going to act as if P for some practical purpose, but I'm actually mentally
representing P as true. And so I think beliefs plays roles that acceptance cannot, which is this
representing the world such as P, letting us mentally take a stand on P,
and also helping us not be spineless when we get counter evidence against P.
The second objection is when I'm actually kind of still mulling over and thinking about, I think
it's a really important objection. And that's the question of when we act on a belief versus
acting on a credence, like beliefs, maybe they close off possibilities, credences leave them open,
but when do we act on one versus the other? And I do think when we talk about the simplifying
role of belief, there's a really good answer. And that's that you act on your beliefs when
the stakes are low, or you have to make a quick decision, but credences are useful when the stakes
are high, or we have a lot of time to think through something. And so I think a further
interesting question here is, what about these cases where we want to take a stand on something?
And I think those could actually be really high stakes cases, but cases where it is appropriate
to act on our beliefs, maybe that belief underlies an important philosophical or political or ethical
or even a religious commitment. So I don't want to say that beliefs are just only associated with
low stakes and credences are just only associated with high stakes. But I think it's going to be
a complicated story here, where some beliefs, it probably is going to depend on the content of the
belief, will be more associated with low stakes, but other beliefs where the content is really
important to us, those may be beliefs that we can kind of maintain even in the face of high stakes.
So either way, I hope you have a good sense of kind of what my dissertation was about,
and why I think beliefs don't just reduce to credences. And I don't think credences just
reduce to beliefs. So thanks for listening.
