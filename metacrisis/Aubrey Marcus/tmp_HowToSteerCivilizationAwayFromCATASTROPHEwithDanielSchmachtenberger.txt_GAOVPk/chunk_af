and then it started to verticalize with the digital revolution and the exponential tech
that digital makes possible. So what that means is the speed and the consequentiality
of the types of issues we've had for forever, the problems of both warfare,
meaning cause direct harm with our power and externality, indirect harm caused by our capabilities,
is now on the verticalizing part of the exponential curve. And so can we run exponential
externalities in a finite biosphere? No. Can you do exponential warfare? Can you do exponential
control of what different populations think, meaning exponential disinformation and still
have enough coherence or consistency for anything like a viable civilization? No. So we are at this
unique point where the total magnitude of power makes the way that we've been behaving that's
been problematic for a long time inexorably catastrophically problematic. But those same
types of capacities, that same abstraction and technology makes possible if we repurpose how
we're using it, something like a new type of viable global civilization that has never been
possible before. The ability to process, I mean, obviously, we're having a conversation mediated
by computers and satellites and the internet that then lots of other people are watching that allows
for something that couldn't have happened previously, right? If we want to make decisions
regarding the biosphere and the technosphere and very complex things, you have to be able to
coordinate the sense-making intelligence of lots of people. That same tech that being used for
narrow rival risk purposes, driving externalities, destroy stuff, if we took those externalities
and kept internalizing them and saying, let's take all the things that matter and apply the
tech towards that progressively better, make a very different set of possibilities.
Yeah. One thing that you bring up, which is I think really important, is in the world where we
cannot escape the mystery and that we must adopt this felt sense of humility, oppression of
contrary opinions is absolutely a problem because you cannot be certain that you're
right about anything. When you start to censor or oppress through any different type of cancel
culture, force, removal, de-platforming, etc., even though your justification might be, well,
from a utilitarian standpoint, this might be causing harm. The fact that you can't be
certain about whether you're right, especially when you're dealing with a hyper-object like
the interaction of a virus, which we know very little about with the most complex organism,
you could argue on the entire planet, which is a human being, which is in itself a hyper-object,
the unknowable. You can't start censoring people, de-platforming them because you think you're
doing the right thing. It fundamentally degrades the whole thing. This is one of the deep challenges
of this hubris, this certainty that you're right. We need this chorus of voices in discourse
to try and outsource this problem to as many different perspectives as possible and then
start to wade through it, get them in healthy discussions. As I was leading up to this, I was
thinking like, fuck man, the art of debate, really honest debate where you give each other a hug at
the end and thank them for bringing the ideas, that idea between these different polemic sides.
This is something that needs to come back and it needs to come back in the public form and be
encouraged. Like, great, wow, this is an interesting, contrary opinion that you have, Dr. Thomas Cowan.
Like, let's have you talk to someone who's the leading expert in germ theory and let's talk about
your terrain theory and let's just discuss this. Let's encourage this type of thing. It seems like
that's what's necessary to move forward and start to sort out all of these immense problems.
Unfortunately, it's not what's happening. It's opposite of what's happening right now in many
ways. What we're seeing is just the use of force. We're seeing power games being played out,
which I think they're grounded in this hubris, but ultimately this is, and I think it's a big
part of what your conciliance project is, is to make transparent these things that are happening
so that we can get to the point where everybody's just starting to talk to each other and collectively
we're starting to figure shit out together. This is actually really tricky and nuanced.
Most people really don't like the idea of censorship of speech and de-platforming when it
comes to ideas that they resonate with. But most of the people, let's say we take someone who has a
politically right perspective that doesn't like the de-platforming impulse of cancel culture,
they might still feel really happy to censor Chinese sock puppets that are sowing propaganda in
the U.S. and they're like, we have to fucking stop that because people don't have the epistemic
training to be able to know what is a sock puppet and what isn't. And they're influencing teenagers
who are on here who are already upset and suicidal or whatever the fuck it is, right? And they're
using AI tools to be able to do it. They're using amplification in a way when we talked about freedom
of speech, the most people that you could talk to was like the people that could hear you speak
when you were standing somewhere. And so do we want to censor Russian propaganda in our media
space? Do we want to? So most people think that there are certain actors that don't have the
interest of whatever the in-group we're paying attention to is that could share information
that is false but with a higher degree of game-theoretic capacity than the general public has
that could beat them and they're like, no, we actually have to deal with that. So it's tricky,
right? There's a nuanced argument here. And because there's a nuanced argument,
it's the kind of thing that you need the right kind of conversation around. What does
when we talk about free speech, a right, what is the responsibility that's associated with a right?
And what does that look like in the digital amplification age? And then when the AI
optimization algorithms take whatever the stickiest shit is and optimize it for people who've already
been trained for a whole life of addictive susceptibility who will then go act on that
consequentially, I can put out something that is almost tailor engineered to fuck people up
psychologically and it will work across the say I kind of think is that a good thing? Should we
just allow all of that? Well, then no, we'll stop that. Well, who is the we that we trust to adjudicate
what is true? Because any power that can adjudicate what is true if captured would be the most
powerfully bad books. So this is why this is tricky, right? And this is why we have to rethink,
okay, in the digital AI empowered, etc. world, we have to rethink some of these things.
So what are fundamentals rights and responsibilities being paired as an important concept?
If I have a right and no responsibility that's associated, you get certain kinds of entitlement
and tragedy of the commons issues. No one is responsible to mediate that, which is well,
who gives you the right? Where the fuck does the right come from? Who's tending to and moderating
that if I'm not willing to take any responsibility for? In democracies, we can vote ourselves rights
that we're not willing to take responsibility for and the things start to decay. So, okay, if I have
responsibilities and I don't have rights that are attached at some kind of servitude, so there's a way
that those have to be held together, right? And different cultures could do it differently, but
just like there's a dialectic between traditionalism and progressivism, a dialectic between individualism
and collectivism, there's a dialectic between rights and responsibilities that has to be thought
about well. And you can fall off on either side of that thing real easy. Now, just like there's
epistemic hubris, there's moral hubris, right? I'm so certain that my moral position is right
that I'll fight a holy war over it. And there are modern online versions of holy wars
associated with new ideologies that are kind of like, that have religious like elements,
belief, in-group, et cetera, proselytizing. So, there is a need for both, and this is
so interesting. You were mentioning earlier epistemic hubris and epistemic nihilism.
There's this very sad phenomena where a lot of people go from epistemic hubris where like,
they have a not well-considered position on something. They think it's well-considered
because they watch 10 YouTube videos. And they have no idea how much it they don't actually
know about it. So, there's a Dunning crew. And this person is actually literally wearing a shirt
right now that says, because science, period. Like, I've actually seen that shirt, because
science, period, where they're so certain that the science that whatever they're talking about
is so right that they're just proclaiming it. Well, it can go both sides, right? There's a
because science and then there's also a because religion and because Q said so.
Of course. Of course.
What is the thing that I think gives me the certainty and authority that I can defer to
in this way? And things are complex. I want certainty. I don't want to do the hard work.
So, I want to cognitively offload somewhere. Well, that's then very useful for anyone who
wants power because they're like, oh, these people want to cognitively offload. I'll tell
them what's true. And now you have a power game for being able to share versions of truth that
have economic and political advantage to somebody. So, this question of a trusted institution,
well, what would be the basis of warranted trust? How do I know if I can trust this fucking thing?
So, what is the oversight process and what are the capacities that people have to have to oversight
it properly? Can I oversight something where I don't understand the technical details of it?
These are good and important questions and things that we have to develop because we do
need to develop a certain capacity for shared sense making if we're going to do shared choice
making. And if we don't do shared choice making, then we're fucked. Then China will do shared
choice making because it just says everyone will sense make the same way because of dictate.
And Sesame Credit will ensure they don't do anything else. And a IoT surveillance system
will make sure they don't, because of anyone else, they don't think anything else or act on it.
And we don't have term limits. So, we don't have to worry about four years doing one thing. And
then the other four years undoing whatever was done in those years, most of the energy just going
into campaigning. We don't have internal parties just using up most of the energy of the country
wasted as heat, right? So, they can actually build high speed trains all around the world.
And the US hasn't built one in our own country. You're like, that's not a good sign. That's not
a good sign for them a better capacity to actually do real shit, right? To coordinate
towards some real important things. They lifted 300 million people out of poverty in a fairly short
period of time, like nobody else has done that kind of thing. So, you're like, oh, autocracy is
actually quite effective. And high tech empowered autocracy is something the world has never seen.
The world has never seen a Sesame Credit IoT AI empowered autocracy.
That's an interesting proposition of what that thing could be. Well, that's going to beat an
open society if the open society is spending all its energy fighting with itself. And the left
and the right spend most of their energy fighting each other. You spend four years doing something,
four years undoing it because the term limit no one even thinks about a 30 year plan for anything.
Because I'm not going to get reelected if the shit that I do doesn't show up in the four years of
that time. So the short term orientation in the internal infighting, we just lose, right?
So technologically empowered autocracy runs a 21st century, unless you can get an open society to
coordinate more effectively than an autocracy can. How the fuck do you get an open society with lots
of people to coordinate more effectively? This is the societies are societies end up failing
on either the direction of chaos or oppression. I can say, well, the people think different
stuff. They had different life experiences. They have different beliefs. They want different
stuff. They aren't that connected to wanting to make sacrifices for people they don't know.
The tribal thing worked because you knew everybody in that tribe. Your life depended on them.
There were only 150 people, but this is huge numbers of anonymous people. And fuck those
people in that state I've never been to or whatever it is. So how do I bind those people
together when there's so little basis for binding and so much energy for cleaning?
So if I don't, it's very easy to have chaos emerge pretty naturally. I want this thing. I
want this thing. And we're just going to fight over it and you get increasing kind of all against
all the wars, right? And then the thing fails. You say, no, we need order. We actually need
some order to be able to coordinate. Otherwise, we get beat by some external force that has order.
So we're going to get the order through imposing it. We're going to do stronger top-down. Everybody
thinks this thing. Better versions of government cohesion of belief. We call that government
propaganda. Control of the population. We call that authoritarian state, whatever it is. I mean,
control of the behavior. But then that's a failed state in its own purpose because it's not actually
serving and liberating the people. And as a result, it ends up getting a homogeneity of thinking,
which doesn't have the creativity to actually innovate for new problems in the world and usually
fails for those reasons and doesn't have a high enough collective intelligence because of it doing
that homogenizing thing. So what we need is order that is not imposed. So we don't fail on the chaos
side or the oppression side. How do we get emergent order? Well, if the order is to be
emergent rather than imposed, it means everybody has to be able to make sense of the world similarly
and has to be able to reason about not just what is, but what ought. So ethics and morals,
similarly, and have enough respect for each other that you have a conversation where you want to
hear what other people think. And you don't want to just beat them and then think that they don't
exist and they're not going to come back. There's a short-sightedness of these cultural arms races
and political arms races. We beat them and now we won for a minute. And then they up the ante and
come back. If they don't go away, if you don't get the people off the planet, then it's Von Klauswitz
said war is politics by other means, but politics is the way that we get to actually avoid war.
So if I want to avoid war of some kind, how do we coordinate, especially when
there's forced coordination occurring through technologically empowered autocracy?
So now this comes back to your point about dissenting views.
A civically-minded person, as well as even a well-informed epistemically-minded person
knows that they're probably wrong about most things, knows that there's probably a lot of
stuff that they don't know, that they don't know, that they want to know it. They don't want to hold
on to being wrong about something or partial or whatever. They also don't want to hold a view
that is going to polarize a lot of the population against them because that they should cooperate
with, where it would be better to cooperate with them if you really do long-term thinking on what
not cooperating looks like. So I want to seek to understand what other people are thinking,
both what they value and their understanding of the world, and we want to try to create a
situation in which we can synthesize our sense-making of what is. And we can identify,
okay, so in this particular situation, you're saying no to this climate change policy or
whatever, and it's not because you hate the environment and want to fuck the environment,
it's because you think that this particular policy is going to damage GDP for the US,
China's not going to agree to it, and it's going to cede the 21st century to technologically
empowered talkers. What you really want is the protection of open society. So you're looking
at climate change through the lens of liberty. Liberty. Liberty is a valuable thing. I'm actually
down with that. I'm looking at environment. You can't care about the environment in this way.
You can't even believe the science or look at it, and your lack of belief doesn't have to do with
looking at it because you think my solution equals something that will destroy liberty.
But otherwise, you actually also would care about the environment. You prefer clean air and a
world that isn't destroyed through excessive natural disaster. So if we can separate the
strategies that are shitty strategies from the values they're seeking to serve and recognize
that the values on the other side are also real and say, how do we hold these together and then
try to come up with solutions that meet all of them better, that have less unnecessary tradeoffs,
that balance the tradeoffs better, then we stop driving unnecessary polarization.
And you can start to have the fact that in an open society, those diverse viewpoints mean more
collective intelligence than the homogene thing has. And as a result, it can actually coordinate
across a larger body of collective intelligence as the only thing I actually feel much hope about
in terms of how we move through this next phase. For me, what I think is actually gives me hope
that we might do it is I think we all have to get back to the deepest fundamental truths,
which are that we are all connected. We are all in this state of inner being. And I truly believe
that I know with G that this is reality. And you can look at it, and again, you can justify this
in a lot of ways. We're all connected to the earth. We're all connected to each other. We're
all more similar than we're not. We're all in this together. This is a global existential crisis
that we're facing. So either we push against the bounds so much that eventually our tribalism
collapses and all of the petty needs of one versus the other fall apart because we're really
up against the brink of something that is no longer tenable if we continue. And it's so
prescient that we will die. We will all die. It's mutually assured destruction if we continue the
