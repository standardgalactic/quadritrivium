have many, many people in a bind in that way because of the they've just gotten so much momentum.
And there's really nothing that can compete with it.
That's so
when we developed antitrust law in the US and many countries, we're developing antitrust law to make
sure that and monopoly laws, there was a pre-digital world and we didn't have Metcalf network type
dynamics. And so those weren't factored into the way that we thought about it. Something only
became a monopoly. Typically, if they did some work to very actively in criminal ways, suppress
competition and then even get government support for how they did that thing.
But in network dynamics, where you have a Metcalf law type process, meaning that the value of the
network is proportional to the number of people on it. So as more people join, it becomes more
valuable. Then once you get above a certain escape velocity, it's more people are going to be joining
that thing relative to any other thing. Because as more people join it, it continues to become a
stronger attractor. And so you end up getting monopolies that are not a government monopoly,
the previous type, but it is a nothing else is going to emerge. You have a power law distribution
of within a domain, there's Amazon and then there's every other marketplace. There's Facebook and
then there's all the other kind of social media. There's YouTube and then there's all the other
video channels. You end up getting that kind of power law distribution within those verticals.
And so that is functionally a monopoly. It's a monopoly that is bigger than countries
have a very hard time trying to regulate something like that, because countries
move very slow relative to the speed of corporations, especially once the country
countries have decayed as much as ours have. And the corporations have the money to keep
paying for lobbying that is and lawyers that are very effective. And when it's this kind of thing
and affecting public opinion in a way that would be critical to the basis of changing law itself,
so it becomes obligate. Once it becomes large enough where if you choose not to participate
with it, you're really not participating in society, it became an obligate thing.
And so now we have to say, okay, that's very powerful. Is there a way that it is bound to the
good of society? Or is it just unchecked power? And what would check that power anytime a new
power comes? It's really powerful. We have to say, does it differentially serve some over others?
Is it tending to the good of the whole? If it isn't, how do we check it? And that's
a core question with all of the exponential technologies is they make rapidly more power
and much faster than any previous technology did that. And they are not being developed mostly
for kind of comprehensive commons integrity as their basis.
Right. And that's, I think, a key challenge here. Because of course, as we set up,
as the forefathers set up the government, they understood the absolute necessity of checks
and balances. And this is that thing that we've been talking about. But this is just a non-governmental
actor. And a lot of times people think of these corporations as a bunch of evil people plotting
to do bad things to the world. I really don't see that when you actually get in there. My little
brother works for Facebook. He's not trying to fuck the world. He's just trying to do these,
like recruiting different employees. And he likes the lunches that they serve. And he keeps inviting
me over there to campus to go grab a lunch with them. And it's like that, as you even go up,
even in pharmaceutical companies, there's, in some ways, I think there's this kind of
just plausible deniable. They just don't really want to look at what's happening. And they just
kind of look the other way. But it really seems like the organism of the corporation itself
is an entity. And if we really look at that as an entity, that entity has a primary objective.
The collective entity of a corporation has a primary objective. And it is to maximize profits
by whatever means necessary. That is the prerogative of the corporate entity.
So you have to have the people, then, who are the angels, who are willing to collectively within
that, be more powerful than the entity itself and move beyond their own profit motives, and even
to the self-destruction and annihilation of the entity itself when it gets too powerful.
And that's asking a lot from individuals who, to get to that level of power, typically are
running from some kind of trauma, dealing with some kind of validation complex, and, you know,
the desire for importance and love from the world, which they didn't get from their parents or
God or whatever other thing they needed. So they needed, in other external ways, chasing the hungry
ghost of all external validation in all different power games to try and get that. And so that's
what we end up seeing is we end up seeing these entities rise that when the entity itself can
be evil, but the people within it are probably, you know, they have some culpability, of course,
because they're not all rallying together to address the challenges. But it's a lot more
nuanced than I think a lot of people think. Most issues of evil are. Yeah. The fact that almost
all media that we can consume from cartoons on is usually a good guy versus bad guy in our culture
shows how deeply we're conditioning that set of memetic tropes. And most of the time, the who the
good guy is and who the bad guy is, is relatively cut and dry. We celebrate when the bad guy gets
it at the end and good guy makes it identify with. And this is good for socially conditioning the
mindset that will socially support war or something like that. But it's not good for actually
understanding how the world works where it's not that common that the bad guy thinks they're bad guy.
Extraordinarily rare. Yeah, I mean, I don't I don't even know. I mean, maybe some serial
killers, but like, it's so fucking rare, even the worst actors of our time still had some
justification that they were doing some good, even Thanos, look at the story of Thanos, right,
wipes out half of the population for the greater good of the universe was his rationalization.
I mean, obviously, he's a fictional character. But we know we see characters like that that
always seem to have some idea that they're doing some good for the world in some way,
where they they're doing good for someone, but they're in a forcing function. There's a
so having a conversation with somebody about geopolitics the other day, and they were talking
about Putin and somebody there had a lot of respect for Putin as a global strategist and
world leader and someone who kept Russia from being more degraded by external capitalist
forces after the wall came down. And some people thought he was a particularly evil guy. And I'm
like, well, if you're in his position, and NATO forces are trying to set up military bases right
on your border and running propaganda narrative campaigns against your people. And, you know,
on and on, do you do some what look like kind of evil things because you feel obligate that you
have to do that in order to protect the people you take Israel and the Golan Heights, it's like,
that seemed kind of fucked up that they took the Golan Heights, they don't have it, they have no
defensible airspace from people that are sending missiles to them. So you say, well, you shouldn't
have done that and you should just have no defensible airspace. So if there was one tribe
that started tribal warfare, the other tribes died by default, if they didn't get good enough
at tribal warfare to defend themselves. So as soon as anybody starts the game of power in that way,
it becomes an obligate game for everybody to play or they lose by default. And then this creates a
race to the bottom. And then this this defines the characteristic problems in the world that we
have to overcome. These are coordination failures. Both the arms race. Does anybody want to live in
a world filled with autonomous AI drone weapons? No, not good. I don't think really any generals
think that that's a nice world to live in. But is every country that can pursuing that? Absolutely.
Because if we don't and somebody else gets there first, they run the whole world.
And they either kill all our people around the world and we don't like their political
philosophy or whatever it is. So not only do we have to make them, we have to make them faster
than they make them and make the counter weapons and spy on their doing it and the light to their
spies. And so then so that's the arms race, right? And then we're like, well, what if we just made
an agreement that nobody makes the AI weapons? How about we come together and make a treaty?
How do I know that they're keeping the treaty? How do I know that in an underground black project,
they're not building it? And I'm keeping my side of the treaty and then they come out and take over
the world. Fuck it. I can't actually ensure that they aren't keeping the treaty.
And most likely, and most likely, we know that that's the way that governments work.
That's the way that we've always done it, right? This is the way, look at Game of Thrones, right?
It's like, yes, absolutely. We honor this treaty. But it's not the case. You look at history and
rarely have we seen that. We haven't evolved to a point where that is a reality where the noble
virtues of honoring your word in a good, healthy handshake really mean something. Never has been
at that kind of scale. So it's sensible to not trust that that's going to happen.
So the people who've paid attention and understand real politic are like, okay,
your treaty is a cute idea and we're going to build our AI weapons. And either we'll sign the treaty,
lie and say that we're keeping it, try to lie to your spies that are finding out if we are or not,
and spy on you to see if you're doing it or not. Or we won't even bother doing it, right?
Like those are the ways that it ends up going. And this is the same of like, why have we not
done nuclear deep proliferation? Who wants to be the chump that gives up their last nuke first?
Because what happens to them, they give up their last nuke first and then the other person's
effects on the deal. How do we know they gave up their last nuke and they aren't hiding one?
This, and so how do we know that the one that they aren't hiding isn't faster so they can win
at first strike because they were doing hypersonic missile stuff? Fuck, we have to actually keep
racing with a nuclear arms race to build faster and faster hypersonics to win the first strike game.
That's, we're stuck in that thing, right? Very largely the world's stuck in that thing. And it
has been historically, it's just, it wasn't until World War II that existential risk or catastrophic
risk for the whole world was a possibility because our tech wasn't big enough to be that damaging
to the world. It's important to give it for the history of the world existential risk to
civilizations always was a real thing. There is no more Roman Empire as it was or Egyptian Empire or
Aztec or Maya or like the thing that we understand about civilizations, if they have in common, is
they all have a lifespan and they fall. And so that was an existential risk, a collapse of civilization
for those people. And that always happened, but it was always local, right? And they happened for
reasons that are not that different than the ones we're looking at today. They overused the
environmental resources and stopped being able to feed the people adequately. Like that was a
very common thing that outstripping environmental resources is a many thousands of year old issue.
And or they got so big that they couldn't create coordination amongst all of the people. And then
they couldn't also protect all of their border space. And then they got overtaken by a smaller
rival or they got so powerful that infighting amongst each other was the most profitable
thing to do rather than fight somebody else. And then the thing decayed. These are all
civilizational decay models. Joseph Tainter and the collapse of complex societies and
Baudrillard and simulation and simulacra and other people address how does civilization
decay, how do institutions decay, which is a super important topic. And sometimes they got
taken over by an external military. And so they had to keep the arms race of their military
capacities, right? Which also meant the total size of their population so they could lose
people in war, which also meant a sustainability issue for the environment.
Harvest more resources to support larger populations to win at wars of others that are
doing the same thing, or lose by default. With World War II, we get to the first place where we
have now a catastrophic weapon that's so big that if the major empires fight and use it,
it can destroy everything for everybody. That was never the case.
Absolutely sure destruction, yeah.
And so when you study history, like most of history is studying the way we're
commonly studied is the study of warfare between adjacent empires, right? The European history is
that the warring regions period of China is that you can study that. The Bhagavad Gita,
the central Hindu text is this warfare between brothers and cousins. And
so for the first time in the world with World War II, the major empires couldn't fight
kinetic wars. And there was never a time where they figured out how to not fight for a long time.
And so the answer to that was the Bretton Woods world, right? The Bretton Woods world came together
and said, okay, we can't fight wars. How do we make sure we don't war? Well,
national governments alone aren't enough to prevent war as World War I and World War II
showed us because the nations can optimize their own interest at the expense of each other.
So we can have now world wars, but our tech is so big that you can't really,
nobody wins these wars. So we need something beyond national governments. You need some
intergovernmental organizations. So we make the United Nations, the World Bank, the IMF,
all those types of agreements. And the idea was, let's do this thing called globalization,
where we have these supply chains where the computer that we're talking on was made in
six continents, right? No country could make the computer in terms of the mining of the raw
materials, the processing of them, the hardware development, the software development. And so
as a result, we all like the computer. So we don't want to bomb someone that's part of that supply
chain that we depend on. So let's do these complicated supply chains where we're so
economically interdependent on each other that we don't want to fight. And where we can grow the
whole world's economy so fast through this globalization thing that everybody can get ahead
without having to take each other's shit. If the game is positive some enough, we can all get ahead
without having to take each other's stuff worth. If it's not growing and I want to get ahead,
I got to take somebody else's stuff and now we're in rivalry. And so that was fundamentally the set
of ideas in the Bretton Woods world, fast forward 75 years. And you get to a point
where that rate of growth, it means extraction of unrenewable resources faster than they replenish
themselves from the earth and then turning them into waste, putting them back in the earth faster
than they can be processed, starts hitting planetary boundaries along lots of axes. You
have species extinction across the board. You have overfishing issues across the board.
You have not just climate change, but dead zones in the ocean from nitrogen runoff and peak phosphorus
and mining waste issues and all those types of things. You're like, okay, so we don't get to
keep doing exponential growth of the economy connected to an unsustainable linear materials
economy on a finite planet. And we're actually running right up against the boundaries of the
ability to keep doing that thing. And when the world is this interconnected, it's also very fragile
because something can break in one area and you get cascading breaks across the whole space.
We can have an issue in Wuhan and we can have breaks in the supply chain of food and fertilizer
and fundamental things across countries all across the world. So we're looking at now
fragility of the ecosystem and fragility of the techno sphere in the economy. And so we're like,
okay, now we need a new thing. So the world before World War II was one thing. After World
War II, it was this other thing, but that system is now ending. It can't continue that way because
it creates its own catastrophic risks and fragilities. So how do we do global cooperation?
All those previous empires that failed were local, so they could fail and it wasn't a failure of
everything. But since that meant that they produced the things they needed to live, now
no country produces the things that need to live, the global supply chains produce the whole thing.
So we have the first truly global civilization, but we don't know how to make civilizations that
don't fail. And so we have to do things we've never done in history. We have to figure out how
to deal with differences that don't involve war. We have to figure out how to deal with people's
desire to get ahead that doesn't involve exponential growth ongoingly. We have to
figure out how to make a civilization that can evolve and regenerate itself that doesn't self-collapse.
These are the unique challenges of this particular time.
And I think really the solution then goes back to where we were originally
talking about is the epistemic commons, where people are actually getting
real reasonable information that they can trust from good actors, or at least they have the
awareness to be able to sort through the melee that we're kind of getting fed right now and
actually wield power by collectively voting. And if we do trust the democratic process,
which has its own problems, but ultimately, if we are informed, we can presumably vote
people into office, which presumably can impose these changes that we need. But it all depends
on us actually seeing through the haze and the things that is just getting thicker and thicker
and thicker and preventing us from actually seeing anything reasonable and also creating this kind
