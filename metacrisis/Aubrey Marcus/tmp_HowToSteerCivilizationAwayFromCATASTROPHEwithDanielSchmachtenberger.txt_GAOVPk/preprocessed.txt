To the degree that you want something, is the degree you're afraid of not having.
God, I wish I started when I was younger.
I go, yeah, but you didn't.
So shut the fuck up and let's keep going.
Nobody changes until they change their energy.
When you change your energy, you change your life.
Because it's not till then that it's really real.
It's like, oh, this is way worse than I thought.
Oh yeah, it's way, way worse than you thought.
But luckily there's more to you than you think.
Yeah.
Daniel, how are you, my brother?
I'm good, my friend.
friend. And I said that I said that that way particularly because we were just commenting how
some people don't receive the warm welcome of my brother in the same way as other people. So I
wanted to really put extra emphasis on my brother just for the intro here. Start us off right.
I receive it and appreciate it. Absolutely, man. Well, there's a lot of amazing shit for
us to talk about. And, you know, one of the new things that you've you've gotten into is called
The Consilience Project. And it's just a really beautiful, you know, group of people. And I'll
let you describe, you know, the people you've brought together, what you're trying to do and the
problems you're trying to solve with this project. And then we'll get into the details of some of
the things that you're pointing to. Yeah, so start with just a brief overview of The Consilience
Project. Yeah, totally. Yeah, I will just clarify, it's not people I've brought together as kind of
group of people who had known each other, worked in related spaces and self assembled into this thing.
It's actually an important distinction. Come back to that more. But yeah, some of the people who's
thinking about world problems, I have learned the most from respect the most and have a
depth of actual care and commitment in addition to very nuanced understanding.
Maybe the easiest way to talk about it to begin with is
we can look at the history of our social institutions and social coordination systems
before we had formalized ideas of markets, global markets, say before Scottish Enlightenment,
go back, you know, feudalism before nation states, back to tribal cultures, early empires,
changes in the social systems by which lots of humans can coordinate effectively towards shared
purposes, humans who understand the world differently and want different things.
Those social systems had to make major evolutionary leaps as the underlying tooling basis, the techno
industrial basis of the societies did because it changed the nature of the types of things that
people were doing, how many of them could coordinate the division of labor and specialization and
the types of issues they had and like that. So you'd see step functions and tooling and then you'd
see correspondingly breakdown of the previous societies that couldn't handle those issues and
the new step functions and the social capacities. And obviously that had to also mean step functions
in the nature of education. How do we develop the people who can understand the whole knowledge
base that is needed to run the civilization? Because obviously in, you know, 100 years ago,
we didn't have to develop people that could run a internet and now you and I are speaking
mediated at the speed of light, mediated by satellites. There's a lot of human knowledge
that is needed to keep that system that we all depend upon running. So education
to be able to advance that civilizational knowledge has to evolve to do that thing.
If we look at the current problems that face the world, we look at the fact that
we had a movement from broadcast media where a few people could broadcast a message and everyone
else would get a relatively consistent message from the printing press on through radio and television
to with the internet, this kind of decentralized everybody can broadcast and then a complete
explosion of more content than anybody can take in. And then how does someone find the
result that they're looking for when there's a billion search results for anything? So you get
these major platforms that based on network dynamics end up being people's main interface with
the totality of the internet that is curating content specific to them. This is Facebook,
YouTube, Google. And so of course, people get customized worldviews that have nothing in common,
like a person in a red state and a person in a blue state, their newsfeed on Facebook might
have not a single thing in common. And yet they don't realize that the world that they're getting
exposed to is not actually the world. It is just a little fragment of it. And of course,
since Facebook is a company and it is making money by selling this person's attention through
advertising, it wants to optimize people's time on site. It optimizes their time on site by
having them spend as much time as possible through attention hijacking. And that happens
if I stay in a very conscious, self-aware place, I'll realize I don't want to spend that much
time on Facebook and get the fuck off and do something else. So the degree to which I get,
of course, distracted, engaged, limbically hijacked by fear, desire, in-group, out-group type
dynamics, I'm going to spend more time. So the AI that optimizes that newsfeed automatically
ends up driving individual bias, like confirming people's bias, because people spend more time
when their bias is getting confirmed than when they're being exposed to new stuff that disorients
them. And in-group, out-group type of identity, so we get more outrage, more kind of limbic
hijack, more bias confirmation. How do you run a democracy with that? Those are new issues. Nobody
ever faced those issues of a completely fragmenting worldview mediated by technological infrastructure
of that type that has more people than China and the US combined. No previous people had to deal
with the issue of weaponized drones that could take out infrastructure targets that anybody
could make on their own at home, or actually arms race on weaponized AI, or hitting planetary
boundaries regarding species extinction and dead zones and oceans and climate change and
a million other things. So when you look at how badly we are doing at solving those issues,
the fact that none of the sustainable development goals have been met, the fact that we can't do
nuclear disarmament despite how important it is. In fact, we get more countries that have nukes
rather than less, and we get new arms races. Every time there's a new technology, you get a
kind of inexorable arms race on it. We can't solve the tragedy of the common's issues,
and the issues are moving closer to catastrophic risk, eminent catastrophic risk, and it's like,
okay, maybe our problems are such that we need new problem-solving mechanisms. And it kind of
makes sense that the founding fathers, as smart as they were when they were coming up with a social
coordination system for the US at the time, they didn't have these problems. When they were
thinking of the Second Amendment, they weren't thinking of thermite weaponized drones, like
it's just a different thing in terms of catastrophe-level weapons that individuals,
non-state actors can have. Like, what are you doing with that? And they weren't thinking of a
satellite-based IoT surveillance state, and how do you deal with that kind of thing? So if you
try to apply that system, you'll find as brilliant as it was and adequate at the time, it also
categorically fails. And the same is true when the Scottish Enlightenment was doing theory of
markets. They didn't have these issues to deal with. So the biggest company possible, the asymmetry
between that and the individual was nothing like the asymmetry it is now, and limits of growth
planetarily weren't a thing. And a financial services sector that was running on AI high-speed
trading wasn't a thing. And the same was like Marx's critique of that, didn't have to deal with
this. And even the Bretton Woods world that says, oh, shit, we have to deal with the bomb,
that's a new thing, and so we can never have war again between the major countries,
the Bretton Woods world right after World War II didn't have to deal with these
complex of issues. And so fundamentally, what we were kind of recognizing in this is that the
problem-scape of the world currently has to be addressed for life to be able to continue,
because the risks are actually catastrophic and increasing in number and probability as time
goes on. And they are not being adequately solved through the types of approaches through either
business or individual governments or IGOs or nonprofits that just they're not being solved
adequately through those processes. And for the most part, our problem-solving processes either
don't solve the problems, or they solve a narrow problem and externalize harm somewhere else in
the process. And so the major problem that needs solved is that our problem-solving processes are
inadequate to the problems we face. So what are the new problem-solving processes? What are the
new coordination processes that civilization needs to have to be safe stewards of the level of power
that full globalization and exponential tech gives us? And so when you think about the Scottish
Enlightenment was good thinking on this idea of theory of markets and that thinking ended up
becoming the basis of new social systems. Marxist thinking became the basis of new social systems,
the Federalist Papers and the kind of thinking that on social issues in the early formation
of the American democracy gave rise to a social system. We're working on an analysis of the problems
that the world faces that is deep enough and detailed enough both in how the problems interconnect,
why they haven't been able to be successfully solved and what's generating them,
that it gives insight into what adequate problem-solving processes would look like as the
next phase of kind of social organization. And that if we don't want that social organization
to be imposed, some people get it and now we're going to impose by force this more enlightened
thing on everybody, which is itself a fail case. Impositional government, we would say,
is a fail case of a different kind. Then it has to be commensurate with the ideas of an open
society, even though it would be a more advanced type of open society, meaning that the government
derives its power from the, or the governance process derives its power from the consent of the
governed, that the people are actually, as Franklin said, the depository of the power.
Well, that means that the people have to understand the issues well enough and
want these new problem-solving mechanisms and be capable of participating with it.
Well, that is a kind of cultural enlightenment that requires people developing a lot of
capacities to make sense of the world and to have high-quality conversations with others and to have
effective problem-solving, which requires a change in value that would even have them invest in that
and in the development of new capacities. So what is the necessary current kind of cultural
enlightenment that could give rise to new problem-solving processes and institutions that could
solve the problem space that we're facing now and usher us into a high-tech digital global world
that works and doesn't drive catastrophic risk? Those are the things that we're exploring and
trying to help advance this project. Well, I think you've very eloquently described some of the
problems that we're facing, and we're going to certainly get into those and also the need for
this to happen, because what we're seeing right now is it's kind of this transition point. We're
in this interesting bardo where we're somewhere still riding on some constructs and systems that
used to work in the old times under different circumstances and situations and are starting
to fail and starting to collapse. And the way that everything is working now is somewhat urgent,
I think to say, and that might even be a euphemism. So let's start getting into this and start talking
about the potential solutions. And one of the things that you mentioned was the importance of
the epistemic commons. And the epistemic commons, epistemic, meaning pertaining to knowledge,
commons meaning available to everybody, the places where we are able to access knowledge
are now being, this is now, I think you refer to it as the hyper battlefield
right now of non-kinetic warfare. Everybody is using the commons as a way to manipulate people,
to actually change information. It's become something that no longer is trusted and for
good reason. So let's talk about that. Let's go into, first of all, the importance of the
epistemic commons. And then what is happening to the epistemic commons?
Yeah, there's actually quite a few things that you said there.
So when you were talking about the battlefield of non-kinetic warfare, just to clarify for some
people, if the term isn't obvious, kinetic warfare means bullets and bombs and physical warfare.
von Klausowitz said war is politics by other means. And so you can say that everything other than
kinetic warfare is politics, meaning it is a battle between the interests of various groups.
But you can also start to recognize that when those groups identify each other as rivals,
fundamentally, and we'll use whatever kind of capacity they have to make a win over their rival,
it's just non-kinetic warfare so that we can think of economic warfare when you're trying to
corner the market on the thing, you're trying to sanctions and whatever. You can think of
diplomatic and political warfare. You can think about narrative and information warfare. How do
we control the narrative so more people vote for our side or believe in our country and its
patriotic purpose or whatever it is or our religion in advance of holy war? It's not a new
thing. Narrative warfare is a very old thing. Sun Tzu talks about it, the 36 stratagems in
ancient Chinese military theory are basically all about it. But the modern age gives us
narrative warfare capacities via the web and social media that are really radically unheard of.
So we would actually say that the most fundamental warfare occurring is economic.
It's backed up by the possibility of kinetic warfare, but the front where most of the
activities happening is cultural war, narrative war, info war. If you control what people believe
is true, then they will think that they are self-governing and you believe what they,
you affect what they believe about what is meaningful. They will think that they are
freely self-governing towards a purpose that happens to be a purpose that other people
helps to engineer. Let me challenge something that you said real quick.
You said that the fundamental warfare that we're experiencing is economic warfare,
which to my mind, and just to clarify, that would mean like US versus
China in this kind of grappling with what the world economy is actually, where the balances
are shifted and scaled. To me, it seems like that would mean that there was a coherent
United States that was, I think there may actually be a coherent China, but that's
because they have a different regime. That would imply that there's a coherent United States that
actually cares about something other than their own political career. I'm not convinced that there is
any actual cohesion between the United States actually giving a shit about anything other than
individuals giving shit about themselves at the time that we're in right now.
Who is the actual actor in warfare is a very good question.
Is the US a coordinated and coherent monolithic actor, or are individual people in positions of
lobbying power, legislative power, political power, making decisions that largely have to do with CYA,
cover your ass kind of stuff for themselves and ladder climbing and bonus structures and whatever,
and kind of actually debasing the integrity of the commons, in this case, the country?
Are they making party wins that hurt the country as a whole? Even if it likes, let's increase the
narrative rhetoric about how bad the other party is so we make a win, even though we're driving
countrymen against each other so much, the country actually loses its coherence and ability to do
anything in the presence of other geopolitical powers rising very rapidly who don't have that issue.
So there's a school of libertarian thought called public choice theory that gives a very good critique
of the idea of representative democracy. And it's not offering a good solution, but we just have
to know the critique, which is the representative in a position of government is still an individual
economic actor themselves. And especially if they have term limits, they're going to get out
and do something else afterwards. And especially because the position of being a representative
that has limited economic return, but they're regulating industries that have huge economic
potential, and they're supposed to largely regulate in a way that decreases some of the
economic possibilities that would otherwise be predatory, right? No, you're not going to dump
that pollution there. You have to process it in a more expensive way or whatever it is. And so
kind of no matter what the representative does, half of everybody won't like them and almost
nobody will know what they really did when you have a system that becomes this opaque and complicated.
So whether they fuck the hole in virtue signal or really authentically serve the people, they'll
be kind of equally liked and disliked most of the time. And nobody will really be able to see the
accounting. And so how do you actually bind their interests to being a representative of the hole
rather than a representative of their own self interest so that they check the market rather
than the market capture the regulatory process that's supposed to check it? The fundamental idea
in liberal democracy is, okay, we're not going to try to have the state run everything the way that
a communist structure might. We're going to let the market run things because all the ideas of
why we like markets, it's a decentralized system and the supply and demand is kind of a collective
intelligence when there's more desire for something, the demand goes up, which creates a basis for
supply to occur emergently. And then the rational actors will choose the best product or service,
the best price, like all of that kind of market theory. So we'll let the market do that thing.
And it has less total imposition force than a state trying to do it. But we don't do laissez-faire
pure market with no state because there will be a market for really bad things. Like we can have
a market for organ harvesting and we can have a market for sex trade and whatever kinds of things.
And it could be profitable to cut down all the trees. And there's no national forest left or
kill all the fish or whatever it is. So a lot of law organized crime, whatever, right? A lot,
it wouldn't be crime. There would be enough no force checking it other than competing organized
crimes. So the idea... Well, I mean, you could presumably have law, but with radical economic
libertarianism, right? Like you can't hurt other people, the environment being the indirect way
to hurt other people. So I suppose if you are making a libertarian, I don't think you're saying that
there isn't an argument for a different type of libertarian belief in which you protect
the commons that are the earth, not the epistemic commons, but the actual logistical,
physical commons of our shared mother. And you also protect each other, but also leave everything
completely laissez-faire. And I'm not advocating that.
When you mention law, the topic of enforcement comes up. So who is the you that could do the
thing? And if the enforcement doesn't have asymmetric capacity to those who are violating it,
it breaks. So rule of law is based on the concept of a monopoly of violence.
And the military force and the police force are the idea of who is a safe
holder of a monopoly of violence to be able to institute rule of law. So here, I'm not saying
that it's accurate, but the kind of foundational idea, and it's accurate enough that it's worth
understanding, the foundational idea of why a liberal democracy is this kind, is the market
on its own. We'll do some things really well, but some predatory stuff. So you want something to
check it, but the thing that checks it has to be more powerful than it or it doesn't work.
But then the question is, what is checking it? And so in a market, let's say that we even started
out T equals zero, everybody has the exact same amount of money. It would never happen that way,
but let's pretend that we did. Pretty soon, you'd have a power law distribution of wealth,
just always ends up occurring that way, because some people get ahead better because of better
capacities, luck, whatever it is. And then those increased financial capacities make it easier
to make more money, make interest on interest, you gain interest on debt, you know, that kind of
thing. So this principle takes over and gets even more exacerbated. So when you get a power
law distribution of wealth, how do you have anything like representation or justice for
these people when these people can put everybody in their employment and like that? Well, the idea
is you need something even more powerful than the top of the market. And that's the state.
And so we're going to give it monopoly of violence, but it has to be representing the people as a
whole. So the commons, the collective, everybody is going to be. So this is why we want a government
of foreign by the people. And that the basis of law, which is the only thing that monopoly of
violence will back up is the collective ethics of the people, right? The values of the people
that get to come through some kind of discussion and voting process, turn into the basis
or the jurisprudence basis of law itself. The key thing is that the purpose of the state is to
check the predatory aspects of the market while leaving the healthy aspects of the market. But
that only works if the people check the state, right? And when you look at the structure of the
Constitution, it was largely around how do we make sure that the state doesn't become a runaway
thing and that the people actually check it while giving it enough power that it checks the otherwise
predatory aspects of market that would make feudalism again. Because if you don't have a state
and you have a power law distribution of wealth, you end up getting something like feudalism.
And so this is why George Washington famously said, I'm going to paraphrase, but the number one
aim of the federal government is the comprehensive education of every single citizen in the science
of government. And it's so huge, right, that that was the founding idea that he was saying that,
because he didn't say the number one aim is to institute rule of law. And he didn't say it's
to protect the borders, right, or monetary creation. Because if the number one aim is to
protect the borders, it can become a military dictatorship very effectively. If the number
one aim is to institute rule of law, it can become an oppressive dictatorship very easily, a police
state. The only way it stays a democracy of formed by the people is if the number one goal is the
comprehensive education of everyone in science of government was the term of art at the time.
What are the principles about how humans coordinate with each other that everyone would
need to know to intelligently participate in their own sovereign self-governance?
So they have to understand history and political theory and game theory and coordination theory
and all those kinds of things. Now you can see that most people don't have any sense in the U.S.
today that they are part of government at all. They will complain about government as if it's
something out there. But if you don't participate actively in your own governance, you are de facto
consenting to be ruled, right, by whoever it is that does show up to do that thing.
So this is where the epistemic commons comes in, right? That was a quote about that the number
one aim of the federal government has to be to support the integrity of the epistemic commons,
the process by which everyone comes to understand things. So specifically, education and the fourth
estate, the education by which people could learn how to think, could have enough basis in the
understanding of how economic motives work and how coordination works and those types of things.
Where they don't come up with dumb propositions that have already been tried and figured out
because they just didn't understand it, how a rule of law works. That education has to be
foundational. And the fourth estate is what is the information about what's happening today
that we're going to need to make choices on in an unbiased or biased, corrected way that the people
have both the current information and the ability to process the information so that they can
participate in deciding what are the right propositions and crafting propositions. Before
the lobbyists, the idea was that people would actually craft the proposition in a town hall
talking to each other, right? And so it's the education and the fourth estate are prerequisite
institutions for democracy torque or anything like a republic or an open society torque.
If those erode, then you could not possibly have people participating in collective effective
governance because they don't know how to think about the issues. We asked average people in the
U.S. today about almost any of the issues that government is having to govern on from a DOE policy
on microgrid stability for the electrical grid or nuclear first strike policy if an issue came
with another nuclear country or whatever. I never even thought about those fucking things.
We're too busy worrying about gay rights in some country where someone's arguing about it or
some other kind of red herring that is being thrown out that triggers some tribal or kind of
gut reaction response instead of talking about the actual real serious challenges that are being
faced. And that's certainly just one of the many aspects that you're mentioning is that the things
that we're debating are actually, in large case, a lot of things that are not the things that are
actually the boot that is with the soul on our throat. You know what I mean?
You mentioned, okay, so now we're going to come back to the economic warfare thing. And when you
say gay rights, gay rights as a subset of the different types of highly polarizing issues
and identity polarizing and any politic type issues are a great way to have a population
largely stay divided against each other and not notice the macro structures
that are most problematic, particularly things associated. Okay, I'm going to share a construction
here. A poor white person and a poor black person have more in common with the possibility space of
their life and either of them have in common with the billionaire. And they have differences,
like important differences and depending upon where they live more significant. So
and so one could start to say, well, all of our lives would get better if we had better economic,
like fundamentally, we had better access to resources. If our kids went to better schools,
we had better healthcare, these are economic issues, we're working two jobs or whatever it is
to barely pay for a crappy house, can't spend time with our kids so we can't parent well,
like these are economic issues. And then there are some people who at the top of the power law
distribution own almost all the wealth, that if that was differently allocated, it would create
a very different quality of life for everybody, the degree to which races continue to stay focused
against each other or LGBTQ against cis hetero, whatever, or partisanship left versus right is
the degree to which they don't recognize that they have some deeper commonalities that have
deeper structural drivers that if they that would require some kind of unity to actually address.
So that is a classic trap. That's a classic narrative warfare trap. What is it? And this
is not just by those in the top economic class within the within the country. Also,
if I'm another country that wants to not have the US be dominant for say real reasons,
because they're doing political geopolitical bullying or whatever, or because we actually
want to win the geopolitical great game of power, I'm not going to take the US on head on the biggest
military in the world, I'm not going to do an attack that doesn't have plausible deniability.
But if I can find existing fault lines in the system where people are sensitive to be turned
against each other, and I can just poke on that where the people turn against each other more,
how you turn the larger enemy against itself is a classic military strategy
for to for dealing with a larger opponent. So now fucking Facebook does it on its own
without even having that intention. It's not that Facebook has a conspiratorial intention
or political intention. It made the people who wanted QAnon stuff get more of that and the
people who wanted Antifa stuff get more of that based on the algorithm that was optimizing time on
site. And that algorithm, you mentioned you mentioned the strength of that algorithm. I
mean, you told a story where, you know, Gary Kasparov lost a deep blue, which is the chess
algorithm. And that beat a chess grandmaster, and he knew he was facing off against a computer.
Well, the algorithms that are running social media are more advanced than the algorithm that
beat Gary Kasparov. And we don't even really know that we're squaring up against him. I mean,
that's just a that just is a mind blowing example of what we're actually dealing with. And I think
the people there, they're just letting it run, you know, based on it's getting more attention,
more attention, because more ads serve more ads served equals more money. And it's just the
thing is just running and it's kind of running out of control at whatever cost by whatever means
necessary. So most people, their time on site doesn't get maximized by showing them
complex nuanced arguments. They bounce, right? They get to an article and there's a complex
nuanced argument, they bounce. If there's a click baity title, they're more likely to click on it.
So there is a actual incentive for salaciousness. And then if it's short enough, if it's put into
a soundbite or a tweet, right, that somebody can get a hit without hitting their increasingly low
attention span that wants it more dopaminergic hits per minute, then they are more likely to
engage in it. And really all they're doing is they're a memetic processing machine in that
moment that's saying, does this mean fit with or not fit with my existing meme complex? If not,
reject if so, accept and propagate. Because also the discomfort, there's an intense discomfort when
things disagree with those beliefs that we hold in our identity, that ego construct inside of us,
that is like basically getting a paper cut every time we see something that disagrees,
it's getting an ego paper cut every time we see anything that disagrees with something we believe
because we're so attached and we've assumed that as part of our identity. So we don't want that,
we don't want paper cuts, ah, but a nice little dopamine hit, a nice little, you know,
little bang of a bang of the neurochemical we love so much. We'll go for more of that. So
of course, you know, of course it works. You just mentioned, right? This is not
the highest angels of our nature. This is not the highest potential of being human. It's some of
the lowest, right? That wants to be right whether we are or not, that is uncomfortable with uncertainty
and wants artificial certainty, right? So is to feel secure. We can see through the history of the
world, people were willing to kill and die for religions where they were sure that God's name
was such and such, and most of those gods don't even exist anymore, like nobody really cares about
Thor or Apollo or whatever. And they were the kill and die over certainty for those types of things.
And so we can see how powerful certainty as a driver is, and we can see how historically
is a, it almost always looks wrong. And so does everybody else's certainty that isn't on our side.
And so those are things we want to overcome, not drive and make worse in the same way that
everybody has addictive tendencies, but to make a healthy society, you want to help people overcome
addictive tendencies, not push on them and make them worse. And yet, if I'm a business,
and I, let's say I have a fiduciary responsibility to my shareholders to maximize profit from a
public business, right? Then I maximize the value of my business by increasing the total
addressable market and increasing the lifetime value per customer. And I increase the total
addressable market by trying to make products or services that are relevant to everybody,
to increasingly more people. And I increase the lifetime value of a customer by having them
want to keep coming back to whatever the thing that I do is, and there's no way to do that
better than addiction. And so the supply side motive benefits from addiction. The society,
and this is where we understand that war makes GDP go up, right? Military spending makes GDP go up,
sick people spending a lot of money on medical care makes in pharma industry makes GDP go up.
GDP is a very, very bad indicator for well-being because total amount of money flowing through
an economy has a lot to do with things that are managing bad problems. So the problems
actually make it go up. But the demand side does not have the coordination that the supply side has
because you and me and all Google users aren't getting together and coordinating as effectively
as Google is with itself. So even though we're the same, like the total amount of attention
money flowing from demand into supply is the same in aggregate, the demand is disaggregated and the
supply is coordinated. So you have an asymmetric warfare. So then the supply side says, I can
manufacture demand. This was where Theory of Market started to break. This was one of the
key places where Theory of Market started to break because Theory of Market was people
want real shit that will improve the quality of their life. And they'll make rational decisions
between the various products or services available. So the fact that people want something,
they're willing to pay something for it creates an evolutionary niche for others to try to create
supply and the best product or service at the best price will win. Well, obviously all the
behavioral econ stuff that shows we don't make rational choices, particularly when we have the
ability to have emotionally manipulative advertising that's as effective as it is,
that hacks status desires. If I don't have that thing, I'm not part of the trend, the in-group
or whatever, that now gets to be AI optimized, split tested, AI optimized, that mostly is a
drive to satisfaction to then give them a hit that they got something. But also the supply
sides are to recognize, I can make people want shit, they never want it. And I can manufacture
demand. And so manufactured demand now broke the idea that the market is actually a collective
intelligent system of things that are actually meaningful to increase quality of people's lives.
And the best manufactured demand is addiction, of course. And the supply side has much more
ability to coordinate that motive. That's the AI and employment of it compared to the people who
don't even know that there's a rivalry scheme for their own attention happening.
And also there's the problem because, listen, I mean, we're having this conversation about
Facebook global and the challenges that it's actually perpetrating upon our society and
the ills of it. But I still have an Instagram account and I put a lot of beautiful ideas and
things and I reach a lot of people and I get dozens of message every day. Thank you, Aubrey,
for what you put out. This really means a lot to me. And so I'm in one level participating
because that is the place. This has now become the medium by which I can express ideas that are
helpful. So that becomes this cost-benefit analysis. I'm contributing to something that is
overall detrimental to the society. But if I don't contribute, then I lose my ability to share
my gift, which is actually contributing positively to society. So they have me in a bind and they
have many, many people in a bind in that way because of the they've just gotten so much momentum.
And there's really nothing that can compete with it.
That's so
when we developed antitrust law in the US and many countries, we're developing antitrust law to make
sure that and monopoly laws, there was a pre-digital world and we didn't have Metcalf network type
dynamics. And so those weren't factored into the way that we thought about it. Something only
became a monopoly. Typically, if they did some work to very actively in criminal ways, suppress
competition and then even get government support for how they did that thing.
But in network dynamics, where you have a Metcalf law type process, meaning that the value of the
network is proportional to the number of people on it. So as more people join, it becomes more
valuable. Then once you get above a certain escape velocity, it's more people are going to be joining
that thing relative to any other thing. Because as more people join it, it continues to become a
stronger attractor. And so you end up getting monopolies that are not a government monopoly,
the previous type, but it is a nothing else is going to emerge. You have a power law distribution
of within a domain, there's Amazon and then there's every other marketplace. There's Facebook and
then there's all the other kind of social media. There's YouTube and then there's all the other
video channels. You end up getting that kind of power law distribution within those verticals.
And so that is functionally a monopoly. It's a monopoly that is bigger than countries
have a very hard time trying to regulate something like that, because countries
move very slow relative to the speed of corporations, especially once the country
countries have decayed as much as ours have. And the corporations have the money to keep
paying for lobbying that is and lawyers that are very effective. And when it's this kind of thing
and affecting public opinion in a way that would be critical to the basis of changing law itself,
so it becomes obligate. Once it becomes large enough where if you choose not to participate
with it, you're really not participating in society, it became an obligate thing.
And so now we have to say, okay, that's very powerful. Is there a way that it is bound to the
good of society? Or is it just unchecked power? And what would check that power anytime a new
power comes? It's really powerful. We have to say, does it differentially serve some over others?
Is it tending to the good of the whole? If it isn't, how do we check it? And that's
a core question with all of the exponential technologies is they make rapidly more power
and much faster than any previous technology did that. And they are not being developed mostly
for kind of comprehensive commons integrity as their basis.
Right. And that's, I think, a key challenge here. Because of course, as we set up,
as the forefathers set up the government, they understood the absolute necessity of checks
and balances. And this is that thing that we've been talking about. But this is just a non-governmental
actor. And a lot of times people think of these corporations as a bunch of evil people plotting
to do bad things to the world. I really don't see that when you actually get in there. My little
brother works for Facebook. He's not trying to fuck the world. He's just trying to do these,
like recruiting different employees. And he likes the lunches that they serve. And he keeps inviting
me over there to campus to go grab a lunch with them. And it's like that, as you even go up,
even in pharmaceutical companies, there's, in some ways, I think there's this kind of
just plausible deniable. They just don't really want to look at what's happening. And they just
kind of look the other way. But it really seems like the organism of the corporation itself
is an entity. And if we really look at that as an entity, that entity has a primary objective.
The collective entity of a corporation has a primary objective. And it is to maximize profits
by whatever means necessary. That is the prerogative of the corporate entity.
So you have to have the people, then, who are the angels, who are willing to collectively within
that, be more powerful than the entity itself and move beyond their own profit motives, and even
to the self-destruction and annihilation of the entity itself when it gets too powerful.
And that's asking a lot from individuals who, to get to that level of power, typically are
running from some kind of trauma, dealing with some kind of validation complex, and, you know,
the desire for importance and love from the world, which they didn't get from their parents or
God or whatever other thing they needed. So they needed, in other external ways, chasing the hungry
ghost of all external validation in all different power games to try and get that. And so that's
what we end up seeing is we end up seeing these entities rise that when the entity itself can
be evil, but the people within it are probably, you know, they have some culpability, of course,
because they're not all rallying together to address the challenges. But it's a lot more
nuanced than I think a lot of people think. Most issues of evil are. Yeah. The fact that almost
all media that we can consume from cartoons on is usually a good guy versus bad guy in our culture
shows how deeply we're conditioning that set of memetic tropes. And most of the time, the who the
good guy is and who the bad guy is, is relatively cut and dry. We celebrate when the bad guy gets
it at the end and good guy makes it identify with. And this is good for socially conditioning the
mindset that will socially support war or something like that. But it's not good for actually
understanding how the world works where it's not that common that the bad guy thinks they're bad guy.
Extraordinarily rare. Yeah, I mean, I don't I don't even know. I mean, maybe some serial
killers, but like, it's so fucking rare, even the worst actors of our time still had some
justification that they were doing some good, even Thanos, look at the story of Thanos, right,
wipes out half of the population for the greater good of the universe was his rationalization.
I mean, obviously, he's a fictional character. But we know we see characters like that that
always seem to have some idea that they're doing some good for the world in some way,
where they they're doing good for someone, but they're in a forcing function. There's a
so having a conversation with somebody about geopolitics the other day, and they were talking
about Putin and somebody there had a lot of respect for Putin as a global strategist and
world leader and someone who kept Russia from being more degraded by external capitalist
forces after the wall came down. And some people thought he was a particularly evil guy. And I'm
like, well, if you're in his position, and NATO forces are trying to set up military bases right
on your border and running propaganda narrative campaigns against your people. And, you know,
on and on, do you do some what look like kind of evil things because you feel obligate that you
have to do that in order to protect the people you take Israel and the Golan Heights, it's like,
that seemed kind of fucked up that they took the Golan Heights, they don't have it, they have no
defensible airspace from people that are sending missiles to them. So you say, well, you shouldn't
have done that and you should just have no defensible airspace. So if there was one tribe
that started tribal warfare, the other tribes died by default, if they didn't get good enough
at tribal warfare to defend themselves. So as soon as anybody starts the game of power in that way,
it becomes an obligate game for everybody to play or they lose by default. And then this creates a
race to the bottom. And then this this defines the characteristic problems in the world that we
have to overcome. These are coordination failures. Both the arms race. Does anybody want to live in
a world filled with autonomous AI drone weapons? No, not good. I don't think really any generals
think that that's a nice world to live in. But is every country that can pursuing that? Absolutely.
Because if we don't and somebody else gets there first, they run the whole world.
And they either kill all our people around the world and we don't like their political
philosophy or whatever it is. So not only do we have to make them, we have to make them faster
than they make them and make the counter weapons and spy on their doing it and the light to their
spies. And so then so that's the arms race, right? And then we're like, well, what if we just made
an agreement that nobody makes the AI weapons? How about we come together and make a treaty?
How do I know that they're keeping the treaty? How do I know that in an underground black project,
they're not building it? And I'm keeping my side of the treaty and then they come out and take over
the world. Fuck it. I can't actually ensure that they aren't keeping the treaty.
And most likely, and most likely, we know that that's the way that governments work.
That's the way that we've always done it, right? This is the way, look at Game of Thrones, right?
It's like, yes, absolutely. We honor this treaty. But it's not the case. You look at history and
rarely have we seen that. We haven't evolved to a point where that is a reality where the noble
virtues of honoring your word in a good, healthy handshake really mean something. Never has been
at that kind of scale. So it's sensible to not trust that that's going to happen.
So the people who've paid attention and understand real politic are like, okay,
your treaty is a cute idea and we're going to build our AI weapons. And either we'll sign the treaty,
lie and say that we're keeping it, try to lie to your spies that are finding out if we are or not,
and spy on you to see if you're doing it or not. Or we won't even bother doing it, right?
Like those are the ways that it ends up going. And this is the same of like, why have we not
done nuclear deep proliferation? Who wants to be the chump that gives up their last nuke first?
Because what happens to them, they give up their last nuke first and then the other person's
effects on the deal. How do we know they gave up their last nuke and they aren't hiding one?
This, and so how do we know that the one that they aren't hiding isn't faster so they can win
at first strike because they were doing hypersonic missile stuff? Fuck, we have to actually keep
racing with a nuclear arms race to build faster and faster hypersonics to win the first strike game.
That's, we're stuck in that thing, right? Very largely the world's stuck in that thing. And it
has been historically, it's just, it wasn't until World War II that existential risk or catastrophic
risk for the whole world was a possibility because our tech wasn't big enough to be that damaging
to the world. It's important to give it for the history of the world existential risk to
civilizations always was a real thing. There is no more Roman Empire as it was or Egyptian Empire or
Aztec or Maya or like the thing that we understand about civilizations, if they have in common, is
they all have a lifespan and they fall. And so that was an existential risk, a collapse of civilization
for those people. And that always happened, but it was always local, right? And they happened for
reasons that are not that different than the ones we're looking at today. They overused the
environmental resources and stopped being able to feed the people adequately. Like that was a
very common thing that outstripping environmental resources is a many thousands of year old issue.
And or they got so big that they couldn't create coordination amongst all of the people. And then
they couldn't also protect all of their border space. And then they got overtaken by a smaller
rival or they got so powerful that infighting amongst each other was the most profitable
thing to do rather than fight somebody else. And then the thing decayed. These are all
civilizational decay models. Joseph Tainter and the collapse of complex societies and
Baudrillard and simulation and simulacra and other people address how does civilization
decay, how do institutions decay, which is a super important topic. And sometimes they got
taken over by an external military. And so they had to keep the arms race of their military
capacities, right? Which also meant the total size of their population so they could lose
people in war, which also meant a sustainability issue for the environment.
Harvest more resources to support larger populations to win at wars of others that are
doing the same thing, or lose by default. With World War II, we get to the first place where we
have now a catastrophic weapon that's so big that if the major empires fight and use it,
it can destroy everything for everybody. That was never the case.
Absolutely sure destruction, yeah.
And so when you study history, like most of history is studying the way we're
commonly studied is the study of warfare between adjacent empires, right? The European history is
that the warring regions period of China is that you can study that. The Bhagavad Gita,
the central Hindu text is this warfare between brothers and cousins. And
so for the first time in the world with World War II, the major empires couldn't fight
kinetic wars. And there was never a time where they figured out how to not fight for a long time.
And so the answer to that was the Bretton Woods world, right? The Bretton Woods world came together
and said, okay, we can't fight wars. How do we make sure we don't war? Well,
national governments alone aren't enough to prevent war as World War I and World War II
showed us because the nations can optimize their own interest at the expense of each other.
So we can have now world wars, but our tech is so big that you can't really,
nobody wins these wars. So we need something beyond national governments. You need some
intergovernmental organizations. So we make the United Nations, the World Bank, the IMF,
all those types of agreements. And the idea was, let's do this thing called globalization,
where we have these supply chains where the computer that we're talking on was made in
six continents, right? No country could make the computer in terms of the mining of the raw
materials, the processing of them, the hardware development, the software development. And so
as a result, we all like the computer. So we don't want to bomb someone that's part of that supply
chain that we depend on. So let's do these complicated supply chains where we're so
economically interdependent on each other that we don't want to fight. And where we can grow the
whole world's economy so fast through this globalization thing that everybody can get ahead
without having to take each other's shit. If the game is positive some enough, we can all get ahead
without having to take each other's stuff worth. If it's not growing and I want to get ahead,
I got to take somebody else's stuff and now we're in rivalry. And so that was fundamentally the set
of ideas in the Bretton Woods world, fast forward 75 years. And you get to a point
where that rate of growth, it means extraction of unrenewable resources faster than they replenish
themselves from the earth and then turning them into waste, putting them back in the earth faster
than they can be processed, starts hitting planetary boundaries along lots of axes. You
have species extinction across the board. You have overfishing issues across the board.
You have not just climate change, but dead zones in the ocean from nitrogen runoff and peak phosphorus
and mining waste issues and all those types of things. You're like, okay, so we don't get to
keep doing exponential growth of the economy connected to an unsustainable linear materials
economy on a finite planet. And we're actually running right up against the boundaries of the
ability to keep doing that thing. And when the world is this interconnected, it's also very fragile
because something can break in one area and you get cascading breaks across the whole space.
We can have an issue in Wuhan and we can have breaks in the supply chain of food and fertilizer
and fundamental things across countries all across the world. So we're looking at now
fragility of the ecosystem and fragility of the techno sphere in the economy. And so we're like,
okay, now we need a new thing. So the world before World War II was one thing. After World
War II, it was this other thing, but that system is now ending. It can't continue that way because
it creates its own catastrophic risks and fragilities. So how do we do global cooperation?
All those previous empires that failed were local, so they could fail and it wasn't a failure of
everything. But since that meant that they produced the things they needed to live, now
no country produces the things that need to live, the global supply chains produce the whole thing.
So we have the first truly global civilization, but we don't know how to make civilizations that
don't fail. And so we have to do things we've never done in history. We have to figure out how
to deal with differences that don't involve war. We have to figure out how to deal with people's
desire to get ahead that doesn't involve exponential growth ongoingly. We have to
figure out how to make a civilization that can evolve and regenerate itself that doesn't self-collapse.
These are the unique challenges of this particular time.
And I think really the solution then goes back to where we were originally
talking about is the epistemic commons, where people are actually getting
real reasonable information that they can trust from good actors, or at least they have the
awareness to be able to sort through the melee that we're kind of getting fed right now and
actually wield power by collectively voting. And if we do trust the democratic process,
which has its own problems, but ultimately, if we are informed, we can presumably vote
people into office, which presumably can impose these changes that we need. But it all depends
on us actually seeing through the haze and the things that is just getting thicker and thicker
and thicker and preventing us from actually seeing anything reasonable and also creating this kind
of political system, which is what I see now and what I feel is this kind of political nihilism,
because we have two parties who are pretending to be different, but they're so similar in everything
that they end up doing that the actual choices seem inconsequential. So it's like, fuck it.
It's an old libertarian trope, same shit, different piles. It doesn't really matter.
And of course, I respect that there are certain differences in certain things and whatever. And
some of those things are important, arguably. But for the most part, everybody's kind of doing
the same shit and it's not really helping either way as we go. So then it ends up being like,
all right, politics aren't the way, which is just, again, retreating to this political nihilism,
which is not going to work because then there's literally no solution.
So what you're talking about is actually cleaning up the epistemic commons,
the ability for us to access information and then reinvigorating faith
in a political system by making demands that politics actually work so that we actually care
about it. I mean, that to me, it seems like I don't see another solution here.
Yes. Yes. Say something divergent first and then come back. I was just smiling because I was
remembering a conversation I had with a friend the other day. And he said, you know, there's a big
chunk of Americans who kind of hold it, not consciously, but intuitively, that the founding
fathers and Moses went up the hill together and came down with the tablets and the Constitution was
on them. And it's this kind of like, they're treated like scripture, right, treated like
anything that you can do to change it is definitely making it worse, which shows both a good respect
for the wisdom of it, which was actually really important, shows how much the attempts to change
it have been in bad faith or at least ill-informed, but also doesn't acknowledge how fundamentally
different the world is today than then and how well formed they were at the time, given the
capacities and yet also simultaneously inadequate. And this is where one of the deepest dialectics,
when we think about left and right or the various ways political polarization occurs,
one of the dialectics, there's a lot of ways to talk about this, is traditionalism and progressivism.
And the traditional impulse says, let's conserve the conservative impulse. Let's conserve the old
institutional wisdom, insights, et cetera, that have worked for a long time because of something,
whether it was a religious system or a political system, if something got us here,
and most of the civilizations failed, most of the religions failed, most of the, there's some
evidence that that thing was affected, and maybe we don't even understand it as well as we think.
So we break it and it was doing something that we didn't know. So there's almost like an intuitive
sense of conserving the wisdom that is in that thing, right? And some people almost intuitively,
they wouldn't even frame it that way. They have that sense. And then there's a progressive intuition.
And the progressive intuition says, we're dealing with novel problems that we have not dealt with
before. And evolution moves forward, it doesn't move backwards, new adaptive capacities based on new
environments, opportunities, stimuli. So we need to actually rethink situations and come up with
new novel innovations and insights. Obviously, all of tech has that focus, right? We're coming up with
new and science has that focus. So can we apply the kind of the fact that the technosphere is
changing means we might need different ways of thinking about and governing it? And can we apply
that same kind of progressive insight that we're doing in science to our social systems? Those
need to not be in a fight. Those need to not be in a debate, but in a dialectic that says,
where do the previous systems and previous thinking have real wisdom that we have not,
if we haven't been good enough students of history, we don't understand as well as we think. So we
criticize it as irrelevant old dumb, whatever, because we didn't go through a war, we don't
actually know, we don't understand real politic from an embodied experience, because we live in
a rich abundant time, not the difficult time or whatever it is, right? So we break the thing down
and then we realize that we fucked ourselves because we didn't understand it well enough.
How do we make sure we understand it well enough that we conserve what should be conserved?
And then how do we understand both new possibilities that can make this better than could
have been made by the wisest people at the time, and new problems that need new things and create
new progressive insights that are fully logically consistent with the previous ones that are worth
conserving, right? How do we do that together? That dialectical process of, and there's a similar
one for individualism and collectivism, right? We don't want the individual advantaging themselves
in a way where they're ruining the commons and in rivalrous dynamics with other people. We also
don't want a way that prioritizing the commons ends up being oppressive for individuals. So how
do we make a situation where you have collective structures like systems of education and healthcare
and economic incentives that condition better lives for the people that are born into it,
but better not meaning just dependent on the system, better meaning more sovereign and self-directing?
And then how do you develop people that also have a civic virtue? So they in turn work to
improve the system. So you have a virtuous cycle of more individualism and more collectivism
simultaneously, you know, more benefit to the individual and more harmony between the people
and the commons. And so one of the key things, defining things in the kind of to get past
culture war, narrative war, is to take the values that different sides are speaking to and recognize
that there is some true value on both sides that doesn't have to be held as fundamentally
dichotomous, but actually is necessarily symbiotic, synergistic and say, how do we hold the true part
of both sides of that dialectic and seek something that is at the level of the synthesis?
Yeah. And this is not something that we're seeing happen in our political system to any degree. And
I think it's something that we ultimately have to demand, but it's not just the political system,
like you can look at this at another polarized topic, like vegetarianism versus, you know,
eating meat and even a carnivore diet, right? There's so much identity wrapped up in each camp
that there's virtues to both of these different, both of these different dietary styles, but people
are so entrenched in their own ideology that it's not a dialectic. It ultimately becomes
a heated and, you know, debate with all kinds of ad hominem attacks and all kinds of different
logical fallacies being used and obstruction and misinterpretation or interpretation to
advantage of all different kinds of data. And we end up getting in this place where
we have that kind of epistemic, you know, hubris on one hand, which is something you talked about,
where people are very overconfident about what they believe to be true because of the information
that they've seen. And then other people are like, well, fuck it, we have these experts who know more
than I ever will about these different topics, and they're all disagreeing. So I don't even know
what to care about. So then you retreat into nihilism. And then you end up in either one of
these two sides where you're confident and you're sure that you know everything because science said,
you know, or you're like, who knows, because science is saying this way or this way or science
is saying this way or this way. And this is the place that we find ourselves in in these key
important issues. Let's go back to your case of Thanos. Thanos was motivated, at least explicitly,
right? Maybe there's other implicit motivation, but explicitly by the desire to serve the
universe and life. With the utilitarian ethic that says I'm willing to cause the ends justify
the means I'm willing to cause some harm to prevent worse harms, it's a trolley problem
calculus, right? And he had a certainty that the universe was going to end and self terminate if he
didn't do that thing. So doing that thing was not only ethically okay, it was ethically obligate,
because the ethics of inaction for him guaranteed an outcome that was so much more horrible,
right? This is now a key thing of why utilitarian ethics can be dangerous. We of course need to
do utilitarian calculus of saying, well, not just does my action seem intrinsically right,
but what will the consequences be? Because, okay, don't ever lie. When the Nazis come to my house
and ask if I have any Jews there and I do, I lie, I say, no, I have no Jews here. In that moment,
the virtue ethic that says don't ever lie is less important than the utilitarian calculus of I would
rather lie to the Nazi in this situation than send these people to the slaughter. So utilitarian
calculus is necessary, but it's also not sufficient. It creates real problems in the main place it
creates problems is when we believe, pretend that we have more certainty than is actually
epistemically warranted about what's going to happen in the future. Then, and that's what Thanos
had, it was an excessive certainty that he had that the universe would be worse if he didn't do
that, that it made it ethically obligate for him to do that thing. So very often, we have some
argument of, okay, well, the future is definitely going to go this way if I don't act. And that
definite is actually unjustified. It's based on some simple rationale that seems unavoidable to
us. But how much is in the unknown, unknown set that is relevant that we don't know that we aren't
factoring is the place where we get, that's where the real critical thing is. So we can't predict
whether 10 days out with the very best supercomputing types of capabilities that we have, because
complex systems are complex, right? That's the thing to understand. And yet, when I'm so certain
that such and such is going to happen for civilization, that if I don't, whatever, then the
utilitarian calculus can make me do super unethical things, where contextually, they're actually the
only ethical thing. So this is where excessive certainty is extraordinarily dangerous. And you
notice that the holy wars were fought based on certainty, not uncertainty. People don't say,
I don't know the reality of God. It's an interesting question. I feel humbled by the awe of it. Let me
go slaughter some people. It's like, I know for certain. And so I'm willing to go kill and die
for that thing. So if we don't overcome the certainty bias, one, we don't learn very well,
because now you have confirmation bias that just seeks confirmation of the thing you already believe,
and it's actually only a depth of curiosity that makes you keep learning well. And two,
we actually become dangerous. And particularly so with increased power, exponential tech power.
The thing that should give us a good, healthy dose of understanding of the mystery, the factors
that we cannot factor in, which is really the argument that Charles Eisenstein makes in the
more beautiful world, our hearts know as possible, is it's an argument from his own spiritual gnosis,
gnosis with his knowing with the G. This felt sense of the state of inner being, the connection
that we have to capital S source, what you can call God, but God has a lot of connotations to it.
But it's a felt thing for many of us who've gone through different plant medicine journeys and
experiences, this understanding that the universe, the earth itself is alive and that there is a
binding and common force and a wisdom and this felt sense of love being the currency that is
underpinning everything else. That there's a reason why that's been called the mystery,
capital M mystery, because we can't fathom it, but we can tap into it and we can feel it.
And so to assume that we can understand what's going to happen with that in play, and this is
something we talked briefly about before, you know, the Dow, whatever you want to call it,
that is ultimately the mystery to pretend that we know that thing. It's incomprehensible. It is
the ineffable. So there's a certain humility that we all have to have saying, we actually don't
understand more than we do understand. And you can look at it, even if you want to take it out of
the spiritual contest, look at the bleeding edge of quantum physics and our understanding of what's
happening at the subatomic level and the laws of the universe, which are continually evolving.
We should have just a tempered epistemological humility, epistemic humility, which is really
one of the solutions you're pointing to. But when you really understand that, that there are the
ineffable factors, it only makes really a lot of sense.
Okay, so this is, this is a topic that's on my mind most of the time. We're wanting to encourage
and we're wanting to develop a culture where people do much better sense making,
using rigorous processes while understanding the upper bounds of their own sense making.
And that the upper bounds don't give the kind of absolute certainty that
before certain kinds of development where people can be emotionally oriented to want.
So, you know, you and I were talking about this previously, the first verse of the Tao Te Ching,
this always was so meaningful to me that, so loud, so whoever that was going to write a book
of wisdom. And the very first thing in a book of words was the Tao that is nameable is not the
eternal Tao, the knowledge that is knowable is not the eternal knowledge. And the naming
is the creation of the 10,000 things and the 10,000 things will obscure you from understanding
the Tao. So it's like, okay, here's a book about the Tao and you can't do it in words. If you do
it in words, it's not the thing. But then finishes the book, right? That's the key insight was it
wasn't just the first verse and then nothing else is then the rest of the book, which is saying
the words are pointing to something beyond what can be captured in them and see if you can notice
what that is. And so it's like, okay, is that just kind of superstitious mumbo jumbo or what is
what does that really mean? So you're mentioning quantum mechanics. So Heisenberg's uncertainty
principle says, we can't know the position and momentum of a quantum particle simultaneously
in full, the more you know about the position, the less you know about the momentum and vice
versa. That's an upper bound on the knowable itself. Right? It's saying that there is a rigorously
unknowable that is at the foundation of all of reality, that there is an upper bound to know
ability that is fucking fundamental. That's important. Then you go to girdle's theorem in
mathematics. And girdle's theorem showed that for any arithmetic set, because David Hilbert
was trying to make this process of a complete set of mathematics, a fundamental set of math,
a standard model from which all math can be derived. And in the process, Girdle did a proof
that showed that that could never happen. And one of the most significant things that ever
happened in math, because it was again, an upper bound on know ability said for any arithmetic
set, I have a finite set of propositions in it. There is some other proposition that is true with
that, meaning logically consistent, that can't be derived from a combination of those things,
meaning that there is no finite set that will propagate the entire set, meaning if the system
is to be consistent, it can never be complete. And so I can just like position and momentum,
I can get consistency, but not completeness. So I'm bound to incompleteness, that's why it's
called girdle's incompleteness theorem. And that's a huge deal. Then Tarski's theorem was a
generalization of that from arithmetic to all formal logical systems. The axioms in the
formal logical system can't be proven within the formal logical system, they have to be taken. So
the system can show its own validity, but it can't do soundness. There's something outside of the
system necessary to say, does that validity map to what is outside of it? So these are all upper
bounds on noability itself. And so another way of saying it is, you take it, you know,
all of the study of human medicine before the genome, you're like, wow, there was some really
critical show we didn't even know existed, then we get the genome, but we don't have the epigenome,
we don't have the transcriptome, we don't understand the proteome, we don't understand
the exosome, the whatever. So then there's a new thing, we're like, wow, this thing is kind of
everything. The history of the epistemic hubris is not paying attention enough to how much
whole new fields emerge that we didn't know we didn't know before, they were in the unknown,
unknown set that answer huge amounts of stuff, right? So can I prove that there's nothing that's
in the unknown, unknown set that is relevant to the topic that I'm looking at? So what that means
is I'm studying a thing, I'm studying a body or a cell or a plant or a market or whatever it is.
And I try to model it through some small number of variables I can make sense of, there's this
thing called supply and demand and rational choices and whatever. So or there's a thing called mitochondria
and ATP and NAD, I'm going to try and model the thing, right? Using what I know of it. And I don't
know how tiny a subset that is of what's actually happening. I can't even know how tiny the subset
is of the things that are happening. So my model of reality, and this is what science is doing,
and it's helpful, right? It allows us to build tech and the fact that tech works is very interesting.
But the model of the thing is not actually the thing, right? This is the map is not the territory
thing. And so if I have a thing, I make a model of it. Now the map of the thing is the thing for
tech, for physical tech that we made, right? And that's the difference between complicated systems
that we build that don't self organize and don't evolve and don't replicate versus complex systems
that do self organize, self correct. There's a fundamental difference in the nature of those
systems. But when we're trying to understand complex systems, which is psychology, biology,
sociology, ecology, the foundational things, the model of it isn't the thing. So when I then
optimize for the model, wherever the model's wrong, wherever it's missing something is where
that thing that I'm optimizing can externalize harm. So I find a specific way that a disease is
acting, I find a specific molecular target, I create a drug for that molecular target, that model,
and it works, and it stops that symptomology or that aspect of pathogenesis. It causes side
effects somewhere else that I didn't know, and couldn't have really predicted ahead of time.
And maybe doesn't address some things that are upstream from that molecular target that
were why that thing was happening in the first place. And so is that useless? No. Is it anything
close to knowledge with a capital N or capital K? No, of course not, right? So I might be reading
into this, I have no idea if this is how it was originally intended or it's just a nice way to
interpret it. But the whole idea of no graven images, no false idols, the way I think of that
is that the model of reality is an idol. If I take it to be reality, and that's the too much
certainty in the believable thing, the doubt that is knowable is the model, that I can fully
explicate, that has no more mystery in it of the unknowable set of possibilities. So the model's
useful. We're not saying we shouldn't be doing science, of course we should. The model's useful.
And Newtonian gravity, as useful as it was, got massively updated with
Einsteinian gravity and quantum gravity, and then that will get updated. So we want to hold it as
useful and not capital T true, which means what we stay actually our reverence is about reality,
which is beyond knowable. I can keep knowing parts, but I can keep doing that indefinitely.
And so there's a reverence for reality that means none of my models or beliefs should ever
be sacred to me. The sacred is fundamentally unknowable, unexplainable. I can kind of point
to it through poetry, which is what Lao Tzu was doing. And so then I'm like, it's beautiful that
we were able to come up with a model that's as predictive as it is, and let's use this. And
let's not get certain about it. Let's not even seek certainty around that. Let's have mathematical
certainty that we can actually make a plane that will work or whatever. But let's keep seeking to
understand reality in deeper ways and have a certain epistemic humility bound to that. That's
critical. And this is why the very best scientists had this. This is why Einstein said the things
about, I want to know God's thoughts, the rest is trivia and the value of intuition and imagination,
and why I think it was a sillard who was saying, of all the founders of modern physics,
John Yvonne Neumann was the smartest in terms of clock speed, but Einstein had the deepest
insights. And what was Einstein doing that wasn't clock speed that had the deepest insights? It was
something connected to when he would puff his pipe and look at the clouds and go blank and then
come back to the whiteboard or play his violin and be raptured, that had to do with not just
a processing of parts, but a sensing of wholeness. And there's a way that most people do one or the
other of those things. They orient either to say on this side something like a monastic process or
art, or on this side something like science, technology, engineering. I would say the full
human experience is the way those relate to each other. The way we can seek better formal
understanding, because let's say we're going to make a decision about the electrical grid. I want
to actually use science to understand very formally what the risks are and how to build
the thing and the materials and all like that. I also want to understand that there might be
risks that are not being factored on our current risk assessment. So I want an elastic possibility
to update this with the input of new information. So how do I say this is the best of what we know?
Let's move forward with it and how do we keep not just, we don't want to resist new information. We
want to be actively seeking how we're wrong. It seems to me that what's emerging. So let's
talk about briefly here before we talk about where this is kind of leading. But you discuss
hyperobjects. Hyperobjects are these constructs which are so complicated that they're actually
truly unknowable, because there's too many factors for us to actually sort out. The
ultimate of the hyperobjects is a human being, because particularly we're part material and
reductionist and we can talk about our different cells. But even though cells are made of atoms,
which we can't fully even grasp with our own quantum mechanics. And so we're also this other
thing, this felt sense of this other thing, the capital M mystery thing. And so we end up with
the hyperobject of a human being as a very fundamentally challenging thing to grapple with
at the very base level. So it seems that we have to, as you were somewhat suggesting, bring in
this healthy respect for awe, for rapture, for the mystery, for a lot of what Jamie Weill has been
talking about, like finding the divine within the entheogen, the etymology of that awakening,
that sense, that knowing of what we have, and then combining that with science to figure out what
we're doing our best. But it seems like the thing that's the check and balance, the bounds,
the checks on whatever we're doing, it has to reduce to something else, like Eisenstein's sense
of inner being, this feeling that we are all interconnected, or the highest ideal of truth
and love, right? Like these things that perhaps have to be the ultimate or maybe are the only
checks and balances. So when somebody is doing something that is out of a cord with the fundamental
principle of inner being, which is the belief that everybody is you living a different life,
the earth is actually not separate from you, but a part of you. And we can actually look at that by
everything that we consume from the earth becomes us, we can look at it atomically, we can look at
it in a variety of different ways. We have to bring that understanding and blend it in a very
kind of sensible way with what we can know from science. But that's not, as you said, it's not
happening. It's being siloed. There's people who are exploring these other kind of spiritual aspects
of things. And then there's the scientists that are sorting these things out and asserting that
they have full knowledge of everything in there. And then there's the middle actors, the politicians
who are claiming that they know everything about COVID, for example. And maybe they even feel
justified about claiming the dangers of these certain things because they don't really know.
And if they say they don't know, they're worried about what people do. So they have this kind of
Thanos justification. And what we better say it's as bad as we can possibly say because we need
people to act in a certain way because that will actually save lives rather than being bound by
truth, by love, by this sense of mystery, of the unknowing and really trusting that those principles
will actually somehow, some miraculous way those principles will hold. But without those
checks and balances, it seems like there are no checks and balances.
So I'll translate what you're saying to another way of speaking about it is asking,
are there different methods of knowing that are relevant for different types of contexts?
Science is a method of knowing things, right? It's a methodology. So epistemology means,
how do we know what we know? What is our process of coming to understanding or belief or knowing?
And so science is really an epistemic process of how do we do observation, do measurements, do
testing and prediction, etc. Science per se pertains to the domain of things that we can measure
first, which means third person, objective things, and where we can repeat the measurements.
Are there some things that are real where I might get a measure, but I can't repeat it? Sure.
Are there some things that are real that I can't even measure, either because they're outside of
either because they're outside of the scope of current measureability or because they're not
measurable in kind, like a first person experience. Oh, well, I can measure a first person experience
by measuring brain states. No, measuring a brain state as a neural correlate of a first person
experience is not the nature of the first person experience. This is the, no matter how much I
know about the genetics and evolutionary history and chemistry of a strawberry. If I've never tasted,
I still don't want to fucking strawberry taste like the taste of a strawberry.
Sure. A five MEO can create a one Hertz delta brainwave state, but it doesn't mean that you
have any idea what it's like to be in the experience of a five MEO journey, right?
Neuroscientists studying the brainwaves of people on five MEO or 40 years and meditators
and saying, okay, I know more about their brain states than they do. It's true.
Do you know how to navigate into those experiences or even have a sense of what they're like? Not
at all. So what that means is, but are they real? Yes, they're real, but they're not objective.
So subjective is not fake. An objective is real. Objective is a subset of the real. Subjective
is a subset of the real. Now we get in trouble when we take a subjective experience and try to
make an objective proposition about it, right? So I have an experience, whatever it is, the
experience is an angel spoke to me or something about. Now, if I make an objective proposition,
angels are definitely ontologically real. They live in this thing called the astral plane,
they whatever it is, I'm making a jump from a domain of experience to a domain of statement
about objective reality without doing the appropriate check to see does that hold. If that
was true, what beyond my experience would also be true, they can be appropriate validation.
So what I can say is, it is real that I had an experience of this type and that it was
meaningful for me in these ways, right? And so this is where it's like, there are different
domains. Mathematics doesn't involve measurement. It involves just pure principles of order. So
math isn't science. That's a whole other domain of epistemology of just pure principles of order
and relationality, right? So there's a reason I'm bringing this up.
Everyone does rationality, but they don't hold to it well, you have to train it, right? The
early Greek thing of saying, well, if I at arm's length, close one eye and hold my thumb up like
this to the moon, my thumb obscures the moon, therefore the moon is smaller than my thumb.
That's a rational argument that's wrong, because it's not factoring the change in visual
perception of size based on depth, depth perception, right, farness away. And so we can
do rational constructions that are wrong. So basically critical thinking in science is the
study of how to do rationality well. And we have whole university programs and how to do
rationality well, because almost everyone is rational wrongly most of the time, right?
And there's a similar thing for intuition. Most people do intuition wrongly and there is
a process to refine it, but we don't actually have good school processes for how to do that as
much. So most people will say they'll have an experience and then they'll make a claim about
objective reality. That's a problem, right? And their desire for certainty is still getting
booted. In that moment, they might have been in a trans-egoic state, but then their ego tries to
capture it and say, no, I can say this for sure about the nature of God or what happens after
we die or whatever. Probably not. Like you don't actually have the base for that. You're moving
from something that was an experience beyond belief to trying to make a belief about it.
Don't do that. That's not the thing to do. That's what the knowledge that is knowable is not the
eternal knowledge is referencing. That there is a domain that isn't about believing, right?
It's about a nature of an experience that creates a sense of devotion that will affect the nature
of how I act, including the nature of how much I want to pay attention and study so that I can
act better. But when I convert it into belief, I have to be careful. Did I do that properly or did
I go sloppy? I can give an example of how this happens in this where you have this kind of spiritual
epistemic hubris, right? And I've seen it in ayahuasca ceremonies. Somebody has, and ayahuasca
gives you unbelievable access to what feels like gnosis with a gs, a felt sense of things,
but it will also give you images. And then these images will then play out a story. And I've had,
you know, you always have a sharing circle and you'll have people who will share something and
they'll share something. And often this happened recently sharing something about me. Oh, I appeared
to them as this bunny and this bunny said this thing. And they were certain that I was actually
the bunny actually saying this thing. Whereas with the humility, it would have been like,
there was this thing like a dream, for example, you know, like not, it's not imagining that
this dream was a real dream. But what does this say about potentially about something that is
actually real, but potentially about me, maybe this was about me needing to see you as a bunny.
So I felt more comfortable with my own relational nature to you. And so there's so much that you
have to look at that you have to approach these things as the mystery. And I think this is the
problem when anybody gets into, you know, channeled text or this kind of idea of reading someone
psychically, or you can even on the spiritual side, let alone on the materialistic scientific side,
you can arrive at certainty from your own subjective experience, which is also, you know,
challenging. And I talked about that with Eric Davis as well, like, you also have to just have
great respect for even the most transcendent truth that you arrive at, just this kind of
humility of like, maybe, maybe, and this was interesting. And, you know, let's, let's sit
with this, let's feel it until it feels, you know, until it feel and see how it feels and see what
it reveals over time. Yeah, if like this actually interesting that the essence of the scientific
impulse, the high essence of the scientific impulse is a reverence for reality.
There's actually a kind of felt reverence where it's like, I want to come to study and know what
is including if it's different than what I think, I'm totally happy to have the experiment prove me
wrong, because I respect what is more than I respect my own wrong ideas about it. And there's a depth
of curiosity and desire to know an epistemic drive that arises out of a certain like respect and
reverence for reality. It's fucking beautiful. Is that held all the time? Because I can also have
an unhealthy spirit of science, which is I want to be maximally certain of all the things I possibly
can so that my emotionally negative relationship with uncertainty can be crowded out. So I want to
just have all the facts that I can and feel like I have good answers for everything
so that I feel secure. Those are very different spirits, very different like come from of the
thing. And so if I have a respect and a reverence for reality, and I study history a little bit,
and I look at how many things the best thinkers in the world historically got wrong, got right,
but then also wrong or partial and then couldn't have possibly figured how it was going to be
advanced beyond them. There's a humility I'm bound to, to not just be ridiculous, right? Like I
would be ridiculous otherwise. And then I also get that everyone else that is perceiving reality,
there is some signal on what they're perceiving. There's some reality. So my respect for reality
also means my interest in the way other people see it. Now this becomes the basis of politics.
When you were talking about politics earlier, polis of the people, right? Do we have to do politics?
Yes, we have to say how do these Homo sapiens that don't have stone tools, that have
the ability to split atoms and create nuclear weapons, that have the ability to create artificial
intelligence, have the ability to go into space? How do these ape creatures with the power of gods
coordinate with each other in a way that doesn't just do the ape creature thing with that much
power? Because if I have the power of gods and I don't have some kind of commensurate wisdom
and virtue guiding it, then we self-destruct. And so what is the wisdom and virtue that is
adequate to guide the amount of power that our tech has given us is like a defining question.
And so one of the key insights is that in all the wars, let's say that it's a physical war,
if I don't kill the other side completely, we win a battle, they're still in the world.
They don't go away. They learn whatever weapon that we used or whatever military strategy they
make their own innovations and then they come back. And that's the escalation of war. That's an
arms race of some kind. But the same is true in a political war. We work real hard to beat them. So
for four years, our guy gets in and we made an innovation of how to get more people out to vote
or how to do a more compelling piece of media that scared people and chained them into voting,
whatever the fuck it was. We figured out how to use a better AI system to make customized versions
of our message for demographics that aren't voting. Well, the other side that loses don't stop
existing as people and they don't agree with you. They actually feel more disenfranchised,
more upset against you. They reverse engineer that innovation, add innovations and come back
and the whole field of warfare just escalates. Same in culture wars, any view of left, right,
whatever kind of thing. And with the Industrial Revolution, this very long exponential curve
of us developing the power of God's through tech, right, through abstraction, tech and coordination
that other animals didn't have that makes us not an apex predator because apex predators are fit to
a single environment and then kind of built in harmony. They eat a little bit too many of the
prey and then the prayer fast enough and their population goes down. We were able to become
the apex predator in every environment and over hunt every single environment, right? And then
continue to do that thing. Well, I mean, I think ultimately, ultimately, what we're leading back
to is the necessity for the, you know, the necessity for this, this other, this other way of,
this other way of knowing this other way of, of a check and balance that, that we have to,
we have to have in place that seems to be something beyond, something beyond technology.
The love and wisdom or the virtue and wisdom of God's power. Okay. So, so basically the moment
we started getting the abstraction capacities that gave us tools, language, et cetera, we were
differentiated from the rest of animals in a fundamental way. And there was an exponential
curve of our differentiation that started, but it was long and slow for a long time,
like exponential curves are, and it started to uptake kind of with the Industrial Revolution,
and then it started to verticalize with the digital revolution and the exponential tech
that digital makes possible. So what that means is the speed and the consequentiality
of the types of issues we've had for forever, the problems of both warfare,
meaning cause direct harm with our power and externality, indirect harm caused by our capabilities,
is now on the verticalizing part of the exponential curve. And so can we run exponential
externalities in a finite biosphere? No. Can you do exponential warfare? Can you do exponential
control of what different populations think, meaning exponential disinformation and still
have enough coherence or consistency for anything like a viable civilization? No. So we are at this
unique point where the total magnitude of power makes the way that we've been behaving that's
been problematic for a long time inexorably catastrophically problematic. But those same
types of capacities, that same abstraction and technology makes possible if we repurpose how
we're using it, something like a new type of viable global civilization that has never been
possible before. The ability to process, I mean, obviously, we're having a conversation mediated
by computers and satellites and the internet that then lots of other people are watching that allows
for something that couldn't have happened previously, right? If we want to make decisions
regarding the biosphere and the technosphere and very complex things, you have to be able to
coordinate the sense-making intelligence of lots of people. That same tech that being used for
narrow rival risk purposes, driving externalities, destroy stuff, if we took those externalities
and kept internalizing them and saying, let's take all the things that matter and apply the
tech towards that progressively better, make a very different set of possibilities.
Yeah. One thing that you bring up, which is I think really important, is in the world where we
cannot escape the mystery and that we must adopt this felt sense of humility, oppression of
contrary opinions is absolutely a problem because you cannot be certain that you're
right about anything. When you start to censor or oppress through any different type of cancel
culture, force, removal, de-platforming, etc., even though your justification might be, well,
from a utilitarian standpoint, this might be causing harm. The fact that you can't be
certain about whether you're right, especially when you're dealing with a hyper-object like
the interaction of a virus, which we know very little about with the most complex organism,
you could argue on the entire planet, which is a human being, which is in itself a hyper-object,
the unknowable. You can't start censoring people, de-platforming them because you think you're
doing the right thing. It fundamentally degrades the whole thing. This is one of the deep challenges
of this hubris, this certainty that you're right. We need this chorus of voices in discourse
to try and outsource this problem to as many different perspectives as possible and then
start to wade through it, get them in healthy discussions. As I was leading up to this, I was
thinking like, fuck man, the art of debate, really honest debate where you give each other a hug at
the end and thank them for bringing the ideas, that idea between these different polemic sides.
This is something that needs to come back and it needs to come back in the public form and be
encouraged. Like, great, wow, this is an interesting, contrary opinion that you have, Dr. Thomas Cowan.
Like, let's have you talk to someone who's the leading expert in germ theory and let's talk about
your terrain theory and let's just discuss this. Let's encourage this type of thing. It seems like
that's what's necessary to move forward and start to sort out all of these immense problems.
Unfortunately, it's not what's happening. It's opposite of what's happening right now in many
ways. What we're seeing is just the use of force. We're seeing power games being played out,
which I think they're grounded in this hubris, but ultimately this is, and I think it's a big
part of what your conciliance project is, is to make transparent these things that are happening
so that we can get to the point where everybody's just starting to talk to each other and collectively
we're starting to figure shit out together. This is actually really tricky and nuanced.
Most people really don't like the idea of censorship of speech and de-platforming when it
comes to ideas that they resonate with. But most of the people, let's say we take someone who has a
politically right perspective that doesn't like the de-platforming impulse of cancel culture,
they might still feel really happy to censor Chinese sock puppets that are sowing propaganda in
the U.S. and they're like, we have to fucking stop that because people don't have the epistemic
training to be able to know what is a sock puppet and what isn't. And they're influencing teenagers
who are on here who are already upset and suicidal or whatever the fuck it is, right? And they're
using AI tools to be able to do it. They're using amplification in a way when we talked about freedom
of speech, the most people that you could talk to was like the people that could hear you speak
when you were standing somewhere. And so do we want to censor Russian propaganda in our media
space? Do we want to? So most people think that there are certain actors that don't have the
interest of whatever the in-group we're paying attention to is that could share information
that is false but with a higher degree of game-theoretic capacity than the general public has
that could beat them and they're like, no, we actually have to deal with that. So it's tricky,
right? There's a nuanced argument here. And because there's a nuanced argument,
it's the kind of thing that you need the right kind of conversation around. What does
when we talk about free speech, a right, what is the responsibility that's associated with a right?
And what does that look like in the digital amplification age? And then when the AI
optimization algorithms take whatever the stickiest shit is and optimize it for people who've already
been trained for a whole life of addictive susceptibility who will then go act on that
consequentially, I can put out something that is almost tailor engineered to fuck people up
psychologically and it will work across the say I kind of think is that a good thing? Should we
just allow all of that? Well, then no, we'll stop that. Well, who is the we that we trust to adjudicate
what is true? Because any power that can adjudicate what is true if captured would be the most
powerfully bad books. So this is why this is tricky, right? And this is why we have to rethink,
okay, in the digital AI empowered, etc. world, we have to rethink some of these things.
So what are fundamentals rights and responsibilities being paired as an important concept?
If I have a right and no responsibility that's associated, you get certain kinds of entitlement
and tragedy of the commons issues. No one is responsible to mediate that, which is well,
who gives you the right? Where the fuck does the right come from? Who's tending to and moderating
that if I'm not willing to take any responsibility for? In democracies, we can vote ourselves rights
that we're not willing to take responsibility for and the things start to decay. So, okay, if I have
responsibilities and I don't have rights that are attached at some kind of servitude, so there's a way
that those have to be held together, right? And different cultures could do it differently, but
just like there's a dialectic between traditionalism and progressivism, a dialectic between individualism
and collectivism, there's a dialectic between rights and responsibilities that has to be thought
about well. And you can fall off on either side of that thing real easy. Now, just like there's
epistemic hubris, there's moral hubris, right? I'm so certain that my moral position is right
that I'll fight a holy war over it. And there are modern online versions of holy wars
associated with new ideologies that are kind of like, that have religious like elements,
belief, in-group, et cetera, proselytizing. So, there is a need for both, and this is
so interesting. You were mentioning earlier epistemic hubris and epistemic nihilism.
There's this very sad phenomena where a lot of people go from epistemic hubris where like,
they have a not well-considered position on something. They think it's well-considered
because they watch 10 YouTube videos. And they have no idea how much it they don't actually
know about it. So, there's a Dunning crew. And this person is actually literally wearing a shirt
right now that says, because science, period. Like, I've actually seen that shirt, because
science, period, where they're so certain that the science that whatever they're talking about
is so right that they're just proclaiming it. Well, it can go both sides, right? There's a
because science and then there's also a because religion and because Q said so.
Of course. Of course.
What is the thing that I think gives me the certainty and authority that I can defer to
in this way? And things are complex. I want certainty. I don't want to do the hard work.
So, I want to cognitively offload somewhere. Well, that's then very useful for anyone who
wants power because they're like, oh, these people want to cognitively offload. I'll tell
them what's true. And now you have a power game for being able to share versions of truth that
have economic and political advantage to somebody. So, this question of a trusted institution,
well, what would be the basis of warranted trust? How do I know if I can trust this fucking thing?
So, what is the oversight process and what are the capacities that people have to have to oversight
it properly? Can I oversight something where I don't understand the technical details of it?
These are good and important questions and things that we have to develop because we do
need to develop a certain capacity for shared sense making if we're going to do shared choice
making. And if we don't do shared choice making, then we're fucked. Then China will do shared
choice making because it just says everyone will sense make the same way because of dictate.
And Sesame Credit will ensure they don't do anything else. And a IoT surveillance system
will make sure they don't, because of anyone else, they don't think anything else or act on it.
And we don't have term limits. So, we don't have to worry about four years doing one thing. And
then the other four years undoing whatever was done in those years, most of the energy just going
into campaigning. We don't have internal parties just using up most of the energy of the country
wasted as heat, right? So, they can actually build high speed trains all around the world.
And the US hasn't built one in our own country. You're like, that's not a good sign. That's not
a good sign for them a better capacity to actually do real shit, right? To coordinate
towards some real important things. They lifted 300 million people out of poverty in a fairly short
period of time, like nobody else has done that kind of thing. So, you're like, oh, autocracy is
actually quite effective. And high tech empowered autocracy is something the world has never seen.
The world has never seen a Sesame Credit IoT AI empowered autocracy.
That's an interesting proposition of what that thing could be. Well, that's going to beat an
open society if the open society is spending all its energy fighting with itself. And the left
and the right spend most of their energy fighting each other. You spend four years doing something,
four years undoing it because the term limit no one even thinks about a 30 year plan for anything.
Because I'm not going to get reelected if the shit that I do doesn't show up in the four years of
that time. So the short term orientation in the internal infighting, we just lose, right?
So technologically empowered autocracy runs a 21st century, unless you can get an open society to
coordinate more effectively than an autocracy can. How the fuck do you get an open society with lots
of people to coordinate more effectively? This is the societies are societies end up failing
on either the direction of chaos or oppression. I can say, well, the people think different
stuff. They had different life experiences. They have different beliefs. They want different
stuff. They aren't that connected to wanting to make sacrifices for people they don't know.
The tribal thing worked because you knew everybody in that tribe. Your life depended on them.
There were only 150 people, but this is huge numbers of anonymous people. And fuck those
people in that state I've never been to or whatever it is. So how do I bind those people
together when there's so little basis for binding and so much energy for cleaning?
So if I don't, it's very easy to have chaos emerge pretty naturally. I want this thing. I
want this thing. And we're just going to fight over it and you get increasing kind of all against
all the wars, right? And then the thing fails. You say, no, we need order. We actually need
some order to be able to coordinate. Otherwise, we get beat by some external force that has order.
So we're going to get the order through imposing it. We're going to do stronger top-down. Everybody
thinks this thing. Better versions of government cohesion of belief. We call that government
propaganda. Control of the population. We call that authoritarian state, whatever it is. I mean,
control of the behavior. But then that's a failed state in its own purpose because it's not actually
serving and liberating the people. And as a result, it ends up getting a homogeneity of thinking,
which doesn't have the creativity to actually innovate for new problems in the world and usually
fails for those reasons and doesn't have a high enough collective intelligence because of it doing
that homogenizing thing. So what we need is order that is not imposed. So we don't fail on the chaos
side or the oppression side. How do we get emergent order? Well, if the order is to be
emergent rather than imposed, it means everybody has to be able to make sense of the world similarly
and has to be able to reason about not just what is, but what ought. So ethics and morals,
similarly, and have enough respect for each other that you have a conversation where you want to
hear what other people think. And you don't want to just beat them and then think that they don't
exist and they're not going to come back. There's a short-sightedness of these cultural arms races
and political arms races. We beat them and now we won for a minute. And then they up the ante and
come back. If they don't go away, if you don't get the people off the planet, then it's Von Klauswitz
said war is politics by other means, but politics is the way that we get to actually avoid war.
So if I want to avoid war of some kind, how do we coordinate, especially when
there's forced coordination occurring through technologically empowered autocracy?
So now this comes back to your point about dissenting views.
A civically-minded person, as well as even a well-informed epistemically-minded person
knows that they're probably wrong about most things, knows that there's probably a lot of
stuff that they don't know, that they don't know, that they want to know it. They don't want to hold
on to being wrong about something or partial or whatever. They also don't want to hold a view
that is going to polarize a lot of the population against them because that they should cooperate
with, where it would be better to cooperate with them if you really do long-term thinking on what
not cooperating looks like. So I want to seek to understand what other people are thinking,
both what they value and their understanding of the world, and we want to try to create a
situation in which we can synthesize our sense-making of what is. And we can identify,
okay, so in this particular situation, you're saying no to this climate change policy or
whatever, and it's not because you hate the environment and want to fuck the environment,
it's because you think that this particular policy is going to damage GDP for the US,
China's not going to agree to it, and it's going to cede the 21st century to technologically
empowered talkers. What you really want is the protection of open society. So you're looking
at climate change through the lens of liberty. Liberty. Liberty is a valuable thing. I'm actually
down with that. I'm looking at environment. You can't care about the environment in this way.
You can't even believe the science or look at it, and your lack of belief doesn't have to do with
looking at it because you think my solution equals something that will destroy liberty.
But otherwise, you actually also would care about the environment. You prefer clean air and a
world that isn't destroyed through excessive natural disaster. So if we can separate the
strategies that are shitty strategies from the values they're seeking to serve and recognize
that the values on the other side are also real and say, how do we hold these together and then
try to come up with solutions that meet all of them better, that have less unnecessary tradeoffs,
that balance the tradeoffs better, then we stop driving unnecessary polarization.
And you can start to have the fact that in an open society, those diverse viewpoints mean more
collective intelligence than the homogene thing has. And as a result, it can actually coordinate
across a larger body of collective intelligence as the only thing I actually feel much hope about
in terms of how we move through this next phase. For me, what I think is actually gives me hope
that we might do it is I think we all have to get back to the deepest fundamental truths,
which are that we are all connected. We are all in this state of inner being. And I truly believe
that I know with G that this is reality. And you can look at it, and again, you can justify this
in a lot of ways. We're all connected to the earth. We're all connected to each other. We're
all more similar than we're not. We're all in this together. This is a global existential crisis
that we're facing. So either we push against the bounds so much that eventually our tribalism
collapses and all of the petty needs of one versus the other fall apart because we're really
up against the brink of something that is no longer tenable if we continue. And it's so
prescient that we will die. We will all die. It's mutually assured destruction if we continue the
path. And that will bring us together in some form of humanism. You could imagine that there's
some Independence Day situation where we're attacked by another species and all humans rally
together. You can suppose all of these different things. But the thing, all of those are horrible
situations ultimately that may be necessary. And for me, what actually drives my faith and my
belief that we can all do this in the way that you're proposing, where we all start to sense make
together, is there is a trend in mental health where mental health is declining severely. The
more that we do this, the more isolated we become, the more that we're unhappy. And you can see this
in all of the different trends of depression, suicidality, anxiety, all of these things,
how many people are moving to pharmaceutical solutions, which are not particularly working
that well and being at the rates of all of these different mental conditions are rising.
At the same time, we have a new paradigm, which is the legalization of psychedelic medicine
for treatment of some of these specific conditions, post-traumatic stress disorder,
end-of-life anxiety, depression. There's going to be myriad different things that
psilocybin, MDMA are legalized for, and perhaps other things. So what we're facing is we're
facing a situation where the mental health crisis is going to drive people to these
psychedelic medicines. And as someone with 22 years of experience in these,
what they're actually treating is a side effect of the experience itself, the effects that it has
on depression. This is my belief that the effects it has on depression, the effects that it has on
trauma, the effects it has on anxiety, the effects it has on any one of these different things that
it's going to be legalized for. It's actually treating that as a side effect of the fundamental
experience, which is an experience that is ineffable and indescribable in its fundamental
state. And you can look at the Johns Hopkins study, top-life experiences for people who are
experiencing psilocybin for the first time, all of these different things. We're driving
ourselves to a situation where we finally have what we're reaching for is going to be an alternative
to pharmaceuticals. And I think that's what most people are going to reach towards. But what they're
accidentally going to get is a dose of the fundamental, inexorable truth of reality,
which is that we're all bound by love and commonality. And I think as this moves, this is
the thing actually for me personally, and I think maybe you can also say that we all need hope for
some reason. And this is the way that I'm hanging my hope just so I can have sanity in my life.
But I believe that we're all going to be driven to this. Some people will reach for it who are
ready. Some people will be driven to it because the mental conditions will continue at such a pace
that they'll just have to go to treat their depression and they'll have to go to treat some
condition. But more and more people are going to get to that state, which is going to reach a
critical mass. And then that is going to create the commonality and openness where all of this work
that you're doing is going to proliferate and proliferate at such a point. It's not just you.
I'm saying you and the participatory and the collective you of the people and the ideas and
the zeitgeist that's emerging from these things that you're talking about, the meta discussions.
But it's going to drive this in a way that has far more momentum than we realize and it's going
to continue to build. And to me, that is the way that I make sense of the greatest hope for what
we have. That's my Gandalf on the hill with the shining staff and the white robes. That's the
thing that I believe has a very good chance of saving the day. So here's the thought that comes
up for me about that. I'm going to start with a tangent and come back in.
If I think about physical tools, some tools are intentionally made at called weapons. It's a tool
for a rivalrous purpose explicitly. But pretty much any tool that is intended for another purpose
could be weaponized if I had to. A hammer is not made for that purpose. A screwdriver is not made
for that purpose. A laptop isn't. I could hit somebody with a laptop if I needed to and be
more effective than maybe my fist. So every tool can be weaponized. And of course, the laptop can
be one of the most powerful weapons if I'm talking about cyber attacks or narrative attacks.
Because the tool is just extending our power. And then the question is, what does our power
and service do, both knowingly and unknowingly? It's also true that psychological tools and
epistemic tools and even spiritual capacities can be weaponized. And this is why we have a history
of holy wars. That's a weird thing. How is it that ultimately the basis of what's being served
is some sense of the true, the good, and the beautiful and something transcendent that it
creates a basis of war so effectively? All virtues exist in dialectic with a virtue that
seems like the opposite, and you can fail on either side. This is the Ecclesiastes,
there's a time to sow and to reap and for peace and for war. So what is it that knows which one?
Well, there's some discernment, some presence and discernment that is able to do that.
So we can weaponize certainty, make people falsely certain about something so they
move forward with the holy war. But we can also weaponize uncertainty. So it's not like certainty,
bad uncertainty, good. Weaponized uncertainty is actually one of the most common political
narrative warfare things that happens. The term FUD, fear, uncertainty, and doubt.
When people feel more fear, uncertainty, and doubt, so not uncertainty with the all in beauty,
but uncertainty like fuck what's going on, I feel scared, they defer to strongmen more,
strongmen leaders. So anyone who has a strongman leader orientation actually likes to drive
fear, uncertainty, and doubt as a narrative weapon for power consolidation. Because then,
look, you feel highly uncertain, I'll give you some certainty now.
Or you at least go nihilistic and don't get in the way. And similarly, people can weaponize uncertainty
like, okay, it's the beginning of Facebook. Just starting, it's a dating app, right,
then it's like a social app. Nobody's thinking it's going to destroy democracy by ruining the
systemic commons because of its ad model and powered by AI and the monopoly of network adoption.
But some people actually were talking about that, right? There were some people early on,
the Jaren Laniers and folks like that, who were saying, actually, this thing shouldn't have an
ad model. There are reasons why that's a really bad thing. And it was like, dude, you can't be
certain of that. Like, let's just, we don't know what's going to happen. We're doing a good thing,
you got to have faith, you got to just like build the positive thing, we'll move fast and break
things. That's what drives innovation, right, is that we have new problems and humanities rising
to the occasion to innovate more. So it's weaponized uncertainty. You can't know,
therefore, do the thing that I have an incentive to do, as opposed to really try to do deep risk
analysis and say, what are the possibilities of what could happen? What is the best risk analysis
we could do? What's the best design we can do? And then what's the best iterative design process
that when we realize things we didn't realize, we can change the design and not be bound to
shareholder fiduciary responsibility or things that make an auto poetic machine that nobody can
control. So now in terms of psychedelics, I would say the thing that you're saying that I totally
agree with and find is true is that people's ability to increase their sense making adequately
that open societies can coordinate to solve the problems of the world
doesn't start with sense making, it actually starts with something like virtue.
Right, it starts with, because it's so common that I forgot this train earlier, people have
epistemic certainty, and then they realize that there's other stuff and they're wrong and they
flip in one step to nihilism, it's too much, I can't make sense of anything. And there's almost
no fortitude to be like, I'm going to try to understand progressively better while
acknowledging that I don't and do hard work and not just cognitively offload.
So there's something like epistemic humility and commitment at the same time. But there's
a virtue that is required to invest in that, there's a virtue that's required to want to hear
what you have to say and not just feel some fake connectivity with someone else by outgrouping
the same person. So we're on the end group together, which is a, it's a bullshit connectivity,
right, or a bullshit hit or whatever it is. So the work that it takes to sense make
reality well and to coordinate with each other well, why would people invest in it? There is
something that they have to actually value, there's a number of things they have to value
deep enough to summon that investment. So do I think that the health of our systems and our
global society is connected to the health of individual
psychologies and relational health? Absolutely. So the idea, are there emerging technologies
and possibilities and awareness about mental health that could be part of the breakthrough,
where we actually, in the same way we will say better living through chemistry, DDT,
whatever, super helpful for agriculture and then realize all the harm that it externalized,
and there's no pollinators left, whatever, we externalize harm to people's mental health,
right? So radically increased addiction, depression, complex PTSD for almost everybody,
low grade existential angst for almost everybody, that is not actually the native human condition,
that is the result of the society that is optimized for GDP and GDP per capita through
optimizing addiction and distraction and competition and shit like that, right? And
broken tribe, the healthy kind of tribal relationships where there is a basis of
real trust with people. So we need to recognize that external and say, no, no, fuck, we actually,
the civilization shouldn't be optimizing for GDP. The civilization should be optimizing for the
psychological health of the people and their ability and the social health of the people,
their ability to coordinate together, because that's what's going to determine
the health of the commons, national security and everything else, because all the things are fucking
done by people. So what is the basis by which humans are making choices and then making choices
with each other? What is their own sense making and meaning making and forming their choice making?
And what is their ability to coordinate with the sense making and meaning making of other people
towards coordinated choice making? That has to become the basis of what civilization is trying
to help, right? Trying to serve. Now, I do think that awareness of this and not just psychedelics,
but, you know, there's been a huge proliferation in mindfulness and CBT and various different methods.
I think psychedelics have the ability to do state induction easier than lots of other
processes because a Sundance is hard. Not that many people are going to do a Sundance
and even a vision quest and, you know, four days of water fasting is hard.
And the amount of meditation it takes to start to have an experience of the
numinous is hard. So in a culture where people don't mostly do hard stuff yet, can we
help them have a numinous experience that puts them in the right direction?
You and I both seen a lot of people be helped by this.
But there's a lot of the best people that have ever lived have never done psychedelics. And
there's a lot of people who do lots of psychedelics that are just shits. And
you know, if I look at a Jimmy Carter type person who post cancer,
after all the service he did for the world is something like 98 and he's still swinging hammers,
literally building homes for poor people around the world. And like,
I will take more people like that, even if he's never had a numinous experience, like whatever
condition that kind of ethical commitment, like, I'll take that over people who,
because they have a transcendent experience, will do that Facebook kind of weaponized uncertainty.
And be very good entrepreneurs who are moving forward, something that is a very partial vision
that's externalizing harm other places, not paying attention to it. I've seen people do
psychedelics and actually say, now I know for real, this is a simulation,
because I could see into the code of the matrix on an NDMT or whatever. And so,
and I know that it's really just a game. And I actually know that my consciousness is the only
thing there is. And so I'm just going to fucking win the game. Yeah, I know it can lead to mania,
it can lead to all it's not, it's not a panacea by any means, you know, and I think that's a very,
it's a very important point that that this is not there. However, I would, I would dare say,
let's talk about one of these, you know, cheap manipulative tools that we talked about, like
where people are arguing about gay marriage, right, which is patently obvious that, of course,
a human being, if you want to get married, it doesn't matter your sexual orientation.
I would dare say that someone who is against that in the peak of a guided MDMA assisted journey,
as they were completely open, their serotonin system was flooded and they had that sense of
deep belonging and security and connection that the that the facilitator could ask them,
what do you think about people with a homosexual orientation getting married?
I would venture to say that at that point, they'd be like, yeah, for sure. Like, if they love,
like, let them love and like, let them be, I do have a fundamental belief that in the right context,
to course correct from kind of stubborn stuck patterns of thinking these the kind of
brittle and unplastic, unmalleable belief systems, it has a way of potentially melting
those enough and getting to a point where it's like, yeah, yeah, we can't do that. Yeah, we
can't fuck the oceans. Yeah, we can't fuck over each other. Yeah. Like, I just feel like,
from my own experience and watching people go through it, there's, there's hope there. There's
hope there that it will, you know, even though it's going to create some outliers and even though,
you know, as Moctezuma had his priests all taking, you know, Teotonactyl, which is psilocybin and
cutting the hearts out of people and shoving those hearts in the mouth of, you know, Whitzel
Approachly, the hummingbird God. And while, you know, certain gang members will take MDMA when
they go on a shooting because it'll prevent them from feeling the kind of the impact that they're
doing. And certainly it can be used in bad ways. Certainly I've seen people go, you know, completely
manic and think that they are the actual linchpin for the world and, and all of these other things.
We're looking at situations that need to make a gross positive impact. And I think the net gross
positive impact is going to be overwhelmingly positive. But there will be, you know, certainly
casualties to this and also opportunities for this to be misused, different cult leaders that
could rise using entheogens and different things that are driving people into weird,
psychologically manipulative states. There's risks, you know, there's no, there's no
panacea and there's no risk free solution. It just seems that what we really need is most people
aren't Jimmy Carter's, you know, I mean, that's a, it's a kind of a rare breed. We need something
that turns the, turns the tide a little faster because it feels like time is bearing down on us.
And something needs to happen quicker. And to me, this is the thing that in my assessment,
again, which I need to have humility and saying, I don't know the assessment of how much time we
have and what is actually going on. But in my assessment, it feels like there's a sense of
urgency and that urgency is there's something that needs to move masses more quickly. And to me,
this is the thing that can move the masses more quickly. And there's many, many different ways.
I mean, I love breath work. I love ecstatic dance. I love sensory deprivation tanks. I love vision
quests. I love all of these things. And these methods I think are also incredibly important
it just feels like the thing that's going to actually move the masses to the greatest degree
that is going to be that MDMA assisted psychotherapy in particular.
I agree that it has really significant meaningful potential. And, you know, we come back to the
with great power comes great responsibility, or we go off the rails with it. And that's kind of
the whole story of our time is the power of exponential tech not being guided with the
right wisdom and the right virtue towards what. So I would consider psychedelics a very powerful
psychotechnology. And because of that, I want it stewarded really well. I want to see that the people
who are likely to have psychic breaks, there's assessment and they don't go into that first
that the meaning that people make afterwards is facilitated that they integrate it in a
way that actually leads them to more psychological health rather than the various other ways that
it can go. So I like like the work that Stan Groft did early on with psychedelic assisted
psychotherapy was using existing psychotherapeutic techniques and just recognizing that the increased
visualization capacity and the increased plasticity, you could get the effects of 50 sessions and two
sessions. And but it was still in the context of people who had deep study and understanding of
the nature of psychological health and how to facilitate that. So I think groups like Mass
are doing really important work currently advancing that kind of early work. And it's always tricky
like with psychedelics or natural medicine or various things that are unregulated. By being
unregulated, they can be totally fucked up. But when soon as we understand the issues that you and
I understood earlier of how easy how hard it is to have a regulator actually be good, then it's like,
okay, I don't really actually want it regulated by the types of regulators we currently have. I also
don't really like it unregulated. Fuck, what's the answer? Well, I want it regulated by a collective
intelligence that actually understands the issues better. This is the why a cultural enlightenment
has the basis of new institutions and stewarding new capacities is the only way that I really see.
And so of course, there's this bootloading thing of like a certain level of cultural
enlightenment is needed to even hold psychedelics well. And then of course,
can psychedelics in turn facilitate that? Now, when you start to think about how do you move
the masses quickly with regard to psychological health? First, I don't I just want to retract.
I hate the term the masses. How do we have lots of people start to have meaningful
shifts in their experience of reality that affects the nature of the choices they're making to be
both healthier for them, their close relationships and the larger world and so far as they affect it.
Let's take Facebook. And let's take the fact that my feed is going to be curated to stickiness
for me stickiness is usually limbic. So during George Floyd protests,
the people who would be sensitive to it were just getting image after image
of black guys being killed by cops. And so much so that as I kept scrolling and seeing all of this,
it seems like it's the whole world because it's my whole Facebook feed.
And so I'm getting I'm getting vicariously traumatized by somebody that I identify with
being traumatized. That is that is network dynamic, satellite mediated, AI mediated,
micro trauma at scale that is custom targeted to traumatize each group in their own unique
susceptibilities like fuck that. I don't need psychedelics for that. I mean, it might help.
I need to actually change that machine because could it be sharing with people things that
were actually helping to heal and uplift them if it had a different optimization basis?
And again, if even the broadcast media, if people are going to click on the thing with
a salacious headline, I'm going to have a system of like exponential warfare that is traumatizing
to everybody at scale and polarizing them against each other. Those things have to be addressed
because people in new environments can heal quickly. And people in the same environments
mostly can't. This is actually a really important thing is if you or I got moved to
a war-torn region of Darfur, we would change. If we went to a maximum security prison, we would
change or we would die. And so am I my own psychology or am I the result of the context
I'm a part of? Both, right? And anyone who thinks you're not affected by the context is just it
doesn't get it. So there are contexts that everyone is in that are conditioning the things that they
condition and we changing those can start to change. So like for instance, if the moment someone
decides that they're going to go to a month-long camping trip with their friends,
their generalized anxiety and trust issues in paranoia as well as addictions might just start
dissolving without psychotherapy because they're around. They're having present human interactions
so they're not seeking artificial human stimulus through the dating app and Facebook and porn,
whatever it is. They are having interactions where they know they can trust things because
they're getting to watch those people. And the trust that is increasing starts to heal them
psychologically whereas they're currently in an environment where they don't know if the people
at work or friends are foes. They don't know if the politicians are lying to them to fuck them
saying their friends or not. That drives people kind of crazy, right? Because now people are running
the simulation of do I trust her or not? Is is too real and they're really blood drinking vampires
or is that totally gibberish and I'm being misled as a psyop or like that drives people crazy.
And so when we think about healing, we have to not just think about it as healing the individual
but healing the context that us as tribal people because individual Homo sapiens never survived.
Evolution didn't select for sapiens. It's selected for tribes of sapiens.
That's another really key part to think about.
Is there any way that we can change the context, change these institutions, change
these things without changing the people to demand a different context, right? Like is there any way
that we can rise up against these incredibly effective structures that are creating this chaos
other than knowing that we ourselves as participatory in them or not
have to reach that state of healing? I mean, it seems to me that ultimately we're saying
the same thing. I'm just saying that a priori, the first thing that needs to happen is the individual
needs to demand that needs to want to go on that camping trip or needs to want to do this other
thing in the first place, which is then going to cause them to share different ideas and then
that will actually change the structure. As more people want healthier food,
Walmart has become the number one supplier of organic produce. As people move against different
processed food, I'm sure that we'll look back and McDonald's is going to be crushing it,
providing people with the nutrients that are actually helpful for the most part,
because they have the system in place and as demand warrants it, the people will receive it.
It always seems to always go back to, can we get more and more individuals
desiring the change and then allowing these corporate structures, which are going to maximize
profit, when the profit is in a different area and the area is actually in alignment with what
healed people actually want, then the structures themselves will change. But it seems like anything
else is, I don't know, I just don't see how it works, but I'm certainly open to it.
But you're coming back to the question of does demand drive supply or does supply drive demand?
Yeah, I suppose so.
And it does both and we have to work with both of the sides and we have to work with the virtuous
relationship between them. This is a key thing and this again, demand relates to the individualist
orientation, supply relates to the more collectivist orientation. And to think of them not in a
dialectic and what's the relationship between them just won't work. It's just silly. It's not
understanding the mechanisms yet, well enough. So let me give you an interesting example.
There's other ways to interpret this. This is not a comprehensively accurate interpretation,
but it's worthwhile as it's illustrated for this.
What Elon did with Tesla was there was not a market demand for electric cars.
The oil prices were cheap enough. There wasn't a belief that electric cars could be that good,
that the market demand was actually very low. So supply wasn't rising to do it. People were buying
SUVs, whatever. And he's like, no, I think we need electric cars because of climate change and stuff
that he believed in. I got enough money coming out of PayPal that I can make a source of supply
and then manufacture demand where people will want something they don't want right now because
they don't even know it exists. And so because of the asymmetry of supply side, he's like, let me
make something that is fast as a Ferrari and greener than a Prius and safe as a Volvo and
as luxurious as a BMW all together and everybody who fucking wanted through ground up kind of
innovation because I can do that. I got in the plane to do that. So that was a supply side
innovation independent of demand. It was somebody like one guy's demand, a few people's demand,
a belief in what we should demand. They create a source of supply that manufactured demand within
all the other car companies now are in a race to do that thing. So the other sources of supply
had to follow demand, but demand wasn't triggering itself. The market was not self-correcting in an
appropriate way without somebody coming in and kind of helping to do that. So in a way, you could say
he was playing the invisible hand of the market there because the invisible hand wasn't doing
the thing that it needed to do because the market wasn't coupled to thinking about long-term
environment. And it wasn't coupled to thinking about long-term innovation. So the short-term
money on money dynamics of the market didn't give it the intelligence it needed to orient.
So that's an example of how does a small number of people understanding something,
you still have some people that have to come to it, right? He came to that, the other people who
were doing it creates something that makes it easier for other people to come to it.
This is now individualism driving a collectivism that drives more individualism that drives more
collectivism in the right direction. And so if I grow up in Darfur or I grow up in Finland,
I'm not going to get the same education. I'm not going to get the same psychological conditioning.
It's just really, really different. And that has nothing to do with me as an individual,
same genetic, put me in one place or the other place, right? So how individualism
fucking put me in Finland, right? Like nobody would have a question about which of those educational
systems or trauma systems or like access to healthcare or early nutrition. So the libertarian,
like we need to start with the individual's wanting and saying, okay, well, how does that work for
the person born in utter fucking poverty? It doesn't. How does it, where they're born in a
poverty to where their brain will not develop because of the lack of nutrients or with AIDS
or with the kind of trauma that they can't escape. And this is where we get that, like,
we affect the whole and we're affected by the whole. We can't think of ourselves just as
hive members of a collective because we're much more individual than termites are or bees are.
But we also can't think of ourselves just as individuals. We're not affected by the whole.
So how do we hold ourselves as unique and interconnected at the same time?
And agentic and where all of our agency will affect the environment, which will affect others,
but we're also affected by the environment. How do we hold that synthesis together? So
some people are going to have a sense of something that is worth doing that the market
doesn't currently incentivize, that there isn't adequate demand for. Figure out how to make that
thing. This is why it has to start with culture, not start with the market. Because the market is
going to incentivize the thing it incentivizes. That's just flowing on the topology of market
incentives. And it will continue to incentivize the war with a for-profit military industrial
complex is profitable and extraction and blah, blah, blah. So if we want to do something that
is different than the power structure currently in sense, why? What is the why? Some people have
an awakening to a why that is not winning at the current system. But they then have to make
a system that makes more people able to on-ramp onto it, not just do their own thing. And then
that's where you get auto-poesis. That's where you get something that can actually become a strange
attractor for a new possibility. Absolutely agreed. It seems to me that that will become more likely
because Elon, he arose from that and whatever. This is not saying that Elon is the better
angel of all of us. I don't know, Elon. I don't know what's going on in his mind or whatever.
But it feels to me like the better angels with the capability and potentially the resources and
potentially the collection, they're amongst us, interspersed amongst us in this collective
world. And it's going to take, yes, every different individual to arise to these
different understandings about the nature of how connected we actually are. And then certain of
these individuals who have the ability to create new structures like Elon did with the cars that
will have to emerge to build these new structures. And those will be actually select individuals
that will come together. But I guess for me, what I'm trying to sort out for myself is where can
I put my efforts that will be best served? And it feels to me like, yes, sometimes this will
just be for an individual and their family. They'll be a little sweeter to their spouse. They'll be
a little kinder to their kids. They'll be a little more helpful to their neighbors when we have in
Texas where it's snowed like hell for no reason. In the middle of February and neighbors were
helping neighbors, they'll be more likely to do that. They'll be creating this. And then there'll
be some hidden Elon's or hidden better angels that are awakened to this, or maybe they even weren't
even better angels at all, but they'll turn over to this. And these different structures,
like you said, which are absolutely necessary, will have to emerge structures that are competitive
with the current structures and then get enough momentum where you can actually, where I could
actually legitimately hop off Instagram and be like, see you later, Instagram. There's this other
thing that's way cooler and has the fundamental values that are needed. And I think I've met
some individuals who are actually doing that, and that's actually their prerogative, their
targeting. I know one individual, and I won't mention his name, but he's taking some of the
builders of AI, some of the leading edge builders of AI, and bringing them into five MEO ceremonies
and saying like, whatever you build in this AI needs to have this fundamental understanding of
unicity. And this is my best way, and this is his word, my best way of sharing this felt sense of
unicity is through this particular ceremonial experience. And so if I can give these people,
he's targeting them specifically, if I can give these people, because he has access,
and he has also the experience. If I can give these people this felt sense,
they'll build this into the new structures. This is the new structure that has the force,
and this will create a new system ultimately. And it also, hearing you talk makes me want to
reach out to them and be like, fuck, man, thank you again. Like I see how important it is what
you're doing, but it's now I'm even more aware how important that is that the people who have the
ability to create massive structural technological and corporate change by creating a different system
that they're empowered and embodied in a way that's going to actually carry that out.
And I think a lot of people ask the question, if we need to recouple
power with wisdom and virtue, where we've had a system where wisdom and virtue make you less
good at the game of power. And those who are more sociopathic, more narcissistic, both oriented
towards power and happy to win it when lose games, do better in those systems. Do we recouple them by
taking people who have more orientation towards wisdom and virtue and trying to figure out how
to empower them or get them to be good at the game of power? Or do we take people who currently
have power and try to condition some wisdom and virtue in them? And they're both honestly very
difficult propositions and both important. That's a both and, and the both and is definitely
seems to be the synthesis, you know, and there's always there's dangers on every side.
And I think finding that middle way is immensely important. And I get that that's what you are
doing, you know, with this podcast of you have an individual,
agentic, you know, orientation towards a healing growth learning path, you're coming across things,
you're like, fuck, I want everybody else to know those things so that they can do have to get access
to it and do stuff with it. So how do I take the people who I find insightful and, and help? And
that's a cultural enlightenment process, right? How do I help bring more knowledge, wisdom, insight
to more people with the belief that increased collective intelligence and collective wisdom
will generate lots of positive things beyond the obvious ones we can predict?
Yeah. Well, and being able to talk to, you know, brilliant heart centered people like yourself
are a huge part of that. So just the utmost gratitude for everything you're putting out and
for having this conversation. And yeah, man, just just really grateful that that we're in this space.
And, you know, ultimately, the other thing that gives me peace is whether we win or not,
you know, whether this thing goes up in a ball of flames or it doesn't,
how we orient towards it is really what matters. We can't control the unknown, we can't control
all outcomes, but how we play like how we fight the fight, do we fight with love, do we fight
heart forward and head up, helping as many people along the way. If the end comes, and we've known
we've done everything else, you know, even though it's the worst possible outcome, we can do so
with the full heart and just say, fuck, I gave it everything I got, you know, like today's a good
day to die, you know, like I've done my best. And I think that's all that we can do is just know that
we've given it our best and given it everything we got. And, you know, certainly these tools that
you're providing are absolutely crucial in helping us all be able to live that out in the best way
possible. There's good talking with you. Thank you for here. It was fun. Absolutely,
brother. Thank you so much, everybody for tuning in. Is there anything, give people the URL for
Consilience and anything else you want to point people to? Sure. The Consilience project,
Consilienceproject.org is just at the date of publishing this is super nascent, like not even
really a beta. It's a prototype that is pointing towards what we're working on. We can talk about
that more sometime. It's a five-year project itself terminates at the end of five years because,
as you were mentioning, the organization, the organization's desire to keep perpetuating itself,
which every organization has, ends up being a perverse incentive if it's trying to solve a
problem or if it really solved it, it obsolete itself, and then it becomes a basis to just manage
the problem forever because it gets some power by doing so. Sometimes building life cycles in
or completion processes in is very helpful. More on that we'll show up over the next several
months at consilienceproject.org. That's it. Beautiful. Thank you so much, brother. Thank you
everybody for tuning in. Thanks for checking out this video. For more like it, please subscribe to
my channel. And of course, the Aubrey Marcus podcast with new episodes every single week.
And follow me on Instagram at Aubrey Marcus. Thank you so much.
