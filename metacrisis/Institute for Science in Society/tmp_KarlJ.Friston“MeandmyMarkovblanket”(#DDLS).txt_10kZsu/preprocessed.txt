Okay, so I would like to ask everybody except for the speaker to mute themselves.
So welcome to the third session of the Dutch Distinguished Lecture Series in Philosophy
and Neuroscience.
It is my enormous pleasure today to welcome Professor Carl Friston, who is one of the
godfathers, if not fathers, of many developments that happened in neuroscience and imaging,
near imaging since the 80s and 90s.
And so I will just give you some brief highlights of who he is, if you don't know already who
he is, but given the number of people who attend this talk today, I assume a lot of
people are familiar with his work and significance for the brain research.
So Professor Friston is a theoretical neuroscientist and authoritative in brain imaging, invented
statistical parametric mapping, voxel-based morphometry, and dynamic causal modeling.
These contributions were motivated by schizophrenia research and theoretical studies of value
learning formulated as this connection hypothesis of schizophrenia.
So mathematical contributions by Professor Friston include variational Laplacian procedures
and generalized filtering, or hierarchical Bayesian model inversion, and his e-corner
works on the model of functional integration in the human brain and the principles that
underlie neuronal interactions.
His main contributions to theoretical neurobiology is, of course, a free energy principle for
action and perception.
And among other things, he received the first Young Investigator Award in human brain mapping
already in 1996, and he was elected a fellow of the Academy of Medical Sciences.
In 2000, he was president of the International Organization of Human Brain Mapping.
In 2003, he was awarded the Venerable Golden Brain Award, and he was elected a fellow of
Royal Society in 2006.
In 2008, he received the Medal College de France and an honorary doctorate from the University
of York in 2011, and he became the fellow of Royal Society of Biology in 2012 and received
the Walden Memorial Prize and Medal in 2013 for Contributions to Mathematical Biology.
And then he was also elected as a member of the Excellence in the Life Sciences in 2014
and the Academia Europea in 2015.
He was the 2016 recipient of the Charles Branch Award for Unparalleled Breakthroughs in Brain
Research and the Glass Brain Award, a Lifetime Achievement Award in the field of Human Brain
Mapping.
He holds honorary doctorates from the University of Zurich and, of course, from our own university,
Radbaude University.
And so without further ado, I would like to give floor to Professor Freiston, who will
talk about he and his mark of blankets.
So Professor Freiston, floor is yours.
Well, thank you very much for that lovely introduction.
I've forgotten about my young investigator brain award, I was very nostalgic.
It's a great pleasure to be able to speak to you today.
I should apologize in advance, I know very little about philosophy.
So what I've done is try to take some of my favorite formalisms that may be unpacked in
terms of philosophical implications, but I'm afraid you are going to have to do the unpacking.
So I'm going to be talking about the nature of sentient behavior, the self-organization
of sentient systems, and I'm going to do it in two parts.
I've got to tell two stories.
The first story is from the point of view of a physicist, and now we're talking about
the statistics of life, especially focusing on mark of blankets and the implications for
a Bayesian mechanics that attends the mark of blanket.
And I'll try and illustrate what that means from first principles using toy simulations
of a primordial soup.
And then I'm going to repeat the story mathematically, but using a different semantics, that of a
neurobiologist, and talking about predictive processing and coding in the brain and how
neuronal networks may enact the same kind of dynamics that we saw in the physics part
of the talk.
And then we'll conclude if we have time with a closer look at action perception.
The purpose of this is to introduce a distinction between fast reflexive action of a sort you
might see in a very simple system, like say a virus, from the kind of deliberative planned
actions that systems or curious creatures like you and me tend to engage in.
So I start this talk usually with a question from Schrodinger, how can the events in space
and time, which take place within the spatial boundary of a living organism, be accounted
for by physics and chemistry?
And now we're not going to answer that question, what we are going to do is focus on this notion
of a spatial boundary and just acknowledge that in order to talk about anything, any
system, any particle or person, you need to define or it is defined almost stipulatively
in terms of what demarcates it from everything else in the universe.
So Schrodinger would be the first person to acknowledge that this blanket, this separating
boundary is itself a statistical object, a random object.
And I'm going to read that, that boundary as a mark of blanket introduced by people like
Pearl.
For those of you who don't know what a blanket is, it's relatively simple.
Imagine that I could describe some universe with a whole set of states that influenced
each other to where these little arrows denote an influence of this state over this state.
And then we elect to identify a particular set of states and let's call them internal
states and these are going to be states that are internal to a particle or a person or
any system that we can identify.
So the mark of blanket comprises the parents, the children and the parents of the children
of the internal states.
And the role that they play is to supply a statistical separation between the internal
states and the external states in Sean here in the sense that if I wanted to predict my
dynamics of the internal states, given the rest of the universe, I would only need to
know the blanket states.
There is no further information available beyond the blanket states.
So when conditioning the outside on the blanket states, I have everything I need to know to
tell me about my state or the internal state.
And I'm going to make a further move which will become more intuitive in the next slide.
I'm going to just split the blanket states into sensory states in magenta and active
states into red and do that on the basis of the fact that internal states, external, sorry,
sensory states influence internal states but are not influenced by internal states, whereas
active states are influenced by internal states but do not influence internal states.
So that may sound a little bit arbitrary but if we think about all our favorite systems
then that separation into sensory and active states that together constitute a particle
or person's blanket states and together the blanket states and the internal states that
they enshroud constitute the states of a particle or a person or a brain or a cell.
So here's a brain and here's a cell.
So under this construct, we can associate all internal brain states such as synaptic
efficacy, activity, everything that I would need to know to describe the state of the
brain at the moment.
We can associate those with the internal states that influence our active states or actuators
or muscles or genomic nervous systems that then cause changes in the external milieu
or indeed the internal milieu of our body that then generate sensory states that are
registered by sensory epithelia that feed back into the brain, cause evoked responses,
induced responses and changes in the internal states.
And exactly the same conditional dependencies and sparse influences exist in any system that
you can imagine.
So for example a cell will have intracellular states being the internal states, we can associate
the active states with the active filaments that support the sensory states that are
pushed into the external environment, changing the external states that couple back to the
cell surface sensory receptors, the sensory states that get back into the game either
directly or precariously to influence the internal states.
So that's the basic construct upon which everything else is based.
What I want you to do for the moment is just to forget about Markov blankets, what we're
going to do is just look at the physics of self-organising systems and then we're going
to put the Markov blankets back into the game and see what special implications there
are for dynamical systems that you can find a subset of that you can identify with a system
or a particle.
So this gets a bit technical but I think it's worthwhile drilling down on this formally
because it underwrites as we'll see nearly all that we know or use to describe the physical
world.
So I'm going to start with something called a large van formulation of any given universe
so that rates of change of some states that can be anything can be written down as some
flow function which is state dependent plus some random fluctuations.
And if I trace out the flow of a trajectory of a given state of a given system, say this
is me and I get up in the morning and I have my cup of coffee, I do my emails, I have my
lunch, then for systems that attain a non-equilibrium steady state that exists over some period
of time, in other words that have an attracting set, what you will see is almost by definition,
by definition, this trajectory will always revisit after a certain period of time the
neighbourhood of any given state.
So the trajectory is captured or unfolds on this attracting set or manifold.
This can be at any time scale, it's exceedingly high dimensional, it could be my heartbeat,
it could be a time course over the year with Christmas and Easter and birthdays and summer
holidays.
The same basic structure is in plain.
It's a useful formalism because it is described or affords an interpretation in terms of the
probability that I will or any system will be found in a particular state if sampled
at a random point in time.
So we can also interpret this trajectory in terms of a probability distribution of the
kinds of states to which I am attracted.
We can write that down with a very generic equation, the Boca Planck equation in terms
of the density dynamics, the way this dot denoting the change with time, the way in
which this probability density changes as a function of the amplitude of the random
fluctuations gamma and the flow.
So why is that important?
We've just said that this attracting manifold exists over enduring periods of time, which
means that the probability distribution doesn't change with time, so that means it's zero,
which means in turn I can write down a fundamentally important equality, which is a solution to
the Boca Planck equation, which just expresses the flow, the dynamics, the way I move through
my state space as a function of this probability density and the amplitude of random fluctuations
and something else called solenoidal flow.
So this is called the Helmholtz decomposition.
It's very important in physics, it breaks detailed balance and it describes real world
systems that are open to their external states.
To give you an intuition, imagine that I placed a drop of ink in a cup of water.
Now what would happen for non-equilibrium steady state systems that didn't have an
attracting set is that the random thermal motion of the water molecules would knock
and disperse, dissipate the ink molecules and the ink would diffuse throughout the solvent.
And I can cartoon that in terms of the diffusion away or down concentration gradients as the
ink dissipates or disperses through its medium.
That's not the kind of system that we're trying to describe, we're trying to describe
this kind of system where it gathers itself up again and then attains and maintains this
non-equilibrium steady state and in so doing you can see immediately that the kinds of
flow required to assemble, self-assemble this steady state require somewhat counterintuitively
a flow up the concentration gradients, a reverse diffusion if you like.
And that's basically what that decomposition describes.
All it's saying is that for any system that gathers itself up there must be two separable
components of the flow, one which is a gradient flow flowing up the concentration gradients
and another circular or solenoidal flow which circulates around the isoprobability contours.
So that's all that this equation is basically saying.
Even more intuitively we're all very familiar with this kind of decomposition when we watch
water flowing in a circular fashion down the plug hole.
Going down the plug hole is a gradient flow and the circulating flow is the solenoidal
flow.
So that's nice but what about the Markov-Rankit?
Well this equation has to be true for any system that exists in the sense that it has
attained some form of non-equilibrium steady state and I can therefore write it in a non-trivial
way in terms of the states of a particle, the internal states and in particularly active
states, the autonomous states that don't depend upon the external states.
And if I do that what we have because the internal and active states don't depend upon
the external states I can limit this to a function of probability distribution over
the blank state.
So what we're saying is something quite interesting.
We're saying that the internal states are something say my neuronal states and my action,
the way that I move or the way that my autonomic reflexes work, come both or must be describable
in terms of a gradient flow on the log probability of something that doesn't actually include
the states that are hidden behind the Markov-Rankit and I'm going to try and sell that formalism
as a mathematical image of perception and action respectively and in so doing suggest
that this key quantity, this log probability emerges in many different guises, in many
different disciplines.
So for example if I was in behavioral reinforcement learning as a psychologist, if I was an engineer
using optimal control theory, if I was an economist dealing with expected utility theory,
this quantity, this potential if you like of a probability or a Bayesian belief as we'll
see later, of the kinds of states to which I am attracted, these are the attracting sets
that we were talking about before.
This quantity, this log probability would emerge as value.
So all of these things are trying to maximise or describe systems that maximise utility,
minimise cost or loss or maximise utility.
That's interesting and it's also important from the point of view of the free energy principle
that we heard in the introduction because the free energy is just a way of writing down
this value and this is the negative free energy.
I should note if you're a physicist you want small free energies, if you're a machine learning
you want big free energies so please bear with me in terms of the different signs.
The free energy here, being the negative of this quantity, is therefore also very understandable
from the point of view of people working in information theory.
So why is that?
Well, this negative value is known as self-information in information theory, a surprise or a more
simply surprise, which means that any active system where autonomous states are trying
to minimise surprise can now be understood in terms of things like the principle of maximum
utility information or the information principle, minimum redundancy and indeed the free energy
principle.
That's nice because the time average of surprise is entropy, which means that any system that
exists will look as if it is self-organising to minimise the entropy of its blanket states
and of course that's a holy grail of things like synergetics.
And if I was a physiologist, this is just a statement of homeostasis, keeping states,
blanket states, sensory states of an autonomic sort for example, within certain bounds and
stopping them exceeding those bounds and dispersing into non-bible regimes.
There's a final interpretation that I want to leverage, which is that of a statistician.
So hitherto we've been talking about M as any given Markov model that defines the distinction
between external, internal and blanket states, but I can also interpret M as a model of the
external states implied by the sensory data that they supply inherent in the blanket states.
So this quantity now becomes or takes on the role of model evidence in Bayesian statistics
that I'm trying to maximise.
So this now leads to notions of the Bayesian brain, evidence accumulation and predictive coding,
as I'm sure most of you are fully fluent and familiar with.
So those are four perspectives on this fundamental gradient flow on the log probability of some states of the system.
What I want to do here, please again ignore the equations, they're just being used
iconically to underwrite a very simple observation that the mechanics that we're talking about here
are no different from that which we'd find in classical mechanics, thermodynamics or indeed
quantum mechanics.
So let me just explain or show you how simply this one equation maps onto these different kinds of physics.
For example, imagine we're dealing with very large cold systems where we can ignore the random
fluctuations and then we just have the solenoidal flow apt for describing the circular motion of
the heavenly bodies or pendular or any massive bodies and this equation just reduces to Newton's
laws of motion and classical i.e. Lagrangian dynamics.
Conversely, if I go to the other end of the scale, look at very small hot things with lots of random
fluctuations where the inherent probabilistic behavior becomes dominant, then we are talking
about a description of statistical mechanics, almost precisely stochastic mechanics,
where this equation gives rise to fundamental theorems or constructs in statistical mechanics
such as the fluctuation dissipation theorems.
I can make another move, I can just deal with the square root of this probability distribution
or density, call that a wave function and this equation becomes the time independent
Strogen equation that underwrites all of quantum electrodynamics and quantum mechanics.
So that's good in the sense that there's a constant validity here, but what about the Markov blanket?
So the only thing that the Markov blanket brings to the table is this partition of
x the states into autonomous states and non-autonomous states or internal, external,
but it also affords an opportunity to interpret the underlying mechanics and dynamics in a
slightly more interesting way that brings with it a mapping between the inside and the outside and
this is the the bit that I thought might be interesting from a philosophical point of view,
it's a bit more technical than I would normally go through, but if you'll indulge me let me just
take you through the moons here. So we already know because these autonomous states do not depend
upon the external states by construction, by existence of the Markov blanket, that they will
appear to flow on a function of the blanket states and the internal states, the particular states,
and we know what that function is, it's just our surprise or self-information.
So internal active states share the same functional and this functional does not
depend upon the internal states. Now with one substitution of variables I can also write down
this functional as a function of a function, that's what a functional is, of probabilistic beliefs,
Bayesian beliefs about external states. So how do we do that? Well all we can all we do is basically
associate the expected internal state given any blanket state with a state or a position on some
internal manifold and we'll see what that looks like in the next slide. And then for any given
expected internal state say that it parameterizes stipulated by definition the probability density
over the external states and then this function of the blanket and internal states becomes a
functional of beliefs because I can substitute that into there and now I have a functional
of my sensory data, my blanket states, and my beliefs about the causes of that sensory data,
namely the external states and this leads to an interpretation of dynamical systems
if and only if they have a Markov blanket in terms of self-evidencing under a Markov blanket.
So just a bit more graphical intuition, I've never shown this slide before so
please bear with me with any hesitancy. This is our picture of a random dynamical system with
this an attracting set. If I just pick a particular slice through this state space at any given value
of the blanket states B and I've cartooned the probability density under or given that slice
conditioned upon B here, I have a distribution and this is two-dimensional over internal and
external states denoted by this expression here and again by construction it's independent so
there are no correlations here. I can summarize it completely with a marginal distribution,
what the distribution of states over the internal and the external denoted by these blue lines here.
So why is that important? Well what it means is for any given blanket state there is always
an expected internal state that depends upon the blanket state that has a mapping
to a probability distribution over the external states and this is what licenses an interpretation
of the internal dynamics as standing in for or holding beliefs about the external states.
So technically that induces a conditional manifold here with various values of B where
flow internal dynamics like brain activity can be regarded as the internal dimension
of this flow here which we know does this gradient flow and here are expected external states.
So the expected states encode or are mapped to or imply a distribution or a belief about the
external states. So internal states parameterize probabilistic beliefs about external states
I'm going to now show you how that works in practice using simulations and then we'll conclude
the first half of this this talk. What we've done here is just simulate a little universe
this universe happens to comprise 128 macromolecules with strong and weak electrochemical and
euclidean like forces. The details are not important all that we need to do is to sort of
create a little universe why well if we can do that and examine this little primordial soup
we can in principle because we wrote down all those conditional dependencies and influences
identify a set of internal states and their mark of blanket and if we can do that we can ask
is there a little particle or creature living in this soup that actually conforms to this
Bayesian interpretation this Bayesian mechanics that should be in play given our understanding
of the the gradient flows and their interpretation. So here is exactly the same simulation what I've
done here is color code the macromolecules according to their designation as internal
states in blue here with a little tail coming out here that are surrounded by active states that
themselves support the surface of the sensory states here that are exposed to the external
states and this little virus like particle happily wriggles around with cilia or cilia or tail here
at a non-equilibrium steady state. So why have we done that well it would now be useful to go back
and see does this sort of Bayesian interpretation of self-organization namely self-evidencing hold
can we demonstrate it numerically and it's fairly simple to do that here is one example
what we've done here is take any mixture of the internal electrochemical states say
depolarization of neurons in a brain and ask do they encode motion in the outside world
say visual motion of all of these particles so any mixture of flow of physical euclidean
motion in the outside is it represented in a probabilistic sense by the internal states
and to do that we have to identify this conditional manifold where everything's conditioned upon any
given blanket state and once we've done that we can use that mapping between the inside and the
outside to reconstruct the implicit Bayesian beliefs in terms of the expectations in blue and the
confidence intervals or credible intervals in the shaded area that encompass the actual behavior
of the external states hidden behind the blanket states not shown here and when we do that we see
a remarkable correspondence in the sense that the the real external states do actually lie
within the confidence intervals of the Bayesian beliefs based upon the expected value of internal
states for any given external states that expectation is important this is a synchronization
manifold that comes out on average so we only see this association when we average over multiple
instances here peaks of the internal states and I've just gathered these particular instances here
and put them on top of each other why have I done that well they look remarkably similar to empirical
neurophysiological results here are some ERP results from monkey electrophysiology timed up to
some visual motion as opposed to physical motion here as simulated so this would be a numerical
analysis that endorses this notion that it is emerging property of any system equipped with a
mark of blanket that will it will have this representational aspect that can be cast in
terms of an information geometry on the other hand although I know that he wasn't I think at
in Nijmegen although perhaps his brother was it's just a statement that your
forefather Christian Huygens made about the nature of loosely coupled dynamical systems this is just
an instance and a way of interpreting generalized synchronization or synchronization of chaos between
loosely coupled systems so his observation was that there are there will inevitably be a
synchrony whereby clocks suspended from the same wall or beam will come to oscillate in
synchrony and here's one of his drawings here so from our perspective what we're talking about
are two clocks one's the inside one the outside internal external and the beam of the wall constitutes
the blanket states that couple them enabling the carous and reciprocal influences to induce this
kind of generalized synchrony that characterizes these non-equilibrium steady states so let's
just summarize how far we've got so far so the existence of a particle something implies a partition
of systemic the states of the system into internal blanket namely sensory active and external states
that are hidden behind the Markov blanket and because active states change but are not changed
by external states they will look as if they're reducing the entropy of the blanket the dispersion
of the blanket states this is the homeostasis or self-assembly perspective and this means
action will appear to maintain the structural and functional integrity of the Markov blanket and
this is closely related to notions of self-assembly and chemistry and then the life sciences or
polices internal states appear to infer the hidden causes of sensory states by increasing
Bayesian model evidence and actively influence those causes and we're going to unpack that in
terms of active influence in a moment and internal states parametrize probabilistic beliefs about
external states lending their expectations and information geometry as we saw in the previous
slide and that in the philosophical world has been recently cast in terms of a Markovian form
of monism yes a little brief interlude here so this is a picture that sent to me by one of my
postdoctoral fellows went to France who went to America and then with his wife had a baby
and then his wife bought him a Markov blanket so this is a blanket with Markov on it and this is
little Kira making inferences about her world underneath her Markov blanket so if you want
to mark off blanket you can buy them in America apparently right so we've done all the the heavy
lifting from the point of view of the the technical backstory that inherits from the
self-organization of random dynamical systems what I'm going to do now is tell exactly the same
story but from the point of view of a neuroscientist or a psychologist trying to understand
sentience and action in an embodied brain and I'm going to do that in a sort of
conceptual way just by starting with this notion of the brain as a Bayesian machine,
a statistical organ literally an organ of fantasies having hypotheses that are confirmed or
disconfirmed in the face of sensory evidence and this is very much a 21st century view which you
will again be both fluent and familiar with that's more of a sort of inside out
inactive view of of perception that contrasts with 20th century sort of inside out extracting
information feed forward like notions of how perception works I think this is beautifully
illustrated by this 16th century oil painter famed for doing still lives that when viewed
from a different perspective evoke a very different explanation a very different hypothesis as to what
generated this particular pattern of sensory input so if you now see a face the point here
is that you made that face it's something you have brought to the table to explain this particular
pattern of visual impressions and talking visual impressions these ideas I guess can be traced
back to the students of Plato and certainly through Kant and to my in my world best articulated by
Helmholtz for example objects are always imagined as being present in the field of vision as would
have to be there in order to produce the same impression on the nervous mechanism and that's
clearly very closely related to psychological ideas appealing to perception as hypothesis
testing and I've attributed that to to Richard Gregory here ideas that underwrite many technical
advances in machine learning and indeed people like Jeffrey Hinton and Peter Diane proposed the
Helmholtz machine as a metaphor for the Bayesian brain borrowing from Bayesian probability theory
and in particular the key advances in statistical physics brought to us by Richard Feynman this is
the variational approach that gives us this free energy and we'll see why that is an important
treatment of Bayesian mechanics in the final final few slides let's just return to this notion
of sensory impressions on the nervous mechanism so I've sketched that here in terms of shadows and
a sensory veil for us are the sensory states of our Markov blanket and if it's the case that we are
compelled in virtue of this generalized synchrony that defines our existence conditioned upon a
Markov blanket and then it will look as if we are compelled to infer what caused these
shadows on our sensory epithelia and one might ask well how might that be described or articulated
in terms of a machine or a person or or a brain and it's actually much simpler than you might imagine
and can match to be written down in the form of predictive coding in engineering this will be
known as a Kalman filter so that is what I have done here we've taken the this existential gradient
flow where now I've replaced the the self-information with the free energy form of it and I just
decomposed the gradient flow per se and the solenoidal flow into a solenoidal part
and an update part so what does this mean well let's imagine that these expected internal states
stand in represent expectations about the causes of our sensations so this gradient flow basically
tells you how you believe update this denoting again the rate of change with time update your
expectations or beliefs about what's out there and I can write that down in terms of predictions
if I know what's out there I know how it's going to change over time and then the gradient part
so the gradients of any free energy function can be written down as a prediction error so the gradient
flow part of it becomes at the update which is just a scaled version of the prediction error that
is being minimized so what is prediction error well imagine I had this sensory impression on
say my retina and I had an expectation mu that this was a dog and if I had a generative model
that would generate the sensory states that would be there if this expectation was a plausible
explanation for my sensations then the prediction error is just the mismatch between my sensations
and those predicted under a generative model given my beliefs or my expectations that is the
prediction error so what we're saying is there's a simple interpretation of this gradient flow
in that it looks as if it is trying to minimize prediction errors and that's all there is to it
it's not to say that you will ever believe or know what's actually out there but provided you can
come to some plausible explanation with minimum or no prediction errors that's good enough for
and you can if you can keep doing that over your lifespan then job done
so that's appealingly simple we can forget about all that physics and just say well look
action and perception then are just in this in the game of minimizing prediction errors
what are the two ways of doing that well we can either change our internal states to make them
make the predictions that are generated from those internal states more like sensations and
we can call that perception by changing predictions currently we can change the sensations at a
sample to make them more like the predictions and that's also minimizing prediction error
and by changing sensations you know I mean very simply looking over there as opposed to looking
over there palpating the world in a way to solicit sensations that minimize prediction error or
maximize model of evidence as scored by this variation free energy and again we come back
to this notion that both perception and action work hand in hand in the service of self-evidence
and to form a prediction error and to realize the functional form of that gradient plural predictive
coding we need to be able to generate the predictions and I mentioned generative models that
one would imagine that the kind of generative models that we use are deeply structured now
the hierarchical form the very dynamic I've sketched that out here so imagine I set you the task
of generating some sensory data sampled by the fovea in your eyes so what you would have to do
was basically work out what was causing that pattern of sensory stimulation all the dynamics
and kinetics involved in where you and how you are sampling that object here a face and then
compose through a cascade of hierarchical or deeply composed hierarchical levels
these causes until you could actually generate the sensory data I've just written that down here
schematically in terms of causes causing causes causing causes ultimately causing sensory states
or sensory input with random fluctuations here so that's if you're like a model that you might
use to explain or generate sensory visual sensory input so what scheme what internal dynamics
would be implied by this sort of model well we know exactly what the answer is because we
know that it has to be this gradient flow here written in terms of a calm and bucy filter or
predictive coding and when we put that in play what we see is a following computational architecture
we swap out the random fluctuations for prediction errors and equip this with these ascending
influences such that the expectations about the world are informed by updated by the prediction
errors so we now have an architecture that comprises this kind of message passing where
you have these counter streams of ascending predictions and ascending predictions that
looks very much like what you see in the actual brain where these are superficial pyramidal cells
and these might be deeper pyramidal cells so let me run you through that from the point of view of
neurophysiology in the visual system and beyond let's say that we have some visual input here from
the retina it comes in to the lateral geniculate and it has some top-down predictions that enable
the lgn the lateral geniculate nucleus to evaluate or to compute a prediction error
that can then be sent forward to update primary visual cortex cells that have beliefs about say
edges and other elemental features of the world but these elemental expectations themselves
are subject to top-down predictions that create a secondary prediction error that can then be
fed forward to update beliefs in a higher level of our hierarchy and so on to any required hierarchical
depth so this is a description of sort if you like a deep inference in the in the same sense as deep
learning in machine learning where you're trying to find a minimum prediction error maximum model
evidence minimum free energy explanation by optimizing those implicit objective functions
through a gradient flow that we know has to be in plane so where's action in this model of perception
well let's look at another kind of input proprioceptive input from the ocular motor system
that comes in it goes into nuclei and the pons and will be will be predicted by sending
predictions from certain frontal eye fields and we have a proprioceptive prediction error
that could be sent up to update our expectations about where we're pointing our eye however
there's another much more efficient way of suppressing these proprioceptive prediction
and that's to send them back out into the world via our active states to change the
stretch of the receptors until the sensations match the top-down predictions so now these
descending predictions take on a very different kind of role they actually prescribe in the set
points for what is nothing more than a classical reflex arc sometimes formulated in terms of the
equilibrium point hypothesis so what we now have is a picture of the action perception
cycle that circular causality reduce now to essentially a predictive coding scheme of the
sort originally described by well many people but including david manford and people like
dana ballard and raj rail but it is now crucially made active because we've equipped it with these
reflexes so what kind of behaviors can you simulate or elicit or understand
under that predictive coding with reflex like construction you can get quite a long way so
this is one of my favorite examples that goes right from sort of willed action through to
action observation which speaks in a sense to theory of mind at a very elemental level
but remember we're just using reflexes that are realizing some deeply structured autonomous
dynamics that can be read as expectations or belief distributions about things out there
so here in this example i've used something called a heterotonic cycle a succession of
unstable fixed points quite easy to write down but what i've done here in the journey model
is map these mathematical fixed points to actual locations on a piece of paper
and i've equipped this model with the belief that whenever this location is active it will
pull my hand to it so i'm now predicting that my hand is going to be pulled to a succession of
fixed points and i've configured it in a way to make it look as if i will realization of those
predictions by these active reflexes will look a little bit like writing and so here it's in
action so this is the if you like a central pattern generator it's just this sort of
dynamical autonomous dynamics and internal states that underwrites what we think the world is doing
but we're actually creating our own sensations by realizing them in the world as perceived
visually through visual input and a sense through proprioceptive predictions so i'm supplying both
proprioceptive predictions that become commands that move my hand around and they supply the visual
sensations that are predicted in virtual having this explanation for a sensorium that i created
and this has many features that you see um um empirically so for example if i look at the activity
of these synthetic neural populations and i plot their activity when it exceeds half maximum
as a function of where we are on this piece of paper we see place selectivity celebrated by people
like uh jonah keef and furthermore a selectivity that not only plays specific but directionally
selective so this unit if you like lights downward strokes and not upward strokes the other um
appealing thing about this particular demo is that i can make another change and simply remove
whoops and simply remove the um descend the ascending um proprioceptive prediction error
so it's as if i was seeing handwriting but felt nothing so as if someone else was doing it for
me but of course i've got all the equipment in the generative model to make perfect visual
predictions about what is going on so in principle i can use exactly the same system and you can see
where we're going with this mirror neuron system to either prescribe and predict the movement via
active reflexes whilst at the same time um in another context using um uh the same model to
supply visual predictions in the um in the in the predictive coding sense to make sense of
the visual information that underwrites writing and exactly the same pattern of firing is observed
although it takes slightly longer to fill out the model to be informed by the ascending visual
prediction errors so we're nearly finished now um the reason i introduce that particular example
and emphasize the role of reflexes as fulfilling top-down predictions about what should be going
on and in so doing creating your own sensory input that looks as if you you made that um
is that there's another kind of um self-evidencing that i want to bring to the table at the moment
we've got this sort of conceptualization of the coupling between the inside and the outside in
terms of an action perception cycle where sensory input comes in we use that sensory input to do
our gradient flow so it looks as if we're optimizing beliefs about external states and then
those beliefs are being used to generate predictions to form a proprioceptive prediction
error that then we're resolving by um kinetics in our actuators our um strident muscles or
autonomic reflexes to change the external states so that they supply better data uh or data that is
predicted uh and this would be a simple explanation for elemental action and a lot of um homeostasis
but it's not apt to really to understand planning allostatic responses that rest upon the long-term
future consequences of any particular action to do that we have to move to something else
that Richard Freiman brought to the table which is technically a path integral formulation
of quantum electrodynamics and integration schemes or converting integration schemes and
optimization schemes through a path integral of a free energy which i'm denoting here by
an expected free energy in the future consequent upon a particular action so previously we were
talking about the perception part the perceptual inference as the gradient flow that looks as if
it's optimizing this free energy functional minimizing it um if you're a statistician you'd
actually decompose this um free energy into something called complexity and accuracy so you
you can simply um rewrite the expression for free energy which is normally cast as a an
evidence bound on log evidence the probability of some sensory data given a model and rearrange it
into complexity and accuracy so minimizing or self-evidencing by minimizing um this variational
bound on log evidence is exactly the same as trying to minimize prediction or maximize the
accuracy of my predictions whilst minimizing their complexity the KL divergence between my posterior
beliefs about states the world and my prior beliefs the num the degrees of freedom i have to
use in belief update and move my internal states to provide the simplest possible explanation that
is accurate so this is really just a statement of Occam's principle here but when we take the
expected free energy the complexity and accuracy take on a very different interpretation so if i
take the expected complexity accuracy under the predicted outcomes that would ensue following an
action this complexity cost here becomes risk it's just the basically the difference between
what i anticipate will happen what i priori think will happen or prefer to happen in terms of writing
down uh the kind of external states associated with my um the maintenance of my attracting set
the accuracy or the expected inaccuracy becomes ambiguity so i will make moves i will choose
actions when self-evidencing then look as though they're panning they're panning in two senses to
minimize and risk in relation to my preferences whilst at the same time minimizing ambiguity
for example just turning on the lights to resolve uncertainty about the external states or maximize
the coupling between the external states and the sensory states um in the in the visual
neurosciences this is sometimes known as a as a base in surprise or salience and this slide just
gives you a few other interpretations of this decomposition of an expected free energy when
we think about selecting actions that underwrite a minimization of free energy in the future
predicated on this notion of expected free energy so here i've just rewritten the complexity and
the accuracy of the free energy that become now risk and ambiguity and expected free energy
in a similar way we're talking before about the free energy being an evidence bound the machine
learning that's an evidence lower bound to also known as an elbow and that simply means that
i can write down the free energy as the log of the evidence under a particular model or mark of
blanket plus this non-negative quantity which is a a bound or kale divergence between my beliefs
and the true posterior distribution of external states given my sensory states the equivalent
of the bound and the evidence in the expected form actually in unpacks is a very interesting way
as an intrinsic value an extrinsic value or affordance of any given action and so let me just
take you through that briefing ignore the extrinsic value for the moment look at what this means and
when you interpret this from the point of view of an information theoretician it's just the mutual
information between the causes the external states hidden behind the mark off and the consequences
the sensory states which is just the degree of belief updating in terms of the information gain
afforded by beliefs about external states if i could see in the future the sensory states that
followed an action compared to if i couldn't see them so it's the amount of uncertainty that i've
resolved about in terms of my beliefs about the causes of my sensations if i committed to that
action so that's good um let's now um take um a particular part of uncertainty away and specifically
let's remove the ambiguity let's just assume we can see the external states so the s's and the
e to the external states become the same thing and then we're just left with this term which is
called risk so this is just the difference between my preferred um states of the world
sensory samples of those states and my expected states in other words the divergence between
what i anticipate will happen and what a priori i prefer to happen that underwrites this attracting
set that defines who i am so this would be known in engineering as KL control in economics is known
as risk sensitive control final move is to take away the other kind of uncertainty which is the
risk really or the uncertainty consequent upon an action and then if i do that i have left just
with the extrinsic value here and that can be interpreted as we started um in terms of utility
negative cost or loss or expected value the kind of imperatives that would underwrites a
basing decision theory in the absence of any kind of risk or ambiguity so in the this return
to the visual neuroscience and give you uh and turn to our very last example
this really a way of formalizing epistemic affordance um the intrinsic value of looking
over there or as opposed to looking over there lends um an interpretation under the notion of
salience so you can now think of a map of if i looked over there how much information game would
i have and then you can put that information in a map leading to the notion of a salience map
and this is exactly what people in visual search and the visual neurosciences use when trying to
understand say eye movements or sequences of eye movements so i've cartooned that here let's assume
that the some the image being sampled could only be sampled in a limited way with a revealed sample
in this little portion deleted by the circle here and given this equation i can evaluate the
expected free energy or the salience uh in terms of the information gain i got this information
how much uncertainty does it resolve about whether or not the stimuli were caused by this particular
face and i can move that circle around and i can compute every point in the image the information
gain of the salience oh we have a salience map and this salience map almost exactly captures
where people actually look so this is from the classic work of yarbas where action here is an
ocular motor action of visual palpation that seems to be driven or certainly a sufficient
empirical explanation for this kind of active vision or active sampling of the world certainly
seems to be salience as described by the expected free energy and we can simulate that and build a
little or a deep small genetic model that is equipped with this expected free energy in the salience
map and ocular motor reflexes and actually simulate visual searchers and watch the synthetic subject
resolve her uncertainty about what she's looking at so in this example the universe is very simple
for the synthetic subject she can either be looking at an upright face a sideways face or an upside
down face so she will now in compliance with the self-evidencing choose those actions that resolve
the most uncertainty or have the greatest in information gain in terms of disambiguating
between these three hypotheses about states of affairs out there and these circles here show
the limited foveal information that she can acquire or garner with a particular eye movement
and this is the pattern of eye movements shown in this little movie over here and what we see is
that she goes straight for where she thinks there's going to be information or same information
around the eyes or the noses sometimes checking the forehead to make sure that the face isn't upside
down and as her beliefs are updated during this process of planned evidence accumulation
in this sort of generalized or sort of formal way of describing self-evidencing the salience
maps change as a certainty is resolved and certain parts of the image lose their epistemic
affordance these are the visual samples and these this is the shrinkage of uncertainty
that occurs between and within different eye movements as more evidence is assimilated by
her evidence accumulation or belief updating or if you like generalized predictive coding
and ultimately she comes to infer that indeed the face that provides a best explanation for this
sequence of samples is indeed an upright face here enabling her to hold this belief with confidence
so that's it and I'll give the last word to Helmholtz who summarized everything I've just
said much more now concisely and eloquently each movement we make by which we alter the appearance
of objects should be thought of as an experiment designed to test whether we have understood
correctly the invariant relations of the phenomena before us that is their existence in definite
spatial relations so with that it only remains for me to thank those people whose ideas I've been
talking about and of course thank you for your attention thank you very much indeed
thank you very much Professor Friston for this truly amazing talk so we still have some
55 minutes left for Q&A and so I would suggest to proceed in the following way
so there are some people who ask some questions during the talk and so we will start with those
first and if you have a question just type Q in the chat and we will just go chronologically okay
okay so the first question was from Elke Spak he says or she says in this simulation
was the boundary between the internal and external states constructed manually in quotation marks
or did it self-emerge?
So in the simulations of the primordial soup it was an emergent property
so just practically speaking only certain systems actually attain non-equilibrium
steady state so when you write down these equations of motion three things happen either they completely
explode and never converge like a dissipating gas a hot explosion or they
freeze and become a very crystalline uninteresting structure so what we do is we just adjust either
the amplitude of the random fluctuations or the parameters of deterministic chaos that is used
to underwrite this sort of electrochemical dynamics of each of these little particles or
macromolecules to get it into a Goldilocks regime where you have interesting non-equilibrium steady
state when you when you do that when there is a system that has attained some kind of non-equilibrium
then for free you will get a little universe of Markov blankets so it's a great question because
well the answer is no your Markov blankets emerge in the right kinds of systems and usually those
kinds of systems are those that describe the worlds and the eco niches in which we survive by
definition um however that doesn't mean to say there's just one Markov blanket so what we did was
pick the most connected eight macromolecules and just having to define those are the internal
states of interest then you can go in and ask what is their Markov blanket that will always exist
sometimes in certain situations it will be a trivial or an empty set but mathematically it
always exists good good um all right uh so the next question is for us and Hank already
answered but just repeat for everybody else yes this these recordings will be available on our
web page and we will communicate when they're online through the mailing lists and channels
through which you heard about this talk in the first place all right so Juan Felipe Miranda Medina
asks what is the difference between perceptions and sensations sorry the question is still on entry
oh it's not at all I would imagine that there are books written in philosophy about that difference
from my point of view and it's very simple a sensation is just the state of your sensory organs
or the sensory part of your Markov blanket so it's just the the activity or the state of your
um sensory receptors say filter receptors or chemo receptors so the things that you used
to sample the environment the the perception brings a little bit more to the table so
if you look at the process of perception as a process of inference that is one interpretation
of this fundamental gradient flow on the internal states then it's much more of an internal
constructive dynamic process where you are understanding say neuronal dynamics as encoding
or parameterizing beliefs about the causes of the pattern of sensory input so the the perception here
would be if you like associated with the state of your brain or your internal brain state say
in a visual portable hierarchy um you know the the way that you would mathematically talk about
the perception part of it um sorry let me say so if you're a physiologist um and I said um then
then you would be happy looking for the neuronal correlates of perception deep inside some hierarchy
deep inside the brain um that was representing some abstract feature or level or attribute
of some hypothetical object that was the best explanation for your sensory input
if you were a statistician you would be asking um does the state of the brain or neuronal populations
in uh how can you understand that in terms of an information geometry the information of
representation um and so technically um if you and by definition this is the case
associate the state of the brain at any one moment with a probability distribution over
something else and this is the external states then technically what you what you induce is a
statistical manifold over which internal brain states move and that movement has a particular
geometry called an information geometry which allows you to write down things like precision
and confidence and distance and metrics um in terms of things like the curvature of that of
that statistical manifold that's technically very interesting certainly in terms of building
synthetic machines that do perception efficiently um and understanding the key role of confidence
and how it relates to uh curvature and precision and neurochemistry um I was just wondering from
a philosophical perspective it also I think brings something very important to the table that you've
got a mathematical description of physiological brain states that now requires an information
geometry that is only articulated in terms of beliefs about something so it has a um you know
in a layman's sense a representational aspect which you didn't have before if you just look at
correlations between neural activity so that's another important distinction between sort of
perception and sensations you know the mechanics and the interpretation of perceptual dynamics
become much much more interesting vexed and important good good thanks very much uh so the
next in line is uh walker trimble so go ahead unmute yourself and ask your question all right
thank you let me try and unmute my I can't unmute my camera here I'm sorry uh so can this
be used to explain much larger causal relationships that are much more complex
such as the um the relationships that we see between um irregular verb forms in across language
paradigms and individual learning patterns in language so where you can see you have something
that we where we've got patterns that emerge within an individual such as in language learning
and then on a vast scale such as irregular verb forms within the language within a language or
let's say population distributions like that famous paper about the the number of the relationship
between links and uh and and snowshoe hairs where you've got you know vast scales where we can't
really establish very clear causal relationships between these rare things where there are huge
numbers of variables a lot of noise uh can this help us to understand these kind of vast causal
can establish a causality between what would certainly hope for hope so I mean that that's
quite a challenging question so you'll know I mean all I was talking about in in this particular
presentation um was a very sort of particle-centric perspective an explanation of the implicit
self-evidencing and and Bayesian mechanics what you'll bring to the table now is well let's put
lots of particles together and we and um furthermore introducing the notion of um particles of
particles where the Markov blanket is now not at the states of any given particle but actually
a set of particles and so on in any sort of hierarchical nested way to any scale that you
might want to consider so in terms of you know can you scale it up to talk about ensemble dynamics
where you know where you've got a collection or ensemble of sentient particles or in the
surface of trying to minimize their own expected free energy and by implication because free energy
is an extensive quantity collectively doing the same thing what you now have is a mathematical model
of coordination communication cooperation that should in principle conform to exactly the same
mass and I think I think it's an important observation that is being pursued hasn't been
pursued enormously um over you know sorry let me put it off another way it's something of current
interest that is being vigorously pursued by a number of usually young people um in a variety
field sometimes known as um eco niche construction um in terms of theoretical biology um sometimes
taken into the um the cultural domain so when you know one might look at some aspects of language
acquisition in terms of cultural eco niche construction the special twist here is that you
sort of treat the environment and the person as two Markov blankets that are both trying to infer
the other so the environment is just an active player trying to learn about the denizens um
or the phenotypes that that particular eco niche contains and some lovely arguments about desire
paths and elephant paths emerge from that perspective as the environment starts to infer what kind of
agents or phenotypes uh are most suited or most likely to be found in that environment
whilst at the same time the phenotype is trying to learn about the environment and how it works
so there's this sort of collective convergence of a joint minimization of free energy there
but then you get things get even more interesting when you replace the environment with another person
so now you've got two um Markov blankets trying to predict each other and of course the best way
to maximize the mutual predictability to minimize the free energy or the self-information
is to both use the same generative model so the more that you um become like me the more
that I can use my predictions about myself to predict you and vice versa we become mutually
predictable and of course what are we saying we're saying basically our exchange
via our Markov blankets is a form of language and then we get into the game of you know how does
how does that those shared narratives or generative models elaborate themselves with more and more
particles or people in the game um and then you start to think about very deep generative models
sort that you might see in um and computational um language you know hierarchical Dirichlet models
for example and then we get to the very highest level questions which you are intimating
you know the exceptions and the shared exceptions and how they you know are found in and only in
one ensemble that has its own community Markov blanket from another ensemble so a lot of these
things a lot of things I've just mentioned have been written about uh within one or two papers
but my my my my my feeling is that they will um there's a lot of work to be done in these areas
um and the formalism afforded by the sort of um variational um uh account or formalization is
writing down this belief updating this coupling between um um Markov blankets
can take you quite a long way because you can start to simulate these things you can
have to start to simulate conversations and generalize synchronization and exchange of language
or songs um in a computer just to provide a proof of principle you're on the right track
I I have a follow-up is how in that case do you
oh sorry I'm sorry only if it's quick because we have
we have time late okay if it's quick okay it's quick uh how do you determine that the the agents
the individual agents then well if you're um sorry I might rather give a quick answer there
isn't a quick answer uh first of all there are agents at every scale so I think you just have to
determine the scale of you know the explanatory target of your particular study so I could identify
a single uh brain cell or its dendrites as the agent to Markov blanket I could look at a hierarchal
level in the visual hierarchy at a different person I could look at um you know sort of swarm
dynamics and ensemble behaviors of populations I could even look at the you know the biosphere
within each level there will be Markov blankets and Markov blankets all the way down to you know
to small particles so I think you just have to commit to a particular scale and once you've
done that you know the sort of granularity of the generating models in play so if you're into
language then you know that you're going to need quite a deep hierarchal generating model
probably a derisional like processor um uh hit the Markov model if you're interested in bird song
for example you can get away with say um continuous attractor dynamics you know we've used two a slow
and a fast the rents attractor to simulate the exchange of bird song the recognition of bird
song amongst agents so I think it's more a question of just you know what are you interested in
expanding or understanding or perhaps building you know if you're if you're in the artificial
general intelligence and machine learning world thank you all right uh so the next question is from
uh March in C go ahead oh okay sorry so uh he asks he says thank you for a great lecture
and uh I have a question does minimizing free energy guarantee that agents behavior
will be optimal in brackets intelligent or do you need additional constraints
so I'm just trying to find that oh I've got it right so we'll be um no um oh sorry um yeah
the the answer depends um really um on what you would take as a sufficient description of
intelligent behavior it will always be optimal in a rather deflationary sense because the whole
the whole notion of ideal basing observation observers and basing optimality um is sort of um
you're being used here um in the sense that the the basing interpretation of a variational free
energy is just um under um the constraints of approximate basing inference the optimal way
to do things in in fact um it's the only way to do things um but it does beg the good so that's it's
always optimal um but that's deflation the sense it can be no other once you've got some form of
non-equilibrium study state that is optimality defined in the sense you exist um I think the
more interesting question here is um what different kinds of geranium models would look more or less
intelligent um and I guess I was trying to speak to that by comparing contrasting the two simulations
of a very simple agent just using reflexes that was just realizing its internal beliefs about
what was going on by just waving its hand around and and writing with no real sense of the future
as opposed to this um much more sophisticated agent where she was actually thinking about the
consequences of action and planning ahead and going to responding to epistemic
affordances that she had computed in order to resolve uncertainty about what she would see next
I would say that's closer to intelligent optimality but in many senses a virus and a
thermostat are entirely optimal that is not very intelligent so if the question was about
intelligence I think you're talking about the different kinds of geranium models that will be
apt for describing um the world that you inhabit and if you inhabit a world that is also composed of
deep and sophisticated agents like you as we do then of course your geranium model is going to have
to have both a hierarchical depth and what Anil Seth sometimes calls the counterfactual depth
which implies a roll out into the future in order to um model the consequences of of my actions
so I think the intelligence bit probably lies in the structure in the form of the genitin model and
its depth all right thanks uh so the next question is from Zef Fassen he says uh thank you very much
for this talk and for your wonderful insights in general as you say this is the first principled
account of the brain uh how far do these implications reach for example Lisa Feldman Barrett has
created a new theory of emotion based on predictive coding in brackets in short
emotions are predictions close brackets uh do you know her theory and what is your opinion about
this way of using predictive coding in uh other in brackets less uh beta scientific disciplines
all right I'm tempted to ask what a less beta scientific discipline is um but yes and I do
know uh I haven't met Lisa but I do know we have corresponded on email and I know her work
and um I think that it certainly is entirely consistent with the first principle sort of
physicist account that we've been talking about but um is cast in the language of predictive coding
I think quite useful because predictive coding is one of a number of process theories to which
the free energy principle can apply so I'm using principle theory in a very specific way here so
the free energy principle is essentially a variational principle of stationary action like
Hamilton's principle least action it can be applied or it cannot be applied to certain processes
generally I would submit it can be applied to every process that exists but that's not
necessary for it to be a principle but the processes um acquire a theoretical theoretical
aspect so it could be that you could apply the free energy principle to understand
brain processing as belief updating under a whole raft of process theories and they could
include predictive processing they could include belief propagation they could include variational
message passing all of these are well characterized crisp and clearly formulated mathematical
message passing schemes and dynamics under different sorts of gelative models each time somebody
comes along with a new way well perhaps the message passing is like this um that's a new
process theory so predictive process predictive coding I think is the probably the most celebrated
and predominant at the moment what makes Lisa's approach special um it's the same thing that
makes the work of people like Anil Seth and lots of his colleagues at Sussex University
and beyond special it's a it's a focus on accounting for embodied interceptive states
so we were very much talking about predictive um processing active inference and active vision
where we're predicting um the visual consequences of moving um if you now take exactly the same
principles and apply them to our internal bodily states your autonomic sensations
then you can play exactly the same game and now um you have a way of writing down
literally feelings about the embodied self as this perceptual process but it requires some
special attributes first of all it's certainly your body and may underwrite a minimal sense of
selfhood and then you ask them why would you want that and then you get into uh notions of
which we haven't talked about which is um what are the homologues of attention and bias and
sensory attenuation under predictive coding and where the the predictions of um whether to attend
or dis attend or attenuate information from this domain or that domain come from a map come from
a gelative model and then suddenly you have a hierarchical model that's making predictions
not only about the state of the body but about which state the body should attend to um and at
that point you start to um get into the world where it would have the right kind of expressivity
to talk about um gut feelings and emotionality in the sense that there are certain bodily states
that I can explain by attributing them uh constructs or hypotheses such as arousal or fear
or love or your whatever way you want to carve up an emotional state space so I think that um the
work of people like Lisa and people like um Anil Seth um have really taken the uh the
fundamentals of predictive coding a really long way in drilling down on what it is to be
sentient with a body um so you know probably 99 percent of the world that we have to um our brain
has to model and synchronize with in this sense of generalized synchronous Huygens like sense
is actually our body it's not actually what's out there it's it's all the bits of our body that we
have to we have to uh predict and um and um synchronize with
great uh thanks so the next in line is Nestor Timonidis who says thank you very much for the
enlightening lecture uh from a behavioral point of view uh how does seeking knowledge
fit into the framework of minimizing free energy or surprise?
Excellent question um so surprise and free energy um is a central construct um and
stands in for for self-information um and sometimes that can lead to um an anthropomorphical
um intuition that in order to minimize surprise I just need to make everything completely
predictable which is certainly true uh which itself then leads to uh what philosophers have
sometimes um talked about in terms of the dark room problem that I should just basically go away
switch off all the lights lie down and then everything's totally predictable all my surprise
is minimized and that would be a very um apt and appropriate uh generative model instead of
prior beliefs if you could survive forever lying down in the dark and some creatures can
but that would not be a good model a low free energy model for something like you and me the
first thing we do is to go and switch on the lights um why do we do that? Well because those are the
actions that minimize expected surprise so what is expected surprise? Well it has this um this
intrinsic and this extrinsic value or you can carve it another way in terms of risk and ambiguity
so the imperatives that underwrite those actions that will minimize
expected surprise consequent upon those actions have in them this novelty they have this um
artificial curiosity um which is that's a term in um so the worker you're going to smithuba
in the in your bot neuro um botics um it's also called intrinsic motivation that's part of
expected surprise minimization um and um that's what I meant by salience so salience scores
the information gain that you would get if you did that so these are the moves that um afford
that are have an epistemic affordance of the kind that um underwrites novelty or novelty seeking
or sensation seeking what would happen if I did that um I'm pausing slightly because there's a
slightly technical distinction between salience and novelty so both can be ways of us um affording
um or uh endowing certain behaviors or certain courses of action with an epistemic affordance
that resolves expected surprise um however about what if it's about states affairs we generally call
that salience if it's about the parameters of the gerative model the lawful contingencies um
then we normally call that novelty so when learning a new environment we're not really
resolving directly where we are in that environment more what's behind that door if I go around that
corner what will I learn can I go down that route and that's what we call we'll call novelty I'll
just close by um this pointing out a very simple semantic trick that allows you to resolve the
apparent dialectic between minimizing surprise and maximizing novelty in the sense that if
surprise is uncertainty um then expected surprise sorry if expected surprise is uncertainty
then by minimizing surprise in this expectation you are essentially minimizing uncertainty and
minimizing uncertainty is basically the drive for sensation seeking and novelty and novelty
seeking and it's a central part of explaining most interesting behavior particularly when
with this planning as in-prince perspective on minimizing expected free energy so in information
theory um surprise is known as self-information expected surprise is expected self-information
that's entropy entropy is a mathematical expression of uncertainty so minimizing surprise
is minimizing uncertainty good uh all right uh so the next question is from christoph molatter
he says a point of clarification um uh marker blankets per suppose a Bayesian network which
is a directed uh acyclic graph in brackets d a g uh in a d a g no feedback loop is possible yet
later in the talk the visual neuroscience example includes many feedback loops i'm certainly missing
something but how do you reconcile acyclic dag assumptions necessary for identifying marker
blankets with modeling in brackets such as the one with the visual system that imply circles
error in the course but that's a very technical but excellent question um so first off um the the
the graphical models that we use to describe a universe and a a particle or a creature within
that universe um is not acyclic um so the markoff blanket just certainly require the
absence of certain conditional dependencies that that is how it is is defined but there is a larger
circular causality and therefore loop loopiness so these are not directed acyclic graphs so we're
not constrained to um the markoff blankets that you will read about if you read about causality
in bayes nets that are for static probability distributions these are more um these are markoff
blankets that would apply to dynamical systems and in the sense that applying to dynamical systems
you can sometimes understand that as rolling out in time and because you're rolling out in time
and you don't have influences that go backwards in times you can actually reroute read a rolled out
loopy cyclic directed graph as a dag or directed acyclic graph in virtue of the fact that they are
dynamic so the markoff blankets that we deal with are slightly more complicated objects than
you will read about in standard um bayesian treatment of bayesian nets however the question
about well how can you get all these reciprocal connections um in a visual cortical hierarchy
is an excellent question because um you could easily answer that and say well look and you know
there is no markoff blanket on the inside the markoff blanket defines the states that comprise
internal states and all of these neuronal populations are just um uh examples or instantiations
of internal states but i think that would be um disingenuous because of course we said that there
are markoff blankets at different scales and one of the most important um illustration or
manifestation of a markoff blanket structure within the brain is the hierarchical organization
that lends it this deeper hierarchical structure it is exactly the same in conditional dependency
structure um that you find in deep learning networks so this is there's something quite
fundamental about the about things like hierarchies and the um similar conditional dependencies
underlie mean field approximations that allow us to think about separate bottom wear streams in the
brain um so all of these um aspects of functional specialization segregation if you're talking about
functional anatomy from the point of view of a brain scientist are statements about mark markoff
blankets the very fact you can segregate one part of the brain from another part means operation
there has to be a markoff boundary or a markoff blanket so now the game is which connections are
not in place in terms of these neuronal reciprocal recursive connections and which are
and the understanding that sparsely structure is of course just understanding the connectome
and the implicit factorization and hierarchical structure that is implied by that connectome
and if you understand that you can start to understand the form and the structural majority
model that is entailed by that structure and you can start to ask is it a really deep one
is it a shallow one how many factors does it have do we have more than just what and where
so in answer to the question um you don't need DAGs but you do need to think very carefully
and exploit the the utility of markoff blankets in a more generalized application in a more
generalized setting all right so the next question is from Calle Timperi who says
thank you for a very exciting talk I can one think about the emergence and evolution in
time of markoff blankets does the mathematical form of model implicitly will predict changes
in or creation of new markoff blankets uh as the surrounding ambient system
is changing in time and could this be framed in the theory of non-autonomous dynamical systems
and or bifurcation theory in deterministic dynamics or in systems perturbed with noise
there are three really intriguing themes to this question I'll deal with the sort of more technical
simpler one first and then turn to the other two so more than it could be framed in the theory of
dynamical systems and bifurcation theory perturbed with noise it is and it's nothing
that it has to be so the the the noise gets in when we as soon as we commit to using a
launch van formulation and remember the launch van formulation is the thing that underwrites
quantum physics classical mechanics and statistical mechanics there is nothing else really very
interesting so deterministic dynamics is interesting in a limiting case and probably
its place is homolog would be um sort of the classical mechanics of um and and body problems
for example but more generally we're talking about random fluctuations and noise perturbed
dynamics and the chaotic aspects so we're talking about stochastic chaos why well
if you remember I said before there are two there are three things that can happen when you
actually simulate little universes they explode into infinity or they perform a pointer tractor
with a crystalline structure and do absolutely nothing they're frozen there forever
and the the the interesting domain is stochastic chaos so I don't think there is anything else
really um so that would be the first thing um the second um the second um sorry just just
the technical bit so often cast in terms of random dynamical systems so you're now looking
at this as a physicist in terms of a launch van formulation and from that you derive
your pocker plank and scrolling wave equations or you can look at this from
from the point of view of um random dynamical systems um or you can look at this from the
point of view of stochastic chaos mathematically I think the law basically the same thing the
the the evil the emergence of um Markov blankets in time that's really interesting um I should say
that the um the current formulation of maths really does assume you are actually at non-equilibrium
steady state so it does not allow for um sort of the fusing and the merging and the wandering of
Markov blankets or children emerging from parents and then themselves engendering children
other than to um to actually look at the entire generational tree as one big um sort of a gothic
system as it goes around sort of you know its life cycle reproduction cycle that's a complicated
challenging um thing to account for under the most simplifications this month so that's something
I think that someone hopefully will do um in the future um having said that though um there is I
think a lot of mileage and understanding evolution of phenotypes where remember to be a phenotype
you have to have a Markov blanket so when we're talking about the theoretical biology of evolution
of phenotypes we are talking about the um the um the evolution of Markov blankets I think that then
you can um and again in a crisp and clear way apply these variational mechanics to explain this
it's a very simple move um that can be heuristically remembered by noting that in statistics the
optimization of variational bounds and model evidence namely variational free energy is called
basic model selection so you have a number of competing generative models or hypotheses about
this given set of data um and then you score your different hypotheses in terms of the model
evidence or their variational free energy and then you select the one that's got the most evidence
aka the the marginal likelihood now with that semantics in mind um then you can easily see
how easy it uh you can easily see a way of describing natural selection as nature's way
of doing basic model selection by selecting those phenotypes that have the um the the least
free variational free energy or the greatest marginal likelihood of existing so there's a
beautiful if you like and simple connection between basic model selection and natural selection
both of which are underwritten by um either the model evidence or its variational
proxies that can be evaluated the other way of looking at this is to go in and ask um in terms
of evolution do the established mechanics um have the look and feel of the gradient flow on a
variational um free energy or a a self-information uh function and yes they do so the price equation
replicated dynamics they and a it's um a multi simplification are formally identical now the
same functional form as that gradient flow that I described before so they are actually
in linear cases just common filters so this then licenses an understanding which many people
have pursued not many three people I know have pursued in the past decade um licenses an explanation
of evolution as really the environment or the evolutionary process as accumulating evidence
for the kinds of phenotypes that it's most that are most likely to inhabit it so you know you're
now looking at evolution as an evidence accumulation scheme a Bayesian engine that's trying to if you
like test out different hypotheses where unfortunately we are the hypothesis we are we are the feeder
time that may or may not get selected so I think I think that sort of style of thinking in theoretical
biology is probably the you know the most useful in terms of uh talking about how your Markov blanket
itself can optimize it you know the optimizing ratio to its marginal like or its or its evidence
all right so thank you very much all right so the next question is from uh Tuomas Pernou
who says thanks for a great talk uh and then asks uh how would you say your approach connects
to control theory uh for example you mentioned common filter either classical control theory
and or perceptual control theory and would you say that the control theory can be built on this
or would the connection go perhaps uh the other way around um I I think um again brilliant question
um I think both um you you could certainly pull out of this more generic um you know sort of um
variational principle um a um control theoretic optimal scheme or you could say look KL control
as used in engineering is in fact formally identical to an extended Kalman-Busey filter
and in fact that has been said um by people like um Emo Todorov uh no in fact he said that Kalman
himself said this so um the the math the functional form of a linear quadratic control
scheme in plant control and engineering is just a Kalman filter um so there's a direct
correspondence between the two when you go nonlinear you get an extended Kalman filter
which formally is exactly the same as the um the predicted coding that the people at the
Donders and we focus on uh when you put it in the hierarchical context so you know I think we're
all part and parcel of the same thing from my perspective things like control theory um are
if you like a special case of application of this more generic uh first principle approach
and particularly in relation to the KL control because the KL control really does emphasize
the minimization of risk and risk of course um entails a degree of uncertainty bringing us back
to the importance of belief distributions the importance of that noise when treating things in
terms of stochastic chaos that has to be part of it so you know this is a grown-up control theory
um you know not just feedback control um the the other part of the question there is interesting
so perceptual control theory I can't see him visually oh no there you are no you're not no
that's Walker Trimble um I was going to ask um uh the question though if they wanted to
describe perceptual control theory does anybody want to describe perceptual control theory
excellent good please do you have to unmute yourself
okay sorry I'm actually not an um uh expert on on perceptual control theory but um
it's something that people have been talking about since the early 70s already where uh
you should think about cognition as uh so it's it's it's fitted in this classical control theory
framework where you can uh think about um cognition as a control process controlling
perception not actions directly so yeah I was just thinking that since this is what we're talking
about in in kind of this mental mental framework whether this is something that you would uh find
uh fitting in your approach yeah no absolutely um and Neil Seth in particular um
a colleague of mine uh Warren Mansel uh have been championing um powers is perceptual control
theory um for some time and it certainly is exactly consistent with with active inference
um I'm not sure it's exactly the same thing but I always remember sort of turning on its head of
action and perception as as basically moving to keep a ball in you know in in the same line of
sight is quite sufficient for very skilled anticipatory movements imagining where the ball
might be when you want to catch it that just basically controls a very elemental low level
features of your um of your perceptual domain uh makes it look as if you're actually quite skilled
in terms of planning but actually it's a very simple procedure and I think the spirit of that
is exactly the same that I was trying to get up with um this sort of reflexive sort of action
that you just need to to know what is likely to happen in this very limited domain that you know
the reflexes can can if you like fulfill in order to produce systems look as though they're actually
quite um sophisticated and quite creative to can do handwriting but all that is happening there
all the heavy lifting is being done by the muscles responding to these delicately and deeply informed
predictions you should be that length or that length so all the control is in this very very
simple state space of proprioception so you know the trick is then that uh or I guess that um powers
its insight was really um you know the actual action is is you know is quite simple um provided
and that's what matters in terms of making moves on the work on the world and exchanging with the
environment that's what your underwrites your auto poesis and your self assembly and your existence
but it does depend upon having these deeply informed and veridical and realizable predictions
where the perceptual part comes in and these deep charity models um are requisite but at the end of
the day it's just in the service of controlling those sense the sensations um that you can control
right thanks all right any further questions or comments for Professor Friston
we still have some I have just a brief comment if I might okay go ahead uh I I was struck by
how uh your part of your argument not just the kind of ecological uh elements of it with
affordances and whatnot uh resembles uh Samuel Taylor Coleridge's uh idea the perception is
imagination and it's it's seemed like quite a beautiful uh confirmation of that after what
250 years ago it was so it seemed like uh it resembles it in some of his theories in some
interesting ways but then you should write that out for ticks or something then I didn't know that
I in many areas I'm um what Jerry Edelman used to call an intellectual thug so I wasn't aware
that that does sound very interesting um and certainly um resonates with this notion of the
brain as a um a fantastic organ you know so everything is a fantasy it's just those fantasies
that are sufficient explanations for the sensorium that are selected by this process of internal
Bayesian model hypothesis selection um you know so they're all um you know we we basically
waking perception is what people refer to as as sort of um dreaming or hallucinations that that is
entrained or constrained by sensory impressions that that starts to um have a bit more pragmatic
or practical uh traction when you start to uh simulate things like sleep and dreaming
where you do actually talk about sort of um training yourself in the service of a particular kind
of Bayesian model selection which is actually getting rid of um unneeded or redundant parameters
using fantasy data so you generate fantasy data from your geriatric model and then you try to perceive
it and learn from it um thereby acquiring a much simpler a much more efficient and simpler
explanation for it so fantasies and imagination um may play an vitally important role not just
during sleep but also just in terms of introspecting and thinking about things as the device that um
minimizes the complexity of our explanations for things that the road to those aha moments of
simple insight oh it's just one of those or these are the same thing so these do require if you're
like um an updating the structure of the underlying genetic models that one could easily motivate as
necessitating your imagination as you know as the accompanying um the accompanying process
that does that so if that's if that was known several centuries ago you should you should
tell people i'll i'll send you the reference all right um we still have some six minutes left or
maybe less for a quick question maybe
and if not
all right
right uh so yeah sorry may i ask may i ask a quick question still sorry so i was i was
previously here no because i'm just asking about this formalism because it's this longevity
interpretation of things and and and so like on the technical side like the interpretation of
noise or the randomness is a kind of particular one in this and so i guess like you typically
could be like a brown in motion based or or some kind of Gaussian so but but but you could think
of other ways of modeling the noise let's say a bounded noise or this kind of thing and then you
could perhaps like because i'm i'm looking actually at bifurcation theory in dynamical systems perturbed
with bounded noise and you tend to get a different kind of picture and maybe you can overcome some
difficulties that are associated with this let's say the the more prevalent this kind of Gaussian
interpretation so so so do you think that a different kind of formalism could could or
different kind of formalism for the noise in particular could still accommodate this theory
but that would be the question it's a very technical it is i shall give you um as technical
an answer as i can um just to just to frighten off the rest of the audience so they go and
have a cup of coffee in the cigarette so the um so first of all i you know i think that um the
you know the analysis of dynamical systems in terms of bifurcations and the like and and
all the different ways that you can engineer and understand itinerancy is vitally important in this
game because all of the interesting simulations and realizations of behavior under this formalism
at some point rest upon bifurcations or you know deterministic chaos that then becomes
equipped with noise in some instances to give you stochastic chaos simple examples will include
that lotterra heterotonic cycle under right set pattern generators without which you would never
get movement you could never simulate movement so i think i think there's your the the dynamical
systems understanding of the functional forms of internal states and external states as they try
to mirror and predict each other is vitally important for this itinerancy that we'll talk
about before that my eyes between the the frozen crystal and the exploded gas um so the
slightly more technical question is you know you're right with normally treatments of uh
launch van equation um immediately um employ markov norvina assumptions and you can get very
quickly and gracefully to sort of simple focacoplank equations and the alternative formulation in
terms of pathological formulations um however they are not limited to that um the maths gets a
little bit more complicated certainly you know the focacoplank formalism when you want to um
when you want to write down the ensemble of the density dynamics of systems that have
non markovian random fluctuations not impossible but you know it just gets a little bit more difficult
to follow through uh follow through the maths um the way that it's handled um in sort of vanilla
treatments of the um of the particular physics under rights of free energy principle is to use
an adiabatic approximation just say that basically there are states where where do states come from
well we'll assume that states are basically the states of markov blankets and that once we've
done that we can hierarchically compose uh um markov blankets and markov blankets and then
we have an emergence of states but states come into flavors they come in terms of states of the
system and the random fluctuations so what licenses mean to even before I write down
a long drug formalism what what licenses need to actually just write down the difference between
x and omega and then what we normally say is well we'll just assume that these things are really fast
and these things are really slow right but when we generate using um technically a renormalization
group theoretic approach when we generate states from states what we do is sort of just split the
fast stuff and give that to the the fast stuff goes to the fluctuations and the slow stuff goes to
the states and then we get a dimension reduction or course grading for free and then we can sort of
compose states of states of states in that setting um the the random fluctuations actually lose
strictly speaking a markovian or venalite behavior on two counts first of all um they um can potentially
be non-gaussian they can be heavy-tailed because they are now non-linear mixtures of states that
inherit from the from the scale below and second and possibly more interesting from the point of
view of coping with the foc-a-plank part of the story that they have serial correlations so they
become analytic so then they don't have that venal conditional independence property anymore
so that's another interesting richness that you bring to the table when you actually look at real
random fluctuations um at the moment we tend just to ignore that in mathematical treatments
but that but certainly the latter kind of serial correlations becomes absolutely essential
when dealing with predictive coding on the fly when simulating eye tracking for example
you know you really you know the markovian assumptions are just not fit for purpose we use
generalized quads and motion to articulate the the dynamics of the the state the rate of change
the rate of change up to about six orders that usually and then you can recover a venal assumption
in this generalized generalized state space the heavy-tailed stuff um yeah i don't know about
in terms of random fluctuations but i do know in nearly every generative model of interest
for example things like independent component analysis you know you really do rely upon these
non-linear or heavy-tailed assumptions to get interesting stuff out okay all right and this
is exactly the this is exactly on time so it's time to stop and let's all together thank professor
fristen for his wonderful talk and i'd like to thank you all for your very insightful questions
i'd like to say that i'm really pleased that we end this year's run of the lecture series
with such a bang and next year next talk in the series is on 7th of january at 6 p.m. central
european time but that's 6 p.m. Amsterdam berlin paris and our guest speaker will be
professor patricia churchland and i'm also very excited about that and i hope i'll see
many of you that other than that i wish you happy holidays happy new year and so that next year
with the vaccines underway we actually managed to see each other in person so happy holidays
ciao ciao bye bye
