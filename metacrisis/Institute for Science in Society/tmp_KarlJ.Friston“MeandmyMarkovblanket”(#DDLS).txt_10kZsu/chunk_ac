we can call that perception by changing predictions currently we can change the sensations at a
sample to make them more like the predictions and that's also minimizing prediction error
and by changing sensations you know I mean very simply looking over there as opposed to looking
over there palpating the world in a way to solicit sensations that minimize prediction error or
maximize model of evidence as scored by this variation free energy and again we come back
to this notion that both perception and action work hand in hand in the service of self-evidence
and to form a prediction error and to realize the functional form of that gradient plural predictive
coding we need to be able to generate the predictions and I mentioned generative models that
one would imagine that the kind of generative models that we use are deeply structured now
the hierarchical form the very dynamic I've sketched that out here so imagine I set you the task
of generating some sensory data sampled by the fovea in your eyes so what you would have to do
was basically work out what was causing that pattern of sensory stimulation all the dynamics
and kinetics involved in where you and how you are sampling that object here a face and then
compose through a cascade of hierarchical or deeply composed hierarchical levels
these causes until you could actually generate the sensory data I've just written that down here
schematically in terms of causes causing causes causing causes ultimately causing sensory states
or sensory input with random fluctuations here so that's if you're like a model that you might
use to explain or generate sensory visual sensory input so what scheme what internal dynamics
would be implied by this sort of model well we know exactly what the answer is because we
know that it has to be this gradient flow here written in terms of a calm and bucy filter or
predictive coding and when we put that in play what we see is a following computational architecture
we swap out the random fluctuations for prediction errors and equip this with these ascending
influences such that the expectations about the world are informed by updated by the prediction
errors so we now have an architecture that comprises this kind of message passing where
you have these counter streams of ascending predictions and ascending predictions that
looks very much like what you see in the actual brain where these are superficial pyramidal cells
and these might be deeper pyramidal cells so let me run you through that from the point of view of
neurophysiology in the visual system and beyond let's say that we have some visual input here from
the retina it comes in to the lateral geniculate and it has some top-down predictions that enable
the lgn the lateral geniculate nucleus to evaluate or to compute a prediction error
that can then be sent forward to update primary visual cortex cells that have beliefs about say
edges and other elemental features of the world but these elemental expectations themselves
are subject to top-down predictions that create a secondary prediction error that can then be
fed forward to update beliefs in a higher level of our hierarchy and so on to any required hierarchical
depth so this is a description of sort if you like a deep inference in the in the same sense as deep
learning in machine learning where you're trying to find a minimum prediction error maximum model
evidence minimum free energy explanation by optimizing those implicit objective functions
through a gradient flow that we know has to be in plane so where's action in this model of perception
well let's look at another kind of input proprioceptive input from the ocular motor system
that comes in it goes into nuclei and the pons and will be will be predicted by sending
predictions from certain frontal eye fields and we have a proprioceptive prediction error
that could be sent up to update our expectations about where we're pointing our eye however
there's another much more efficient way of suppressing these proprioceptive prediction
and that's to send them back out into the world via our active states to change the
stretch of the receptors until the sensations match the top-down predictions so now these
descending predictions take on a very different kind of role they actually prescribe in the set
points for what is nothing more than a classical reflex arc sometimes formulated in terms of the
equilibrium point hypothesis so what we now have is a picture of the action perception
cycle that circular causality reduce now to essentially a predictive coding scheme of the
sort originally described by well many people but including david manford and people like
dana ballard and raj rail but it is now crucially made active because we've equipped it with these
reflexes so what kind of behaviors can you simulate or elicit or understand
under that predictive coding with reflex like construction you can get quite a long way so
this is one of my favorite examples that goes right from sort of willed action through to
action observation which speaks in a sense to theory of mind at a very elemental level
but remember we're just using reflexes that are realizing some deeply structured autonomous
dynamics that can be read as expectations or belief distributions about things out there
so here in this example i've used something called a heterotonic cycle a succession of
unstable fixed points quite easy to write down but what i've done here in the journey model
is map these mathematical fixed points to actual locations on a piece of paper
and i've equipped this model with the belief that whenever this location is active it will
pull my hand to it so i'm now predicting that my hand is going to be pulled to a succession of
fixed points and i've configured it in a way to make it look as if i will realization of those
predictions by these active reflexes will look a little bit like writing and so here it's in
action so this is the if you like a central pattern generator it's just this sort of
dynamical autonomous dynamics and internal states that underwrites what we think the world is doing
but we're actually creating our own sensations by realizing them in the world as perceived
visually through visual input and a sense through proprioceptive predictions so i'm supplying both
proprioceptive predictions that become commands that move my hand around and they supply the visual
sensations that are predicted in virtual having this explanation for a sensorium that i created
and this has many features that you see um um empirically so for example if i look at the activity
of these synthetic neural populations and i plot their activity when it exceeds half maximum
as a function of where we are on this piece of paper we see place selectivity celebrated by people
like uh jonah keef and furthermore a selectivity that not only plays specific but directionally
selective so this unit if you like lights downward strokes and not upward strokes the other um
appealing thing about this particular demo is that i can make another change and simply remove
whoops and simply remove the um descend the ascending um proprioceptive prediction error
so it's as if i was seeing handwriting but felt nothing so as if someone else was doing it for
me but of course i've got all the equipment in the generative model to make perfect visual
predictions about what is going on so in principle i can use exactly the same system and you can see
where we're going with this mirror neuron system to either prescribe and predict the movement via
active reflexes whilst at the same time um in another context using um uh the same model to
supply visual predictions in the um in the in the predictive coding sense to make sense of
the visual information that underwrites writing and exactly the same pattern of firing is observed
although it takes slightly longer to fill out the model to be informed by the ascending visual
prediction errors so we're nearly finished now um the reason i introduce that particular example
and emphasize the role of reflexes as fulfilling top-down predictions about what should be going
on and in so doing creating your own sensory input that looks as if you you made that um
is that there's another kind of um self-evidencing that i want to bring to the table at the moment
we've got this sort of conceptualization of the coupling between the inside and the outside in
terms of an action perception cycle where sensory input comes in we use that sensory input to do
our gradient flow so it looks as if we're optimizing beliefs about external states and then
those beliefs are being used to generate predictions to form a proprioceptive prediction
error that then we're resolving by um kinetics in our actuators our um strident muscles or
autonomic reflexes to change the external states so that they supply better data uh or data that is
predicted uh and this would be a simple explanation for elemental action and a lot of um homeostasis
but it's not apt to really to understand planning allostatic responses that rest upon the long-term
future consequences of any particular action to do that we have to move to something else
that Richard Freiman brought to the table which is technically a path integral formulation
of quantum electrodynamics and integration schemes or converting integration schemes and
optimization schemes through a path integral of a free energy which i'm denoting here by
an expected free energy in the future consequent upon a particular action so previously we were
talking about the perception part the perceptual inference as the gradient flow that looks as if
it's optimizing this free energy functional minimizing it um if you're a statistician you'd
actually decompose this um free energy into something called complexity and accuracy so you
you can simply um rewrite the expression for free energy which is normally cast as a an
evidence bound on log evidence the probability of some sensory data given a model and rearrange it
into complexity and accuracy so minimizing or self-evidencing by minimizing um this variational
bound on log evidence is exactly the same as trying to minimize prediction or maximize the
accuracy of my predictions whilst minimizing their complexity the KL divergence between my posterior
beliefs about states the world and my prior beliefs the num the degrees of freedom i have to
use in belief update and move my internal states to provide the simplest possible explanation that
is accurate so this is really just a statement of Occam's principle here but when we take the
expected free energy the complexity and accuracy take on a very different interpretation so if i
take the expected complexity accuracy under the predicted outcomes that would ensue following an
action this complexity cost here becomes risk it's just the basically the difference between
what i anticipate will happen what i priori think will happen or prefer to happen in terms of writing
down uh the kind of external states associated with my um the maintenance of my attracting set
the accuracy or the expected inaccuracy becomes ambiguity so i will make moves i will choose
actions when self-evidencing then look as though they're panning they're panning in two senses to
minimize and risk in relation to my preferences whilst at the same time minimizing ambiguity
for example just turning on the lights to resolve uncertainty about the external states or maximize
the coupling between the external states and the sensory states um in the in the visual
neurosciences this is sometimes known as a as a base in surprise or salience and this slide just
gives you a few other interpretations of this decomposition of an expected free energy when
we think about selecting actions that underwrite a minimization of free energy in the future
predicated on this notion of expected free energy so here i've just rewritten the complexity and
the accuracy of the free energy that become now risk and ambiguity and expected free energy
in a similar way we're talking before about the free energy being an evidence bound the machine
learning that's an evidence lower bound to also known as an elbow and that simply means that
i can write down the free energy as the log of the evidence under a particular model or mark of
blanket plus this non-negative quantity which is a a bound or kale divergence between my beliefs
and the true posterior distribution of external states given my sensory states the equivalent
of the bound and the evidence in the expected form actually in unpacks is a very interesting way
as an intrinsic value an extrinsic value or affordance of any given action and so let me just
take you through that briefing ignore the extrinsic value for the moment look at what this means and
when you interpret this from the point of view of an information theoretician it's just the mutual
information between the causes the external states hidden behind the mark off and the consequences
the sensory states which is just the degree of belief updating in terms of the information gain
afforded by beliefs about external states if i could see in the future the sensory states that
followed an action compared to if i couldn't see them so it's the amount of uncertainty that i've
resolved about in terms of my beliefs about the causes of my sensations if i committed to that
action so that's good um let's now um take um a particular part of uncertainty away and specifically
let's remove the ambiguity let's just assume we can see the external states so the s's and the
e to the external states become the same thing and then we're just left with this term which is
called risk so this is just the difference between my preferred um states of the world
sensory samples of those states and my expected states in other words the divergence between
what i anticipate will happen and what a priori i prefer to happen that underwrites this attracting
set that defines who i am so this would be known in engineering as KL control in economics is known
as risk sensitive control final move is to take away the other kind of uncertainty which is the
risk really or the uncertainty consequent upon an action and then if i do that i have left just
with the extrinsic value here and that can be interpreted as we started um in terms of utility
negative cost or loss or expected value the kind of imperatives that would underwrites a
basing decision theory in the absence of any kind of risk or ambiguity so in the this return
to the visual neuroscience and give you uh and turn to our very last example
this really a way of formalizing epistemic affordance um the intrinsic value of looking
over there or as opposed to looking over there lends um an interpretation under the notion of
salience so you can now think of a map of if i looked over there how much information game would
i have and then you can put that information in a map leading to the notion of a salience map
and this is exactly what people in visual search and the visual neurosciences use when trying to
understand say eye movements or sequences of eye movements so i've cartooned that here let's assume
that the some the image being sampled could only be sampled in a limited way with a revealed sample
in this little portion deleted by the circle here and given this equation i can evaluate the
expected free energy or the salience uh in terms of the information gain i got this information
how much uncertainty does it resolve about whether or not the stimuli were caused by this particular
face and i can move that circle around and i can compute every point in the image the information
gain of the salience oh we have a salience map and this salience map almost exactly captures
where people actually look so this is from the classic work of yarbas where action here is an
ocular motor action of visual palpation that seems to be driven or certainly a sufficient
empirical explanation for this kind of active vision or active sampling of the world certainly
seems to be salience as described by the expected free energy and we can simulate that and build a
little or a deep small genetic model that is equipped with this expected free energy in the salience
map and ocular motor reflexes and actually simulate visual searchers and watch the synthetic subject
resolve her uncertainty about what she's looking at so in this example the universe is very simple
for the synthetic subject she can either be looking at an upright face a sideways face or an upside
down face so she will now in compliance with the self-evidencing choose those actions that resolve
the most uncertainty or have the greatest in information gain in terms of disambiguating
between these three hypotheses about states of affairs out there and these circles here show
the limited foveal information that she can acquire or garner with a particular eye movement
and this is the pattern of eye movements shown in this little movie over here and what we see is
that she goes straight for where she thinks there's going to be information or same information
around the eyes or the noses sometimes checking the forehead to make sure that the face isn't upside
down and as her beliefs are updated during this process of planned evidence accumulation
in this sort of generalized or sort of formal way of describing self-evidencing the salience
maps change as a certainty is resolved and certain parts of the image lose their epistemic
affordance these are the visual samples and these this is the shrinkage of uncertainty
that occurs between and within different eye movements as more evidence is assimilated by
her evidence accumulation or belief updating or if you like generalized predictive coding
and ultimately she comes to infer that indeed the face that provides a best explanation for this
sequence of samples is indeed an upright face here enabling her to hold this belief with confidence
so that's it and I'll give the last word to Helmholtz who summarized everything I've just
said much more now concisely and eloquently each movement we make by which we alter the appearance
of objects should be thought of as an experiment designed to test whether we have understood
correctly the invariant relations of the phenomena before us that is their existence in definite
spatial relations so with that it only remains for me to thank those people whose ideas I've been
talking about and of course thank you for your attention thank you very much indeed
thank you very much Professor Friston for this truly amazing talk so we still have some
55 minutes left for Q&A and so I would suggest to proceed in the following way
so there are some people who ask some questions during the talk and so we will start with those
first and if you have a question just type Q in the chat and we will just go chronologically okay
