or love or your whatever way you want to carve up an emotional state space so I think that um the
work of people like Lisa and people like um Anil Seth um have really taken the uh the
fundamentals of predictive coding a really long way in drilling down on what it is to be
sentient with a body um so you know probably 99 percent of the world that we have to um our brain
has to model and synchronize with in this sense of generalized synchronous Huygens like sense
is actually our body it's not actually what's out there it's it's all the bits of our body that we
have to we have to uh predict and um and um synchronize with
great uh thanks so the next in line is Nestor Timonidis who says thank you very much for the
enlightening lecture uh from a behavioral point of view uh how does seeking knowledge
fit into the framework of minimizing free energy or surprise?
Excellent question um so surprise and free energy um is a central construct um and
stands in for for self-information um and sometimes that can lead to um an anthropomorphical
um intuition that in order to minimize surprise I just need to make everything completely
predictable which is certainly true uh which itself then leads to uh what philosophers have
sometimes um talked about in terms of the dark room problem that I should just basically go away
switch off all the lights lie down and then everything's totally predictable all my surprise
is minimized and that would be a very um apt and appropriate uh generative model instead of
prior beliefs if you could survive forever lying down in the dark and some creatures can
but that would not be a good model a low free energy model for something like you and me the
first thing we do is to go and switch on the lights um why do we do that? Well because those are the
actions that minimize expected surprise so what is expected surprise? Well it has this um this
intrinsic and this extrinsic value or you can carve it another way in terms of risk and ambiguity
so the imperatives that underwrite those actions that will minimize
expected surprise consequent upon those actions have in them this novelty they have this um
artificial curiosity um which is that's a term in um so the worker you're going to smithuba
in the in your bot neuro um botics um it's also called intrinsic motivation that's part of
expected surprise minimization um and um that's what I meant by salience so salience scores
the information gain that you would get if you did that so these are the moves that um afford
that are have an epistemic affordance of the kind that um underwrites novelty or novelty seeking
or sensation seeking what would happen if I did that um I'm pausing slightly because there's a
slightly technical distinction between salience and novelty so both can be ways of us um affording
um or uh endowing certain behaviors or certain courses of action with an epistemic affordance
that resolves expected surprise um however about what if it's about states affairs we generally call
that salience if it's about the parameters of the gerative model the lawful contingencies um
then we normally call that novelty so when learning a new environment we're not really
resolving directly where we are in that environment more what's behind that door if I go around that
corner what will I learn can I go down that route and that's what we call we'll call novelty I'll
just close by um this pointing out a very simple semantic trick that allows you to resolve the
apparent dialectic between minimizing surprise and maximizing novelty in the sense that if
surprise is uncertainty um then expected surprise sorry if expected surprise is uncertainty
then by minimizing surprise in this expectation you are essentially minimizing uncertainty and
minimizing uncertainty is basically the drive for sensation seeking and novelty and novelty
seeking and it's a central part of explaining most interesting behavior particularly when
with this planning as in-prince perspective on minimizing expected free energy so in information
theory um surprise is known as self-information expected surprise is expected self-information
that's entropy entropy is a mathematical expression of uncertainty so minimizing surprise
is minimizing uncertainty good uh all right uh so the next question is from christoph molatter
he says a point of clarification um uh marker blankets per suppose a Bayesian network which
is a directed uh acyclic graph in brackets d a g uh in a d a g no feedback loop is possible yet
later in the talk the visual neuroscience example includes many feedback loops i'm certainly missing
something but how do you reconcile acyclic dag assumptions necessary for identifying marker
blankets with modeling in brackets such as the one with the visual system that imply circles
error in the course but that's a very technical but excellent question um so first off um the the
the graphical models that we use to describe a universe and a a particle or a creature within
that universe um is not acyclic um so the markoff blanket just certainly require the
absence of certain conditional dependencies that that is how it is is defined but there is a larger
circular causality and therefore loop loopiness so these are not directed acyclic graphs so we're
not constrained to um the markoff blankets that you will read about if you read about causality
in bayes nets that are for static probability distributions these are more um these are markoff
blankets that would apply to dynamical systems and in the sense that applying to dynamical systems
you can sometimes understand that as rolling out in time and because you're rolling out in time
and you don't have influences that go backwards in times you can actually reroute read a rolled out
loopy cyclic directed graph as a dag or directed acyclic graph in virtue of the fact that they are
dynamic so the markoff blankets that we deal with are slightly more complicated objects than
you will read about in standard um bayesian treatment of bayesian nets however the question
about well how can you get all these reciprocal connections um in a visual cortical hierarchy
is an excellent question because um you could easily answer that and say well look and you know
there is no markoff blanket on the inside the markoff blanket defines the states that comprise
internal states and all of these neuronal populations are just um uh examples or instantiations
of internal states but i think that would be um disingenuous because of course we said that there
are markoff blankets at different scales and one of the most important um illustration or
manifestation of a markoff blanket structure within the brain is the hierarchical organization
that lends it this deeper hierarchical structure it is exactly the same in conditional dependency
structure um that you find in deep learning networks so this is there's something quite
fundamental about the about things like hierarchies and the um similar conditional dependencies
underlie mean field approximations that allow us to think about separate bottom wear streams in the
brain um so all of these um aspects of functional specialization segregation if you're talking about
functional anatomy from the point of view of a brain scientist are statements about mark markoff
blankets the very fact you can segregate one part of the brain from another part means operation
there has to be a markoff boundary or a markoff blanket so now the game is which connections are
not in place in terms of these neuronal reciprocal recursive connections and which are
and the understanding that sparsely structure is of course just understanding the connectome
and the implicit factorization and hierarchical structure that is implied by that connectome
and if you understand that you can start to understand the form and the structural majority
model that is entailed by that structure and you can start to ask is it a really deep one
is it a shallow one how many factors does it have do we have more than just what and where
so in answer to the question um you don't need DAGs but you do need to think very carefully
and exploit the the utility of markoff blankets in a more generalized application in a more
generalized setting all right so the next question is from Calle Timperi who says
thank you for a very exciting talk I can one think about the emergence and evolution in
time of markoff blankets does the mathematical form of model implicitly will predict changes
in or creation of new markoff blankets uh as the surrounding ambient system
is changing in time and could this be framed in the theory of non-autonomous dynamical systems
and or bifurcation theory in deterministic dynamics or in systems perturbed with noise
there are three really intriguing themes to this question I'll deal with the sort of more technical
simpler one first and then turn to the other two so more than it could be framed in the theory of
dynamical systems and bifurcation theory perturbed with noise it is and it's nothing
that it has to be so the the the noise gets in when we as soon as we commit to using a
launch van formulation and remember the launch van formulation is the thing that underwrites
quantum physics classical mechanics and statistical mechanics there is nothing else really very
interesting so deterministic dynamics is interesting in a limiting case and probably
its place is homolog would be um sort of the classical mechanics of um and and body problems
for example but more generally we're talking about random fluctuations and noise perturbed
dynamics and the chaotic aspects so we're talking about stochastic chaos why well
if you remember I said before there are two there are three things that can happen when you
actually simulate little universes they explode into infinity or they perform a pointer tractor
with a crystalline structure and do absolutely nothing they're frozen there forever
and the the the interesting domain is stochastic chaos so I don't think there is anything else
really um so that would be the first thing um the second um the second um sorry just just
the technical bit so often cast in terms of random dynamical systems so you're now looking
at this as a physicist in terms of a launch van formulation and from that you derive
your pocker plank and scrolling wave equations or you can look at this from
from the point of view of um random dynamical systems um or you can look at this from the
point of view of stochastic chaos mathematically I think the law basically the same thing the
the the evil the emergence of um Markov blankets in time that's really interesting um I should say
that the um the current formulation of maths really does assume you are actually at non-equilibrium
steady state so it does not allow for um sort of the fusing and the merging and the wandering of
Markov blankets or children emerging from parents and then themselves engendering children
other than to um to actually look at the entire generational tree as one big um sort of a gothic
system as it goes around sort of you know its life cycle reproduction cycle that's a complicated
challenging um thing to account for under the most simplifications this month so that's something
I think that someone hopefully will do um in the future um having said that though um there is I
think a lot of mileage and understanding evolution of phenotypes where remember to be a phenotype
you have to have a Markov blanket so when we're talking about the theoretical biology of evolution
of phenotypes we are talking about the um the um the evolution of Markov blankets I think that then
you can um and again in a crisp and clear way apply these variational mechanics to explain this
it's a very simple move um that can be heuristically remembered by noting that in statistics the
optimization of variational bounds and model evidence namely variational free energy is called
basic model selection so you have a number of competing generative models or hypotheses about
this given set of data um and then you score your different hypotheses in terms of the model
evidence or their variational free energy and then you select the one that's got the most evidence
aka the the marginal likelihood now with that semantics in mind um then you can easily see
how easy it uh you can easily see a way of describing natural selection as nature's way
of doing basic model selection by selecting those phenotypes that have the um the the least
free variational free energy or the greatest marginal likelihood of existing so there's a
beautiful if you like and simple connection between basic model selection and natural selection
both of which are underwritten by um either the model evidence or its variational
proxies that can be evaluated the other way of looking at this is to go in and ask um in terms
of evolution do the established mechanics um have the look and feel of the gradient flow on a
variational um free energy or a a self-information uh function and yes they do so the price equation
replicated dynamics they and a it's um a multi simplification are formally identical now the
same functional form as that gradient flow that I described before so they are actually
in linear cases just common filters so this then licenses an understanding which many people
have pursued not many three people I know have pursued in the past decade um licenses an explanation
of evolution as really the environment or the evolutionary process as accumulating evidence
for the kinds of phenotypes that it's most that are most likely to inhabit it so you know you're
now looking at evolution as an evidence accumulation scheme a Bayesian engine that's trying to if you
like test out different hypotheses where unfortunately we are the hypothesis we are we are the feeder
time that may or may not get selected so I think I think that sort of style of thinking in theoretical
biology is probably the you know the most useful in terms of uh talking about how your Markov blanket
itself can optimize it you know the optimizing ratio to its marginal like or its or its evidence
all right so thank you very much all right so the next question is from uh Tuomas Pernou
who says thanks for a great talk uh and then asks uh how would you say your approach connects
to control theory uh for example you mentioned common filter either classical control theory
and or perceptual control theory and would you say that the control theory can be built on this
or would the connection go perhaps uh the other way around um I I think um again brilliant question
um I think both um you you could certainly pull out of this more generic um you know sort of um
variational principle um a um control theoretic optimal scheme or you could say look KL control
as used in engineering is in fact formally identical to an extended Kalman-Busey filter
and in fact that has been said um by people like um Emo Todorov uh no in fact he said that Kalman
himself said this so um the the math the functional form of a linear quadratic control
scheme in plant control and engineering is just a Kalman filter um so there's a direct
correspondence between the two when you go nonlinear you get an extended Kalman filter
which formally is exactly the same as the um the predicted coding that the people at the
Donders and we focus on uh when you put it in the hierarchical context so you know I think we're
all part and parcel of the same thing from my perspective things like control theory um are
if you like a special case of application of this more generic uh first principle approach
and particularly in relation to the KL control because the KL control really does emphasize
the minimization of risk and risk of course um entails a degree of uncertainty bringing us back
to the importance of belief distributions the importance of that noise when treating things in
terms of stochastic chaos that has to be part of it so you know this is a grown-up control theory
um you know not just feedback control um the the other part of the question there is interesting
so perceptual control theory I can't see him visually oh no there you are no you're not no
that's Walker Trimble um I was going to ask um uh the question though if they wanted to
describe perceptual control theory does anybody want to describe perceptual control theory
excellent good please do you have to unmute yourself
okay sorry I'm actually not an um uh expert on on perceptual control theory but um
it's something that people have been talking about since the early 70s already where uh
you should think about cognition as uh so it's it's it's fitted in this classical control theory
framework where you can uh think about um cognition as a control process controlling
perception not actions directly so yeah I was just thinking that since this is what we're talking
about in in kind of this mental mental framework whether this is something that you would uh find
uh fitting in your approach yeah no absolutely um and Neil Seth in particular um
a colleague of mine uh Warren Mansel uh have been championing um powers is perceptual control
theory um for some time and it certainly is exactly consistent with with active inference
um I'm not sure it's exactly the same thing but I always remember sort of turning on its head of
action and perception as as basically moving to keep a ball in you know in in the same line of
sight is quite sufficient for very skilled anticipatory movements imagining where the ball
might be when you want to catch it that just basically controls a very elemental low level
features of your um of your perceptual domain uh makes it look as if you're actually quite skilled
in terms of planning but actually it's a very simple procedure and I think the spirit of that
is exactly the same that I was trying to get up with um this sort of reflexive sort of action
that you just need to to know what is likely to happen in this very limited domain that you know
the reflexes can can if you like fulfill in order to produce systems look as though they're actually
quite um sophisticated and quite creative to can do handwriting but all that is happening there
all the heavy lifting is being done by the muscles responding to these delicately and deeply informed
predictions you should be that length or that length so all the control is in this very very
simple state space of proprioception so you know the trick is then that uh or I guess that um powers
its insight was really um you know the actual action is is you know is quite simple um provided
and that's what matters in terms of making moves on the work on the world and exchanging with the
