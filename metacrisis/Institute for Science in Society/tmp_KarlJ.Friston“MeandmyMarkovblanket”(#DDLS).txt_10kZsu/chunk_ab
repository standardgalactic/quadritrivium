you want big free energies so please bear with me in terms of the different signs.
The free energy here, being the negative of this quantity, is therefore also very understandable
from the point of view of people working in information theory.
So why is that?
Well, this negative value is known as self-information in information theory, a surprise or a more
simply surprise, which means that any active system where autonomous states are trying
to minimise surprise can now be understood in terms of things like the principle of maximum
utility information or the information principle, minimum redundancy and indeed the free energy
principle.
That's nice because the time average of surprise is entropy, which means that any system that
exists will look as if it is self-organising to minimise the entropy of its blanket states
and of course that's a holy grail of things like synergetics.
And if I was a physiologist, this is just a statement of homeostasis, keeping states,
blanket states, sensory states of an autonomic sort for example, within certain bounds and
stopping them exceeding those bounds and dispersing into non-bible regimes.
There's a final interpretation that I want to leverage, which is that of a statistician.
So hitherto we've been talking about M as any given Markov model that defines the distinction
between external, internal and blanket states, but I can also interpret M as a model of the
external states implied by the sensory data that they supply inherent in the blanket states.
So this quantity now becomes or takes on the role of model evidence in Bayesian statistics
that I'm trying to maximise.
So this now leads to notions of the Bayesian brain, evidence accumulation and predictive coding,
as I'm sure most of you are fully fluent and familiar with.
So those are four perspectives on this fundamental gradient flow on the log probability of some states of the system.
What I want to do here, please again ignore the equations, they're just being used
iconically to underwrite a very simple observation that the mechanics that we're talking about here
are no different from that which we'd find in classical mechanics, thermodynamics or indeed
quantum mechanics.
So let me just explain or show you how simply this one equation maps onto these different kinds of physics.
For example, imagine we're dealing with very large cold systems where we can ignore the random
fluctuations and then we just have the solenoidal flow apt for describing the circular motion of
the heavenly bodies or pendular or any massive bodies and this equation just reduces to Newton's
laws of motion and classical i.e. Lagrangian dynamics.
Conversely, if I go to the other end of the scale, look at very small hot things with lots of random
fluctuations where the inherent probabilistic behavior becomes dominant, then we are talking
about a description of statistical mechanics, almost precisely stochastic mechanics,
where this equation gives rise to fundamental theorems or constructs in statistical mechanics
such as the fluctuation dissipation theorems.
I can make another move, I can just deal with the square root of this probability distribution
or density, call that a wave function and this equation becomes the time independent
Strogen equation that underwrites all of quantum electrodynamics and quantum mechanics.
So that's good in the sense that there's a constant validity here, but what about the Markov blanket?
So the only thing that the Markov blanket brings to the table is this partition of
x the states into autonomous states and non-autonomous states or internal, external,
but it also affords an opportunity to interpret the underlying mechanics and dynamics in a
slightly more interesting way that brings with it a mapping between the inside and the outside and
this is the the bit that I thought might be interesting from a philosophical point of view,
it's a bit more technical than I would normally go through, but if you'll indulge me let me just
take you through the moons here. So we already know because these autonomous states do not depend
upon the external states by construction, by existence of the Markov blanket, that they will
appear to flow on a function of the blanket states and the internal states, the particular states,
and we know what that function is, it's just our surprise or self-information.
So internal active states share the same functional and this functional does not
depend upon the internal states. Now with one substitution of variables I can also write down
this functional as a function of a function, that's what a functional is, of probabilistic beliefs,
Bayesian beliefs about external states. So how do we do that? Well all we can all we do is basically
associate the expected internal state given any blanket state with a state or a position on some
internal manifold and we'll see what that looks like in the next slide. And then for any given
expected internal state say that it parameterizes stipulated by definition the probability density
over the external states and then this function of the blanket and internal states becomes a
functional of beliefs because I can substitute that into there and now I have a functional
of my sensory data, my blanket states, and my beliefs about the causes of that sensory data,
namely the external states and this leads to an interpretation of dynamical systems
if and only if they have a Markov blanket in terms of self-evidencing under a Markov blanket.
So just a bit more graphical intuition, I've never shown this slide before so
please bear with me with any hesitancy. This is our picture of a random dynamical system with
this an attracting set. If I just pick a particular slice through this state space at any given value
of the blanket states B and I've cartooned the probability density under or given that slice
conditioned upon B here, I have a distribution and this is two-dimensional over internal and
external states denoted by this expression here and again by construction it's independent so
there are no correlations here. I can summarize it completely with a marginal distribution,
what the distribution of states over the internal and the external denoted by these blue lines here.
So why is that important? Well what it means is for any given blanket state there is always
an expected internal state that depends upon the blanket state that has a mapping
to a probability distribution over the external states and this is what licenses an interpretation
of the internal dynamics as standing in for or holding beliefs about the external states.
So technically that induces a conditional manifold here with various values of B where
flow internal dynamics like brain activity can be regarded as the internal dimension
of this flow here which we know does this gradient flow and here are expected external states.
So the expected states encode or are mapped to or imply a distribution or a belief about the
external states. So internal states parameterize probabilistic beliefs about external states
I'm going to now show you how that works in practice using simulations and then we'll conclude
the first half of this this talk. What we've done here is just simulate a little universe
this universe happens to comprise 128 macromolecules with strong and weak electrochemical and
euclidean like forces. The details are not important all that we need to do is to sort of
create a little universe why well if we can do that and examine this little primordial soup
we can in principle because we wrote down all those conditional dependencies and influences
identify a set of internal states and their mark of blanket and if we can do that we can ask
is there a little particle or creature living in this soup that actually conforms to this
Bayesian interpretation this Bayesian mechanics that should be in play given our understanding
of the the gradient flows and their interpretation. So here is exactly the same simulation what I've
done here is color code the macromolecules according to their designation as internal
states in blue here with a little tail coming out here that are surrounded by active states that
themselves support the surface of the sensory states here that are exposed to the external
states and this little virus like particle happily wriggles around with cilia or cilia or tail here
at a non-equilibrium steady state. So why have we done that well it would now be useful to go back
and see does this sort of Bayesian interpretation of self-organization namely self-evidencing hold
can we demonstrate it numerically and it's fairly simple to do that here is one example
what we've done here is take any mixture of the internal electrochemical states say
depolarization of neurons in a brain and ask do they encode motion in the outside world
say visual motion of all of these particles so any mixture of flow of physical euclidean
motion in the outside is it represented in a probabilistic sense by the internal states
and to do that we have to identify this conditional manifold where everything's conditioned upon any
given blanket state and once we've done that we can use that mapping between the inside and the
outside to reconstruct the implicit Bayesian beliefs in terms of the expectations in blue and the
confidence intervals or credible intervals in the shaded area that encompass the actual behavior
of the external states hidden behind the blanket states not shown here and when we do that we see
a remarkable correspondence in the sense that the the real external states do actually lie
within the confidence intervals of the Bayesian beliefs based upon the expected value of internal
states for any given external states that expectation is important this is a synchronization
manifold that comes out on average so we only see this association when we average over multiple
instances here peaks of the internal states and I've just gathered these particular instances here
and put them on top of each other why have I done that well they look remarkably similar to empirical
neurophysiological results here are some ERP results from monkey electrophysiology timed up to
some visual motion as opposed to physical motion here as simulated so this would be a numerical
analysis that endorses this notion that it is emerging property of any system equipped with a
mark of blanket that will it will have this representational aspect that can be cast in
terms of an information geometry on the other hand although I know that he wasn't I think at
in Nijmegen although perhaps his brother was it's just a statement that your
forefather Christian Huygens made about the nature of loosely coupled dynamical systems this is just
an instance and a way of interpreting generalized synchronization or synchronization of chaos between
loosely coupled systems so his observation was that there are there will inevitably be a
synchrony whereby clocks suspended from the same wall or beam will come to oscillate in
synchrony and here's one of his drawings here so from our perspective what we're talking about
are two clocks one's the inside one the outside internal external and the beam of the wall constitutes
the blanket states that couple them enabling the carous and reciprocal influences to induce this
kind of generalized synchrony that characterizes these non-equilibrium steady states so let's
just summarize how far we've got so far so the existence of a particle something implies a partition
of systemic the states of the system into internal blanket namely sensory active and external states
that are hidden behind the Markov blanket and because active states change but are not changed
by external states they will look as if they're reducing the entropy of the blanket the dispersion
of the blanket states this is the homeostasis or self-assembly perspective and this means
action will appear to maintain the structural and functional integrity of the Markov blanket and
this is closely related to notions of self-assembly and chemistry and then the life sciences or
polices internal states appear to infer the hidden causes of sensory states by increasing
Bayesian model evidence and actively influence those causes and we're going to unpack that in
terms of active influence in a moment and internal states parametrize probabilistic beliefs about
external states lending their expectations and information geometry as we saw in the previous
slide and that in the philosophical world has been recently cast in terms of a Markovian form
of monism yes a little brief interlude here so this is a picture that sent to me by one of my
postdoctoral fellows went to France who went to America and then with his wife had a baby
and then his wife bought him a Markov blanket so this is a blanket with Markov on it and this is
little Kira making inferences about her world underneath her Markov blanket so if you want
to mark off blanket you can buy them in America apparently right so we've done all the the heavy
lifting from the point of view of the the technical backstory that inherits from the
self-organization of random dynamical systems what I'm going to do now is tell exactly the same
story but from the point of view of a neuroscientist or a psychologist trying to understand
sentience and action in an embodied brain and I'm going to do that in a sort of
conceptual way just by starting with this notion of the brain as a Bayesian machine,
a statistical organ literally an organ of fantasies having hypotheses that are confirmed or
disconfirmed in the face of sensory evidence and this is very much a 21st century view which you
will again be both fluent and familiar with that's more of a sort of inside out
inactive view of of perception that contrasts with 20th century sort of inside out extracting
information feed forward like notions of how perception works I think this is beautifully
illustrated by this 16th century oil painter famed for doing still lives that when viewed
from a different perspective evoke a very different explanation a very different hypothesis as to what
generated this particular pattern of sensory input so if you now see a face the point here
is that you made that face it's something you have brought to the table to explain this particular
pattern of visual impressions and talking visual impressions these ideas I guess can be traced
back to the students of Plato and certainly through Kant and to my in my world best articulated by
Helmholtz for example objects are always imagined as being present in the field of vision as would
have to be there in order to produce the same impression on the nervous mechanism and that's
clearly very closely related to psychological ideas appealing to perception as hypothesis
testing and I've attributed that to to Richard Gregory here ideas that underwrite many technical
advances in machine learning and indeed people like Jeffrey Hinton and Peter Diane proposed the
Helmholtz machine as a metaphor for the Bayesian brain borrowing from Bayesian probability theory
and in particular the key advances in statistical physics brought to us by Richard Feynman this is
the variational approach that gives us this free energy and we'll see why that is an important
treatment of Bayesian mechanics in the final final few slides let's just return to this notion
of sensory impressions on the nervous mechanism so I've sketched that here in terms of shadows and
a sensory veil for us are the sensory states of our Markov blanket and if it's the case that we are
compelled in virtue of this generalized synchrony that defines our existence conditioned upon a
Markov blanket and then it will look as if we are compelled to infer what caused these
shadows on our sensory epithelia and one might ask well how might that be described or articulated
in terms of a machine or a person or or a brain and it's actually much simpler than you might imagine
and can match to be written down in the form of predictive coding in engineering this will be
known as a Kalman filter so that is what I have done here we've taken the this existential gradient
flow where now I've replaced the the self-information with the free energy form of it and I just
decomposed the gradient flow per se and the solenoidal flow into a solenoidal part
and an update part so what does this mean well let's imagine that these expected internal states
stand in represent expectations about the causes of our sensations so this gradient flow basically
tells you how you believe update this denoting again the rate of change with time update your
expectations or beliefs about what's out there and I can write that down in terms of predictions
if I know what's out there I know how it's going to change over time and then the gradient part
so the gradients of any free energy function can be written down as a prediction error so the gradient
flow part of it becomes at the update which is just a scaled version of the prediction error that
is being minimized so what is prediction error well imagine I had this sensory impression on
say my retina and I had an expectation mu that this was a dog and if I had a generative model
that would generate the sensory states that would be there if this expectation was a plausible
explanation for my sensations then the prediction error is just the mismatch between my sensations
and those predicted under a generative model given my beliefs or my expectations that is the
prediction error so what we're saying is there's a simple interpretation of this gradient flow
in that it looks as if it is trying to minimize prediction errors and that's all there is to it
it's not to say that you will ever believe or know what's actually out there but provided you can
come to some plausible explanation with minimum or no prediction errors that's good enough for
and you can if you can keep doing that over your lifespan then job done
so that's appealingly simple we can forget about all that physics and just say well look
action and perception then are just in this in the game of minimizing prediction errors
what are the two ways of doing that well we can either change our internal states to make them
make the predictions that are generated from those internal states more like sensations and
