Hello everyone, my name is Memming and like many of you, I want to understand
how the brain works. In this talk I will introduce a family of machine learning
methods we've been working on to make modern neuroscience real-time. If we go
back in time a little bit, in the old days of single neuron recording,
electrophysiologists watched and listened to neurons during experiments
which provided insights and in turn influenced experimental design within a
single experimental session. Here's an example of Hubel and Wiesel who won a
Nobel Prize in 1981 for their study of visual cortex. I'll show you a short
video clip of their experiment. While they're recording from a single neuron
they would play the amplified signals through the speaker and listen to the
neurons' spiking activity which you will hear. You will also see them drawing
while mapping the visual motion stimuli the neurons respond to as they
manipulate the light bar stimulus.
Okay so you just saw Hubel and Wiesel mapping this neurons preferred
orientation and direction. As you can see these mapping experiments were very
interactive and dynamic. They were changing the stimulus based on what they
were hearing. So this very intimate connection between the neuron and
the experimentalist. However in the current era of massively parallel
recording the number of simultaneously recorded neurons are doubling every six
years and hundreds or more neurons are routinely observed using various
techniques and designs such as the Utah Array and the NeuroPixels probes. In these
settings it is very difficult to listen to every individual neuron because there
are hundreds of them. Because of that the experimentalists really can't connect
with the neurons and the subjects. What they do instead is they hope that if you
collect a lot of data and the post hoc analysis they will use machine learning
analysis and so on which will allow them to better understand the brain and
answer their scientific questions. This large time lag between alternating
cycles of experiments and analysis of such data sets is a major obstacle to
rapid scientific progress. Therefore I believe the field needs new sets of
tools analogous to oscilloscopes and speakers that the experimenters were
using before for single neurons. So for example if you have neural recording,
high-dimensional neural recording, we could have a signal processing pipeline
such that in real time it'll spit out a monitoring signal such that the
experimentalist can get an intuitive idea of what's going on in the brain
while they're doing the experiments and they can change the experiments. Or you
can use the output of these estimated descriptions to use and generate feedback
control signals. So in part one of this talk I'd like to tell you about machine
learning tools for inferring neural trajectories and neural dynamics. What
is neural trajectory? So even for very high-dimensional neural recordings, often
their effective dimensionality is much lower. This could be due to low complexity
of the task. The task that the animal or the subject is performing could be super
simple like a working memory or decision-making tasks are typically
designed to be very simple. It could be because of the biophysical network
constraints which limits the effective degrees of freedom of the neural
states. Regardless, we often see both the neural states being very low
dimensional and the variability of course also being very low dimensional,
although it's not always the case. So in practice what we do is we use
dimensionality reduction techniques such as PCA, the principle component analysis
or VLGP in this case, to extract the low-dimensional neural state evolution
these trajectories and analyze those which has been very successful. In
addition, what I really want to know is I want to recover this underlying law.
There's a hidden dynamical system law that governs these neural trajectories
and this is typically called the state-space modeling. So suppose we
have some data, this is neurons over time, this y here, and we use a
dimensionality reduction techniques such as PCA to recover a blue line. This is
the neural trajectory over time starting from the green dot ending at the red
one and if we collect a lot of these trials or if we recorded for a long
enough time, we might be able to slowly see that there's a ring shape here where
all the trajectories are attracted to. So we might be able to infer from this
that there is an underlying dynamical system that's represented by this vector
field here. All these arrows are pointing towards this ring here where the
color represents the speed of the flow. So this vector flow is fast outside and
as it reaches the ring it gets slower. So this is actually representing a
theoretical model called the ring attractor which are used for, for example,
storing head directions, representing head directions and orientations. So if we
can get the picture, get a picture like this, the vector field like this, then we
could understand how neural computation is implemented as a dynamical system and
I'll be very happy. So how do we get to here is the main question. And once we
get here, we can also describe how we could generate data based on this
description. So the dynamic sparse can be represented as a conditional property
distribution, p of x of t given x of t minus 1. This is how states evolve over
time with some noise and given a state x of t, the likelihood function describes
how can we generate spikes given the current state. So here the unknowns
are the x's and the theta which parameterize the dynamics, the vector
field and all we know are these observed y of t. So the inference problem is
quite difficult. Okay, so this inference problem to get x of t and theta from
data has been a problem for a long time and in neuroscience a lot of people
have tackled this. These are some list of methods that I collected a couple of
years ago except for common filter which is very famous method for doing linear
Gaussian case. All the other methods are specialized for analyzing neural data,
some of which are my own methods. And they're assuming different kind of
structures for the dynamical system model and different kind of observations.
And of course to do the actual inference we'll use various statistical
methods and machine learning methods to do this inference. And I will highlight
just a couple of these ones here that I will talk about in more detail. To do
this inference, most of these methods are offline. You need to give it a bunch
of data, then it will chock through the data and give you the answers. But we're
interested in doing this in real time in online fashion. So these two algorithms
that I highlighted here are online and they are based on a principle called the
recursive Bayesian filtering. If we can do recursive Bayesian filtering then we
can solve this problem. And the recursive Bayesian filtering basically tells you if
you already know in the previous time step of time step t minus 1, given all the
data from time step 1 to t minus 1, if you know what the distribution of x of t
minus 1 is, then using these formula and with a new observation y of t, you can
combine that information from y of t to obtain the updated x of t distribution
given all the data from 1 to t. So this will update your distribution one
point at a time. And this would be wonderful if we can do this. We can do
it for particular cases. If it's Gaussian-likely with Gaussian dynamics, then
we can do this. But in most cases, most interesting cases, this is
intractable, especially because we're interested in non-neonural dynamics
and observations which are spike trains, which are not very well described by a
Gaussian likelihood. So these are intractable. And the goal here is to
approximate these, this recursive Bayesian filtering, with a different
online algorithm. But it needs to be in real time, so it has to be constant time.
Every time you get a new sample point, new observation, it only uses a
constant computation time. And the total algorithm has to be finite memory
capacity, such that it doesn't become bigger and bigger in memory as you get
more and more data. So the first algorithm that I'll introduce to you is the
variational joint filtering, which was published in 2020. This is a variational
method, as the name indicates. And a variational method is a method where
you produce a queue of x of t. This is a different distribution that you
parameterize, typically with a neural network. And it's a parametric Gaussian
distribution, where its mean and variances are outputs of a neural
network. And this queue of x of t, you're trying to construct through the neural
network to approximate the best, the real thing that you cannot compute, the p of
x of t given y of 1 to t, all your observation up to time t. And to do so,
we will maximize the marginal likelihood. This is, if you can maximize this, try to
find the queue that maximizes this is good. It's hard to compute the marginal
likelihood itself. So in the variational inference, the main trick is to find a
lower bound that you will maximize instead. So in our derivations, we found
this lower bound where we have three components. The first component is the
reconstruction likelihood. So given a queue of x of t, your current state, your
observation y of t should be well explained. This is the likelihood. So if
you maximize this, it's good. And the third term here is the entropy, which says
you need to maximize the entropy of q of x. Relationship between x of t minus 1
and x of t to be also well described by this queues. So if q of x of t minus 1
and q of x, those two distributions should be related through this p of x of t
given x of t minus 1. So if you can maximize this, we are good. We're
explaining the dynamics pretty well. So if we run this in spike train data, for
example, for, if you simulate from a nonlinear oscillator, which goes around
this attractor here, this is the ground truth two dimensional attractor state
forward on time. These are the spike trains over time. This is our competition.
This is our method that produced a vector field. And this is our method
filtering up to time one thousand, time step 1000, and a time step 1000. We're
predicting in the future without any observations and also producing imaginary
observations on top of here. So you can see that it's doing a good job. But we
were also at the same time slightly not fully satisfied because this is a
variational method. There's inequality always have some gap. So what is hiding
in this inequality or that we cannot really maximize anymore? The lower bound
are these two variational gaps. There's there's a intrinsic gap that we cannot
bridge. And there are two of them, unlike the usual variational inference where
there's only one of these gaps. So in the next algorithm that we developed,
which is called the streaming variational Monte Carlo or SVMC, we ditched the idea of
using a Gaussian form q of x. Instead, we're going to use particles to represent
that distribution, to approximate that distribution. So this is an idea that is widely
used in particle filtering, if you know particle filtering. And what it is, is we have a bunch
of samples x of x, x's, which are potential trajectories. We're going to sample these
trajectories and weight each of these sample trajectories with a certain weight w.
And together, these are representing, these are going to approximate, these samples are going
to approximate the full distribution. And the way we assign these weights is through this
importance weight equation here. On the bottom, you have the proposal distribution r of s,
which I will tell you how we constructed it. And on the top is the true joint distribution.
So the way it works is you first sample, given x of t minus one from a trajectory,
you sample x of t using this r of s. And then you evaluate that r of s on the top and see what
the ratio is. If it's a good proposal distribution, which is very important for the success of this
algorithm, the proposal distribution will generate samples that are of high probability under the
true distribution. And that means the weights will be high. So the way that we construct this
proposal distribution is by using a neural network and a reparameterization trick that's often used
in variational inference. So h here is a neural network that takes input three things, x of t
minus one, y of t, the previous state, the current observation, and this epsilon t, which is a random
sample from a Gaussian distribution. And this is the basic form of the reparameterization. We are
parameterizing nonlinear distribution, non non Gaussian distribution using a Gaussian input
to a neural, you know, nonlinear neural network, where the neural network is parameterized by
this lambda of t. So this is an easy way of sampling points through x of t, this h.
And we will learn, unlike most particle filters or important samplers, we will learn this h.
And this h will contain input from x of t minus one. We don't know of any other particle filter
that uses this kind of trick. Okay, so then one thing to notice is that the lower bound that we
were using in the variational inference is now something very simple. It's deceivingly simple
here. It's this yellow guy, which is an expectation of a summation over the logarithm of these weights.
This is all. And this is a consistent objective, because the expectation is exactly the lower bound.
And also this lower bound has a small gap. If we increase the number of particles n here that
we use, and the number of weights, of course, same number of weights, if we increase the number of
weights, this gap between the likelihood and the lower bound gets arbitrarily small. So it's a small
gap, arbitrarily small gap, and a consistent objective. So what we do to actually learn the
system is to take the derivative of this quantity, respect to all the parameters, and take stochastic
gradient steps. And that's it. This gives us unbiased gradient for all the parameters, including
the proposal distribution neural network parameters, and the dynamical system parameters, and the
observation model parameters, all of them together. So let me show you an example of how
this works. This is what we call the NASCAR dynamics example. This is a 50-dimensional
time series that we simulated. This is over time. You can see there's a spatial temporal structure to
it. And remember that every time step is only getting one of these vectors, 50-dimensional vectors.
On the left is the true dynamical system. This is the vector field of the true system. As you can
see, this resembles a NASCAR track. That's why it's called a NASCAR dataset. The true state is the
blue X, and the estimated posterior mean state is the green. That's what the model is thinking.
And on the right, you will see what the model's inferred vector field looks like.
As time is ticking, as I have seen, 80 samples or so, the posterior mean is tracking the true state pretty well, and it's trying to draw some lines here corresponding to the time evolution of the true state, or the estimated state.
And the way we parametrized this dynamical system here, the P of X of t given X of t minus 1, we used a sparse Gaussian processes prior,
which means we not only get the vector field, but we also get the uncertainty on top of the vector field.
So let me replay the video, but with the uncertainty as colored here.
So this appearance of this dark green region is because the model knows that the state has
been here for a long time. So it's more confident about the flow being slow, and it's toward the right.
And as the system evolves over time, many, many cycles, it'll become more and more confident around that region.
Of course, far from those confident regions, it's inferred a fast flow to the wrong direction,
but the confidence, of course, is very, very low. It's very uncertain of what's going to happen.
So that's okay. We can apply this method, this SVMC, to spiking neural networks. Here we have a
2,000 spiking neural network that's implementing a binary decision-making task.
These are the spike trains that it generates. But basically, there are two populations that are
either winning or losing, depending on what the actual decision was in each trial.
After the inference, we get back the phase portraits. So this is exactly as predicted by
theoretical analysis of this spiking neural network. And we can recover that theoretical
