And the way this plays out now is we assume,
okay, what if she were 17 pounds?
Well, we need to multiply that now by the probability of our prior showing that she's 17 pounds,
which actually makes that quite small.
Now we calculate and multiply the three probabilities of our measurements occurring.
So now we have something small times something very small times something very small.
So we get a very small result probability that she actually weighs 17 pounds.
And now we repeat this process at 16.5 pounds and 16 pounds and 15.5 pounds and 15 pounds all the way through.
And then by the time we're done, we tally up all of those and we get this new posterior distribution.
It's normally distributed at about 14.1 pounds and it has a standard error of less than a pound.
You'll notice it's even narrower than our original prior.
So we've taken our original belief and we've been able to sharpen it up just a bit.
And so incidentally the peak of this curve is called the maximum a posteriori result.
If we had to choose one value to represent our belief, that's not a bad one to choose.
And now we compare this with our original estimate.
It's labeled non-Basian here, but more accurately it could be Basian with a uniform prior.
You can see that it is much broader and also the peak of that curve is in an entirely different place.
So the answer that we got, it's more confident because it's more centered and it's probably based on what we know closer to being correct.
So this is how Bayes' theorem is used most often in data science or in analysis.
It's a prior that you then update based on your measurements to sharpen up and get a revised set of beliefs.
So there's a lot of times that it makes sense to use Bayesian inference.
Sometimes we just know things.
Like if we're measuring age, we know that everyone is more than zero years old.
And so we can take that information and build it in and we can get sharper estimates with fewer measurements.
Now, it should, if you're paying attention, make you a little bit nervous.
We humans are actually not always aware of what we believe and putting it into a mathematical distribution can be very tricky.
More importantly, the reason we're measuring something is because we want to learn about it.
We want to be able to be surprised by our data.
So if we believe something that's not true, it can make it hard or impossible to learn from our data.
I like how Mark Twain phrased this.
He says, it ain't what you don't know that gets you into trouble.
It's what you know for sure that just ain't so.
So the way to avoid this pitfall is to always believe things that we think are impossible, at least just a little bit.
So by leaving this room for something to be impossible, we can do like Sherlock Holmes says,
and once you've excluded the impossible, then whatever remains however improbable must be the truth.
We don't want to exclude the improbable out of hand because then we're left with nothing.
Alice, in a conversation with the Red Queen, summed it up well too.
There's no use in trying, she said.
One can't believe impossible things.
I dare say you haven't had much practice, said the Queen.
When I was younger, I always did it for half an hour a day.
Why sometimes I've believed as many as six impossible things before breakfast.
So the secret to using Bayesian inference as well is to keep believing impossible things.
Thanks for your attention.
Here's how you can get in touch with me if you'd like to carry on the conversation.
I look forward to talking with you again soon.
