called subjective probability or Bayesian probability, so you have now laid out the
two sides in our conflict. Most statisticians would agree that objective probability is
the right way to describe the blue dice and subjective probability is the right way to
describe the gold top. It's really hard to get all statisticians to agree on anything,
but most. But what about those middle two situations? In both of those situations, I
have uncertainty about a real physical system. The wooden dice do exist, they have some physical
properties, they have some distribution over their outcomes, so that's like the blue dice
situation. However, I am ignorant on some level about how the system behaves. I could
conceivably learn more about it. So in that case, I also have some subjective uncertainty
about how these systems work. So when I say I want to use probability to describe those
two intermediate systems, the frequentists say, well, of course, you should use objective
probability to describe a physical system, and Bayesian say, well, you should use subjective
probability to describe your state of belief, and then they fight. So that's the difference
between the Bayesians and frequentists. It really is almost a unit's problem, even though
probability is unitless, where it can be used to describe two very different kinds
of uncertainty. And to give you an idea of how we found ourselves in this point, now
I'm going to give you a brief history of uncertainty quantification. How did we end up with different
styles of probability describing different things? Going back to the beginning, what
we consider to be the origin of mathematical probability today is a series of letters that
were exchanged between Blaise Pascal and Pierre de Fermat in 1654. What were they writing
about? Well, they were writing about gambling, and specifically something called the problem
of points, which is the question of if you are playing a game of chance against an opponent
and you are interrupted before that game is completed, how do you split the stakes? And
this was a matter of great interest to both mathematicians and gamblers. And in the course
of figuring out a mathematically rigorous way of addressing this problem, they came up
with the core concepts that describe probability today. For example, Pascal came up with the
concept of expected value, which these days means something like a mean or a measure of
central tendency. Back then, it was literally the expected value you will get back when
you place a bet on a game of chance. And this is what probability was. It wasn't even called
probability back then. It was called the doctrine of chances or the study of chances because
it was the mathematical description of games of chance, things like dice and cards and
lotteries. And that's how things stayed for a very long time with the first hint of broader
application coming in 1763, when a publication came out that had been written by a gentleman
by the name of Thomas Bayes. Now, Thomas Bayes was a Presbyterian minister, and he was also
an amateur mathematician. He'd published in a variety of areas on different mathematical
problems, but he had a very interesting idea about this doctrine of chances, which we now
call probability, which is, how can you use probability to describe learning? How can you
use it to describe an accumulation of information over time so that you can modify a probability
based on additional knowledge? So since he was a Presbyterian minister, he wasn't going
to talk about dice or cards or lotteries. He came up with his own thought experiment,
which he did not bother to name, but which I shall. And I call it blindfolded one-dimensional
table-matchy. Bayes-matchy for short. And this is a notional game set up. The way that
the game is played is that you don your blindfold and you take in hand your starting ball. You
are going to throw this ball at the table in such a way that it has an equal probability
of landing in any location on that table, and your job is to guess where it is. If that
sounds impossible, that's because so far it is. This is where your friend comes in. They're
not wearing a blindfold. Now, you're going to take one of these secondary balls shown
here in blue. You're going to throw it at the table in the same way, and your friend
is going to tell you whether it landed to the left or the right of the ball you started
with. And as you continue playing this game for multiple rounds, you will learn where the
red ball is. So what does this look like? Here is my Bayes-matchy simulator. You can
see the overhead view of the table. We've also got the side view because we're only
interested in that distance from the left. And on the bottom, that is my starting probability
distribution for the location of that red ball, where it is flat, because I threw it
in such a way that I do not have an idea that it's in one part of the table versus another,
and the true location is marked by that vertical line. So round one. Blue ball fell to the
left of the initial ball, and you can see I updated my probability distribution. It's
fallen to nothing on the extreme left edge of the table, gradually increasing the closer
you get to the right. Round two. Two balls have fallen to the left. Now I have almost
no probability on the left half of the table, again, increasing the closer that we get to
that right edge. Let's skip ahead a little bit. Round ten. I've now had nine balls fall
to the left and one fall to the right, and I've got this peeky distribution, which is
not centered exactly at the true location, but it's pretty close. Skipping ahead to round
twenty-five, we've now had twenty-two balls fall to the left and three fall to the right,
and again, this distribution is becoming narrower and getting closer to the true location of
the red ball. Now, trust me, if I kept playing this forever, eventually I would get something
that's very, very closely centered around the true location of my starting ball. How
did Thomas Bayes come up with this, and how am I doing those calculations for the probability
distribution? Well, though Bayes was far too modest to say, so he used Bayes' theorem.
Bayes' theorem describes a concept called conditional probability, which is the probability
distribution of one event, a random variable, given information about other random events.
So in this case, the event we're trying to get information about is x, the location
of that red ball. Our ancillary information is the left-right information we have about
the secondary balls, and you can see we have, this is a function of the distribution of
the left-right information for the secondary balls, given the location of that red ball,
that's just a binomial distribution, and that starting flat unconditional distribution for
the red ball. So what is Bayesian about this? Remember I said Bayesians are so defined because
they use a subjective interpretation of probability, probability as state of belief, rather than
description of randomness. So what's Bayesian about Bayes' theorem? Absolutely nothing. Bayes'
theorem is a theorem, which means it works for probability no matter what your interpretation
of probability is. If you want to be Bayesian with Bayes' theorem, then you need to take
an additional step. So what Bayesians do is they use Bayes' theorem to perform inference
about distribution parameters. Remember I said that's what statisticians describe. We
talk about distribution parameters theta, and what they do is they calculate the conditional
distribution of a parameter theta given the observed data x. So what makes this a Bayesian
procedure? Well it's got a couple pieces. The first is our old friend the likelihood where
you're just taking a probability density or mass function, treating it as a function of
theta rather than x, but then there is the prior. So the prior is the unconditional distribution
that you put on that parameter theta. We do not necessarily think theta is random. Remember
my example of a parameter earlier, the mean height of men at the lab. We don't think that's
a random variable, we just don't happen to know what it is. So if I'm using probability
to describe something that is not random, I'm not using objective probability, I'm using
subjective probability. Probability as a description of a state of belief or a state of knowledge.
You put all these things together and it's called the posterior distribution of theta
given x, and again we have our constant of integration because probabilities have to
integrate to one. It's the rule. So I've already told you Bayes' theorem isn't Bayesian,
was Thomas Bayes' Bayesian? Well we don't quite know. We do know that he never really
applied his theorem to real problems. In fact, the paper describing it wasn't even
published until after his death. So who was the person who took Bayes' theorem and did
this with it? Who said we should be doing this subjective probability based inference
for scientific problems? And that gentleman was Pierre Simone Laplace. Pierre Simone Laplace
was what you might call a probability enthusiast. He took this thing that was used to describe
gambling games and he said let's just use it to describe everything. And he applied
it to problems in biology and problems in sociology, to astronomy. He wanted to apply
it to criminal justice where he wanted trials in France to actually quantify the evidence
and come up with some kind of posterior distribution of guilt or innocence at the end. That part
didn't catch on. But the science parts did and the reason was up until this point there
wasn't really a quantitative way of accounting for uncertainty in data or models. And so this
style of thinking which we call Bayesian statistics back then was called inverse probability was
the only game in town. Eventually Laplace came up with something called the central limit
theorem which is a cornerstone of a frequentist inference so the entire conflict really is
his fault. But the central limit theorem only applies when you have large samples. And so
during Laplace's time and for over 100 years after that the only way to do inference for
small samples was using Bayesian statistics basically. And some people hated it. And it's
worth talking about why because it's not like there was a better alternative available and
the issue was the prior. Some people just did not like this prior. They weren't sure
how they were supposed to come up with it and they really didn't like the fact that
if two people came up with two different priors you could get a different answer to the same
scientific question. So here is an example that illustrates this that is actually one of Laplace's
own. How do you calculate the probability that the sun is going to rise tomorrow? So first we
need some prior on the probability of the sun rising and Laplace said well it may rise it may
not other than that I don't know so it's just a flat prior on that interval. We need a likelihood
and he said okay well we're going to use as our successes every time the sun has risen in the
past which thankfully has been every day so far. And one of the confusing things about Bayesian
statistics at least when you talk about it is that you're calculating probability distributions
on probabilities. What we're actually going to call the probability of sunrise tomorrow is the
expected value of this distribution over the probability of sunrise tomorrow and it is available
in closed form in this case. Trust me I'm a professional. And it's simply the number of
times the sun has come up in the past plus one divided by the number of times the sun has come
up in the past plus two. Plugging in numbers Bayes said the sun has risen every single day for
the last 5,000 years including leap years and so that is his calculated probability of the
sun rising tomorrow. One minus that the probability of the sun not rising tomorrow is about one in
two million. That number is very small it is not small enough. For one thing we know that the
earth is over four billion years old which means that if that were the actual probability of the
sun not rising on any given day we'd have had well over 2,000 sunless days by now. So not only do
we not believe that number Laplace didn't even believe that number so when he was talking about
the probability of the sun rising at that point nine nine nine nine etc. he said this number is
far greater for him who seeing in the totality of phenomena the principles regulating the days
and seasons realizes that nothing at the present moment can arrest the course of the sun. So if you
ask some random person who doesn't know anything about the sun this is their correct probability
for the sun rising tomorrow. If you ask Laplace he says don't worry it's coming up. How does this
work? Remember probability got to start describing gambling games and the probability of rolling
snake eyes does not depend on who you ask ideally it also doesn't depend on who's rolling but how
do you make that leap from a description of physical phenomena physical processes which are the same
for everyone to a situation where the probability of the sun coming up changes depending on who
you ask and the answer is of course this is subjective probability we aren't talking about the
actual probability of the actual sun coming up tomorrow we're talking about our state of belief
that the sun will come up tomorrow which of course depends on what you happen to know. How did Laplace
make this leap? How did he go from a description of random events to a description of a state of
belief as the interpretation of probability and why on earth didn't he tell people that that was
what he was doing? Well the answer is because Laplace didn't think he was making a leap at all.
Laplace did not believe in randomness. It was actually pretty common during Laplace's time to
believe that the the world was entirely deterministic and predictable and that if you just had enough
knowledge of starting conditions and the laws of physics you could predict every event including
the role of a die going out into eternity and it wasn't until the 20th century that we started
to see scientific and mathematical revelations that made people start to question this. So to Laplace
the only kind of uncertainty there was was uncertainty due to ignorance was what the kind
of uncertainty you describe with subjective probability. Now that being said even though
this is how he he justified it and this was literally the only way people had of sort of
calculating probabilities for hypotheses a lot of people didn't like it because first of all you
have to come up with a prior and second of all different people come up with different priors
particularly if there's not a lot of data you can get different answers. So there was a real
push to get the prior out of statistics the only way that you can which is by coming up with a
style of inference which is tied only to objective probability only to randomness and that is what
the frequentist did. So my two representative frequentists are Ron Fisher who came up with
the concept of maximum likelihood and ANOVA he was also very influential in coming up with the
idea of randomization experiments and would not appreciate being called a frequentist by the way
he advocated a third style of inference called fiducial probability but it didn't catch on so
we'll just leave them up there and also we have Neyman pardon me Jersey Neyman who along with his
partner in crime Egon Pearson came up with the decision theoretic foundations of frequentist
hypothesis testing so this idea of controlling your false positive or type one error rate and
then minimizing your false negative or type two error rate and using that to define an optimal
test that was that was due to his work. So these gentlemen and a variety of other people who founded
frequentist inference did something very interesting they came up with a way of doing
probabilistic inference which is tied only to randomness it doesn't have subjective probability
at all and as you might imagine there are some caveats to this and some some limitations on it
and the best way for me to explain them to you is by showing you a particular inference problem
doing it as a Bayesian and then comparing that to how you might approach the same problem as a
frequentist. So let's go back to our statistical lunch punch and imagine we have decided to use
the wooden dice and I have been assigned the number one remember we don't know if these dice are
fair so I want to make sure that they're at least unfair in my favor so I do a little experiment I
roll the dice 50 times and I get 12 ones which is a 24 success rate that's better than fair which
is closer to 17% but I know I have not fully characterized these dice so I want to know okay
what is the lowest reasonable value for this probability of rolling a one which I'm going
to call theta from here on out and I'm going to say well I'm willing to accept an uncertainty of
5% weasel word is used advisedly because uncertainty is going to mean two different things over the
next two minutes so first off I am a Bayesian so the first thing I have to do is pick a prior
and that prior that you see up there is called the Jeffries prior turns out that's a better way
of expressing ignorance of a proportion value than just a flat prior now I'm going to calculate
my posterior distribution using my 12 successes and 50 trials and I get something that looks
like that nice peaky distribution centered around 0.24 and I say this is my probability
distribution for theta find the fifth percentile and say with 95 probability the probability of
rolling a one with these dice is at least 15.3% so far so good now I put on my frequentist hat
and I can't do any of that anymore remember as a frequentist I can only describe random events
or events that are similar to random events using probability so what was random in that
in that problem I just described well the only thing that was random was the experiment where I
rolled the dice 50 times unfortunately it's not random anymore I already did it but can I come up
with a procedure that if I had 100,000 dice and I wanted to come up with an interval for each of
them by rolling it 50 times and counting the ones can I come up with a procedure that is going to
work for 95 percent of those random experiments which is called a 95 coverage probability and it
