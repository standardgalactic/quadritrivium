Welcome to the seminar series. This is put on by the Computational Engineering Division.
So the Bayesian and Frequentist divide within the statistics profession is of historic proportion
and has relevance to both statisticians and non-statisticians alike.
The scientists and engineers are having to grapple with ever larger quantities of data.
Statistics plays an increasingly important scientific role for data fusion, for uncertainty
quantification, and ultimately for informed decision making.
An understanding of the historical approaches to statistics and probabilities of interest
to all of us, who as our speaker says, quote, employs, applies, consumes, or contemplates
statistics and data analyses.
Kristen Lennox has been at the lab since finishing her PhD in 2010 at Texas A&M University.
She is both the founder and the current director of the Engineering Statistical Consulting Service.
She has provided statistical expertise on a range of problems at the laboratory, involving
everything from lasers to explosives. Please join me in welcoming our speaker, Dr. Kristen
Lennox.
Today I speak to you of war. A war that has pitted statistician against statistician for
nearly 100 years. A mathematical conflict that has recently come to the attention of
the normal people. And these normal people look on in fear, in horror, but mostly in
confusion because they have no idea why we're fighting.
I speak, of course, of that Bayesian versus frequentist thing. Now, not too long ago people
didn't have to worry too much about the differences between different types of statistics. Some
people didn't even know there were different types of statistics. That started to change
in the 90s when this thing that we call Bayesian inference began to slowly creep its way in
and infiltrate various areas of science and technical interest, but it was still something
that you wouldn't just encounter in day-to-day life. No more. These days you can be minding
your own business, reading the news, and all of a sudden, bam, Bayesian statistics happens.
This is particularly common in election years. I blame Nate Silver. But as so many of us
do. But the reason this is an issue is because you're being presented with this information,
but no one's exactly told you what to do with it. We live in an increasingly quantitatively
sophisticated world and people have access to tools for prediction and inference and
understanding data that previously they would never have seen, which, again, would be grand
if someone had ever bothered to tell you how they work.
Now this is not a uniquely Bayesian problem. Let's face it, most people view all statisticians
as sort of a hybrid of an accountant and a wizard, which is ridiculous. We have nothing
in common with accountants. But the fact remains, before I can explain to you the difference
between different kinds of statistics, I have to first tell you what is statistics without
qualifiers. And I like to call this the central dogma of inferential statistics. Statisticians
use something called probability to understand and to quantify uncertainty. Now this is not
the only thing that statisticians do. Sometimes we draw pictures. But this is something that
all statisticians do and it's something that we all spend a significant amount of our time
doing. And the statistical procedures that you have most likely been exposed to are this
or at least attempts at this. So if the underlying principles of statistics are this simple,
where is there room for disagreement? And I'll give you a hint. We mostly agree on what
probability is. So the place where you see conflict in divisions within statistics is
this second italicized word, uncertainty. Probability is a mathematical concept. It
is exquisitely well defined. Uncertainty is an English word. What it means kind of depends
on when you hear it. So the central difference between Bayesians and frequentists is what
they mean when they say that they are quantifying uncertainty. So how am I going to explain this
to you? Here's our little roadmap for the talk. Hopefully you already believe that this
is important. It matters that people understand how statistics works because frankly it's
inescapable at this point and you ought to know what you're expected to do with it since
it's already there. I'm going to explain these two key concepts in my central dogma of inferential
statistics. What is this thing called probability? This is mostly a vocabulary lesson. And secondly,
what is this thing called uncertainty or rather what are these different things called uncertainty
that different statisticians are trying to describe? I am then going to take you through
a very, very abridged tour through the history of uncertainty quantification, which is the
history of mathematical statistics and probability. The reason for doing this is because different
people throughout the last several hundred years have used probability in different ways
to solve different problems. And if I can show you the different styles of inference
that people have been using throughout history, hopefully that will allow you to better understand
not only what the Bayesians are, but the different styles of inference that you are presented
with today. And finally, the big reveal. This is a highly partisan topic. One of the nice
things about it is it's very openly partisan. You are never really left in doubt as to whether
the person you are speaking to is a frequentist or a Bayesian and what their corresponding
biases might be. So I have tried to keep this talk as unbiased as possible, but at the end
it's only fair to let you know how I feel about it so you can figure out where you should
believe me and maybe where you should believe somebody else. So moving along, what is this
thing that we call probability? Probability, as we currently understand it, dates back
to a 1933 monograph by Andre Komogorov. And Komogorov's insight was that this concept
of probability, which previously had been sort of isolated from the rest of mathematics,
was actually a special case of something called measure theory. And what measure theory is
is the mathematical formalization of ways that we actually measure stuff in real life.
So for example, there is a mathematical formalization of the concept of length. It's called the
Lebesgue measure. There is a mathematical formalization of the concept of counting. It's
called the counting measure because no one quite had the nerve to name counting after
themselves. Different, not after all this time. So different measures measure different
kinds of things. The kind of measure that we apply to things called uncertainty is probability.
And what makes it different from other measures is that it always takes a value between zero
and one. So key concepts in understanding probability. Probabilities have to take a value between
zero and one, which means if you take all possible outcomes or all possible things of interest,
the probability of all of them together has to be one. The way that you allocate those
fractions of probability among individual events or sets of events is called a probability
distribution. And there are a couple of familiar distributions, such as the exponential distribution
there, which allocates probability across all real numbers. The normal or Gaussian distribution,
which, pardon me, exponential is all positive real numbers. The normal or Gaussian, which
allocates probability across all real numbers. And there are also discrete distributions,
such as, for example, the distribution over the outcomes when you throw a six-sided die,
which is a distribution over the numbers one through six. So statisticians define distributions
according to things called parameters. When you have a named distribution, like the exponential
or the normal, you can perfectly define it using a small set of numbers. So, for example,
with the exponential distribution, if you know the scale parameter, you know everything
about that distribution. You can calculate any number that you want. Similarly, with
the normal or Gaussian distribution, if you know the mean and the standard deviation,
you can calculate any probability that you want. For our dice distribution, the parameters
are the probabilities of occurrence for each of the six sides. The reason that you, as
non-statisticians, should care about parameters is because this is what statisticians do inference
on. So let's say, for example, I want to test a hypothesis about whether or not men who work
at the lab tend to be taller than women who work at the lab. Well, I will define a distribution
on the heights of men at the lab. I will define a distribution on the heights of women who work
at the lab. But I'm not going to compare these big distributions head to head. I'm going to
compare their parameters. I'm going to compare probably their means to assess whether or not
my hypothesis is true. So parameters matter because they're the tools of inference that
statisticians use in a lot of cases. I will sometimes have exceptionally bad notational
manners and use the terms parameter and hypothesis interchangeably. I apologize, but hopefully
now you'll kind of understand what I mean. Last key concept is something called the likelihood.
Now, the formula that's up there is something called a probability mass function. It's a
way of describing a distribution with parameter theta. And basically, it is just the function
that returns the probability that a random variable takes a value little x given that
the distribution has parameter little theta. And if I summed up over all possible values
of little x, I get one because that's what probability distributions do. Now, what happens
if I flip this function on its head if instead of fixing my parameter theta and varying my
data x, I fix x and I vary theta? That is something that is called a likelihood. So the
likelihood is a key tool in both Bayesian and frequentist inference. And you can sort
of see why that would be where if you calculate the likelihood for a bunch of different parameter
values, the ones that have a higher likelihood value are in some sense more consistent with
your observed data than the ones with lower likelihood values. Something to keep in mind
about the likelihood though is that it is not a probability distribution. Remember when
I was integrating over x, that had to integrate to one. If I integrate over theta, that does
not have to integrate to one. It doesn't even have to be a finite value. And this is going
to matter a little bit later in the talk. So I'm sure you're relieved. That's everything
you need to know about probability for now. Now we're going to get into this more subtle
concept. What is uncertainty? Or what are the different kinds of things that statisticians
would call uncertainty and try to describe with probability? This is a subtle concept
and I've been told that one of the best ways to explain subtle concepts is through the
use of story. So I wrote you one. I call it the statistical lunch bunch and the summer
student revolt of 2015. It is entirely fictional yet strangely plausible. So once upon a time
there were six statisticians and these statisticians worked together and they played together and
they went to lunch together every Thursday. Now there are two key things that you need
to know about statisticians. The first, we are creatures of iron will. The second is
that we are creatures of slight whimsy. Now the iron will was really causing problems
for this group of statisticians because they could never agree about where they should
go to lunch. However, instead of taking terms, they came up with a more whimsical solution
in the form of dice. So every statistician had a number. We rolled the dice and whoever's
number came up got to pick the restaurant. But these were not just any dice. Oh no. These
are what are called precision dice or gaming dice and they are exquisitely engineered to
have equal probability of occurrence for all six sides. So when I say I am uncertain about
where I am going to lunch on Thursday, that is due to the inherent random nature of the
outcomes of throwing these dice rather than any situation where I am ignorant about the
physical properties of these dice. Now one of these statisticians was a collector of
dice and a connoisseur of dice and was not entirely satisfied with the current lunch
selection solution mostly because the dice are kind of boring. I mean they are mass
produced, they are plastic, they are also sharp and they kind of hurt when you hold
them. So she came up with a more whimsical and overall superior solution in the form
of hand carved ebony dice with hand applied brass pips. Now these dice add a certain amount
of elegance and panache to any event where they are used and she presented this alternative
to her fellow statisticians and they liked it. But they were a little bit concerned because
they were uncertain that these dice were fair. So remember with our blue dice, we know that
the outcome probability for each of those sides is equal. For these dice, we do not
actually know what the probability of outcomes are for different numbers because they are
less carefully manufactured. So the mathematicians talked for a little while and they decided
that the increase in whimsy was acceptable as a benefit for the sacrifice in certainty.
However, they did want to certify that these dice were at least kind of fair and they came
up with a testing procedure that basically involved rolling the dice 50,000 times and
writing down the outcome, which is doable, but no one was volunteering. Fortunately,
a solution presented itself in the form of our summer students. So we went to our summer
students and we told them that they were going to spend their internship at a national laboratory
rolling a die over and over and over again and writing down the outcomes. And we told
them they were following in the proud footsteps of John Carrick, who was a mathematician interned
in Denmark during World War II, who spent the period of his imprisonment flipping a
coin over and over and over and over and over again to prove that the law of large numbers
works. And he got a publication out of it. So this is a true story and I personally find
it very compelling. They didn't buy it. So they refused to help us with our little experiment
and we had a period of very tense negotiations while we were trying to figure out how can
we figure out if the dice work while they have what they consider to be an intellectually
satisfying summer experience. Apparently somebody told them that if you come to a national lab
it's all lasers and explosions all the time. But eventually we were able to come to a mutually
acceptable solution in which they were going to leverage the fantastic computational capabilities
available here at Lawrence Livermore to build an exquisitely refined physics model of our
wooden dice so that they could simulate rolling them over and over and over again instead
of doing it for real. There was just one tiny problem. Our summer students, like us,
are statisticians, which means they had never built an exquisite three-dimensional physics
model before and we were uncertain as to whether or not they had done it right. So while we
were discussing how we might validate their work, the entire situation was overcome by
events in that the statistics group hired two new people. Now we can't use six-sided
dice at all, we need eight-sided dice. And you might imagine that a statistics group
with a dice collector as a member might have access to an eight-sided die or even a selection
of eight-sided dice. You would of course be correct, but you know, we're back to mass-produced
plastic, aren't we? Whereas there are alternative options such as, for example, additively manufactured
custom-made eight-sided spinners available in a variety of attractive metals and finishes,
which are just a wonderful way of making any eight-factor decision-making process more
fun. However, one is uncertain as to whether one should bite the bullet and purchase this
item because on the one hand, I don't actually need it. On the other hand, all of my dice-collecting
friends will be extraordinarily jealous. So here's a form of uncertainty which is not
tied to any physical process at all. It exists only in one's mind and it describes a state
of belief. So I've run out of space, which means that we're not going to talk about any
additional kinds of uncertainty and I leave you on the cliffhanger, did I buy the top?
Of course I bought the top. But the point is, I have shown you four different kinds
of uncertainty, not exhaustive, and all of these styles of uncertainty are quantifiable
and all of them can be described using probability. However, if I use probability to describe all
these different kinds of events, clearly that probability is going to mean something different
in different situations. And I'd say the two cleanest examples of that are going to be
the blue dice and the gold top, where in the blue dice situation, we have an actual physical
system about which we have exquisite knowledge, but we are still uncertain as to its next
outcome. Now this is a style of uncertainty that's called randomness, it's called aleatoric
uncertainty, and when I use probability to describe this situation, it's called objective
probability or frequentist probability. And the word frequentist refers to the long range
frequencies of random events. Now on the other side, I have the gold top. The gold top is
not tied to any physical system, there's not a right answer somewhere, graven and stone.
If I am using probability to describe my thought process on whether or not I should make this
purchase, then that probability is entirely subjective. It describes a state of knowledge
or a state of belief, and it could differ from person to person. Now this is sometimes
