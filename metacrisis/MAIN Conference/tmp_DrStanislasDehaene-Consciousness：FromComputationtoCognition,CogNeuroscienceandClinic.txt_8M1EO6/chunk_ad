this visual stream of 10 pictures per second
or other five pictures in half a second.
So what that means is that this fleeting impression
of seeing a picture has a correlate
in the prefrontal cortex, which can be decoded.
Of course, what would be nice
would be to be able to ask the monkey
to hang on to one of these pictures.
Here it's just passing through
because of these pictures flashed by.
And you can sort of briefly see them.
What would happen if we had to select a picture,
hang on to it and report it later?
It's very hard to train in a monkey.
Maybe we will be able to do that later,
but we did that in a human.
Again, with Sebastian Martin.
So this is the paradigm.
You can see all of these pictures being flashed
one after the other.
In this case, there is nine pictures per second.
It's a long stream of 12 images.
And we present a green frame around one of the picture.
And the subject has to decide
what was the identity of this picture.
Keep it in mind.
Keep it in the global workspace
because you have to decide
among all of the possible pictures, which one you saw.
When we do this, we can build the decoder
based on independent data
where the pictures are presented alone.
This is what I showed you earlier.
We can build the decoder
for which picture is being presented.
Is it a face? Is it a house?
Is it a body part? Or is it an object?
But then we can apply this decoder
to this stream of pictures.
And the result is similar to the monkey result
I showed you earlier.
We see these streams of decoding.
We see these decoders that for a certain duration of time
are able to detect what was the identity of the image one
then the image two, then image three, and so on and so forth
coded by color here.
So I insist that one horizontal line
through this graph is one decoder.
But the decoder spits out a different answer
that corresponds to the image number one,
then the image number two, then the image number three.
And later in time,
you can get another decoder
that decodes the subsequent image.
So an interesting aspect of this data
is if you take a vertical slice through the data here,
you have the same exact data point.
But it can be decoded in different ways.
If you capture the early activity,
you're decoding the image, let's say, number seven.
But if with the same data,
use a different decoder,
you might be capturing the image six or the image five.
You're capturing the previous images.
So we must have this idea of a brain
which is constantly crisscrossed
by these bottom up perceptions
coming into the system
and reaching into prefrontal cortex.
Now what happens
when one of them is a target?
So now we can make the same exact decoders
for target versus non-target.
And what's the difference?
Well, we see essentially two differences.
There is an amplification of the late activity,
just like you should have expected
from the previous experiments I showed you.
The target is held for a longer duration.
So now we're reaching 500, 600 milliseconds
and you can still decode the target.
You can no longer decode the non-target here.
And at the same time,
there is an amplification of an earlier decoder,
around 170 milliseconds,
which used to tell you what was the image
but now becomes amplified a second time
at the same time as the top.
So this is probably top-down amplification.
What's very interesting
is that these two decoders
decode slightly different things.
The late one decodes just the identity
of the picture, which is your target.
And when a subject makes an error,
it decodes the error.
But it's really amplifying one particular item.
It's discrete, all or non-selection,
correlated with subjective reports.
So we think that this corresponds
to the access to the global workspace,
the conscious report of one particular item,
and the others you forget.
But at this earlier time,
you see that there is partial and gradual selection.
There are several candidates.
That's normal because they are,
as I told you, at a given slice of time here,
there are many possible candidates
in the early visual areas.
You have one picture,
but in the later areas,
you have the previous picture in this pipeline.
So this earlier activation
corresponds to several potential candidates.
But at the later stage,
here, there's only one that's being selected
and that can enter this global workspace
and be reported.
So I think this characterizes
a little bit the architecture of the system.
Pipelines of unconscious processing,
making inferences,
and then a single selection system.
I want to move to an auditory paradigm
to tell you that the contents of consciousness
can be even richer
than what I described to you already.
Because, of course,
it doesn't have to be visual.
It could be auditory.
But also in the auditory domain,
it's not just about the identity of the stimulus,
but it's also about the organization in time.
And we've used this local global auditory novelty paradigm
to investigate the representation
of stimuli through time.
So I hope you will be able to listen to the stimulus.
Okay. So this is our basic paradigm.
We have you listen to a sequence of sounds.
And in this case, the last one is different.
And this will generate mismatch responses in your brain,
the so-called mismatch negativity and the P300 waves.
You are surprised and you attend to the stimulus
because there is a surprise.
But then we adapt you
to hearing this global sequence of five sounds
and we do that several times.
And at the end, you still get the mismatch negativity,
but you lose the P3.
This is what we call local novelty alone.
Globally, you expect the entire sequence.
Of course, your early unconscious processors
still detect that there's a change of tone,
but that's expected consciously.
And now what happens is that
if we present you a monotonic sequence of tones,
that's when you react and you say,
oh, I'm surprised.
There is a global surprise.
The sequence is not the one I expected.
So in this way, we can dissociate
the local transition probability
from the global surprise.
We can have two levels of errors if you want.
And in this case, the error is that there is no error.
So it's a hierarchical error processing paradigm.
We can do it in this way.
This is the full design.
What is one block?
What is the base stimuli?
And this is the surprise.
And there is another block
where the base stimuli is monotonic.
And this is the surprise.
So we dissociate local surprise from global surprise.
Now, when we do this,
we find two completely different types of computations.
On top here, you see the local effect.
Local in time as well as in space.
It's a very fast response.
It's this mismatch response.
It primarily sits in the auditory cortex,
although there is also a little bit
of prefrontal cortex activation.
It's a very sharp response.
You can see it in intracranial recordings.
You see the first four sounds.
They habituate.
They become smaller.
And then suddenly you recover this very high activation,
even bigger than the beginning for the deviant sounds.
And it's a completely diagonal pattern of decoding,
which means it's a sequence of sharp processing steps
for this stimulus.
And we find it can be completely unconscious.
You can keep that even if you don't attend.
If you are asleep, if you are in coma,
you may still have it.
The global effects completely different
