We are now at the point where we have reached the third keynote lecture of May 2020 and
it is my distinct pleasure and honor to introduce Professor Stanislas Deouane from Collège
de France in Paris.
Professor Deouane is a professor of experimental cognitive psychology at the Collège de France
in Paris and he is director of the cognitive neuroimaging unit at the Orsay Brain Imaging
Centre.
He received his training in mathematics, cognitive psychology and neuroembodding.
Professor Deouane's interests concerned the cerebral basis of specifically human cognitive
functions such as language, computations, calculations and reasoning.
He has received several international prizes.
I won't have time to list them all here.
They include the McDonnell Centennial Fellowship and the Louis de Price for the French Academy
of Sciences with Daniel Lybion.
I could go on and on, I can just tell you about how excited I am that personally and
also the organizing committee of Maine that this is finally happening.
I mean Stan probably remembers that I've been bugging him with emails every year just
some months before Maine saying, is this going to happen this year?
So finally it's happening, it's coming true.
We have now the chance to listen to a talk keynote lecture by Stanislas Deouane in Maine.
So without any further ado, please join in welcoming Professor Deouane for his talk that
is entitled Consciousness from Computation to Cognition, Cognitive Neuroscience and
the Clinic.
So, hey, hello, thank you so much for this nice introduction.
I hope you can see my slides and yeah, I wish I had accepted your invitation years
ago so I could be in Montreal right now, but locked from my room, I will try to tell you
a little bit about my thoughts about consciousness and a lot of new data.
The plan of my talk is the following.
First I will tell you about some of the contents of this first book, Consciousness and the
Brain and new data to suggest that basically I think we begin to understand the basic operation
of conscious access, how we perceive something in the internal world.
We have identified signatures of consciousness and we are progressing in this respect.
They are shared between animals and humans and we are guided by a theory, the global
neuronal workspace theory and the data so far seem to converge nicely.
But in the second part of my talk, if I have enough time, I would like to tell you a little
bit about new ideas that I have developed in the second book, How We Learn, and I developed
the second idea that the contents of consciousness may be different in humans.
They are richer in humans.
We possess a language of thought which leads us to unique competencies for language,
for mass, for music, conscious representation of ourselves and others.
And I will try to show you therefore the bizarre abilities that require specific models.
In terms of AI, this is really on your science talk, I think, but here is where AI is going
to come in.
First of all, it's used as a tool in order to decode brain signals and to classify patients
with disorders of consciousness based on the signatures of consciousness.
And second, it's used as a potential model.
I think it's achievable to model the global neuronal workspace and we've just heard from
Josh Bengio about this.
But I will also claim that the current AI remains limited in its ability to capture human
behavior and propose some challenges that I think are not met, at least as far as I know,
from simple current neural network approaches.
So my talk will be based on the progressive development of a theory of consciousness which
is called Global Workspace Theory.
It started with this very nice book by Bernard Barthes which I can still heavily recommend
in 1988.
And then through the years, my colleagues and I have been refining the theory.
And if you want to read just one paper, I think this recent paper in 2017 or maybe the
even more recent review with Peter Rofselman, George Machaud and Jean-Pierre Changeux,
we'll give you some more details.
But to beef up the idea, I want to start with a very simple visual illusion that I think
many of you know.
Here you can see some chess pieces on the board and there's a black piece and there's a white piece.
And well, where is the illusion?
I think you know where it's coming is that these bits of the image are actually strictly
identical.
They are the same exact luminance.
I hope you can see this now if I go back and forth.
But we subjectively see them as completely different.
And what's going on is that our brain unconsciously detects that there is a sort of shadow, a sort
of gray zone in the image, subtracts it and lets us see the luminance of this object as
lighter because if it was in the shadow, it would have to be a lighter color.
What I like about this example is that first of all, I think it nicely illustrates the notion
that it's from Helmholtz, that the visual system operates by unconscious inference.
And what we see consciously is really the result of a lot of computation.
But also, this is a subjective illusion.
It's very clear that we don't see the objective reality, which would be these gray devils here.
So it's subjective.
And yet a machine confronted with the same display would have to come to the same conclusion.
If you're really trying to see the objects on the scene, you have to subtract the shadow.
And so subjective illusions are not at all incompatible with even optimal computations
by a machine.
I think that's what the brain does.
So I will use two key ideas here.
The first one is that there is a lot of early perceptual processing which is unconscious,
accumulates the evidence from the scene, combines it together.
And that conscious perception relates to a later wave of longer-lasting neuronal activity that
integrates the incoming signals.
For instance, here it has to integrate the knowledge of the shadow and the luminance
in order to create more global and globally available information.
So this is, of course, the idea of the global neuronal workspace.
I've shown this picture many times.
What's the idea?
Well, first of all, there are many chains of processors in the brain.
Cortical areas are typically autonomous processors.
Neurons operate in parallel.
And all of these chains can operate unconsciously.
And there can be many such chains at a given time.
But the second claim is that what we subjectively experience as consciousness
is the global availability of information.
There are some chains, the green one here,
that end up in this high-level system for sharing information.
And in turn, they can contact other processing chains, link them together.
And the idea is that consciousness relates to the activity of this global neuronal workspace
that evolves to select a piece of information from this chain, for instance, here.
So to attend to it, to broadcast it to other systems,
leading to a global knowledge inside the system.
And the ability, for instance, to report verbally the stimulus,
to act upon it, to memorize it, and so on and so forth.
In terms of physiology, the hypothesis
has been that conscious access corresponds to the ignition
of neurons with long distance connection.
You need these long distance connections to broadcast information
that would be distributed in prefrontal cortex,
another associative cortex.
This is not a localist theory of consciousness,
but the idea that prefrontal cortex is just one of the nodes here.
And that top-down signals are also being sent back to the processors.
And I won't go through that, but there's more and more evidence
for this notion of a sort of central system,
a bottleneck of multiple areas that speak to each other very quickly.
And for instance, in the work of Henry Kennedy here from Anatomy of the Monk.
So what is common to all conscious processing states?
Well, not necessarily the same nodes, not a single state or a single marker or NCC,
but more a processing style, a type of neural trajectory
that involves this broadcasting operation.
And so what are the predictions of these models?
I speak mostly about the predictions about the trajectories
of conscious and unconscious processes,
and that's why I will be using in my talk data mostly from MEG
and also neurophysiological recordings rather than fMRI,
because we want the dynamics.
So the dynamics, first of all, is that there should be
propagations of activity coming from unconscious stimuli.
They may not reach consciousness,
but they can still proceed along deep processing lines.
Second prediction, there should be this sudden global ignition.
All of these areas come together.
This created nonlinearity in the system, global amplification,
when another content gains access to consciousness.
And this should be seen at the level of prefrontal cortex neurons among others.
They should contain, this is a very strong prediction,
there should be a complete neural code for any conscious contents at a given moment
in a prefrontal cortex and related areas.
There are two other predictions.
This is a bottleneck, so only a single conscious object
can make it at a given time,
so if it's the green one, it's not the orange one, for instance.
And there's also the idea of spontaneous ignition.
You don't have to have an external stimuli.
It doesn't have to come from the outside, from the periphery.
It can come from inside, from memory,
from spontaneous patterns of thought.
But I won't have time to cover all of these points,
so I will focus on this idea of sudden global ignition
coming after a series of processing stages that are unconscious.
We've been doing a lot of experiments with this,
and the typical experiment goes like this.
We will flash an object, for instance, a digit here.
It's flashed for a very brief duration.
And then there is a mask,
and the mask can come after a variable delay, which we vary here.
And if the delay is very short, you don't see the stimulus,
and you don't even distinguish it from target apps and trends.
At threshold, sometimes you can see it, sometimes you don't.
And above threshold, typically,
after something like 60, 70 milliseconds,
you can see the stimulus.
And we've been chasing in the brain the activation caused by such stimuli.
This is an old experiment already from 2007, only using EEG.
And we could see that there are indeed several waves of processing.
What we could see here is that if you record from visual cortex,
you see a first wave, which is essentially linear in activation
as a function of the evidence provided by the stimulus
before it's being cut by the mask.
So you can see evidence accumulation here.
And then there's this second wave,
which, by the way, is the only one
which is seen very strongly here in the prefrontal cortex
following this sort of slow buildup here.
There's this non-linearity in the system.
And here, the curves are separated much more non-linearity.
For instance, if you can see, if you can focus on the green curve,
you can see that the 33 milliseconds stimulus
will create visual activation, but then it dies up.
And there is no second wave here.
What we could see is that the fraction of scene digits,
the subjective reports of the subjects,
correlates with the size of this late wave.
And we propose that this is a possible signature of consciousness.
I'd just like to point that this division between a linear phase
and a non-linear recognition phase is present in many, many experiments.
And we have even been able to use it to find
that there is such an organization in the baby.
The baby cannot report, but we can still see
that if you flash a phase for a short duration,
this experiment was done by Sieg-Qui there,
there is a linear variation in the evoked potentials
as a function of phase duration here.
And then the non-linear stage, where only the long duration phases
create this sustained negativity, whereas the short ones
that essentially return to zero.
