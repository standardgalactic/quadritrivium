We are now at the point where we have reached the third keynote lecture of May 2020 and
it is my distinct pleasure and honor to introduce Professor Stanislas Deouane from Collège
de France in Paris.
Professor Deouane is a professor of experimental cognitive psychology at the Collège de France
in Paris and he is director of the cognitive neuroimaging unit at the Orsay Brain Imaging
Centre.
He received his training in mathematics, cognitive psychology and neuroembodding.
Professor Deouane's interests concerned the cerebral basis of specifically human cognitive
functions such as language, computations, calculations and reasoning.
He has received several international prizes.
I won't have time to list them all here.
They include the McDonnell Centennial Fellowship and the Louis de Price for the French Academy
of Sciences with Daniel Lybion.
I could go on and on, I can just tell you about how excited I am that personally and
also the organizing committee of Maine that this is finally happening.
I mean Stan probably remembers that I've been bugging him with emails every year just
some months before Maine saying, is this going to happen this year?
So finally it's happening, it's coming true.
We have now the chance to listen to a talk keynote lecture by Stanislas Deouane in Maine.
So without any further ado, please join in welcoming Professor Deouane for his talk that
is entitled Consciousness from Computation to Cognition, Cognitive Neuroscience and
the Clinic.
So, hey, hello, thank you so much for this nice introduction.
I hope you can see my slides and yeah, I wish I had accepted your invitation years
ago so I could be in Montreal right now, but locked from my room, I will try to tell you
a little bit about my thoughts about consciousness and a lot of new data.
The plan of my talk is the following.
First I will tell you about some of the contents of this first book, Consciousness and the
Brain and new data to suggest that basically I think we begin to understand the basic operation
of conscious access, how we perceive something in the internal world.
We have identified signatures of consciousness and we are progressing in this respect.
They are shared between animals and humans and we are guided by a theory, the global
neuronal workspace theory and the data so far seem to converge nicely.
But in the second part of my talk, if I have enough time, I would like to tell you a little
bit about new ideas that I have developed in the second book, How We Learn, and I developed
the second idea that the contents of consciousness may be different in humans.
They are richer in humans.
We possess a language of thought which leads us to unique competencies for language,
for mass, for music, conscious representation of ourselves and others.
And I will try to show you therefore the bizarre abilities that require specific models.
In terms of AI, this is really on your science talk, I think, but here is where AI is going
to come in.
First of all, it's used as a tool in order to decode brain signals and to classify patients
with disorders of consciousness based on the signatures of consciousness.
And second, it's used as a potential model.
I think it's achievable to model the global neuronal workspace and we've just heard from
Josh Bengio about this.
But I will also claim that the current AI remains limited in its ability to capture human
behavior and propose some challenges that I think are not met, at least as far as I know,
from simple current neural network approaches.
So my talk will be based on the progressive development of a theory of consciousness which
is called Global Workspace Theory.
It started with this very nice book by Bernard Barthes which I can still heavily recommend
in 1988.
And then through the years, my colleagues and I have been refining the theory.
And if you want to read just one paper, I think this recent paper in 2017 or maybe the
even more recent review with Peter Rofselman, George Machaud and Jean-Pierre Changeux,
we'll give you some more details.
But to beef up the idea, I want to start with a very simple visual illusion that I think
many of you know.
Here you can see some chess pieces on the board and there's a black piece and there's a white piece.
And well, where is the illusion?
I think you know where it's coming is that these bits of the image are actually strictly
identical.
They are the same exact luminance.
I hope you can see this now if I go back and forth.
But we subjectively see them as completely different.
And what's going on is that our brain unconsciously detects that there is a sort of shadow, a sort
of gray zone in the image, subtracts it and lets us see the luminance of this object as
lighter because if it was in the shadow, it would have to be a lighter color.
What I like about this example is that first of all, I think it nicely illustrates the notion
that it's from Helmholtz, that the visual system operates by unconscious inference.
And what we see consciously is really the result of a lot of computation.
But also, this is a subjective illusion.
It's very clear that we don't see the objective reality, which would be these gray devils here.
So it's subjective.
And yet a machine confronted with the same display would have to come to the same conclusion.
If you're really trying to see the objects on the scene, you have to subtract the shadow.
And so subjective illusions are not at all incompatible with even optimal computations
by a machine.
I think that's what the brain does.
So I will use two key ideas here.
The first one is that there is a lot of early perceptual processing which is unconscious,
accumulates the evidence from the scene, combines it together.
And that conscious perception relates to a later wave of longer-lasting neuronal activity that
integrates the incoming signals.
For instance, here it has to integrate the knowledge of the shadow and the luminance
in order to create more global and globally available information.
So this is, of course, the idea of the global neuronal workspace.
I've shown this picture many times.
What's the idea?
Well, first of all, there are many chains of processors in the brain.
Cortical areas are typically autonomous processors.
Neurons operate in parallel.
And all of these chains can operate unconsciously.
And there can be many such chains at a given time.
But the second claim is that what we subjectively experience as consciousness
is the global availability of information.
There are some chains, the green one here,
that end up in this high-level system for sharing information.
And in turn, they can contact other processing chains, link them together.
And the idea is that consciousness relates to the activity of this global neuronal workspace
that evolves to select a piece of information from this chain, for instance, here.
So to attend to it, to broadcast it to other systems,
leading to a global knowledge inside the system.
And the ability, for instance, to report verbally the stimulus,
to act upon it, to memorize it, and so on and so forth.
In terms of physiology, the hypothesis
has been that conscious access corresponds to the ignition
of neurons with long distance connection.
You need these long distance connections to broadcast information
that would be distributed in prefrontal cortex,
another associative cortex.
This is not a localist theory of consciousness,
but the idea that prefrontal cortex is just one of the nodes here.
And that top-down signals are also being sent back to the processors.
And I won't go through that, but there's more and more evidence
for this notion of a sort of central system,
a bottleneck of multiple areas that speak to each other very quickly.
And for instance, in the work of Henry Kennedy here from Anatomy of the Monk.
So what is common to all conscious processing states?
Well, not necessarily the same nodes, not a single state or a single marker or NCC,
but more a processing style, a type of neural trajectory
that involves this broadcasting operation.
And so what are the predictions of these models?
I speak mostly about the predictions about the trajectories
of conscious and unconscious processes,
and that's why I will be using in my talk data mostly from MEG
and also neurophysiological recordings rather than fMRI,
because we want the dynamics.
So the dynamics, first of all, is that there should be
propagations of activity coming from unconscious stimuli.
They may not reach consciousness,
but they can still proceed along deep processing lines.
Second prediction, there should be this sudden global ignition.
All of these areas come together.
This created nonlinearity in the system, global amplification,
when another content gains access to consciousness.
And this should be seen at the level of prefrontal cortex neurons among others.
They should contain, this is a very strong prediction,
there should be a complete neural code for any conscious contents at a given moment
in a prefrontal cortex and related areas.
There are two other predictions.
This is a bottleneck, so only a single conscious object
can make it at a given time,
so if it's the green one, it's not the orange one, for instance.
And there's also the idea of spontaneous ignition.
You don't have to have an external stimuli.
It doesn't have to come from the outside, from the periphery.
It can come from inside, from memory,
from spontaneous patterns of thought.
But I won't have time to cover all of these points,
so I will focus on this idea of sudden global ignition
coming after a series of processing stages that are unconscious.
We've been doing a lot of experiments with this,
and the typical experiment goes like this.
We will flash an object, for instance, a digit here.
It's flashed for a very brief duration.
And then there is a mask,
and the mask can come after a variable delay, which we vary here.
And if the delay is very short, you don't see the stimulus,
and you don't even distinguish it from target apps and trends.
At threshold, sometimes you can see it, sometimes you don't.
And above threshold, typically,
after something like 60, 70 milliseconds,
you can see the stimulus.
And we've been chasing in the brain the activation caused by such stimuli.
This is an old experiment already from 2007, only using EEG.
And we could see that there are indeed several waves of processing.
What we could see here is that if you record from visual cortex,
you see a first wave, which is essentially linear in activation
as a function of the evidence provided by the stimulus
before it's being cut by the mask.
So you can see evidence accumulation here.
And then there's this second wave,
which, by the way, is the only one
which is seen very strongly here in the prefrontal cortex
following this sort of slow buildup here.
There's this non-linearity in the system.
And here, the curves are separated much more non-linearity.
For instance, if you can see, if you can focus on the green curve,
you can see that the 33 milliseconds stimulus
will create visual activation, but then it dies up.
And there is no second wave here.
What we could see is that the fraction of scene digits,
the subjective reports of the subjects,
correlates with the size of this late wave.
And we propose that this is a possible signature of consciousness.
I'd just like to point that this division between a linear phase
and a non-linear recognition phase is present in many, many experiments.
And we have even been able to use it to find
that there is such an organization in the baby.
The baby cannot report, but we can still see
that if you flash a phase for a short duration,
this experiment was done by Sieg-Qui there,
there is a linear variation in the evoked potentials
as a function of phase duration here.
And then the non-linear stage, where only the long duration phases
create this sustained negativity, whereas the short ones
that essentially return to zero.
So we believe that there is ignition already in the young baby.
At set, certainly at 12 months, we see also it very clearly,
and I think this is the data from 12 months,
but perhaps much earlier, probably, maybe even very close to birth.
The earliest evidence we had in this experiment was at five months.
So it's a basic architecture of the system.
We can see it many times.
We have a new tool now to look at these things,
which is multivariate decoding.
And this has been a very strong contribution of Jean-Rémy King,
who did his PhD in the lab.
What we can do is we can take a slice of time coming from these EEG nets,
or from the MEG that you can see here,
and using all of these sensors and this slice of time,
we can try to build a decoder for what the subject has been presented with.
For instance, decoding which image you have seen.
Is it a face, a house, an object, or a body part?
And this is actual data showing that,
of course, before the stimulus, you can't decode.
After the stimulus, there is a period where you can't,
and then you can decode the stimulus.
But what's great about this is you can also use the pattern
of generalization across time
to illuminate the organization of the system.
Think about it.
If there's a chain of processors, they each have a specific code,
then you could train on a given time,
and you could decode at the same time, even with new data,
but you could not decode at a different time
because the activation is gone onto a different code.
But if there's a stable, sustained, ignited code,
then you could train at a given time
and still generalize to a different generalization time.
Using different data from a different time point
because the data is stable.
And it's not just theory
because this is what we see in the actual data.
So this was the work of Sébastien Martin.
You can see here when we flash a picture,
we do see a sort of diagonal pattern of decoding,
which means we train at a given time,
we can mostly decode at about the same time,
and then the information moves to another coding scheme.
But later in time, you can see this late,
much more stable pattern,
and I will outline it for you here.
So you can see there's this much more square pattern,
which means that the neural activity has become stable in time,
and we can decode it.
And it seems in our hands that this diagonal phase
corresponds much more to non-conscious processing,
and this more stable phase to conscious processing.
So one way to see this is to use this decoding
in this masking experiment.
So here is our masking stimuli.
What we decode here is just the presence of the stimuli.
Can we distinguish between a stimulus,
which is present, like the D9 here,
and a stimulus where there was no digit at all, just the mass?
We can make this distinction.
We can make it even when the stimulus is extremely short,
like 17 or 33 milliseconds here.
And this is a subliminal stimulus below the threshold,
so you can see that it creates a whole pipeline of activation.
But notice what happens when we cross the threshold here.
There's this much more intense activation building up,
and then suddenly there's this intense square pattern,
stable pattern of activity,
which, if we simply take the same exact stimulus
and separate unseen trial, nicely separates these two categories.
You can see that there is much more stable activity
on the scene case.
And this has been proposed as a notion of metastability.
It's not that the activity is no longer changing.
It's still changing, but it's changing much more slowly.
The system has reached a much more stable state of activity,
which we claim is associated with broadcasting.
Jean Rémi has been replicating this pattern many times.
Initially, our experiments were criticized
because we were using symbolic digits,
so we did them again with grids, you can see here.
And in this experiment, also, it's a long delay
before the subject sees a probe
and has to decide whether the probe is tilted left or right
compared to the target.
You have to make this choice even if you don't see it.
It's very interesting that you can be above chance.
So even after a long delay like this,
or close to one second, you can still use some
of the subliminal information provided by the target.
But of course, you're much better
when you cross the threshold.
Information becomes much more stable in your mind.
When we decode this situation, we see once again
a sort of diagonal pattern for the unseen trials here.
So we see a trajectory in neural space.
And surprisingly, we can continue to decode
the unseen stimulus for a long time.
But still, you can see that the non-conscious trial
is evoking decaying activity in blue.
The seen stimulus is evoking much more stable activity,
sustained through time.
And even though it's not a perfect square,
it continues to evolve through time,
it's much more stable, much more broader in its matrix
compared to the more diagonal pattern
evoked by the unseen stimulus.
So you think this difference here.
So this is what we call ignition.
It's not just a stable pattern, it's a stable trajectory.
And this notion that conscious and unconscious processing
can be seen as a divergent dynamic trajectory
has been a point that has been made by others,
for instance, multi-sulty or so.
What they see here is the same as we see.
The seen trials, even for a fixed constant stimulus,
the seen trials diverge very quickly from the unseen trials.
If you measure the speed of divergence,
I saw this was a very clever trick here,
just measure the speed with which
the magnetic fields in the MEG change.
You can see that suddenly they start to change
very quickly for the seen trials compared to the unseen trials.
That's what we call nonlinear radiation.
Now, can we go beyond this simple observation of ignition
to what it does?
What's the computation?
Our idea with Jean-Rémy,
and we proposed that in this paper in 2014 very formally,
is that the computation is one of the posterior.
Think of my original example.
You have to compute the posterior distribution of light,
the probability that this is white or dark,
as opposed to based on all of the information on the seat.
So it's a perceptual decision following
a long unconscious influence.
We wrote this sentence, which I still like,
what we call a subjective report,
may simply be the brain's best attempt
at solving a difficult perceptual decision problem
with myriads of potential classes,
each with different costs and prior probabilities
that depend on the subject's prior experience.
So the subjective report is not random at all.
Subjective is a computation,
but a computation of a posterior.
In order to test this idea,
Jean-Rémy and Gabrielle Améad did a very recent experiment.
It's not published yet.
But the idea is that we can manipulate the evidence
by masking,
but in order to separate it better from the posterior,
we can also manipulate the prior.
So we have a masking paradigm here.
We flash a digit.
There's a mask.
We vary the SOA, the delay between the digit and the mask,
but we also vary the prior here by having two blocks.
You can see them here.
There's one block where most of the trials are invisible,
because we present all of these short duration trials.
Most of them are invisible.
And your prior is that you're going to get a trial
where you don't see the stimulus.
And then in another block,
we present some of the same durations,
but also longer durations,
so that the prior is that you're going to see
most of the trials.
And if you look at the behavioral data,
this is sufficient to shift as predicted
by the model, the subjective reports.
The subjective reports of seeing integrate the prior
and shift the second block towards more visibility,
even though it's the same stimulus
and even though the objective discrimination
as predicted by the fact
that this is based on unconscious computation,
the objective discrimination.
If we look at what happens at the MEG level,
we once again replicate this idea of a trajectory
for unconscious stimuli,
which gets broader for when the stimulus is seen.
And if we contrast unseen versus seen stimuli,
simply based on this middle stimuli,
where the stimulus is the same,
and one of these durations here.
So for a fixed SOA,
we have this distinction between seen and unseen stimuli,
which creates this region of significant difference here.
Amplification of the activation
followed by this very late metastable phase.
But now we can dissociate it from SOA.
We can do multiple regression.
This is what Jean-Rémy did here,
to predict the outcome of this detector
for present versus absent trials.
And we can see that the early stages
are dominated by the SOA,
by the objective evidence,
the duration of the stimulus before the mask.
And this is the visibility, the subjective component,
whether the subject declared that he could see it.
And we can clearly see that this affects
different stages of processing.
What about the prior?
We can also identify your modulation by the block,
which the subject is confronted.
Is it a visible block,
where most of the trials are visible?
Or is it an invisible block?
And this prior affects the entire trajectory of processing,
but primarily affects the beginning,
even prior to the presentation of the stimulus,
as should be expected, perhaps from the term prior.
So this is the key figure.
If we put together all of these influences,
we can see the successive effects
of the prior, of the evidence,
and of the posterior, the visibility ratings,
on the decoding of the presence
versus absence of the stimulus.
And I hope you can see these chains of processing,
which go through time here.
Each of these is a slice of the decoding.
So this is a decoder trained at 120 milliseconds
to decide whether there was or there was,
or there was not a stimulus.
And you can see that the decoder is first influenced
by the prior, then by the evidence,
and finally converges to the posterior.
And we see that multiple times.
I think this is consistent with the idea
of a chain of processes
that all have the same sort of computation,
the same style of computation at different levels.
And eventually, when you reach the last level here,
by 300 milliseconds, you're completely dominated
by the visibility, the subjective,
final posterior of the subject.
Now, all of these MEG data is very nice,
but as you can see, I'm showing it to you in decoding space.
We can also do source modeling,
and we can see that prefrontal cortex contributes to this,
and this is a distributed response.
But the best, of course,
is to go to animal research
in order to be able to pinpoint
the neural basis of this ignition.
And so we started doing this,
first of all, in collaboration with Peter Ruth-Semmastien
in this recent science paper,
we had a monkey model of a flash stimulus
crossing or not crossing the threshold.
So the paradigm was even simpler than before.
We just flashed a little bit of light
with a variable contrast,
and sometimes there is no stimulus at all,
so zero contrast.
And if the monkey sees the stimulus,
he has to make a saccade to the item.
And if he doesn't see the stimulus,
he has to make a saccade to a fixed out
to report not seen.
And once again, we have behavior
which is characterized by this nonlinear threshold function.
There's a threshold contrast for a given animal
below which you don't perceive the stimulus
even though it's present
and above which it becomes very easy to perceive.
And there are some ambiguous stimuli here.
So we could ask in monkeys,
how does the firing of cells in V1, V4,
and prefrontal cortex
varies as a function of seeing or not seeing,
including for the first time here,
the presence of a large number of missed stimuli
that is to say stimuli that are present.
There is a contrast on screen,
but the animal reports not seeing them.
And what we saw is very clear.
I think you can see it by yourself.
The visual areas V1 and V4
cannot be the basis of conscious perception
because they can be very strongly activated
both by seen stimuli but also by missed stimuli.
So it doesn't really matter much to these areas
whether there is going to be subjective perception
of seeing or not.
On the other hand, the prefrontal cortex,
as you can see here, ignites
whenever the monkey reports perceiving a stimulus.
It does so on seen trials.
You can see the green curve here.
And it also does so on false alarm trials
where there was no stimulus,
but the monkey thought that there was a flash of light
and made a second.
Most important, I think,
is the divergence between the red curve
and the green curve here.
They're the same stimuli,
but in one case, you missed the stimulus.
The monkey reports not seeing the stimulus.
And you can see that there is what we call failed ignition.
There's a beginning of a wave reaching prefrontal cortex,
but then it converges to the low state
which corresponds to the one
when the monkey reports not seeing.
So we really have a sort of dynamic system here
diverging between two possible states,
the high state for the monkey reports.
Yes, I saw the stimulus and the low state.
This is just about reporting because it's not reporting.
So it's really a sort of neural correlate
of signal detection theory here.
But according to the theory,
we should be able to go further than that.
And really, we should see that there is a detailed
neuronal code for the consciously perceived contents
and that this has nothing to do with report.
It should be seen even in no report paradise
where the monkey doesn't have to do anything.
So this has been a beautiful work
by a fanis Panagiotaropoulos,
first in Nico's Logothetis lab,
which pioneered all of this work on consciousness in monkeys.
And then now in Neurospin in our lab.
So what he's doing is using a no report paradigm
binocular rivalry situation
where the nice trick is that if the rivaling stimuli are grids
and in one eye they're moving up,
in the other eye they're moving down,
the two stimuli rival.
So even if you're a subject, you're a human subject,
you see one stimulus and then you see the other.
The stimulus is constant,
but your subjective perception alternates.
But you don't have to ask for a report
because you see it in the eye movements.
The eyes track the visible stimulus
and if you perceive movement towards the top of the screen,
for instance, you see slow movement followed by nystagmus
to return to the initial position.
And then you know that the subject is seeing the top stimulus.
So using this trick,
Fanis has been able to show that there are neural populations
in the prefrontal cortex that encode
which stimulus the animal is seeing,
even when there is no need to report at all.
And in fact, even when there are no eye movements at all,
just these states of the prefrontal cortex switch
and they switch in correspondence
with the perception of the animal.
Whether it's physical switches
or whether it's binocular rivalry
and the switches are purely subjective,
there is no switch in the actual stimulus.
Now this is just for up motion versus downward motion.
So you could argue this is a very poor
contents of consciousness.
The contents of consciousness should be much richer than that.
So can we go to much richer stimuli?
Well, that's what Joachim Bele and Fanis are doing
here at Neurospin.
We have these Utah arrays that allow to record from
close to 100 neurons in the ventrolateral cortex of the monkeys.
And we can see what happens
when you just submit them to a passive viewing paradigm
where they see an object.
And can we use the firings of the cells in prefrontal cortex
to decode where the monkey is seeing?
Well, yes, we can.
And not only that,
but we can decode every single picture that he is seeing
out of a large set of pictures, such as 10 or 15.
So there is a neural vector that suffices
to provide a lot of information
compared to chance about the identity of the picture.
And we can decode each of the successive pictures
even in a relatively fast stream where the subjective impression
is that there is a very fleeting view of the image.
If you're just submitted to this as a human subject,
you say, oh, I can see almost every picture.
They are going very, very fast.
They keep changing each other.
What we see in the prefrontal cortex,
if we look at the decoding matrices,
is this sort of very short diagonal followed
by cutting by the next stimulus.
So for the last stimulus,
you can see there is longer decoding.
And the matrix is actually longer
and leads to this more stable state here.
But we also have the same state.
This is the same decoder in the horizontal slice here.
So the same brain state
allows to decode the identity of the picture
only for a shorter duration
when the picture has been presented inside
this visual stream of 10 pictures per second
or other five pictures in half a second.
So what that means is that this fleeting impression
of seeing a picture has a correlate
in the prefrontal cortex, which can be decoded.
Of course, what would be nice
would be to be able to ask the monkey
to hang on to one of these pictures.
Here it's just passing through
because of these pictures flashed by.
And you can sort of briefly see them.
What would happen if we had to select a picture,
hang on to it and report it later?
It's very hard to train in a monkey.
Maybe we will be able to do that later,
but we did that in a human.
Again, with Sebastian Martin.
So this is the paradigm.
You can see all of these pictures being flashed
one after the other.
In this case, there is nine pictures per second.
It's a long stream of 12 images.
And we present a green frame around one of the picture.
And the subject has to decide
what was the identity of this picture.
Keep it in mind.
Keep it in the global workspace
because you have to decide
among all of the possible pictures, which one you saw.
When we do this, we can build the decoder
based on independent data
where the pictures are presented alone.
This is what I showed you earlier.
We can build the decoder
for which picture is being presented.
Is it a face? Is it a house?
Is it a body part? Or is it an object?
But then we can apply this decoder
to this stream of pictures.
And the result is similar to the monkey result
I showed you earlier.
We see these streams of decoding.
We see these decoders that for a certain duration of time
are able to detect what was the identity of the image one
then the image two, then image three, and so on and so forth
coded by color here.
So I insist that one horizontal line
through this graph is one decoder.
But the decoder spits out a different answer
that corresponds to the image number one,
then the image number two, then the image number three.
And later in time,
you can get another decoder
that decodes the subsequent image.
So an interesting aspect of this data
is if you take a vertical slice through the data here,
you have the same exact data point.
But it can be decoded in different ways.
If you capture the early activity,
you're decoding the image, let's say, number seven.
But if with the same data,
use a different decoder,
you might be capturing the image six or the image five.
You're capturing the previous images.
So we must have this idea of a brain
which is constantly crisscrossed
by these bottom up perceptions
coming into the system
and reaching into prefrontal cortex.
Now what happens
when one of them is a target?
So now we can make the same exact decoders
for target versus non-target.
And what's the difference?
Well, we see essentially two differences.
There is an amplification of the late activity,
just like you should have expected
from the previous experiments I showed you.
The target is held for a longer duration.
So now we're reaching 500, 600 milliseconds
and you can still decode the target.
You can no longer decode the non-target here.
And at the same time,
there is an amplification of an earlier decoder,
around 170 milliseconds,
which used to tell you what was the image
but now becomes amplified a second time
at the same time as the top.
So this is probably top-down amplification.
What's very interesting
is that these two decoders
decode slightly different things.
The late one decodes just the identity
of the picture, which is your target.
And when a subject makes an error,
it decodes the error.
But it's really amplifying one particular item.
It's discrete, all or non-selection,
correlated with subjective reports.
So we think that this corresponds
to the access to the global workspace,
the conscious report of one particular item,
and the others you forget.
But at this earlier time,
you see that there is partial and gradual selection.
There are several candidates.
That's normal because they are,
as I told you, at a given slice of time here,
there are many possible candidates
in the early visual areas.
You have one picture,
but in the later areas,
you have the previous picture in this pipeline.
So this earlier activation
corresponds to several potential candidates.
But at the later stage,
here, there's only one that's being selected
and that can enter this global workspace
and be reported.
So I think this characterizes
a little bit the architecture of the system.
Pipelines of unconscious processing,
making inferences,
and then a single selection system.
I want to move to an auditory paradigm
to tell you that the contents of consciousness
can be even richer
than what I described to you already.
Because, of course,
it doesn't have to be visual.
It could be auditory.
But also in the auditory domain,
it's not just about the identity of the stimulus,
but it's also about the organization in time.
And we've used this local global auditory novelty paradigm
to investigate the representation
of stimuli through time.
So I hope you will be able to listen to the stimulus.
Okay. So this is our basic paradigm.
We have you listen to a sequence of sounds.
And in this case, the last one is different.
And this will generate mismatch responses in your brain,
the so-called mismatch negativity and the P300 waves.
You are surprised and you attend to the stimulus
because there is a surprise.
But then we adapt you
to hearing this global sequence of five sounds
and we do that several times.
And at the end, you still get the mismatch negativity,
but you lose the P3.
This is what we call local novelty alone.
Globally, you expect the entire sequence.
Of course, your early unconscious processors
still detect that there's a change of tone,
but that's expected consciously.
And now what happens is that
if we present you a monotonic sequence of tones,
that's when you react and you say,
oh, I'm surprised.
There is a global surprise.
The sequence is not the one I expected.
So in this way, we can dissociate
the local transition probability
from the global surprise.
We can have two levels of errors if you want.
And in this case, the error is that there is no error.
So it's a hierarchical error processing paradigm.
We can do it in this way.
This is the full design.
What is one block?
What is the base stimuli?
And this is the surprise.
And there is another block
where the base stimuli is monotonic.
And this is the surprise.
So we dissociate local surprise from global surprise.
Now, when we do this,
we find two completely different types of computations.
On top here, you see the local effect.
Local in time as well as in space.
It's a very fast response.
It's this mismatch response.
It primarily sits in the auditory cortex,
although there is also a little bit
of prefrontal cortex activation.
It's a very sharp response.
You can see it in intracranial recordings.
You see the first four sounds.
They habituate.
They become smaller.
And then suddenly you recover this very high activation,
even bigger than the beginning for the deviant sounds.
And it's a completely diagonal pattern of decoding,
which means it's a sequence of sharp processing steps
for this stimulus.
And we find it can be completely unconscious.
You can keep that even if you don't attend.
If you are asleep, if you are in coma,
you may still have it.
The global effects completely different
is distributed in the space of the cortex.
It's much slower, typically after 300 milliseconds,
200, 300 milliseconds.
And it creates this very broad decoding ability.
It's a sustained state.
If you decode it at a given time,
you can see it at later times.
And we've seen that this one disappears
on the unconscious situation.
We've explored a lot this paradigm
to show this dissociation between the local unconscious
versus global conscious response.
And we've done it in the monkey as well.
This has been done by Beshear Jaraya and Lynn Urik
in the lab.
We've been able to do fMRI of the monkey
to see that there is a global workspace
in the monkey as well.
There is this distributed system of areas
that come up only for the global response.
And in recent research, we've seen that the global response
can disappear suddenly during anesthesia
when we fall asleep, regardless of the type of anesthetic.
And it will reappear.
And this is perhaps the most interesting aspect
from a clinical point of view.
It will reappear if we stimulate using deep electrodes
the centromedial nucleus of the thalamus.
This is still unpublished work by Jordy Tasseri.
I hope soon to be published.
So what we have here is a system that is essentially
a reflection, a signature of consciousness.
If you have this novelty response
that is high level of processing, which
integrates all of the five sounds together to say,
this is my expected melody and it's been violated,
then this is a conscious level of processing.
And you only get this response if the animal is conscious.
Now that we have this paradigm, we
can go back to our electrodes and ask
what is being coded in the prefrontal cortex of the monkey.
Can we see these global responses?
Can we see a code for what the monkey is seeing?
So you know that with these Utah arrays,
we can see several single neurons.
And this setup has been provided by Fanny Spanagio de Ropoulos,
Timo von Kerkule.
And this is the beautiful work of Marie Bellet here.
So what do we see here?
First of all, we see that we can decode from prefrontal cortex
neurons the identity of every object in a sequence.
We move to a visual presentation because we
record more neurons that respond to vision in the monkey.
But this is a small difference, so bear with me.
So we can see the identity of the stimuli here.
Blue, blue, blue, blue, orange, orange, orange, orange,
et cetera.
We can decode the identity of the stimuli.
I've already told you this.
So if the last item is different,
well, we can decode that the identity of the object is changed.
But in fact, we can decode every single bit of knowledge
that the monkey has of the sequence.
And that's exactly what I told you at the beginning.
There should be a code in the prefrontal cortex
for every single bit of information
that the monkey has, every single bit of conscious information.
So I told you we can decode which picture just appeared.
Is it picture A or picture B?
This is running blocks, so you can get decoding even
before the stimulus appears.
But of course, it gets amplified.
And we don't have to run these experiments in blocks.
We can decode identity.
But we can also decode the ordinal position.
There's something clicking in the monkey's head.
And in our head, when we go through the stimulus,
it says, well, this is the first sound.
This is the second sound.
This is the third sound.
And when it comes to the fourth sound,
maybe I should expect something different.
Because it's the end of the sequence.
And I know it's going to end differently.
So we can see this.
We can see neural codes that have first been described
by Andreas Nieder that care about the ordinal position
of the stimulus.
Because we don't vary the SOA for the moment,
and this is, again, unpublished data,
we cannot really tell whether this is number of time.
But we think it's a mixture of both and also some notion
of first and last in the sequence.
You can see item 1, item 2, item 3, and 4.
There is a mixture of identity information
and ordinal position information that tells you
where you are in the sequence.
And then there's much more than that.
There is, is the last item different?
If the last item is different, it creates this huge mismatch
response, which can be seen in different contexts.
And of course, the monkey knows consciously
that the last item is different.
And interestingly, we also see this numerical response here.
You can see something that says, oh, it's
like the first item.
It's like a new group of one.
This light item is different.
So it's a little bit like one.
We can also decode the global deviants.
So we have other neurons that allow us to build this decoder
here, which is expectedly slower in time,
and tells us, did I just see an unexpected sequence?
I expected that it should end with a different sound,
and it didn't.
So I get this global response here.
So there's something in the prefrontal context that says,
I'm surprised.
I should work more.
And what's very interesting is we even find neurons
that before the onset of the sequence encode,
what should I expect?
The monkey knows, as we know in this paradigm,
that ease in a block where it should end with a different sound.
So we can decode that from the beginning,
from specific cortical populations.
So all of these neurons are intermixed together.
And we can think of prefrontal cortex
as having multiple vectors that each code
for these dimensions of experience.
But the entirety of experience is reflected
in prefrontal cortex.
And I insist that this is in a non-reporting.
Monkey, there is no report here.
Just passive listening to these sequences.
So I promise to go very quickly to the clinic
just to say that this local versus global response is just
one of the tools that we have currently in the clinic
to decide, whether to help decide whether a person is
or is no longer conscious.
This is a very difficult clinical problem
of deciding whether someone with vegetative state
or minimal consciousness, so-called unwakeful,
sorry, vegetative state is now
responsive wakefulness syndrome, UWS here,
or minimal consciousness MC.
How do we decide?
It seems that some of these patients
in apparent vegetative state are actually still conscious.
Well, we can have them listen to this paradigm.
And as shown by Jacobo said, this is one indication
that they might still be conscious
if they still get this global response.
The local response we know we can get from comatose patients.
It's not the only tool.
And from global workspace theory,
we have several additional tools.
We can simply look at the amount of sharing
of information, especially in the theta band here,
in the long distances of the cortex,
the more there is sharing of information,
the more likely the patient is to be conscious.
And we can also look at fMRI,
and this is something I won't have time to describe at all,
but just the resting state activity in fMRI
has become a very interesting cue
to the state of the subject.
If there is variation in the resting state activity,
as you can see, these matrices
of functional connectivity varying through time,
then there is the high likelihood
that the patient is conscious.
This is a signature that we found in the monkey first
and translated to the human.
So by combining these signatures,
we can begin to have automatic classifiers of patients.
Using multiple EEG markers,
we can classify much better than chance,
whether a patient is or is not still conscious.
I will not have time to describe
all of the specific measures here,
but from a clinical point of view,
it does not matter.
Of course, it matters from the theory.
What are these signatures?
But from the clinic, the important thing
is that we can begin to help classify these patients better.
And very interestingly, inside the vegetative state,
it seems that we don't always agree
with the clinical classification,
which is provided by the doctor, the classifier,
the machine learning may not agree.
And in fact, the machine perhaps predicts better
at least sometimes because a greater number of patients
that are classified as being conscious
tend to recover as opposed to not improving.
So there is also a pronostic value
from some of these markers.
This has become quite an industry
of decoding of these patients.
It's all done in the laboratory of Lionel Nakash.
And in this paper,
putting together a lot of data from different groups,
we show that using random forest algorithm,
we can get robust EEG decoding.
And what's important is that it is cross-site now.
So from different clinical sites,
maybe using different EEG machines,
we can begin to have a common classifier.
In the last part of my talk,
and it will have to be necessarily a bit short,
I would like to move to this theme
that I mentioned at the beginning.
Do we all have the same contents of consciousness?
I hope I've shown you that from macaque to human,
we have similar mechanisms of access to consciousness.
When we perceive a line or when we perceive motion
or perhaps a face,
the mechanisms are very, very similar.
And we have this nonlinear access to consciousness.
But my hypothesis is that there is something different
in the human when it comes to higher level states.
We have richer states.
We are able to represent information in deeper manner.
In this review, in the journal Neuron,
we discussed the representation of sequences
with this idea coming from this local global paradigm
that sequence knowledge is already present in the monkey.
And of course, the monkey already knows
about the transitions between the items
and knows that there's one which can be expected.
I've shown you this.
Other experiments show that the monkey
can group the items together into charms.
The monkeys also know about the order of items.
This is the first.
This is the second.
This is the third.
I've shown you that.
And the monkeys may even be able to learn algebraic patterns.
So the first two are identical, for instance, AAB.
AAB.
And then there is perhaps a violation of this pattern.
All of this is available to monkeys
and probably many other levels as well.
But there might be a level which is unique to humans.
This is the level of nested symbolic structures.
In order to describe the structures of language,
such as this very simple phrase here,
those gifted car factory workers,
you need three structures.
You need parenthesis.
You need to be able to say it's a car factory.
And then there are workers in this factory.
It's not just car factory workers as a sequence of words.
It's a tree.
And the same applies to mathematical patterns
or mathematical equations, to musical patterns.
Or to a theory of mind, we need recursive structures
that have nested inside each other.
So our hypothesis is that this may be unique to the human brain
and that the human brain uses these three structures
to further compress the information
to discover some of the laws, symbolic laws, perhaps,
that Joshua Benjio was talking about.
It uses nested three structures
to further compress the information
into extremely compact expressions.
I don't think I have time to show you
all of the power of these ideas,
so I'll refer you to this book, How We Learn.
But I think this is a key idea
for how humans grow concepts.
And I'm very influenced by the work of George Tannenbaum
and in his paper by Kemp and Tannenbaum,
they show how to build an algorithm
that can build new concepts out of the grammar,
the generated grammar, or smaller ones,
and build concepts such as the tree of species.
Through this idea of a sort of language of thought,
a grammar of thought.
So we are starting to investigate
whether this actually occurs in humans
and not in the monkey,
using extremely simple paradigms.
I will show you one.
You'll be surprised by the simplicity.
So I hope you can see the movie on the screen.
You can see that there are eight locations here,
and this is a test for young children.
We tell them there's a fish,
which is hiding in this pond,
and try to guess where he's going to go.
Okay, so this is one trial learning.
I hope you guessed where he's going to go next.
Everybody says he's going to go here,
and then here, and then here.
You guessed the pattern even before it occurs.
Try to do that with neural networks.
It's not so easy.
This is very fast learning.
And what we've shown
is that in order to understand this sort of learning,
you need to assume some kind of language of geometry.
You need to assume primitives.
For instance, you need to assume
that the subjects understand that all of these diagonals,
they're all symmetries.
They're on the fixed axis.
They're all similar in a certain sense.
And so you can anticipate that this is the next one,
and then there will be this other segment here.
And you need a sort of formula
that expresses these repetitions.
This formula is a bit complex,
but really what it says is that
there is a repetition of four segments.
There's a first segment, second segment,
a third segment, and a fourth segment here.
And you can build other shapes,
such as two rectangles.
As long as there is regularity,
you can find an expression which is compact
and captures the regularities that human captures.
Well, we've done a lot of work with this.
I won't bore you with all of the results,
but just to say that our memory is driven
not by the length of the sequence.
In fact, all of the sequences we use were always eight items,
but it's driven by the minimal description length,
which we call Kolmogorov's complexity.
So the length of the shortest expression
that can compress the sequence.
And if you don't have a language,
you don't have the correct expression
for these minimal description lengths.
It's not just slots.
There's this idea of working memory as slots.
But I think in humans, it's not just slots.
It's really compressing the information.
Well, we have a lot of ongoing work at the moment
to try to see if this is true in the monkey.
As you can see, we did experiments with adults,
we did experiments with preschoolers,
so it doesn't have much to do with being trained in mathematics.
We even tested adults from the Amazon
that have very little access to education
and again found that you make more errors
sentences for phrases, sequences that are more complex.
That is to say, they are less compressible.
They require a longer expression in order to be described.
Well, this relationship we don't find in the monkey at all.
In the current work, which is done by Lippin-Wong
at the Institute of Neuroscience in Shanghai,
after staying in my lab for many years,
we see that monkeys do not seem to care at all
about the temporal or geometrical regularities.
They just store the locations in working memory.
They don't seem to care for the structure of the transitions.
In order to understand this language,
you need to care very much about the nature of the transitions,
much more than the particular locations.
You need to be able to understand that it's four segments,
regardless of how they are oriented, for instance.
Monkeys don't seem to be there.
In very recent work, which has just been accepted
in plus computational biology,
we extend this approach to auditory sequences.
Let me test your memory for sequences.
Do you think you could remember this sequence?
Okay, this is eight, I'm sorry, 16 tones long,
16 tones that can be A or B, high or low.
Let me have you listen to it again.
Okay, I think you will agree
that it's almost impossible to remember.
At least you will need many trials before you can remember it.
Now, let's listen to this one.
You think you could repeat it?
The evidence is that you can.
Maybe you'll need two trials, but not more,
because this is highly regular, and maybe there's another one.
Your capacity to remember these sequences
is again proportional to their regularity.
We've tested this in two different ways.
One is just to ask subjects for subjective complexity rating.
So just rate the complexity as you feel it.
But the other is to ask for an objective measure of complexity.
Can you detect whether there is a violation?
One of these tones is wrong.
Can you detect it?
And this is the percentage of detection,
and combine also with the time that it takes you to detect.
So remarkably, the very same measure of complexity
that we used for the geometric sequences
can be used for the auditory sequences.
It's a cross-modal notion of regularity.
The only thing that you need to capture what's happening here
is a notion of nested repetition.
There is repetition of repetition of repetition,
and you can compress the sequence
by understanding how these repetitions behave.
Do you switch from A to B or not?
Once you have that, the length of the compressed expression
is the direct predictor of how complex the sequence is to remember.
So there is something in the mind of humans
that compresses the information.
Can monkeys do this at all?
The evidence is that they can't.
In fact, they may be missing some of the most basic mechanisms
in order to integrate information as we do in humans.
Here's a nice experiment by DB1 when he was in the lab,
where the idea was we should ask,
how do subjects really understand the local global sequence
that I showed you earlier?
So let me have you listen to the pattern.
Okay, I hope you perceive that even though there is variation now
between the tones, there's a lot of regularity.
It's always three identical sounds,
and then there is a different one.
Can monkeys understand that?
Do they have something in mind just like us?
They would say it's three tones X and then another tone Y.
This seems to be a sort of minimal expression
that humans will use in order to compress this information.
Do monkeys have this at all?
In order to test it, we had several violations.
You can change to a new set of tones,
but still keep the same rule.
So it's new examples of the same rule.
Or you can violate the number.
You can have only two or maybe six items.
Or you can violate the sequence itself.
You expect that the last one is going to be different,
but it's not.
Or you can have double deviants, double the violations.
It's the wrong number and also the last item is not right.
We scan monkeys and we scan humans during this task.
It's a complex set of results,
but I will summarize it very briefly.
This is the activation to the violations in number.
And this is the activation evoke to the violations of sequences,
the last item rule.
And this is the intersection in yellow.
You can see that the monkey has both.
He has regions such as the inter-parietal cortex,
which we know cares about number and reacts to number of violations.
And we find that in a human as well.
We have a number sense, ability to react to number.
We also have responses to violations of sequences in the monkey.
You can see that in green, in particular,
in the inferior frontal cortex.
What we don't have in the monkey is the areas in yellow.
In humans, there is a whole set of areas
in the inferior frontal gyrus, Broca's area here,
and in the PSTS in both hemispheres
that react to the violation of both rules.
And that seemed to encode a single formula
for the entire rule that the monkey or the human
has been remembering.
And we really see this as a strong dissociation.
Humans show a similar pattern of activity
for number of sequence change,
as if they had a single representation.
Sorry about that.
Monkeys show a negative correlation.
So if a voxel activates for number,
it does not activate for sequence.
So monkeys don't have the integrated representation
that we suggest is present in humans,
and may be present, in fact, around Broca's area
and around the inferior prefrontal cortex.
In several areas of the human prefrontal cortex,
we find evidence for this integration according to rules.
So monkeys may simply not be able to integrate
the information consciously in the same way that we do.
If I still have a few minutes,
I would like to show you this in yet another form,
which I think is a nice challenge
for artificial intelligence.
This is a drawing undoubtedly from humans,
not from any ape, not from any non-human ape.
You can see the evidence of drawing an animal,
but you can also see geometrical shapes here,
a rectangle or a series of dots.
Is this unique to humans indeed?
Would a monkey ever understand this sort of shape?
I like this joke which appeared in the New Yorker here.
We have these humans watching a hunting scene and they say,
we have to record this or no one's going to believe us,
because what they see is not the actual animal,
they see the shapes, they see the abstraction,
just like the artist that wrote this in Moscow.
Can we test this?
Can we test the idea that even when we look
at a very simple geometrical form,
we are compressing it using its regularity?
We are seeing regularities.
So this is the work of Matthias Sablé-Meier in the lab.
What we do here is we present you a very simple display
like this one here,
and you have to spot the oddball, the outlier.
And I hope you've seen that this one is the oddball
because these are five rectangles
and this one is not a rectangle.
We do this for every possible shape that is displayed here
from highly regular square or rectangle
to completely irregular shapes that have no way to be compressed
other than remembering the specifics of the particular shape.
And we find that regularity has a dramatic effect
on subject's ability to detect the outlier.
This is another example.
It's a bit harder to detect the outlier, I hope, for you
until you find that this one has a displayed corner.
We always displace the corner.
This is important by the same amount.
So it's not the amount of displacement that counts.
It's the regularity of the shape.
The more regular the shape is, the better you are.
But you are super good at detecting
violations of the square or rectangle.
You are very, very poor at detecting
violations of an irregular shape.
And the other ones, they fall in between
as a function of a degree of regularity.
So the humans may have this special notion of a square
as something which is regular, particular.
It is a complete human universal.
I don't think I have time to explain to you
all the replications of these effects
in different paradigms.
Just subjective ratings, again,
we have a notion of introspection.
We have a conscious introspection
for the complexity of these shapes.
We can even present them as sequences.
It doesn't have to be a shape.
So that's a little bit of a challenge for, let's say,
CNNs, convolutional neural networks,
because here the humans resist to the presentation
of the shapes as a sequence of the four corners.
But even preschoolers or the himba here,
adult people who have very little access to education,
they live in Namibia outside of the normal
Western environment, they still show this regularity effect.
So it's a complete human universal in our hands, at least.
It doesn't depend on education,
or at least it's present already
in a sort of simple form in the absence of education.
So what about monkeys?
We were able to test it in baboons.
This is a wonderful facility in the south of France
with Joël Fago running this facility
where the baboons can access these booths at any given time,
and they can get video games.
This could be at two in the morning.
You have a monkey entering,
and he's recognized by the system,
and he has access to a video game.
The video game is, of course, the one that we designed.
We don't start with the game.
I'm getting angry.
Okay, Mr. Panda, I'm closing.
So I think you get where I'm getting.
Baboons can learn the outlier task.
They can detect the oddball flower here.
They can generalize to all of this stimuli.
So they are able to learn the oddball task,
but what they don't do is show a shape regularity effect.
They're completely different from the last.
And you see that they're essentially flat.
They detect the outliers regardless
of whether it's a square or a very irregular shape,
which serves as a base.
And we claim that CNNs capture very well
in multiple regression the behaviors of baboons,
but that they don't capture what's happening in humans, not at all.
And that a completely different model
is needed to capture what's happening in humans,
a model which lists the internal properties of the shapes.
I think I will just go to my conclusion.
I think that human consciousness is special.
Of course, there is a conscious global workspace
in all primates and perhaps in many other animal species.
There's a beautiful paper by Andreas Nieder on corvids
showing the same sort of thresholds and ignition in the crown.
I think we also share with many other primates
the same core concepts, for instance, the concept of number.
Of object, but also of space, of person, and so on.
The basic concepts are there in other primates.
But maybe, according to this new hypothesis,
only humans possess an internal language of thought
that discretizes, first of all, the concepts
into mental tokens or symbols
and combines them recursively into mental programs
whose complexity determine
whether we are going to be able to remember them.
And my argument is that something happened during hominization.
Our brain architecture must have changed.
In a way that facilitates the acquisition of recursive languages.
And this happens in several brain networks,
language areas, but also mass responsive areas
or theory of mind regions,
giving rise to the extraordinary complexity
of human conscious experiences.
This second part here, what's special to the human brain,
I would argue, is not yet well captured
in artificial intelligence.
It's more like system two that Joshua Benjio was discussing.
So we might have a discussion about that there.
With that, I will leave you with these two books
and thank you very much for your attention.
Unknown?
No, I know.
Yes.
Yes.
Thank you so much.
It was an impressive talk.
As expected, that was wonderful,
mind blowing, a lot of beautiful data.
The cognitive experiments are just so mind blowing
and amazing and it nicely complements
all of the work we've been looking at today.
We do have time for questions
and we have to take questions and just weigh so many questions.
So I'm just going to pull up here the questions
and see those that have been uploaded most.
And maybe we can go through a few of them.
And again, we'll have time later in the panel.
So I'm going to ask the first one.
So the first question, you probably see it also stand
on the Ask a Question tab.
The first one is by Elif Miller,
who's asking in the global network space,
in the GNW theory,
does consciousness require control-oriented
interceptive inference
as advocated by Anil in his talk this morning?
So the way to incorporate interceptive inference.
Yeah, I don't think so.
I think that there is a lot,
but I may not fully understand the concept
that Anil has been proposing,
but I think the theory that I'm proposing
is that we can be conscious of many different things
and this does not necessarily require
any sense of self or any notion of interoception.
So all it requires is an internal system
for both casting information.
It can be very abstract.
So think of what you are doing
when you're doing mathematics.
But I'm not sure I fully understand
also the particular proposals here.
So fair enough.
We should discuss that later.
Yeah, we can get back to it.
So I'm going to take a question
by Andy Dykstra,
who's asking,
how do you address the work of Michael Pitts,
Steve Hilliard, and others that claim
that the P3B is post perceptual,
rather than perception, actually, per se?
Yeah, I think it was a little bit wrong
to claim that one particular wave,
which of course varies from paradigm to paradigm also,
is can be a universal signature of consciousness.
So that has been clearly refuted, I think.
What is still clear is that
if you have another stimulus,
one which is not expected,
then the P3B is not a bright sign of consciousness.
But as soon as the stimulus becomes habitual, expected,
you don't necessarily get it.
And also if the stimulus does not require
a lot of post processing,
as being said in the question,
then it can be severely reduced.
That does not, I think,
depart from the fact that you have ignition.
The ignition phenomenon is still present,
as I showed, I think,
especially in the new neural recordings,
in the prefrontal cortex,
you have very brief activation,
but still crossing the prefrontal cortex.
And if you don't need to hang on to it,
because you're just passively looking,
then you get it and then it's gone.
It flies by, basically.
So it will not create this very global wave
that you can detect from the outside,
which is called the P3B.
The piece review will be seen if you are surprised,
or if you have to actively report all the stimulus.
Thank you.
I'm going to switch to a question by Andrea Brevelli.
So Andrea is asking,
so from Marseille,
he's asking differences in eye movements,
be it saccades or micro saccades,
may exist between conscious,
so seen and unconscious,
unseen processing of visual stimuli,
which may lead to different responses,
for example, with MEG,
in the prefrontal cortex,
starting from 400 milliseconds.
So the question is,
can you exclude such potential confounding effects?
We typically do.
We typically always record eye movements in MEG.
It's also the case, of course,
in the monkey experiments.
And we can analyze and show
that there is no detectable difference.
So you could always argue that there are micro saccades
that are still present,
of course, below the resolution
of the particular scanner.
But I think there are enough paradigms now
that we can exclude this interpretation,
in particular in the auditory paradigms.
I see no reason why there would be
a contamination with eye movements.
Okay, so maybe one last question here
before we move on later on to our panel discussion.
This is a question by Hikaru Tsujimura,
and basically it relates to linking the global neural workspace
to default mode networks.
So the question is,
what is the core difference between the global neural workspace
and the default mode network,
especially the advantage of the global neural workspace
to explain mechanisms of consciousness or awareness?
That's an interesting question.
First of all, I think that in science,
it's often the case that we name
same things with different names,
and then we see the bridges later on.
So this could be a case.
However, I think that the global neural workspace is broader
than the particular default mode network
just typically pointed out in some studies.
For instance, you get a different network
within the global workspace.
You get different topologies of the network
depending on the contents of what's being accessed by the subject.
And default mode networks seem to relate more
to verbal contents, perhaps,
although it's bilateral,
so in the right initial is more than that.
But we can also get slightly different network
if you think about mathematical concepts, in a sense.
And then it's clearly a different network.
So I think that this relates
to what I said in the introduction.
There's a style of processing
which is associated with conscious processing,
but it's not necessarily a fixed set of areas
that are always coming up when you're conscious.
It's the style of activation, the ignition,
the fact that the subset of prefrontal neurons
are being activated and the others are being silenced,
which tells us that the subject was conscious
of a piece of information.
Awesome. So I will take one last question
because this one's the most upvoted one.
So you can probably see it at the very top of the list.
So the question is, in the global neural workspace,
an important role is described, the prefrontal cortex.
But the question is, what about the hippocampus,
which sits on top of the cortical sensory hierarchy
and has important roles in obviously association,
memory, of course, and space and time.
So how do you see hippocampus?
This is a great question and very important one.
There is the hippocampus.
There is also the thalamic nuclei
that are connected with the cortex.
And of course, in a human,
we tend to study mostly the cortical responses
and also in the monkey,
now that we have access to PFC recordings.
But I completely agree with the notion of the question
that this is a linked system.
And I think it's often the case that what gets recorded
in episodic memory has to be conscious first.
So I think there's a sense in which it's highly likely
that what gets stored in the hippocampus
in episodic memory was first a cortical content
that was ignited.
And in this sense,
there would be a very important relation between the two.
It works also in the opposite direction.
When you access consciously a memory,
you can search your memory
and suddenly it pops into your consciousness.
This is ignition.
It comes from the hippocampus.
It doesn't come from the external world,
but it comes from the hippocampus being able to replay
and eventually ignite an entire assembly
in a prefrontal cortex and related areas.
So once again, this is not a localist theory.
I think because it is a global workspace,
it needs a distributed system.
And I don't like the idea of reducing it
to just prefrontal cortex.
I think it's very likely
that the hippocampus plays an important role.
Now we know that if you have a lesion in the hippocampus,
you can still be conscious.
Again, this points to the idea
that this is a distributed system.
It's not one node that will knock it off,
but still dynamically these nodes
tend to come up together when they're activated.
Great.
Thank you so much, Stan,
for all these enlightening answers to these questions
and to the wonderful talk once again.
We could go on forever with these questions.
There are many more popping up,
but in the interest of time,
and because we have the panel
to be able to continue the discussion,
I think we will move on.
So thanks once again.
So please, everybody, join me in thanking Stan and Stan
for this amazing keynote lecture at May 2020.
And we will be closing this session
in a few, maybe in about a minute or so,
before we switch on to the next one,
which is going to be the panel discussion.
And just one note,
because we are many people meeting,
we cannot have the panel discussion,
at least from the speaker's perspective,
in Crowdcast.
You all stay on Crowdcast,
but we will be moving to Zoom
and will be re-broadcast through Crowdcast.
So you don't have to worry about anything.
Just the speakers,
this is a reminder to the speakers joining the panel.
You now need to close your Crowdcast window
and switch to the Zooming that we sent you.
But for everybody else,
just stick around.
Everything is going to continue happening
on Crowdcast.
Fingers crossed, everything goes well.
I hope.
So thank you once again.
And one last comment that I'd like to make,
this is out there for the students,
newcomers of the field,
and people who have heard a lot
about consciousness this morning
and who might not have the background
and find it interesting,
or who have some background
but would like to know more.
I would just like to point out
there's going to be an introductory lecture
tomorrow morning,
because tomorrow is our introductory courses lectures
of May 2020.
And there's one tomorrow,
which is going to be given by
Stephanie,
so Professor Stephanie Blain-Morais
from McGill,
who's been working on consciousness
for quite a while
and has a strong expertise in field.
So she will be giving a talk on the introduction
to the basics of studying consciousness
with neuroscience.
So the neuroscientific approaches
to the study of consciousness
and introduction.
That's going to be actually the opening lecture
tomorrow morning at 8 or 8.20.
I think it's 8.20 tomorrow morning.
So make sure you don't miss that.
And so that's all I wanted to tell you right now.
We'll be closing this session
and meeting up again
in a couple of minutes
for the panel discussion.
And just to let you know,
the panel discussion is going to be when we start it.
You will see there will be some questions
that will be sent in the poll.
So down at the bottom,
you'll see appearing a button
where you can press
and we've prepared a couple of questions
because we want to ask you,
make this more interactive.
So there'll be two or three slightly provocative
or confusing questions about consciousness.
So as soon as you see those questions,
the poll appear,
please answer those questions
and we'll have a look at your answers.
Thanks once again
and thank you to all the speakers.
