about carefully choosing
the smallest amount of data
in the algorithmically
minimally complex way
to get to the same
reduction of uncertainty
or increase in evidence.
That means the challenge is using
small amounts of data
very carefully selected
to solve the problem.
That's not what current
sort of industry
artificial intelligence
is interested in. It's going in exactly
the other direction exploiting the availability
of very large amounts
of data labels,
exploiting leveraging Moore's law
and actually
celebrating the computational complexity.
For me, that's obscene
because the
computational complexity is part
of the variation free energy. It is
fundamental of this variation principle
of least action.
So I haven't seen much movement in that
and indeed we have been told by the good
and great in charge of the money in this area
that some bright-eyed
youngster like you or somebody like me
is not going to change the direction of this
oil tanker. That's where it's going.
But in your robotics, certainly
in the industrial scale
where you actually have to make real things
actively engage and interact with the world
I see active inference making a much more
simple, elemental and fundamental
difference. Just putting
servers and reflexes. Inference
is panning
on top of existing
robotics starting to think more
about sort of interpersonal
exchanges with robotics and the like.
I see that's probably
industry-wise making a difference
purely engineering perspective.
Just on the physics, I have one question
here from Ralph Hafner at the University of Rochester
who's
asking, does the free energy
principle also apply to purely physical
systems?
How is it different from Hamilton's
principle of least action and if so
what does it add? And if it does
not apply to purely physical systems, wouldn't
that make it falsifiable after all?
And just to mention there's been at least
10 or 15 people asking whether the theory
is falsifiable.
This is all you.
That is clearly a question for the physicists.
I'll do the physicists one, but the falsifiable
one, that's yours.
You'd religiously not use the word scheme.
You'd be very careful in the use of the word
frameworks.
I think you should go first though.
Sorry, that's my part.
The free energy principle,
the way the story was told here was
concise, almost
at the point of being tongue in cheek about
what the underlying equations are,
what it would look like from the point of view
of biological sciences, but the back
story is
a version of Hamilton's principle of least
action, not actually Hamilton's principle of least action,
but it is a variational principle of least
action.
It certainly
applies to physical systems, in fact we go a little
bit further, it would say that physical systems
inherit from the
same variational principles
that give rise to the
free energy principle.
The idea is you've got this
variational principles
based upon random
dynamical systems.
When you have random fluctuations
that dominate those, you get quantum physics.
When you deal with ensembles
you get statistical thermodynamics
or more precisely stochastic thermodynamics.
When you take
random fluctuations out of the game
you get classical mechanics and then you get
Lagrangian Newtonian mechanics
and Hamiltonians
come to the fore.
When you put
the Markov blanket, which we haven't spoken about,
but if we
frame this
self-organization in terms of
inference, you then get the Bayesian mechanics,
which is the free energy principle.
It doesn't explain
physics, but it inherits from exactly the same
maths that quantum physics
and other physics explain.
Again, it's not
falsified, but it's not there to be falsified.
It's not a theory that requires evidence.
It's just a mathematical truism.
Clear.
I'll answer your question.
I have one for Jeff here.
Someone has asked, following up,
which I think is an interesting question
which you've touched on, on
Rammstadt et al's 2019 work,
are generative models better conceived
as encoded in the brain
and enacted by agent and
environment?
Where does the model
live?
If it has a subscript
M, it's in your brain.
I think that's my short
answer.
It is part of the definition of
your computational energy, is the
set of available generative models,
and then the other thing that's important
is the restrictions on the set of
posterior distributions that you're capable of
of generating and representing.
So, brain.
Of course, as an extreme skeptic,
there is nothing outside of that.
So, I think that's why I have
my answer that I'm happy with.
I'd agree.
It's the free energy
gradients that drive the dynamics.
You need to define
the generative model to define the gradient,
but it's the gradient itself that does the heavy lifting.
Therefore, strictly speaking,
there is no generative model sub M.
It's just that which would be necessary
to explain the gradient flows and the dynamics.
He's frowning.
We've found a point of controversy.
Sorry, it sounds like you're saying
you don't even have a generative model
as long as you have the gradients.
I think from the point of view of a physicist,
that's probably right, yes, but if you wanted to interpret...
What if I don't want to do gradient descent?
I like coordinate descent
personally, and so
those gradients are a little different.
I think even when you move
to a coordinate descent,
so I don't mean to say that you can
write down a scheme that will optimize
something or self-organize
your particular attracting set of states
in the absence of a generative model.
I'm just saying that the generative model
is a mathematical construct.
You will only find it expressed
in the machinery during the message passing
the coordinate descent or the gradient descent
in the brain itself.
So you'll see reflections, a bit like
cortical hierarchies in a hierarchical generative model,
the factorization into where and what
in terms of mean-filled
approximation of latent causes
of sensory input.
But mathematically,
the generative model
itself does not exist as a physical object.
Is that still true when you're doing model comparison
inside the brain? Because you have multiple generative models
that are currently in sync? Because it seems to me
in that situation, you do need to evaluate
the probability of the data
given each of your models
