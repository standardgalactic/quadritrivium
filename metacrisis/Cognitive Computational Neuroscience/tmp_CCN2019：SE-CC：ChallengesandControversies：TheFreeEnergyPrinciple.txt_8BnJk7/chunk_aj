real question which goes back to
falsifiability, which I think a lot of people
are interested in here and
let me just make sure I understood Jeff's
proposed experimental
strategy. So you're thinking about
defining some generative model
imposing it on an experimental subject
so that you
know what the optimal policy
is, the optimal posterior is, and then looking
for deviations and thinking and trying
to examine to what extent you could explain those
deviations in terms of some restriction
on the posterior. Is that correct?
Yes.
So that strikes me as
not being a strategy for falsification because
assuming
that
the way in which you pick, you're
looking for restrictions such that
when you minimize
free energy, that restriction
will satisfy the minimal free energy.
That's
maybe implicit in the way that you've set it up
but maybe not. It seemed to me that what you'd
really want to be doing is
impose the generative model
or at least separately elicit people's
assumptions about the generative model and
try to then characterize their prior
beliefs in terms of some restriction
on the variational family
before they've seen data
and then ask after they've seen data
would the
posterior within that restricted family
reduce free energy?
Note that it doesn't have to minimize free energy
so that kind of short circuits
the question about the algorithms because
even if you just take a gradient step
in that direction, you're at least reducing it
but if the free energy ever went
up, if people ever chose
an approximate posterior that increased
free energy, that would be
I think decisive falsification of the
free energy framework conditional
on having pinned down all the other pieces.
Well, perhaps not. Not enough samples
is a reason why free energy
can blip up.
Well, it depends
what you mean when you're talking about samples. So there could be
a sample based variational family
but then that would be part
of your specification of the variational family
that you do in the first part of the experiment
or I think what you're saying is
maybe that people are approximating
the expectation
with a bunch of samples and they didn't take enough
samples. Is that what you're talking about?
In my experience
there are two reasons why free energy goes up
it's usually because
that's the hardest thing to code up
is the evaluation of free energy
for me personally. So in other words
it's a bug. The other cause
is
because I'm doing something that's
I'm using some kind of stochastic method
that's the only thing that ever
causes it to go up in my experience
but then again, how would we
evaluate that behaviorally? I don't know
I just want to clarify
what you're actually falsifying
in the silly example I gave
is that the brain is optimally Bayesian
on this task.
That's already false, right?
Yes, but well, depends on the task
I could probably
I guarantee you that there are some
paths out there in general.
There's plenty of examples where the brain is not optimally
Bayesian. That's right.
Those are the interesting examples
because that's where we can start
nailing down the question. Okay, the falsifiable
thing is, is the brain optimally Bayesian? No.
Now we need an explanation. There are a variety
of different explanations, many of which
would take two forms, at least
within this framework, right? Wrong P
wrong Q
or severely limited Q
and we have to explore
those. We can do model comparison to see which one
is right completely within
this framework in terms of right as in
best fit to behavior
and that's the best
you can do. So the funny thing
about type of falsifiability is that
to a large extent it's not
like this is not a falsifiable
theory. Most theories of interest
complicated theories are not really falsifiable
in my opinion.
It's really, we would love to
live in the, I'm just going to finish
it, it's okay. Trust me, I'm just going to
interrupt you until I'm done.
I would love to
live in like a nice world of falsifiable
theories but at this point we don't have
any, right? We have descriptions of behavior
some are better than others and we use model
comparison to say this is right, this is wrong.
Very interesting that happens a lot of times when we're looking at human
behavior is that there isn't a single
model that fits everybody.
It's
incredibly rare. People use
a variety of different strategies to solve
exactly the same problem, often
with very minimal differences in reward
rates. You know,
I'll talk about specifics later, it's not
really important now.
So where does that leave us?
That leave us with the best description of behavior
and again this is now the skeptic talking one more time
last time, I promise.
Oh
crap, I skits down on what I was going to say.
Variety
of ways to do that. No, that was
okay, yes.
No, okay.
At the end of the day
science, in my opinion
is about prediction
and data compression
and not about truth.
It never bothers me
at all when
a hypothesis is not
falsifiable. I
really only care about those two things
and prediction is really the only thing I care about.
But I think the point still stands.
And if I'm marginalizing, I mean that's the automatic occupancy
effect of like doing Bayesian inference. Yeah, you got a bunch
of models that are way over parameterized,
they're total, they're not really useful, so what do you do
with them? Low posterior probability, they're gone.
You're doing great prediction because
you're focused on the models that actually work.
But my point was
I guess less about falsification and more just about
is there some distinctive prediction
specifically of free energy
that is
independent of the particular choice of P and Q
and the core prediction
has to be that free energy has to go down.
Right? And so
if it goes down...
If it doesn't, it's because
you're using the wrong Q.
That's the sense in which it's not falsifiable.
That's it.
I think it's still on the board.
That SG is you.
Paraphrase slightly.
SG is what?
Yes, yes.
I always say SG is you.
Good.
Thanks.
More on falsifiability.
Because I...
If I can leave this debate
and not spend the next several years testing
hypothesis that cannot be true
or maybe it's trivially true,
I would like to avoid it.
Just to bring it back
to some of the work that we've seen today
the scruffies
have given us over the past several years
a bunch of neural networks.
They take images
