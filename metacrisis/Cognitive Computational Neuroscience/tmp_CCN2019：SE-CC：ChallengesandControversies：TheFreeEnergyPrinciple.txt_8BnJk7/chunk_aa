Okay, let's start. Good afternoon everyone. It's my pleasure to welcome you to CCN's
Challenges and Controversies session where we will collectively discuss and
hopefully debate the free energy principle. So as you may know, the free
energy principle or active inference has been developed and applied in the
neuroscience community for the past 15 years, particularly in the field of
cognitive neuroscience and psychiatric research. And somewhat in parallel, it's
developed into a good model and robust debate amongst philosophers, particularly
there in the field of consciousness research and embodied cognition. And even
more recently, the framework has reached formally into physics where the maths
have been unfurled to reveal Schrodinger's equations, Maxwell's law of
electromagnetism and wave particle duality. And this is all afforded by
dynamical systems theory and Markov blankets, where spatiotemporal
recursions of a single idea, the drive to minimize free energy, speaks to
thinness across multiple scales from quantum phenomena to large active
particles like ourselves. So today in this session, I hope we can cover the core
concepts and mathematics and its implications for the study of the
human brain and cognition. And the format for the next hour and a half, we'll see
introductory remarks from our discussants for 15 minutes or 20 minutes a
piece, followed by hopefully a lively debate and Q&A from the audience. So
there'll be no prerogation here of our parliament. And to facilitate audience
participation, we'll have one roving mic. And I've also set up a poll
everywhere channel where you can submit your questions live now or during the
introductions or during the discussion via your smartphone or your laptops.
And so to do this, you go to pollev.com and enter a username which is me
Rosalind M092 or you can go directly to pollev.com forward slash Rosalind M092
and it's written on the boards here. And there you can submit your questions and
I'll pass them to discussants depending on how much time we have, we'll get
through as many as we can. If we have a lot of questions, I'll be updating the
live polls, so be patient if the polls fill up. I'll be putting a new poll on
the same address. And do add your name and institution to the end of the
question if you so wish. Okay, so to our discussants, they say that a good
boxing match is not based on opponents of different abilities, but on
matching opponents of different styles. And so today I think we'll have a very
good boxing match. Since in the red corner and in the blue corner, we have
two exceptional scientists who have in some ways sympathetic views and ideas,
but distinctive points of view. So in the red corner, we have Professor Carl
Friston. Carl is the scientific director of the Welcome Trust Center for
Human Ear Imaging at University College London. Carl is the originator of the
free energy principle and you might say has published extensively in the theory
from its development to applications across the fields I've mentioned. And in
the blue corner, we have Professor Jeff Beck. Jeff is professor of neurobiology
and biomedical engineering at Duke University and at Duke Institute of
Brain Sciences. And he is well known to this community for his seminal
contributions to probabilistic coding, Bayes in the brain, in sensory motor
domains and also in higher cognitive functions studying decision making
across species. So thank you both sincerely for agreeing to come and
participate. So from the rumble in the jungle to the thriller in Manila, we now
have the Battle of Bayes in Berlin. And so with that, for round one, let's
welcome Carl Friston.
Well, thank you for our invigorating introduction. It's clearly a great
pleasure to be here. And I'm flattered in a perverse sort of way, you know, to be
controversial. I don't think I've normally cast as controversial, so that's
good. And the last time I had to do something that was controversial was to
discuss different ideological positions under the banner of neats versus
scruffies. I don't know if this is a sort of dichotomy which people are aware of.
I liken this to a sketch, a sort of pre-Monte Python sketch in England where
class wars were the thing in the 1970s and 80s. And here we have John Cleese and
the two Ronnies talking about the class that they come from. And this tall
gentleman here is upper class, and he looks down upon this gentleman here who is
middle class, who in turn looks down upon Ronnie Corbett, who in this sketch is
very lower class. And I'm going to make the position, just to situate the
debate, I'm going to make the argument that this hierarchy of ideological high
churchness is parallel in the neats versus the scruffies and the mystics. From
our point of view, I'm going to associate the neats with physicists, people who are
in search of simple, unifying, neat explanations for everything. And I'm
going to contrast that with engineers who are the scruffies. And these are people
who are much more pragmatic and they want to know what works. So they will
adopt anything that works. And from our perspective, that could be 20th century
behaviorism, reinforcement learning, drift diffusion models, temple discounting. If
it works, use it. And then we have the mystics. Now I usually have psychologists
under that, but I thought there would be too many. You've got to keep the crowd
on the side, haven't you? So I've made them philosophers. We don't need to talk
about them any further. So in four slides, my brief is four slides through the
free energy principle. So here is the free energy principle in four slides. At its
simplest, it just says everything that can change will change to minimize
variational free energy. And that's sometimes articulated, particularly in
philosophy, as self-evidencing. Now free energy here, I've expressed in terms of
complexity minus accuracy. And that mathematically provides an upper bound on
a quantity known as log evidence or just evidence or marginal likelihood. That's
the probability of some outcomes or observations given a model or my
understanding of how those data were generated. So I'm going to focus on this
decomposition as a way of understanding the role of minimizing complexity whilst
providing an accurate explanation for the sensory observations at hand. And
motivate the importance of that just by unpacking the different kinds of
interpretation one could bring to bear to understand what this quantity is here.
The log probability of some outcomes at some time, possibly in the future, given
a model of how those outcomes were generated. And if you associate that
log probability with value, what we're basically saying is that minimizing free
energy is the same thing as minimizing a bound on value. And I should say if you
come from machine learning, this is exactly the same as the elbow or the
evidence lower bound using things like variational autoencoders. But from point
of view of a psychologist, it could also be value. It could be the sort of
expected reward that you will obtain pursuing a particular course of action.
So this can be regarded as a statement of the imperatives that underwrite
reinforcement learning, optimal control theory, and indeed in economics expected
utility theory. So that's nice. That covers a large bunch of people. There are
other groups of people who would think more in terms of information theory. So
the negative of this value is called self-information in information theory,
also called surprising. And it is the quantity that's upper bounded by the
variational free energy. And minimizing self-information or minimizing
surprising is essentially the same as maximizing the mutual information. And
from that, you can spin off the principles of minimum redundancy, the
principles of maximum efficiency, the information principle of Ralph Linska, and
indeed the free energy principle itself. That in turn is nice because the
expected, the time average of self-information is known as entropy. So
what we're saying is if everything has to minimize free energy, then it has to
basically minimize over time entropy. And of course that is the holy grail of
self-organization in physics, synergetics, and of course if you're a
physiologist, it's just homeostasis. It's just keeping outcomes within
physiological bounds, preventing the dispersion and the tendency to
disorder that one normally attributes to the second law of thermodynamics. But
there's a final interpretation here which might appeal to many of you in the
audience, and that's this drilling down on this marginal likelihood itself. So
if I interpret M as a model of, a gerontic model, of how these data were
generated, then this becomes model evidence, also known as integrated
evidence, which means that minimizing free energy is simply a statement of the
fact that or an imperative to maximize the evidence for one's models of the
world. And from that we can develop the Bayesian brain hypothesis, evidence
accumulation, and things like predictive coding. And that's largely the
perspective that I'm going to adopt on free energy minimization. There's another
move entailed by the free energy principle, which is probably less
familiar to many people. It's not just about inferring the best explanation for
the causes of your sensorium. It's also inferring what you're going to do. It's
also about what are the best data or sensory samples that with my active
palpation of the world, I can gather together in the aid of minimizing free
energy or maximizing the evidence for my own models. And we're appealing here to
very old ideas first elaborated by people like Lindley in terms of optimal
Bayesian design. So it's not about building good models of data. It's what are
the best data you can go and actively sample from your world in order to
afford the best kind of inferences about the causes in that world. And
that's formally can be articulated in terms of perception being in the game
of minimizing free energy. Basically the difference between your posterior beliefs
about hidden or latent states of the world at some time, possibly in the
future, in relation to your two posterior, which is the bound, and this is the log
evidence here. So policy selection in this expression here, where Pi denotes a
policy, is all about minimizing the free energy consequent upon taking a
particular policy or acting on the world in a particular way. And all we need to
do is to take the average free energy under our beliefs, our posterior
predictive beliefs, about the outcomes that would ensue if I did that. And if we
applied that to the free energy expression here, we're now conditioning on a
particular policy and we're just slightly relabeling and rearranging the
terms to express it in terms of a mixture of incentives and values. And
I've written them down here in terms, there are a number of ways of unpacking
this and I'll do that in a second, in terms of instrumental and epistemic
value. So what does that mean? Well, if I just focus on components of the terms
of the expected free energy and pretend that we had an agent or somebody who
had no particular prior preferences, no value, extrinsic value or reward
preferences, then we're left with these two terms here. And it turns out that
these are exactly, or this is exactly the quantity that's optimizing optimal
Bayesian design. In the visual neurosciences, it's known as Bayesian
surprise, popularized by people like Christoph Koch and Itty and Baldi.
Mathematically, that is exactly the same as a mutual information between
outcomes and their causes in the future. And of course, that is consistent with
the principle of maximum efficiency or minimum redundancy articulated by
people like Horace Barlow. Let's just now take two sorts of uncertainty
out of the mix and see what this expected free energy looks like. And I'm
hoping that you will start to recognize the terms. So the first sort of
uncertainty is basically ambiguity. I have no ambiguity about what's out
there beyond my sensations. I can see the states of the world directly. And
that just leaves us with these two terms here that basically score the
difference between what I will predict will happen and what I prefer will
happen. And that's known as a KL objective function for KL control in
optimal control theory. Or if you're an economist, it's risk sensitive
control to minimize the outcomes of behavior in terms of my expected
outcomes in relation to my goals or what I prefer to happen. Now I'm going to
take the final source of uncertainty, which is what will happen if I do that.
And if we take both sorts of uncertainty out, we're right back to
reinforcement learning expected utility theory. So the expected outcomes on my
prior preferences under what I think will happen. The point here is that
these are all internally consistent and equally valid ways of trying to write
down optimal behavior, but they are all special cases of one imperative, which
is to minimize the expected free energy or maximize the expected evidence for
your models of the world in the future. I won't go into this in detail.
Rosalind's is intimated you can extend this argument right down to quantum
physics or right up to evolution. And many people have started to do that by
putting a Bayesian gloss on in theoretical biology in terms of evolution.
Practically though, I just want to conclude with a comment upon the
expiry scope and what this actually means for people creating artifacts or
creating prediction machines to explain, say, fMRI responses in the
ventral stream. It is neat and simple. That's the whole point about being a
neat or a physicist. It's just basically saying what we have to do is to
provide accurate accounts of our world, of the sensed world, that is as
minimally complex as possible, thereby maximizing the evidence for me as a
model of my world. And this complexity term is extremely important. It's just
Occam's principle. And from that, we can motivate certain factorizations that
simplify a journal model of the world. You can get into functional specialization
as the neuroatomical or functional anatomy that belies or speaks to that
factorization. We can talk about redundancy minimization, the shape of
receptive fields and maximize the information gathered from the
environment, efficient coding and so on. We can also think about this from the
point of view of pragmatism and economics. What we're talking about,
because we're using an evidence bound, we're talking about bounded
rationality, slightly disingenuous use of the word bounded rationality from
the point of view of the economists, but it's still bounded rationality. It's
perfectly base optimal, but it's using an evidence bound. And that is the
definition of approximate base inference based upon free energy bounds. It
also very gracefully accommodates heuristics that emerge in many different
levels. So in economics, it would be Lorenzo like heuristics. These are just
priors, empirical priors that have inherited from your parents or neuro
development or some other form of Bayesian model selection. And if you're an
