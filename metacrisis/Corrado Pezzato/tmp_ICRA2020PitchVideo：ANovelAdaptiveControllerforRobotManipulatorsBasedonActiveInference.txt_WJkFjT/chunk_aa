Hello everyone, my name is Corrado Pezzato, I am part of the Connective Robotics Department
at the Technical University of Delft in the Netherlands.
This video presents our work on adaptive control for all manipulators through active
inference.
Before diving into the presentation, I would like to thank the institutions that allowed
all of this, in particular the Systems and Control and Country Robotics departments at
the TU Delft, as well as Ahol de Heize, which partially supported this work within ERLAB Delft.
First of all, why do we seek for adaptive controllers for robot manipulators in the
first place?
The first industrial manipulators were used in pretty structured and safe environments
surrounded by big fences.
The robots had to perform always the same task with very little variations and were provided
with an accurate model for control.
In recent approaches, verbal manipulators are being applied in more dynamic environments.
Here, the work cell has to be flexible enough to handle different packages, which can have
different shapes, weights, etc.
More cutting-edge and future applications are trying to increment the cooperation between
humans and robots, which are now sharing the same workspace.
And as you can imagine, in situations like these, we cannot provide any more an accurate
model for control.
Thus, we need more controllers that can adapt to large uncertainties.
Thinking about the manipulation task from the perspective of a human, you can realize
that we rarely have an accurate model of what we're handling, yet we can achieve amazing
motions.
In our work, we took inspiration from a neuroscientific theory proposed by Carl Friston called Active
Inference.
This theory tries to explain how our brain might function in terms of both perception
and actions, capturing the adaptability skills of humans.
The premises are that we can derive a control scheme which avoids the use of accurate models,
and which is also adaptive against large uncertainties.
However, when we started this study, the published work on Active Inference Robotics was really
limited.
The main problems of fast solutions were that Active Inference was too computationally expensive
and had poor performance.
But we will see how with our work, we overcame these limitations.
Since Active Inference is a fairly new concept in the field of robotics, I'm going to describe
its working principle, to have a common ground and understanding.
Let us assume that we have a real process that we want to control, let's say a robot
arm.
This robot arm can be represented by a number of states, X.
To control the robot, we have of course our Active Inference controller, which can sense
some noisy quantities from the real process through the sensor input.
The controller also represents the real process with a pretty rough model.
In particular, it has an internal representation, so an internal belief, mu, about the real
states, X.
The controller also encodes two generative models.
In particular, the first one, G, explains the relation between Y and mu, and the second
one, F, represents the belief about the evolution of the states.
Furthermore, the controller can apply some control actions to their robot arm, Torx,
for example.
Doing so, it can change the sensor input in order to match a desired sensation.
As a recap, the controller uses the sensor input together with G and F to refine its
internal beliefs, and the controller uses actions to match a specific desired sensor
input.
Going a bit more in details, how do we update the beliefs and how do we compute the control
actions?
Well, the belief update and the control actions are computed through the minimization of one
single function, the so-called free energy, using a gradient descent.
The controller can suppress the free energy by changing the two things it depends on.
It can change its internal beliefs about the external states, so performing filtering and
state estimation.
Or it can change sensor input by acting on the environment, using the control actions.
So to be able to compute the beliefs and actions updates, we have to specify the relation between
the states and sensor input, so G, but also the expected evolution of the states, F, and
the effects of the control actions on the sensor input.
In our work, we formulate the first active inference controller for online closed loop
chain space control of industrial robots, using Torx commands.
We impose the states to be controlled as the joint positions, so geo-mu is simply mu.
Also we use low-level Torx commands for each joint.
To define our active inference controller, we have to make several design choices to
define the expected evolution of the states, F, and the effects of actions into the sensor
input.
But the key point here was really to keep it simple.
So instead of modeling the true dynamics through F, we impose that the states should
evolve as a first-order linear system, which converges to a desired value mu D.
To compute the control actions, we have to specify the two partial derivatives, which
represent the effect of a torque on major position and velocity.
Possible ways of doing so are deriving the dynamic equations, but this would defeat the
purpose of our study.
Or we could learn the dynamics, but as we saw in past work, this requires a lot of
data and can produce unreliable results.
Finally, we could approximate the dynamics, relying on the high adaptability of active
inference.
This was the way we chose to pursue.
The approximation we introduced was to only encode the sign of the full-time variable
relation.
This means basically that a positive torque leads to a positive acceleration.
Using active inference, we then derived a model-free control law, where instead of modeling
the true and no dynamical process, we define a reference model that active inference has
to follow.
To evaluate the performance of our active inference scheme, we chose a model reference
adaptive controller as benchmark, due to its similar characteristics.
In particular, also the MRAC does not require a dynamical model of the plan to be controlled.
For the tests, we used a Franca emica-panda 70-crisis freedom robotar, basically the active
inference and MRAC are a tuning simulation using a heavily approximated model, with fairly
wrong links masses and inertias.
Then, the controllers are directly applied to the real robot to appreciate their adaptive
properties.
First of all, we would like to point out that the active inference controller could be transferred
from simulation to real robot without retuning, while MRAC causes safety stop.
We can see, however, some oscillations for the second last joint of the robot, but these
are at the end, dampened out.
After retuning on the real robot, we used both controllers in a pick-and-place scenario,
in case of an empty and a full bottle of water.
In general, we can see that the active inference controller has a smoother response, which causes
less oscillations in the handled object.
And this can also be appreciated looking at one cycle in joint space, where the active
inference controller achieves the set point in both a faster and a smoother manner.
And this brings us to the discussion section.
The active inference controller resulted in a very adaptive and yet compliant robot,
which is also easier to tune, having less tuning parameters.
In fact, the active inference controller has only 6, compared to the 119 of the MRAC.
Besides, the control scheme is computationally inexpensive.
We were able to provide a control torques within a hard well-timed constraint of 300
microseconds, using just a standard laptop.
However, a form of stability proof for the algorithm is still missing.
To conclude, the main contributions of this work and take-home concepts are that, first
of all, we confirm the value of active inference for adaptive control, providing experimental
evidence.
Doing so, we provide the first active inference scheme for online closed loop torque control
of robot manipulators.
This scheme is model-free, easy to tune, and computationally lightweight.
Besides, its adaptive properties allow also to transfer from simulation to real setup
without retuning.
In all the tests we did, we outperformed the benchmark MRAC, however, as we told you before,
even if we have a strong evidence of stability of our active inference controller, a formal
mathematical proof is still missing and will be part of future work.
This concludes the presentation, so thank you very much for your attention, and we'll
be happy to answer any questions you might have.
