about Frequentism and Bayesianism.
Bayesianism.
Well, thank you.
I'm glad to be here.
So my name is Jake.
I work at University of Washington in the East Science Institute,
and we'll have a table outside to talk about the kinds of things we're doing.
It's really, really some exciting work.
And what I wanted to talk about today is this kind of divide and statistics
between Frequentism and Bayesianism.
This is something I find in my teaching that a lot of people have heard of,
but don't really know.
And from my own experience, I remember as a grad student,
kind of hearing these words.
And I even took a course in computational physics where the professor
spent a whole day telling us about the differences,
and at the end of the day, I had no idea what the differences were, right?
So my goal here in this talk is to kind of go through basically
the essential differences of what Frequentist and Bayesian statistics are.
You know, it's this kind of divide in the statistics world
that lots of people talk about, but in my experience,
not a lot of people know exactly what the whole issue is.
And I want to give you a brief discussion of some of the tools available
to allow you to do Frequentist and Bayesian analysis in Python.
And then also, being who I am, it's all going to be a thinly veiled argument
to tell you why you should be a Bayesian.
So get ready for that, too.
So what this talk is not, this is not a complete discussion of this by any means.
It's not a complete discussion of any of the examples.
I'm anticipating lots of people raising their hands
and talking about the things that I overlooked in these examples that I'm giving.
There's a lot, and if you want to know more,
I think I did a good job in the proceedings paper that accompanies this.
So that'll come out within the next week or so, I hope.
So anyway, Frequentism and Bayesianism, what it basically comes down to
is a question of philosophy, and that philosophy is what you mean by probability.
So this whole thing is just a question of what is probability,
and everything else is derived from there.
So what is probability?
For Frequentists, a probability is something that's related to
the frequencies of repeated events.
So if we say that there's a 50-50 chance that a coin toss will land heads or tails,
the reason we know that is because if we toss a coin over and over a thousand times
and somewhere around 500 of those will be heads and 500 will be tails.
For Bayesians, it's a little bit different.
Probability for Bayesians is fundamentally related to our own certainty
or uncertainty of events.
So when I say that I'm 50% sure that this coin will land heads as a Bayesian,
it's not because I've sat there and tossed that coin a thousand times
or even imagined doing that toss.
It's because I've somehow assigned some sort of probability to define that uncertainty in my knowledge.
It's a 50-50 chance.
And this fundamental difference kind of boils up through all the methods
that have been developed in both these areas.
And keep that in mind.
This is what we're talking about, difference in probability.
And so the immediate consequence of that is that we're analyzing different things.
So Frequentists, since we're talking about the frequency of repeating events,
Frequentists analyze the variation of data and the derived quantities from the data.
So we measure something and that's something we can make those measurements over and over again.
We can analyze how those measurements might vary given our model.
Bayesians, we're analyzing variation of beliefs about parameters.
So basically this is the core consequence.
Frequentists talk about models as being fixed and the data vary around them.
Bayesians talk about data, observed data being fixed.
This is what we've observed and the models can vary around those.
So it's sort of this opposite approach to what's going on in the world.
So I want to do some quick examples and I'm going to run through some of these.
It's going to be a bit of mathematical formalism, a bit of code here and there,
but I'm hoping some of this will make some of these issues more clear.
So for example, if we're looking at a star, we have a telescope and we want to know how bright that star is.
We measure the flux and here we're measuring the flux 50 different times
and you have each one, you have some value and you have an error on it.
And the question is given these observed flux values, what's the best estimate of the true value?
You have these repeated measurements, you want to figure out what they are.
So from the frequentist approach, you use something called the maximum likelihood.
Now I'm going to throw up this equation.
This equation just is basically a Gaussian that's centered on the observed value with a width that's given by the errors.
So this is your probability.
If you have a measurement, this is single measurement, this is the probability of what you think the true flux is.
So it's somewhere in there.
And when you have multiple measurements, you multiply those probabilities together into something called the likelihood.
And so this is what the likelihood looks like.
This gray normal curve here is a single measurement.
If we take in a second measurement, we multiply those together and the likelihood is the product,
which is kind of a tighter curve between those.
And if we continue multiplying more and more data points together, that curve, that likelihood gets tighter and tighter around the central value.
And eventually you have, once you put all the data points in there, you have this likelihood that sort of, by the nature of it, zeroes in on the true value.
So here we generated our data with the true flux of a thousand, which is right where that little red curve is centered, the little red likelihood.
So in frequentism, you can actually do this analytically.
You can do the math.
And essentially what you come up with here is a weighted average.
So this is an average.
You sum up all the values times the weights and divided by the sum of the weights.
You're basically taking the mean of all the values to get your estimate.
So this is kind of the thing that you do automatically, right?
If you're measuring, if you wanted to know, if you're just sort of doing it from common sense, you'd maybe take the average of all the values that you got, right?
And you can actually, from the likelihood approach, you can say that's the correct thing to do in the frequentist regime.
So in Python, it's just a couple lines of code.
And for our points, we get 999 plus or minus four.
So we basically recover our input.
Is that all clear?
Yeah, so we're basically, we're doing this maximum likelihood thing.
We're multiplying all those probabilities together.
For the Bayesian approach, it's a little bit different.
What we're interested in fundamentally is a probability.
And when I write up here P of F true and then that little bar and a D, what that says is we're asking for the probability of the true flux given the data that we observed.
So that is what Bayesians are looking for.
And in order to compute that, they use something called Bayes theorem, which is an identity of probability that you can prove and apply.
And what Bayes theorem says is you have this posterior.
This posterior is the thing you're interested in.
It's the probability of my model value given the data that I've observed.
And Bayes theorem allows you to turn that around and ask about it in terms of some other parameters.
So you have the likelihood here, the prior, and the model evidence.
So these are all these, this is all this vocabulary that you need as a Bayesian.
So basically the posterior here is our, on the left, this is our value that we're interested in, right?
This is the brightness of our single star that we want to know.
The likelihood is the same thing we saw in the Frequence approach.
Essentially, we're just multiplying all those probabilities together.
We get that little red blip in the middle.
And then the thing that gets really more controversial is this prior, right?
So in order to flip these probabilities around, mathematically, we need to put in a prior.
We need to say what is the probability of, what's the probability distribution of this value we're interested in before we take any data?
So you could say, you could do that prior based on all the other stars in the sky.
How bright are all the stars in the sky?
We know that our star is among those, so we can do an empirical prior.
Or we can do something that's called a non-informative prior.
We could just say, well, I don't know anything, so let's make all the fluxes equally probable.
And in practice, that's what a lot of Bayesians do.
And in practice, that's what Frequentists complain about the most.
And then the last term is this denominator, the model evidence.
And it's interesting in some situations, but for our purposes, we can basically treat it as a normalization and ignore it.
And with the Bayesian, with a flat prior, we're basically multiplying the likelihood by one.
So we get the same result as the Frequentists here.
We get 999 plus or minus four for this flux.
So what we see is that in these extremely simple problems,
Frequentists and Bayesian results are often distinguishable.
We can't really, we don't get different answers.
But there are some cases as we go, as we get more complicated, that the differences become apparent.
And I've listed a few of these here.
There are things like handling nuisance parameters, these parameters that you don't really care about in the end,
but that are important for the analysis.
The interpretation of uncertainty, that's a really important one.
Incorporation of prior information.
So for example, if you're trying to learn about the expansion of the universe,
and the cosmic microwave background tells you something,
and then you want to add in some extra information from supernova.
That's a way that Bayesian analysis, that's something that Bayesian analysis does well,
is incorporating that prior information.
In comparison and evaluation of models, we're going to focus in on two of these,
the nuisance parameters and the uncertainty.
So looking at nuisance parameters, we're going to go back to a situation that Thomas Bayes himself proposed back in the 1760s.
And this formulation is a more recent one by Eddie in 2004.
So Alice and Bob, we're talking about Alice and Bob who have a gambling problem,
and their friend Carol comes in and designs a nice game for them to play.
So what Carol's going to do is she's going to take a ball and she's going to roll it down the table,
and that ball is going to settle somewhere.
And then after that, depending on the position of that ball,
Bob and Alice both have different areas of the table where they can get points.
So Carol is going to continue rolling balls down the table,
and if it lands in Bob's area, he gets a point.
If it lands in Alice's area, she gets a point.
And the first person to get six points wins, right?
So this seems pretty simple.
You can kind of figure out where things are and figure out who has the odds of winning.
Where it gets interesting is when you cover the table, you make it a black box.
So now we have this model, and all we know are the results.
We get Alice winning, Bob winning. Alice winning, Alice winning, Bob winning.
And you don't know anything about the model inside.
So this is kind of an analog of what we do as statisticians.
We have a model that's kind of this black box that generates data,
and all we get to look at is the data itself, the data themselves.
So here's the question.
In a certain game, Alice has five points and Bob has three points.
What are the odds that Bob will go on to win?
So you can think about this a little bit, and you can basically say,
well, you need to know the division of the table, right?
And this division of the table is an example of a nuisance parameter.
This is something that's really important for our calculation,
but in the end, we don't really care.
We're not really estimating where that first ball is on the table.
We just want to know the results.
We want to know how much money Alice should put down on this answer.
So a frequentist approach.
This is something that might occur to someone who's been working on this.
We need to estimate this location of the ball,
basically how probable Alice is to get a point.
So we can do a quick maximum likelihood estimate,
and we get p equals 5 8, because 5 out of the 8 balls landed on Alice's side.
And we know that for Bob to win, he needs to win the next three rolls,
so we multiply 1 minus p cubed,
and we get a probability of 0.053, which is about an odds of 18 to 1.
So that seems reasonable, right?
A Bayesian approach is a little bit different.
A Bayesian approach involves marginalization.
So when you have a nuisance parameter,
a parameter you don't really care about in Bayesianism,
you just integrate and you get rid of it.
So the way this looks right here is you have this probability of Bob winning,
given the data, is just the integral over the probability of Bob winning
and some p value, and you integrate over all possible p values.
So this is what Bayesians are doing when they're marginalizing.
They're just getting rid of parameters they don't care about.
So you do some algebraic manipulation,
and I'm not going to go into the details of how to solve this.
That's in the paper, but you basically find that the odds are 10 to 1
against Bob winning after the marginalization.
So here's what you got.
You have the frequentist says 18 to 1 odds,
the Bayesian says 10 to 1 odds,
and the question is, who's right?
I'm not going to tell you who's right,
but I'm going to tell you what's different.
The main difference is that the Bayesian approach allows this nuisance parameter to vary,
and the frequentist approach keeps the nuisance parameter fixed.
There's probably some people thinking in here that I'm full of it
because the frequentist can allow nuisance parameters to vary in certain ways,
and you can explore the sampling distribution,
or you can transform the problem,
you can do various things like that.
But what I would say is I think the Bayesian approach
offers a much more natural way to allow these nuisance parameters to vary.
So essentially the difference is that the frequentist
is taking a slice of this joint probability
and gets a very narrow posterior.
It's not really a posterior, but they get a very narrow result.
The Bayesian is taking the whole probability
and kind of squishing it horizontally there,
and in the process of that gets a very, very wide result.
So this is the difference, taking a little slice
versus taking the whole thing and integrating or squishing it together.
So second example, this is one that I think is the most important difference
between frequentism and Bayesianism,
and this is the handling of uncertainties.
So when someone gives you an answer, you say the flux is 999 plus or minus 4.
What does that plus or minus mean?
And it turns out that because of the philosophical differences between these approaches,
it's a very, very, it's a very different thing.
It's subtly different, and it's different in a way that a lot of people miss.
So for frequentists, they talk about something called the confidence interval.
They say if this experiment is repeated many times,
95% of those cases, the computed interval will contain the true value.
So this is a 95% confidence interval.
Bayesian says given our observed data, there's a 95% probability
that the value lies within the credible region.
So these seem really similar, but notice the difference.
The things that are varying and the things that are fixed are the opposite.
So the frequentist keeps the model parameter fixed
and says that the confidence interval itself is varying.
The confidence interval is derived from the data,
which is a random quantity derived from the model, right?
The Bayesian keeps the credible region fixed
and varies the value of the model parameter.
So the model parameter is, this is our belief about the model parameter
that can kind of move throughout space.
So this is the way that they're a little bit opposite.
And this is why for a long time,
Bayesians were called, the Bayesian problem was the inverse probability problem
because you're basically taking the frequentist problem
and you're turning it on its head, right?
And this ends up having some interesting consequences for certain problems.
And I want to illustrate it with this truncated exponential example.
So this is something that James, he was a physicist back in the mid-20th century.
He wrote about in 1976.
Basically, we're considering a model where you have a certain amount of time
given by theta, and after that certain amount of time
you have a probability of something happening.
So for the example that James used,
this was a chemical inhibitor that kept a device from failing.
And then say after 10 minutes, that chemical inhibitor runs out
and the devices start failing with this exponential decrease.
And I put this in a blog post recently and I thought it was pretty cool.
I got an email from a guy in the Institute of Health Metrics at UW,
and he said, this is the exact model that we use for mosquito nets in Africa.
So it turns out that this model actually is applicable.
People are using this sort of thing.
So the question is, you observe some failure times of this device
or you observe when the mosquitoes get through the nets.
And you want to estimate from that how good these mosquito nets are,
how long they'll last before they fail on average.
So we have a couple ways of doing this.
We want to know the 95% bounce on this parameter theta,
how long the nets last before they fail.
Now for the common sense approach, we can look at this and we can say,
well, it's impossible for these to fail while the inhibitor is still there.
It's impossible that the failure starts after a certain time.
So each point that we observe has to be greater than that inhibitor time.
So the smallest observed point here is 10,
so we can immediately say that theta has to be less than 10.
So this is just common sense.
We're not applying any statistics.
Oh really?
I'm running over.
I'm going to finish this real quick.
So a frequentist approach, this is the unbiased approach.
You create an expectation value.
You create an unbiased estimator.
I won't go into the details,
but I can assure you this is the correct unbiased estimator.
You compute the sampling distribution
and what you find is that the 95% confidence interval is between 10.2 and 12.2.
So we've said by common sense it should be less than 10,
but the frequentism tells us, well, it's between 10.2 and 12.2.
So let's see what the Bayesian does.
The Bayesian, again, we use Bayes' theorem.
We compute the likelihood.
With the flat prior, we get a posterior that looks like that.
We draw the limits and Bayes says 9.0 to 10.0.
So immediately right now you're thinking,
frequentism is wrong.
But actually, frequentism isn't wrong.
What we're seeing here is that the frequentism
is answering a different question than what we expect.
And to visualize that,
so basically the Bayesianism is making a probabilistic statement
about the model parameter, that theta that we're interested in,
given this fixed region we've computed.
And on the other side, frequentism is giving a probabilistic statement
about the recipe for computing this bound
given a fixed model parameter.
And, you know, I plan to do way too much in here.
So I'm going to end with just this visual description of what this is
because I think this will kind of hit at home.
So the Bayesian-Credible region looks like this.
We create an interval and we say,
given all these parameters that fit within our belief structure,
95% of those will fit within this interval.
The frequentist version says,
well, we have one parameter and we're going to construct
a whole bunch of credible regions
and 95% of those credible regions will contain this parameter.
But the problem is right now we happen to choose this one, right?
So we can't say that this value has a 95% chance
of sitting in this particular credible region.
But the frequentist result is still correct
in the sense of the long-term limiting frequency
of this recipe for constructing things.
So you've got to remember this.
In general, when someone gives you a frequentist confidence interval,
it's not 95% likely to contain the true value.
And this is a Bayesian interpretation of a frequentist construct
and it happens all the time.
You have to be really, really careful about this.
So I always imagine this sort of conversation happening.
And the statistician says,
95% of such confidence intervals and repeated experiments
will contain the true value.
The scientist says, ah, yeah, so there's a 95% chance
of the values in the interval, right?
And the statistician says, no, you see,
parameters by definition can't vary,
so referring to chance in that context is meaningless.
The 95% refers to the interval itself.
And the scientist says, oh, so there's a 95% chance
of the parameters in the interval.
And the statistician says, no, it's like this.
A long-term, limiting frequency of the procedure
for constructing this interval ensures that 95%
of the resulting ensemble of intervals contains the value.
The scientist says, ah, so there's a 95% chance
that it's in the interval.
And the statistician says, no, it's just,
write down what I said in the paper and the scientist says,
okay, value is 95% likely to be in the interval.
So this is what we have to be really careful about
as scientists, that we don't misconstrue
those frequentist constructs.
I have some other slides, but I'm going to just skip down.
I obviously planned way too much.
These sorts of things happen, you know.
But basically, the conclusions,
so frequentism and masianism fundamentally differ
in their definition of probability.
And in simple problems,
the results are basically the same.
You don't have to worry too much
if you're computing the mean of a distribution.
But what I think I've argued for here,
and people might disagree with me,
is that Bayesianism provides a more natural handling
of nuisance parameters.
So these things that you have to fit into your analysis
but don't really affect the results
except for the intermediate calculations.
And I think Bayesianism provides
a more natural interpretation of errors too.
You know, we don't, with our scientific results,
to phrase it in terms of this 95% of an ensemble
of potentially calculated confidence intervals.
We want to show an interval
and say the parameter is 95% probable to be in there, right?
So I would say that Bayesianism is more natural
for communicating our scientific results to the public.
There's some philosophical issues with priors in there,
and to give a fair treatment,
I probably would have gone over those a little more.
But what I can say is that both paradigms are useful
in the right situation.
And I think it's on us as scientists
to learn the situations where they are useful
and to interpret those results carefully.
So, thanks very much.
APPLAUSE
That was a great talk.
We have time for one lightning quick question.
So, in your first example,
you said that frequentist and Bayesian interpretations
gave different odds.
Isn't that something that a frequentist would say
is empirically testable by running the game over and over again
and finding out how many happen in this situation?
Yeah, the question was,
in the first example of frequentism
and Bayesianism give different odds,
and can't we empirically test that in a frequentist manner?
The answer is yes, and it confirms the Bayesian results correct.
But that Bayesian result is correct
only if you have the prior correct.
So, this is the detail that I sort of glossed over.
The choosing of the prior and the Bayesian analysis
can have some real subtleties,
and if you don't choose it correctly,
you might end up biasing your results.
And I have, in the proceedings paper,
I have some references for that
where you can read a little bit more.
But that's the one thing that you have to be careful about,
is the prior and Bayesianism.
