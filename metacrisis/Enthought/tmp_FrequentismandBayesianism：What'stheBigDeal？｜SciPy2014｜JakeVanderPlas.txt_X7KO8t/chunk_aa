about Frequentism and Bayesianism.
Bayesianism.
Well, thank you.
I'm glad to be here.
So my name is Jake.
I work at University of Washington in the East Science Institute,
and we'll have a table outside to talk about the kinds of things we're doing.
It's really, really some exciting work.
And what I wanted to talk about today is this kind of divide and statistics
between Frequentism and Bayesianism.
This is something I find in my teaching that a lot of people have heard of,
but don't really know.
And from my own experience, I remember as a grad student,
kind of hearing these words.
And I even took a course in computational physics where the professor
spent a whole day telling us about the differences,
and at the end of the day, I had no idea what the differences were, right?
So my goal here in this talk is to kind of go through basically
the essential differences of what Frequentist and Bayesian statistics are.
You know, it's this kind of divide in the statistics world
that lots of people talk about, but in my experience,
not a lot of people know exactly what the whole issue is.
And I want to give you a brief discussion of some of the tools available
to allow you to do Frequentist and Bayesian analysis in Python.
And then also, being who I am, it's all going to be a thinly veiled argument
to tell you why you should be a Bayesian.
So get ready for that, too.
So what this talk is not, this is not a complete discussion of this by any means.
It's not a complete discussion of any of the examples.
I'm anticipating lots of people raising their hands
and talking about the things that I overlooked in these examples that I'm giving.
There's a lot, and if you want to know more,
I think I did a good job in the proceedings paper that accompanies this.
So that'll come out within the next week or so, I hope.
So anyway, Frequentism and Bayesianism, what it basically comes down to
is a question of philosophy, and that philosophy is what you mean by probability.
So this whole thing is just a question of what is probability,
and everything else is derived from there.
So what is probability?
For Frequentists, a probability is something that's related to
the frequencies of repeated events.
So if we say that there's a 50-50 chance that a coin toss will land heads or tails,
the reason we know that is because if we toss a coin over and over a thousand times
and somewhere around 500 of those will be heads and 500 will be tails.
For Bayesians, it's a little bit different.
Probability for Bayesians is fundamentally related to our own certainty
or uncertainty of events.
So when I say that I'm 50% sure that this coin will land heads as a Bayesian,
it's not because I've sat there and tossed that coin a thousand times
or even imagined doing that toss.
It's because I've somehow assigned some sort of probability to define that uncertainty in my knowledge.
It's a 50-50 chance.
And this fundamental difference kind of boils up through all the methods
that have been developed in both these areas.
And keep that in mind.
This is what we're talking about, difference in probability.
And so the immediate consequence of that is that we're analyzing different things.
So Frequentists, since we're talking about the frequency of repeating events,
Frequentists analyze the variation of data and the derived quantities from the data.
So we measure something and that's something we can make those measurements over and over again.
We can analyze how those measurements might vary given our model.
Bayesians, we're analyzing variation of beliefs about parameters.
So basically this is the core consequence.
Frequentists talk about models as being fixed and the data vary around them.
Bayesians talk about data, observed data being fixed.
This is what we've observed and the models can vary around those.
So it's sort of this opposite approach to what's going on in the world.
So I want to do some quick examples and I'm going to run through some of these.
It's going to be a bit of mathematical formalism, a bit of code here and there,
but I'm hoping some of this will make some of these issues more clear.
So for example, if we're looking at a star, we have a telescope and we want to know how bright that star is.
We measure the flux and here we're measuring the flux 50 different times
and you have each one, you have some value and you have an error on it.
And the question is given these observed flux values, what's the best estimate of the true value?
You have these repeated measurements, you want to figure out what they are.
So from the frequentist approach, you use something called the maximum likelihood.
Now I'm going to throw up this equation.
This equation just is basically a Gaussian that's centered on the observed value with a width that's given by the errors.
So this is your probability.
If you have a measurement, this is single measurement, this is the probability of what you think the true flux is.
So it's somewhere in there.
And when you have multiple measurements, you multiply those probabilities together into something called the likelihood.
And so this is what the likelihood looks like.
This gray normal curve here is a single measurement.
If we take in a second measurement, we multiply those together and the likelihood is the product,
which is kind of a tighter curve between those.
And if we continue multiplying more and more data points together, that curve, that likelihood gets tighter and tighter around the central value.
And eventually you have, once you put all the data points in there, you have this likelihood that sort of, by the nature of it, zeroes in on the true value.
So here we generated our data with the true flux of a thousand, which is right where that little red curve is centered, the little red likelihood.
So in frequentism, you can actually do this analytically.
You can do the math.
And essentially what you come up with here is a weighted average.
So this is an average.
You sum up all the values times the weights and divided by the sum of the weights.
You're basically taking the mean of all the values to get your estimate.
So this is kind of the thing that you do automatically, right?
If you're measuring, if you wanted to know, if you're just sort of doing it from common sense, you'd maybe take the average of all the values that you got, right?
And you can actually, from the likelihood approach, you can say that's the correct thing to do in the frequentist regime.
So in Python, it's just a couple lines of code.
And for our points, we get 999 plus or minus four.
So we basically recover our input.
Is that all clear?
Yeah, so we're basically, we're doing this maximum likelihood thing.
We're multiplying all those probabilities together.
For the Bayesian approach, it's a little bit different.
What we're interested in fundamentally is a probability.
And when I write up here P of F true and then that little bar and a D, what that says is we're asking for the probability of the true flux given the data that we observed.
So that is what Bayesians are looking for.
And in order to compute that, they use something called Bayes theorem, which is an identity of probability that you can prove and apply.
And what Bayes theorem says is you have this posterior.
This posterior is the thing you're interested in.
It's the probability of my model value given the data that I've observed.
And Bayes theorem allows you to turn that around and ask about it in terms of some other parameters.
So you have the likelihood here, the prior, and the model evidence.
So these are all these, this is all this vocabulary that you need as a Bayesian.
So basically the posterior here is our, on the left, this is our value that we're interested in, right?
This is the brightness of our single star that we want to know.
The likelihood is the same thing we saw in the Frequence approach.
Essentially, we're just multiplying all those probabilities together.
We get that little red blip in the middle.
And then the thing that gets really more controversial is this prior, right?
So in order to flip these probabilities around, mathematically, we need to put in a prior.
We need to say what is the probability of, what's the probability distribution of this value we're interested in before we take any data?
So you could say, you could do that prior based on all the other stars in the sky.
How bright are all the stars in the sky?
We know that our star is among those, so we can do an empirical prior.
Or we can do something that's called a non-informative prior.
We could just say, well, I don't know anything, so let's make all the fluxes equally probable.
And in practice, that's what a lot of Bayesians do.
And in practice, that's what Frequentists complain about the most.
And then the last term is this denominator, the model evidence.
And it's interesting in some situations, but for our purposes, we can basically treat it as a normalization and ignore it.
And with the Bayesian, with a flat prior, we're basically multiplying the likelihood by one.
So we get the same result as the Frequentists here.
We get 999 plus or minus four for this flux.
So what we see is that in these extremely simple problems,
Frequentists and Bayesian results are often distinguishable.
We can't really, we don't get different answers.
But there are some cases as we go, as we get more complicated, that the differences become apparent.
And I've listed a few of these here.
There are things like handling nuisance parameters, these parameters that you don't really care about in the end,
but that are important for the analysis.
The interpretation of uncertainty, that's a really important one.
Incorporation of prior information.
So for example, if you're trying to learn about the expansion of the universe,
and the cosmic microwave background tells you something,
and then you want to add in some extra information from supernova.
That's a way that Bayesian analysis, that's something that Bayesian analysis does well,
is incorporating that prior information.
In comparison and evaluation of models, we're going to focus in on two of these,
the nuisance parameters and the uncertainty.
So looking at nuisance parameters, we're going to go back to a situation that Thomas Bayes himself proposed back in the 1760s.
And this formulation is a more recent one by Eddie in 2004.
So Alice and Bob, we're talking about Alice and Bob who have a gambling problem,
and their friend Carol comes in and designs a nice game for them to play.
So what Carol's going to do is she's going to take a ball and she's going to roll it down the table,
and that ball is going to settle somewhere.
And then after that, depending on the position of that ball,
Bob and Alice both have different areas of the table where they can get points.
So Carol is going to continue rolling balls down the table,
and if it lands in Bob's area, he gets a point.
If it lands in Alice's area, she gets a point.
And the first person to get six points wins, right?
So this seems pretty simple.
You can kind of figure out where things are and figure out who has the odds of winning.
Where it gets interesting is when you cover the table, you make it a black box.
So now we have this model, and all we know are the results.
We get Alice winning, Bob winning. Alice winning, Alice winning, Bob winning.
And you don't know anything about the model inside.
So this is kind of an analog of what we do as statisticians.
We have a model that's kind of this black box that generates data,
and all we get to look at is the data itself, the data themselves.
So here's the question.
In a certain game, Alice has five points and Bob has three points.
What are the odds that Bob will go on to win?
So you can think about this a little bit, and you can basically say,
well, you need to know the division of the table, right?
And this division of the table is an example of a nuisance parameter.
This is something that's really important for our calculation,
but in the end, we don't really care.
We're not really estimating where that first ball is on the table.
We just want to know the results.
We want to know how much money Alice should put down on this answer.
So a frequentist approach.
This is something that might occur to someone who's been working on this.
We need to estimate this location of the ball,
basically how probable Alice is to get a point.
So we can do a quick maximum likelihood estimate,
and we get p equals 5 8, because 5 out of the 8 balls landed on Alice's side.
And we know that for Bob to win, he needs to win the next three rolls,
so we multiply 1 minus p cubed,
and we get a probability of 0.053, which is about an odds of 18 to 1.
So that seems reasonable, right?
A Bayesian approach is a little bit different.
A Bayesian approach involves marginalization.
So when you have a nuisance parameter,
a parameter you don't really care about in Bayesianism,
you just integrate and you get rid of it.
So the way this looks right here is you have this probability of Bob winning,
given the data, is just the integral over the probability of Bob winning
