It's just information processing, and self-organization just is
the processes that evolve that effectively do believe updating or process information,
usually classical information, you know, when it comes to sort of kind of biotic self-organization
that Mike Levin deals with. So, he's famous for Xenobox and all sorts of really insightful
takes, new takes on cellular and biological self-organization.
You know, some of my favorite ideas are, you know, if you'd, you might like, is that, you know,
when you appreciate that sort of, you know, physics, and this is a Chris Fields quote,
there is no bright line between sort of physics, biology, and psychology. They're all the same
things, just using different words. And Mike takes this to his extreme, what he used to,
he's got more sophisticated in the past review, but several years ago, he had this notion that
cancer was a delusion, a delusion that arose from a pathology of basal cognition, which I think is
why your cells are failing to infer, know their place, they're failing to infer that, no, I shouldn't
be growing in this context. They've got this delusion, oh, I should keep on growing. And of
course, he's absolutely right. So you can even get a computational psychiatry of cancer out of this,
but it does require a commitment to think about all self-organization as basically a process that
can be read as an inference process or a belief of basic dating process, the right kind of
processing and bounding self-information and entropy read from the point of view of information
theory. Chris Fields' particular take comes from his skills with Jim Glacebrook in quantum
information theory. So that's where the information theoretic aspects come, and then you can start to
talk about the relationship between the principles of unitarity and entanglement and the like,
and what that means when read or what it means in terms of a quantum formulation of the classical
reading of the free energy principle that doesn't normally deal with quantum, you know, it usually
starts with, you know, classical mechanics with all the kind of formulation of the like.
I know, I love so much about what you just said, because when I talk about it, I often think about
the same thing. I often call ourselves receiving persons organized by organelles, crafted by cells,
designed by DNA, manufactured by molecules, assembled by atoms, forged by fusion over,
forged by fusion via stellar supernovae. So this is a saying, because I think if you don't
incorporate all these things together, you're just, you're missing out an opportunity not to
reduce things to the nothing but aspects, but rather to grow the complexity of what we're talking
about. You just increase the scope of the conversation so much more by discussing every realm of reality.
And I think you get that, and you seem to be working on that from that perspective as well.
Absolutely. That Gail, I think that's a lovely way that you actually expressed it.
You should definitely get Chris Fields on your podcast, because his big thing is that scale
freeness, that scale invariance. And in fact, I was on a call literally about two hours ago,
where he made, I thought, a delightful point that because the free energy principle is by
construction scale free, it cannot be reductious at the same time. So it is quintessentially
anti-reductionist. So what you just expressed, I think, covered all those scales. And I think
that's part of the saying, your formalism has to be scale free. It has to be deployed
for me, mathematically, in the spirit of the renormalization group. It has to be deployed
time and time and time again. And as soon as you realize that, then you start to ask deep questions
about bottom-up and top-down causation between scales. So as soon as you've got a scale free
theory that can apply either to gamma oscillations in your hippocampus, or it can apply to natural
selection, led as Bayesian model selection. Then you start to ask big questions, well,
how does this very slow self-evidencing process contextualize and be informed by this very fast
self-evidencing process or information processing in a way that is emergent from just having these
same kinds of processes unfolding with a separation in this instance, temporal scales. So, you know,
Chris would wax lyrical for a long time about this. So you should perhaps you can get Chris and
Mike together. I think that's a very good idea. I think I should start doing that. I know the
last, I think you Kurt and Mike, I think spoke together as well, if I recall correctly, I can't
remember. Yes. Yes. I wanted to ask you, when you think about this project that everyone's talking
about, and Markov blankets, do you think that because some systems are so complex, do you
find, do you think there will be any sort of indirect or hidden causal relationships that
might hinder this from happening? What sort of applications or techniques should be employed
to effectively identify Markov blankets within complex systems?
Ah, right. Yeah. So this is a very sort of practical issue. And it would be very nice to be able to
sort of parcelate the brain, for example, or parcelate an institution or an economy to be able
to identify the different Markov blankets given some empirical data. There is a worked example
of this, which is little known because it's just so complicated. It's almost impossible to read,
but I wrote it and I'm quite proud of it. And I think it was in network science, but it was
exactly the challenge of taking brain imaging data with thousands, hundreds of thousands of
measurements of activity over time, and then parcelating it at different scales. So it was
exactly what we're just talking about. It was creating Markov blankets and Markov blankets
and doing it in a way that was empirically constrained by measuring the connectivity
and its sparsity to imply where the Markov blankets were. And then once you've got a Markov
blanket, those now constitute the Intel states of a bigger Markov blanket. And then you can sort
of carve up the entire brain at successively course from course spatial scales. And what was
really interesting is a phenomena that is, I was going to say emergent, but in fact it's actually
baked into the normalization group that you would access mathematically, or you would use to access
the scale free behavior, at least formalize or naturalize it, that things get slower as they
get bigger. So we could actually estimate the time constants of the neuronal fluctuations
and implicit belief updating associated with different spatial scales ranging from a cubic
centimeter or millimeter or so of the brain through to entire frontal lobes. And then we can
extrapolate out to very, very big things and very, very small things and look at the characteristic
time scales. It was just implicit by scanning through the time scales by having lots and lots,
you know, literally hundreds of thousands, well at least a thousand, a thousand little Markov blankets
all jostling together, partitioned and then moving to say a hundred of them and then to ten.
And just by extrapolating, you could then think about sort of collections of brains,
ten brains, or a tenth of a cubic centimeter of the brain right the way down to the quantum scale.
And just look at the different time constants that were engaged. So that was a really interesting
academic exercise, but it did rest as the same, being able to identify Markov blankets. What
you're asking though is a key issue in terms of complex system analysis and modelling, being able
to carve the system in the right kind of way in order to usually to simulate it in a way that
allows you to do forecasting or scenario modelling and the like or projecting a response to a
therapeutic intervention in say clinical neuroscience or psychiatry through to weather forecasting.
You know, getting the right course-graining, the right Markov blankets in plain is absolutely
essential. There are lots of people working on that at the moment. One email exchange I've had
this week is from a gentleman called Jeff Beck who's taken on the very deep challenge
of considering Markov blankets that wander around. So one interesting aspect
of a simple definition of a Markov blanket is that it depends upon a probability distribution
that exists over a non-trivial amount of time. But if you think of something like a candle flame
that is moving and furthermore the constituents, the molecules and the irons that constitute
the plasma that is the surface of the flame, is it fair to say that the flame has a Markov blanket
given all its constituent molecules, i.e. other small-scale Markov blankets, are continually
being exchanged and moving and wandering around. So he's taken on the challenge of taking Markov
blankets into this sort of more liberal domain and dynamic domain and see if one can still apply
the free energy principle in a practical way. But to do that, he has to have at least simulations
on numerical studies that allow him to actually identify Markov blankets that move like waves
in certain media. So that's still an outstanding problem which a lot of people, when I say a lot,
a few key postcomings are looking at and I think it's a very useful ability to be inquiring.
That's quite fascinating. It's great to see that so many different people are working on this at
this point because when you look online and you look at the amount of citations, I mean you are
one of the most cited neuroscientists on the planet and it's great to see that a lot of people
are taking these concepts seriously and trying to roll with it. Looking ahead to the future,
what directions or advancements do you anticipate in the study of Markov blankets, for example,
except for the one you just mentioned? Where do you think the free energy principle is going from here?
I think there are probably three directions of travel and we've implicitly already covered
the most important ones in our conversation. So the first one is indeed computational psychiatry
and computational neurology. I mean in a sense all the work that Chris Frith and I and many other
colleagues put in decades ago into understanding functional brain architectures via brain imaging
was in the service of ultimately asking questions about neurology and psychiatry and much of the
theorising that led to active inference and the free energy principle inherited from the data
analytic and modelling that we were applying to make sense of brain imaging data and realised
exactly the same principles could be applied to the brain or when I say realised we're told by
people like Geoffrey Hinton you can apply the same principles to the brain, the Helmholtz machine.
So that's one direction of travel I think. Again, I use the word naturalising. I recently
learned what it means and I think it's a useful phrase to naturalise psychopathology in a way
that you can write down the laws and the maths and you can start to create in silico patients
and digital twins and intervene on them without actually giving drugs or psychotherapeutic
interventions to patients until you've shown. To a certain extent that style of approach is
already starting to bite not in the context of the free energy principle explicitly but certainly
in the modelling of things like epilepsy. Having naturalised a pathophysiology say the
transmission of epileptic discharges and seizure activity in the brain to the extent you can
actually put it in the computer and start to do weather forecasting of this particular person's
brain and what might happen if we did this and that. I think that's one very exciting way forward.
Another complement of that sort of applied application of the free energy principle
would be the ability to phenotype people. So there's a phrase computational phenotyping which
I quite like which basically means being able to characterize this person or this cohort
in terms of the parameters of their generative models that they use to explain their world
and that provides a really powerful and efficient summary on this person and in terms of their beliefs
and their belief updating and their prior commitments and being able to be able to measure
and quantify somebody in that kind of way can be very very useful not only in terms of tracking
the responses to therapy but also just getting the right nosologies the right way of carving up
various psychiatric conditions and their etiologies because now you've got a naturalised
process theory under the hood. So that's one kind of thing. The other direction of travel I think is
in artificial intelligence just actually building see practically what the free energy principle
brings to the table is not really a pretty first principles account of existence and sentient
behaviour but practically another strange inversion another denit strange inversion
instead of having to instead of having to understand the system in terms of its dynamics
as you would the complex system modelling you're trying to understand the underlying mechanics
by saying well these dynamics this set of say differential equations looks as if
it's performing a gradient flow on this light who not functional this
Lagrangian and I'm going to try and estimate what this what this underlying potential function
is that causes my dynamics and it's best a simple explanation for the complex system I want to
understand. For me of course that's always going to be this surprise or the log marginal likelihood
or the free energy bounds on that but what you can do is if you know that the dynamics of your
complex system can always be expressed as a gradient flow on a free energy functional
of a gerative model where the gerative model just scores or articulates characteristics states of
being that you want to emulate then what you can do is you can just write down the free energy
functional of your preferred states of being and then just integrate the system to reproduce
the sentient behavior that you would have seen if this thing existed and had these was attracted
to these characteristics states so it's a really powerful way of building machines that look as
if they exist in a particular way of course that's the aspiration of machine learning and
artificial intelligence you know and so it's certainly in principle you could deploy the
free energy principle in the context of building artifacts that do the right kind of belief updating
by the right kind of course I mean being able to model their world where their world is basically
the world of users basically you and me which brings us to the third direction of travel which is
the kind that Chris Fifth would like which is you know the explicit acknowledgement that
what is really interesting here is this scale free application of free energy principle where
you've got lots of different free energy minimizing self-evidencing Markov blankets
all living in Markov blankets of a different scale in institutions and theologies and their
ideologies and your ethnic bounds and all that so how does that unfold and how do you get the
right kinds of ecosystems that have this joint free energy minimizing behaviors that does not
incur upon or require certain Markov blankets to be vitiated or destroyed you know so what
we're talking about now is a physics of an ecology that has sustainability at its heart
or at its core because the whole point of the free energy principle it's a description of systems
that have an attracting set and how they sustain themselves within that attracting set so I would
imagine that the free energy principle will be useful and indeed pursuing this with colleagues
that and versus AI so my colleagues in industry this this is one application the free energy
principle in the service of in you know underwriting in a principled way the aspirations of all
right-minded people engaged in designing the next version of the world the world wide web
or artificial intelligence or information services and speak not to growth but speak
to sustainability that you're a biomimetic take on sustainable ecosystems but in this instance
ecosystems of intelligence so that was a bit hand wavy but it's you know it really is a fascinating
game when you start to talk to people who are actually in charge of engineering the next the
next web there really is so much potential um there's something I wanted to ask and I forgot
about it earlier but I was thinking about Markov blankets and how they they play this role um to
sort of this differentiate between let's say it can sort of play a role between differentiated
between a self and an other in a sense and does it have any role or impact when it comes to free will
how can you incorporate these ideas together well let's do my games
um so the self versus others
check the sound there as your sound is my sound good on your side
my sound is good and your sound is good otherwise yeah good
are you hear me yeah I can okay so I think you picked two ideas um
I haven't been able to return to that question um so let's um self and services
uh sorry just having an issue with your audio
um okay are you
okay are you okay no no sorry I was having issues with this audience
yes I couldn't hear you for about
it's back it's back sorry what did you do
okay so what I mean was when you think of Markov blankets they can indirectly play a
role in differentiating between a self and an other
how is this possible is this what's the trait of the free energy principle and
Markov blanket and what role does this
when it comes to
right yes thank you okay um so the self versus other I think is really important um
it was irrespective of
issue that that's that's that's what we didn't know we haven't covered any of our conversations
and it is the
and so you're thinking about early development and
I myself have been thinking of a new goal in Charles as to engage in that kind of work
