flea moves to the next letter and that is weight moves to the next letter feed and slowly
accumulate beliefs about the sentence that is generating this particular actively sample
sequence of of outcomes and because sentences one and four share the first three words she
has to wait right till the end before she can resolve uncertainty about the final sentence
and this kind of belief updating is very reminiscent again of what you see empirically
so if you actually look in the brain using sort of invasive electrophysiology
you can imagine that the unit activity here recorded in during the delay period
pre-soccalic delay period in the prefrontal cortex you can imagine that it looks very much like
the this synthetic belief updating when your activity or spiking is representing the most
likely on the expected hidden state at a high level of the generative model if I were to take
these time series here and then just filter them using the frequencies that people use in
EEG research then I get these fluctuations in synthetic local field potentials which again
look remarkably similar in many details to those observed empirically and earlier and later
visual cortex during or while measuring periscadic field potentials during active vision
and their similarity some certain aspects of this are very interesting from the point of view
of the belief updating and the sort of the compute in the sense that a slow accumulation of
evidence at the highest scale translates into slightly lower slower frequencies in terms of
belief updating that is seen both in terms of the simulated simulations but also in terms of
the empirical signatures on your own correlates of this kind of belief updating so that's it
I'll stop there just by reminding myself and everybody else that all of this ensues either
in the moment or in expectation consequent upon an action on an appreciation that evidence that
you know if you like the evidence that exists the most important existential objective function
can always be decomposed into simplicity and accuracy thereby everything that I think and do
should be basically trying to provide an accurate account but as simply as possible
and with that it only remains for me to thank those people whose ideas I've been talking about
and of course to thank you for your attention thank you very much indeed
okay thank you
Carl um great fascinating stuff and you have time for questions
seem to be getting to echo here but uh I think that the way we can do this is people
can either just pipe up with a question or can type something in the chat
um so while we're waiting for some questions to come in uh I will go ahead and ask one of my own
that um you sort of briefly skipped over the the sort of connections to the neuroscience and I do
know there's a quite some number of neuroscientists on this uh listening to the lecture so I wonder
if you could just give us a brief sort of view of that connection and why why is this uh these
Bayesian models thought to be somehow or how accurately do they they come to modeling what's
really going on in the human brain is that amazing excellent question uh yeah I deliberately took out
the the neurophysiology for time but also to emphasize the computer science part of it but
that the biological possibility and using this as an observation model of neuronal dynamics and
assistive processity is an important motivation for this work and specifically
how that could go wrong in certain conditions like schizophrenia or depression so it's a really
important question. The brief answer is everybody including me has been very impressed by how similar
the functional forms of the updates are in when just deriving the updates from a first principal
account and the sort that I've given you um and those neuronal dynamics and um connectivity
weight update um equations that have been used in computational neuroscience and this model
electrophysiology remarkably similar at a core strain level of analysis um the um further to that
there's people that's one one so that is um the kind of message passing you get when you deal with
geriatric models with continuous time and continuous state spaces so when you implement
that this sort of modeling version for those continuous time and state models what you get
out is a Bayesian filter um which um from the point of view of an engineer or a neuroscientist
would be known as predicted coding so predicted coding is the special case of this kind of Bayesian
mechanics um a geriatric model that deals with continuous states and time of the sort you might
want to use for early vision or very early acoustic processing for example and there's a lot of
biological plausibility um that attends uh writing down the dynamics in the Bayesian filter or a
predicted coding scheme and a neuronal dynamics it's basically a fast gradient flow on uh a free
energy or an evidence lower bound or a marginal maximum marginal likelihood uh and please for
those people interested it is always the case that you can um express the gradients of that
variational free energy functional as a prediction error um it could either look like a classical
prediction error in terms of the the arithmetic difference between my sensory data and my predictions
of those data or it can be the same kind of arithmetic difference but um read now as a
KL divergence in terms of differences for long probabilities in both instances you could always
write down these dynamics this gradient flow as a gradient on a prediction error so you can always
express these schemes in terms of minimizing prediction error um and I'm emphasizing the
predictive coding is to contrast it with another kind of belief update you get when you don't use
continuous state space models but you use discrete state space models and discrete updates in time
you've got a very different kind of message passing schemes the same maths and you still use
a gradient flow or a gradient um descent on the uh the negative free energy or the prediction errors
inherent in that negative free energy so you still go very plausible account of neural dynamics
but it now has a sortatory or episodic nature every 20 usually every 250 milliseconds you have
these dynamics and then you've supplied new data and then you you do get your descent to get to the
next um next point which is your the solutions that I showed you with that brief propagation before
the next bit of data comes along you do get your descent and what when you interpret those
schemes and notice that you know it's important that there's a dynamics and a gradient descent
that if you like um scheduled usually every 250 milliseconds um what that is um our data that
looks very much like what we see um in in in neuroscience um that implicitly have things
like theta gamma coupling because the the every 250 milliseconds is a theta rhythm and then the
fast gradient descent is giving faster frequencies um you can reproduce all sorts of things using
that little two maze rat or stem I gave you could you can look at you can play cells you can find
you can simulate this much negativities you can simulate heavy plasticity you can
simulate that theta gamma coupling all of that good stuff just falls out for free from this um
this this belief updating under under a discrete journal model so technically um then you
choose the propagation um to solve this in the brand you'd use um variational message passing
and form it in continuous time so that now it looks like a a dynamics a gradient flow
so and that um my point of view having done your science and and the computational aspects
I have to say that the discrete bits look more like really empirical data than the continuous bits
but it's more than like it the brain uses both kinds of message passing so the the point it has
to interface with continuous things like motion or you know fluctuations frequency lights and
sound processing it's likely that that's all advertised um pretty decoding or amazing filtering
and then when you get deeper into the hierarchy you start to have a quantized of discrete representation
that you're like grandmother cells and that you know discrete notions I am in the kitchen as
opposed to being x y z in relation to some reference or landmark point um point then the
the better explanation for empirical um both in terms of the computational architecture the
hierarchical architecture but also the dynamics seems to be um a discrete space space model
with the sort of um discretized updates every 250 milliseconds that corresponds to um whenever I
you know articulate a phoning or whatever you know the frequency with which I paint my visual
scene if I was a mouse the frequency which I'm whisking so most of this sort of discretized
sample of the world seems to appear at about four. Okay um Carl can you your microphone I think has
some we're getting a lot of static on the line I wonder if you're uh you could just try muting
and unmuting if that might help us I don't know um it may be coming from somewhere else uh so
we do have another question so uh uh Christoph do you want to ask your question directly or do
you want me should I you can go ahead and just ask uh Carl your question directly if you'd like
or I can read it so he's uh say okay uh he's he's uh we have a question about type one
processes so it's reads you have focused on type one processes in the the dual process theory style
I wonder how these principles can be applied to a more holistic model that integrates type one and
two processing so I think this is related to our what we were just talking about I guess the
how high up does this continue to go can we get this kind of what type two or deliberative
processing uh working in these kinds of models
how's my how's my study gone away yeah it's gone away yeah thank you
come close to the microphone I was yeah I'd like to say that's a great question
I'm afraid I so little at what a type one type two is so quickly tell me what they are now
I'll attempt to attempt to answer them
I guess okay I'm gonna end with myself yeah this is just referring to um you know this this idea
that um you know there's the the uh sort of unconscious uh fast processes
oh versus the system dual process theory basically and you know kind of we're talking
about that uh you know the higher levels you have more and more kind of discrete processing
you know kind of wonder how how some of these models might explain for how you acquire sort of
the higher level knowledge or how you decide to allocate I don't know mental um capacity for the
for the sequential uh you know type two processes right
so I right I think I understand that well I think just as already intimated that this
this this separation I think um corresponds to whether you're at low levels of um active
inference which which can be read as planning as inference so um in machine learning panning
as inferences basically means that choosing what to do next is an inference problem and
then I apply all the normal um inference machinery to that and then choose the best thing so that
must effectively one way of looking at planning as inference so if you had a very shallow model
um now a lot of that can be automized um technically people like to talk about amortization but
we can regard that as sort of habitizing um something that was previously deliberately
deliberately inferred um by having a slightly higher hierarchical model so
if you want to simulate this distinction what generally happens is it might be slightly
counterintuitive but um generally what happens is um that the the fast automatic which I presume is
is a type one but please forgive me I've ever got this got this wrong way around uh the type one
processing um inherits from um first of all engaging in more deliberative planning um
in explicit goal directed behavior so put very simply what we do is say with that simulation of
the um of of the mouse in the two step maze um we would um it would basically and we kept the um the
two um the two uh rewards um randomly allocated to the two arms then what would happen is that she
would or the simulated mouse would would pursue this very deliberative explorative planned behavior
she's going through um explicitly a sequence of policies and always identify this epistemic
policy this explorative policy um plan as you can read policy for plan as the best thing to do so
that would be if you like a you know um a minimal version of planned um uh motivated behavior where
the key thing is you are choosing among a number of different counterfactual policies after a period
of time though that epistemic policy can itself now become habitized or if it's the case that the
context does um does not change and the reward is always found on one side on the other side
then what emerges as we saw in the simulations is that the uncertainty about which of these
counterfactual plans to evaluate and then commit to resolves so ultimately there's a
priori just one plan at which point there is no more planning and you can immediately commit to
that um commit to that particular policy which effectively now becomes automatized or or
habitized and do you no longer have any if you like volition not that these simulations have
any volition but there's no choice at hand you just do this now notice what happens is
if now the environment changes and you've a priori now assume that the uh the environment
doesn't change but you've got these habits it's very difficult to actually get back from that habit
to the uh the active inference with uh by uh unless you relax your priors over the plans at hand so
it speaks for all sorts of interesting issues about wide devaluation for example um is a natural
and emergent property of this sort of hierarchical inference that can become habitized um with
sufficient exposure to a non-volatile environment was that the kind of difference between type 1
and type 2 that you had in mind? Yeah that makes sense it was just just flipped in a sense but
and I guess the question is like you know what type of representations uh you need that um you
know the the higher level of your mdp hierarchy versus lower where for example I guess at the
higher level we you have to think about your information source and how do I um you know
I guess explore information sources or that I take into account this this possibility it's
probably a it's a different type of uh knowledge that that uh that's exploited there versus the
habitual level yeah like that. Yeah absolutely yeah so so you know that as soon as you habitize
or automatically or your priors get sufficiently precise that they dominate all the other bits of
the expected free energy by definition that those epistemic imperatives or those epistemic
aspects are suppressed so or by construction in your in this formulation that's absolutely right
that you know you have learned that there is no value in intrinsic value in going to find out
any more information about this and you just go you do you just do do the right thing um so you're
I think that phenomena you would you'd see at all you're at all levels of planning I guess your
point is that you you clearly have to have a sufficiently deep and sophisticated generative
model to actually entertain a non-trivial number of policies all of which will be
scored in terms of you know what will I learn how much information would I get if I did that
and is that worth the payoff that comes from the prior preferences or the more utilitarian
extrinsic value value part of it so all of this does depend upon the sufficiently deep
generative model the equivalent I don't know if you're interested in in in in sort of the
steel process theory as it relates to physiology but the equivalent in physiology has been written
very about very artfully by Giovanni Pazzullo in terms of the distinction and people like
class Stefan and the distinction between allostasis and homeostasis so instead of worrying about
sort of motor choice behavior you just think about autonomic behavior interceptive inference
then the distinction I think you're talking about is whether you have an immediate homeostatic
response or whether you go and search out for the context the optimal context that enables the
homeostasis so instead of releasing insulin because my blood sugar is low I might suspend that
automatic response and then go and prepare some food to eat so that I don't need to release my
insulin so that theme of putting context upon context upon context with deep generative models
I think you'll find is endemic and it has to be in the sense that it's a key attribute of these
generative models and the generative models underlies all the Bayesian mechanics and the
behaviors that we're trying to explain. Thank you. Okay we have another question here
I'm going to just read it there's Arti Mahoutros asking about the dark room problem but I'm
going to suggest we save that for the student meeting unless you want to address that Carl
but there's another question here on the role of long-term memory on policy selection
maybe you can just asking for your thoughts on the role of long-term memory on policy selection
but she's also asking about the dark room problems if you want to explain what that is and then try
to get into that in 10 minutes we can do that here or we could save it for the for the student
meeting. We'll briefly resolve it in one minute and then turn to the other question then we can
revisit it at the student meeting so the dark room problem is the notion that if I want to minimize
my surprise I should go into a very dark room and stay there forever because I know exactly what's
going to happen to me and on the surface of it it seems very plausible as a consequence of
minimizing surprise but it just doesn't work it's one of these false thought experiments and
indeed you can see that immediately in relation to what we're just talking about in terms of
resolving uncertainty so the first thing that I do when I go into a dark room to switch on the light
why because that resolves my uncertainty about what is causing what's in that room I think
probably more tellingly the dark room problem just fails to account for action
the dark room problem is only good for cesare creatures or computers that don't have to decide
which data to gather as soon as you are moving to an active frame of reference and think about
