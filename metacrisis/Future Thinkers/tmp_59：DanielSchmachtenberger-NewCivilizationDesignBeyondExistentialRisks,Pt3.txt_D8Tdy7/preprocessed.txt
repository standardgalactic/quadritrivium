Welcome back to part three of our three-part series with Daniel Schmockdenberger on the
generator function of existential risks.
In this episode, Daniel shares his vision for a path towards a post-existential risk
future and the three key features of this new civilization design.
He also talks about why there is no place for incentives in such a world.
To get all the links and show notes from this episode, go to futurethinkers.org slash 57.
You can also find the first and second part of this interview there.
This episode is brought to you by Qualia, a premium-neutropic supplement that helps
support mental performance and brain health.
It's specifically designed to promote focus, support energy, mental clarity, mood, memory,
and creativity.
UVA and I have both used it in the past.
We really like it, and we actually met the founders and interviewed them on FutureThinkers.
You can check out those interviews.
They're one of our favorites at futurethinkers.org slash Daniel and futurethinkers.org slash
Jordan.
They've got a new formula up called Qualia Mind.
It's got more natural ingredients, and you can get it at futurethinkers.org slash Brain
Hack, and you can get 10% off if you use the code FUTURE.
All right, let's get into the show.
Welcome to FutureThinkers.org, a podcast about the evolution of technology, society, and
consciousness.
I'm Mike Gilliland, and I'm UVA Ivanova.
If you're new to the show and you'd like a list of our top episodes and resources, go
to futurethinkers.org slash start.
And if you like our podcast, leave us a rating and a review on iTunes and elsewhere.
It really helps others find the show, and we really appreciate it.
I'm reading Carl Jung right now, and he's talking about his experience of going to live
with the Pueblo Indians and how it completely just blew apart his conception of what was
natural and how the Western worldview is different from other worldviews.
And he noticed that they were so happy and serene, and they felt themselves as one with
their environment, and they had this very special relationship with the sun, and it
was just, it was very beautiful, but at the same time, he realized how they were very
vulnerable to the invasion of the Western civilization.
So if we create a new civilization operating system that is not oriented towards winning
wars, then how do we ensure that it doesn't get destroyed by those who are?
Imagine there's a group of people that get a stronger theory of causation.
So they learn Newton's physics, and so now they can use calculus to plot a ballistic
curve and make the cannonball hit the right spot every time, rather than the pendulum
dowsing, which is kind of a hit or miss.
That belief is going to catch on.
And that's why science really caught on, took us out of the dark ages, was because it led
to better weapons and better agriculture tech and better like real shit.
So it proliferated because it was proliferative.
If we increase our theory of causation, that ends up catching on.
But if we could increase our theory of causation and our theory of choice and the relationship
between them, that would actually be the most adaptive, especially in the presence of where
our particular game theoretic model of choice with the extension of causation we have is
definitely self-terminating, definitely anti-adaptive.
And so, I know we've been on for a long time, so there's really only one more thing that
I want to share that kind of closes this set of concepts.
So remember we said that any source of asymmetric advantage, competitive advantage in a win-lose
game will end up, once it's deployed, being figured out and utilized by everybody.
You just up the level of fencing in the playing field.
So, but we also said that Indians you were just mentioning, and many of the tribes we've
mentioned, lost win-lose games.
We don't want to try and build something that's just going to lose at a win-lose game.
But we know that if it tries to win at win-lose games, it's just still part of the same existential
curve that we're on.
So it has to not lose at a win-lose game, while also not seeking to win.
So it's basically not playing the game, but it is oriented about how not to lose.
This is a very important thing.
And so, we can think about power, the way we have traditionally thought of power as a
power over or power against type dynamic, a game theoretic win-lose dynamic.
And that that any agent that deploys a particular kind of power leads to other agents figuring
how to deploy the same and other kinds of power.
Power keeps anting up till we get to problems, but we can think about another term we might
call strength, which is not the power to beat someone else, but it's the ability to not
be beat by someone else.
It's the ability to maintain our own sovereignty and our own coherence and the presence of
outside forces.
And so, we can talk about my power, like can I go beat somebody up?
But my strength is can my body fend off viruses?
And can I fend off cancers?
And can I actually protect myself if I need to protect myself, which is different than
can I go beat other people up?
And now, the power game is the game we actually have to cure.
Power over dynamics mean rivalrous dynamics mean win-lose dynamics is the source of evil.
It's not that money is the source of evil, it's that power over where I think my well-being
is anti-coupled to yours, ends up being the source of evil, and money is just very deep
in the stack of power dynamics, but statuses and certain ways of relating to sex and a
number of things are.
So, we have to get rid of the power over dynamics, but it doesn't mean that I can't develop strength
that makes me anti-fragile in the presence of rivalry.
And then I say, well, what kind of capacity can I develop that doesn't get weaponized
by somebody else and used against me, given that any asymmetric capacity I get can be
weaponized.
There's really only one and this is a really interesting thing.
If I make the adaptive capacity of, say we're trying to make a new civilization as a model
and a new full stack civilization, new economics, new governance, new infrastructure, new culture
that has comprehensive loop closure, doesn't create accumulation or depletion, doesn't
have rivalrous games within it, et cetera, if I try to have some unique adaptive capacity
via a certain type of information tech, the other world will see that information tech
and use it for all kinds of purposes, including against me where there's an incentive to do
so.
And the same is true if I use military tech or if I use environmental extraction tech,
now I'm still in the same problems.
But if my advantage, the advantage of the way the civilization is structured has to
do with increased coherence in the sense making and choice making between all the agents in
the system, all the people in the system, increased interpersonal coherence, this cannot
be weaponized and anyone else employing it is now just the system itself propagating.
So for instance, when we start playing rivalrous games, we start realizing that it's not just
us against somebody else, it's teams against larger teams, right?
And so then the idea of the team is we're supposed to cooperate with each other to compete
against somebody else, but compete against someone else idea ends up going fractal and
I end up even competing against my teammates sometimes.
And that's part of that.
Why the collective intelligence doesn't scale thing is because I'll cooperate with my other
buddies on the basketball team unless there's also a thing called the most valuable player
and I'm in the running for it and I have a chance to make the three point shot rather
than pass even though it decreases the chance of the team winning.
Now I have a incentive misalignment.
So I might go for that.
And then it gets bigger where there's a couple of us that both want the same promotion.
To the same position at the company.
And we're actually going to try and sabotage the other one, even though that harms the
company because my own incentive is not coupled with their incentive and with the company.
And then I can look at, say a couple different government agencies that are competing for
the same chunk of budget, they will actually seek to undermine each other so they get more
of the budget when they're supposed to be on the same team called that country.
And so what we realize is we get this thing called like fractal disinformation, fractal
decoherence and defection happening everywhere and that creates the most broken information
ecology and the least effective coordination and cooperation possible.
And that's everywhere.
That's ubiquitous and it's the result of that underlying rivalry.
So as we mentioned before, now if I have some information, I want to make it to where nobody
else can use it.
I want to trademark it, patent it, protect my intellectual property.
And before I've released it, I actually want to disinform everybody else about it, right?
Tell them the goal to somewhere else so that they go dig in somewhere else and don't pay
attention to what I'm doing.
So if I am both hoarding information, disinforming others and keeping my information from being
able to be synthesized with others, that means I'm going to not let my knowledge about cancer
research and whatever it is be out there because I got to make the pharma on your back.
So the best computer that the world could build doesn't exist because Apple has some
of the IP, but Google has some of the IP and 10 other companies have some of the IP.
And so the best computer that science knows how to build can legally not be built in this
world.
And the best phone and the best car and the best medicine and the best every fucking thing
there is because we keep the actual adaptive knowledge from synthesizing, let alone that
everybody is having to reproduce the same fucking work because we don't want to share
our best practices.
And then almost all the budget is going into marketing against the other ones rather than
actual development and the marketing is just lying in manipulation, you know, at least
about why ours is comprehensively better when they then have to say the same thing about
what their IP does that's good and our IP does some other thing.
Now imagine if we had a world where all the IP got to be synthesized, nobody was disinforming
anybody else.
Everybody was sabotaging anyone else.
Everyone was an incentive to share all of the info and to synthesize all the info to
synthesize all of the intellectual property ideas, etc. work towards the best things possible.
Imagine how much more innovation would actually be possible, how much more collective intelligence
and capacity would actually be possible.
Now if our source of adaptive advantage is that, right, is we make a world where and
now we have to come back to, we were talking about if you possess a good and I no longer
have access to it, we're an arrival risk relationship, right?
You possess a piece of information and that I don't then get to have access to it, we're
an arrival risk information knowledge, etc.
But if you have access to something and we've structured the nature of access where we have
engineered the scarcity out of the system such that you're having access doesn't make
me not have access and you having access leads to you being a human who has a full life and
some of your full life is creativity and generativity.
And so now not only do you have the full access to those transportation resources, but also
maker studios and art studios and education and healthcare and all the kinds of things
would make you a healthy, well-adaptive, creative person and every well-adaptive person is
creative because nobody wants to just chill out watching TV all the time unless they were
already broken, broken by a system that tried to and sent them to do shit that nobody wants
to do or if they can get away out, they will be their broken person.
But if someone was supported in an education system to pay attention to what they were
innately fascinated in and facilitate that, they'll all become masterful at some things
with innate intrinsic motivation to do those things.
And so now in a world where we support everybody to have access to the things that they are
intrinsically incented to want to create, which if right now I get status by having
stuff, but if we are engineering scarcity out of the system, everyone has access, nobody
possesses any of it, everybody has access to all of it, there's no status of having
things and it's totally boring.
There's no differential advantage, the only way you get status, the only way you get to
express the uniqueness of who you are is by what you create.
And so now the whole system's oriented towards that, but you don't create something to get
money because money for what?
To have access to shit you already have access to.
But because you get to be someone who created that thing in both your own intrinsic experience
of it and extrinsically getting to offer to the world and recognize that.
So now we have a situation where we all have access to commonwealth resources that create
an anti-rivalrous relationship to each other.
And obviously I'm just speaking about this at a 100,000 foot level and we could drill
down on what the actual architecture looks like, but there's actual architecture here
that is viable that meets the design criteria.
And we have sense making processes where we look at what a good design would be before
making a proposition for a design that don't lead to polarization and radicalization, but
that lead to progressively better synergistic satisfies that get us out of theory of trade-offs
and into, right, synergistic satisfies also as a way of having people be more unifiable
and on the same team.
Now if I've got this world where it's source of competitive advantage, if you want to call
it that, is that it is obsolete in competition within itself so it has real coherence, then
not only is the quality of life there radically higher because the people don't feel lonely
and they actually have creative shit to do and they aren't being used as instrumental
pawns to some other purpose and et cetera, and the quality of life is better because
they're actually making better medicine and better technology and better et cetera because
of the ability for the IP to synthesize and everything else.
But this world can also out innovate in really key ways, other places in the world.
And so then rather than the rest of the world wanting to attack it, the world, it can actually
say here, will export solutions you want?
And so the rest of the world starts to create a positive dependence relationship.
And the rest of the world says, shit, we want to be able to innovate.
Why were they able to solve that problem?
We weren't able to solve it because our guys were like sabotaging each other and their
guys weren't sabotaging each other.
And we say, great, here's the social technology we use.
Now as soon as they implement that, it's not being weaponized.
That's just the world actually shifting.
That's where this model actually becomes a new basin of attraction the world starts flowing
to.
And so you have to do that.
You create a prototype of a full stat civilization that is anti-rivalrous.
It is anti-fragile against rivalry, strength, non-power, and that is auto propagating that
by the nature of the solutions that it is exporting and by its own adaptive capacity,
its own design starts to get implemented other places.
And that's ultimately the desire.
That is a path to a post existential risk world, which is building it in prototype in
a way where it auto propagates.
That's so exciting.
Are there places where these prototypes are being built?
Kind of, but not really.
There are intentional communities where people are trying to practice some things that they
feel will be relevant, a closed loop agriculture system, where they at least have regenerative
agriculture and maybe some kinds of social coherence technologies where they have a better
system of conflict resolution than our current judicial system, better parenting, better
education.
Like we have those things and those are cool and they're valuable, but they still have
to buy their computers from Apple and fly on a Boeing to get somewhere that depends upon
environmental destruction and war.
And so they can't actually provide a high tech civilization, so they're not yet civilization
models.
And the civilization models are all part of this one dominant civilization model.
So this is a next endeavor.
And before a full stack civilization occurs, obviously partial ones, but that are directed
towards the full stack civilization have to occur because in the world we're talking
about, there is no place for the things currently called judges or lawyers or politicians or
bankers because those systems don't exist.
Now that doesn't mean that there isn't a equivalent of a judicial system, but it's totally fucking
different from the level of the theory of ethics to the jurisprudence.
And somebody has to be getting trained in the civics of that system.
And there's nothing like banking, but there are things like paying attention to how the
accounting of this new economy works, but people have to be trained in that.
I'll give you one for instance, if we think about the physical economy, so we'll take
attention out and just look at physics, we see that there's at least three different
kinds of physics involved in the materials economy that are fundamentally different in
their math.
So there is a physics of atoms, physical atoms, there is a physics of energy, and there's
a physics of bits.
And right now those are all fungible, I can use the same dollar to buy software or to
buy energy or to buy metals or physical stuff, food.
But there's a fixed number of atoms of a certain type on the planet that are reasonably accessible.
And right now we're just taking them from the environment in a way that causes depletion
and then putting them back into the environment as waste in a way that causes accumulation,
toxicity on both sides, we can't keep doing that.
We have to close loop it where we have then a give or take finite amount of metals and
not just metals, but hydrocarbons, everything, a finite amount of atoms that are in a closed
loop relationship, but they can be upcycled because we have the energy to upcycle them,
which means putting the same atoms into higher pattern where the pattern is involved in the
pattern stored in bits.
So if I take the atoms out of one battery, put it in a new battery, what's evolved is
battery technology, that new battery is in bits, a blueprint.
And I'm going to use energy to take the atoms in the current form, disassemble them and
reassemble them into this new battery.
And so there's a fixed amount of atoms, we have to close loop those.
There's not a fixed amount of energy, we get new energy from the sun every day.
But we have kind of a finite bandwidth of how much we get.
So we have to operate within, that's not closed loop, right?
We can use that up and it has a entropy, but within that bandwidth, we have to work.
And then bits are fundamentally unlimited, limited only by the compute of the energy
and matter.
So that can keep expanding basically indefinitely.
Once I've made a bit, I can reproduce it exponentially without any unit cost.
Because I can reproduce it exponentially without unit cost once I've developed it once, I can
get exponential returns on software in a way that I could never get on atomic stuff, which
is why Elon has a hard time raising money for physical stuff and what's absolute for
$19 billion.
It's why all the unicorns are software and mostly social tech or fintech or something
that is actually doing not good things for the world, but can create exponential returns.
And it's why Silicon Valley has basically mostly just invested in software stuff.
If you make those fungible, you'll actually be moving the energy away from the atom and
away from the energy into the virtual, away from the physical into the virtual.
Even though the virtual depends on the physical, so you're actually debasing the substrate
upon which it depends.
And so you notice that since the bit, we can keep having more of forever.
They don't go through an entropic degradation when we use them.
The energy we can use, it entropically degrades, but we get more of it every day and the atoms
don't entropically degrade, but we have to keep cycling them and there's a fixed number.
The physics, the accounting of those are totally different.
That's not one economy that's fungible to itself with one accounting system.
That's three, completely separate, but interacting physical economies.
And now again, we already said we're not owning goods.
We're having access to shared commonwealth services, but this is just first to really
go into it.
It's a lot of things.
But these are examples of some of the considerations that have to happen to actually be able to
think about things like economics at a level of depth that is appropriate to the nature
of the issues.
If we don't answer the question of what makes a good civilization and we simply say would
allow civilization to endure.
And so we start with, let's just say we don't want existential catastrophic risk and there's
a whole bunch of different types of existential catastrophic risks that all have the same
generator function.
So we have to create categorical solutions to the generator functions.
It turns out that those are the generator functions that have made all the things that
we intuitively have experienced as sucking like violence and environmental devastation
and that solving those generator functions doesn't just allow us to survive in maybe
some dystopian dynamic, anti-rival risk dynamics with each other and closed loop dynamics and
the proper relationship between the complicated and the complex scalable collective intelligence
systems and a right understanding and theory of choice and relationship, the theory of causation
end up being a way of mapping to a world that is definitely pro-topic on any meaningful
definition of pro-topian, any meaningful kind of consideration of what good could mean.
And so when we come back to this mythopoetic, we can't keep going the way that we're going.
There's a purgatory coming and it's going to go one way or the other and one way is
really shitty and one way is really lovely.
That's a true story and Bucky Fuller said utopia or oblivion and it's going to be hit
or miss till we're actually there and I can't know which way it goes.
That's the thing I would just kind of end on is what it takes, if we try to solve the
various risks in isolation, it's impossible we fail.
If what it takes to solve them categorically ends up also mapping to how we engage everyone
in creating the true, the good and the beautiful that is theirs to create progressively better,
both up regulating their sense making of what that is with themselves and with each other
and being able to make that, scaling the collective intelligence that is progressively answering
those questions better.
Can you leave us with some book recommendations for anyone who wants to read up on this a little
more and expand their understanding?
Books or other resources?
Yes, I wish I could share more things than I can but a lot of what we're thinking in
terms of new civilization design like this is new.
It doesn't mean it's not drawing on lots of elements.
So a couple things.
We mentioned Jeffrey West's work scale on collective intelligence, that's very valuable.
We talked about some of the dynamics of game theory that have to shift and so finite and
infinite games is just my favorite starting point and it's one of the types of books that
is very simple but has multiple levels of depth of meaning that if you read it multiple
times you'll gain new insights.
Yeah, that one blew my mind.
Yeah, me too.
James Kars, very beautiful.
And I have a blog, civilizationemerging.com that has some articles and these types of
topics and there's also a book list there with a heap of books.
Great.
Great.
Awesome.
This as always is enlightening and so fun.
There are books that are valuable and there's obviously like all of your podcasts are valuable.
If you had the experience of anything that I said making sense and actually seeming obvious
but then you also realized you never thought it in that particular way then there's a question,
why did I never think it in that way even though it seems obvious after the fact?
And that's one of the principles that clarity, one of the properties that clarity has is
it can add novel insight but that seems obvious and kind of prima facie relates to everything
that we know.
When you say, okay, I wasn't thinking about rival risk dynamics and upping the ante clearly
enough.
I wasn't thinking about the exponential economy and software and atoms all being fungible
like there's a problem there.
I wasn't thinking about open loops, closed loops in this particular way but you can if
you start just asking for yourself, what do I think is actually wrong?
And then of all the things that seem wrong, what do they have in common?
And why are those things that are wrong wrong?
What is going on?
And then go deeper, keep going deeper with that and don't look for one answer or there
are a number of different things that come together that are partial answers to this
and what would solving that look like?
And there are resources of other people's thinking on these things but they won't replace,
they will inspire, they won't replace your own deep thinking on these things for your
own sense making and so the resource that I would offer the most is when you are bothered
by something or you wish some beautiful thing existed more than it does, really think hard
about why things are the way they are and know that the first thoughts you will come
up with are not that good but if you stop you won't get beyond there but if you really
keep working on it and thinking about it and then going and researching in light of that
question and then thinking about it more, you actually start to get novel and meaningful
and deeper sense making that is aligned with what is yours to pay attention to and work
on.
To get to what you said earlier, I think it really helps to use different modes of inquiry.
People can get stuck in just intellectual inquiry or just spiritual inquiry but you
know all are valuable and when we can see the same thing from several different perspectives
it becomes a 3D object rather than just being flat.
You just actually mentioned one of my favorite practices is really endeavoring to see and
experience the world through the perspective of someone else and actually see and experience
it and if I am still thinking no if I was in their position I wouldn't do that I haven't
got it yet so if I was in their position I would do it if I am really putting myself
in their position.
I would get enraged by the things they are enraged by, I would get excited by the things
they are excited by and so this both as a practice of empathy and connection, as a practice
of understanding, as a practice of intelligence and learning because I see different things.
If I look at the world through the lens of a mechanical engineer I see shit everywhere
that mechanical engineers see that you never saw which is different than if you look through
the lens of a fashion designer where you look through the lens of a game theory person they
are looking at different things or an evolutionary biologist and you are like there is a whole
universe I wasn't paying attention to.
Like when you buy the car and you see it everywhere you put it on the lens and you start seeing
all kinds of stuff, in fact it sends me.
But also as a kind of spiritual technology of getting out of the default mode of what
you think you are and when I am trying to be someone else it is not my personality that
can do that.
If I am trying to take their personality on it is not my perspective that can do it.
It is the same consciousness that is witnessing my perspective that can then witness somebody
else's and as soon as I do that I actually dissociate from just being my personality
and then I get some more spaciousness around it and less reactive by it.
And this also relates to not just looking through the lens of different personalities
or different modern frameworks it is also looking through the lens of pre-modern frameworks
or even animal frameworks and that can all be very useful as well because if we look
at the world through the lens of quote unquote primitive tribe then different things come
into focus and different things become very meaningful and very powerfully meaningful
like it resonates through your whole being just you know wow.
And that is not to be dismissed because there is something there.
At the very minimum for self-discovery it is super useful because you know we spent
more time as those primitive versions of ourselves than we have the modern versions
and you can kind of untie a lot of behaviors that you don't really realize you have based
off of just looking at the world from a primitive standpoint.
Well if your chair has some people decide to go visit the Amazon and live with the tribe
and experience the world through those eyes and be affected by it and then look at how
they can incorporate elements of that experience of the world and their previous experience
of the world to being able to live more fully that would be beautiful.
This is wonderful I really appreciate being here with you both and I just I really do
want to say that I love your podcast and I love what you're creating both of you together.
It's very easy to have well informed dystopian views and it's easy to not think about things
or it's easy to have poorly informed positive views but to have well informed positive views
is actually tricky because if we keep being anything like the kinds of people that we
have always been that do really wonderful and really atrocious shit with our power but
having exponentially more power they're all dystopian scenarios and so we have to be something
really different than we've ever been which requires some type of deep shifts that could
make that happen that requires some deep thinking right some deep imagination and I know that's
what you are really dedicated to doing here on the show and reminded of this quote from
the book of Romans it says the pathway to heaven is narrow and steep and the pathway
to hell is wide and many and it's kind of just like a way of thinking about thermodynamics
which is that there's just more ways to break shit than to build it there's like not that
many ways this all the cells in your body can come together that make you with the emergent
property of you there's a lot of ways that you just get like 150 pounds of goo and so
say like okay we've got a lot of power and most of those scenarios with a lot of power
suck how could we have this much power that doesn't suck how could we have this much power
not use it against each other and we start seeing Orwell and control systems when we
start seeing how that sucks too and to keep thinking through how could we have it that
doesn't suck and I can't depend on aliens or Jesus what coming back like well how do
we get us to be that kind of consciousness it's a really good way of thinking about how
to actually address these problems because if we can't know Voltaire's without vision
man perishes if we can't even see a well grounded positive future and positive use of the technological
capacity we have we are not going to make it and so I love that you all have this space
dedicated to exploring that topic incentive is always evil to Mitch so I don't want to
move from perverse incentive to positive incentive positive incentive means my sense making has
determined what I think is good and I'm going to try and extrinsically override your sense
making to make a choice aligned with my sense making I'm going to use a extrinsic reward
strategy to co-opt your sovereignty and have your choice making be based on my sense making
incentive schema rather than your own sense making and that is always the basis of evil
if I want to have a collective intelligence it's actually intelligent I need everyone
to have intrinsic sense making and choice making that is uncorruptible which means it's
not being co-opted by extrinsic reward and punishment schemas I got this wrong at first
I used to say we have to create a world where the incentive of every agent is rigorously
aligned with the well-being of every other agent and of the commons that is wrong what
is right is to say that we must rigorously remove any place where the incentive of an
agent is misaligned with the well-being of other agents in the commons but a adequate
future is one that has no system of structural incentive oh that's a mindblower the cells
in your body are actually not trying to get the other ones to do what they want them to
do they have their own internal sense making processes and they do what makes sense to
them and what makes sense to them also happens to be what's good for the ones around them
because they depend on the ones around them and vice versa and they're in a communication
process but the brain is not overriding the cells and in no way could handle the complexity
necessary of the cells not doing their own sense making and so better incentive schemas
as a transition which is happening in the blockchain is nice it's worse than more verse
incentives but it is transitional not post-transitional it actually does not address existential risk
it doesn't give us the right collective intelligence the right collective intelligence has to be
fractal sovereignty meaning at the level of an individual and every group size it has
its own intact sense making and choice making that ends up being vectoring towards omnic
consideration level of shit that we're talking about is hard to imagine yeah and what has
to be invented to even begin a transition and then be put to rest so that the next version
can come along is such a long road the reason that we incent people is because we have a
civilization that needs a lot of shit done that is not fun it's dreadful stuff so we
want to get the people to do the dreadful stuff if we created a commonwealth where everyone
had access to resources then nobody would do the dreadful stuff and so then the state
would have to force them that's why we don't like communism then you get the state imperialism
so we say okay cool we'll let the free market force them instead it's economic servitude
but at least that doesn't look like somebody did it because the market is just anonymous
thing right if you don't do the shitty job your homeless and your kids can't eat cool
but we'll tell you the story that you can work your way up and you know become wealthy
even though statistically we know that it's silly it happened to those two guys at one
time even though statistically the rest of the time having more resources makes it easier
to make more resources and having less resources makes it harder to make more resources and
so the system has a gradient that makes it actually continue in the direction of inequality
and not the you know otherwise but so that's where incentive came from right was that's
the good side the negative side is a few controlling a many want to use incentive reward and punishment
and to get people to do the shitty things we have to do that this is using choice to
create a system of causation incentive is a causal system game theory is a causal system
to control the choice of others controller co-op I want to have my theory of choice affect
causal dynamics that are only causal i.e. if I make an automated robot I haven't actually
made a sentient being a utility so I'm going to say something even deeper which is instrumental
relationships are evil can you expand that yeah I'm interacting with you to meet some
people that you know to get my network ahead or to get some knowledge from you or to gain
access to something or to whatever it is I have something that I want to do that you
are an instrument towards you are a path towards it's a utilitarian ethic then you are a ends
to a means for me so however I relate with you however to affect your own sovereign sentient
experience is a place I might externalize harm because it's not why I'm relating with
you yeah yeah and so in a healthy world world of the future other people need to have intrinsic
value independent of utilitarian value to everyone that's a part of the culture and
not just the other people and other beings all kinds of sentient beings but relationships
have intrinsic value so I'm going to invest in the integrity of our relationship independent
of me getting anything out of it because it is actually the basis of meaningfulness itself
which is why in a utilitarian and instrumental dynamic we're getting ahead while feeling
utterly fucking meaningless and destroying everything that is meaningful in the process
that is us being hooked to addiction to a stupid game where what we think we want is
not not what we actually want and what we think of as a win is actually a omnistupid thing
and this is why you know like the Hindu concept of Dharma was a virtue ethic not a utilitarian
ethic and and there was a very meaningful set of concepts of do what is inherently right
in your relationship with life independent of what the outcome might be because you really
don't know what the fucking outcome is going to be and if you try and just figure out the
outcome is going to be you're going to be wrong a lot of times and you're also going
to justify a lot of unethical stuff and utilitarianism is kind of the rampant ethics that anyone
who's paying attention to ethics pays attention to right now and it's not without any merit
but it is also problematic it is up there with democracy and capitalism you know in
the philosophy of science in terms of being a problematic thing to be the dominant system
because we cannot actually predict in complex systems well enough to do a utilitarian thing
and they intrinsic dynamics of a relationship and another being end up becoming moved to
being a means to an ends other than them and as soon as I start factoring everything meaningful
along the chain of whatever I think my outcome is to where my outcome is actually being in a way
that is an integrity with an honoring of all life now it's a virtue ethic. Yeah I was having
this conversation recently about people who are obsessed with life hacking and optimizing everything
and when they get into that mindset eventually they get to what what they call optimizing
relationships and then they start putting people on a value hierarchy where they want to interact
with high value people and they want to get a high value woman and they're using these tactics
to find and attract the most high value woman and it's funny because those people in my experience
are some of the most existentially unhappy people that I've met and they will never
demonstrate it outward in an outward way but that's what I've noticed that you know people who try to
optimize everything in this kind of utilitarian way end up really profoundly unhappy. Yeah what's
the same thing as continuously pursuing a better high it's I'm getting a hit from winning at a
particular thing so I gotta try and win at it all the time but I need the hit because my baseline
is that life feels fucking meaningless because I don't actually have any real relationships and
they're I don't even know what meaning means. I don't even know what intimacy means and so
that hyponormal environment needs a hypernormal stimuli to feel anything and then the fact that I
use people instrumentally has people end up not liking me which makes me hurt even more which
makes me want another hit even more. People like you make it super easy you just come on and it's
like we listen to audiobooks all day and then we get to actually talk to the person who is coming
up with the cutting-edge ideas themselves so it's quite interesting thank you. It's always wonderful
getting our brains blown by you thank you. Thank you both this was really fun.
All right that's it thanks for listening guys that was the last part of our fascinating
conversation with Daniel Schmockenberger. If you haven't heard the first and second part of this
interview you can find it at futurethinkers.org slash 57 you can also find all the links and
resources mentioned in all three episodes there and to check out our sponsor Qualia go to futurethinkers.org
slash brain hack. If you're new to the show and you like a list of our top episodes and resources
go to futurethinkers.org slash start. If you want to sponsor our show go to futurethinkers.org slash
sponsor. If you like our podcast leave us a rating and a review on iTunes and elsewhere
it helps others find the show and we really appreciate it. Thanks for listening and we'll
see you in the next episode. Bye!
