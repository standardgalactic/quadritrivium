Welcome to episode number 46. Today on the show we have Daniel Schmocktenberger again. This time
he's talking about existential risks and how to avoid them. We've already done several other
episodes with Daniel before and they were always some of our favorites, a very mind-expanding
and inspirational, but I think this one is particularly important because he talks about
some of the most pressing issues that we face on our planet today and proposes some ways that we
can solve them. If you want to check out the previous episodes that we've done with Daniel,
go to futurethinkers.org slash Daniel. To get all the books, resources, and the other things that
we mentioned in this episode, go to futurethinkers.org slash 46. This episode is brought to you by
BCDC. They're working on several blockchain-based apps to help save the environment. One of them is
called EcoChain and it's a crowdfunding and investment platform for renewable energy projects
where people can invest in new clean energy installations and get an ROI. So BCDC is doing
a token sale which is now happening in November 2017, but the pre-sale is already happening now.
You can see our report and listen to the interview we did with them by going to
futurethinkers.org slash BCDC. You can also find all the links to their website, white paper,
and bounty campaign there as well. Last but not least, before we get into the episode,
we want to thank our recent patrons, Ray and Dean, for supporting us on Patreon. Alright, let's get
started. Welcome to futurethinkers.org, a podcast about the evolution of technology,
society, and consciousness. I'm Mike Gilliland and I'm Yuvia Ivanova. To get notified of new
podcasts and videos, go to futurethinkers.org and subscribe to our mailing list. You can also find
us on iTunes, Stitcher, and YouTube. If you like what we do and you want to help us make more podcasts
and videos, give us a like or a review, share it with your friends, and consider becoming a patron.
Go to patreon.com slash futurethinkers. If you're looking to get serious about meditation,
check out the meditation app that we've created with Negupta called the Cutting Machinery.
Go to cuttingmachinery.org slash app. Last but not least, if you want to get access to more
content, hidden episodes, or if you just want to chat with us and previous guests, then check out
our community at community.futurethinkers.org. Daniel, welcome to the show. It's good to have you
on again. So today we're talking about existential risks, which is a topic I know you're quite familiar
with that, you know, you've brought up in past episodes with us. So this is something I've actually
really been looking forward to getting into with you. Great. So why don't we start with the big
questions? What are some of the biggest existential risks that we are facing on the planet right now?
So for those who aren't familiar with the term existential risk means some risk that could stop
us from existing. So a species-threatening event, there's also plenty of catastrophic risks that
would just really suck even though we wouldn't be completely wiped out as a species. So there are
versions of World War III that are existential kinds of nuclear holocaust that nobody makes it
through. There are kinds of World War III that are catastrophic, meaning some group of people in
remote areas make it through, but the atmospheres hold uranium and, you know, most of the people
did very poorly. So we're kind of interested in preventing all of those things, right? So what
are the categories first? There's different ways of kind of chunking in different ways of doing
taxonomy. One thing we can look at is start by saying there are kind of human induced things,
and then there's kind of natural phenomena. The natural phenomena are things that either arise
from within our earthen biosphere or outside of it. So outside of it is things like solar flares
and Carrington events and asteroids that can be catastrophic or existential. And obviously,
you know, within our atmosphere most of the natural phenomena that would occur would not
be existential, but there are some super caldera kinds of scenarios that would be. We're obviously
interested in any of them because, you know, if there was an event that we just couldn't avoid here,
then Mars Colony moves up on the priority list, right? But surprisingly, most of these things,
if we have more intel about them, many of them can be avoided or at least mitigated against. So for
instance, if we look at something like a Carrington event where we're looking at solar flares or
coronal mass ejections that besides the just effect that they would have on biology directly
would also have effects on electrical circuitry. As far as biology goes, there might be an impact
on one part of the planet. People can go underground. It's not that big a deal. But as far as frying
the circuitry goes, if we're talking about frying the circuitry of nuclear cooling stations on the
power plant, so then they turn into nuclear volcanoes, that's a pretty big deal. Now we could,
of course, do things to mitigate against the sensitivity there like hardening the
nuclear cooling stations and, you know, other forms of key infrastructure. So even with regard to
things that we can call natural phenomena, obviously, you know, there are projects that are
looking at asteroids and other near earth objects, because depending upon what we see, they might
actually be movable. And there are a number of projects focused on that. Then we move our attention
to, you know, human induced things. And we can look at the ones that go through environmental
pathways. Basically, we either through biodiversity loss, or climate change, ocean acidification,
or other kinds of effects on our biosphere, we create a biosphere that is uninhabitable to humans.
But we don't even have to get to full uninhabitability for partial uninhabitability to
lead to the beginning of cascade effects. You know, when we look at what happened in Syria,
we see that a major part of what happened, factoring that there were many, many factors
simultaneously, but one part of it was droughts in an area that had not had droughts led to
subsistence farmers moving into the cities that taxed the resource capacity of those cities beyond
their limits that led to resource wars that led to factions and that whole kind of thing.
So when we start looking at climate change, creating massive numbers of refugees,
and the refugee dynamics leading to war dynamics and resource shortage wars, economic collapse,
and then, you know, cascading wars, you can have scenarios where environmental phenomena
are the first step in a series of cascades that can occur. So you've got all of the
environmental phenomenon, the effects of on coral of ocean temperature, ocean acidification,
the loss of big fish and the trophic cascades, key species collapse throughout many different
dynamics, pollinators, like there's a lot, there's a lot of things in there. Then we can look at
other reasons for just human induced violence towards each other. So all of the reasons that
something like a World War III could happen. And we see right now, the United States leaving its
position of clear supremacy as a superpower, we see China moving up into that position, we have
rarely seen transitions of power go smoothly in the history of civilization. And we've never had
transitions of power be at this kind of global level and with existential level technologies,
and with over 7 billion people and with a biosphere near collapse and near fragility points, like
we're in a very different place. But even when just there was a local hegemony where the power
was moving from one kind of local power to another, those were usually not easy transitions. So
lots of different scenarios. And then there are the exponential tech scenarios where different
kinds of exponential technology, exponential technology means exponentially increased power
to affect stuff. And whether we're talking about through AI, or through CRISPR and biotech, or through
nanotech, you know, or through robotics, if we have exponentially increasing ability to affect stuff
without exponentially increasing good choice making, that is just self terminating, no matter what.
And that is the scenario we have right now. So exponential tech can lead to existential scenarios
on purpose or on accident, right? You can have just much more powerful kind of capacities,
military capacities, and much more powerful capacities that even smaller actors are able
to get. Nuclear bomb started off as such a difficult thing that only huge state actors
could have it, those state actors could watch each other, you could have a mutually assured
destruction system, so nobody could use it. But as you start to have exponential tech that
becomes distributed, where smaller and smaller actors have access to larger and larger potential
to affect things, the ability to avoid that happening gets harder and harder. And then you
also have exponential tech that leads to existential scenarios accidentally. So most of the AI risks
that Boston lays out in superintelligence, the gray goo risks that Drexler lays out, you know,
these are mostly where we create an auto-poetic system, we create a self-fueling system that
has a faster feedback loop, is more adaptive than biology and not commensurate with biology.
And so we have to avoid accidental extinction, as well as on purpose extinction, you know,
that's kind of a rough lay of the land of the categories of existential risk. Now, if we take
a step back from it, we can say all of these categories have some things in common, some deeper
underlying drivers that are actually the real existential concerns, because at this level,
the scenarios are basically countless. But if we go deeper, one way of saying it is that the real
existential risk is a loss of sense-making, a loss of the ability to actually make sense of the world
around us, and what is worth doing, what the likely effects of things will be, what the effects of
our actions are now. And so when we think about it, how long do we have with ocean acidification
before the coral die? Right now, the thoughts on that vary so widely that it's either the most
important issue, or we have quite a bit of time. And is Fukushima really close to releasing a lot
of radiation or not? And can North Korea's nukes really reach certain places or not? And what are
the real risks with AGI, parasitic AI, et cetera? Like if we don't have better ability to make sense
of these things, then they just all fail scenarios, right? Because we don't know how to prioritize,
what should actually get attention paid to it, and what could be successful and what's not likely
to be successful. So we can say that a lack of information coherence is one of the things that
is at the heart of driving them. And now to take a deeper step, we say, well, within capitalism,
and we can step even further back in a moment, but let's take that step. Within capitalism,
where we're playing a competitive game, we're playing a win-lose game, usually zero, sometimes
small positive sum, but still fundamentally win-lose, information is a source of competitive
advantage. So we are incented to both hoard information and to create disinformation. We
actually, like if we succeed at that, we will actually do better within the system. So as you
have exponential technologies, the ability to do more media, spread more different info through
more channels, et cetera, how do we have exponential information tech with the incentive to disinformation
and actually be able to have enough coherent information to have any idea what the fuck is
going on? Well, basically, we don't. When you think about getting towards the tipping point of
climate change, where if we get to a positive feedback loop with warming or something, and if
we don't stop a dynamic before a certain point, we won't be able to afterwards, we're actually pretty
close to the point of peak discoherence, where if we get to that place, we might not actually be able
to recover coherence. And so I would say that's one way of thinking about what is actually essential.
Another way of thinking about what's essential is, like we said, exponential technology. It's very
hard for people's intuition to grasp what an exponential curve is, because most of the things
we experience don't feel like exponential things, but most of technology that is exponential is
increasing our ability to affect something with our choice, but it's not increasing the quality
of our choice. Now, when you multiply these together, actually decreased information coherency
with increased impact, that is a self-terminating scenario.
So what are some of the ways of avoiding that? Especially, I liked what you said about our
loss of sense making and the exponential curve of that also. That's a really interesting factor
that I think a lot of people aren't talking about. It relates to one of the questions I was going to
ask. What do we do about the institutionalized ignorance of people to what is actually going on?
You mentioned the corporate interests and producing disinformation, but there's also bad
educational systems that are outdated or motivated by different factors that have nothing to do with
actually giving people good information, and then there's research that serves corporate needs,
and then there's media propaganda and politics and all this stuff. So what kind of tools do we
actually have to change these systems in a way that they serve the planet, rather than serving
these individual interests? We could say, well, when you talk about sense making, shouldn't that
be science? Shouldn't science be sense making? In the same way that we could say, shouldn't
journalism be sense making? Shouldn't the intelligence agencies of the world be sense making?
We've seen scenarios where a scientist publishes a scientific paper in a prestigious scientific
journal where the paper that they wrote is complete gibberish. They made it up with technical sounding
words, but it's actually gibberish, and it goes through the publication process because they
came from the right university or whatever, and they were doing that just to show that the peer
review process is broken. We've also seen where stats like 50% of the articles posted in places like
Journal of American Medical Association five years later, the findings are found to have been
misinterpreted or wrong or had bad methodology, et cetera. 50% wrong means that if I'm reading a
cutting edge medical journal, my chances of knowing what's true are 50-50. It's like pulling
tea leaves would give me as much of a sense of what's true. That is a broken sense making system
within science. If you want to think about what the heart of science is, like what the essence
of the philosophy of science is, the essence of it is earnest inquiry, like earnest desire to
understand the nature of reality. Whatever the speed of sound actually is, I don't care
if it is different than I think it is, I want to find out. There's a certain reverence for
reality and respect for the nature of what is beyond my own ideas about it or how I can benefit
from it that is at the heart of the scientific impulse. But the scientists that need paid and
the equipment has to come from somewhere. If there are some of the answers that are more profitable
than other answers, then it's easier to put money into it because I'll be able to get that money
back and if an herb or a plant has some medicinal property, but I will never be able to patent it
and I won't be able to recoup the money that I get from the small margins that I would put into
the research, how can we afford to pay for it? But we will with, say, some synthetic thing,
I can get a patent on, etc. What actually gets researched within that structure and how it gets
researched? You have to factor how deep those kind of perverse incentives end up trickling
through the whole thing. Then you ask a good question, which is, within a system,
within a fundamentally win-lose game-theoretic system, how do you prevent these issues and
be able to have real coherency when we are incented to withhold information and even,
you'll see in soccer or football, whatever, someone will fake left to try and get the other
person to go left and then they'll actually go right. That's disinformation, intentional
disinformation so that you can throw the opponent off so you can win. This is not different in
corporations or nations, right? Intel and counterintel and intentional disinformation, same thing,
but with global level consequence. Here's another good way of thinking about it. Think about early
tribes as competitive teams, almost like a sports team, where they have to work really well together
and be very coherent with each other to be able to compete with other teams in military conflicts
when they occur and compete with the other teams for scarce resources in the shared environment,
the shared commons. Say they weren't military, right? They're just doing their own thing,
there's plenty of abundance, but then if any of them realize that they can do this military thing,
go kill another tribe, take their stuff and get the riverfront that they had, or get whatever
kinds of things they had acquired and developed, that actually worked for them, worked better.
Everyone else has to build defensive militaries at least, otherwise they lose by default. One
of the things to get in the history of win-lose game theory is that, one, it worked. You could
actually go kill the other people, take their stuff and make stuff better for you and your people,
and two, if you didn't play win-lose game theory and someone else did, you lost by default,
which is why most of the more peaceable, less militaristic cultures got wiped out.
Then we say, one of the tribes is just bigger and stronger than us, we're not going to be able
to compete with them, but if two or three of us smaller tribes band together, we can, but then,
of course, the other side has to compete, so they band together. Now we move from tribes to villages,
right? Then we can move up to kingdoms and to nation states and to global economic trading
blocks. We can think about those evolutions of what we think of as civilization structures,
as evolutions of competitive teams within a win-lose game theoretic structure that have
more and more power to be able to out-compete the other one, and that's both have more people that
can be coherent with each other against the other one, right? As a nation, we're a team competing
against the other one, we have a shared military-industrial complex paid for by taxes, whatever,
or as a religion or a race, so we can have some overlapping teams. But once you get to the point
where all of the teams are stepping up simultaneously, that's the kind of evolutionary
driver, they're stepping up in their power, once you get to the point that you have exponential
technological power on multiple teams, where the amount of power that it would take to actually
win would require destroying the playing field, which becomes inevitable, right? Inevitably,
power will keep increasing until it's actually bigger than the playing field can tolerate,
and then winning pretty much means losing because there is nothing left to win, right?
So right now, we're at a place where the superpowers of the world cannot win a war against
each other. When you have hundreds of times the nuclear capacity necessary to kill all life on
earth, there is no winnable war, but we keep building more fucking military capacity. We just
spend a trillion and a half dollars on the F-35 because we didn't have badass enough jets with
the military that already has all the technical capability that it has in the US, right? And
think about what a trillion and a half dollars of resources means to other kinds of things.
And so when you say, why did we ever get more than five times as many nukes as we needed to
kill all life on earth? Like, after you've got enough nukes to kill life on earth five or ten
times, why do you keep building more? Well, you have hundreds of times. Was that ever a really
just strategically smart idea? Or was that because we had a for-profit military industrial complex
that makes money when that happens, where the people who are in positions of decision-making
power also happen to be shareholders or have vested interest in those structures? And this
is not blaming the people involved. These are structural, right? These are structural dynamics.
And so can you have lasting peace and a for-profit military industrial complex at the same time?
Of course not, right? Like, that's supply and demand 101. If there is a massive capacity for
supply, it has to protect the demand. And then you think about where those perverse incentives
go everywhere, right? Healthcare, where if people weren't sick, then the system loses all of its
resource. And so how could it ever really invest in prevention deeply when its profitability
depends upon symptom management? And if you even cured people quickly, that's not profitable. But
if you manage symptoms ongoingly, it's profitable. And if the symptom management causes other issues
that need more symptom management, i.e. more meds, that's just like an upsell or a cross-sell,
maximizing the lifetime revenue of a customer that happens to be a patient. So when you think about,
you know, win-lose game theory within that kind of incentive structure, where we can't win at the
wars anymore. And yet we're moving closer to the kinds of tensions where war becomes more and more
probable. And we also can't win at competing for extracting the scarce resource. When we've already
extracted so much scarce resource, we're almost at the biosphere's limits, right? We're almost
at the limits of what can be handled in the extraction of oil or fish or grazing land for
cattle or so many things. And so either we continue with win-lose game theory, and it becomes omni
lose-lose catastrophically, or we have to figure out how to have that power not turned against
the other power and figure out what does omni win-win mean, where no one has incentives that
are misaligned with the well-being of others in that system that has that much power. And that's
really the fork in the road we're at as a species for the first time ever now, is we either figure
out what omni win-win means economically, as a worldview, governance-wise, we either figure out
what that means, or we continue with win-lose and it becomes omni lose-lose, which pretty much means
we either step up into a radically higher level of quality of life existence with a new kind of
collective intelligence, or we have a catastrophic step down, existential or near existential. But
in the next not very long time, that's really the fork in the road.
And what evidence do you see of us going down one path or the other with more preference?
If we just plot curves, it doesn't look good. If we just plot the curves of what has happened so far
with regard to how much harm came from new power that we developed, and we look at how
fast we are developing new power on exponential curves, if we look at the population curves and
we look at biosphere issues, it all looks pretty bad from that point of view. And you can try and
take the techno-optimist route and say, but look at the rate at which we are developing solutions.
But here's the problem with that. Here's another way of thinking about what the driver of the
existential risk and all the catastrophic risks are. So one way of thinking about it is that
win-lose game theory is driving the whole thing, right? Win-lose structures are driving the whole
thing with win-lose game theory multiplied by exponential power and exponential populations.
Another way of looking at it is a lack of information coherence. I mean, there's information
coherence and coherence as beings and agents with each other. Another way of thinking about it is
a lack of coherence around value measures. And this is actually a very deep and essential way of
thinking about it. Think about a tree in an ecosystem and we say, well, what is the value of that tree?
Well, it's providing a home for a bunch of pollinators and birds. It's providing food for
them with flowers. It's stabilizing topsoil. It's symbiotic with the micro-rysia and the fungus
and bacteria and the soil. It's providing shade for all of these things. It's pulling out CO2
and producing oxygen and providing food for animals. And it might have millions of value
metrics as part of this kind of complex ecosystem. But then we cut it down to make it $10,000 with
a 2x4 and its value is $10,000. And the 2x4s, they're not sequestering CO2 and stabilizing
topsoil. They are serving as a structural strut. It's this one really simple thing,
right? Structural strut. So we took this very complex thing and we reduced the complexity
of it radically. We made it a very simple thing. So we downcycled the shit out of it
because what the metric we were seeking to optimize was dollars in my account. And so a
dollar is a value metric. But I get the $10,000 from that tree or I get $10,000 from the elephant
tusks, right? Or I get $10,000 from this servicer. Well, it's like, how do I relate the value of an
elephant tusk or a person's art or a tree? Like these should not be fungible. These should not
be inter-exchangeable. These are fundamentally different things. But because I remove all of
the information from them and all of the context, I want them to be simply exchangeable in terms
of capital so I can maximize the ease of transaction to grow pools of capital. That is an
extinctionary dynamic is that we're taking complex value and turning it into simple value.
That almost sounds like a gray goo scenario of itself. It is.
We're taking all of these super complex things and reducing them to this homogenous goo that is
monetary value. I actually just saw a really good article that was called Capitalism as a
paperclip maximizer. And it's actually a really fun thought experiment. Paperclip maximizer,
if the people aren't familiar, was, I don't remember who came up with it first, but it was in
Nick Bostrom's book on AI issues and just said we could have an AI whose job was working
at a paperclip company to maximize paperclip production. And it also had the capacity to
upgrade its own capacity. And it ends up getting into a place where it makes all these paperclips
and upgrades its own ability to make more paperclips and then starts competing,
taking all of the resource that humans needed to make paperclips because that's its algorithm.
And as it's increasing its own capacity, it's being able to out-compete us. And then it realizes
that we're made of atoms, that it can make paperclips out of, that it's this continuously
growing, this auto-poetic capacity that's just turning everything into paperclips.
And so they were saying, this paper capitalism is a paperclip maximizer because
capital is making more capital. That's the gist of this distributed system. Rather than as a
central AI, it's this distributed collective intelligence system that uses these distributed
human bioprocessors within it. But because we've reduced the value to capital and having more
capital makes it easier to get more capital. The capital gains interest faster than the overall
economy grows, gives you access to more financial services, etc. Then that's the goal. So to say
capitalism is a paperclip maximizer is a reasonable thing. And Drexler's model of gray goo was based
on another exponential tech, which was nanotech, the ability to rearrange things at a molecular or
atomic level. If we do that right, it's pretty awesome. If we do it right, it's like the replicator
from Star Trek, we can take trash and turn it back into rad stuff at the level of just atoms.
And that actually might be the future of the materials economy is that we have quantum computing
that has enough sophistication, give or take a million qubits to be able to properly direct
nanotronics to take old stuff and turn it back into new stuff at atomic level, creating a closed
loop materials economy that can upcycle indefinitely. But if we get it wrong, then you can have these
machines that are just turning everything into goo. So Drexler had this model called gray goo.
And in a way, UV, you're right, capitalism as gray goo is we take this tree with this
radical contextualized complex value and take it out of its context and give it this reduced,
abstracted, simplified value metric. And we've done that to 80% of the old growth forests that
the earth spent billions of years developing, and 90% of the large fish species in the ocean.
And then what does that capital really do other than continue to do that auto poetic thing?
And so when people think about like, what is capitalism? And honestly, we can say communism
and socialism were really actually subsets of this kind of resource concentration system.
It's a process of abstracting value. So we go from complex value to abstracted value,
and then extracting it and accumulating it. That particular model came from a colleague,
Forest Landry, and capitalism does that. But socialism and communism have other versions
of doing that. But that's the core thing. That's the ring of power that has to be broken is abstraction
of value and specifically a reductive abstraction, extraction. So you remove the content from its
context and accumulation. And that's how you take a complex system that is resilient and
turn it into a complicated system that's not resilient, that's becoming progressively simpler
and kill it. This brings up something I find to be fascinating, which is the use of blockchain
to tokenize abstract value. Do you have thoughts about this and whether it's actually possible
to do this? I can get more specific if you need. Yeah, please do. So we had an interview last year
with Vince Means, and he talked about tokenizing these abstract values. Actually, he used the
tree example. So what if you can tokenize all the extra abstract value that a tree provides,
have a token for oxygen converted, that sort of thing? And what if you can optimize those
different tokens in the same way that capitalism optimizes capital? Can we use these other systems
of value and use them as currency as well? I say that loosely and optimize that using the existing
capitalist system. I don't think so. Laser-affair capitalism always kind of goes there. It says
the tragedy of the commons is because if nobody owns it, then they'll fuck it up. But if someone
owned it, they take responsibility for it. So really, the answer is to have everyone own everything.
Every coral reef, everything is owned, and we have some way of creating capitalist value in
the process of owning it. This breaks down for a number of reasons. So why is air not worth
anything and gold is worth so much? Because in a win-lose game model, something that everyone
has access to and can't not have access to and I can't get any more of doesn't give me competitive
advantage. So everyone has access to air, so I don't need to value it. I don't need to pay
attention to it. Now, if I cut down this tree, of course, I'm cutting down something that produces
oxygen and sequester CO2, but I'm not cutting down enough to fuck up everything. I'm not cutting
down enough to really affect my experience at all. Now, of course, as you get 7 billion people
with that mindset, it becomes a different story. But distributively, they're all thinking about
their own action and that if I cut this tree down, I have $10,000 worth of 2x4s in my pocket
and I need to feed my family and I don't have any measurably less oxygen, but multiply that by 7
billion and we all die, right? But if I don't cut this tree down, that tree in the commons is worth
nothing to me in terms of differential or competitive advantage. And I have a system where
pre something like basic income, even before competitive advantage, I just need to live,
right? So if I can take something out of the commons to live, like I'm going to do that.
So gold or diamonds or whatever are worth a lot because they were perceived as scarce when
we started the valuation schema. And if there wasn't enough for everyone to have lots of it,
then some people could have it and others wouldn't and those who had it had something that was unique
where they had some differential advantage. But it's still fiat, right? Like whether it's just
printed dollars or gold that we ascribe that value to that is not based on the actual material
value of the gold. And then we set it in vats. It's still like, it's a value metric that we made
up. And so we'll have gold worth, you know, however much per ounce. And because of that,
if there's gold under some trees, we'll cut down a lot of trees to get the gold out and burn up the
oxygen or damage it in the process, because we have a system that is valuing differential value,
not systemic value. That's if you start saying, well, how do we actually advance systemic value?
You can't really tokenize that because as long as there are separate balance sheets,
and I have some number of tokens and I'm trying to advance the number of tokens that I have in
competition with other members, we're going to keep getting all these win-lose dynamics.
So the post-capitalist move is a deeper move than that. Now, does that mean that tokens and
blockchain can't serve a transitionary role? No, of course they can. Right now, we make up the
currency units, you know, through a central bank. Well, you can have another group make up a different
kind of unit, and you can build some better structures into that unit. And that can be
valuable, totally. But as long as we still have private ownership of those units, that if I have
more of the units to begin with, it's easier to get more of them. If I have less to begin with,
it's harder to get more of them. So I have widening wealth gaps built in. All of the other shitty
aspects of capitalism, all of the derivatives and complex financial instruments and fucked up
markets will end up arising from those competitive structures. Those are just basically inexorable
ways to game the game. So then you're like, oh, fuck, so what do we do? We do need a completely
new economics. We do need a completely new system of sense-making. We do need a completely new system
of choice-making, governance, at an axiomatically redesigned level. And when most people, when
you ask them what is economics, they think, well, it's a system of trade, system of barter.
They're already assuming private ownership and trade and barter that is then mediated by some
kind of currency. But you have systems that don't have private ownership, that don't have trade,
right? Because I don't own shit to trade to you. We have some kind of systemic value. We just didn't
like those ones, because for the most part, we thought of those as communist socialist systems,
where if I didn't privately own stuff, then the state was giving me what I needed, but then the
state was also forcing me to do shit. Because as long as there are shitty jobs that nobody wants to
do, that we don't have intrinsic motive to do, but the society needs done, how do you get the
people to do the shitty jobs? Well, if we kind of meet everyone's needs throughout this thing called
like a state, then the state has to force some people to do the shitty job. So we call that
imperialism, and we don't like communism because it's imperialist. So we say, well, let's let the
free market force them, which is if they can't be smarter and educate themselves better to do a
better job, then they get the shitty jobs. And if they don't, the state isn't forcing them, but they
will still be homeless and starve. It's just where do we switch the imperialism, right? We switch it
from the state to the market. But basically, we still have to have a system of extrinsic incentive
to control people to do shit that they're not intrinsically oriented to do. Well, okay, so that's
been part of what we've had to work with. And Marx had thoughts on it and Smith had thoughts on it.
But technological unemployment is changing that whole fucking story, where you can start to automate
the shittiest jobs. So you can have a system where the things that people actually could have
intrinsic incentive to do are what are there for humans to do, the things that you had to
extrinsically incentive them for, you don't have to like that's a new thing. That means an axiom,
which is how do we deal with the labor force and axiom is changing. And so we have to go back and
rethink all of our economic ideas. And with regard to sense making, there's a lot of core things
that are changing in terms of our capacity for sense making. We have the ability to have
IoT sensors, right? Internet of Things sensors that are giving us real time data about air
chemistry and water chemistry and soil chemistry and fisheries and the commons and etc. And we have
deep learning systems that can be synthesizing that information. We never had sense making systems
like that. We didn't even have the technological capacity for things like that. And choice making
systems. So basically we are at the face of deeper issues than we've ever been at the face of before,
but also with deeper capacities. So the same increased technological capacity that if we keep
using it to take complex things and make them simple, simple or complicated, instead of complex.
And we keep using it to fight against each other and win and competitive win-lose games.
If we keep doing that with these increased technologies, that's existential. But if we
use those technologies to actually obsolete those core social structures and create coherency-based
social structures where that technology can be used for, not against, then, I mean, we really
do have a fork between radically better than anything we've ever experienced or catastrophic.
So now my question is, we talk about all these different structures that we can create for humanity
to exist within. But there's also human nature and not just human nature, but the nature of
something being alive as essentially being a replicator machine. So we have some sort of
intrinsic tendencies that may be very difficult to hack. And no matter how you structure the system,
we're going to default to those tendencies. For example, that's probably one of the reasons
why communism didn't work. Just in some ways, it probably went against human nature or the
nature of just things that are alive. So how do we deal with that, in your opinion?
That's not why communism didn't work though. Yes, there were things about the way it was
structured that did not structure themselves well with humans. But it's important to get
that it wasn't like it wasn't a good structure and fucked up human nature was the problem. It's
that it actually wasn't a good structure. There were good parts of it. But in trying to keep us
from having economic inequality, because economic inequality would continue to inexorably widen,
it became a lowest common denominator system. And it became a system of lack of freedom in some
really key ways. So yes, it was against our nature, but it was actually against good parts of our
nature. So then the question is, are there shitty parts of our nature or inexorably problematic
parts of our nature? This will be the hardest part of the conversation so far. Because I'm going to
say that what we call human nature is mostly human conditioning that is actually quite changeable.
And I don't even mean genetic engineering or brain computer interface are necessary.
Let's unpack this. The question you asked is an essential question. When we look at Japan or
Denmark or I think there's a few Nordic countries that have had decreasing populations
after they reach a certain level of economics and education, it is not that the nature is to do
exponential population curves forever. That is the nature within a certain set of conditions.
When the conditions change, many of the deepest, like even procreation, behavioral dynamics and
drives start to shift without externally imposed things like birth caps like China had. It's really
important to see that. When you look at some of the indigenous cultures pre-capitalism, they didn't
have private ownership. They had shared structures and they had languages that expressed that concept
of sharing. They had radically de-emphasized words like mine and radically increased words like ours.
In any of those cultures, and we can see some of that in some of the Fujian Polynesian cultures,
the Maswa, a number of them, wherever the mine language was less emphasized in the nature of
the language, also words like selfish and greed and jealous were less emphasized because those are
the results of mimetic structures of scarcity-based value in a competitive framework structures.
So when we say what is human nature, it does a little bit that's definitely human nature,
like an impulse to right oneself when they start falling or to pull away from hot,
these autonomic functions, those are nature. But so when we get what is essentially human
nature, what was uniquely adaptive about us is that our genetics selected for mimetics,
our genetics selected for a creature that could continue evolving itself, developing itself
within the course of its life pretty radically, which is why a baby horse can be up and walking
in minutes and it takes us a year. Think about how many multiples of the 20 minutes it takes a
horse to get up go into a year for a human. How useless we are for so long, even a baby gorilla
can hold onto its mom's fur as she moves around to the trees in the first day. We can't even move
our head for three months, right? And that's because we're born neoteness, we're born basically still
embryos, where we're imprinting the world we're born into because as complex tool makers and
tool evolvers with our capacity for abstraction, we evolve the environment around us radically.
And so creatures, they evolve genetically to their environmental niche, but we're changing
our own environment. So we have to be able to adapt to new environments that we create. So we
have to come in not hardwired because it was super adaptive to be able to throw a spear at one point.
But today, like you and me don't throw spears that much, we text and we do other shit. So
we need to not just have really good genetic orientation for spear throw and we need to have
the capacity to come here with almost nothing, not even move our head and imprint the world that
we're in. And so that mimatics is mediated largely through neuroplasticity and the ability to have
a lot of our behavior, not just bottom up genetically controlled, but top down regulated and the top
down systems are highly influenceable. And so we can say humans genetics selected for plasticity
and plasticity has a pretty huge amount of variance and its capability. And so we can create
environments like in, you know, look at the child soldier situations in Sudan or places like that,
where we can take almost everyone through a process that makes various degrees of psychopathy.
We can also, you know, like look at Buddhist culture where you had millions of people
all care about insects enough to not harm them, right? Beyond the Dunbar number,
they had something that developed abstract empathy across the population. And so that
doesn't mean humans are naturally psychopaths or naturally highly empathetic. It means we are
naturally capable of being conditioned in either of those ways, or any of many different ways.
We do have an innate impulse towards agency, towards self actualization within a win-lose
game structure that will look like a competitive impulse, but within other structures within
win-win structures that will look like the desire to go beyond my own previous capacity,
but not to necessarily be better than or, you know, consume somebody or something else.
And so that's where there's an innate impulse, but that expresses itself through context.
Now let's take the next step. There's another really key step here.
Until very recently, humans didn't have any concept of what evolution was. And we only recently did,
and we're only right now beginning to have a deep sense of what it actually is, not just
biologic natural selection, but the process by which subatomic particles come into atoms,
come into molecules, come into more complex organic structures, the dust clouds turn into
stars and spiral galaxies. That evolution is this process of increasing orderly complexity
in a way that has more and more synergy, so more and more emergent property. And the emergent
properties define the era of evolution. And as we're starting to understand this,
you know, like very few people, but the beginning of us starting to understand this,
we can actually become conscious agents of evolution. We can like say, holy shit,
universe is actually doing something. It's actually moving in this direction of increasing
orderly complexity. We can consciously participate with that. And we move from just being a part of
the whole, where evolution is just kind of this unconscious algorithmic process to thinking about,
feeling about, identifying with, and being an agent for the whole. And so then evolution itself
becomes an agentically mediated process. Like we actually say, shit, the whole evolutionary
process resulted in me. I am the result of this whole evolutionary process. So in a way,
the evolutionary process is kind of awoke to itself in me as I'm contemplating it. And so then
we stop needing pushed by evolutionary pressure and pain to evolve. And we start being able to
evolve consciously by what Tere de Chardon called the lure of becoming, because we actually identify
as evolutionaries, right? As part of the evolutionary impulse. And in doing so, really
obsolete the need for pain as an evolutionary driver. So I know I said a number of things in
there, but human nature has the capacity to transcend much of what human behavior has been so far.
That is so well said.
It's like we're the tentacles of the universe or something.
Yeah, the sensors and the actuators, right?
Yeah, it's quite a spiritual proposition too, that we're becoming conscious of what we are
and acting based on that realization.
Yeah, and I actually don't think anything less than that is adequate for preventing existential
risk. And that's a big deal. That really frames up what we're here to talk about, which is as we
have increasingly distributed exponential ability for impact, we really have to have exponentially
increasing good choice making, omniconsiderate choice making everywhere. So as long as I,
when we talk about win-lose game theory at the deepest level, it starts with me having a sense
of self that's separate from everything else, even all the way down to the semiotics to the
language, right? And I was told when I was a little kid that I'm Daniel and you're Mike and
your UV and that's a chair and that's a house and that's a crow. But it's all this just separate
stuff in universe. And I can be a good boy or a bad boy independent of what's happening for
anybody or anything else. I can actually win at the expense of someone else losing in a baseball
game or whatever and get a whole lot of praise. And someone else winning can mean that I lost,
right? Like I am not only a separate self, but I am also a separate self in competition for the
scarce things, including scarce love, right, scarce attention. So that's imprinted. That's the
basis of the win-lose structures at the level of individual separate self identity. When the
reality is we go a little bit deeper if we weren't playing silly games, right? What the fuck am I
without all the plants that make all the oxygen? I don't exist. I can't breathe. My mother wouldn't
have been able to breathe. I wouldn't have been born, right? Without plants, I am not even a
concept. So how am I a separate self if I am required the plants? But the plants require the
pollinators and the micro-rysium, the soil and on and on. And what would I be without gravity?
I'm not fucking anything without gravity or without electromagnetism. What would I be without the
people that came before me that made the language within which I think all of my thoughts, that
has actually patterned the way in which I think and feel and structure the world, right? And I
start to say, well, shit, I'm actually, I wouldn't exist without all of it. So that South African
saying umbuntu, I am because we are, is actually profound, meaning me as a separate self, right?
It's okay. So take gravity away. Take electromagnetism away. Take the plants away. I'm floating in the
middle of a universe with no, I'm not even floating. There's nothing holding me together, right? Like
the concept of me as a separate self is nonsense. It's a misnomer. Really, it's just like when you
take the tree out of the rainforest and turn it into wood, it's worth a whole lot less. The context
had it was its value, right? Its value was the content within the context which co-evolved.
I am within a context. And without that context, I don't even exist. And so when I get that I am a
misnomer as a separate thing, that really, I am an emergent property of the whole. I'm an emergent
property of the biosphere, but not just a biosphere because without the sun, I wouldn't be very
interesting either. And without the laws of universe, I wouldn't, I'm an emergent property of
universe. And so are you. And we're interconnected in this. And that's waking up at a cognitive level,
existential at a spiritual level. And really, we need new macroeconomics. Economics is basically
what do we value? Don't value oxygen because we can't get any competitive advantage off it,
even though we'd all die without it, but value the gold because I'll get some competitive advantage,
even though I'm just going to stick it in a safe, not do anything with it. Value the whale dead
because I can do stuff with it. I don't value it live, right? Like what do we value? Our value
system is codified in a value equation that then determines what we confer power to. That's economics.
Totally spiritual thing. So we need new macroeconomics that aligns the incentive of every
agent with the well-being of every other agent and of the commons because any gap between your
incentive and my well-being or your incentive and the well-being of the commons, then you will do
what you're intended to do and you will externalize harm directly or indirectly, right? And with
exponential increasing technology, that harm will always become catastrophic eventually.
So we need new macroeconomics that fundamentally align our well-beings with each other. And in
doing so, we have no incentive for disinformation. We only have incentive for information, so now
science becomes science, actually, right? And journalism actually becomes journalism. We
can actually fucking make sense of stuff because I'm not trying to hide information from you or
lead you down the wrong track, so I get there first. And we need, you know, so like new macroeconomics,
new sensemaking, new systems of choicemaking, but all the way down to a new worldview,
where we actually identify with the evolutionary impulse, so we don't need pain to push us.
We're evolving, right? We're being and becoming and doing at the same time,
for ourselves and the whole at the same time. And all the way down to our personal identity
shifting from being a separate self, which is just nonsense, to being a unique emergent property
of reality. And when I get that you are a unique emergent property of reality and you
have had life experiences, you've sensed stuff that I haven't. You have a perspective on everything
that I couldn't possibly have. You have the ability to do stuff that I can't do. If you
self-actualize fully, you will create beauty in the world that I couldn't, right? Like no amount
of Michelangelo's self-actualization would have done MC Escher or Salvador Dali, like their own
fucking kinds of unique creation capacity. And so I can only compete with you when we reduce you and
me to very simple metrics, right? How much money do we have or how fast can you run or whatever,
right? But when we go back to the full metrics and it's basically an indefinite number of metrics
and the synergistic combinatoric of those, they're incomparable. So now the competition thing is gone
because I'm identified with this whole complex thing, not this little narrow thing that in that
narrow thing, we can compete with each other, right? When that's gone, then you self-actualizing
not only doesn't take away from me, you self-actualizing makes a more beautiful universe in a way that I
can't, but I want to live in that more beautiful universe. So I'm incented to help you self-actualize.
The gist of the story as I see it is that we awaken to that to everyone as a unique emergent
property of an interconnected whole who needs to simultaneously self-actualize, help everyone
else self-actualize with the attendant economic systems, governance systems, etc., where all
individual agentic activity is good for the individual and the whole simultaneously just
like cells in your body that are not competing against each other for scarce resource, even
though we've tried to retrofit that shitty capitalist idea on biology as a weird kind of
confirmation bias. When you think of it in almost mythic terms, and you have to think of it in
mythic terms, exponential technology is where does an exponent scale to as we're moving towards
having the power of gods? Like Barbara Marks Hubbard said this when she watched the bomb be
dropped by her godfathers who were the generals that were directing World War II, and she saw
that mushroom cloud from Hiroshima, and she's like none of the depictions I ever heard of of
Zeus's lightning bolt were as big as that. And so she went and asked him. She asked Eisenhower,
and the other generals, I think MacArthur, and she said, I see this new power that we have,
and I see the power of it that's bad. What is the power of it that's good? And they had no answer.
And so she set out on that life quest to answer that question. But this other part of it we can
ask is if we're scaling towards the power of gods, then you have to have the wisdom and the love of
gods or you self-destruct. And so when you think of it in those mythic terms, it's like that's
really the story right now. And so the other part of that mythic term is the coming of a
different age and an age that is not categorized or characterized by like fundamentally separate
interest and competition for scarce resources with separate interests, power over dynamics,
but is characterized by, and this will sound corny, but characterized fundamentally by
the metric we are optimizing is love, which requires all the complex metrics of everything
the tree is. It requires recontextualizing things and unabstracting them into their
instantiation, right? And why I say love is what brings the atoms together into molecules is these
attractive forces, right? What brings the molecules together? What brought the two of you together
to make this thing? What brought us together? There's these attractive forces that bring anything
together that leads to synergy, that leads to the emergent properties, that leads to evolution
and ultimately we become stewards of that bringing reality together into higher and higher order
synergies. It's funny how this is such a repeated lesson to go towards what attracts you instead
of avoiding what repels you. Like love is something I've never cared to define as well as you've
defined. I'm curious how you've actually arrived at that being the metric. Like maybe can you unpack
that a little more? It's not a metric because you can't put a number on it. So that was kind
of euphemistic language, but it is love is a very besides damaged word, unwell to find word in
English. But if we want to borrow from another language and take the Aeros Senegape model,
I think it's useful. So the Aeros model of love, erotic love, doesn't just mean sex. Sex is one
place that it expresses itself, but it is a passionate desire. It's energy. It's an attraction.
So we can think of things being attracted together, right? People being attracted together to
procreate to make new life as a special case example of people being attracted together to
create anything or anything being attracted together to create anything, right? Subatomic
particles being attracted together to have this relationship that is atoms. And so we can think
of the evolutionary impulse, right? As kind of an Eros energy and the agape energy, that's a kind
of love. And so when we think about participating with the evolutionary impulse of universe consciously
participating with it, then we think about supporting things coming together in right
relationships that are synergistic, right? That's what's aiming at the, you know, there is no
destination. It's an eternal process of becoming and blossoming. The agape love is actually worth
mentioning here. It is often thought of as an unconditional caring for, I think, a decent
way of thinking about it is you can't love something or someone meaningfully if you don't
actually see them, understand them, right? Otherwise, it's just an abstract kind of concept.
But for me to really love you, I've got to understand you. I've got to know you, which means
for me to really love you. I have to seek to understand you and know you. And then as I
understand you and know you more, I'm able to love the unique being that you actually are.
And in seeing your uniqueness and your irreplaceability in universe, I want for you everything
that could help you enjoy life, self-actualize, contribute fully. And so the process of seeking
to see and know reality and wanting for it and wanting to add to it is that impulse of love.
And I think it's those two impulses, the becoming impulse and the being impulse, the evolving and
the nourishing impulses that become the deepest kind of drivers of both inner states and the
macro systems of the future. So here's a difficult question. The people who are creating the economic
systems are not very enlightened at the moment. So how can we and can we help people awaken to
this understanding so that we can create the kinds of systems that will support our evolution
because we're kind of running out of time? Well, if you think about, you know, within a current
economic system, moving up in the ladder of success in the economic system requires things
like justifying externality. The thing we're doing is really good. So it's worth all of that
mining damage or all of that waste damage or the, you know, poor condition or workers or whatever.
So someone whose empathy is really intact can't do that. And so if you don't have the ability to
shut your empathy off, which is kind of low-grade psychopathy, you're just not going to be able
to succeed. And as you start to succeed and get rewarded, it's actually a system that is
not just attracting but incenting and conditioning a kind of abstract psychopathy.
And as you get into financial services, even more so, because you are not providing real
goods or services, you're basically the more you can game the system, the better you can do
in that dynamic. So when you have a system that attracts, incents, and rewards pathological
behavior, so it's important to understand that success in the current system has required
being at minimum complicit with the capacity to unwillingness to be complicit with that system.
What we think of as power even, which is a power within a win-lose structure power over,
is psychopathologic, right? And so we're not creating new power structures. We're creating new
structures for shared activity, but they won't be power in the same sense of what we have thought
of as power anymore. There's a few aspects of how people who are in positions of influence currently
can start to tip. One is as they recognize near-term existential risks that are inexorable
within the current system, which means they will not win, right? Their attempt to win
where win-lose becomes lose-lose because of the power dynamics exceeding the playing field's
capacity. If they understand that, which more and more people in positions of influence are starting
to, then they realize that they actually need to learn a totally new kind of game.
And when they realize that the new kind of game that is possible isn't shitty communism, it's not
like a lowest common denominator. It's a world where we can create a commonwealth economics
that has a higher level of material resource abundance for everyone than anyone, including
them currently has. Because right now, we can't make the best phone or the best computer or the
best fucking anything because the science knows how to because the IP for how to make the best one
is held between 10 different companies that are competing against each other. So we don't get
information coherence. We don't even research the best things in medicine because some of them
aren't profitable. So the wealthiest people today don't have access to good healthcare because we're
not investing in it. The world that they have one in is ending. And that is unavoidable. That's
inexorable. So that game is not a game that gets to keep being played no matter what. The world
that we can create is better for even the people who are winning at the current system at the highest
level. The world that we can create can have a better system of medicine, a better system of
sense making a healthier environment, better technological stuff, better transportation
because of the coherence leading to better resource allocation and development of tech
and etc. So we can build a world that is better for everyone than building our quality of life today
in sustainable harmony with the biosphere for everybody. The only thing that they would lose
is the differential of how much better it is for them now than it is for everyone else. But they
can't hold on to that anyways. I've actually seen many people who have been in power positions
within the current system who have been coming to these awarenesses naturally. So that's an
in heartening thing. Daniel, do you have any book recommendations for our listeners if they
want to continue learning about these subjects? Yeah, well as we were just talking about a game
that's ending in the new game, the book Infinite and Finite Games by James Kars is a really great
introduction to thinking about what a world beyond game theory is. And it's short and it's
actually like it is both an interesting treatise on economics and governance and social systems and
a really profound spiritual book. So I recommend that one, Infinite and Finite Games. And you
books like the collapse of complex societies by Tainter that go through all of the civilizations
of the past that collapse and how and why they collapse is a very sobering insight for people
to realize that existential risk at a whole species, at a whole global level we've never
faced before, but we have at the level of civilizations and we almost always fail.
And to kind of understand why so that we can make sure we are not repeating that, that's actually
very valuable, very insightful. And if people want to read about existential risk itself,
going to the Future of Life Institute or the Cambridge Center for the Study of Existential
Risk, places like that and reading their reports, those things have a lot of value. Going even back
to like limits of growth and the World 3 model, it's surprising how many places the World 3 model
was accurate from when it was started. So there's still value and limits of growth. All of those
are good ones. If I had to pick one for people to start with from here, I'd say Infinite and
Finite Games is a good start. Cool. Thank you. I'm going to pick that up. Awesome. Any documentaries
or movies or anything multimedia-esque that you can recommend? For people who are not already
familiar with Jacques Fresco's work on the Venus Project, they should get familiar with it because
there are elements of what's necessary that weren't included. The world he was coming up through,
he didn't get very exposed to complex systems there. So the distinction between needing to
build a world that's complex and self-organizing rather than complicated was not a clear distinction
and how sense-making and how worldview happened. He was working from a pretty straight kind of
technotopian point of view and he doesn't speak much to the transition of how we get there. But
with all those critiques in place, there's a lot that he spoke to and demonstrated regarding how
you could have a system beyond scarcity-based capital that worked radically better than this.
And so I think the documentaries, one is called Paradise or Oblivion, one's called The Choices
Ours and also the second in the Zeitgeist series, Zeitgeist Addendum. The first half is about Fraction
Reserve Banking, the second half is about his work. I think for people who haven't got into
post-capitalism in much depth yet, looking at the resource-based economy that the Venus
Project proposed is a really good entry point to some of the thought.
Daniel, this has been a fantastic conversation, one of my favorites we've ever done. So thank you
again for coming on and sharing your insights and what you've studied. This has just been fantastic
for us. Yeah, very inspirational. I'm sure listeners will love it. These were fun and
important topics that we got to cover today. This was a blast and when you ask how can we
help people in positions of influence shift, I think what you all are doing is meaningful
towards that. So I thank you for that. Thank you. Thank you. All right, Daniel, take care. Bye.
That's all for this episode. Thank you for listening. For all the books,
movies, and other things that we mentioned in this episode, go to futurethinkers.org
slash 46. All right, we'll see you in the next episode. Bye. Bye.
Thanks for listening to the Future Thinkers podcast. To get notified of new podcasts and
videos, go to futurethinkers.org and subscribe to our mailing list. You can also find us on
iTunes, Stitcher, and YouTube. If you like what we do and you want to help us make more
podcasts and videos, give us a like or a review, share it with your friends, and consider becoming
a patron. Go to patreon.com slash futurethinkers. If you're looking to get serious about meditation,
check out the meditation app that we've created with Vinay Gupta called the cutting machinery.
Go to cuttingmachine.org slash app. Last but not least, if you want to get access to more
content, hidden episodes, or if you just want to chat with us and previous guests,
then check out our community at community.futurethinkers.org.
