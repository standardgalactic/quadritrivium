You know, you take it as something like the free energy principle, you try to think,
okay, what's even more fundamental than that?
What's behind that?
What's below that?
What kind of feeds into that?
I have to say, also, you won't get more fundamental or simple than the free energy principle.
When you realize that your environment is composed of other things very much like you,
right, when you're young, your mom or as your own or your colleagues and your friends and your
family, I think that's interesting because now we're getting to a much more symmetrical
sort of relationship between me and the environment and certainly in this context,
you know, most of my universe is basically you and me.
So now there's a certain kind of symmetry in play, whereas you are my environment and I am
your environment and yet we both have gelatine models of our environments, which basically means
I have a gelatine model of you and you have a gelatine model of me, but the best way to minimize
surprise when I surprising signal that generated by things like me, namely you, is to ensure that
I was much like you as possible so that I can predict what you're going to do next,
because that's what I was going to do next.
And exactly symmetric is so for you.
So that basically means that we come to share a gelatine model,
a shared narrative we're seeing from the same PIM sheet and everything becomes mutually predictable.
What it doesn't describe though is the going back to your
firelight zone and the man in the nice hell, the epistemic hell.
So if it was the case that we could become completely mutually predictable and just keep
on singing the same song together for hour after hour after hour, that will become boring.
And at this point, I think you're now into sort of social neuroscience and joint free energy
minimization that can sometimes lead to quite paradoxical results or
understandings of the way that we search for information or engage with people.
On the one hand, I want to make my world as predictable as possible, so I don't get any
nasty surprises.
So I'm going to go to those kinds of news channels, I've talked to this kind of person,
because I think that we have a lined frame of reference, we have common grounds,
we speak the same language.
On the other hand, I'm going to be compelled to be slightly curious about other ways of thinking.
It's not, you know, we're not all going to merge into one massive community and we are
one massive hive mind, one massive collective intelligence.
It's not going to work because we are compelled to, you know, what would happen if I looked at it
this way? Or what's that kind of person like? What's this culture like?
So, you know, I haven't got any answers, but there's a really, really interesting
field of information in sort of social neuroscience.
Professor Carl Friston is a world-renowned neuroscientist and researcher.
He is best known for his work in developing groundbreaking statistical methods and mathematical
models to understand the workings of the brain and how it gives rise to complex behaviors.
Our discussion mainly tackles his free energy principle, which states that the brain is
constantly working to minimize the amount of free energy in its system.
According to this principle, the brain is a predictive engine that is constantly trying
to make accurate predictions about the world in order to minimize its own uncertainty.
If you got this far, please subscribe and I hope you enjoy our conversation.
Professor Friston, thank you for coming up.
Thank you for inviting me.
Yes, it is a pleasure. For the folks watching this on YouTube, I just want to say they should
know that you are one of the most cited scientists in the world and have made, you know,
monumental impacts on the field of neuroscience.
So, it is the highest honor, honestly, to be speaking with you today.
And thank you so much for coming on.
It's very gracious for you. Thank you.
Yeah. And, you know, your time is very valuable.
So, I do want to jump right into it.
And as we discussed over email, the primary focus of the conversation
will be on your free energy principle.
So, I think it will be awesome as it is discover.
Let's maybe set the table, so to speak.
Could you provide a high level, sort of simple description of the free energy principle?
And then I have a number of specifics to ask you about it.
Right. So, when confronted with that challenge, I normally say there are two ways you can
know description. So, there's a sort of intuitive low road approach, which I'll describe first.
And then there's the appreciation of the principle from them through the lens of a
physicist to understand self-organization.
But from the point of view of a psychologist or a neuroscientist, we're talking about a very
longstanding way of formulating our capacity to make sense of our world in terms of being able
to predict. So, these ideas go all the way back to Plato and probably Kantian in nature,
but probably best articulated by Helmholtz in the 19th century.
In the sense that perception is a constructive act.
It is, in the words of people like Richard Gregory, it is the brain actively constructing
explanations, hypotheses, fantasies for what might have caused my sensations.
So, this is very much, as Andy Clark would say, an inside-out process that you're creating a fantasy,
an explanation for what I would have seen if this was the right explanation.
And then you're using the actual sensations to correct, update, revise your internal hypothesis,
your internal fantasies. On that view, you could regard the brain as literally a fantastic organ.
It's a purveyor of fantasies that are trying to make sense of the lived world, or at least the
sensed world. And if you cast that in terms of inference mathematically, abductive reasoning,
and write down the rules that would have to obtain if we were in the game of inferring the
causes of our sensations, then you get to a formalism that can be described in terms of
optimizing a quantity called variational free energy. And this quantity is quite ubiquitous in
statistics and machine learning, also known as an evidence lower bound. And it simply scores the
surprise that is inherent in any sensory evidence or any sensation. And we use that surprise, if you
like, to revise our beliefs. And that mathematically can be written down as minimizing free energy.
So all that you can think of in terms of what constitutes a good brain, and possibly a good
mind, can thereby be described as trying to minimize free energy or minimizing surprise.
You can understand that in terms of the average surprise, which would be uncertainty.
So all of this is really saying, it's a mathematical statement, that self organizing
sentient system, look as if they are trying to minimize uncertainty, trying to find the most
the best guess, if you like, the best hypothesis for the causes of their sensation.
You can understand this in a very generalized sense. You don't have to think of it in terms
of sentience, you could understand this is just a kind of homeostasis.
Both your body and my body is in the same game of trying to minimize surprising deviations from
states of being. And we do so, certainly at the level of physiology, by trying to keep ourselves
within prior ranges of states, a temperature or blood sugar and the like, that would be very
surprising if we found ourselves outside those regimes under very, very cold or
in some kind of physical extremists. So that would be, if you like, a sort of biological
perspective of the energy, the physicist would come along and say, okay, there are certain,
or possibly quite remarkable systems in my universe that seem to restrict themselves to
certain characteristic states of being. They have a peculiar capacity to resist
the second law of thermodynamics, which I should say just applies to some closed systems, but
I think it's a useful concept here in relation to this notion of homeostasis.
So what characteristics must these systems possess in order to keep themselves within
characteristic states, technically, mathematically, of course, a pullback attractor,
is it just states of being that look as if they're attracting certain systems so that
they gather themselves up and keep themselves within these characteristic states. And it turns
out if you write down the equations for the dynamics of these kinds of systems, then you can
explain or you can describe these in terms of a variational principle of least action that just
says you're always trying to flow down gradients established by these surprises, these prediction
errors that's quantified by the free energy. And that's a really nice, or that has a very nice
interpretation. Because mathematically, this surprise is the negative of what statisticians
would call log evidence. It is a quantity that measures the goodness of your model,
of the negative of this goodness of your model, which is simply the probability of my sensations
given a model of how I think those sensations were generated. So this is exactly the same kind
of generative model you'd find in generative AI or say large language models and the like.
So that sort of gives you a theological gloss on this free energy minimizing process.
There's just a way of describing self-organizing systems that have this particular capacity
to organize themselves and resist this entropic dissipation on dissolution, decay and death.
And you can describe this as effectively looking as if they're trying to maximize the evidence
for their models of the world. So this can either be read as basically gathering evidence from my
own existence if I am a model of my lived world, also in philosophy by nicely denoted
self-evidencing. So it's a special kind of self-organization that can be read
as self-evidencing in the sense of gathering evidence from the way I think my world works
and how I operate within that world. So those would be two sort of perspectives on the same
phenomenon. Yeah, it's wonderful. Thank you. That's a great summation. And we're going to dive
into this and we're going to slice this up in many different ways. But one thing that I haven't
heard and I've listened to many of your podcast interviews and watched some of your presentations
and read your papers. What I haven't heard yet is what is the origin story of the free energy
principle? How did this all come together for you? I know you have a long history in the field,
but was there an aha moment or a eureka moment at some point? When did this kind of all start to
come together? What was the origin of this idea? Well, I think the first thing to say
in response to that question is that this idea has been around for, if not millennia, certainly centuries
and has been increasingly formalized and simplified. So there could be many starting
points to this story and each will have their precedent. So this is a legacy and a legacy of
what? Well, you could argue it's a legacy of ideas proposed by Helmholtz and refined by psychologists
like Richard Gregory, notions of analysis by synthesis and all sorts of the brain as a
constructive organ, statistical organ and trying to make sense of its world that you'll find in
the 20th century. Ideas which were taken up to great effect in machine learning by people like
Jeffrey Hinton and Peter Diane, they actually invented a Helmholtz machine that had this sort of
this Bayesian mechanics under the hood, borrowing from another legacy left by Richard Feynman,
which was the technical, resolving the technical differences of doing this kind of
this kind of inference, hence the variation of free energy that he brought to the table
in the context of quantum electrodynamics. Personally, it all started to make a lot more
sense when reading the work of people like Raj Rao and Dana Ballard. That story was a
predictive coding story, but it transpired that this was just another way of telling the same
story, but you are using a slightly different rhetoric. So the prediction errors in predictive
coding just are a measure of free energy under certain simplifying assumptions. But the key insight
in the late 90s was that exactly the same objective function could be used to describe
both perception in the spirit of predictive processing as championed by people like Andy
Clark and predictive coding, but also the learning, the updates to connection strengths
of the kind that you'd find in machine learning, but also you find natural intelligence and
experience dependency in the brain. The thing that I found particularly intriguing was that
if you just stood back and I repeat, so looked at this through the lens of a physicist,
you could also explain all of action through minimizing exactly the same quantity.
So bit by bit, everything that needed to be explained sort of fell into the camp of
it's just minimizing free energy. And everywhere you looked, everything could suddenly be very
simply explained in terms of minimizing free energy, attention, and even in the past few years,
your natural selection is just another free energy minimizing process. So this is,
I haven't really answered your question in this period which we've asked because
there was no one moment. But every few years, I certainly get a nice aha, oh, it's just another
instance of minimizing free energy. And then you write a paper usually using numerical simulations
with a bit of analysis to say, well, this is another way of looking at it. And it looks very
much like this kind of thing. Because it's all, if you like, a reflection of the same fundamental
process of self-organization. Can you give us a sense of, I guess, the scope of this discovery?
So as far as I understand it, it explains, you know, process of dynamic happening in the brain,
which is the most complex object that we know of in the universe. What is the simplest scale?
What is the smallest, say, dynamic or thing that would adhere to this principle? Does that make
sense? Like, basically, what is this principle start? Yeah. Yeah, no, I just wanted to interrupt
to congratulate you on the question because that's the second focus of many colleagues
in vertical biology and physics. So I'm thinking here, people like Mike Levin and Chris Fields
and Jim Glazebrook. So that is, that's absolutely key, I think, that notion. It does this apply
to a particular thing? Or does it apply to everything? And if it applies to everything,
what scale does it apply? And does it apply at every scale? And the answer should be,
it's scale invariant, and it applies to everything, literally. And that sort of
perspective is being championed, I repeat, by my colleagues, Mike, Jim, and Chris,
in the context of quantum information theory, on the one side, on the point of view of physics.
But on the other side, there's this story, which I think is very nicely articulated by Chris Fields,
it is time to remove the bright lines between physics, biology and psychology. They're all
just the same thing. And you get this notion of basal cognition, which is something I think Mike
Levin has brought to the table, that all self-organization can be read as this kind of basic
sentence, this sort of basal cognition, that is just a reflection of the existence of things.
And this may sound a little bit like an overstatement, but the interpretation
of self-organization, in terms of the interpretation of self-organization as self-evident thing,
is a relatively straightforward consequence of the individuation of anything from the rest
of the universe. And this separation appeals to what is now a little literature on Markov
Blankets, in this particular context. So the Markov Blanket is just a definition of
thingness, where you start with the notion, okay, I want to explain the states of something.
And then you ask, well, what's a thing? Now, maybe you have to appeal to
scrolling and formulation of boundaries. Can you explain what goes on within the boundaries
of living things? And of course, as soon as you say that, you realize it's the boundary that's
the important structure that allows you to individuate something from everything else or no thing.
And indeed, if you just then look back with that view on what you learned at school,
in terms of physics, you suddenly realize how important that boundary is,
let's say the heat path in physics, for example. So wherever you look, there's this crucial notion
of a separation, an individuation, and simply by thinking carefully and articulating formally
how you would define that boundary. There is, if you like, a partial separation from
states on the inside of something and states on the outside of something.
But there's a two-way traffic across this blanket or this boundary, this Markov boundary.
