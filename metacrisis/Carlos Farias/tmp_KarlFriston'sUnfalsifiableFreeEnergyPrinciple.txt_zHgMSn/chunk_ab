And this two-way traffic enables you now to describe the internal dynamics or dynamics on the
inside as holding beliefs about probabilistic subpersonal beliefs about the outside. And it is
that that enables you then to assign this free energy functional to belief structures in the brain.
And you can do this for anything. You can do this for a droplet of oil. You can do it for a virus.
You can do it for a person. You can do it. In fact, I've just signed off on a wonderful paper
by my colleagues, Saugir and Lanceter Costa, where they've actually applied it to the biosphere.
So the same maths unfolds. Once you've identified the separation of something from anything else,
you just apply this mechanics as Bayesian mechanics. And then you can interpret the
self-organisation in terms of sense-making and self-evidencing and an implicit or a description
of that sense-making in terms of belief updating by minimising this surprise or maximising this
Bayesian model evidence. So it can be applied to single cells or it can be applied to the biosphere.
So it should apply to everything. And Saugir, that's what Chris Fields would say,
at what level of analysis then it comes to quantum information theoretic applications of the emission.
Yeah, that's fascinating. I'm familiar with Chris Fields' work. I've read some of his research
and actually spoke with Michael Levin a few weeks ago. I interviewed him. Yeah, we actually covered,
I mean, in great detail, one of his papers, I think it was 2019 paper called the Computational
Boundary of the Self. I don't know if you happen to see that, but he has this visual cognitive
light cones, sort of the boundary, the assumed boundary of nested cells, let's say, all going
all the way down to the cell. Say the cell, then you have ants, then ant colony, and it sort of,
he brings up just fascinating ideas around collective intelligence. All intelligence is
being collective and stuff like that. So yeah, a little bit, those things I'm quite a little
bit familiar with. So it's great that you could call them out. Can you define, one thing would be
great to get some definitions down. Can you define free energy? So I believe in a thermodynamic sense,
it's the amount of available energy for a system to do work, because a simpler, perhaps one of the
simpler definitions for it, is that applied in the same way in your free energy principle?
Yeah, again, an excellent question. Yes and no. So the functional form of the variational free energy,
and that's why I tend to say the variational free energy, so that we do not misinterpret it as a
thermodynamic free energy. The functional forms are identical, and they inherit from the same kind
of physics and probability institute dynamics. However, thermodynamic free energy is, I think,
a very particular application of this kind of mechanics to certain systems. So it is, you know,
I think, from the point of view of, you know, so somebody is not a physicist, I think it's
important to say that the variational free energy is an information theoretic measure. It has no
commitments to joules or Boltzmann's constants or anything of that nature. So it's very much like
a statistical measure, like you're a variance or an average or an entropy. So the free energy has
a free energy is just defined effectively in terms of a relative entropy, or sometimes known as a
KL divergence, and a constraint or an internal energy. So the variational free energy is talking
about probability distributions, it's talking about information, and crucially it's talking about
information about things. And then we come back to the central foundations of the Markov blanket,
and separating the inside from the outside. So the whole point of the free energy principle
is that you can interpret the inside states as holding information or probabilistic beliefs
about outside states. So this is, if you like, something quite fundamentally different from
Shannon information on the surprise of finding the brain in this state. So the brain will have
two kinds of free energy, it'll have a variational free energy, which is a comment about its goodness
of fit or its beliefs about what's going on outside, which a statistician would understand,
but it will also have a dynamic free energy in terms of the actual metabolism and electrochemical
signalling, and the metabolic states of the world that requires a further commitment to, I repeat,
sort of interpreting certain quantities, you know, for the amplitude of random fluctuations in terms
of thermal constructs, and applying things like Boltzmann's constant to it. So there is a difference,
you know, between the two. Having said that, I think that difference is specious on two counts.
First of all, you know, taking again a Feynman-esque point of view, information is energy and energy
is information. And at the level of analysis that we're talking about, you know, a thermodynamic
interpretation is just another interpretation. You don't need to start self-organization
if you wanted to talk to a sort of business system, the 19th or 20th century will be useful,
but it's not necessary. Another, the other point is if you did talk to that kind of thermodynamic
person, then you would find that there is a, that these free energies share the same minimum.
There is a necessary thermodynamic cost to any variational free energy minimization or
belief updating by things like that was principle. So there is a physics which really binds these
two things together. The final point of contact, or perhaps the final, you know, some of your
more technical viewers, the free energy principle that we're talking about can be
regarded as dual to James's maximum entropy principle. So James's maximum entropy principle
basically says that the universe or anything in the game of measuring anything else
will conform to the principle of a maximum entropy and the constraints. And those constraints
are what are supplied by the generative model that generates the predictions that are necessary to
provide the surprise. So the surprise part, the internal energy part of the free energy principle
is that which rests upon or is defined in terms of our world models, our generative models.
So we come back to this notion of what is a free energy? Well, it's an internal energy
minus an entropy. So where you want to minimize your free energy, you're going to maximize your
entropy in a chord which changes its maximum entropy principle, but under constraints that
you're trying to minimize the internal energy. And that internal energy just is a surprise that
we were talking about before. So on that view, I think there's a deep connection between
a certain kind of free energy in physics, but it would have to be a Jamesian kind of free energy.
What is the kind of free energy you did at school when you boiled in water, like?
Sure, yes. Okay, it's so interesting. And actually, you bring up William James' maximum entropy
principle, something that I learned about listening to one of your lectures, because I believe you
said, I think it's a quote, if I have no preferences at all, then my best bet is to keep options open.
So it's a bit of, so that's like the non-technical kind of layman's way to look at it,
which I hadn't thought of before. And I was actually thinking, and it's one of the questions that I
have for you, and it's something that I think is really interesting about this principle is that,
please correct me if I'm wrong or fill in here, the preferences are built into the
Bayesian beliefs. Is that correct? Yes, you've immediately gone into a much more glorious world
of preferences and purpose and plan of intentions. Yeah, I'm sorry, we can go there later if you
want, because it's a great place to be. But just at the moment, we've just been talking about
self-organization, self-evidencing, but what you've done is really speak to the active part of this.
So you're just to set the scene. When you look at certain kinds of systems, and specifically
systems that have very precise internal dynamics, so the random fluctuations are suppressed, or at
least at the scale of observation that you might want to apply, that all the random fluctuations
are averaged away. But these kinds of systems, basically systems like you and me, but not
systems that are very, very small and very, very hot thermodynamically, that would have
lots of random fluctuations. But if you get a big enough system like you and me,
then it is the case that the solution or the variational principles that have to be in play
in order for this separation to persist, separation of self from non-self to be in play,
and you apply it to the way that you act upon the world, then you can describe this in terms of
minimizing the free energy that you would expect if you pursued this course of action.
It's at that point, I think you get notions of preferences and how you could interpret
this expected surprise. Very much as we said before, the one way of reading expected surprise
just is in terms of entropy. But there's another way of avoiding surprises, which is just to avoid
surprising outcomes, which means complying with the constraints that were implicit in
James's constraint maximum principle. The complement of avoiding surprising outcomes
is that it looks as if I am always acting in a way that convinces preferred outcomes,
outcomes that just are the characteristic states that define the kind of states that you'd find
the inner. I think you're absolutely right that these prior preferences are just a way of articulating
the typical or characteristic states that define who I am. You can either put a teleology on that
and say, oh, this thing is behaving as if it prefers to be in these states. It's actively
choosing these causes of action, these paths into the future. The result that those consequences
are that you end up in your preferred states. On the physicist's point of view,
you start off with a system that seems to be able to occupy these preferred characteristic states
and then you work out what dynamics must these systems have. That's the deflation part of the
free energy principle. It's just a description of things that have preferred states effectively,
and these preferred states are literally the attracting set that constitutes the pullback
attractor that was mentioned before. You're absolutely right in one sense that these
preferences are part of Bayesian beliefs, but that does, if you like, commit you to a
rather teleological interpretation of the energy principle. You don't have to do that.
You can't do that. You don't have to do that. Please forgive my ignorance here, because I might
shrug my hand a little bit here, but is the brain trying to minimize free energy
because it's trying to use as much of it as possible? I know it's trying to minimize surprise
uncertainty, but I imagine something like a resourceful, greedy brain. Is the minimization
of free energy sort of like the byproduct? Is this a downstream effect, or is it the real pump
that's moving the water along? Does that make sense? It makes sense. In a sense, it's exactly the
question which I try to intimate. There are two completely contradictory answers to, so if you're
talking to a physicist, I know there's no sort of pump here. There's no aspirations to deploy my
free energy in the most efficient way. It's just that's what systems do. Systems just settle down
to a free energy minimum. That's another way. Those systems that settle down to an attractor
set them to their free energy minimum, that is their definitional attribute, the stipulation,
that is what things are. So it is no surprise that when you describe their dynamics, they'll
look as if they're trying to minimize their free energy, because that's what defines them.
But if you now talk to a biologist or a psychologist, then your description is perfectly
out. It will look as if these systems, particularly systems like you and me,
are actively trying to minimize a surprise in a resourceful way. I would actually frame that more
in terms of in a very efficient way. So if you go to Wikipedia and you say, well, free energy is
the amount of energy available to do work, I mean, that's a thermodynamic interpretation.
I don't think it's quite necessary to put that out of all the size things in quite a
but it certainly, I think, would be
you would be perfectly licensed just to interpret various parts or decompose
variation of free energy. And as for what would it look like if we just focused on this particular
part or that particular part? I think one really interesting decomposition of
variation of free energy is that which a statistician would usually appeal to. And that's
basically accuracy minus complexity, where accuracy is effectively how accurate your
predictions of the world are, how good is your explanation of these sensory data, or if you're
a statistician, sort of your empirical data that they're trying to make sense of.
The other thing, the complexity, I think, is even more interesting. So in the same way you were
talking about before, keeping your options open and maximizing your entropy in accord with James's
maximum entropy principle, the same sort of Occam's like principle emerges in terms of this
complexity term. So the complexity is just a way of lumping together part of the internal energy
with the entropy to give you this relative entropy or this KL divergence. And then to put
this very simply, what it measures is effectively the degree to which some sensory data or some
sensations or some sensory evidence changes your mind. So if you're trying to describe this as a
statistician, this is the degree to which you move from your state of privilies to your state of
posterior beliefs. So it's degrees of freedom you're using up in terms of providing an accurate
account of your data. And it is this that is minimized. Remember, free energy equals accuracy
minus complexity. So, well, actually it's going to be around negative free energy is equal to
accuracy minus complexity. So as you're minimizing the free energy, you're also, you're trying to
maximize the accuracy, but at the same time you minimize the complexity. So this is where
I think you get what you're alluding to. You're trying to accurately navigate the world
in the most efficient way possible using up the least resources. But why do I say resource as well?
Because of this link between the information and energy, you're afforded by things like
the Jinsky equality and the Handao's principle. It costs energy to change your mind. It costs energy
to create and well, to destroy information. So that complexity is also a cost. Technically,
it's also an information game, but it's also a complexity cost. So what it looks as if
a brain of this kind would be in the game of updating itself, changing its biophysical
state in a way to make predictions that are as accurate as possible, whilst at the same time
complying with complexity constraints. So do it in the most parsimonious way that it can. So hence
Occam's principle. So that would also translate into the most energetically efficient way of
making sense of the world. And if you sort of unpack that principle in terms of computation
in silico, then what that tells you is that the good computers are those computers that work on
the edge very cheaply with small amounts of electricity. They're doing it very in the simplest
way possible with a cool head, literally. So these are really interpretations of, if you like,
unpacking the terms that go into a variational free energy and making sense of them. And I think
that's exactly what should be done. It's a wonderful game. And you could also repeat that
game in terms of the expected free energy. So now you have expected accuracy and expected complexity.
And when you look at the functional forms of these terms, you suddenly see things that people have
been dealing with and optimizing for nearly a century. So for example, the expected accuracy
or the negative expected accuracy is just the ambiguity or the negative precision
that would be used to explain an efficient sampling of the world of the kind that you might find in
the visual cortex and the organization of the visual brain. The expected complexity becomes risk
of the kind you'd find in economics. It is basically the distance I move from my prior beliefs
if I pursued this course of action. And of course, we've just said that the prior beliefs
about the consequences of action are our preferences. They describe our attracting
set of preferred states. So now the expected complexity, the risk, is just scoring the degree
to which I expect to be displaced from my third states of being probabilistically speaking.
We just measure that with the KL divergence on the relative entropy. So that's, you know, that's
bread and butter for many economists. Another way of, if you're like unpacking or rearranging the
terms is in terms of what is referred to as expected information gain and expected cost. So
those two components are exactly those things that you find in the two aspects of being base
optimal. So there are two ways of being base optimal. One way is to minimize your expected cost
or maximize your expected utility or valuable log preferences. And that's the kind of base
option you'd find in Bayesian decision theory. And you can look at that as grandfathering things
like reinforcement learning and utility theory. On the other hand, though, you've got this sort of
again, this sort of, it's not ambiguity, it's ambiguity with bells on, which is the expected
information gain. And that was exactly the objective function devised at the inception
of the principles of optimum Bayesian design. So if you have the problem of designing an experiment
that's going to yield some data, and you now ask yourself the question, what's the best kind of
experiment I could possibly design that will give me the kind of information that's going to resolve
the most uncertainty about hypothesis? What's going to maximize the expected information gain?
And it is exactly that quantity, that part, that epistemic value, this measure of the resolution
of uncertainty that defines Bayes' optimality in the context of experimental design.
That may seem a little bit sort of unconnected to you and me in conversation or just walking down
the road. But of course, we are experiment, we are actively experimenting all the time,
just by looking around. The way that we move our eyes, the category every 250 milliseconds,
every little act of this kind is an experiment. So we come back now to the notion of Richard
Gregory, that perception just is hypothesis testing. What's the experimentation? It's just
