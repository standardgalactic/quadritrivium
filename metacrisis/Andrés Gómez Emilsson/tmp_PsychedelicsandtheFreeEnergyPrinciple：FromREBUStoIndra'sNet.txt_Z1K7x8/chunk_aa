Hello everybody! So today we're going to talk about the free energy principle and how it relates to psychedelics, which is a very, very exciting topic.
There's a lot of excitement, I think, in the academic community about this topic. I've got to say, I'm going to present three completely new ideas.
Well, two of them have been talked about in various QRI articles, as well as videos. There's one completely new one, but in either case, these ideas are not being talked about in the academic literature.
We intend to publish them and run simulations, but in the meantime, it's just very exciting these new perspectives on how psychedelics and the free energy principle relate to each other.
And as kind of the north star of this conversation, we will have basically the goal of explaining Indra's net in terms of the free energy principle, which I think it's actually possible.
So let's get to it.
So first, the quality of the day is Indra's net. So it is said in various Eastern philosophies that Indra, this very powerful god, basically has this net hanging on the ceiling in one of the palaces in the realms of the gods.
And each of the nodes of the net is a multidimensional gem, this beautiful, beautiful gem. And the net is infinite. It's completely infinite.
And what happens is that each of those gems will contain a reflection, a tiny reflection of every other gem.
And then within the reflection of every other gem, you will find an even tinier reflection of every other gem and so on at infinitum.
Of course, if this was physically realized, it would be a limit because photons are quantized ultimately.
So there's not going to be like infinite resolution when you observe it and you try to find the world in a grain of sand, so to speak.
But yeah, it's a very interesting and powerful metaphor and it's used methodologically to kind of talk about the interdependence on everything else, kind of in Buddhism and even Hinduism.
And that's a powerful kind of vision. Imagine if you assume that that's the case, that everything in the world actually stands in kind of an Indra-net relationship to everything else.
And everything implies each other, even like a piece of trash or a piece of, I don't know, this foam, I don't know, it was a random thing that came in a package of essential oils.
Like this is interdependent with absolutely everything else and more so, you know, this is the final product of its backwards light cone, which contains such a huge amount of cosmic background radiation.
Well, everything is interdependent with everything else. Now, that's kind of a mind-blowing idea, but what's the use of it?
And, you know, recently there's kind of this fascinating Dharma teacher, Robert Bourbier. I've been consuming a lot of his lectures.
He has this book called Seeing That Freeze and one of the things that he talks about is how, in a sense, you can interpret insight practice as opposed to, for example, like concentration practice or morality practice, you know, just insight practice in the Buddhist meditation
as basically ways of seeing the world that reduce suffering, that diminish the dukkha, the unpleasant qualities of experience.
So, for example, like being hyper-aware or like being in the moment or perceiving things as like empty of inherent existence.
When you apply those ways of seeing to even like, you know, unpleasant low-level body sensations for a number of people in a number of circumstances, it can have a great reduction in their suffering.
Now, it doesn't always work and it's really interesting to see, like, why does it work and under what circumstances does it work?
But as kind of like as a general frame, I really like it. You know, it's very, very pragmatic. It's kind of like, oh, these deep quote-unquote esoteric views of the world, you know, interdependence and, you know, dependent origination and emptiness and all of that stuff.
Ultimately, you know, they're not necessarily useful because they're fundamentally true. Maybe, you know, as Buddha might say, like, it's unknowable, ultimately.
But internalizing those ways of seeing the world and your experience lessens the suffering, allows you to kind of like drop a lot of baggage that carries around and causes dissonance internally and kind of like cleans your experience.
And I think a powerful experience of Indra's Web, well, it actually depends on how you interpret them because there's also kind of a spiritual materialism risk of it.
Like, if you experience like a mind-blowing like meditation or LSD state of, you know, everything reflecting everything else and you think like, oh, my gosh, I'm enlightened and like I'm one with everything and like, kind of like now maybe you have even more baggage because you kind of have like this self-conception that arose out of that.
But there's also, you know, kind of the flip side, which is like maybe actually understanding the dependence of everything with everything else, allows you to lessen the amount of fabrications that you essentially engage with, especially mindless fabrications.
Because in a sense, you recognize their empty essence and their co-arising with everything else. And in a sense, you can treat them by modifying the conditions to give rise to them.
Anyway, so Indra's Web, not only is it a mind-blowing experience, it's also potentially like very pragmatically useful in that it might lessen your suffering to some extent.
Now, importantly too, I think it is very valuable to study as an experience itself. And, you know, like different experiences have like different degrees of like how much they are like Indra's net.
Now, because, you know, at QRI we essentially assume indirect realism about perception. Basically, yeah, when you're having like an experience of Indra's Web, I don't think you're literally, you know, contacting the rest of the cosmos and seeing how everything reflects everything else.
But I think what's going on is you're instantiating a state of consciousness that essentially has this fascinating property that every part of that state of consciousness in some tricky but non-trivial and very real sense is actually reflecting every other part of the experience.
And that is what I will explain with a free energy principle. So exciting, isn't it?
I should also remark that because of the symmetry theory of valence, I mean, most of the Indra's net kind of experiences tend to be pretty fractal and like highly detailed, but above all, very constant and very symmetrical.
So they tend to be extremely blissful. So again, a lot of people may experience Indra's net and kind of like be fascinated by it, but not recognizing where the valence comes from.
You know, the main thing that the valence comes from literally becoming embedded into the fabric of reality.
But, you know, that's kind of a tyranny of the intentional object. It's kind of like, in a sense, it's like reading too much into the intentional content of the experience, I would say.
Rather, what I would kind of advise you to do is to pay attention to the way in which those patterns are either consonant or dissonant with one another.
And the claim is that, you know, blissful Indra's net experiences, for the most part, will basically be hyperharmonious.
There's going to be hyper harmony. They're going to be minimizing dissonance in a very, very deep way. So that's the quality of the day.
Highly recommended. You can get it with meditation. It's very common on DMT, as we'll talk about.
And it may be freeing in some deep sense that I think is very valuable.
Okay, so now let's get on to the topic of the day, which is the free energy principle more concretely.
And there's a couple of things to say, you know, I mean, first of all, like Carl Friston's free energy principle and predictive coding as a paradigm,
which are slightly different things and the free energy principle can derive the predictive coding and maybe not the other way around, but they're very interrelated.
And they're part of the lineages of QRI. So basically we have now 10 lineages that basically withdraw a lot of inspiration and theoretical frameworks from lenses that we use to understand the world.
And we also have our own lenses, for example, neural annealing and the symmetry theory of valence and a bunch of other stuff, like the tyranny of the intentional object and so on, which are ours.
I mean, we've been developing them for the last, I don't know, seven years or so, it's been a big effort.
And hopefully we will actually be able to, you know, present all of that in a very formal fashion, all of those developments with their predictions and testing those predictions and so on.
But yeah, I mean, QRI doesn't exist in a vacuum. It very much exists in the context that these other lineages generate and a very important lineage.
They're all very important. So one of those lineages is a free energy principle. So it's very important for QRI.
I would also mention that, you know, Quentin Freerich, you know, the lead engineer at QRI, actually presented about neural annealing to Carl Friesen and his lab.
And, you know, we got a lot of really interesting feedback, mostly extremely positive feedback, very encouraging.
And basically they were suggesting that we publish a particular version of what we were working on.
And so that is, you know, in the works and I'm very excited about that.
Okay, so let's get into the actual content of it.
Okay, so the free energy principle is one of those kind of like really high level, cool ideas that in a sense, as you munch on it, you start to see it everywhere.
And I would compare it with like a couple other kind of things in that kind of category or like very high level interpretations of reality that make you interpret everything.
Kind of like gives you a completely new lens on reality.
One of them, for example, is evolution, you know, this idea that whenever you have reproduction with selection and variation, you will have basically the ingredients for evolution.
Now, that is a fascinating, you know, clever idea, kind of like synthesizing evolution to just those three principles.
And when you have those three principles, you will start seeing evolution everywhere.
You know, not only biological evolution, but like all over the place, you know, in Conway's Game of Life, in fundamental particles, it will show up everywhere.
But you can maybe even distill it further.
You know, you can say like, well, that's maybe a special case of something more deep.
So what could be that thing that is kind of like even deeper?
Well, maybe it is the survival of the stable.
And the survival of the stable is kind of this meta principle, right?
That like from it, you can essentially derive, you know, the three principles of evolution.
And it's kind of like a deeper, deeper truth, you know, that like, yes, sure, there's like biological organisms and all that.
But, you know, if a rock is really stable, you know, it will be here, it will be around.
Like if it has like mechanisms to continue to exist, you know, that's what exists.
What exists is what is good at being stable in some, in some way.
You know, something could be very variable, it could be a dynamic system, but maybe construed as the state space of the entire system.
That is a very stable construct, you know, and I would say that, yeah, biological organisms are like that.
They're very dynamic, but in some sense they do carry some stable kind of a metadata.
And that is what is actually, you know, is immortal.
You know, our genes are immortal over the generations, even if the individual isn't.
You know, and in that sense, survival of the stable is kind of a meta principle.
I would also say, you know, you know, Bayesian epistemology is like maybe one of these like pretty, pretty high level concepts that allows it to reinterpret so many things.
That like, for example, like once you understand that, hey, the brain is receiving information from its environment in a time series fashion.
I mean, there's massive parallelism, but there's also time, you know, we're embedded in time.
So the information that we get is that happens over time.
It's time series.
And whenever you have kind of like that data structure and you're trying to minimize, you know, prediction errors, it follows from math that you're going to be doing Bayesian inference.
And there's no way around it.
I mean, that's just a hard constraint.
And it doesn't matter if the brain is made of like neurons or, you know, it's made of like honey and bees.
Or, you know, if it's made of the population of China or whatnot, like if it's making accurate predictions about time series data structures, it is going to be, you know, making Bayesian inference.
You know, that's just a super hard constraint.
Now, Bayesian inference is something that lives at the computational level.
You still need to dig deeper into the algorithmic and that implementation level.
As I've talked about in other videos, go to the digital, digital sentence video for a deep discussion about this.
But yeah, in a sense, computational level doesn't really tell you the full story, but it is a constraint.
You know, it's kind of a boundary condition up on which everything else has to be fit.
And for sure, you know, nervous systems do Bayesian inference.
Period.
You know, that's, that's a hard constraint.
They have to be.
Otherwise, they wouldn't actually be able to make accurate predictions.
Now, the free energy principle, some could even think kind of brings together all of these high level paradigms, maybe into like an even bigger, higher level paradigm, which is, which is crazy.
And, you know, at QRI, we have a lot of respect in general for thinkers who are what Mike calls one true ontologists, you know, who kind of like take one principle
or one set of ideas and try to basically apply it to all of reality and see how far that goes.
And okay, maybe it doesn't apply to all of reality, but in the process of trying to apply it everywhere, you discover a lot of things.
And you may be able to massively compress a lot of, you know, crazy, highly detailed information reality with just one principle.
And the free energy principle may do that.
So briefly stated, and I'll go into like more detail.
Essentially, it says that any dynamic system that is actually capable of surviving is actually able to sustain itself must be able to, in a sense, minimize the entropy is receiving from its environment.
Right.
You have like a little cat.
And if it's kind of just always going towards, you know, the absolutely most chaotic environments possible, it's going to die.
You know, like it's going to go to the oven or it's gonna go, I don't know, bad images.
But the point is that like, if you're like maximizing chaos, that chaos is going to eat you.
Yeah.
So basically it's going to shake you apart.
So systems that actually do survive, that actually are stable, as I was talking about a skin is like this generator for the theory of evolution are basically those that are able to minimize the amount of entropy, unexpected entropy that the environment basically imposes on them.
And from that, through a chain of inferences, you can arrive at the implication that dynamic systems that survive in the universe have to, on some level, have an internal model or representation of their environment, such that they can anticipate what is going to happen to them,
given the particular input that they are receiving, and basically avoid states of very high entropy as a consequence.
So it's kind of crazy, right?
Like the thing is like this may apply to a lot of like systems that are, you know, counterintuitive.
Like, you know, one thing is, is the brain where like, okay, we kind of intuitively, intuitively understand that yes, we do have kind of any inner model of the environment.
But this may also apply to other things like, you know, like a whirl on water, or, or like a tornado, or like other other dynamic systems like that, you know, convection currents and things like that that like, implicitly, you know, maybe not explicitly, I'm not
saying that convention currents actually contain kind of like a picture of their environment inside them.
But implicitly, they must be doing some, some level of computational processing that is in a sense, making them maximally adapted to their environment.
And now there's like kind of various schools within, you know, the free energy principal literature of like, okay, are the representations explicit or implicit and like maybe that depends on the particular system that we're talking about.
And you know, I think, I think like most people would generally agree that like, at least the brain is making explicit representations.
So it's not, you know, we're not just convection currents, like there's something more explicitly computational going on.
But at the same time, it must be satisfying kind of this principle that if it's going to survive, it has to actually be able to predict this environment.
Now, the actual term of free energy is an information theoretic construct.
So it's not a physical construct, it's an information theoretical construct that bounds evidence for a model of data.
So here's the thing, like, if you had complete information about the world and the inner latent states, basically the latent parameters that give rise to what's happening in the world.
You could in a sense like compute how surprising a particular set of input is.
And in that sense, like, we would actually be talking about the surprise minimization principle as opposed to the free energy principle.
So why are we talking about the free energy principle instead? And what is this free energy?
Well, it's an information theoretical construct. It's not free, it's not energy in the physical sense.
Although, as I'll mention in a moment, there might be an isomorphism in some circumstances.
But free energy appears basically in machine learning and statistics.
You know, I have like this book, for example, of deep learning and, you know, in page 625, you have this definition of variational free energy,
which is essentially the point is that, yeah, I think like here is the variational free energy.
And essentially the point is that this provides an upper bound to how surprising the stimuli is, given your generative model of the world.
I know these are a lot of words and, you know, to do justice to this topic, it would take many hours and actually a detailed presentation with definitions and all the math in there.
But what you have to know right now is that, you know, the variational free energy is an upper bound on the true surprise that a particular stimuli is generating.
And surprise here means that basically the model says that these are very unlikely events.
So this information theory construct, like the negative of the log surprise, basically provides kind of this total surprise of the stimuli.
And that is what you should be minimizing. You don't have access to that. It's intractable.
So instead what you can do is try to minimize free energy, which is an upper bound that is tractable and is computable.
And it's essentially something that, yeah, in machine learning is used routinely to basically optimize inferential learning in probabilistic graphical models.
Again, apologies for all of the jargon. What you have to get is that this is a clever and tractable way of minimizing how surprising the stimuli are from the environment.
There's a couple of things to mention here is like, okay, if somebody might claim that if you're minimizing surprise, why don't you just go to a dark room?
That's kind of the code code dark room interpretation.
Well, yeah, because, you know, if you're in a dark room, everything is infinitely predictable, you know, like, you know exactly what you're going to be getting.
And that in principle should, you know, make you feel great because you're minimizing the prediction errors that you're getting.
Well, not quite, because actually the model that we have of the world is dynamic.
And the things that are expected in that model are sequences of events.
So actually there's no kind of like, you know, local maxima that is kind of like, oh, you know, these homogeneous perfectly, you know, symmetrical state is like, you know, maximally expected, you know, because your model actually goes against it.
It actually says no, like that would be very unexpected.
You know, you don't expect to wake up in the morning and just see nothing and have no sensor input.
That's an incredibly surprising state, right?
So actually going into dark room and becoming super thirsty and not eating and so on, that's a drastically increases your surprise and your free energy.
So actually in a sense like minimizing free energy doesn't tell kind of like doing a lot of very, very simple, cotidian, like normal everyday things that in a sense restrict the range of states that you find in because and that's an important implication too.
You're trying to minimize the entropy of the density of states that you can you can inhabit internally, because that in a sense will maximize your chances of continuing to exist, existing definitely.
And, and yeah, I mean, as a consequence, yes, if you all of a sudden started find yourself in a dark room, maybe on a low level, you could think that's, you know, very, very, there's no prediction errors because it's constant.
At the same time, you will be making the inference that you're probably in huge danger.
So in that sense, yes, actually, it doesn't minimize free energy.
The other fascinating thing about this is active inference that in a sense there's two ways in which you can minimize the free energy.
A, you can change your model.
You know, if you're getting something very, very surprising, in order to minimize the free energy that that is generating, you can change your model.
Such that what you're experiencing now becomes less surprising.
And that's one way.
But we also require basically a balance between the accuracy and the complexity of the model because you shouldn't overfeed.
So basically, there's only so far you basically a free energy minimizing system will be willing to, in a sense, adjust its model to the immediate, immediate information.
Because it's also taking into account all of the previous information.
And like, you know, that shouldn't be discarded.
If it's actually an embodied entity is going to survive, you know, new information could be garbage.
So that you really can't update too heavily on it.
And also that gives, you know, brings us to the topic of the precision on the high level priors of the model, which is that, yes, I mean, like, very surprising things may not actually be warrant.
You know, deeply updating the model precisely because you have way too much evidence in the past that like, yeah, most likely maybe the input that you're getting is like spurious or something.
And you can maybe as a constant, you know, spin up an additional model that is about like, okay, what is the probability that data is noisy or faulty.
And like, then you start to model under what circumstances data becomes faulty.
And that becomes the way in which you minimize free energy, not just instantly updating your model.
And the other thing, though, is that it will be the other way of minimizing free energy is to actually act on the world, such that you actually make the inputs later on more expected.
So that's kind of like, yeah, basically, you're like close to a hot stub or like, you know, I don't know, like a very, very chaotic bar where there's like about to, you know, a bar fight is about to be to break.
There's a bunch of drunk people. It's very chaotic. You know, one that's going to generate a ton of, you know, free energy for you, for you to minimize it to something you can do is kind of like start walking and getting out of the bar.
And you will be outside. It's going to be a way more predictable environment. So there you go, you know, like action onwards, you know, that can also be a method to to reduce the free energy.
And so in the end, what you get with this theory is kind of this beautiful interpretation of, you know, dynamic systems that survive, including humans, that they will be kind of like in a in a balanced way, modifying their internal models
and also acting on the world so that there's fewer prediction errors and that as a consequence, you know, what we are doing right now is kind of doing that implicitly on some level, you know.
Another thing to mention is this concept of the Markov blanket, which is basically in probabilistic graphical models. You should look that up if you're curious.
Basically, you can define this notion of a barrier between an inside and an outside, which is basically for a given set of nodes, you can look at all of the nodes that in a sense, if you were to, to kind of like fix them, they would in a sense
like lock in the information that the internal nodes can get from their environment. In a way, it's kind of like the Markov blanket is the outer shell of a particular set of probabilistic graphical models nodes.
And in that sense, they generate an inside and an outside. And what the free energy principle will entail is that whenever you have a Markov blanket, and you know, those are the needs modeling a dynamic system, it will be the case that the free energy principle
will apply for that Markov blanket. And, you know, in actual something like, you know, Bayesian predictive coding models, where you have a hierarchy of kind of like models that go from very low kind of like sensory data to like very high level
kind of like notions of the self and so on, that in a sense, there's going to be this kind of quasi concentric shells configuration, where each of the kind of layers is going to try to predict and anticipate and modify the one right underneath.
And in a sense, the process of model building and world building of creating the the world simulation that you inhabit in this paradigm is what arises out of the kind of like tug tug of war or competition between all of these various shells trying to predict each other.
And the end result of that is a hierarchical model that in a sense encodes information about the world in a more and more refined way and more and more abstract way as you go go in.
Now, of course, there's a huge debate on like whether a model like that actually fits what happened, you know, what's going on in the brain. Of course, there's like some degree to which you can model the layers of the cortex, for example, in kind of like this hierarchical way, you know, for V and then like V1 V2 and so on.
At the same time, the brain is like really interconnected, you know, and there's like connections between layer one and layer five and and it's kind of like very, very mixed up in a sense.
So identifying the mark of blankets of the neural networks of the brain is not as easy as kind of like just dividing into layers. There's more complication to it.
And also, you know, down the line, you know, at QRI, we actually, you know, believe that consciousness is a holistic field behavior, rather is a utilized as holistic field behavior and that's the reason why it was selected by natural selection and recruited by natural selection for computation.
