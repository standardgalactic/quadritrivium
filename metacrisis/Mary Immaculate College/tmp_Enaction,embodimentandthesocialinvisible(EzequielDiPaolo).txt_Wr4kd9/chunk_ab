and life is precisely the sustainance of an entity that is not material in itself. It's
formal and dynamic. And that puts Hans Jonas in a position to start making an argument
that therefore the relations that this system has with the world are relations of, you may
call it, of interest, of concern. That it's better to get, you know, over here where there
is protection, than to go over there where there is danger. Because I'm trying to conserve
myself. It's better to get some nutrients than to get some poison into your body. Because
I am this particular form of self-conserving identity that needs this sort of food and
so on. So that's the rough philosophical argument. And the question is for the inactive approach
to try to take that into, and make it into a piece of science. And see, can we express
it scientifically? So the idea is that there have been attempts to do this, using the notion
of auto-poeses, which you've heard about and many of you already know about, which tells
the story of the defining features of a living organism being its continuation of self-production.
So you have a network of molecular components that constitute a bounded system. And the
bounded system is what allows those chemical reactions to continue, while the system is
receiving inputs and output and waste products into the environment.
So the typical example of auto-poeses is a cell, where you can draw all these arrows
and say like, look, these things depend on this. I'm going to come back to this. And
therefore there is a kind of a closed organization, not a closed system, but a closed organization
of the system. And you can see similar forms of closed organization at other levels. And
we spoke of the immune system, but I think it was over there. That's one possibility.
The nervous system also, if you see it as a network of relations of changes of activity
between neurons and so on, that itself depends on previous forms of structures that were
specifying different forms of activity and so on and so forth. So it's a kind of circular
relation within the activity of the nervous system and also in the sensory motor coupling
as well, in action perception loops. So we go a bit more and more into detail in a minute,
but this is the kind of idea that's trying to translate Hans Jonas very, you know, almost
poetic point of we are living beings, we can understand life, life is a formal form
of entity. And therefore, because it's precarious and it's under threat, it engages with the
world in what you might call mindful ways. That kind of story, can we make a translation
of that into operational concepts. And this is the starting point for one option to try
to make that story, to cash out that story. And Francisco Varela, in one of his latest
papers with Andreas Weber, he proposes that there is a kind of logical progression from
the idea of audible uses to the idea of sense making. I'm going to say what sense making
means in a second. And that that is the way in which you can articulate Hans Jonas's argument
into his scientific story. Because if you have an auto poetic system, the system will
engage with the world in ways that will either affect the auto poeticist in a good way or
in a bad way. And therefore, those engagements would be appreciated by the system itself,
not in a kind of mentalistic sense of the system looking at itself, but more like the
actual changes are themselves an appreciation of that exchange with the world. And appreciation
will be either like things are good or things are bad, you know, like minor or major breakdowns
in auto poeticists that may occur by as a consequence of certain forms of exchanges
with the world. So he said that would be a way of saying that the system is cognizing
in some very broad sense we're talking about here, cognizing about the world by itself
being affected positively or negatively in its interactions with the world. The idea
by itself doesn't quite work because you need an extra concept which is the concept of adaptivity
which is, and it's not included in auto poeticists itself, it's not included in the dynamics
of self-conservation, self-production of the auto poetic system. Anything that says that
that system will just seek out, say, conditions that will make it live a better life or avoid
conditions that will make it, sorry, avoid conditions that will make it, you know, run
some risk of time. There's no way in which a system can know that this is auto poetic
until the very moment, sorry, that it ceases to be auto poetic until the very last moment.
You know, you just throw yourself off a cliff and you're alive and you're still alive until
the very, very last second you're still alive. And so if the normativity is whether you're
alive or not, you cannot distinguish such a situation from not throwing yourself off
a cliff. So you need something else that tells you, that allows you to regulate interactions
in terms of the potential consequences for your own self-sustaining organization. So
that's the property of adaptivity. We may go into it in some detail if you want, but
I just want to keep it at a sort of a medium flight level and just going through the concepts
and then we can come back if necessary. So then sense making, which would be the appreciation
of whether an exchange with the world is valent, it has a positive or negative valence
or is something that you should seek or avoid, that is the value of those exchanges as a
consequence for your own self-sustaining organization would require first an identity that is self-sustaining,
in this case auto poetic, plus adaptivity, mechanisms that allow you to regulate your interactions
with the world and your internal organization with respect to how things are going. So I
just want them to move to the notion of autonomy. All this, I should say by the way, for some
of you this is really familiar because I end up running through these central concepts
of an active theory always during one third of a talk and so on and then move on to something
new, so I apologize if she's seen this slide. We're trying to understand autonomy, was
one of those questions that we said needed to be addressed. So we speak about cognitive
agents, cognitive systems being autonomous and what do we mean by that? We certainly
do not mean that they're independent of the world, that they are unconditioned, that's
not what we mean. What we mean is that there is a sense in which you can speak of that
system giving itself its own laws or its own norms to be even better, but how is that possible?
I mean if you have a system that you have to sign yourself, that system will follow the
laws of the designer, in this case you. So the only way in which a system could follow
a certain, you know, to have a say in its own laws would be that the system is able
to modify or change itself or better, the system is able to construct itself as an entity.
So by autonomy then what is required, what we have to have is something that is a self-sustaining
process of identity generation and I will cash this out. A self-sustaining process of
identity generation and the precarious conditions. Classical example, auto-polysis, life is self-sustaining,
is constructing itself, you may call this closed network an identity because the closed
network of processes allow you to tell you whether a particular process belongs or do
not belong or does not belong to the system and that allows you to say like, well, this
is a system, you know, and you can follow that system over time, that's why we use the
word identity here. And there may be other, and there are indeed other levels in which
this same dynamic obtains, you know, at the personal level, interpersonal level, et cetera.
Now, what is the consequence of trying to work with our operational concept of autonomy?
And I want to show you why it's an operational concept. Well, one consequence is that we make
in this case, mine or the individual cognizer, we make this into an irreducible level of inquiry.
Most of psychology, cognitive science, neuroscience, it's very comfortable discussing what happens
under the level of the individual, you know, below the individual level, at the sub-personal
level of drives and motivations or neural function, et cetera. Or it's also very comfortable
talking about what happens above that level, the evolutionary histories, relations with
your parents, et cetera, et cetera. So there is a lack of a proper thematization of the
level of the individual, the individual mind. And it's funny because it's the same situation
happens in biology. In biology, the organism itself is some kind of a vanishing entity,
you know, that may be referred to at the beginning of a paper in biology, talk about organisms,
but immediately you just stop talking about organisms, start talking about genes, or start
talking about selective pressures. But it's hard to keep this entity there as a proper
level of analysis. And that actually changes the way we can start looking at cognitive
science, because now cognitive science has been slightly, you know, widened, not just
into the science that tries to say, how does a cognitive system work, but also into the
science that says, what makes a system cognitive? What makes a system mindful? What are we talking
about? What is the difference between that and other forms of systems, you know, a car?
Why would you call this system mindful, and not that one? That is also part of the questions
that we ask in this form of inquiry and cognition. So, I said I was going to go a bit deeper
into the idea of autonomy. There is a definition of autonomy that is there, which is long and
worthy and so on. We have worked to, you know, every comma of it, of trying to just make
sure that, you know, all the cases we want are in and all the cases that we don't want
are not there and so on. But I think I can illustrate this in a different way. And again,
some of you, I hope you can see that. Well, okay. Not too well. Here, you've got an illustration.
You imagine yourself, you're in a laboratory, and you're measuring different things. You've
got different instruments, and you're observing different forms of processes. And here, I
have a picture of several blobs here, not older in any particular way, representing
those things that you're looking at. You're looking at the temperature of a machine. You're
looking at chemical reaction, whatever. So, each one of those processes that you're observing
is represented by a blob. What is not so clear because of the light here is that there are
some very tiny arrows connecting some of these blobs, going from one blob to another. It's
okay. It doesn't matter if you don't see this. There are some arrows going from some blobs
to another, meaning, meaning that you have made the following observation that whenever
something happens to one of these blobs, where you intervene, you change it, there is a
consequent event that happens in the other blob. Then you draw an arrow. There is some
relation of conditioning that says, well, you know, I seem to be changing the pressure
here, and I see the temperature rising. Okay. Draw an arrow between the blob, above pressure,
and the blob that describes temperature. So, you're observing so far things. And at some
point, typically what we do sometimes is we select a series of these observations, these
variables, and we call it a system for some convenient purpose. For instance, you're working
with a robot, and you call that collection of metal, electronics, wires, and rubber wheels.
You call that a robot. So, you as an observer are saying, this is my system. So, you work
in this way by just ascribing some kind of wholeness to a part of the world, which is
you do it in a convenient way, in a way that allows you to exchange ideas, to work with
it, and that's perfectly fine. That's what we typically do. But if you want to understand
autonomy, you cannot do this, because as I said, you cannot just take the point of view
of the designer and decide this is going to be the autonomous system. By doing that, you're
undermining the very concept of autonomy. So, you have to do something else. You have
to keep observing this world, and you may find, now you can see arrows, you may find
that a subset of these observations relate to itself in a very funny way. You may find
blobs that receive arrows from other blobs, and contribute arrows to other blobs. That
is to say, processes that are conditioned by other processes in this subset of all your
observations, and at the same time contribute to the conditioning of these processes in
the same subset. Once this subset becomes close on itself, that's when you're talking
about an autonomous system. One caveat, one additional thing that is not in the figure,
the precariousness. That is to say, you also realize, when you're observing this system,
that not only these things are organized in a close manner, all these arrows pointing
to processes that are themselves into things inside the subset, but the fact that they
are organized in this way is also necessary for each of these processes to carry on existing.
That is to say, if you're starting to intervene in this organization, suddenly you will see
that these processes just break down. They're sustained in a way, by the way, they are related
to each other. That's interesting, and I said before, that describes an operationally
close organization, but that does not imply that the system is disconnected to other things
in the world. There are still arrows that go in and out processes that belong to this
subset, but those arrows that go out go to some process that doesn't come back. You
can say, for instance, trees, plants depend on sunlight for their subsistence, so there
will be an arrow there from the sun into the plant, but the sun doesn't depend on the plants
for its own existence. There is no arrow going back. That's what these things mean. The system
is open to the world, but it's operationally closed. It's organization. It's an organization
of close networks of dependencies. This idea of autonomy, we will apply this several times
in the next part of the talk. One thing that I have to say, because I mentioned this idea
of precariousness, and this is here that actually we throw apart ways, traditional ways of doing
cognitive science. First of all, because this idea of precariousness, it's the recognition
that all these systems are operating in a far from equilibrium condition. They're not
just inert. All the elements in this system, all the processes, components, and so on,
can only be sustained if in the presence of the whole. That is to say that they are precarious.
Now, precariousness is not to be understood as a positive property of matter. It's not
to be understood as something that you can assimilate or put in a box and say, oh, I'll
make my robot a bit precarious by inserting a little component there that says how precarious
it is. Because precariousness is precisely the opposite. It's a lack of permanence of
any positive property that you could ascribe to a function. You've got a neuron, and you
describe the transfer function of that neuron by saying, okay, there's synapses, there's
activation coming in, some process inside, and then pulses thrown via the axon towards
other neurons and so on. So there's a transfer function there, and in connection with models,
you typically describe it as a sigmoid or whatever it is. That function is precarious
in the sense that it is conditioned on many other things. That's an example. And you can
only treat it as a function in a way that has limitation. It won't be the same function
always, or it won't be there always. That means in a deep sense that there is an aspect
of materiality that in this story allows systems to become autonomous, and therefore
to become cognitive. So an autonomous system is necessarily a material system. We're going
to try to explain what that means because you may find that that in a later contradicts
other things I'm going to say. I'm going to say anything there. Now, I just want to
clarify this idea of autonomous organization. By trying to move away from a style of thinking
that already happens within autopoietic theory, which is the idea that, okay, you've got a
system that is organized in such a way where all the elements are contributing to the whole
and in a way they survive thanks to their contributions to the whole. Each organ that
is fulfilling a function in your body that helps other organs survive and help the whole
survive. So this, imagine that you've got nothing. This is, okay, you've got a circle
sort of fitting back on itself, trying to signify this idea of operational closure.
Now, you've got several components in this circle. The action of each of these processes,
all of them more or less fitting back on themselves. You just start following, say, in an organism,
the function of a particular organ and say, why is this organ doing this? Well, it's providing
oxygen to the blood flow. Why? Because that's going to be transported to sort of cells, etc.
And you keep asking, what's going on? And, eventually, you close back on the beginning.
So this is the relation of closure. And you may think that this is a kind of each process
contributing, doing their best to keep the whole going. And this is a way of looking
at considering life as sustaining itself, as being life's self-maintenance. And this
is a typical way where you find in the Yotapoyotic literature. Now, I want to suggest that the
same understanding can be, I mean, the same understanding of a system that keeps going
can be made in a different way, whereby each of these processes has a natural tendency
to destroy the system. Each of these processes has a natural tendency that if you were to
leave your heart, do what it really wants to do, it will just kill you. And the thing
is that these tendencies are negated or overcome by the action of other parts of the system.
