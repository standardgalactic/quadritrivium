Okay Tristan you've been testifying so you I'm not letting you out of this. What percent don't really shouldn't be regulating this that they do not know.
I think it's very understandable why people are skeptical of Congress to regulate this effectively. When they hear senators ask Mark Zuckerberg questions like, how do you make money and he responds famously, Senator, we sell ads.
If I was Zuckerberg I would have paid for that moment to happen and maybe I did, because it generates the impression forever in people's minds it sticks Frank in your language into the minds of the public that government cannot regulate this right so that I've created the outcome that I want and
someone I noticed in the chat was talking about do social media companies own the members of Congress well let's say that this narrative gets really strong well.
It's a $10 market cap corporation it's not very hard to start buying off any of the members of Congress that get critical, and a couple will make some public statements but what's really what we're trying to do here and what Daniel's really saying is that this is existential for our society
continuing to work. This will break our society we've been saying that for eight years. The social lemma says that it's clear than ever January 6 I had text messages from from people Joe Rogan saying.
The social lemma, you know it's so eerie all this stuff is coming true, you know when I remember in the film people may remember the guy who invented Facebook's business model Tim Kendall.
He was asked on camera, you know what are you worried about is the consequence of this and he was, I think he was recorded saying this in 2019 or 2018, and he said Civil War.
And I remember that I think Netflix wanted that to not be in the film because it sounded like it was too aggressive a statement to make it sounded like that wasn't where we were.
And when people saw January 6 and they see the results and people should read this Wall Street Journal article about the outrage economy and how it how it drove up basically more insanity.
It makes perfect sense and the point Daniel's trying to say is that we were trying to ask the question if we don't want to beat China beat China by becoming China, then we have to develop an open society alternative to exponential technology that does not result in catastrophe and chaos.
And we're spending some time in Washington DC and part of the reason Frank I wanted to do this with your audience because I know you have a lot of listeners that are in DC and that are that are curious to get to this point is that you know we're we're trying to see who resonates with this and wants to have a serious conversation about the more comprehensive change.
That's that's needed.
I'm being asked again and again, both and people who are texting me emailing me and in this comment right here. Everybody says, we got to do something, but I don't trust Washington to do it.
What's the answer.
They don't the direct language.
I don't want Washington making the decision for me or my children, what we're going to see.
I can speak to this is one of the things we've seen during cove it is the breakdown of the sense of a shared trustable authority or institution and when it comes to news media and even when it comes to scientists and public intellectuals weighing in on the science there's just radical polarization of what would be a trusted
and so yeah people rightly don't trust Washington, but they would also rightly not trust private companies that have interests that are exactly opposite of their own and radical asymmetries of data manipulation capability.
So the question becomes, when you have technology that is this asymmetrically powerful who could you trust to govern it, given humanity's track record with power.
And yet, like whoever had the cannons in the past is nothing like who has the ai's and all the world's information the behavioral dynamics on your children.
And so as we follow an exponential curve of power. There's this core governance question of we've never done all that good a job of being great stewards of power and now we have radically increasing exponential power how do we govern it.
The whole thing with we don't trust Washington is Washington was never supposed to be a thing separate from of foreign by the people governance it was supposed to be that the state was given the ability to regulate predatory market interests, while still allowing healthy market
interests to ensure the values of the people that were encoded into law could be implemented with a monopoly of violence, but the state could only check the market if the people check the state, and that like everything you can read by the founding
structures within the declaration and the Constitution was all about the people's ability to oversight and check the state and be engaged in governance.
When the people stop checking the government, the government gets captured by the market and you get short term ism crony capitalism regulatory capture those types of things.
Currently, there is a cultural revolution that has to happen of people who get committed to actually being able to make sense of reality together and make effective choices together and participate with the remaking of 21st century governance 21st century
democracy republic open society whatever you want to call it, and the creation of institutions that actually can be trusted because of the right types of checks and balances on power and oversight process with this technology.
Okay, I'm going to ask is, I'm going to read it from Eric Schwartz, due to forceful regulation banks are obligated to know their customers and there's no room for anonymity.
Why shouldn't social media be governed the same way if there was no anonymity, and the platforms were obliged to know how to access all participants with that help.
I'll just respond something there we've been saying also for about five years, the just like banking has no your customer laws and so on KYC.
There is eventually especially going to need to be that with social media and online publishing because of what Daniel was talking about with with GPT three so for those who don't know when you say GPT three, or deep fakes people have heard about this term right
quickly say what this was, Dale and I were actually just with one of the top AI research people in the entire world, and they were saying how much this field has progressed you can basically say, write me a novel in the voice of James Joyce about the topic of, you know, democracy
or something like that, and it would write you, you know, 100 page book, I could say hey write me a article about why COVID, the COVID vaccine is dangerous and with lots of charts and graphs, and, and actually criticize with the names of the logical fallacies that
people are using that that they're that makes them wrong about the vaccine, and why they actually shouldn't trust it, and it'll actually generate like 100 page research paper with charts and graphs that it'll take biostatisticians like a year to actually parse out what's right or what's wrong about that.
That capacity to instantly flood the internet with information and by the way for those who don't believe me do a Google search for open AI, and I don't know what they call this video they can actually do programming so you can actually tell this GPT three AI.
Hey write me a computer program a game where there's a moving asteroid whenever I hit the letter the left and right arrows it goes back and forth, make the asteroid bigger I say all that and it writes the entire code of the video game for me.
I'm just saying a natural language that I want. So in the next election Frank we're moving to a world and this is not sci fi so people people might hear this as alarmism or moral panic and for who believes that this is moral panic, like, listen to the fact that we were saying these
things eight years ago and all of them come true.
We were about to hit a world where in the next election midterm elections for those who don't remember in 2016 there is this popping up with these fake local news websites Denver post the Cincinnati Cincinnati Herald I don't know the names of the fake ones you can basically make them up.
GPT three you can also say spin up a local news website with the fonts and everything and the big sections at the top it'll generate the entire website and it looks perfect it looks totally indistinguishable, then generate lots of articles about why the other side is untrustworthy and he beat his dog and whatever.
And it'll actually just generate thousands of these websites. We're getting so close to that being possible and the reason I'm saying this is to answer Eric Schwartz's question about why we need to know our customers why we need verified identity.
Because if we don't have the sense that someone who generated this comment, or this post or this text is a human being that's traceable to some kind of ID, we're not going to have a working open society.
So table stakes going into the future is we're going to have to have some kind of zero knowledge proof identity and people who are following this closely know that that's one of the big changes that's going to need to make.
When we talk about Congress regulating these issues we're often talking about looking backwards in time at the, at the historical issues how do we deal with these common threads on Facebook or like the stuff from like four years ago issues.
We're missing the fact that what Daniel saying is the first derivative of how technology is constantly changing and generating new issues second and third order effects faster than any of our governance process is keeping up.
So what we really need is a new kind of governance process. We need to meet Manhattan project for governing exponential technologies that move faster and I would actually say, you know, similar to the Einstein Syller letter that was written to FDR in 1939 that said, if we don't do this and open open
society values don't have nuclear bombs if not season gets nuclear bomb or if communism gets nuclear bomb.
They will run the future because whoever wields the power of exponential technologies will run the world. And we're at another choice point today, where we have to have open societies consciously employ the technology and bind to the predatory negative aspects.
Otherwise we're seeing what China is doing and moving much faster.
They say well I don't want us to become China and so there have been several comments about that, that just because China is doing it doesn't make it right they don't value freedom.
They don't value democracy they don't value the things that we insist on.
I agree and that's why that's why what Daniel was saying is actually go ahead Daniel.
I'd like to connect with Tristan and saying to the question that you asked about rigorous identity. So, obviously, being able to know was this a human that produced it or was this an AI be pretty valuable.
But even just, is this the human that it seems like it is, or is this a fake account sock puppet that is part of a state actor propaganda farm. That's pretty valuable because we've forensically find those types of bought farms and fake actor farms all the time.
What they can do is use Facebook split testing algorithm to see what is sticky is for certain populations and continue to modify the content they produce even without AI to push vulnerable populations now the AI just gets to take that exponentially.
So, obviously, rigorous identity would be valuable, but then this question that comes back again it's like saying regulation be valuable, who do we trust to have the rigorous identity associated with all of someone's online behaviors, including through changes in
government that will never forget that where now some despotic government comes in in the future or someone that I didn't vote for or didn't like but now that is an irreversible memory.
So we get to see on either sides here we're like okay, we actually want anonymity because we don't trust anybody on the other side the anonymity makes it to where there's no possibility for justice or knowing what is true or not true.
This is a hard issue. And it corresponds to
it's pretty hard as Tristan was mentioning about the war for the arms race for nukes.
It's pretty hard to make nukes enriching uranium is difficult the precision engineering that was needed for the rockets was hard. It's not hard to make
weapons anymore home based drones with homemade bombs on them it's not hard to take papers that are written about the cutting edge of AI and reverse engineering and make crypto cyber weapons and weapons.
The thing about exponential tech is that the idea of decentralizing tech we have this kind of romantic Silicon Valley idea of this means democratized power for everyone but it also means catastrophe weapons for everyone.
So when you have catastrophe weapons for everybody and it's non state actors and there's no way to even be able to visualize it you can't have mutually assured destruction, you can't create equilibrium.
So then the, the only other answer so far has been okay, well either catastrophe weapons for everyone, if you want something like freedom or ubiquitous surveillance, ubiquitous surveillance is a good answer if we know what everyone's doing in their basement nobody can do work money
those two answers are both so terrible we need a better answer. So in the presence of decentralizing exponential power.
How do you not have ubiquitous surveillance and not have centralized access to that personalized data and yet still have something that can create anti fragility in the presence of that much power that even small actor groups could engage with.
There are some answers that are neither just allow the chaos to continue or become oppressive but we'd say civilizations typically teeter between the civilization is how do we get a lot of people to participate in some way that creates order.
We can get the order through imposition and it becomes increasingly oppressive or we fail to get the order and it becomes chaotic and it fails on either side.
The idea of democracy is that we can have emergent order, rather than imposed, because we can all make sense of the world together and make sense of each other's values and have some basis for shared choice making.
This is ultimately cultural.
I promise to focus on kids, and I've actually got a young person is watching this right now.
This is her question. I'm a senior in high school, inspired after watching the social dilemma and spending a year researching practical ways for young people to limit the use of social media.
I'm curious to know your view and the following. How do the tactics to curb social media use differ by age youth groups, specifically pre teens teens and college.
What advice, what kinds would you give her as she seeks to understand the difference between those three age groups.
Can you say the age groups again pre teen teen and pre teen teen and college, pre teen teen and college. I mean, I will say that I'm actually I don't consider myself an expert on the developmental psychology of children at these
ages what I can speak of is so long as the business model of tiktok and snapchat and Instagram is.
I have to race down your brainstem and create artificial social obligation and artificial social reciprocity that you feel the pressure of getting likes if the other guy doesn't and you don't get it.
That thing is just not compatible with children's development. It turns kids into validation seeking machines, and it creates social pressure and anxiety.
That's simply not it's frankly it's not good for any of those populations right.
It's not good. I don't feel good how none of us feel good when we feel like, you know, frankly, I'm sure you get this all the time so if you get a comment on Twitter you posted Twitter a lot I follow you.
And you get 100 comments on a post that you make and 99 of the comments are negative are positive, and one of the comments is negative. Where does your attention go.
Of course, of course, you've got 99 to one positive.
But our neutral, our brains focus where on the negative and do you think you're alone in this experience or do you think that everyone feels that and do you think that children's feel it more than you are less than you more than you.
So we what we have is essentially a system that creates overwhelming pressure and negativity and the conditions for just not psychological health.
Daniel has this nice line about how what would be how do you measure the health of a society. And it's a hard thing to measure the social health of a society but you could measure it as the inverse of the amount of addiction in society.
I don't know if you want to riff on that but I don't have an answer to your.
I would like to answer her question before.
Because the thing Tristan is saying relates to the question someone asked about boycotts earlier.
When you have a trillion dollar organization with two billion people's behavioral data run by a eyes and then you have a person, just a little person.
The asymmetry of that info war, because the person wants to control their own thoughts and behavior but Facebook wants to control their thoughts and behavior, but it is a mini orders of magnitude asymmetric info war to control their thoughts and behavior.
That's such a problem that you can't just say well let's leave it up to the individual person. It's like saying, let's leave up to individual people turning their lights off as the solution to climate change and environmental destruction.
I know that just really doesn't work this needs solutions that are at the scale of where they're coming from, and switching the burden of responsibility from the joggernauts to the individual is just like a bad move, both ethically and from effectiveness.
So that's what Tristan trying to get to, but we have this person here who's asking a question about what she can actually do so I want to speak to it.
By the way, this has been, this has been Jordan's focus now, since you all created, you got people agitated you got people focused.
Now you got to start to deliver for them. What would you say to her, not going to make a distinction between the three age groups I'm going to say what's true in general and then the developmental application of it is something that you should totally work on.
People are more susceptible to addictive things what we'd call a hypernormal stimuli stimuli that gives more dopamine or hit faster whether it is sugar or drugs or social media type stimulation or porn they're more susceptible to that.
When they're in a hypo normal environment meaning they're less fulfilled in an evolutionary environment in an evolutionary environment humans evolved to be part of a tribe where you were having a lot of rich social interactions a lot of embodied movements a lot of time in nature.
So, those types of things. So, the lonelier people are the more susceptible they're going to be to Facebook and Instagram, the less creatively fulfilled they are.
If you can find groups of friends groups of people and create richer possibilities of offline engagement. It's the thing that'll help them the most.
There's also a place where there's drum circles every Friday night and everybody's dancing and having drum circles if there's musical things where they're getting together and having kind of jazz fun stuff if there's craft places if there's places where they get to have circling to do meaningful like sharing about what's going on for them.
People feel a richer fullness and other opportunities they will be less susceptible to that, then you can actually start to have not only are they're more fulfilling other opportunities, but there's actually social connectivity and status associated with something else.
I've got seven minutes to go, and there are more people on this now in the world after 10 minutes. I've never had that happen in any of these.
Jared Carney asks the primary issue for me is not manipulation, although it's a big issue. It's surveillance.
If Facebook's business model is predicated on conflict plus knowing everything and trying to steer commerce.
How do you counteract that.
I mean this is really the topic of Shoshana Zuboff's book surveillance capitalism that when you control this much of people's lives and you can let's say someone builds an alternative social platform funded by venture capitalists there's got some investors I'm sure on this call.
Many people might be wondering well what if we funded some alternative social network that because we want to do it in a way that doesn't capture people's data.
Well that will be funded by venture capital venture capital expects, you know, big multiples of returns. There's actually no way to exit that except by getting acquired by one of the existing big surveillance capitalism companies whether it's Google or Facebook, etc.
You'd have to do it in some way where it's an independent thing, something more like a Wikipedia or a blockchain type project where the data is kept separate somehow.
But you're not going to be able to transition these existing platforms Daniel do you want to jump in.
You could.
You need something that is like the equivalent of HIPAA.
So, which is the medical privacy regulations.
So, if I have a medical file so that I go into ICU somewhere they can pull up what I'm allergic to and those types of things.
It's very sensitive information about me, everything that's in my life medical file that information could be sold to drug companies it could be sold to lots of places it would be interested in doing stuff with it it's really really important that that isn't sold.
So there is state based governance of that data and how that data can be shared and not shared if.
And so, when you're saying manipulation is second to surveillance the purpose of surveillance is manipulation, right the gathering of the data is to use the data for a purpose, and whether it's to affect how you vote, or to affect your market
or to affect how you affect the cultural zeitgeist that will affect market behavior and voting of others, or to be able to arrest you for things that we decide later or seditious or whatever it was.
Ultimately it's the control of behavior that we're gathering the data for.
And so how do we create safety of the data and this is where the question has been do we trust Facebook with it no do we trust Washington with it no.
Do we want there to be a place where there is data so that we know that it's a person and not a bot putting the information out yes so do we need to create a better checks and balances and oversight process to ensure the trustworthiness.
Do technologies like blockchain do part of the thing where you can do provenance on data and see how it moves and have things where the data only becomes released if certain flags happen otherwise it's in a decentralized rather than the centralized database there's
partial solutions there and we could work on full solutions.
The hippo kind of thing it's that that data, the there's a Hippocratic oath that is saying that data is being gathered by the doctor who has serving your interest not the pharmaceutical or anybody else's interest in mind and we can see it's not perfect.
If Facebook's business model shifted where the user was the customer.
And either that and or as a state say got made into being a state utility so the interest of the state which would mean that people didn't take views in such antipathy to each other in the state that was basically like second order trees and
in addition, but where the interest of the integrity of the state and the interest of the well being of its citizens were actually what was directing its AI and its use of that data, as opposed to advertisers and there was the appropriate privacy and protections
on it and I got to adjust the settings and say, I'm interested in learning these things I'm interested in being exposed to these other kinds of ideas here's the ways that here's what I want my time on site to do of all the information here's what I wanted to curate for me.
Now we have a situation where the death the behavioral data that happens by the fact that I click on stuff. I can't have technology where I click on stuff and not gather behavioral data, but who is storing it for what purpose, and how is it being stored becomes really critical and it could be
stored where the legal binding of it kept it from being used for purposes other than the ones that I am actually consenting to.
It's like personalized learning Frank I mean think about things like Khan Academy where it's your yesterday you're personalizing information you're gathering lots of information about where people look like they're getting stuck or what lessons they might want to learn
more of but the purpose of Khan Academy isn't to manipulate you into clickbait and to make you hate the other political party it's to help increase learning right so you could have.
That's the kind of thing that we're talking about is personalized in the interest of helping society get wiser and more thoughtful not the direction of whatever gets their attention.
I wanted to answer the question you can't get these.
This conversation doesn't happen.
There is no news program that has a conversation like this like I'm embarrassed to have to keep saying to Daniel to simplify. I shouldn't have to do that.
Just like we said, just like we said that the fourth estate has broken obviously so his education because the idea in the founding of this country following the enlightenment and modernity was that everyone could be educated well enough to understand the issues that
are going to be created that would affect and bind their life if I'm going to be bound by law I need to understand the issues well enough to get to have a say in that. If the people are not educated well enough to have a say in the law that's going to bind their life it's not a democracy it's just a story or a simulation of it
in which case monarchies might actually be better and not have all the attention go to flipping back and forth every four years and internal divisiveness.
If we really wanted to be a democracy and effective for the state and education are prerequisites at the level that is needed for people to understand the issues well enough to participate now we have to say, using AI and attention tech and all of the modern technologies
how could we make new better educational systems and better participatory governance systems where everybody can't fit in the town hall but everybody can give input that now these a is can semantically parse and help create propositions that are not best at interest group propositions but that are saying
the best proposition that fulfills the interests of everyone look like and now we get to work on proposition crafting. We could use these same technologies that are destroying open societies to build better ones.
That though has to become the central imperative of the time, and it does require a new cultural enlightenment that does require an educational rise to understand the issues well enough, or it just doesn't matter it's over like if Congress and the public.
If we understand the issues well enough, then of course the corporate interests are just going to run and authoritarian nation states employing exponential tax see both Facebook and Google on one side and China on the other side are deploying exponential tech towards purposes,
but neither of them are open societies. If the open societies are not also developing and deploying where the power is then they will just lose.
What we're saying is that the open societies have to develop and deploy the full suite of modern technologies to create new digital era open societies that can protect against catastrophe, but also protect against dystopias.
And that is the central imperative.
The last central imperative which is to keep people alive during this at the, hopefully at the back end of COVID, and I don't know of any example that frightens me more or angers me more than the crap that's put out against the vaccines, and I go absolutely crazy.
And I read it, and I shouldn't, because it makes my head explode.
Help me here. What can we do, we are coming down to the end of the vaccine process, and we are not going to hit herd immunity, and the US is not even in the top 15 of vaccines anymore, because of the crap that's coming as being generated in America about from social media.
How do we combat it when it comes to health, because Tristan, your idea that they're going to be able to create these stories with these reports, I've read them, I've seen them.
They look real. And I know they're not.
How do we combat it right now, because we don't even have a year to wait on this, we have to do this right now.
Great question.
You.
Sure.
We're not going to that's just that just loses.
In the same way that we're not going to prevent climate change from creating droughts and affecting areas of poverty that will create massive human migration.
There's a lot of impending catastrophes that will just happen and we'll just lose that we, we could have done a better job with this pandemic at a million points.
And so this is why we're thinking a little bit more long range about what are the even worse catastrophic things that we possibly have time to address and why do we, why are we doing so badly at all of them and what would it take to do a better job at all of them.
Because if we can't coordinate for, for climate change or overfishing or biodiversity things or nuclear deproliferation or stopping AI arms races or stopping CRISPR arms races, or getting misinformation right.
We just fail at everything. So ultimately we have to get better global coordination capacity for global level coordination challenges. If we get that we get all the other things otherwise we don't.
So you're talking here about a shared sense making of what is true what is base reality but in a world where there's a breakdown of trust and a breakdown of trust and what is legitimate authority you will not get shared sense making so then you either do have to become China and say, I don't
care if you don't believe it and if you think it's terrible we're going to force it on you, or you have to say well, we're going to just fail, or you have to say oh we actually have to be able to recreate legitimate authority and not just people's fall see, faulty belief in it but a good basis for it
how do we do that, how do we recreate a shared sense of sense making but also not just that the social contract and social solidarity that if someone thinks something different than me.
And they're a fellow countrymen I don't just instantly have antipathy for them I try to steal man rather than strong man, what might be true what values might they hold in their perspective, because if I just go to a culture war with my fellow countryman and China doesn't have that
but we get to amplify our net antipathy towards each other using exponential information tech then our country just destroyed it's over open societies. There has to be a process of how do we do better sense making, but also better understanding of the partial truths and the values in each
other's perspective so that we can find new attractors together.
Daniel, Daniel, if you're right, we're screwed.
Yeah, if your conclusions are right because we're not going to be able to do the things to address the challenges challenges that you lay before us, it cannot. It will not happen.
Not not in the time scale of the issue you're focused on.
For this now we're screwed.
Tristan you're gonna have the last word you do not have to make people feel good. I want you to end in 45 seconds with what you want people to take away from this conversation.
Don't screw it up.
I was, I was just going to say that I think people think that trust can't be recovered from where we are. And I feel, just to say something very concrete is that if people were to communicate and feel like they're in a way that they reflected why people
don't trust the CDC that I've been shown talked about. And if those institutions came out and said, Yeah, we did flip flop on this and this they people need to feel like they're being told the truth with earnestness and sincerity, and
not gaslit and I think the problem in communication is when you communicate to large audiences and you feel like people aren't going to get it. You simplify the message, and you say something that's not completely true but you force it down people's
those who know that that's happening, get rebellious and we're not going to create a unified understanding until we come with sincerity and I think trust is the sort of the fuel that undergirds all of this conversation and I feel like sincerity and earnestness is the is the vehicle to re establishing that trust.
And I feel like that's what we're, we're trying to do now and just to name one thing is Daniel and I are, and some others are really looking to see in Washington DC, especially in the national security community, who resonates and understands with what we've laid out, and
we're not trying to be pessimists we're just very we're trying to be very clear about the space space of problems, and what it will take to actually look ahead. So we don't just, you know, have another coven and we in climate change we get, we mess those up to.
We have no chance right now to not mess up some of the future tech that's impending dooms that's coming.
And we're looking for help so if you're interested, you know, hope we can all connect through through Frank, and I really appreciate Frank you giving the opportunity to have this conversation I think, happy to do more.
I know we kept this to an hour but I think it's incredibly important and each of the issues go very deep I mean the teenage mental health stuff versus the polarization and how do we deal with the exponential tech issues.
Well, I it this is incredible. And as Harry Clark says go see Ben's ass.
I need to find a way to have the two of you sit down with him, and you don't have to simplify it. Daniel, you can say it exactly as you say it right now and he'll be he'll be with you every step of the way.
You guys are brilliant you guys are the way it should be.
You know your parents, I'm sure, were are proud of you.
You got a great education. This was probably the most important session I've ever done.
And I'm grateful for you all for not pulling any punches for not dumbing things down.
And the next time I will go to sleep will probably be never after all the things that you just said. So everyone thank you. We're not going to do this that often. I'm only going to do it when it really matters and this time it really matters.
Daniel, I hope people pay attention to you trust on I hope you do another documentary with another couple Emmy Awards. You deserve them.
This session is done and had all done your favorite posts on YouTube. Now, unedited complete. Let's use Twitter to take a couple segments from this. We're going to use social media the right way to get your message out to as many people as possible.
Everyone. Good night. Good afternoon.
It was an honor to be here. Thank you. Thanks Frank.
