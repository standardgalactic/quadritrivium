As people get brought into the Zoom, I don't know if I've ever done a Fridays with Frank
that was more appropriate and more timely because of all that has happened in the last
seven days.
Justine Harris, congratulations on winning two Emmy Awards.
You're the first personal friend I have that is actually a multiple Emmy Award winner.
Thank you for you.
You should feel very proud.
Thank you.
And you're already getting a comment from one of the people who is listening in.
And Daniel, what you are trying to achieve with a more constructive, a more open,
a more useful dialogue and the teaching of civility and decency and how we
communicate in the public square is something that we should all emulate.
I am a proponent of technology.
I am a supporter of it.
We're going to hear a lot of criticism today because of the problems.
I do want to open up saying that I believe in it, believe in what it has done for us.
And in fact, I'm going to do something I've never done one of these Fridays with Frank, which is I'm actually going to show some data that we've not shown publicly until now.
We've been looking at technology. Now people react to it.
This is important.
We asked the question in the opposite way that most people do.
How would your life be different?
If you didn't have all that technology is stuff that we use every day Google Amazon YouTube.
And the public actually by almost two to one say that the quality of your life would be better without that technology.
However, then wanted to know whether technology has made their life easier or more difficult.
And overwhelmingly they say that technology has made it much easier to keep in touch with people, as well as issues that are important to you another example, given people more choices.
To make their lives easier to consume, because you get more services and more products and again numbers are overwhelming.
In terms of making shopping hassle free 63% easier, only 6% harder we got more for these, saving money and the things you buy overwhelmingly easier.
It's a made it easier harder to get involved in politics by 47 to 10. They say it's made it easier. Again, I go back to that very first statistic I showed you.
Not easier but better, the public has an issue with that.
So let me go to you Tristan, and again congratulations on your success.
You talked about this you and I've known each other for a year and a half.
Our meeting, our was a chance encounter by a friend of mine who said I must sit down with you and I admit that I was going to not show up.
I was going to cancel the meeting. And probably in the year 2020 you're the single most important that I'm the most important person I met.
And that data, you know how much people need and want and value technology, but you also know the consequences.
What have you learned in the last seven days the Wall Street Journal has been pummeling Facebook and really shining a bright light on social media.
What have you learned over the last week that would be helpful for all the people who are on this zoom.
Mike, and yeah, really pleasure to be here with both you and Daniel.
So, for those who don't know, over the last seven days, last five days, I think the Wall Street Journal has released a new series called the Facebook files.
It looks like it's the largest event I would say they call this the largest event since Cambridge Analytica, in terms of revealing research that the company has been aware of harms across the balance sheets of teenage mental health increases in teen suicide body image issues for
years. The radicalization of political parties there's evidence of the way that Facebook changed its ranking systems that then cause political parties to actually tell Facebook we know that you change your algorithm and we switched it to we know
because we have to publish now 80% negative content about our opponents to even get any attention the way that we used to.
So I'm pretty sure is had to learn to publish to publish more negative content to get any attention. I just really recommend that people check out the Facebook files because it's really the first time that there's evidence of so many of the things Frank that you and I because we've done one or two of these
before.
You know have been saying for a long time and that what we said in the social limit that yeah for those who don't know the social limit.
We won a couple Emmy awards came out a year ago we're coming up on the one year we just passed the one year anniversary. And really what the social dilemma is about to answer your question Frank is it's not about technology.
It's about these certain kind of incentive systems that are built into technology so if you take a look at Facebook, TikTok, Snapchat, YouTube, what do they have in common they seem like they're different products like one is a video broadcasting site that's
a social networking tweet site Twitter. So they seem like different categories, but their business models are all optimizing for the same thing which is whatever gets people's attention.
And so I think that is the generator function of all the harms because in the same way that a values blind economy that's counting GDP war is good for GDP.
So addiction and drugs are good for GDP human trafficking is good for GDP. In the same way things that are good for attention that are not things that we want. Well body image issues that had had kids basically, you know infinite looking at anorexia
videos. That's really good for keeping time spent up addiction is really good for keeping time spent up negativity and outrage and things that go viral that are, as we said in the social dilemma fake news spread six times faster than true news, because the, the speaker
anything that they want to unconstrained, meaning they can lie is going to do better than a person who has to wait and say well what's actually true that the unconstrained actor is going to win.
So for your slides, Frank that the thing here is is not that it's about technology being good or bad. It's about the kind of technology and incentives that we bind to the technology.
So this model of maximizing engagement what we found out in the in the Wall Street Journal articles and I could run through some of the, you know the things that we found but basically Facebook knew, for example, that that they were increasing some of the negativity in society, and they
knew that they knew that, but Zuckerberg didn't want to change the ranking algorithms of Facebook, if it was going to hurt engagement. And now you could say he's just greedy or he just wants the profits, or he just needs to keep his share price up.
He also is bound because he set up a set of incentives all of his employees all those people at Facebook, most of them are incentivized by how much they can get engagement up.
So, all throughout the company, imagine you have a bonus structure where everyone's, you know, salaries and paychecks come in through maximizing engagement but then you find out that let's say 50% of that engagement is causing genocides and
Ethiopia is causing body image issues and kids, you can't say we need to have our engagement because now all your employees are going to leave, because they won't be able to get their benefits you've actually gone against the own incentive structure for your own employees.
Yes. So what what is it so I want to know what it is causing. And I'm going to add a little bit of pressure on you, which is that we have two members of the judiciary committee.
By the way, I'm in Belfast. I'm actually here in conflict capital of the globe.
And that's why I'm so happy Daniel that you're involved but I just got one more for you.
You've got two members of the judiciary committee say that fast five times.
What should they deal with us. What should they know if I gave you 30 seconds.
What should they know that you know about what's happening.
I think Daniel in a moment I think we'll help elevate the conversation to what kind of changes needed because unfortunately while I wish that there was, you know, a couple of laws or bills that we could pass to get to some better state.
The challenge is that this is based. This is now baked into the, the infrastructure that we use is now the fabric of our democracy and virality, the thing that is causing some of this I think of this everyone's now familiar with the idea of a lab leak and
Wuhan, the Wuhan Institute of virality that was doing potentially gain of function research on what viruses can go viral. Well people now know what are not is the idea of something that can go viral and how many people does it infect.
The purpose of Facebook is to be the Zuckerberg Institute of Verology. The purpose is to create and allow for things to go viral across the world and be spread to millions of people, and to literally take the, the are not to be as high as possible
we want it to infect as many people and spread to as many people because that makes engagement go up. And that's the core thing so you say what's the law that we can pass what's the issue that we can change.
It's going to be as simple as that I think we have to change the nature we can't have it be the Zuckerberg Institute of Verology. It has to turn into something safer.
So, I will warn you that there is a Facebook executive that's on this conversation so don't be surprised by challenging Harry Clark, who is one of the best minds in communication public relations.
I think is part of the Q&A one more and this is going to both of you.
Why not just boycott Facebook. Why, why, why is that a strategy you're considering.
And I don't want to, I don't want to sandbag you someone from Facebook is going to hear this. Why not boycott Facebook. He wants to know.
I mean, if people could boycott Facebook and there was meaningful alternatives that were not the same problem and tick tock is basically has the same problem YouTube has some many of the same problems Snapchat has different but some of the same problems.
So boycotting and then going there's nowhere safe to go. That's, that's one of the issues. And the second issue is that you can't really boycott it when your life depends on it.
So one of the problems that's actually in the article about teenage girls is that you can't actually say it's not an individual choice to say I don't want to use these things because I'm going to ostracize myself.
And if all my friends are still on it, you'd have to get the entire world to boycott it together and move to something else.
Because it's it's fundamentally been baked into our lives small businesses have to use it to advertise how else they're going to reach their users and their and their and their customers.
So they've owned the capacity to reach people if we want this video to be just as many people as possible we probably want to post it on not some random tiny video site no one's going to click on but you want to post it on the one that gets as many views and likes etc so you can post it on Facebook and you're going to post it on YouTube.
So they have a monopoly on reach, which makes it very hard for people to boycott it and say let's go somewhere else.
You, even though you're involved in this issue I look at you as being essential to to public discourse, because you're looking at it, you're looking for solutions.
You're looking for results.
You're one of the strongest thought leaders in how we talk to each other now in society.
I ask you the question I asked Tristan, would you recommend a boycott, knowing that there's a Facebook person on this conversation.
And do you have any solutions to the problems that Tristan has raised.
I think it's kind of like what Tristan said that there's a monopoly but not a monopoly in terms of a government contract monopoly but in terms of a network dynamic monopoly network dynamics create natural monopolies where one, as you get increasing
the numbers on the more people that are in a network, then you fundamentally have to engage with that thing because there's something like exclusive value offered there there.
If somebody decides they're not going to sell on Amazon and they have a small business they just can't compete with the ones that are doing that or similarly if they're advertising on Facebook.
So one of the things is when we built the laws around monopoly and antitrust network dynamics didn't exist yet those were built before internet and those dynamics so we actually have to take the emergence of the internet and the emergence of network dynamics and met
kaf law and say we actually have to rethink that monopoly didn't just mean a crony capitalist government contracting.
Can you, for those of us who only went to the University of Pennsylvania can you dumb it down just a little bit so we, so we understand what you're talking about.
Nobody wants to use 20 different social networks and have to remember all the logins and find some friends in one place and some friends in another place just like they don't want to use 20 different kinds of currencies.
So if there's a currency that everyone accepts that currency kind of gets a monopoly value.
If there is a network that everybody's on, and you can see your friends from high school and your family and the news and all the things you're interested in with one login, like those stats you showed people said it was easier and made their life worse.
Every one who has conveniences where they don't exercise and don't do the things that actually strengthen them or read or study there's a lot of things that make life easier and worse.
And so, where something has a network dynamic where the more people that engage with it the more value it has because now everybody's producing content, everyone I want to find is on there.
The AI will curate all the content to show me exactly what I want to see, but which part of me wants to see.
Well, it's going to the AI is going to optimize based on my behavior and how long I spend on site and how many things I like and comment on and share.
And it happens that the things that appeal to my existing biases and increase my sense of certainty in an uncertain world, and the things that scare me and kind of create emotional responses that make me less clear about the fact I don't want to be on Facebook and go do other stuff with my life.
And the things that reinforce tribal identity, maximize time on site and engagement.
So, it's one of those things where you can manufacture demand from the supply side and then say we're just giving people what they want, but you're appealing to the weakest lowest angels of people's nature, and then doing so with radical asymmetries of power.
So, Richard Dreyfus who's always been a friend of these Fridays with Frank and he's just his brain is incredible.
Is there proof that social media is leading to instability, leading to anger.
We may think it.
Daniel is there proof of this.
Well, this is what you were talking to Tristan about regarding what the Wall Street Journal has been showing this week. And they're obviously previous cases and it's this week and what will be continuing as more information comes out is stuff that Tristan and Jared Lane here have been saying
what happened for nine years because the business model guarantees it.
Now there is increasing proof in the form of hard internal documents and disclosure.
But for anyone who's been kind of paying attention, the business model of maximizing people's time on site and maximizing engagement combined with the technology of behavioral modification ai's was bound to be antithetical to democracy and antithetical to health so Tristan
can give the proof, but for the people who've been paying attention it was.
It's kind of like saying, if you is there proof that deforestation is happening and as soon as you're looking at the financial incentive to cut down the trees in an area where the trees alive or worthless and the trees dead you're kind of like it's going to happen.
Right, in the same way that trees worth more dead than alive and whales worth more dead than alive. In this case, our attention.
It's easily more sought with outrage.
It will be that will be the profitable model us being happy or civil talking to each other off screens and not on screen is not profitable for any of the social media company specifically some of the data and again I recommend people check I think it's the third article that the Wall Street
Journal released. They talk about actually due to some of my own work Facebook changed its core metric, it used to be maximizing for time spent I was part of a movement called time well spent that was my first head talk.
Facebook decided actually Mark Zuckerberg wrote in his January 2018 post his yearly goal is his new goal for the year was to take Facebook in the direction of time well spent not time spent he took my words.
Then he said we're going to change the way we measure success at Facebook, we're going to use something called meaningful social interactions MSI.
And this Wall Street Journal article I recommend everybody reads it showed how meaningful social interactions they were trying to give the sign different points so for example, you got one point, if you for a post would get one point if it had a like.
It got five points if it got a reaction or a reshare without any text. It got 15 points for what they call a non significant comment, and then it got 30 points for significant comments and significant reshares.
What that really meant was the more long comment threads and article created which is say more arguments, the more those things got boosted to the top.
So whenever there was an argument, it was like hey let's put that at the front and center for everyone's feet, and then do that in a decentralized way for the entire world all at once for two billion people.
And when you basically highlight divisiveness and disagreement and in civility, which is the thing Frank that you're trying to find one thing you and I were just at the milk and conference.
And there's a lot of people who are funding things like hey how do we do American one room how do we fund with hundreds of millions of dollars of depolarization for the country.
And let's have people together physically in rooms talking to each other that's great. But how's that going to compare to the four hours a day people spend seeing in civility every single day.
And if 90% of people became civil, but only 10% are left that are in civil.
Then what does Twitter and Facebook show you will they only show you that all the bad faith in civil people so that keeps just completely blasting over and plastering your whole feed.
And so it continues to look like the world is in civil even if many people are starting to get better.
I should have that system with democracy period open societies cannot allow this situation to be and Daniel I'd love for you to speak about that because I think it's the reason why I wanted to have Daniel here Frank is, I think this isn't just about less toxic social media
how do we just rain in let's take the reins and if we just move at five degrees this way we would suddenly have a better democracy, plus, you know, Facebook, we have to look at a deeper problem statement there to get to where we want to go.
Okay, so I'm going to ask both of you, and you can go another order, solve it.
By the way, we've got a lot of parents on this. And I'm going to ask you in a moment to scare the living hell out of them.
Give me your, your most frightening conclusion based on all the research you've done on young people.
Before I do, we're adults. Do either of you have an actual solution that you're going to be presenting to Congress.
Either of you.
Daniel you want to try to describe.
I can say, I can say some things that would be directionally right.
We read all the documents around the founding of this country, and know that the idea of universal public education and a adequate fourth estate were considered prerequisite institutions for democracy to function, the people had to be educated.
And they had to have access to the information to participate in governance.
There's a very deep question of
hold on one second.
Those people who are watching because you're actually we're 25 minutes into this. And I can see the number of participants is actually rolling.
I'm going to focus on kids and about five minutes. So if you guys want to send out an email want to send out a text to people saying tune in.
And about five minutes we're going to specifically focus on what social media is doing to your children.
So I suggest you stay honest, Daniel, please continue.
So you can actually see how the critical role of the fourth estate following the printing press and it's been well analyzed the role that the printing press had in the formation of democracy we don't need a small educated nobility who rules everybody because everyone can have access to
books and newspaper they can be educated and we can come to a town hall and participate in our own governance.
But this was based on the idea that we could get something like fair and independent news and all read the same thing and then be able to have an educated discussion about it.
So when you have an internet where there's radically more information than anyone could begin to parse what information you see ends up being determined by curation processes I'm not going to see all the videos I'm not going to see all the news I'm
going to see all the posts. And so it's not like we respond as rational actors to the best information we respond to whatever YouTube's algorithms and Facebook's algorithms put in front of me, and they put it in front of me based on a business model.
That's maximizing time on site based on engagement and it happens to be that that which appeals to my existing biases and emotions maximizes time on site.
So someone on the far right and the far left when they're looking at their news feed and how they're coming to understand the world might see nothing in common.
And so, and yet it's representing the world to them so you have to say, if democracy doesn't exist without a fourth estate and people having a shared sense of what base reality is.
And the internet, and specifically, network curation based internet has destroyed the fourth estate irrevocably.
How do you remake a democracy post internet network age, because people can't do shared choice making if they don't have a basis for shared sense making of what's going on.
Yes, answer that question and how do you do it.
It's the right question, but I'm pushing you now. How do you do it. Well, you can see that China decided well let's control our internet to not have radically divisive ideas that end up making people against being good citizens.
And you can see that there's an effectiveness in that but it's antithetical to the idea of an open society.
So you either keep an open society with these type of network dynamics and it just becomes increasingly chaotic and fails, or you try to apply the China model those are the only two things currently as the possibilities and what we want is how do you have something
like open speech, but with this degree of radical amplification possibility that doesn't become total chaos, and you have to look at what is the incentive for the amplification.
If there's a tool that can curate it and make stuff radically more amplified what is the incentive guiding it.
To say for instance, if Facebook is the most powerful behavioral modification machine in the history of the world that can gather micro targeted information on people and then specifically put information in front of them to control their behavior for advertisers.
But the people who it's gathering information about an influencing are not the customer, but it's gathering privileged information about people to then sell it to the customer who is the advertiser.
Maybe a break of a fiduciary contract where you're not allowed to gather privileged information about someone and then use it against them. If the user was the customer, rather than the advertiser being the customer.
And as a result, the optimization algorithm was not to sell people ads or to maximize time to sell them ads but was to find the metrics that actually correspond to people's real quality of life and the AIs were oriented to that we might start to get somewhere, but that's the beginning of a radically
business model in ad based business model with AI controlled behavioral mechanics will break democracies, they don't go together.
I trust down I know you agree with this but can you explain it to someone who only went to pen.
Daniel, half of Congress is not going to understand this.
They still call the tape recorder a machine or sorry a microphone speaking the speaking the machine now it's actually a microphone.
They don't even know what the internet is just on go ahead.
Well, I think the thing that Daniel saying is that an advertising supported.
I imagine, Frank, I put a brain plan in you, and I actually talked to the guys at Neuralink once about this right imagine Neuralink Elon Musk's Neuralink project I'm going to put a brain implant in your brain.
It's going to shape the thoughts and give you thinking superpowers.
But let's imagine that brain implant in your brain it's going to intimately shape every thought that you have from from the moment you wake up to the moment you go to bed and your dreams that someone attached the advertising business model to that Neuralink brain implant.
So now you start having thoughts that you didn't even intend to have and it's actually in control, we would just say immediately when I say it that way.
It should be clear, we maybe we can have brain implants, but we certainly would never allow brain implants with an advertising based business model.
What Daniel is saying is that we cannot have democracy, and the primary brain implant of that democracy, be an advertising based business model.
When Daniel says fiduciary what he's referring to is a brain implant that would have your best interest at heart just like a doctor theoretically is supposed to have your best interest at heart.
And a psychotherapist you're going to tell the psychotherapist all this privilege deep information that's deep in your psyche they have to have your best interest at heart.
What we're saying is such a deep change that we have to have technology that's humane with our best interests at heart.
What's in that such an uncomfortable conversation is that I believe Facebook stock price has not moved that much this week, despite the fact of these these awful revelations, and it's worth about a trillion dollars and that trillion
dollar valuation comes from the advertising based business model so it's as if we had an entire industry of psychotherapy that was based on a manipulative business model that was worth a trillion dollars.
And now we have to switch to what does it look like to be in the interest of people. And the question is that's it that's a that's a very dramatic economic change. So I think it's more than our brain wants to shy away from that because it's so uncomfortable that we'd have to make a
change as deep as that that's one of the big things that has to change.
I know that one of the comments is, maybe we need more people like you in Congress, that it's not your fault that you're speaking the truth it's their fault for not understanding it, and actually that's not such a bad idea.
I wanted to speak to what you said earlier about what people in Congress would understand.
If because of who the people in government are or the structure of government, if it cannot understand the nature of the issues it's supposed to regulate, and particularly as technologies evolving rapidly faster than the people who are in there are able to
understand the consequences of then it will just break right if the regulatory apparatus can't understand the effects of what it needs to regulate it will just break.
And this is the key thing that we're talking about is we're right now talking about the case of social media tech following a business model, but we could also be talking about crisper and tabletop crisper emerging, where we're getting very very close to cheap
to make bioweapons for everybody. And with regard to AI and generative text AI, we're getting very very close to the ability to make content in your voice, saying anything that anyone can do, and flood the internet with more information that passes the
And, and so, and Elon said this he said, if we wait to regulate AI and the other technologies that operate this quickly AI specifically who's talking about till after the effects have been seen for as long as we did with cigarettes or dbt it's way too late.
The effects will have been irreversible.
So when we say exponential tech what we mean is exponentially faster to scale exponentially larger effects that can happen from exponentially smaller groups of people.
It doesn't take stay actors like it did to make nukes to make AI weapons bioweapons crisper weapons.
So, the big question becomes in the presence of the speed and scale of emerging technologies are processes of governance are just inadequate, they're too slow.
They are too divided and this is why China has done a good job of saying no we actually have to control these technologies otherwise they'll break the country how do we do it, but it's in a particular direction if we want something like an open society and the presence of exponential
how do we make a regulatory apparatus capable of regulating what it needs to in time and ahead of time that is aligned with the civil values of an open society that's the central question of our time, I believe.
I want a simple number, a number.
Daniel what percent of Congress house in the Senate is really intellectually not ready to tackle this issue.
I don't know. I don't know them enough.
What would you guess, I would trust your guess over mine on this.
