As people get brought into the Zoom, I don't know if I've ever done a Fridays with Frank
that was more appropriate and more timely because of all that has happened in the last
seven days.
Justine Harris, congratulations on winning two Emmy Awards.
You're the first personal friend I have that is actually a multiple Emmy Award winner.
Thank you for you.
You should feel very proud.
Thank you.
And you're already getting a comment from one of the people who is listening in.
And Daniel, what you are trying to achieve with a more constructive, a more open,
a more useful dialogue and the teaching of civility and decency and how we
communicate in the public square is something that we should all emulate.
I am a proponent of technology.
I am a supporter of it.
We're going to hear a lot of criticism today because of the problems.
I do want to open up saying that I believe in it, believe in what it has done for us.
And in fact, I'm going to do something I've never done one of these Fridays with Frank, which is I'm actually going to show some data that we've not shown publicly until now.
We've been looking at technology. Now people react to it.
This is important.
We asked the question in the opposite way that most people do.
How would your life be different?
If you didn't have all that technology is stuff that we use every day Google Amazon YouTube.
And the public actually by almost two to one say that the quality of your life would be better without that technology.
However, then wanted to know whether technology has made their life easier or more difficult.
And overwhelmingly they say that technology has made it much easier to keep in touch with people, as well as issues that are important to you another example, given people more choices.
To make their lives easier to consume, because you get more services and more products and again numbers are overwhelming.
In terms of making shopping hassle free 63% easier, only 6% harder we got more for these, saving money and the things you buy overwhelmingly easier.
It's a made it easier harder to get involved in politics by 47 to 10. They say it's made it easier. Again, I go back to that very first statistic I showed you.
Not easier but better, the public has an issue with that.
So let me go to you Tristan, and again congratulations on your success.
You talked about this you and I've known each other for a year and a half.
Our meeting, our was a chance encounter by a friend of mine who said I must sit down with you and I admit that I was going to not show up.
I was going to cancel the meeting. And probably in the year 2020 you're the single most important that I'm the most important person I met.
And that data, you know how much people need and want and value technology, but you also know the consequences.
What have you learned in the last seven days the Wall Street Journal has been pummeling Facebook and really shining a bright light on social media.
What have you learned over the last week that would be helpful for all the people who are on this zoom.
Mike, and yeah, really pleasure to be here with both you and Daniel.
So, for those who don't know, over the last seven days, last five days, I think the Wall Street Journal has released a new series called the Facebook files.
It looks like it's the largest event I would say they call this the largest event since Cambridge Analytica, in terms of revealing research that the company has been aware of harms across the balance sheets of teenage mental health increases in teen suicide body image issues for
years. The radicalization of political parties there's evidence of the way that Facebook changed its ranking systems that then cause political parties to actually tell Facebook we know that you change your algorithm and we switched it to we know
because we have to publish now 80% negative content about our opponents to even get any attention the way that we used to.
So I'm pretty sure is had to learn to publish to publish more negative content to get any attention. I just really recommend that people check out the Facebook files because it's really the first time that there's evidence of so many of the things Frank that you and I because we've done one or two of these
before.
You know have been saying for a long time and that what we said in the social limit that yeah for those who don't know the social limit.
We won a couple Emmy awards came out a year ago we're coming up on the one year we just passed the one year anniversary. And really what the social dilemma is about to answer your question Frank is it's not about technology.
It's about these certain kind of incentive systems that are built into technology so if you take a look at Facebook, TikTok, Snapchat, YouTube, what do they have in common they seem like they're different products like one is a video broadcasting site that's
a social networking tweet site Twitter. So they seem like different categories, but their business models are all optimizing for the same thing which is whatever gets people's attention.
And so I think that is the generator function of all the harms because in the same way that a values blind economy that's counting GDP war is good for GDP.
So addiction and drugs are good for GDP human trafficking is good for GDP. In the same way things that are good for attention that are not things that we want. Well body image issues that had had kids basically, you know infinite looking at anorexia
videos. That's really good for keeping time spent up addiction is really good for keeping time spent up negativity and outrage and things that go viral that are, as we said in the social dilemma fake news spread six times faster than true news, because the, the speaker
anything that they want to unconstrained, meaning they can lie is going to do better than a person who has to wait and say well what's actually true that the unconstrained actor is going to win.
So for your slides, Frank that the thing here is is not that it's about technology being good or bad. It's about the kind of technology and incentives that we bind to the technology.
So this model of maximizing engagement what we found out in the in the Wall Street Journal articles and I could run through some of the, you know the things that we found but basically Facebook knew, for example, that that they were increasing some of the negativity in society, and they
knew that they knew that, but Zuckerberg didn't want to change the ranking algorithms of Facebook, if it was going to hurt engagement. And now you could say he's just greedy or he just wants the profits, or he just needs to keep his share price up.
He also is bound because he set up a set of incentives all of his employees all those people at Facebook, most of them are incentivized by how much they can get engagement up.
So, all throughout the company, imagine you have a bonus structure where everyone's, you know, salaries and paychecks come in through maximizing engagement but then you find out that let's say 50% of that engagement is causing genocides and
Ethiopia is causing body image issues and kids, you can't say we need to have our engagement because now all your employees are going to leave, because they won't be able to get their benefits you've actually gone against the own incentive structure for your own employees.
Yes. So what what is it so I want to know what it is causing. And I'm going to add a little bit of pressure on you, which is that we have two members of the judiciary committee.
By the way, I'm in Belfast. I'm actually here in conflict capital of the globe.
And that's why I'm so happy Daniel that you're involved but I just got one more for you.
You've got two members of the judiciary committee say that fast five times.
What should they deal with us. What should they know if I gave you 30 seconds.
What should they know that you know about what's happening.
I think Daniel in a moment I think we'll help elevate the conversation to what kind of changes needed because unfortunately while I wish that there was, you know, a couple of laws or bills that we could pass to get to some better state.
The challenge is that this is based. This is now baked into the, the infrastructure that we use is now the fabric of our democracy and virality, the thing that is causing some of this I think of this everyone's now familiar with the idea of a lab leak and
Wuhan, the Wuhan Institute of virality that was doing potentially gain of function research on what viruses can go viral. Well people now know what are not is the idea of something that can go viral and how many people does it infect.
The purpose of Facebook is to be the Zuckerberg Institute of Verology. The purpose is to create and allow for things to go viral across the world and be spread to millions of people, and to literally take the, the are not to be as high as possible
we want it to infect as many people and spread to as many people because that makes engagement go up. And that's the core thing so you say what's the law that we can pass what's the issue that we can change.
It's going to be as simple as that I think we have to change the nature we can't have it be the Zuckerberg Institute of Verology. It has to turn into something safer.
So, I will warn you that there is a Facebook executive that's on this conversation so don't be surprised by challenging Harry Clark, who is one of the best minds in communication public relations.
I think is part of the Q&A one more and this is going to both of you.
Why not just boycott Facebook. Why, why, why is that a strategy you're considering.
And I don't want to, I don't want to sandbag you someone from Facebook is going to hear this. Why not boycott Facebook. He wants to know.
I mean, if people could boycott Facebook and there was meaningful alternatives that were not the same problem and tick tock is basically has the same problem YouTube has some many of the same problems Snapchat has different but some of the same problems.
So boycotting and then going there's nowhere safe to go. That's, that's one of the issues. And the second issue is that you can't really boycott it when your life depends on it.
So one of the problems that's actually in the article about teenage girls is that you can't actually say it's not an individual choice to say I don't want to use these things because I'm going to ostracize myself.
And if all my friends are still on it, you'd have to get the entire world to boycott it together and move to something else.
Because it's it's fundamentally been baked into our lives small businesses have to use it to advertise how else they're going to reach their users and their and their and their customers.
So they've owned the capacity to reach people if we want this video to be just as many people as possible we probably want to post it on not some random tiny video site no one's going to click on but you want to post it on the one that gets as many views and likes etc so you can post it on Facebook and you're going to post it on YouTube.
So they have a monopoly on reach, which makes it very hard for people to boycott it and say let's go somewhere else.
You, even though you're involved in this issue I look at you as being essential to to public discourse, because you're looking at it, you're looking for solutions.
You're looking for results.
You're one of the strongest thought leaders in how we talk to each other now in society.
I ask you the question I asked Tristan, would you recommend a boycott, knowing that there's a Facebook person on this conversation.
And do you have any solutions to the problems that Tristan has raised.
I think it's kind of like what Tristan said that there's a monopoly but not a monopoly in terms of a government contract monopoly but in terms of a network dynamic monopoly network dynamics create natural monopolies where one, as you get increasing
the numbers on the more people that are in a network, then you fundamentally have to engage with that thing because there's something like exclusive value offered there there.
If somebody decides they're not going to sell on Amazon and they have a small business they just can't compete with the ones that are doing that or similarly if they're advertising on Facebook.
So one of the things is when we built the laws around monopoly and antitrust network dynamics didn't exist yet those were built before internet and those dynamics so we actually have to take the emergence of the internet and the emergence of network dynamics and met
kaf law and say we actually have to rethink that monopoly didn't just mean a crony capitalist government contracting.
Can you, for those of us who only went to the University of Pennsylvania can you dumb it down just a little bit so we, so we understand what you're talking about.
Nobody wants to use 20 different social networks and have to remember all the logins and find some friends in one place and some friends in another place just like they don't want to use 20 different kinds of currencies.
So if there's a currency that everyone accepts that currency kind of gets a monopoly value.
If there is a network that everybody's on, and you can see your friends from high school and your family and the news and all the things you're interested in with one login, like those stats you showed people said it was easier and made their life worse.
Every one who has conveniences where they don't exercise and don't do the things that actually strengthen them or read or study there's a lot of things that make life easier and worse.
And so, where something has a network dynamic where the more people that engage with it the more value it has because now everybody's producing content, everyone I want to find is on there.
The AI will curate all the content to show me exactly what I want to see, but which part of me wants to see.
Well, it's going to the AI is going to optimize based on my behavior and how long I spend on site and how many things I like and comment on and share.
And it happens that the things that appeal to my existing biases and increase my sense of certainty in an uncertain world, and the things that scare me and kind of create emotional responses that make me less clear about the fact I don't want to be on Facebook and go do other stuff with my life.
And the things that reinforce tribal identity, maximize time on site and engagement.
So, it's one of those things where you can manufacture demand from the supply side and then say we're just giving people what they want, but you're appealing to the weakest lowest angels of people's nature, and then doing so with radical asymmetries of power.
So, Richard Dreyfus who's always been a friend of these Fridays with Frank and he's just his brain is incredible.
Is there proof that social media is leading to instability, leading to anger.
We may think it.
Daniel is there proof of this.
Well, this is what you were talking to Tristan about regarding what the Wall Street Journal has been showing this week. And they're obviously previous cases and it's this week and what will be continuing as more information comes out is stuff that Tristan and Jared Lane here have been saying
what happened for nine years because the business model guarantees it.
Now there is increasing proof in the form of hard internal documents and disclosure.
But for anyone who's been kind of paying attention, the business model of maximizing people's time on site and maximizing engagement combined with the technology of behavioral modification ai's was bound to be antithetical to democracy and antithetical to health so Tristan
can give the proof, but for the people who've been paying attention it was.
It's kind of like saying, if you is there proof that deforestation is happening and as soon as you're looking at the financial incentive to cut down the trees in an area where the trees alive or worthless and the trees dead you're kind of like it's going to happen.
Right, in the same way that trees worth more dead than alive and whales worth more dead than alive. In this case, our attention.
It's easily more sought with outrage.
It will be that will be the profitable model us being happy or civil talking to each other off screens and not on screen is not profitable for any of the social media company specifically some of the data and again I recommend people check I think it's the third article that the Wall Street
Journal released. They talk about actually due to some of my own work Facebook changed its core metric, it used to be maximizing for time spent I was part of a movement called time well spent that was my first head talk.
Facebook decided actually Mark Zuckerberg wrote in his January 2018 post his yearly goal is his new goal for the year was to take Facebook in the direction of time well spent not time spent he took my words.
Then he said we're going to change the way we measure success at Facebook, we're going to use something called meaningful social interactions MSI.
And this Wall Street Journal article I recommend everybody reads it showed how meaningful social interactions they were trying to give the sign different points so for example, you got one point, if you for a post would get one point if it had a like.
It got five points if it got a reaction or a reshare without any text. It got 15 points for what they call a non significant comment, and then it got 30 points for significant comments and significant reshares.
What that really meant was the more long comment threads and article created which is say more arguments, the more those things got boosted to the top.
So whenever there was an argument, it was like hey let's put that at the front and center for everyone's feet, and then do that in a decentralized way for the entire world all at once for two billion people.
And when you basically highlight divisiveness and disagreement and in civility, which is the thing Frank that you're trying to find one thing you and I were just at the milk and conference.
And there's a lot of people who are funding things like hey how do we do American one room how do we fund with hundreds of millions of dollars of depolarization for the country.
And let's have people together physically in rooms talking to each other that's great. But how's that going to compare to the four hours a day people spend seeing in civility every single day.
And if 90% of people became civil, but only 10% are left that are in civil.
Then what does Twitter and Facebook show you will they only show you that all the bad faith in civil people so that keeps just completely blasting over and plastering your whole feed.
And so it continues to look like the world is in civil even if many people are starting to get better.
I should have that system with democracy period open societies cannot allow this situation to be and Daniel I'd love for you to speak about that because I think it's the reason why I wanted to have Daniel here Frank is, I think this isn't just about less toxic social media
how do we just rain in let's take the reins and if we just move at five degrees this way we would suddenly have a better democracy, plus, you know, Facebook, we have to look at a deeper problem statement there to get to where we want to go.
Okay, so I'm going to ask both of you, and you can go another order, solve it.
By the way, we've got a lot of parents on this. And I'm going to ask you in a moment to scare the living hell out of them.
Give me your, your most frightening conclusion based on all the research you've done on young people.
Before I do, we're adults. Do either of you have an actual solution that you're going to be presenting to Congress.
Either of you.
Daniel you want to try to describe.
I can say, I can say some things that would be directionally right.
We read all the documents around the founding of this country, and know that the idea of universal public education and a adequate fourth estate were considered prerequisite institutions for democracy to function, the people had to be educated.
And they had to have access to the information to participate in governance.
There's a very deep question of
hold on one second.
Those people who are watching because you're actually we're 25 minutes into this. And I can see the number of participants is actually rolling.
I'm going to focus on kids and about five minutes. So if you guys want to send out an email want to send out a text to people saying tune in.
And about five minutes we're going to specifically focus on what social media is doing to your children.
So I suggest you stay honest, Daniel, please continue.
So you can actually see how the critical role of the fourth estate following the printing press and it's been well analyzed the role that the printing press had in the formation of democracy we don't need a small educated nobility who rules everybody because everyone can have access to
books and newspaper they can be educated and we can come to a town hall and participate in our own governance.
But this was based on the idea that we could get something like fair and independent news and all read the same thing and then be able to have an educated discussion about it.
So when you have an internet where there's radically more information than anyone could begin to parse what information you see ends up being determined by curation processes I'm not going to see all the videos I'm not going to see all the news I'm
going to see all the posts. And so it's not like we respond as rational actors to the best information we respond to whatever YouTube's algorithms and Facebook's algorithms put in front of me, and they put it in front of me based on a business model.
That's maximizing time on site based on engagement and it happens to be that that which appeals to my existing biases and emotions maximizes time on site.
So someone on the far right and the far left when they're looking at their news feed and how they're coming to understand the world might see nothing in common.
And so, and yet it's representing the world to them so you have to say, if democracy doesn't exist without a fourth estate and people having a shared sense of what base reality is.
And the internet, and specifically, network curation based internet has destroyed the fourth estate irrevocably.
How do you remake a democracy post internet network age, because people can't do shared choice making if they don't have a basis for shared sense making of what's going on.
Yes, answer that question and how do you do it.
It's the right question, but I'm pushing you now. How do you do it. Well, you can see that China decided well let's control our internet to not have radically divisive ideas that end up making people against being good citizens.
And you can see that there's an effectiveness in that but it's antithetical to the idea of an open society.
So you either keep an open society with these type of network dynamics and it just becomes increasingly chaotic and fails, or you try to apply the China model those are the only two things currently as the possibilities and what we want is how do you have something
like open speech, but with this degree of radical amplification possibility that doesn't become total chaos, and you have to look at what is the incentive for the amplification.
If there's a tool that can curate it and make stuff radically more amplified what is the incentive guiding it.
To say for instance, if Facebook is the most powerful behavioral modification machine in the history of the world that can gather micro targeted information on people and then specifically put information in front of them to control their behavior for advertisers.
But the people who it's gathering information about an influencing are not the customer, but it's gathering privileged information about people to then sell it to the customer who is the advertiser.
Maybe a break of a fiduciary contract where you're not allowed to gather privileged information about someone and then use it against them. If the user was the customer, rather than the advertiser being the customer.
And as a result, the optimization algorithm was not to sell people ads or to maximize time to sell them ads but was to find the metrics that actually correspond to people's real quality of life and the AIs were oriented to that we might start to get somewhere, but that's the beginning of a radically
business model in ad based business model with AI controlled behavioral mechanics will break democracies, they don't go together.
I trust down I know you agree with this but can you explain it to someone who only went to pen.
Daniel, half of Congress is not going to understand this.
They still call the tape recorder a machine or sorry a microphone speaking the speaking the machine now it's actually a microphone.
They don't even know what the internet is just on go ahead.
Well, I think the thing that Daniel saying is that an advertising supported.
I imagine, Frank, I put a brain plan in you, and I actually talked to the guys at Neuralink once about this right imagine Neuralink Elon Musk's Neuralink project I'm going to put a brain implant in your brain.
It's going to shape the thoughts and give you thinking superpowers.
But let's imagine that brain implant in your brain it's going to intimately shape every thought that you have from from the moment you wake up to the moment you go to bed and your dreams that someone attached the advertising business model to that Neuralink brain implant.
So now you start having thoughts that you didn't even intend to have and it's actually in control, we would just say immediately when I say it that way.
It should be clear, we maybe we can have brain implants, but we certainly would never allow brain implants with an advertising based business model.
What Daniel is saying is that we cannot have democracy, and the primary brain implant of that democracy, be an advertising based business model.
When Daniel says fiduciary what he's referring to is a brain implant that would have your best interest at heart just like a doctor theoretically is supposed to have your best interest at heart.
And a psychotherapist you're going to tell the psychotherapist all this privilege deep information that's deep in your psyche they have to have your best interest at heart.
What we're saying is such a deep change that we have to have technology that's humane with our best interests at heart.
What's in that such an uncomfortable conversation is that I believe Facebook stock price has not moved that much this week, despite the fact of these these awful revelations, and it's worth about a trillion dollars and that trillion
dollar valuation comes from the advertising based business model so it's as if we had an entire industry of psychotherapy that was based on a manipulative business model that was worth a trillion dollars.
And now we have to switch to what does it look like to be in the interest of people. And the question is that's it that's a that's a very dramatic economic change. So I think it's more than our brain wants to shy away from that because it's so uncomfortable that we'd have to make a
change as deep as that that's one of the big things that has to change.
I know that one of the comments is, maybe we need more people like you in Congress, that it's not your fault that you're speaking the truth it's their fault for not understanding it, and actually that's not such a bad idea.
I wanted to speak to what you said earlier about what people in Congress would understand.
If because of who the people in government are or the structure of government, if it cannot understand the nature of the issues it's supposed to regulate, and particularly as technologies evolving rapidly faster than the people who are in there are able to
understand the consequences of then it will just break right if the regulatory apparatus can't understand the effects of what it needs to regulate it will just break.
And this is the key thing that we're talking about is we're right now talking about the case of social media tech following a business model, but we could also be talking about crisper and tabletop crisper emerging, where we're getting very very close to cheap
to make bioweapons for everybody. And with regard to AI and generative text AI, we're getting very very close to the ability to make content in your voice, saying anything that anyone can do, and flood the internet with more information that passes the
And, and so, and Elon said this he said, if we wait to regulate AI and the other technologies that operate this quickly AI specifically who's talking about till after the effects have been seen for as long as we did with cigarettes or dbt it's way too late.
The effects will have been irreversible.
So when we say exponential tech what we mean is exponentially faster to scale exponentially larger effects that can happen from exponentially smaller groups of people.
It doesn't take stay actors like it did to make nukes to make AI weapons bioweapons crisper weapons.
So, the big question becomes in the presence of the speed and scale of emerging technologies are processes of governance are just inadequate, they're too slow.
They are too divided and this is why China has done a good job of saying no we actually have to control these technologies otherwise they'll break the country how do we do it, but it's in a particular direction if we want something like an open society and the presence of exponential
how do we make a regulatory apparatus capable of regulating what it needs to in time and ahead of time that is aligned with the civil values of an open society that's the central question of our time, I believe.
I want a simple number, a number.
Daniel what percent of Congress house in the Senate is really intellectually not ready to tackle this issue.
I don't know. I don't know them enough.
What would you guess, I would trust your guess over mine on this.
Okay Tristan you've been testifying so you I'm not letting you out of this. What percent don't really shouldn't be regulating this that they do not know.
I think it's very understandable why people are skeptical of Congress to regulate this effectively. When they hear senators ask Mark Zuckerberg questions like, how do you make money and he responds famously, Senator, we sell ads.
If I was Zuckerberg I would have paid for that moment to happen and maybe I did, because it generates the impression forever in people's minds it sticks Frank in your language into the minds of the public that government cannot regulate this right so that I've created the outcome that I want and
someone I noticed in the chat was talking about do social media companies own the members of Congress well let's say that this narrative gets really strong well.
It's a $10 market cap corporation it's not very hard to start buying off any of the members of Congress that get critical, and a couple will make some public statements but what's really what we're trying to do here and what Daniel's really saying is that this is existential for our society
continuing to work. This will break our society we've been saying that for eight years. The social lemma says that it's clear than ever January 6 I had text messages from from people Joe Rogan saying.
The social lemma, you know it's so eerie all this stuff is coming true, you know when I remember in the film people may remember the guy who invented Facebook's business model Tim Kendall.
He was asked on camera, you know what are you worried about is the consequence of this and he was, I think he was recorded saying this in 2019 or 2018, and he said Civil War.
And I remember that I think Netflix wanted that to not be in the film because it sounded like it was too aggressive a statement to make it sounded like that wasn't where we were.
And when people saw January 6 and they see the results and people should read this Wall Street Journal article about the outrage economy and how it how it drove up basically more insanity.
It makes perfect sense and the point Daniel's trying to say is that we were trying to ask the question if we don't want to beat China beat China by becoming China, then we have to develop an open society alternative to exponential technology that does not result in catastrophe and chaos.
And we're spending some time in Washington DC and part of the reason Frank I wanted to do this with your audience because I know you have a lot of listeners that are in DC and that are that are curious to get to this point is that you know we're we're trying to see who resonates with this and wants to have a serious conversation about the more comprehensive change.
That's that's needed.
I'm being asked again and again, both and people who are texting me emailing me and in this comment right here. Everybody says, we got to do something, but I don't trust Washington to do it.
What's the answer.
They don't the direct language.
I don't want Washington making the decision for me or my children, what we're going to see.
I can speak to this is one of the things we've seen during cove it is the breakdown of the sense of a shared trustable authority or institution and when it comes to news media and even when it comes to scientists and public intellectuals weighing in on the science there's just radical polarization of what would be a trusted
and so yeah people rightly don't trust Washington, but they would also rightly not trust private companies that have interests that are exactly opposite of their own and radical asymmetries of data manipulation capability.
So the question becomes, when you have technology that is this asymmetrically powerful who could you trust to govern it, given humanity's track record with power.
And yet, like whoever had the cannons in the past is nothing like who has the ai's and all the world's information the behavioral dynamics on your children.
And so as we follow an exponential curve of power. There's this core governance question of we've never done all that good a job of being great stewards of power and now we have radically increasing exponential power how do we govern it.
The whole thing with we don't trust Washington is Washington was never supposed to be a thing separate from of foreign by the people governance it was supposed to be that the state was given the ability to regulate predatory market interests, while still allowing healthy market
interests to ensure the values of the people that were encoded into law could be implemented with a monopoly of violence, but the state could only check the market if the people check the state, and that like everything you can read by the founding
structures within the declaration and the Constitution was all about the people's ability to oversight and check the state and be engaged in governance.
When the people stop checking the government, the government gets captured by the market and you get short term ism crony capitalism regulatory capture those types of things.
Currently, there is a cultural revolution that has to happen of people who get committed to actually being able to make sense of reality together and make effective choices together and participate with the remaking of 21st century governance 21st century
democracy republic open society whatever you want to call it, and the creation of institutions that actually can be trusted because of the right types of checks and balances on power and oversight process with this technology.
Okay, I'm going to ask is, I'm going to read it from Eric Schwartz, due to forceful regulation banks are obligated to know their customers and there's no room for anonymity.
Why shouldn't social media be governed the same way if there was no anonymity, and the platforms were obliged to know how to access all participants with that help.
I'll just respond something there we've been saying also for about five years, the just like banking has no your customer laws and so on KYC.
There is eventually especially going to need to be that with social media and online publishing because of what Daniel was talking about with with GPT three so for those who don't know when you say GPT three, or deep fakes people have heard about this term right
quickly say what this was, Dale and I were actually just with one of the top AI research people in the entire world, and they were saying how much this field has progressed you can basically say, write me a novel in the voice of James Joyce about the topic of, you know, democracy
or something like that, and it would write you, you know, 100 page book, I could say hey write me a article about why COVID, the COVID vaccine is dangerous and with lots of charts and graphs, and, and actually criticize with the names of the logical fallacies that
people are using that that they're that makes them wrong about the vaccine, and why they actually shouldn't trust it, and it'll actually generate like 100 page research paper with charts and graphs that it'll take biostatisticians like a year to actually parse out what's right or what's wrong about that.
That capacity to instantly flood the internet with information and by the way for those who don't believe me do a Google search for open AI, and I don't know what they call this video they can actually do programming so you can actually tell this GPT three AI.
Hey write me a computer program a game where there's a moving asteroid whenever I hit the letter the left and right arrows it goes back and forth, make the asteroid bigger I say all that and it writes the entire code of the video game for me.
I'm just saying a natural language that I want. So in the next election Frank we're moving to a world and this is not sci fi so people people might hear this as alarmism or moral panic and for who believes that this is moral panic, like, listen to the fact that we were saying these
things eight years ago and all of them come true.
We were about to hit a world where in the next election midterm elections for those who don't remember in 2016 there is this popping up with these fake local news websites Denver post the Cincinnati Cincinnati Herald I don't know the names of the fake ones you can basically make them up.
GPT three you can also say spin up a local news website with the fonts and everything and the big sections at the top it'll generate the entire website and it looks perfect it looks totally indistinguishable, then generate lots of articles about why the other side is untrustworthy and he beat his dog and whatever.
And it'll actually just generate thousands of these websites. We're getting so close to that being possible and the reason I'm saying this is to answer Eric Schwartz's question about why we need to know our customers why we need verified identity.
Because if we don't have the sense that someone who generated this comment, or this post or this text is a human being that's traceable to some kind of ID, we're not going to have a working open society.
So table stakes going into the future is we're going to have to have some kind of zero knowledge proof identity and people who are following this closely know that that's one of the big changes that's going to need to make.
When we talk about Congress regulating these issues we're often talking about looking backwards in time at the, at the historical issues how do we deal with these common threads on Facebook or like the stuff from like four years ago issues.
We're missing the fact that what Daniel saying is the first derivative of how technology is constantly changing and generating new issues second and third order effects faster than any of our governance process is keeping up.
So what we really need is a new kind of governance process. We need to meet Manhattan project for governing exponential technologies that move faster and I would actually say, you know, similar to the Einstein Syller letter that was written to FDR in 1939 that said, if we don't do this and open open
society values don't have nuclear bombs if not season gets nuclear bomb or if communism gets nuclear bomb.
They will run the future because whoever wields the power of exponential technologies will run the world. And we're at another choice point today, where we have to have open societies consciously employ the technology and bind to the predatory negative aspects.
Otherwise we're seeing what China is doing and moving much faster.
They say well I don't want us to become China and so there have been several comments about that, that just because China is doing it doesn't make it right they don't value freedom.
They don't value democracy they don't value the things that we insist on.
I agree and that's why that's why what Daniel was saying is actually go ahead Daniel.
I'd like to connect with Tristan and saying to the question that you asked about rigorous identity. So, obviously, being able to know was this a human that produced it or was this an AI be pretty valuable.
But even just, is this the human that it seems like it is, or is this a fake account sock puppet that is part of a state actor propaganda farm. That's pretty valuable because we've forensically find those types of bought farms and fake actor farms all the time.
What they can do is use Facebook split testing algorithm to see what is sticky is for certain populations and continue to modify the content they produce even without AI to push vulnerable populations now the AI just gets to take that exponentially.
So, obviously, rigorous identity would be valuable, but then this question that comes back again it's like saying regulation be valuable, who do we trust to have the rigorous identity associated with all of someone's online behaviors, including through changes in
government that will never forget that where now some despotic government comes in in the future or someone that I didn't vote for or didn't like but now that is an irreversible memory.
So we get to see on either sides here we're like okay, we actually want anonymity because we don't trust anybody on the other side the anonymity makes it to where there's no possibility for justice or knowing what is true or not true.
This is a hard issue. And it corresponds to
it's pretty hard as Tristan was mentioning about the war for the arms race for nukes.
It's pretty hard to make nukes enriching uranium is difficult the precision engineering that was needed for the rockets was hard. It's not hard to make
weapons anymore home based drones with homemade bombs on them it's not hard to take papers that are written about the cutting edge of AI and reverse engineering and make crypto cyber weapons and weapons.
The thing about exponential tech is that the idea of decentralizing tech we have this kind of romantic Silicon Valley idea of this means democratized power for everyone but it also means catastrophe weapons for everyone.
So when you have catastrophe weapons for everybody and it's non state actors and there's no way to even be able to visualize it you can't have mutually assured destruction, you can't create equilibrium.
So then the, the only other answer so far has been okay, well either catastrophe weapons for everyone, if you want something like freedom or ubiquitous surveillance, ubiquitous surveillance is a good answer if we know what everyone's doing in their basement nobody can do work money
those two answers are both so terrible we need a better answer. So in the presence of decentralizing exponential power.
How do you not have ubiquitous surveillance and not have centralized access to that personalized data and yet still have something that can create anti fragility in the presence of that much power that even small actor groups could engage with.
There are some answers that are neither just allow the chaos to continue or become oppressive but we'd say civilizations typically teeter between the civilization is how do we get a lot of people to participate in some way that creates order.
We can get the order through imposition and it becomes increasingly oppressive or we fail to get the order and it becomes chaotic and it fails on either side.
The idea of democracy is that we can have emergent order, rather than imposed, because we can all make sense of the world together and make sense of each other's values and have some basis for shared choice making.
This is ultimately cultural.
I promise to focus on kids, and I've actually got a young person is watching this right now.
This is her question. I'm a senior in high school, inspired after watching the social dilemma and spending a year researching practical ways for young people to limit the use of social media.
I'm curious to know your view and the following. How do the tactics to curb social media use differ by age youth groups, specifically pre teens teens and college.
What advice, what kinds would you give her as she seeks to understand the difference between those three age groups.
Can you say the age groups again pre teen teen and pre teen teen and college, pre teen teen and college. I mean, I will say that I'm actually I don't consider myself an expert on the developmental psychology of children at these
ages what I can speak of is so long as the business model of tiktok and snapchat and Instagram is.
I have to race down your brainstem and create artificial social obligation and artificial social reciprocity that you feel the pressure of getting likes if the other guy doesn't and you don't get it.
That thing is just not compatible with children's development. It turns kids into validation seeking machines, and it creates social pressure and anxiety.
That's simply not it's frankly it's not good for any of those populations right.
It's not good. I don't feel good how none of us feel good when we feel like, you know, frankly, I'm sure you get this all the time so if you get a comment on Twitter you posted Twitter a lot I follow you.
And you get 100 comments on a post that you make and 99 of the comments are negative are positive, and one of the comments is negative. Where does your attention go.
Of course, of course, you've got 99 to one positive.
But our neutral, our brains focus where on the negative and do you think you're alone in this experience or do you think that everyone feels that and do you think that children's feel it more than you are less than you more than you.
So we what we have is essentially a system that creates overwhelming pressure and negativity and the conditions for just not psychological health.
Daniel has this nice line about how what would be how do you measure the health of a society. And it's a hard thing to measure the social health of a society but you could measure it as the inverse of the amount of addiction in society.
I don't know if you want to riff on that but I don't have an answer to your.
I would like to answer her question before.
Because the thing Tristan is saying relates to the question someone asked about boycotts earlier.
When you have a trillion dollar organization with two billion people's behavioral data run by a eyes and then you have a person, just a little person.
The asymmetry of that info war, because the person wants to control their own thoughts and behavior but Facebook wants to control their thoughts and behavior, but it is a mini orders of magnitude asymmetric info war to control their thoughts and behavior.
That's such a problem that you can't just say well let's leave it up to the individual person. It's like saying, let's leave up to individual people turning their lights off as the solution to climate change and environmental destruction.
I know that just really doesn't work this needs solutions that are at the scale of where they're coming from, and switching the burden of responsibility from the joggernauts to the individual is just like a bad move, both ethically and from effectiveness.
So that's what Tristan trying to get to, but we have this person here who's asking a question about what she can actually do so I want to speak to it.
By the way, this has been, this has been Jordan's focus now, since you all created, you got people agitated you got people focused.
Now you got to start to deliver for them. What would you say to her, not going to make a distinction between the three age groups I'm going to say what's true in general and then the developmental application of it is something that you should totally work on.
People are more susceptible to addictive things what we'd call a hypernormal stimuli stimuli that gives more dopamine or hit faster whether it is sugar or drugs or social media type stimulation or porn they're more susceptible to that.
When they're in a hypo normal environment meaning they're less fulfilled in an evolutionary environment in an evolutionary environment humans evolved to be part of a tribe where you were having a lot of rich social interactions a lot of embodied movements a lot of time in nature.
So, those types of things. So, the lonelier people are the more susceptible they're going to be to Facebook and Instagram, the less creatively fulfilled they are.
If you can find groups of friends groups of people and create richer possibilities of offline engagement. It's the thing that'll help them the most.
There's also a place where there's drum circles every Friday night and everybody's dancing and having drum circles if there's musical things where they're getting together and having kind of jazz fun stuff if there's craft places if there's places where they get to have circling to do meaningful like sharing about what's going on for them.
People feel a richer fullness and other opportunities they will be less susceptible to that, then you can actually start to have not only are they're more fulfilling other opportunities, but there's actually social connectivity and status associated with something else.
I've got seven minutes to go, and there are more people on this now in the world after 10 minutes. I've never had that happen in any of these.
Jared Carney asks the primary issue for me is not manipulation, although it's a big issue. It's surveillance.
If Facebook's business model is predicated on conflict plus knowing everything and trying to steer commerce.
How do you counteract that.
I mean this is really the topic of Shoshana Zuboff's book surveillance capitalism that when you control this much of people's lives and you can let's say someone builds an alternative social platform funded by venture capitalists there's got some investors I'm sure on this call.
Many people might be wondering well what if we funded some alternative social network that because we want to do it in a way that doesn't capture people's data.
Well that will be funded by venture capital venture capital expects, you know, big multiples of returns. There's actually no way to exit that except by getting acquired by one of the existing big surveillance capitalism companies whether it's Google or Facebook, etc.
You'd have to do it in some way where it's an independent thing, something more like a Wikipedia or a blockchain type project where the data is kept separate somehow.
But you're not going to be able to transition these existing platforms Daniel do you want to jump in.
You could.
You need something that is like the equivalent of HIPAA.
So, which is the medical privacy regulations.
So, if I have a medical file so that I go into ICU somewhere they can pull up what I'm allergic to and those types of things.
It's very sensitive information about me, everything that's in my life medical file that information could be sold to drug companies it could be sold to lots of places it would be interested in doing stuff with it it's really really important that that isn't sold.
So there is state based governance of that data and how that data can be shared and not shared if.
And so, when you're saying manipulation is second to surveillance the purpose of surveillance is manipulation, right the gathering of the data is to use the data for a purpose, and whether it's to affect how you vote, or to affect your market
or to affect how you affect the cultural zeitgeist that will affect market behavior and voting of others, or to be able to arrest you for things that we decide later or seditious or whatever it was.
Ultimately it's the control of behavior that we're gathering the data for.
And so how do we create safety of the data and this is where the question has been do we trust Facebook with it no do we trust Washington with it no.
Do we want there to be a place where there is data so that we know that it's a person and not a bot putting the information out yes so do we need to create a better checks and balances and oversight process to ensure the trustworthiness.
Do technologies like blockchain do part of the thing where you can do provenance on data and see how it moves and have things where the data only becomes released if certain flags happen otherwise it's in a decentralized rather than the centralized database there's
partial solutions there and we could work on full solutions.
The hippo kind of thing it's that that data, the there's a Hippocratic oath that is saying that data is being gathered by the doctor who has serving your interest not the pharmaceutical or anybody else's interest in mind and we can see it's not perfect.
If Facebook's business model shifted where the user was the customer.
And either that and or as a state say got made into being a state utility so the interest of the state which would mean that people didn't take views in such antipathy to each other in the state that was basically like second order trees and
in addition, but where the interest of the integrity of the state and the interest of the well being of its citizens were actually what was directing its AI and its use of that data, as opposed to advertisers and there was the appropriate privacy and protections
on it and I got to adjust the settings and say, I'm interested in learning these things I'm interested in being exposed to these other kinds of ideas here's the ways that here's what I want my time on site to do of all the information here's what I wanted to curate for me.
Now we have a situation where the death the behavioral data that happens by the fact that I click on stuff. I can't have technology where I click on stuff and not gather behavioral data, but who is storing it for what purpose, and how is it being stored becomes really critical and it could be
stored where the legal binding of it kept it from being used for purposes other than the ones that I am actually consenting to.
It's like personalized learning Frank I mean think about things like Khan Academy where it's your yesterday you're personalizing information you're gathering lots of information about where people look like they're getting stuck or what lessons they might want to learn
more of but the purpose of Khan Academy isn't to manipulate you into clickbait and to make you hate the other political party it's to help increase learning right so you could have.
That's the kind of thing that we're talking about is personalized in the interest of helping society get wiser and more thoughtful not the direction of whatever gets their attention.
I wanted to answer the question you can't get these.
This conversation doesn't happen.
There is no news program that has a conversation like this like I'm embarrassed to have to keep saying to Daniel to simplify. I shouldn't have to do that.
Just like we said, just like we said that the fourth estate has broken obviously so his education because the idea in the founding of this country following the enlightenment and modernity was that everyone could be educated well enough to understand the issues that
are going to be created that would affect and bind their life if I'm going to be bound by law I need to understand the issues well enough to get to have a say in that. If the people are not educated well enough to have a say in the law that's going to bind their life it's not a democracy it's just a story or a simulation of it
in which case monarchies might actually be better and not have all the attention go to flipping back and forth every four years and internal divisiveness.
If we really wanted to be a democracy and effective for the state and education are prerequisites at the level that is needed for people to understand the issues well enough to participate now we have to say, using AI and attention tech and all of the modern technologies
how could we make new better educational systems and better participatory governance systems where everybody can't fit in the town hall but everybody can give input that now these a is can semantically parse and help create propositions that are not best at interest group propositions but that are saying
the best proposition that fulfills the interests of everyone look like and now we get to work on proposition crafting. We could use these same technologies that are destroying open societies to build better ones.
That though has to become the central imperative of the time, and it does require a new cultural enlightenment that does require an educational rise to understand the issues well enough, or it just doesn't matter it's over like if Congress and the public.
If we understand the issues well enough, then of course the corporate interests are just going to run and authoritarian nation states employing exponential tax see both Facebook and Google on one side and China on the other side are deploying exponential tech towards purposes,
but neither of them are open societies. If the open societies are not also developing and deploying where the power is then they will just lose.
What we're saying is that the open societies have to develop and deploy the full suite of modern technologies to create new digital era open societies that can protect against catastrophe, but also protect against dystopias.
And that is the central imperative.
The last central imperative which is to keep people alive during this at the, hopefully at the back end of COVID, and I don't know of any example that frightens me more or angers me more than the crap that's put out against the vaccines, and I go absolutely crazy.
And I read it, and I shouldn't, because it makes my head explode.
Help me here. What can we do, we are coming down to the end of the vaccine process, and we are not going to hit herd immunity, and the US is not even in the top 15 of vaccines anymore, because of the crap that's coming as being generated in America about from social media.
How do we combat it when it comes to health, because Tristan, your idea that they're going to be able to create these stories with these reports, I've read them, I've seen them.
They look real. And I know they're not.
How do we combat it right now, because we don't even have a year to wait on this, we have to do this right now.
Great question.
You.
Sure.
We're not going to that's just that just loses.
In the same way that we're not going to prevent climate change from creating droughts and affecting areas of poverty that will create massive human migration.
There's a lot of impending catastrophes that will just happen and we'll just lose that we, we could have done a better job with this pandemic at a million points.
And so this is why we're thinking a little bit more long range about what are the even worse catastrophic things that we possibly have time to address and why do we, why are we doing so badly at all of them and what would it take to do a better job at all of them.
Because if we can't coordinate for, for climate change or overfishing or biodiversity things or nuclear deproliferation or stopping AI arms races or stopping CRISPR arms races, or getting misinformation right.
We just fail at everything. So ultimately we have to get better global coordination capacity for global level coordination challenges. If we get that we get all the other things otherwise we don't.
So you're talking here about a shared sense making of what is true what is base reality but in a world where there's a breakdown of trust and a breakdown of trust and what is legitimate authority you will not get shared sense making so then you either do have to become China and say, I don't
care if you don't believe it and if you think it's terrible we're going to force it on you, or you have to say well, we're going to just fail, or you have to say oh we actually have to be able to recreate legitimate authority and not just people's fall see, faulty belief in it but a good basis for it
how do we do that, how do we recreate a shared sense of sense making but also not just that the social contract and social solidarity that if someone thinks something different than me.
And they're a fellow countrymen I don't just instantly have antipathy for them I try to steal man rather than strong man, what might be true what values might they hold in their perspective, because if I just go to a culture war with my fellow countryman and China doesn't have that
but we get to amplify our net antipathy towards each other using exponential information tech then our country just destroyed it's over open societies. There has to be a process of how do we do better sense making, but also better understanding of the partial truths and the values in each
other's perspective so that we can find new attractors together.
Daniel, Daniel, if you're right, we're screwed.
Yeah, if your conclusions are right because we're not going to be able to do the things to address the challenges challenges that you lay before us, it cannot. It will not happen.
Not not in the time scale of the issue you're focused on.
For this now we're screwed.
Tristan you're gonna have the last word you do not have to make people feel good. I want you to end in 45 seconds with what you want people to take away from this conversation.
Don't screw it up.
I was, I was just going to say that I think people think that trust can't be recovered from where we are. And I feel, just to say something very concrete is that if people were to communicate and feel like they're in a way that they reflected why people
don't trust the CDC that I've been shown talked about. And if those institutions came out and said, Yeah, we did flip flop on this and this they people need to feel like they're being told the truth with earnestness and sincerity, and
not gaslit and I think the problem in communication is when you communicate to large audiences and you feel like people aren't going to get it. You simplify the message, and you say something that's not completely true but you force it down people's
those who know that that's happening, get rebellious and we're not going to create a unified understanding until we come with sincerity and I think trust is the sort of the fuel that undergirds all of this conversation and I feel like sincerity and earnestness is the is the vehicle to re establishing that trust.
And I feel like that's what we're, we're trying to do now and just to name one thing is Daniel and I are, and some others are really looking to see in Washington DC, especially in the national security community, who resonates and understands with what we've laid out, and
we're not trying to be pessimists we're just very we're trying to be very clear about the space space of problems, and what it will take to actually look ahead. So we don't just, you know, have another coven and we in climate change we get, we mess those up to.
We have no chance right now to not mess up some of the future tech that's impending dooms that's coming.
And we're looking for help so if you're interested, you know, hope we can all connect through through Frank, and I really appreciate Frank you giving the opportunity to have this conversation I think, happy to do more.
I know we kept this to an hour but I think it's incredibly important and each of the issues go very deep I mean the teenage mental health stuff versus the polarization and how do we deal with the exponential tech issues.
Well, I it this is incredible. And as Harry Clark says go see Ben's ass.
I need to find a way to have the two of you sit down with him, and you don't have to simplify it. Daniel, you can say it exactly as you say it right now and he'll be he'll be with you every step of the way.
You guys are brilliant you guys are the way it should be.
You know your parents, I'm sure, were are proud of you.
You got a great education. This was probably the most important session I've ever done.
And I'm grateful for you all for not pulling any punches for not dumbing things down.
And the next time I will go to sleep will probably be never after all the things that you just said. So everyone thank you. We're not going to do this that often. I'm only going to do it when it really matters and this time it really matters.
Daniel, I hope people pay attention to you trust on I hope you do another documentary with another couple Emmy Awards. You deserve them.
This session is done and had all done your favorite posts on YouTube. Now, unedited complete. Let's use Twitter to take a couple segments from this. We're going to use social media the right way to get your message out to as many people as possible.
Everyone. Good night. Good afternoon.
It was an honor to be here. Thank you. Thanks Frank.
