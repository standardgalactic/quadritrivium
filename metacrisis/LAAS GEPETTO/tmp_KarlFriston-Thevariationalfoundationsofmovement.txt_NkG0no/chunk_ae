that constitute the hierarchical generative model.
So this example essentially uses a point attractor.
So the equations of motion
that describe this prior belief
or this heuristic have a fixed attracting point.
The next example just takes exactly the same idea,
but with two twists.
First of all,
we're going to make the target invisible.
And now it's not going to have a point attractor.
The location of this fictive target
is now going to pursue a heteroclinic cycle.
And we've heard about central pattern generators.
I'm just writing down now a central pattern generator.
It actually has a Volterra locker form
that produces a heteroclinic cycle
that attracts the fictive location
of this point in Euclidean or extrapersonal space
to a series of unstable fixed points.
And again, it did strike me that the notion
of computing your points of contact
and then working out the dynamics
has a lot of similarity
in the way that one chunks and sequences.
But what we're doing here
was saying that this one equation,
a very simple equation,
I repeat, a locker Volterra differential equation
that has a number of unstable fixed points
that are visited in sequence.
This is just nothing more
or less than a central pattern generator.
And then there's a mapping from the location
in this abstract space to some points
in a 2D planar space that attract the finger
in exactly the same way
that the point attractor attracted the finger before.
And by just putting these points here
in an appropriate place,
I can simulate the writing
that you've just seen being traced out there.
Now, so there's an interesting simulation
from the biologist's point of view
because the activity of the units
that are encoding these prior beliefs
and generation predictions
that are fulfilled by action
do actually show a lot of characteristics
that people in neuroscience are familiar with.
So, for example, if I plot the activity
of one of these in terms of the position in space,
we get place selectivity.
Furthermore, we get place selectivity
that has direction selectivity.
It prefers the downstroke,
as opposed to the upstroke of the J here.
And another nice thing about this simulation,
it actually shows that...
Oh, it allows me to remind myself and remind you
all this behavior is being produced
by deep dynamic descending predictions
in the proprioceptive domain.
At the same time, the agent is making visual predictions
and seeing the consequences of its behavior,
and it's well-happy
because those predictions are completely fulfilled.
However, if I just reduce the gain
on these descending predictions,
and replay the same visual input,
I now have a simulation scenario
where it will be like the agent
watching somebody else write.
And yet it can use exactly the same forward model
to infer the trajectory and what is being written.
And I've simulated that here
in terms of looking at the activity of this unit here
when I've precluded movement
by switching off the gain of these descending predictions
but left these in play,
and then replayed the visual input to the agent.
And it excites exactly the same selective responses
in the same forward model.
So it's using this generative model
that has multimodal, extraceptive,
and proprioceptive predictions
in the one hand to prescribe behavior
through descending proprioceptive predictions,
but also in another context,
it can prescribe the extraceptive
or visual or auditory consequences
of another's behavior.
So it can also accumulate sensory evidence
to infer what something else
or what another robot was doing.
And of course, that's basically
the premise of the Muren neuron system
which this provides a very crude model of.
Okay, finally, what we did there
was write down explicitly
the number of the attracting locations.
What I want to do now is to show you
the last simulation
that asks the question,
well, how do we in visual neuroscience
identify the points of attraction
the next point of attraction
in this heteroclinic itinerant sampling
of our sensory space.
And the way that I'm going to choose those
is this is the second equation here.
We're going to choose those
is actually quite principled.
I won't go into the arguments now,
but basically it rests upon
the following argument.
If it is the case
that all systems that exist
in a gothic sense
can be written down
in terms of minimizing their
variational free energy.
And if it is the case that the behavior
of all systems is determined by
the empirical prize or the priors
inherent in their model
that forms the basis of that free energy,
their heuristics.
What are the only necessary heuristics
to explain the existence of a system
that doesn't go off exponentially
to plus or minus infinity?
Well, it's just that they believe
that they minimize free energy.
So if a system believes
it minimizes free energy in the future
then it will act
to fulfill that belief
and it will therefore minimize free energy
and it will therefore exist.
So what does that mean in terms of
understanding the imperatives
for planned action
or if you like, goal directed action?
I haven't got...
I'll go into this. It is a very interesting
sort of game.
If one writes out
the full expression for expected free energy
in the future, it actually entails a lot of interesting things
that subsume optimal control
and KL control.
But I'm actually taking the sort of
the interesting
bits out of the loss function
that make it the sort of loss functions that you would deal with
and just looking at what is left
and what is actually left
is the information gain
and the weight value.
The reduction in certainty I would get
if I moved like this.
So as applied to the visual domain
that simply means that we're going to
the point attractors of our eyes
or ocular motor system
are going to be those movements
that harvest or solicit
or elicit sensory samples
that reduce
my uncertainty about
the state
of the world.
I can compute that. So if I had this
hypothesis about
that this image was causing my local
sensory samples, see I can move this circle around
compute the
decrease in expected free energy
conditioned upon that control
and score it
in terms of information gain
and epistemic value and create a salience map.
I can now use the maxima
of those salience maps to drive
that itinerant searching
that we illustrated in the previous slide.
Here's the architecture.
I won't go into this.
It's not very interesting.
The more interesting thing here is the behaviour.
So here the locations
of this successive
autonomously selected
now attracting points for
successive fixations
in a movie format. These are the data
that are sampled, simulated EOGs
or electrical eye movement
recordings, the visual samples
at the end of each saccade
