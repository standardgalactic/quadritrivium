electrons
and it can't be analytically solved
and it certainly can't be done possibly
over evolutionary time with some
sampling technique
but in real time that can't be done
hence the free energy
so the free energy provides an analytic bound
that is really easy to measure
but it renders
now your optimal
dynamic
no longer is it exact
Bayesian inference, it now becomes known as
approximate Bayesian inference
so the whole point of the free energy principle
as opposed to just maximising
Bayesian model evidence
maximising
minimising surprise
is that it allows exactly for that
it provides a tractable
finessing of the problem
that you're talking about
so everything I'm talking about is approximate
Bayesian inference
which lends another aspect I guess
to the use of the word heuristics here
so the free energy
which is always by definition
by Gibbs inequality
bigger than the
the log of the probability itself
now can be written down in this form
so
and then it has a flavour and a feel
where suddenly you feel comfortable
because you know and talk about likelihood models
we know and talk about prize
if you're comfortable with hierarchical models
or deep models you will also be comfortable
with the notion of parametric empirical
Bayes and
empirical prize
so these are the things that
you are forced to do when doing modelling
because we cannot measure
usually to non-linear models
the actual thing we want to approximate
which is the probability of s
so probability of s given m does not appear in this equation
but what we now have to do
is to write down the prize
and the likelihood explicitly
and notice that the entropy term is on the end here
so this conforms to James's maximum entropy principle
so we try to maximise
basically the accuracy
of our model
but at the same time maximising
the entropy
or the uncertainty in our explanations
slightly paradoxical but this is what leads to
the generalisation
and the simplicity
and the complexity
of the approximate Bayesian solutions
and again I was thinking
about your presentations
you know
part of that simplicity
I'm not sure it's an appalling abuse of the word
but the minimisation of the complexity
that you would get
from including this entropy term
tells you
or usually makes it the case
that sparse models
with nice sparse hierarchical structures
with low dimensions
as their sort of explanations
for high dimensional data
have much more
evidence
or more exactly lower free energy
than models that don't have that low dimensionality
so you can actually write this equation
out in a number of different ways
and that complexity becomes a KL divergence
between the posterity and the prior
and that the determinant of that complexity
which is all part of this
completely standard free energy
and free energy, variable Bayesian
ensemble learning formalism
you get for free when you
use low dimensional
hierarchical models of your data
so I think it's a principal drive to get into those
good heuristics that have that low dimensionality
with that hierarchical temporal structure
that we've been talking about
it's actually mandated by the very
nature of the problem that we're trying to solve
or trying to explain
is that okay?
I actually have a technical question
so this
relationship between
Bayesian inference and optimal control
that you pointed out
with all the idea going back to Kauman
and in his world
in the linear world there are one-to-one
just like you were describing
but later there was work by Mitter and Fleming
in the non-linear case
and then I did something and BirdCup did something
relating it to patented growth
and collectively we figured out that control
is actually a much bigger problem
than Bayesian inference
specifically what that means is that
there is a subclass of stochastic optimal control problems
that map one-to-one to Bayesian inference
but there are infinitely many other stochastic
optimal control problems that do not have
an inference analog
and the reason is very simple
actually if you look at Bayesian and the Fokker-Plank
and the Kushner equation they're all linear
the Hamilton-Chicovi-Belman equation
is non-linear
there is a special case where it becomes linear
under logarithmic transformation
but it's not always the case
so I'm wondering you must have made an assumption
somewhere along the way that pruned a very large
class of control problems
that didn't follow all the map
see where the pruning was
I'm guessing you started by saying that p dot is 0
you kind of assumed some kind of statistical equilibrium
in the world
which doesn't have to be true
could that be the
place where you actually ignored a lot of control
right
there are two great questions
but the very last few words were a completely different question
no
it's the same question
because a lot of the stuff
a lot of the things that I showed
they cannot be cast as Bayesian
right
I was choosing the first one
the p dot 0 is more
just a statement of
the conditions that we need to comply with
so I have to say
non-equilibrium steady state
so we're not talking about equilibrium
we're talking about systems that move
and change and fluctuate
that doesn't have to be true
why do you have to assume a steady state
in this case?
by definitions
if I want to talk about
systems that have attracting sets
that have measurable characteristics
over extended periods of time
basically they don't decay or dissolve
that assumption was really to motivate
the variation
formulation of
the hill climbing on surprise
that was not a pragmatic constraint
on the
on the solutions
that I used to illustrate the ideas
it's really a more fundamental
motivation for where
you get that fundamental hill climbing
from in the first place
but it does not entail stationarity
it does not entail
in either a wide sense
or a weak sense
it does not entail thermodynamic
or any other form of equilibrium
it's steady state in the sense that p dot 0
is equal to 0
I think the more interesting question
I don't know
clearly I haven't gone through
the
formalism that would map
specifying the problem in terms of
