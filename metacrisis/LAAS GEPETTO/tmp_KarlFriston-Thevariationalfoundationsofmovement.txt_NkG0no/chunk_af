and this is the interesting thing.
In this simulation
this very simple agent
had beliefs that the world could either
be an upside down phase
a sideways phase
or a vertical phase
and it then sampled information
to resolve its uncertainty or confusion
about what the state of the world was
that was causing its sensory information
and that's now
shown here in terms of the
expectations for the correct explanation
of the right phase
and the incorrect explanations
and the 90% based in confidence intervals
just to show that there is
a within saccade
and between, solitary between saccade
reduction and transit inflation
of uncertainty as this agent goes
and gathers bits of information
that progresses really resolves
its uncertainty about what's going on
beyond its Markov blanket
and clearly
if any evidence
is violated or disconfirmed
its hypothesis would then move to the next
competing hypothesis
very much in
as one would in a winnerless competition
or a winner take or like situation
so
I'll conclude with that example
it would have been nice to show
a further example that spoke more directly
to robotics but I don't have one
I'm sorry
we haven't really got
that far
nor is that our expertise
but I will close with a quote
from Helmholtz that I think
again wonderfully summarizes
everything that I've just said
each movement we make by which
we alter the appearance of objects
should be thought of as an experiment
designed to test whether we would have
understood correctly the invariant
relations of the phenomena before us
that is the existence
in definite spatial relations
and with that I'd like to thank
all the people whose ideas I've been talking about
and of course thank you for your attention
thank you very much indeed
any questions
I have a question
that relates to your pointing example
that you then extended
to a
future development
so based on data
I've seen that in the community
that has been springing together
all of the examples of examples
developed in the community
that you've seen in the community
so how would you
complete that as a transition
and how would you
so then integrate
in the community
and not have to try to complete
that
that was a very nice question
I think it speaks to the progression
from that fixed point
to this
this would feel like we did one step up
from a fixed point
so if I had
thought that was a presentation before
the slides
it would be nice to progress from a fixed point
to a fixed point
to a fixed point
to a fixed point
to a fixed point
and this is actually
a very good point
so you would actually go
in the same direction
in terms of complexity
if I was writing down a really interesting
simulation I would have done this
but if I
thought about
what an interesting
hierarchy model
would look like
very
very slow
etiquette channels
at the top
that would have
transfer sequences
of etiquette channels
that would ultimately carry down
to the inside of this
so we have all the
texturized in any sequences
of selecting a mechanism
within walking
with the exception of things like
the U.S. and Canada irons
we have microstate clouds in them
so I think we would have
a collection of different
mathematical chapter sets
all contextualizing each other
and just from experience in other
simulations
what tends to happen is that when you write down
the heuristics and you write down
the prize in terms of differential equations
the states of the higher level
of capital
10 collective control parameters
on the lower level
but it did remind me very much
of the coefficients that we're hearing about
remember
there was coefficients times
a function
that was affected by the differential
reference property
versus
a sample
so it did strike me that's very much like
we are forced to write it down
then we might be down
so I would imagine
that dynamics that have a tracking set
is possible in all forms
if we write it down
but increasingly still in time experience
where the higher level
the prize in terms of the lower level
we should get more sequences
of sequences of sequences
than what's in this chapter
is that all we have in mind?
Thank you
Thank you
Yeah, excellent question
so
I sort of skipped over that
but there will be a whole
I think
community of people who could come
and lecture on the importance of
variational free energy
in approximate Bayesian inference
that is exactly to finesse that problem
so if I understand your problem
sorry the problem
you're highlighting
if it were the case that one could actually
evaluate p of s
if you could actually estimate
surprise or value
then in principle you could just work out
with respect to control variables
and with respect to internal states
and then just write down
the differential equations
a very adaptive agent
that could be
and one should add
that every aspect including the parameters
would have to minimise free energy
and if you write that down
that becomes associative learning and somatic time
it then becomes natural selection
or Bayesian model selection in evolutionary time
but everything minimises
log energy, that log surprise
but of course you can't measure it
and as I understand it
this is exactly the problem
that Richard Feynman confronted
when he was trying to solve
the pathological problem
to work out the probability
of trajectories
of small particles
