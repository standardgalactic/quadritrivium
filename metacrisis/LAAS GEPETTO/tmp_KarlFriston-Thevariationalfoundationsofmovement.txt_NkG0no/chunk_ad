right down to the bottom level.
Now the interesting thing here from the point of view of a neuroanatomist
is that we actually create forward or ascending connections
or message passing where the prediction errors are propagated up
or deep into the hierarchy to update or correct our expectations.
So there's a reciprocal message passing with descending predictions
and a counter stream of ascending prediction errors
all being mixed together in a relatively simple way,
although there are nonlinearities in this
because the predictions in the prediction errors
are generated by nonlinear descending influences here.
But a fast, simple and efficient way
basically is a map from consequences,
sensory consequences back to causes
in a way that is consistent with maximising Bayesian model evidence.
So just intuitively from the point of view of,
again say a visual neuroscientist,
let's just see how that might pan out
in terms of anatomy and physiology.
We have sensory input coming in here.
There are top-down predictions from the visual cortex.
They're compared to elaborator prediction error.
That prediction error is passed up to the visual hierarchy
to revise expectations about the causes
of that say local pattern of sensory input.
But these predictions or expectations themselves
are in receipt of higher predictions
which form a second level prediction error
that can be sent up the hierarchy
to revise higher and higher, more abstract,
hierarchically deep representations.
And we've heard about the importance
of sort of dimension reduction factorisation
and in the formation or in the use
of these hierarchical models
that are defined by their factorisation,
that sparsely structure,
this is where you get the dimension reduction,
the efficient representation or explanation
for sensory input.
We can tell exactly the same story
for proprioceptive input.
So proprioceptive input from stretch receptors
here in the ocular motor system
coming to the pontine nuclei
in receipt of top-down predictions
say from the frontal eye fields.
We have a prediction error that could be sent forward
to revise our beliefs about the configuration
of our ocular motor system
and provide a base optimal explanation for that.
But, and here's the important thing,
these prediction errors have another way
of suppressing themselves.
They can couple directly back to the actuators
to make the stretch correspond
to the descending proprioceptive prediction.
So they can eliminate themselves quickly
and efficiently just by coupling back to the environment.
So this is the action.
This is basically action minimising prediction error here.
Notice that the only thing that action can change
are the prediction errors at the first level,
not deep in the hierarchy.
And what I've just described there is simply a reflex arc,
nothing more, nothing less.
In this perspective,
basically the descending predictions
provide the reference for the reflexes to fulfil.
So action is in the game, again,
of changing the sampled sensations
to make them more like the predictions,
including the predictions about the motor plant.
And in fact, only in this instance about the motor plant.
So we only have the reflexes right at the bottom of the hierarchy.
So these predictions, of course, are not simple.
They are richly informed by deep hierarchical processing
and gathering together of all information
from all modalities.
So these are descending predictions
that are just in the proprioceptive domain,
but they are all internally consistent
with beliefs about the world and its history
that have benefited from the accumulation
of multimodal information.
So these are very rich descending predictions,
but their actual realisation by the motor plant is trivial.
It's just driven by the reflex arc here.
So these will be basically the reference signals
that we were hearing about earlier on.
So to sum it up before I conclude
with a couple of illustrations,
biological agents minimise their average surprise,
namely their entropy.
They do this by suppressing...
Or you can write this down
in terms of a suppression of prediction error.
And that can be reduced by either changing the predictions,
namely perception or sensations through action.
And this, certainly, the predictive processing
or Kalman filtering scheme that I've just described
entails recurrent message passing to optimised predictions,
and action reflexively makes those predictions come true
and thereby minimises surprise.
So let me just now conclude by giving you...
Working through three examples
that sort of build upon each other,
which maybe speak more to robotics than...
I've got enough time, haven't I?
Yep.
So...
No, no, no, what?
Twenty minutes.
Twenty minutes.
I was just about to accelerate there
into hyperdrive,
now more relaxed again now.
Fifteen minutes.
Fifteen minutes.
Alright, never need time for discussion.
So the first...
So I was trying to think how all the ideas
I've been hearing about this morning
fit with this scheme.
There are lots of points of contact,
but there are also points of confusion for me,
so I'm hoping that some of that will be resolved by the audience.
And often, my confusion is resolved
by going back to these simple toy examples
that self-evidently work.
So the first example was basically
how would you simulate queued reaching?
So there's some change in the environment
that queues a particular movement,
that movement is just reaching to target.
So this is actually a trivial thing to solve
from the point of view of this active inference scheme,
and just involves putting into the model
the prior beliefs that when a target changes colour,
there is an invisible spring,
or an invisible spring that is connected from the target
to the tip of the agent's finger,
becomes very stiff and pulls the finger to the target.
So in the absence of any queue change,
that string has no stiffness,
but as soon as the target changes,
the agent believes that there is an attractive force
pulling its finger towards the target.
Now, if it believes that,
and that is part of its generative model,
then it will expect to see and feel
its arm move to the target.
And action will reflexively fulfil that.
And in so doing, we'll also fulfil the visual predictions.
This is basically the sort of behaviour we get
when the target changes from green to red.
This is just a schematic of the implementation
by reflexes through action
of these descending proprioceptive predictions here.
So I think the interesting point here
is that the forward model
that implicitly resolves
the multiple degrees of freedom problem
is very simple
and it's got absolutely nothing to do with the real world.
The real world does not contain springs.
The actual model is almost heuristic
and heuristic using a very good sense.
So I think heuristics sometimes come along
with a slightly negative connotation.
But in fact, heuristics are your prize
and approximate Bayesian inference.
They are the heart of everything.
And at the very end of the final presentation,
we have this sort of hierarchical decomposition
almost, you know,
appealing to heuristics at very high level constructs.
This, I think, formally is exactly the same
as a deep hierarchical generative model
where the priors induce,
they're called empirical prizes in a hierarchical model.
They are heuristics.
They're neither right nor wrong.
And of course, once you get the action
for making them come true,
they become right,
provided they are allowable.
So if you've got the right heuristics,
they are true.
They're just private beliefs.
And in this instance,
these private beliefs
resolve the usual sort of motor control problem
because you're actually pulling, not pushing.
You don't have to solve a pushing problem.
You're solving a pulling problem
by use of this particular
and very simple prior heuristic or prior belief
that's just part of it,
a very simple part of the differential equation
