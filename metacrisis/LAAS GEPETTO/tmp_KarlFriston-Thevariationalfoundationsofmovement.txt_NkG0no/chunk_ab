if you imagine just dropping a drop of ink into the ocean,
then these random fluctuations here
will disperse the concentration of the ink throughout the ocean.
So in that instance, it wouldn't have an attracting set.
It wouldn't have behaviors that we can measure and admire
or put on YouTube.
So it must be the case then
that there is some deterministic flow
that is countering the dispersive forces.
So it's acting in opposition to the dispersion
which degrades areas of high concentration
and high probability distribution or density.
In other words, it's actually flowing towards
regions of high concentration.
And when those two dispersive
and deterministic flow components are in balance,
then the system becomes,
attains non-equilibrium steady state
and is weakly ergodic.
And that's all that we're describing here.
This equation here is just an expression
of the Helmholtz decomposition.
It's just expressing this flow in terms of a hill climbing
or gradient descent on the log probability
and a solenoidal or divergence free component
that actually breaks the detailed bounds
of a system in general.
We'll use both terms later on,
in a way which I think many of you will be more familiar with.
And this cartoon is just to show
that there are two components to this flow.
But the essence is that the flow of any system
should exist, has to do a hill climbing
on this log probability.
So now let's go back
and put the Markov blanket back into the mix.
And let's do it in terms of the states
that constitute me, my sensory states,
my active states and my internal states.
Hill climbing behavior is still true,
which means it is still the case
that all my internal states will try to maximize
the log ergodic probability.
And all my actions, all my behaviors,
my active states will also try to maximize this quantity here.
And I'm going to associate these with perception and action,
try and motivate that for you in the rest of the talk.
But just to pause for a moment
and just think about what this quantity means
depending upon where you were educated
or what community you come from.
What we're saying is that the system will appear
to self-organize internally and behave in a way
that it's going to maximize this quantity,
which is just the energy of states it thinks it should be in.
It likes to occupy.
It's just the valuable states, the adaptive states.
So from this we can then derive,
or at least form a conceptual bridge
to things like reinforcement learning,
optimal control theory, accepted utility theory and the like.
The negative value is just the self-information
or surprise or surprise.
So any system that exists will be trying to,
in an information theoretic sense,
try to minimize its surprise.
And then that brings us to the principle
of maximum mutual information, minimum redundancy,
and the free energy principle where free energy here
provides an upper variational bound
or approximation to the surprise itself.
The time integral, the path integral over any trajectory
because of the ergodic assumption, is the entropy.
And that's nice because what this means is
there's a resistance to the second law.
It's resisting an increase in entropy.
And of course that is the holy grail
of self-organization, synergetics.
But of course it's just the statement of homeostasis.
It's just saying that systems, biological systems,
that reduce the tendency to disorder,
keep themselves within physiological bounds.
And we see very nice examples of bounds
in terms of, say, the constraints
on various loss functions or cost functions.
Now, as a statistician, you will also notice
that this quantity, or e to the surprise,
is the probability of sensory data given me.
But if I interpret me as a model of me and my environment,
then this is also known as model evidence.
It's the probability of the sensory samples
conditioned upon me existing or the model existing,
which means that this can be interpreted,
this maximization of this quantity here
can be interpreted in terms of the Bayesian brain,
evidence accumulation, and predictive coding.
And these two perspectives are what I want to pursue
and try and unpack in terms of process theories
of how the brain might work and how it might act.
So just to give you a very quick flavor
of how the nature of the dynamics that I've just described,
what I've done here is simulate a little primordial soup
using 128 macromolecules
that I've given autonomous dynamics using a Lorenzo tractor.
So each one has its own dynamics of electrochemical sort.
And they're spatial relationships
determining forces amongst the molecules
with weak electrochemical attraction
and strong repulsion as an inverse function
of the Euclidean separation.
And just lumping these little macromolecules together,
they sort of bubble away quite happily,
showing non-equilibrium state quite quickly.
The details of this simulation are completely unimportant.
You get exactly the same behavior
whatever loosely capital dynamical system you write down.
You put a little bit of random fluctuations in it
and it will show this sort of behavior
in one parameter regime.
The reason I've done that
is because I've written down the equations of motion
and I know the physical separation
and the statistical coupling between these molecules.
I now know that graphical structure, that adjacency matrix
which means in principle I can go in there
and find some internal states
and then mark off blanket.
And I can then look at that system
and then do experiments on it
to try and illustrate the two behaviors
that I was referring to before.
What I've done here is just reproduce exactly
the movement that we had on the previous slide.
But here I've color coded the internal states in blue here,
a little ring here with a small tail.
The active states in red
that surround the internal states
and support the sensory states or the surface states
that are exposed to the external states in cyan here.
And this thing wiggles around,
wrapping its tail, quite happily exchanging,
again, a non-equilibrium steady state
with the environment.
For those who are interested,
it's very easy to find these structures.
You just need to identify the mark off blanket matrix
which is constituted by the parents, the children,
the parents of the children,
and then spit it into the active and sensory states
using the rule that I described before.
So what I've now got is a synthetic little organism
that I can now ask,
does action maintain the structural function integrity of this,
often referred to in terms of things like auto-poesis,
and do the internal states act as little Bayesian engines
or infer the hidden causes of their sensory states,
namely active imprints.
So just briefly to illustrate the sorts of things
which we do as neuroscientists,
which are basically performing brain lesions
or studying people with strokes,
this is an illustration of what happens
when you perturb the system.
So here are the locations of those,
all the elements of that little organism here,
reported in terms of their locations
over 512 seconds under normal progression.
And these three panels show the equivalent locations
where I made mild lesions to either the active states
and these are very mild,
I'm just rendering them insensitive
to the electrochemical interactions coupling.
So this would be like paralyzing the agent,
the sensory states by making it blind
or giving it a little stroke by lesioning the internal states.
And the key thing, the obvious thing here,
is that whatever I do,
I basically kill the organism,
I destroy its equilibrium.
And indeed, we can assume now
that the proper maintenance of its structure
and function did depend upon that hill climbing behaviour
that I've illustrated in the first few slides.
Technically, this is actually known as oscillator death.
And it's closely related to something else,
generalized synchronisation,
which I'll mention in a second.
Here's the second illustration.
It's an illustrative purpose,
or to make a heuristic point anyway.
I'm asking the question,
is there anything in...
or do the electrochemical states
or the internal states
predict the physical motion of the outside world?
So this would be like a brain imaging experiment
where I present some moving stimuli in the outside world,
and I look for evoked responses
in the visual cortex of the brain.
And it's very easy to find mixtures here.
