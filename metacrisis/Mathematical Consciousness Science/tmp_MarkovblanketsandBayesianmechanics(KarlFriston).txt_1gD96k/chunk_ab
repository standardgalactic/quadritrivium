unique to systems that have this bipartition into internal and external separated by the
blanket states and that's this Bayesian mechanics which we've mentioned in terms of this
perception action cycle so remember before that everything has to be described as this
this solenoidal gradient flow on the negative on the logarithm of the
the non-equilibrium steady state density that has to be true for the internal states and the
active states namely the blanket states which sorry and the active states where the blanket
states comprises sensory in the active states notice what I've also done here I've swapped out
the log probability here for a free energy functional that is a function of the blanket
states and this object here which will become quite crucial later on which is a
probability distribution over the internal states that is parameterised by the expected
internal states a bit subtle that but that's going to come very important later on but the two
key things that emerge from this relatively straightforward analysis first of all the internal
and active states which will call autonomous states share the same function so it'll look as if
my internal brain and the way I act have tried to do the same thing so we come back this notion
that they're both trying to minimise say prediction error or in this instance more generally
minimising by this gradient flow this variational free energy functional
clearly because of the structure of the Markov blanket this variational free energy
does not depend upon the external states so notice that this thing here is not a function
of the external states it's a function of a function of the external states that parameterised
by the internal states so I'll just preempt or foreshadow some of the dual aspect geometry
conclusion so what we have here is a gradient flow that can be written down as a functional not
of external states but as a function of external states but as a functional of beliefs about
probabilistic beliefs about external states that is never in and of itself directly influenced by
the external states but just what the internal states think about or parameterise
what the internal states parameterise in terms of a belief distribution over the external states
so that's a bit heavy so let me make it a little bit lighter so this free energy functional
world could have many interpretations it clearly on the present analysis
undergirds all of the self-organisation that we've been talking about I'm just making the
point here again I'll try to go through this quickly the point I'm it is being made here
is that this basic structure this basic mechanics where internal states of a system and their
action upon their world can be construed or it looks as if they are minimising this free energy
functional here of their blanket data their sensory data and what they currently encode
it looks very much like for example action and beliefs trying to minimise free energy or maximise
the negative of that basically value where value is simply the probability or the log
probability of your blanket states being in a particular configuration so this if you like can
be viewed as a sort of a mathematical backdrop to reinforcement learning optimal control theory
economist expected utility theory if on the other hand you had been brought up in terms of
information theory then this value function the log probability of the kinds of blanket states
I am likely to be found in the ones I prefer to be found in that define me and just take the
negative of that logarithm that's known as self-information and information theory
try this call it surprise or we'll just call it surprise this free energy quantity is enough
a bound on that surprise here and if we think of this optimise eight from the point of view
of optimisation what we are saying is that we're trying to minimise our surprise and in so doing
we can unpack that in terms of things like integration information theory minimum redundancy
principle of Horace Barlow and indeed the free energy principle that we're going to occasionally
mention throughout this presentation that's nice because the expected value if I do this on
average over time the expected value of self-information or surprise is entropy which means it looks as
if this minimisation take on this gradient flow will be in the service of resisting the dissipation
and decay and disorder entailed by having a high entropy and it'll look as if it's consistent with
the principles of self-organisation or synergetics if you're in laser physics or if you're a physiologist
it'll look like homeostasis just keeping things within bounds minimising homeostatic surprises
if you're a statistician you would look at this quantity say oh this is a probability of some
blanket states or data that I have access to from the out that are a product of the outside world
under some model here so here the two this has been a mark of blanket but now I'm going to say no
it this is actually we from a statistical point of view it's going to stand in for a model and this
is known as Bayesian model evidence also known as the marginal likelihood because I've marginalised
out all the external causes of my blanket states here so then we can sort of speak to people in
who like the Bayesian brain hypothesis people who look at the brain as accumulating evidence
and get back to predictive processing and its special cousins or variants such as predictive
coding oh yeah so the mark of blanket this was sent to me by one of my young colleagues who
moved over to America he's just had a little baby and his wife bought him a mark of blanket so if
you want to mark off blanket you can get these in America so here's little Keira making her
inferences first inferences about the world through through her own mark that's mark off
on the blanket itself right so information geometry I'm going to use numerical simulations here
just to show how these things arise and how you can think about what we've talked about in terms
of a Bayesian mechanics in terms of something called generalised synchrony so but let me just
take you through this with with an illustration what we've done here is just create a little
universe a primordial soup by writing down equations of motion for 128 little particles
or macromolecules each of which has their autonomous dynamics in fact based upon a rinse
attractor and we've equipped these this ensemble of synthetic molecules with strong and weak
attractions and repulsions the details are irrelevant you can generally get this kind
of behaviour from any set of differential equations the reason we wrote these down
is that now we know exactly the influences that one particle exerts over another particle
and because we know that we can actually go in and identify a mark off blanket
and then ask the question is there a little mark off blanket or a little thing or a particle
inside this soup and if so does it look as if it's conforming to the Bayesian brain or conforming to
Horace Barlow's principle of minimum redundancy so I'm showing the same data here
but where I've colour coded all of those molecules once they have attained non-equilibrium steady
state as to whether there are external states that are hidden beyond the mark off blankets so
therefore sometimes referred to as hidden states sensory states that as is typically in these
simulations are underwritten or above the active states in red that then cells enshroud the internal
states what we see here is something that's not unlike a little prion or viral particles
that particle just wriggling around in its primordial soup having attained this
non-equilibrium steady state and coursing in terms of its state space over this attracting set
so this allows us to ask a question do the internal states the blue states appear to infer
the causes of their sensory states the magenta states in other words are they they look as if
they're doing a gradient flow on this model evidence this Bayesian model evidence sometimes
referred to by people like Jacob Hoey as self-evidencing and indeed they do it's illustrated in this
graphic here so what we've done here is find a mixture of internal states that predicts a
mixture of the motion of the external states so this will be a little bit like finding a
neuronal population or a mixture of neurone neurons in a small brain that responded to
say motion in the outside world communicated by via the sensory states so the visual epithelium
and when we look for this and we try to identify those mixtures that maximally show a correlation
we do indeed find that the internal states are in some way parameterizing or encoding or representing
the behavior of the external states despite the fact they can't see them directly
so what we've done here is just plot the prediction of the external state as a function of the
internal state the expected internal state over time along with 90 confidence intervals and the
actual external motion in cyan here and you can see that there's a pretty good inference going on
interestingly remember before I was talking about the the expected internal states that capital
mu that actually is important because what it allows me to do is to sort of look at the expected
internal states and expected external states and just see this synchronization manifold that
on average when the internal states are like this the external states are roughly like this
if I go through and just pick out excursions here and overlay themselves on each other to get at
these averages here what we see is something very much like what we see in electromagnetic
studies of the human brain and cognitive neuroscience for example which is a simulated event-related
potential so here's one from the empirical literature and this is just overlaying these
fluctuations of internal states that are themselves predictive of external states so I've used the
term synchronization manifold here deliberately because all we're looking at here is something
that has been known for centuries in fact introduced the notion was introduced by
historian Christian Huygens as synchronization of chaos or generalized synchronization
so for those of you who haven't come across this before it's most famously articulated by the
observation that when you have many clocks suspended from the same wall or the same beam
in terms of engineering we call them loosely coupled dynamical systems they will inevitably come
to swing in unison and in synchrony so that is the only attracting set that they can possibly occupy
and that exactly describes this generalized synchrony between the outside and the inside
that we're witnessing here so from our point of view this is actually a drawing by Huygens himself
of two clocks suspended from the same beam one clock we can call the internal states
the outside world can be the other clock and the beam become the blanket states with active
and sensory components here I like this perspective because it highlights the pure
symmetry of this structure so if you subscribe to the notion that you're trying to infer your
universe then you also are committed to the idea that your universe is actually trying to infer
you which actually is an interesting perspective when it comes to things like eco niche construction
and the like anyway just looking at the that that synchronization manifold a little bit more
closely it has within it a structure which holds the key to this dual aspect information
geometry that I have repeatedly mentioned it's a very simple consequence if I simply plot a little
state space with internal states here and external states there and I do so for every given blanket
state say sensory input then it has to be the case there must be a probability distribution
for any given blanket state over the internal states and the external states now that's self
evident it's obvious but it has a fundamental implication what it means is that for every
blanket state there is an expected internal state that effectively via this synchronization
manifold parameterizes a belief distribution over the external states so just by having a
mark of blanket and conditioning the inside and the outside on any given blanket state
it must be the case that on average the internal states in some sense represent the external states
and we can formalize that in terms of information geometry I'll just put this slide up and if you
want to talk about what is information geometry we can do that this slide sorry this panel is just
meant to intimate that there are there are two kinds of information geometries going on here
there's a kind of information geometry that you would be dealing with if you were a physicist
dealing with the statistical thermodynamics of this little soup it's a probability distributions
over the internal states in and of themselves and from that you can spin off dissipation
fluctuation dissipation interval fluctuation theorems the second law of thermodynamics should
you want to but there's another kind of information geometry going on here because for every expected
internal state there's another probability distribution over external states about external
states that has its own information geometry which means as I move around in my internal
state space I am moving in two spaces at the same time one is the space of the likely configurations
on average that I will occupy on the inside but at the same time I'm moving around in an
information geometry which is about things on the outside the causes of my blanket states or my
sensorium so in summary internal states parameterized probabilistic beliefs about external states and
equip them with a dual aspect geometry so let me just summarize we've done all the heavy lifting
now in this talk and so let's just summarize where we come from as you know under this
physicists take on self-organization of things that are equipped with Markov blanket the existence
of a Markov blanket necessarily implies a partition of states into internal states
and their blanket states namely sensory and active states and external states that are hidden
behind the blanket and because active states change but are not changed by external states
they will appear to minimize the entropy of external states and their Markov blanket
and this means that action will appear to minimize the structural and functional integrity of the
Markov blanket and this has been framed very elegantly by people like Varela and his colleagues
in terms of auto cohesus internal states appear to infer the hidden causes of sensory states by
maximizing Bayesian model evidence and influence those causes through action and we would put a
Bayesian gloss on that in terms of an inactive kind of inference and in virtue of the implicit
generalized synchrony that must be there if there's a Markov blanket that must be there if
something exists there exists a dual aspect information geometry in which expected internal
states parameterize conditional beliefs over external states again conditioned upon the Markov
blanket so let me just close now by taking the considerations to the next level predicated on
this representational or dual aspect geometry and see what they might mean for sentience but to do
that I've got to if you like provide a taxonomy of different kinds of self-evidencing that you get
from this framework so here's our Markov blanket again just to remind you we've got our Markov
blanket partition here with the Markov blankets and we can lump the the internal states and the
active states as these sort of free energy minimizing prediction error minimizing states
that lend a system a degree of autonomy we can call them autonomous states I'm going to
know that by alpha in a minute the blanket states comprise a sense of inactive states and then
together these can be thought of as the particle in question either a brain or a the synis
don't look at the equations what I want to do here is just show you where two different ways
of unpacking this Bayesian mechanics come from depending upon how far you want to go
in terms of the mathematical formalism so largely what we've done so far is start off
with the assumption that there is a universe that has long run dynamics with random fluctuations
and flows and we've quantified or enumerated the amplitude of these random fluctuations in terms
of this gamma here this inverse precision and if this is true at non-equivalent steady state
when things have characteristics can measured over time then the solution requires this
relationship to be true the flow is related to the gradients of surprise
if the thing in addition has a mark of blanket so it must have then this applies to this and we
now have this hand in hand internal perception like dynamic and active dynamic both in the
surface of minimizing or minimizing suprisal that we can write in terms of this variational
function that depends upon this parameterized belief about the external states mathematically
that's a variational density or approximate posterior density parameterized by the internal
states and we can write down things like the free energy principle as a principle a variational
principle of least action where the action is in this instance denoted by the active states
but action also has another meaning action in physics means the time or the path integral
of energy so there's a whole other layer to this kind of argument which i'm going to show you in
a second but let me just see how far we can get with this kind of formalism so if i commit to that
those dynamics and just write down some of these promoted distributions and just integrate
those equations of motion then you can get quite a long way in terms of simulating active
sentence or active inference so what we've done here is is just write down a generative model
in terms of that probability over external states and the blanket the consequences the blanket states
so that we can derive a free energy functional write down the equations of motion in this instance
just for your interest this little agent has the belief that there is
an invisible object point that's pulling its finger around a trajectory that is itself prescribed by
a Lorenz attractor and by suitably configuring some non-linear mappings when it acts to fulfill
those beliefs to minimize its prediction errors in this instance the predictions about what it
should see and feel that it's actually doing so it's causing its sensations by moving its hand
around we can get it to simulate things like writing and because we are generating that writing
