in the Cognition and Philosophy Lab at Monash University in Melbourne, Australia, and her
presentation is entitled The Self-Interaction.
Thank you very much for that introduction, all right.
So thank you again for that beautiful introduction and for inviting me to give a keynote today.
I'm really honored by the invitation.
I'm speaking to you today from Monash University in Melbourne, Australia.
I've had to get a special legal permit to leave my home since we're still in lockdown.
We're the city with the longest lockdowns cumulatively so far since the beginning of the pandemic,
and we're coming up on 260 days this week.
So if my word finding is poor, it's because I haven't talked to people in a long time.
But I hope today that I'll give you an engaging presentation anyway.
Today I'm going to talk to you about my work on the self in action, particularly,
and a little bit about the role the role this plays in autism spectrum conditions.
Let me get my phone turned off.
So what I hope is kind of common knowledge or understanding for today's audience,
the predictive processing framework says that the brain models the world to minimize prediction error
and maintain homeostasis or resist entropy.
Minimizing prediction error is about matching our expectations with our sensory input from the world.
And this is supposed to explain both perception and action.
So it's a very unifying theory compared to most cognitive understandings of cognition.
Most understandings of cognition wouldn't tie perception and action under one theory.
So it kind of provides new and exciting ways in.
But most people who talk about predictive processing or active inference don't talk about the self.
And I was happy to hear that some of the conversation happening in the audience,
but in the break people were talking about agency and the self.
So hopefully this fits in nicely with what you've been talking about today so far.
I want to say that if you don't care about selves, if you don't build yourself into your model of hidden causes,
then you're probably going to fail miserably at minimizing prediction error.
Because our selves, the deep hidden causes in our cognitive architecture,
as well as our bodies and things like that, cause a lot of sensory input.
And so in order to properly account for the sensory input that's coming in, we also have to model ourselves.
And what do I mean by a self? What kind of representation am I talking about?
I am talking about things like your body, your internal states,
the size and shape of your body and how your materiality kind of interacts with other physical things in your world.
But also your past experiences, which you might, some of them become conscious priors.
Also the likely future states of your organism and how you're going to get there.
So what kinds of policies you'll infer likely in order to achieve the likely future states of your organism.
And also how effectively you minimize prediction errors.
So are you really good at the job that your brain does or not so good?
The self then is an inferred hidden cause and it's therefore malleable,
just like any other hidden cause that's subject to incoming information.
And we learn about ourselves every day of our lives.
Perhaps uniquely, it's a reflexive, it's a reflexive representation,
which means that the thing that's doing or representing is also the thing of being represented.
It's also maybe one of the deepest hidden causes, the most temporally extended hidden causes that's
there from the very beginning and lasts throughout our lives, constantly being shaped and modeled.
So when I talk about active inference, I just want to get clear on some of the terms I'm going to use
and how they relate to selfhood. I think in the classic predictive process,
classic predictive coding specifically, when back when we started thinking about predictive
mechanisms in the brain, we were focused primarily on perceptual inference,
where we would change our mental model to match the world. So you can think about this as like
watching a TV screen. It's a fairly passive process. If you see something that you don't expect,
then you change your expectations. But actually, and very importantly, when we're looking at
representing selves, particularly the new and improved predictive processing, so I'm going
to contrast predictive coding with predictive processing. I'll primarily use the second term.
I'm talking about then the addition of the active inference option to this kind of
predictive mechanisms. And what I mean by that is that not only do you change your mental model to
match the world when you get prediction error, but you also have the choice of changing the world
to match your mental model. So you interact with the things that you're perceiving, you interact
with other causes, and you can get feedback from that process. So when you get prediction error in,
then you have two choices, you can either change your expectation to match the world,
or you can change the world to match your expectation. So this is particularly important
for selves, because we have this reflexive feedback driven evidence driven representation,
which requires you to experimentally poke things in the world. So this involves the action
perception lip, which is going to be a recurring theme in my keynote today. So if our job is to
match the internal states of our cognitive systems with the hidden states of the world
to minimize prediction error, we only have access to the hidden states through our sensory input.
So it's mediated by the sensory apparatus that we have, we don't have direct access to the
hidden states of the world. And we can only poke the world through action. So our access to the
world is mediated through this action and sensory input. So how does this relate to selves? Let's
take an example. Let's imagine that I see myself as a really good active inference academic,
and one of the future states of the world that I perceive myself to be in is writing a really
good paper about active inference. So how do I make this future state that I expect myself to be in
come to reality, come to fruition? I act, this is fairly trivial, I type on the keyboard. My typing
on the keyboard affects the hidden states in my computer, but this is true for all sorts of things
around us, not just computers. But I don't actually understand the kind of causal mechanisms
underlying all the stuff I'm doing, I don't directly interact with the code of the computer.
But I do get some sensory input from my word processing program. But unfortunately, as all
academics I'm sure, my first couple sentences in the first draft of my paper is usually not a
really good paper about active inference. So I've got some prediction error, some difference between
my expected future state and the state of the world at the moment, which is causing prediction
error. And of course, as a good organism, my job is to minimize prediction error, or that's what
my brain naturally does. So one way that I can do this is by continuing to write. So continuing to
edit or write a new paper. And so to act on those hidden states in order to try and minimize
mismatch by bringing about a better sensory input that more closely matches my internal
state. Now notice the thing that makes my self-representation true is my ability to
close this loop and minimize prediction error. So what grounds my inference that I'm a good
academic, that my self-perception, my self-concept is true, are my actions and how effectively I
can minimize prediction error in this loop. So another option for me if I can't minimize this
prediction error is to totally abandon this expectation of myself as being a really good
academic who writes good papers about active inference. So I think another really exciting
development in the predictive processing space is the new avenues in for understanding psychiatric
conditions. And there are a bunch of people who have applied the predictive processing models to
autism particularly, which I think are making really interesting roads into understanding the
architecture in autism. But I wanted to give you a little taster from the perspective of an
autistic person themselves. So I'm going to show you a little quote from an autistic woman,
Leanne Holiday Wiley, who wrote in her autobiography, the human saga is just not reliable enough for
me to predict. Social situations are not the only thing I find unreliable and hence untrustworthy
and uncomfortable. My sense of visual perception often plays tricks on me, making it difficult
for me to do ordinary tasks. Generally speaking, I know I should not rely on my own visual
perception, but practically speaking, it's sometimes impossible to rely on anything else.
And there are a few things I wanted to pull out of this quote from this autobiography.
One is that prediction and uncertainty or minimizing uncertainty across lots of different
contexts seems really important to her sense of her own cognition and perception.
And that this is not restricted to social situations, which is what most autism research
has focused on so far. So she extends it to visual perception, which I would also say,
well, we should listen to people who experience it, but I totally agree that a lot of autism
is not just in social situations, but also in perception and action behavior.
And that this plays a really big role in her life, that it is really meaningful for her to
understand the difficulty she's having with prediction or that that plays a really big
role in her lived experience. So if I say that selves are just another hidden cause and autism
might be related to differences in predictive processing mechanisms, then we might expect that
autistic selves would present differently than neurotypical selves. So we did a big review of
over 100 papers in cognitive science with different paradigms to try and understand
selves in autism. And we found differences across most domains of cognition. So for example,
we found that autistic people generally show a reduced memory for self, reduced attention to
their own name, developmental delay in mirror self recognition, a difference in cue integration
and the rubber hand illusion, which is about the bodily representation of the self, difficulties
in interception. So understanding your own kind of internal signals, which relates to high prevalence
of olexithymia, which is the inability to name and recognize your own emotions, and a reduced and
less accurate use of pronouns. And when I say that, I mean primarily the use of the word I to refer to
oneself. Now I want to stop here for a second and give you a little puzzle to think about for the
rest of the talk, which hopefully I'll answer at the end. And that is how do we explain fidgeting
under active inference. So fidgeting like clicking pens, tapping your foot, you'll probably be doing
it for the rest of my talk now. You might think that autistic people fidget more often. So they
call it stimming in the community. It's a self stimulatory actions. And you can think of it as
kind of a more frequent or more socially unacceptable form of fidgeting. So the same kinds of explanations
I think apply for stimming and a neurotypical person fidgeting. And the question, the reason
this is a little bit of a puzzle is it seems like if all action is explained as a way to minimize
prediction error, how do we explain actions like fidgeting that don't seem to give us more information
about the environment? We're not manipulating elements of the environment in order to learn about
them. And we're not seeming to get any kind of pragmatic reward. So I'll come back to this at
the end, keep it in mind, try not to fidget too much throughout the talk. But just as a kind of
introduction, trying to find a way into fidgeting might help us understand a bit more about autism
and how active inference works. So the focus of my talk today is going to be on two experiments
about self inference in uncertain environments. And traditionally, when we look at acting in
uncertain environments, we have two primary reasons to act. The first is acting for reward or
pragmatic gain. So for example, grabbing an apple off the trees, acting to obtain some reward that
maintains your homeostasis. The other way that we usually talk about acting is acting for information.
And when we're talking about acting for information in this kind of literature,
usually we're talking about acting to find out whether there is reward for your future self
in a certain environment. So is there a lot of apples on this tree? Or should I go over to that
tree? Because there are more apples there. So this is kind of classic foraging literature.
But I want to say that there's something more fundamental than either acting for reward or acting
for information about the availability of reward. And that's acting to figure out what we can control
in the environment. So acting in order to make agency inferences. So to fiddle with stuff in the
world and figure out what I can control. And if you can't do that, then you probably can't act for
reward very easily. You can't act for information very easily. You have to first map
your actions to their outcomes. So I'm going to talk about these two experiments. The first was
published in cognition earlier this year. The second's on the archive. And hopefully tell you a bit
more about agency inferences in uncertain environments. So if we go back to the action
perception loop, one really nice way to access the action perception loop experimentally is
through a judgment of agency. So this kind of task asks participants which of the sensory
inputs should I attribute to my actions? It asks them to infer I did that. But as we all know,
especially in this field, the connections between actions and hidden states and hidden states and
sensory input is not quite as precise and neat and clean as we would perhaps like it to be.
We live in a noisy world and there's a lot of environmental uncertainty out there.
There's probably also uncertainty on this side of our action perception loop. But for today,
I'm going to focus on environmental uncertainty. So these two experiments are going to look at
participants making a judgment of agency in an uncertain environment to try and understand
this action perception loop a bit better. So I'm going to show you a video of the task.
Hopefully it works. The participants task was to look at the screen and figure out which of
these eight squares they could control with their mouse. They had other than that pretty free range
movement across the whole screen. The edges of the screen kind of wrap around so they kind of have
endless space to move around in. They can make choices about how they do the task. Basically,
the idea is just explore this two-dimensional space and tell us which square you controlled.
Because you're not controlling the square, I've got a little line in the middle of the screen
which indicates the direction and speed of movement. So if the line is longer, they were
moving faster. If it was shorter, then they moved it slower. So see if you can figure out which
of those squares this participant is moving. So now they're moving to the left
and left, right, left, right. So all of the squares are kind of jittering around a little bit,
but the square that they're controlling should follow the movement of the mouse.
I'll show you one more time. Put your answer in the chat for which one you think the participant
is controlling. So it's a little bit harder when you're not actually intervening on the
underlying causal mechanisms, but see if you can figure it out. I'll give you doubly the chance
of a participant. And you can see my map lab underneath. All right, so I see a bunch of oranges
in the chat and you are correct. So this is the underlying data that we get from a trial like
that. In the top left-hand corner, I've got the variability. So this is how much jitter was in
each of those squares movements. It's the same across all the squares, including this square,
which is the me square that the participants were trying to find. And that also changes during
the trial. This is another video, so I'll show you how that works. So that's our variability and
volatility manipulation, which I actually won't talk a lot about today other than they're acting
in an uncertain environment. So if you're interested in that, check out the paper.
We also see in all of the distractor squares, there's this number that's an angular offset from
the trajectory of the me square. So if the participant moves up and to the right, square
number three is going to move 99 degrees around the circle to the left from where the mouse is
moving. And those numbers also change three times during the trial. So those squares turn when the
participant doesn't turn. We see these two white boxes. Those indicate the participant's eye position,
so each box is a different eye. And we see from that we can infer, as researchers, which of the
squares the participant's looking at at any moment during the trial. So that's indicated by the screen
square. It's my algorithm trying to decide which one the participant's looking at. So let's look
at how that trial looks with all of the data kind of laid on top. So we can see, like I said,
a really rich data set, including what the participant's looking at and how they're moving
and how all of the stimuli on the screen are moving. We can see that they're switching around
between the squares quite a bit, but they haven't quite found the correct square yet.
They should be watching ones with kind of small numbers close to zero because those are the ones
that are closest to their movements. And they finally land on the V square at the end of the
trial. So when the trial ends, the black numbers pop up on screen, and they press a button to
indicate which square they thought they controlled. If they thought they controlled no square and there
were trials where they controlled no square, they pressed a zero button. So they also had that choice
of response. So if we map this onto our perception action loop, we're asking the participants to
try and infer this hidden state of which square was the me square. They can act to intervene on
that hidden state through their mouse movements. We can see their internal model and their current
hypothesis about which square they control through the eye tracking data. And we also get
information about what their sensory input is. So this is focused on the square that they were
controlling. So that square with the green line around it and is not necessarily the same as
this hidden state that they're trying to infer. So we get this really rich data set and participants
have a lot of freedom in this experimental design, which I think are both really interesting additions
to the existing literature. Another really interesting addition I think that this experiment
allowed us to do was to measure prediction error as the trial progressed. So we can see a sensitive
and dynamic prediction error measure. It looks like an EEG signal over the whole trial. Importantly,
especially for this audience, this is a behavioral proxy for prediction error. So we don't measure
any neural signals. I mean, you could think of eye movement sometimes as neural signals,
but we don't measure anything from the brain. So this doesn't take into account the participants'
internal model of environmental uncertainty. We would expect participants to change their
predictions and their priors depending on the uncertainty condition. This measure doesn't take
that into account. But let me show you how we measure it. So we take the square that the
participant's looking at and wherever they move the mouse, we take that as the expected location
of the square that they're looking at. So this is kind of the prior expectation of the square's
movement based on lots of experience of moving mouses and seeing stuff move on screen. But of
course, our squares, even the MEE square, doesn't move directly to this expected location. Instead,
we add this variability. So the MEE square will just have this variability. And if they're looking
at the wrong square, if it's not the MEE square, then they'll also have this offset, which is that
number, the white number that was in the middle of the distractor screens squares. So when we add
this offset and variability, the actual square moves to some other location, the square that
they're looking at. And we just very simply take the difference Euclidean distance between the
expected location and the actual location as a dynamic measure of prediction error over the trial.
Now, like I said, this experiment gives a lot of power over to the participants. And one thing
that they have control over is the magnitude of this prediction error. So how can participants
control the prediction error in this experiment? The first way is that they control their speed
of movement. So if they don't move at all, then they get zero prediction error, but they also get
no information about which square they're controlling. Because the distance here is zero,
and the distance here is zero, and you just end up staying in the same spot. If participants move
slower, this triangle is smaller, and so the prediction error is smaller. If participants
move faster, then the triangle gets bigger, and the prediction error is faster. But also,
participants can control the magnitude of prediction error just by choosing a better
hypothesis. So if they're choosing the MEE square, you eliminate all of this offset,
and just look at the variability. So that's much smaller prediction error.
You can also have better and worse distractor squares, which have more and less prediction error.
So those are two ways that the participant can control the prediction error in this experiment.
So because we can measure prediction error, we can also look at how prediction error changes
across the trial in different conditions. So we take the average prediction error for all of
the trials for a participant, and look at, in different conditions, how the minimization of
prediction error changes. So for example, we can look at trials where participants judged that they
did not have agency versus trials where participants picked a square at the end, and we can fit a line
to these averages for each participant, which look at the change in prediction error over time.
And because we're particularly interested in prediction error minimization,
we want to look at the slope of this line that we fit for each participant.
So that's what I'll show you in this graph. Because we're looking at the slope of the line,
a steeper negative slope is more prediction error minimization, whereas a positive slope
is no prediction error minimization. There's prediction error accumulating.
We're going to look at not-agent judgments on the left or trials where the participants judged
that they were not the agent versus agent on the right, and I've also split them by accuracy in this
graph. So what the results show is that when participants judge that they have agency,
they minimize prediction error faster regardless of the accuracy of their judgment.
So these ones are lower. They have lower prediction error minimization. They have steeper
negative prediction error minimization than the ones on the left here. And importantly,
it doesn't matter whether they were right or wrong. There's a main effect of agency here.
And so this indicates to us that participants might be using something like the prediction
error minimization or the speed of prediction error minimization to judge at the end of the trial
whether or not they had agency. We can also look at the prediction error pattern around
particular actions of the agent, so instead of looking at the trend across the whole
trial, we can time lock to particular actions that the participant has taken.
So in this experiment, I want to focus on the hypothesis switch. So this is when a participant
chooses to change their hypothesis from one square to another square based on that eye-tracking data.
So we can look at, for an individual trial, we get some measure of prediction error over the trial,
and we take all of the moments that they switched which square they were looking at,
and we average an epoch around each of these events, just like an ERP analysis for anyone who
does EDG research. So we can see the average pattern of activity around these actions that
the participant's taking. And remember that the timing of these is totally up to the participant.
So what I'm going to show you here is like an ERP, we're going to time lock everything to the
hypothesis switch, look at 500 milliseconds leading up to it and 500 milliseconds after it,
and we're going to see prediction error on the y-axis. And what we're interested in here is whether
the hypothesis switch can be used or is being used as a policy for prediction error minimization.
So if this were the case, you'd see rising prediction error, then the participants would
act which should make the prediction error drop. And that's exactly what we do see. So we get this
really nice peak at the time of the hypothesis switch, which is preceded by increasing prediction
error and followed by decreasing prediction error. So this was really exciting and not the sort of
thing that we've ever seen measured in behavioral data before. So we could see that participants
seem to be using this action of hypothesis switching as a policy for prediction error minimization.
So two things I want you to take away from this experiment. The first is that participants seem
to be using the rate of prediction error minimization to make agency judgments. So when
the prediction error is going up, they tend to decide that it was not them. Whereas when the
prediction error is going down, that's when they decide that it was them, whether or not they were
right about this decision. And the second thing is the participants are acting to counteract
rising prediction error. And in this case, it was through switching their hypothesis about
which square they could control. So in the second experiment I want to tell you about,
it was another squares task. This is newer, a newer paper. And they were deciding between
four squares, which one they controlled. But in this experiment, we were interested in how
participants used the structures in different environments in order to infer agency, whether
they could capitalize on different structures and different environments in order to inform their
agency judgments. So if participants moved the mouse straight up, there were two environments on
the screen. And the participants couldn't see this boundary, but they knew that one half of the
screen was water and one half of the screen was sand. And they were trained a little bit or
instructed as to what the difference between the two was. So in the sand environment, moving up
and up straight, we add to that unpredictable variability. So just like in the last experiment,
on every frame, there was some distribution around the trajectory of the mouse movement.
And we jittered the square around that trajectory that was input into the system.
So this is just like the last experiment's jitter and variability. The difference in the water
environment is that there was some hierarchical deeper structure in the pattern of the variability.
So the direction of the variability was predictable. So for example, in this illustration, we have
two frames where the participant was pushed to the left of where they moved. Then two frames
where they were pushed to the right and then left and then right. So if the participants
properly modeled these waves or the pattern, then they could gain something or minimize more
uncertainty about the consequences of their movement. But by our prediction error measure,
the behavioral prediction error measure, the two environments were equivalent because the
difference between where they expected to be and where they actually ended up
was the same. It was just the sign that became predictable. So we were looking at the policies
that participants used to infer agency in this kind of more structured environment setup.
So if we map this onto our action perception loop, there were two things that we changed
from the last experiment. The first is obviously the addition of this environmental structure,
which affects the movement of the squares. And the second thing we changed was that the
current hypothesis was now measured using a button press. And I can talk more about that
in question time if you're interested. But basically, the pandemic happened, we had to
collect data online. So we changed the current hypothesis measurement to a button press instead
of the eye tracking. So we were looking at environment related policies. And we had these
two environments, one with predictable variability that required more model complexity in order
to make use of the prediction predictableness. And the other, which was the sand environment,
which had this unpredictable variability, had more irreducible uncertainty, but didn't require as
complex a model for the participants to navigate it. So we were what I'm going to focus on in this
talk is whether participants use switching between environments, just mere switching,
as a policy to minimize prediction error. So whether if we do that same kind of analysis,
where we look at the prediction error over time, and we time lock it to the times where they cross
that environmental boundary either through the middle or around the outsides, whether we also
see that same pattern of prediction error minimization around the environment switches.
So in this graph, I'm going to show you the true boundary crossings, which is the same kind of graph
I showed you before in blue. And we've got a control in this version of the experiment,
which is a null permutation. And I can talk a bit more about that in question time also.
So we've time locked everything to the environment switch this time. This is the policy that we're
interested in. We look at the frames before and after this is the same temporal duration as the
last experiment. And we've got prediction error on the y axis. So we're looking to see whether if
there's rising prediction error, the participants seem to act to change it to reduce the prediction
error. And again, the participants had full control over when they switched environments.
So we could really look at the pattern leading up to and following this kind of free decision.
So again, we see this really nice peak at the time of the action, which is significantly different
from this control condition. So the switching environments crossing from one environment to
the other is preceded by an increase in prediction error, unfollowed by a dramatic decrease.
And of course, because a lot of my work is about autism and understanding autism through a
predictive processing lens, in both of these experiments, we had a measure of autism traits.
So this is just a questionnaire. Low AQ indicates that participants had fewer autism traits,
and high AQ indicates the participants had more autism traits. And we can split those nice peaks
that we saw around hypothesis switches and environment switches by the participants autism
traits score. So let's see what that looks like. Now this was really exciting when I found it.
We see this really nice differentiation at the time of the action, particularly
between participants with different autism traits scores. So this shows that participants with low
autism traits across both these different experiments and both these different policies
seem to act at a higher prediction error, whereas participants with high autism traits
act when the prediction error is lower. So what this means, because we've timelocked everything
to the action, you can think of it instead as autistic people or people with high autism traits
acting earlier in response to rising prediction errors. So if we think of the prediction error as
increasing, the time at which the participants with high autism traits act is earlier than the
time when low autism traits participants act. So it's like they're tolerating less uncertainty
before they intervene to try and minimize it. This is really cool because there were lots of
differences between these two experiments. So even though we saw this really striking similarity
in the pattern of the data, remember that the action that we were measuring was different.
It was hypothesis switches versus environment switches. The way we measured prediction error
was different. We had this button press, which was much more intentional and manual and disjointed
versus the eye tracking, which was much smoother, had a lot more kind of subconscious processes going
on, but also that we could measure this at home and in the lab with eye tracking.
So I think it's usually really exciting when you see kind of replications like this,
but it was especially exciting to me because we had changed so much and it seems like a really
general finding. So if we go back to fidgeting as an active inference puzzle, you've probably
forgotten all about that by now, but I asked you in the beginning if all action is explained as a
way to minimize prediction error, how do we explain actions like fidgeting that don't give us more
information about the world or reward pragmatic gain? And what I would say is that fidgeting is
just another one of these actions that we perform when uncertainty is rising, when we're getting
rising prediction error. So the idea is that when the rate of prediction error is not what we expect,
then we get rising uncertainty about our model. So we no longer believe that our model is doing
an adequate job at minimizing prediction error. And so we act in order to try and minimize that
prediction error, we do these self-stimulatory repetitive actions. And the reason we choose these
is because we've learned across all sorts of contexts in our lives, they do the same thing,
they result in the same kind of expected sensory consequences. The kinds of actions that we choose
have a very tight causal loop. And so there's not lots of other hidden causes that are interacting
with our actions. We're usually like touching our own hair or a pen that we find very reliable
or twiddling our fingers. So these are all things that are not usually messed with by things in the
outside world. And doing these actions gives us strong predictable evidence for a continued
existence or model accuracy. So the purpose of the fidgeting action in my view is to minimize
rising prediction error. It's not going to solve the problem that you're having out in the world,
but it will temporarily reassure you that your model is still accurate in some sense, or at
least the deeper stuff. So what I want you to take away from today first is that participants
use the rate of prediction error minimization to make agency judgments. I've got some QR codes on
the right if you're interested in the details, but also that participants act to counteract
rising prediction error across a range of these different experiments and theoretical ideas about
action. So hypothesis switches, environment switches, and fidgeting. That autistic people
might act earlier in response to rising prediction error. And that fidgeting under active inference
might be best understood as a self-evidencing policy. So I just want to thank the organizers who
invited me here today. I'm really honored to have given this keynote. And also my co-author is Jacob
Hovey, Jonah Robinson, Becky Lawson, and Shana Jamadar, who without him I couldn't have done any
of this research. I really appreciate their support. Thank you. Okay, what an amazing talk.
So if anyone would like to ask questions, please go to the Q&A podium. Should I leave the slides up
to if people need to see things, or is it better to take them down? I'll leave them up. And if I'm
looking over here, it's because I'm looking at you not at my screen with my slides. So I'm not being
rude. We're not trying to be anyway. Hi. That was amazing. That's terrific. I almost feel like I'm
at an actual conference. That's how excited I got. Is it not an actual conference? As close as we can
get. Well, first of all, is it New York? Are the results like really clean? That's like, that's,
it's great, right? That's amazing. Yeah, and we had a lot of participants. So in the first
experiment, there were 40 final participants. In the second one, there were 80. And we had to,
especially in the second one, had to throw out a lot of participants for data quality issues. So I
think the final data set is much cleaner than the kind of initial, and there are lots of participants
so you end up with kind of cleaner results. Yeah. And so, so I was, sorry, it's a lot to take in.
Yes, sorry. But I'm impressed with that. But I was wondering about, well, first of all,
the paradigm is new, right? So you developed this experiment paradigm with Howie.
So they've, they've done squares tasks in autistic populations. So it's actually the most common
paradigm used for judgment of agency in autistic populations. But I haven't actually seen it
outside of that literature. And the original squares tasks did not have any uncertainty. And
so it was a direct mapping from what the participants did to the outcomes of the squares. And there
was no jitter or any of that. So I think it really adds, and they didn't do any of the prediction
error stuff. So it's, I mean, there's a lot of new stuff in there, but it's not like I didn't come
up with that. No, because I was wondering, like, it seems like a very fertile soil to do to branch
off in, right? So for example, I was wondering if there is, it's a worthwhile to explore the
connection between fidgeting the sensitivity to prediction errors and the self-stimming,
right? So, so, so you, you separate the groups with the autistic qualities, but that's like
trade wise, right? So that's more. Yeah. So we haven't done anything in diagnostic groups,
for diagnostic groups. Well, what I mean is more like, I'm not familiar with autism literature,
but I was wondering if that sensitivity to the changes in prediction error minimization,
if that is also related to agency and in terms of stimming, right? So, so I'm not sure how ethical
it is, but you know, if you could ask, like, what, what makes you feel like you lose agency and then
you separate them with a group that allows them, you allow them to stim and the other don't allow
them to stim. Yeah. Is it something like that done before? What would you expect?
No, I don't think anything like that's been done before. I mean, people with autism, autistic
people tend to stim more in stressful and exciting environments, kind of this two ends of the
arousal spectrum, the same way that we fidget in, in when we're bored and when we're into something.
And I think that has to do with the rate of prediction error minimization in both those
cases, not being what we expect. So either it's easier or harder than we expected prediction
error minimization to be. But I've, I have struggled to come up with ways of experimentally testing
the fidgeting hypothesis because I think it's so individual. How do you like ensure that
participants are experiencing something that they didn't expect to experience so that they're going
to use this kind of broad context, non specific action to try and minimize it. But yeah, I know
I'm fascinated by the idea of following up. What's a small final question because this is really
fascinating. So how central or how, how, how, how big an effect is the relation between the,
how big, how strong is the relation between the sense of agency for autistic people
and the sensitivities to prediction errors? So we don't find one thing that I didn't say in this
is that we don't find a difference in accuracy of the agency judgments depending on autism traits.
So it's not like autistic people aren't experiencing agency and actually
the one of the only domains we didn't find a difference in our review
was judgments of agency for autistic people. So it's not like the final judgment is changing,
but the behavior, the way that they're inferring the agency seems to be different.
So it's, yeah, I don't want people to come away from this thinking that autistic people don't
feel agency or something. It's just that the way that they do, the way that they
act to make inferences about themselves is different. Okay, that's really interesting.
Thank you so much. Hello. Hello. So thank you for that talk. It was really nice. And I have a few
probably in the big questions. So maybe I should just go read the, the, the paper that you posted.
But the, so I guess you kind of answered already. So you said 40 people for the first experiment
that ended up being in the final paper, right? And then 80 for the second one.
And what was the, because I remember that you had it, I guess, categorized by traits,
really high amount of autistic traits and so forth. How did, how did that come about?
Like what was the destination for that? Yeah, so we took the mean and then
one standard deviation above the mean and one standard deviation below the mean and used those
cutoffs for the groups. So there are more people in this middle group than the two others,
but they're defined by how far away they are from the mean on the autism traits.
And those little vertical bars, is that kind of a compensable guess?
Yeah, 95% compensable. Gotcha. Yeah. So if you guys feel less than 0.5, I guess,
but there is overlap, right? So I see that there's, you know,
so if you do, sorry, that didn't mean to interrupt. I was going to say if you do a
correlation or regression on this central time point, you get a linear effect of autism traits
on the prediction error at the time of action. Okay, cool. And then I guess,
did you guys calculate the school power of the test as well? Or is that kind of just not?
No, we didn't. Yeah, you know, I think that it was a little bit too difficult to do given that
it's like there were so many measures in the task and none of them had really been done before.
So we didn't really do a power analysis. But yeah, I think the fact that it replicates across
these two experiments is meaningful. Oh, yeah, it definitely gives you avenues right for the
research. And I guess, was there a measure of effect size that coincides with something else
that they'll use? I think we do have some in the paper, but I don't remember them off the top of
my head. I'm sorry. No worries. And I guess, did you post a link somewhere, I guess, in the chat,
or maybe I can find that to the papers? Yeah, the main ones I talked about, I've got QR codes here,
so leave those up for a second. Oh, perfect. Thank you so much. Yeah, no worries. Thank you.
Hi, I'm Kelsey. Thanks very much for every stimulating presentation. I like the graphics
and the experimental modeling was awesome. Now, you mentioned the notion of pragmatic rewards
earlier, and it came up in the fidgeting designs. What I'm curious about, though, is the whole notion
of rewards and information you mentioned control. How does the dynamic nature of these values,
or something that may be rewarding in an instant, may not be rewarding in another instant.
The dynamic values of rewards, how do you model that? And then just how do you contrast those
dynamic values with more static types of treats? That's my question. Sorry, we're cutting in a
little bit. I heard the dynamic versus static rewards and asking about the pragmatic rewards
that I was talking about. Would you mind repeating the question? Sure. I was talking about those
notion of the notion of rewards that you mentioned. I really mentioned that information can also be
something that has a value and control and agency over process. What I'm seeing is that
the values of rewards are not always static. They're dynamic. Right. And I'm also seeing that
there are other static attributes, like traits, that are also played in models. So I wanted to
help you handle the dynamic transitions of rewards and those values.
Yeah, I definitely don't think that existing research does it very well, or at least not
in the detail that we would want for the predictive processing theory. Rewards end up being mostly
about prediction error minimization. The theory collapses across the value of information and
the value of pragmatic rewards in some ways. And so there's definitely context specific reward.
The magnitude of the reward differs depending on contextual information and the individual.
So I definitely think there's avenues there for more research, but I'm not sure that my
stuff really gets at that. Thank you. And that's why I found it really hard to test.
In my mind, I think it's really hard to test the fidgeting. You can find a lot of correlational
things that support the theory, but I think empirically testing the fidgeting hypothesis
is difficult convincingly for partially that reason.
Right. So in terms of how you structure the experiment is a preset to define
your behavioral prediction error metric. Can you explain that part, which is how do you
structure the experiment in order to have a defined behavioral prediction error metric?
Yeah. So we, in this experiment, we were not, we didn't design the experiment to pull
the manipulation in the experiments. And the first one was about variability and volatility.
So I didn't talk about this, but we had a low variability condition and high variability
and we had low volatility and high volatility and we had a two by two design.
So the primary kinds of things that we set out when we designed that experiment were about
looking at differences in different uncertainty conditions. But of course, because we were
measuring prediction error and we were interested in how participants make a judgment of agency
and act in these environments in order to minimize prediction error. That's the part that I focused
on today. So we didn't design it with, so parts of our design lead to differences in
prediction error like the variability necessarily has an effect on our behavioral
prediction error measure, but it wasn't, we didn't force that in the agency judgments.
Does that make sense? Yes, it does. Yeah, okay. Yeah, no worries.
Yeah. Oh, thank you so much, Casper, for your talk. It was, it was awesome. And my question is
related with prediction error and agency because sometimes we can know we are the outwards of
the sensors of factions, even if they generate a lot of prediction error. So we can have like a
big mismatch and we'll still know we made it. So how can we, we can be sure that participants were
actually taking into consideration prediction error minimization or I don't know, maybe
temporal contingencies. Yeah, yeah. Yeah, so I think the traditional views of agency are around
this comparator model, which deals with that issue even worse than an active inference approach
prediction or to agency. So under the active inference or predictive processing accounts of
agency, you judge agency when you believe that you can reach an outcome through your actions. So
you have like precise policy mappings, which is a bit different to the comparator model, which is
about the difference between the outcome that you expected and the outcome that you actually perceive.
The reason we think that we have, I think we have evidence that participants are using the
prediction error and make this judgment. And I, the reason I think that is because of this,
the participants, the, when participants choose that they are the agent, when they make this
judgment at the end that they are the agent, however they make that in their heads, it's
related to a decrease in the gradient of prediction error over the trial. And this is
whether they're right or wrong. So if they correctly choose the correct square,
then they have the lowest prediction error minimization significantly different here.
But also when they're wrong, so when they say they have agency, but actually chose the wrong
square, which kind of to me implies that it's not about the reality of the agency that they
experienced, but rather their perception or beliefs about the agency that they experienced,
which is what leads them to make this judgment at the end, rather than this kind of objective,
whether they were right or wrong. And this changes the prediction error gradient changes
depending on the judgment that they're making. Okay. Thank you. That's, that's like a perfect
answer I'm looking for. And last can I see, do you think that the same way you asked us
like to search for the square that was being moved by the participant,
do you think that this data could differ if we are just like an observer or actually
being the one that is moving actively the square? Yeah, I think so. Even just from
experiencing the videos, I don't need to show it again, but even from just experiencing the videos,
it takes you much longer to figure out the perceptual from as just a perceptual task,
which square the participants are controlling, even though it's just a visual matching between the
movement of that line and their the squares movements. Whereas when you're acting, you get
this kind of, it's like being a scientist, you can intervene on the causal process that you're
hypothesizing, which gives you much more informative information. And you can actively test the
hypothesis that you have, rather than just experiencing a mess of things and trying to
sort it out in your head. So yeah, I think there's a big difference between
doing that task as perceptual inference and doing it in an active inference kind of way.
Okay, thank you, Kelsey, and it's an amazing experimental paradigm and thank you so much.
Thank you for your question.
So there was a question by Shen in the chat. There were several questions in the chat during
your talk. I'm looking for it. She said, did only the movement of the squares change or
the perturbations introduced on the mouse trajectory as well?
So in the first experiment, there were different blocks and in the different blocks, there were
different uncertainty combinations. So in that way, the perturbations on the mouse and all of
the other squares, the variability affected all of the stimuli equally. We did manipulate that in
that experiment. So yeah, in some cases, the perturbation of the square changed as well.
Thank you, Shannon. Did you have any additional? She also said thank you.
So then I guess if no one else, I did have a question.
You mentioned that they had an earlier action given some prediction error, at least specifically
that they were more sensitive to prediction error and thus acted earlier. And I was wondering if it
also entailed that potentially they made connection or they made causal pathways faster,
which potentially linked different kinds of actions towards different kinds of
consequence? Yeah, definitely possibly. Definitely possibly. That's not a very good answer.
But one of the theories of autism from the predicted processing view is that they
most of them boil down to a higher learning rate. And some of them have claimed that autistic
people have a higher expectation for volatility. So essentially, they're throwing out their model
and replacing it more often, which I think is also consistent with this kind of action
that they're more act more often intervening to try and confirm that their model is still true.
So definitely. Yeah.
Thank you so much, Kelsey. Does anybody else have any more questions for Kelsey?
Oh, Marco has a question.
I think you're muted, Marco.
Sorry. Very small question. Just curious because some other people also mentioned the comments.
So are you like also a graphic designer or like a teacher or like a pedagogic wizard or something?
Thank you. That's very flattering. I do art in my spare time. So I paint as a hobby and I really
enjoy doing the visual side of academia. So I'm not a graphic designer, but I do have a little
bit of training in artistic stuff. In the realm of academia, you definitely be a graphic designer.
Looks like it. Thank you.
So I know there's a lot more questions possibly, but we are at the end of today's conference. If
you have any questions you wanted to ask Kelsey, I suggest either you go talk to her if she's still
available today or send an email. I know that maybe you want to share an email or just...
Awesome. I'm also on Twitter if you prefer Twitter.
I'm also happy to stick around.
