in the Cognition and Philosophy Lab at Monash University in Melbourne, Australia, and her
presentation is entitled The Self-Interaction.
Thank you very much for that introduction, all right.
So thank you again for that beautiful introduction and for inviting me to give a keynote today.
I'm really honored by the invitation.
I'm speaking to you today from Monash University in Melbourne, Australia.
I've had to get a special legal permit to leave my home since we're still in lockdown.
We're the city with the longest lockdowns cumulatively so far since the beginning of the pandemic,
and we're coming up on 260 days this week.
So if my word finding is poor, it's because I haven't talked to people in a long time.
But I hope today that I'll give you an engaging presentation anyway.
Today I'm going to talk to you about my work on the self in action, particularly,
and a little bit about the role the role this plays in autism spectrum conditions.
Let me get my phone turned off.
So what I hope is kind of common knowledge or understanding for today's audience,
the predictive processing framework says that the brain models the world to minimize prediction error
and maintain homeostasis or resist entropy.
Minimizing prediction error is about matching our expectations with our sensory input from the world.
And this is supposed to explain both perception and action.
So it's a very unifying theory compared to most cognitive understandings of cognition.
Most understandings of cognition wouldn't tie perception and action under one theory.
So it kind of provides new and exciting ways in.
But most people who talk about predictive processing or active inference don't talk about the self.
And I was happy to hear that some of the conversation happening in the audience,
but in the break people were talking about agency and the self.
So hopefully this fits in nicely with what you've been talking about today so far.
I want to say that if you don't care about selves, if you don't build yourself into your model of hidden causes,
then you're probably going to fail miserably at minimizing prediction error.
Because our selves, the deep hidden causes in our cognitive architecture,
as well as our bodies and things like that, cause a lot of sensory input.
And so in order to properly account for the sensory input that's coming in, we also have to model ourselves.
And what do I mean by a self? What kind of representation am I talking about?
I am talking about things like your body, your internal states,
the size and shape of your body and how your materiality kind of interacts with other physical things in your world.
But also your past experiences, which you might, some of them become conscious priors.
Also the likely future states of your organism and how you're going to get there.
So what kinds of policies you'll infer likely in order to achieve the likely future states of your organism.
And also how effectively you minimize prediction errors.
So are you really good at the job that your brain does or not so good?
The self then is an inferred hidden cause and it's therefore malleable,
just like any other hidden cause that's subject to incoming information.
And we learn about ourselves every day of our lives.
Perhaps uniquely, it's a reflexive, it's a reflexive representation,
which means that the thing that's doing or representing is also the thing of being represented.
It's also maybe one of the deepest hidden causes, the most temporally extended hidden causes that's
there from the very beginning and lasts throughout our lives, constantly being shaped and modeled.
So when I talk about active inference, I just want to get clear on some of the terms I'm going to use
and how they relate to selfhood. I think in the classic predictive process,
classic predictive coding specifically, when back when we started thinking about predictive
mechanisms in the brain, we were focused primarily on perceptual inference,
where we would change our mental model to match the world. So you can think about this as like
watching a TV screen. It's a fairly passive process. If you see something that you don't expect,
then you change your expectations. But actually, and very importantly, when we're looking at
representing selves, particularly the new and improved predictive processing, so I'm going
to contrast predictive coding with predictive processing. I'll primarily use the second term.
I'm talking about then the addition of the active inference option to this kind of
predictive mechanisms. And what I mean by that is that not only do you change your mental model to
match the world when you get prediction error, but you also have the choice of changing the world
to match your mental model. So you interact with the things that you're perceiving, you interact
with other causes, and you can get feedback from that process. So when you get prediction error in,
then you have two choices, you can either change your expectation to match the world,
or you can change the world to match your expectation. So this is particularly important
for selves, because we have this reflexive feedback driven evidence driven representation,
which requires you to experimentally poke things in the world. So this involves the action
perception lip, which is going to be a recurring theme in my keynote today. So if our job is to
match the internal states of our cognitive systems with the hidden states of the world
to minimize prediction error, we only have access to the hidden states through our sensory input.
So it's mediated by the sensory apparatus that we have, we don't have direct access to the
hidden states of the world. And we can only poke the world through action. So our access to the
world is mediated through this action and sensory input. So how does this relate to selves? Let's
take an example. Let's imagine that I see myself as a really good active inference academic,
and one of the future states of the world that I perceive myself to be in is writing a really
good paper about active inference. So how do I make this future state that I expect myself to be in
come to reality, come to fruition? I act, this is fairly trivial, I type on the keyboard. My typing
on the keyboard affects the hidden states in my computer, but this is true for all sorts of things
around us, not just computers. But I don't actually understand the kind of causal mechanisms
underlying all the stuff I'm doing, I don't directly interact with the code of the computer.
But I do get some sensory input from my word processing program. But unfortunately, as all
academics I'm sure, my first couple sentences in the first draft of my paper is usually not a
really good paper about active inference. So I've got some prediction error, some difference between
my expected future state and the state of the world at the moment, which is causing prediction
error. And of course, as a good organism, my job is to minimize prediction error, or that's what
my brain naturally does. So one way that I can do this is by continuing to write. So continuing to
edit or write a new paper. And so to act on those hidden states in order to try and minimize
mismatch by bringing about a better sensory input that more closely matches my internal
state. Now notice the thing that makes my self-representation true is my ability to
close this loop and minimize prediction error. So what grounds my inference that I'm a good
academic, that my self-perception, my self-concept is true, are my actions and how effectively I
can minimize prediction error in this loop. So another option for me if I can't minimize this
prediction error is to totally abandon this expectation of myself as being a really good
academic who writes good papers about active inference. So I think another really exciting
development in the predictive processing space is the new avenues in for understanding psychiatric
conditions. And there are a bunch of people who have applied the predictive processing models to
autism particularly, which I think are making really interesting roads into understanding the
architecture in autism. But I wanted to give you a little taster from the perspective of an
autistic person themselves. So I'm going to show you a little quote from an autistic woman,
Leanne Holiday Wiley, who wrote in her autobiography, the human saga is just not reliable enough for
me to predict. Social situations are not the only thing I find unreliable and hence untrustworthy
and uncomfortable. My sense of visual perception often plays tricks on me, making it difficult
for me to do ordinary tasks. Generally speaking, I know I should not rely on my own visual
perception, but practically speaking, it's sometimes impossible to rely on anything else.
And there are a few things I wanted to pull out of this quote from this autobiography.
One is that prediction and uncertainty or minimizing uncertainty across lots of different
contexts seems really important to her sense of her own cognition and perception.
And that this is not restricted to social situations, which is what most autism research
has focused on so far. So she extends it to visual perception, which I would also say,
well, we should listen to people who experience it, but I totally agree that a lot of autism
is not just in social situations, but also in perception and action behavior.
And that this plays a really big role in her life, that it is really meaningful for her to
understand the difficulty she's having with prediction or that that plays a really big
role in her lived experience. So if I say that selves are just another hidden cause and autism
might be related to differences in predictive processing mechanisms, then we might expect that
autistic selves would present differently than neurotypical selves. So we did a big review of
over 100 papers in cognitive science with different paradigms to try and understand
selves in autism. And we found differences across most domains of cognition. So for example,
we found that autistic people generally show a reduced memory for self, reduced attention to
their own name, developmental delay in mirror self recognition, a difference in cue integration
and the rubber hand illusion, which is about the bodily representation of the self, difficulties
in interception. So understanding your own kind of internal signals, which relates to high prevalence
of olexithymia, which is the inability to name and recognize your own emotions, and a reduced and
less accurate use of pronouns. And when I say that, I mean primarily the use of the word I to refer to
oneself. Now I want to stop here for a second and give you a little puzzle to think about for the
rest of the talk, which hopefully I'll answer at the end. And that is how do we explain fidgeting
under active inference. So fidgeting like clicking pens, tapping your foot, you'll probably be doing
it for the rest of my talk now. You might think that autistic people fidget more often. So they
call it stimming in the community. It's a self stimulatory actions. And you can think of it as
kind of a more frequent or more socially unacceptable form of fidgeting. So the same kinds of explanations
I think apply for stimming and a neurotypical person fidgeting. And the question, the reason
this is a little bit of a puzzle is it seems like if all action is explained as a way to minimize
prediction error, how do we explain actions like fidgeting that don't seem to give us more information
about the environment? We're not manipulating elements of the environment in order to learn about
them. And we're not seeming to get any kind of pragmatic reward. So I'll come back to this at
the end, keep it in mind, try not to fidget too much throughout the talk. But just as a kind of
introduction, trying to find a way into fidgeting might help us understand a bit more about autism
and how active inference works. So the focus of my talk today is going to be on two experiments
about self inference in uncertain environments. And traditionally, when we look at acting in
uncertain environments, we have two primary reasons to act. The first is acting for reward or
pragmatic gain. So for example, grabbing an apple off the trees, acting to obtain some reward that
maintains your homeostasis. The other way that we usually talk about acting is acting for information.
And when we're talking about acting for information in this kind of literature,
usually we're talking about acting to find out whether there is reward for your future self
in a certain environment. So is there a lot of apples on this tree? Or should I go over to that
tree? Because there are more apples there. So this is kind of classic foraging literature.
But I want to say that there's something more fundamental than either acting for reward or acting
for information about the availability of reward. And that's acting to figure out what we can control
in the environment. So acting in order to make agency inferences. So to fiddle with stuff in the
world and figure out what I can control. And if you can't do that, then you probably can't act for
reward very easily. You can't act for information very easily. You have to first map
your actions to their outcomes. So I'm going to talk about these two experiments. The first was
published in cognition earlier this year. The second's on the archive. And hopefully tell you a bit
more about agency inferences in uncertain environments. So if we go back to the action
perception loop, one really nice way to access the action perception loop experimentally is
through a judgment of agency. So this kind of task asks participants which of the sensory
inputs should I attribute to my actions? It asks them to infer I did that. But as we all know,
especially in this field, the connections between actions and hidden states and hidden states and
sensory input is not quite as precise and neat and clean as we would perhaps like it to be.
We live in a noisy world and there's a lot of environmental uncertainty out there.
There's probably also uncertainty on this side of our action perception loop. But for today,
I'm going to focus on environmental uncertainty. So these two experiments are going to look at
participants making a judgment of agency in an uncertain environment to try and understand
this action perception loop a bit better. So I'm going to show you a video of the task.
Hopefully it works. The participants task was to look at the screen and figure out which of
these eight squares they could control with their mouse. They had other than that pretty free range
movement across the whole screen. The edges of the screen kind of wrap around so they kind of have
endless space to move around in. They can make choices about how they do the task. Basically,
the idea is just explore this two-dimensional space and tell us which square you controlled.
Because you're not controlling the square, I've got a little line in the middle of the screen
which indicates the direction and speed of movement. So if the line is longer, they were
moving faster. If it was shorter, then they moved it slower. So see if you can figure out which
of those squares this participant is moving. So now they're moving to the left
and left, right, left, right. So all of the squares are kind of jittering around a little bit,
but the square that they're controlling should follow the movement of the mouse.
I'll show you one more time. Put your answer in the chat for which one you think the participant
is controlling. So it's a little bit harder when you're not actually intervening on the
underlying causal mechanisms, but see if you can figure it out. I'll give you doubly the chance
of a participant. And you can see my map lab underneath. All right, so I see a bunch of oranges
in the chat and you are correct. So this is the underlying data that we get from a trial like
that. In the top left-hand corner, I've got the variability. So this is how much jitter was in
each of those squares movements. It's the same across all the squares, including this square,
which is the me square that the participants were trying to find. And that also changes during
the trial. This is another video, so I'll show you how that works. So that's our variability and
volatility manipulation, which I actually won't talk a lot about today other than they're acting
in an uncertain environment. So if you're interested in that, check out the paper.
We also see in all of the distractor squares, there's this number that's an angular offset from
the trajectory of the me square. So if the participant moves up and to the right, square
number three is going to move 99 degrees around the circle to the left from where the mouse is
moving. And those numbers also change three times during the trial. So those squares turn when the
participant doesn't turn. We see these two white boxes. Those indicate the participant's eye position,
so each box is a different eye. And we see from that we can infer, as researchers, which of the
squares the participant's looking at at any moment during the trial. So that's indicated by the screen
square. It's my algorithm trying to decide which one the participant's looking at. So let's look
at how that trial looks with all of the data kind of laid on top. So we can see, like I said,
a really rich data set, including what the participant's looking at and how they're moving
and how all of the stimuli on the screen are moving. We can see that they're switching around
between the squares quite a bit, but they haven't quite found the correct square yet.
They should be watching ones with kind of small numbers close to zero because those are the ones
that are closest to their movements. And they finally land on the V square at the end of the
trial. So when the trial ends, the black numbers pop up on screen, and they press a button to
indicate which square they thought they controlled. If they thought they controlled no square and there
were trials where they controlled no square, they pressed a zero button. So they also had that choice
