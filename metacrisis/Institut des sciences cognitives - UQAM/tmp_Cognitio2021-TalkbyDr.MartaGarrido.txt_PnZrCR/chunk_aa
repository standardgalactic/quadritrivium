This is the last talk of our day, end of the event, and it's from the keynote speaker,
Dr. Marta Garrido.
She was invited by us to present her work at Cognito 2021, and we are really happy that
she's here with us today.
Dr. Garrido is a neuroscientist.
She leads the cognitive neuroscience and computational psychiatry laboratory at the
Melbourne School of Psychological Sciences at the University of Melbourne, where she's
an associate professor.
She is the chief investigator at the Australian Research Council Center of Excellence for
Integrative Brain Function, and Marta initially trained in engineering physics at the University
of Lisbon and then received her PhD in neuroscience from the University College London in 2008.
The main goal of her lab is to understand how the brain learns and makes predictions
about future events while adapting to the contingencies of novel environments.
Her presentation today is entitled, Bayesian Accounts of Autistic Perception, and I will
let her take it away from the show.
Thank you so much for a very nice introduction, and thanks to the organizers for inviting
me.
It is an honor to be here and speak to you.
So a few words of warning, well, first of all, you already noticed that I am a bit of
a dinosaur.
It's the first time I'm using Gadotan, so bear with me for any issues.
The second thing is we're still on lockdown in Melbourne, so I'm at home with two little
kids, so they may or may not make an appearance.
I'm hoping that they'll be quiet.
Okay, so yeah, the last warning is that I decided to give a new talk because I was getting
a bit bored of my prepared slides from a previous talk, and I also thought it would be more
fun in this young context to give a talk on a paper that it's not out yet.
And so I'll be really keen to hear your feedback.
So let me share my screen, and please interrupt me if there's any issues with the slides or
if you can't hear me.
Okay, so today I'll be talking about basic accounts of Autistic Perception.
So basic inference is something that I've been kind of obsessed about for a very long
time, but only a few years ago when a student of mine, Roshini Arandaniya, joined the lab,
I actually thought about doing, to test some of these ideas in autism, and that was really
prompted by her saying, well, I would really like to be in your lab, but I want to study
autism.
And at the time I thought, but I don't really know a lot about autism, but I knew a few
things about basic inference.
And so what happened is what you'll see in the next few slides.
So a few notes about basic inference, and let's bring this back to some real life experiences,
which I'm not having much of it at the moment with lockdown, but hopefully eventually.
So we are in a concert, and we're listening to very nice song that we know by heart.
From the first notes of that song, you are able to guess what they're going to sound
like.
So this, it's quite a common experience, I believe, for all of us.
And of course, these are professional musicians, so mistakes don't really happen, but they
might improvise or they might make some arrangements that make it a little bit surprising.
And so, of course, if you hear the song, take a different route from what you are used
to from what you listen to at home, then you'll be surprised.
So if we were able to put an EEG machine or some electrodes around your head, we will
see a very big response in the brain to that surprising sound or that surprising change
in the auditory environment.
So this sort of phenomena has been explained in terms of basic models, such that the brain
is able to learn about the regularities that go on in the world, and when those learned
regularities don't match the actual input, then there is a very big prediction error.
And so the learned regularities might be your prior, so your prior information about what
the next few minutes are going to sound like, and that prior is based on your previous experience.
You know this song, you have a CD at home, not CD, another dinosaur thing, you listen
to that at home, but in the live concert it is quite different.
So what is happening currently as the input into your EEG is your current sensory information,
and in this case it's fairly unambiguous, but there are situations where the current
information is actually quite ambiguous or uncertain, and so having prior information
is useful to resolve that ambiguity, and that's why basic models have been really so
popular in understanding perception and cognition.
So another example which I think illustrates the basic principles of brain and behavior
for perception and cognition is over here, so you may or may not have seen this image
before, if you've never seen this image before, all you see is sort of patches, black and
white patches and nothing too interesting, however if you see this object over here you
might identify it as a dog or some sort of animal, and then once you see this image again
you can't not see the dog again, and so I think that really demonstrates that perception
is not just sensory information, it's actually a combination of prior information and sensory
information, so again this is an ambiguous image, can you see my cursor when I move?
Yes, yes, no problem.
So again this is an ambiguous image, we might try to make sense of it with whatever priors
we have, if I hadn't, the first time I showed you didn't really have a prior for this image,
so you couldn't really recognize anything from this quite ambiguous information, but
then once you see it then you've got a prior that you can feel in or you can use to resolve
that ambiguity and then you can say oh actually this image represents an animal.
So I think this is a good demonstration that perception depends on prior experience and
it also tells us that the brain is not really a passive machine registering information
from our senses, but it is actively trying to infer what's going on in front of us.
Here's another example, the Canis illusion, so I would ask everybody how many triangles
they can see on the screen and for most of you you'd say two.
In fact the actual reality is that there's no triangles drawn on the screen, but your
brain can infer or can feel in lines over here and over there and sort of imagine, you
can imagine in your head that there's actually two triangles.
So I think again this is another nice demonstration that perception is not passively registering
information from the environment, it is an active process where we feel in with information
that we have from our prior experiences in order to make sense of what we see and hear
and again it depends on prior knowledge.
Now what does this have to do with autism?
So it turns out that autistic individuals are less prone to the Canis illusion and this
has been shown by Francisca Hap√© many many years ago now.
So the question is really why?
Why is it that autistic individuals actually see things more the way they are in this case?
So they don't actually have the illusion of seeing triangles in this image.
So different theories have been put forward around ideas of stronger bottom-up sensory
information.
So autistic perception being more accurate due to the perception of bottom-up information.
So the information that comes from the environment to our senses being more precise.
Another point of view argues that actually it's not about the bottom-up information,
it's the top-down or prior effects.
So there's weaker top-down effects, so there's weaker priors that what the representation
of a triangle is in people's head.
So there's been evidence of foreign against both of these accounts and the data is really
quite messy.
Now in 2012 these sort of bottom-up top-down ideas have been formalized in a mathematical
model or a Bayesian account and that's really when I got excited about testing ideas of
autistic perception with a Bayesian framework.
And so to formalize, so this is a bit of a busy slide, so just bear with me, let's focus
on A first.
So we can formalize Bayesian perception in terms of priors, our experiences, memories
and so forth, that's in blue, and then we've got sensory information in red.
So these are the things that you can hear, the things that you can see and quite often
these things can be ambiguous.
And so we don't know for sure the exact causes of the sensory environment, but what we can
do is to make an inference to guess what is it that we're seeing, like the case of the
dog on the screen.
So we have some ambiguous information, we try to sort of reconstruct in our head what
does that messy information mean.
So in Bayesian terms what the proposal is that in perception we actually combine the
prior information with the sensory information and at the end our percept is actually drawn
from a posterior.
So mathematically speaking we've got, if we assume that priors are Gaussian and the sensory
information is also represented by a Gaussian, then we can integrate the prior and the likelihood
and have again another Gaussian which is our posterior with a mean somewhere between the
prior and the likelihood and the variance being a weighted version of the other two
variances.
So the posterior usually is narrower and is somewhere in between the prior and the likelihood.
And whether it's closer to the prior or closer to the likelihood depends on the precision,
the relative precision of the prior and the likelihood.
So here is right in the middle, but if you see the graph in the bottom for B when the
prior is actually flatter there's a shift of the posterior in this case the percept towards
the sensory information because the sensory information is relatively more precise than
the prior.
So actually this model here, the hyper priors model where the prior is sort of flatter or
more variable, less reliable, has been proposed as a model for autistic perception by Felly
Canberra in 2012.
And so as you can see here for typical individuals will be like A, autistic individuals if the
hyper priors model was true would show that perception is closer to the sensory information
and that is that matches what the Canisian illusion, the triangles illusion demonstrate.
However, there's a bit of a conundrum here because and this was in describing a response
by to Felly Canberra also in ticks and written by John Brock.
And what he said was well sensory information, likelihood information can or sorry the perception
in autistic individuals can be closer to the sensory information or the likelihoods.
But for a different reason, not because the the priors are flatter or less precise.
So this idea of the top down information being weaker, but because the bottom up information
is stronger.
Okay, so that is represented here in the sensory information being sharper or more precise.
And as you can see the effect for the percept or the posterior is the same, there's a shift
towards the sensory information.
So really there's a conundrum here that we it is pretty hard to disentangle these two
models.
At the end of the day, autistic perception is closer to sensory information than prior.
But for two, it can be for two very different reasons, or either.
So we were sort of intrigued by these models.
And we really wanted to empirically test what's going on here.
So this bar is just to indicate how the shift relative to to the typical learning.
So to recap, the model predictions are for these for these two accounts are actually
quite different, except for the first one, which is that autistic individuals rely more
on sensory than prior information.
So both of these accounts predict that, however, only one of these accounts predict that autistic
individuals have less precise priors and typical individuals and that's the hyper priors model.
The precise likelihood model, on the other hand, predict that autistic individuals have
more precise sensory representations than typical individuals.
So really the question that intrigued me and Roshini Arrandinier, who was a PhD student
in my lab, was how do we actually go about empirically testing these models?
Because at the end of the day, what we do in my lab is a very empirical form of computational
psychiatry where we are excited about the ideas, but at the end of the day, we want
to go into the lab and collect data to empirically test them and hopefully disambiguate these
different models.
Okay, so yeah, we were sort of like, okay, how are we going to test these ideas?
Unfortunately, at the time, I was quite excited about this study by Ariz Valariz in Conrad
Cording's lab, which showed very nicely that neuro-typical individuals, so this was just
a normative population, are in integrate sensory information and prior information.
In a Bayesian way, not necessarily optimally, but we'll come to that at the end.
But what they did in this task was to manipulate sensory information to be either with a lot
of uncertainty or less uncertainty, so that is represented here in this two by two design.
So we've got likelihood, which is narrow, so quite precise, and wide, not very precise,
and the sample prior.
So let me tell you what this looks like in a task, but for now, so it's a two by two
design, two factors, prior and likelihood, two levels, narrow and wide.
So what people have to do, so they told there's somebody throwing a coin at the center of
the screen, and what they see are actually the splashes that the coin makes when it falls
on the water.
So the splashes can be quite spread out or quite concentrated, but regardless, the person's
job is to move the net, so the subject moves the net to the estimated position.
Where do they think that the coin fell based on these splashes?
And then at the end, the coin is shown to the participant, so this was in yellow here,
the true hidden position of the coin.
So what's hidden here is that the likelihood, as I said, can be quite spread out, that's
the case here, or quite precise.
So this is how likelihood information is manipulated.
So again, here the variance is small or narrow, and here the variance is wide or big.
So in these situations, as you see, people have to guess what is causing the dots, that's
their job.
If they only use the information from the likelihood, they will put it bang in the middle
of the dots, but it turns out they're not just doing that, because they were told in
the beginning that the thrower is aiming at the center of the screen.
And they learn by trying an error that that's actually happening, that these dots are more
