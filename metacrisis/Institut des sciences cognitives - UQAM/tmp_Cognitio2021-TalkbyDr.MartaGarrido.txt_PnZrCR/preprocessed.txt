This is the last talk of our day, end of the event, and it's from the keynote speaker,
Dr. Marta Garrido.
She was invited by us to present her work at Cognito 2021, and we are really happy that
she's here with us today.
Dr. Garrido is a neuroscientist.
She leads the cognitive neuroscience and computational psychiatry laboratory at the
Melbourne School of Psychological Sciences at the University of Melbourne, where she's
an associate professor.
She is the chief investigator at the Australian Research Council Center of Excellence for
Integrative Brain Function, and Marta initially trained in engineering physics at the University
of Lisbon and then received her PhD in neuroscience from the University College London in 2008.
The main goal of her lab is to understand how the brain learns and makes predictions
about future events while adapting to the contingencies of novel environments.
Her presentation today is entitled, Bayesian Accounts of Autistic Perception, and I will
let her take it away from the show.
Thank you so much for a very nice introduction, and thanks to the organizers for inviting
me.
It is an honor to be here and speak to you.
So a few words of warning, well, first of all, you already noticed that I am a bit of
a dinosaur.
It's the first time I'm using Gadotan, so bear with me for any issues.
The second thing is we're still on lockdown in Melbourne, so I'm at home with two little
kids, so they may or may not make an appearance.
I'm hoping that they'll be quiet.
Okay, so yeah, the last warning is that I decided to give a new talk because I was getting
a bit bored of my prepared slides from a previous talk, and I also thought it would be more
fun in this young context to give a talk on a paper that it's not out yet.
And so I'll be really keen to hear your feedback.
So let me share my screen, and please interrupt me if there's any issues with the slides or
if you can't hear me.
Okay, so today I'll be talking about basic accounts of Autistic Perception.
So basic inference is something that I've been kind of obsessed about for a very long
time, but only a few years ago when a student of mine, Roshini Arandaniya, joined the lab,
I actually thought about doing, to test some of these ideas in autism, and that was really
prompted by her saying, well, I would really like to be in your lab, but I want to study
autism.
And at the time I thought, but I don't really know a lot about autism, but I knew a few
things about basic inference.
And so what happened is what you'll see in the next few slides.
So a few notes about basic inference, and let's bring this back to some real life experiences,
which I'm not having much of it at the moment with lockdown, but hopefully eventually.
So we are in a concert, and we're listening to very nice song that we know by heart.
From the first notes of that song, you are able to guess what they're going to sound
like.
So this, it's quite a common experience, I believe, for all of us.
And of course, these are professional musicians, so mistakes don't really happen, but they
might improvise or they might make some arrangements that make it a little bit surprising.
And so, of course, if you hear the song, take a different route from what you are used
to from what you listen to at home, then you'll be surprised.
So if we were able to put an EEG machine or some electrodes around your head, we will
see a very big response in the brain to that surprising sound or that surprising change
in the auditory environment.
So this sort of phenomena has been explained in terms of basic models, such that the brain
is able to learn about the regularities that go on in the world, and when those learned
regularities don't match the actual input, then there is a very big prediction error.
And so the learned regularities might be your prior, so your prior information about what
the next few minutes are going to sound like, and that prior is based on your previous experience.
You know this song, you have a CD at home, not CD, another dinosaur thing, you listen
to that at home, but in the live concert it is quite different.
So what is happening currently as the input into your EEG is your current sensory information,
and in this case it's fairly unambiguous, but there are situations where the current
information is actually quite ambiguous or uncertain, and so having prior information
is useful to resolve that ambiguity, and that's why basic models have been really so
popular in understanding perception and cognition.
So another example which I think illustrates the basic principles of brain and behavior
for perception and cognition is over here, so you may or may not have seen this image
before, if you've never seen this image before, all you see is sort of patches, black and
white patches and nothing too interesting, however if you see this object over here you
might identify it as a dog or some sort of animal, and then once you see this image again
you can't not see the dog again, and so I think that really demonstrates that perception
is not just sensory information, it's actually a combination of prior information and sensory
information, so again this is an ambiguous image, can you see my cursor when I move?
Yes, yes, no problem.
So again this is an ambiguous image, we might try to make sense of it with whatever priors
we have, if I hadn't, the first time I showed you didn't really have a prior for this image,
so you couldn't really recognize anything from this quite ambiguous information, but
then once you see it then you've got a prior that you can feel in or you can use to resolve
that ambiguity and then you can say oh actually this image represents an animal.
So I think this is a good demonstration that perception depends on prior experience and
it also tells us that the brain is not really a passive machine registering information
from our senses, but it is actively trying to infer what's going on in front of us.
Here's another example, the Canis illusion, so I would ask everybody how many triangles
they can see on the screen and for most of you you'd say two.
In fact the actual reality is that there's no triangles drawn on the screen, but your
brain can infer or can feel in lines over here and over there and sort of imagine, you
can imagine in your head that there's actually two triangles.
So I think again this is another nice demonstration that perception is not passively registering
information from the environment, it is an active process where we feel in with information
that we have from our prior experiences in order to make sense of what we see and hear
and again it depends on prior knowledge.
Now what does this have to do with autism?
So it turns out that autistic individuals are less prone to the Canis illusion and this
has been shown by Francisca Hap√© many many years ago now.
So the question is really why?
Why is it that autistic individuals actually see things more the way they are in this case?
So they don't actually have the illusion of seeing triangles in this image.
So different theories have been put forward around ideas of stronger bottom-up sensory
information.
So autistic perception being more accurate due to the perception of bottom-up information.
So the information that comes from the environment to our senses being more precise.
Another point of view argues that actually it's not about the bottom-up information,
it's the top-down or prior effects.
So there's weaker top-down effects, so there's weaker priors that what the representation
of a triangle is in people's head.
So there's been evidence of foreign against both of these accounts and the data is really
quite messy.
Now in 2012 these sort of bottom-up top-down ideas have been formalized in a mathematical
model or a Bayesian account and that's really when I got excited about testing ideas of
autistic perception with a Bayesian framework.
And so to formalize, so this is a bit of a busy slide, so just bear with me, let's focus
on A first.
So we can formalize Bayesian perception in terms of priors, our experiences, memories
and so forth, that's in blue, and then we've got sensory information in red.
So these are the things that you can hear, the things that you can see and quite often
these things can be ambiguous.
And so we don't know for sure the exact causes of the sensory environment, but what we can
do is to make an inference to guess what is it that we're seeing, like the case of the
dog on the screen.
So we have some ambiguous information, we try to sort of reconstruct in our head what
does that messy information mean.
So in Bayesian terms what the proposal is that in perception we actually combine the
prior information with the sensory information and at the end our percept is actually drawn
from a posterior.
So mathematically speaking we've got, if we assume that priors are Gaussian and the sensory
information is also represented by a Gaussian, then we can integrate the prior and the likelihood
and have again another Gaussian which is our posterior with a mean somewhere between the
prior and the likelihood and the variance being a weighted version of the other two
variances.
So the posterior usually is narrower and is somewhere in between the prior and the likelihood.
And whether it's closer to the prior or closer to the likelihood depends on the precision,
the relative precision of the prior and the likelihood.
So here is right in the middle, but if you see the graph in the bottom for B when the
prior is actually flatter there's a shift of the posterior in this case the percept towards
the sensory information because the sensory information is relatively more precise than
the prior.
So actually this model here, the hyper priors model where the prior is sort of flatter or
more variable, less reliable, has been proposed as a model for autistic perception by Felly
Canberra in 2012.
And so as you can see here for typical individuals will be like A, autistic individuals if the
hyper priors model was true would show that perception is closer to the sensory information
and that is that matches what the Canisian illusion, the triangles illusion demonstrate.
However, there's a bit of a conundrum here because and this was in describing a response
by to Felly Canberra also in ticks and written by John Brock.
And what he said was well sensory information, likelihood information can or sorry the perception
in autistic individuals can be closer to the sensory information or the likelihoods.
But for a different reason, not because the the priors are flatter or less precise.
So this idea of the top down information being weaker, but because the bottom up information
is stronger.
Okay, so that is represented here in the sensory information being sharper or more precise.
And as you can see the effect for the percept or the posterior is the same, there's a shift
towards the sensory information.
So really there's a conundrum here that we it is pretty hard to disentangle these two
models.
At the end of the day, autistic perception is closer to sensory information than prior.
But for two, it can be for two very different reasons, or either.
So we were sort of intrigued by these models.
And we really wanted to empirically test what's going on here.
So this bar is just to indicate how the shift relative to to the typical learning.
So to recap, the model predictions are for these for these two accounts are actually
quite different, except for the first one, which is that autistic individuals rely more
on sensory than prior information.
So both of these accounts predict that, however, only one of these accounts predict that autistic
individuals have less precise priors and typical individuals and that's the hyper priors model.
The precise likelihood model, on the other hand, predict that autistic individuals have
more precise sensory representations than typical individuals.
So really the question that intrigued me and Roshini Arrandinier, who was a PhD student
in my lab, was how do we actually go about empirically testing these models?
Because at the end of the day, what we do in my lab is a very empirical form of computational
psychiatry where we are excited about the ideas, but at the end of the day, we want
to go into the lab and collect data to empirically test them and hopefully disambiguate these
different models.
Okay, so yeah, we were sort of like, okay, how are we going to test these ideas?
Unfortunately, at the time, I was quite excited about this study by Ariz Valariz in Conrad
Cording's lab, which showed very nicely that neuro-typical individuals, so this was just
a normative population, are in integrate sensory information and prior information.
In a Bayesian way, not necessarily optimally, but we'll come to that at the end.
But what they did in this task was to manipulate sensory information to be either with a lot
of uncertainty or less uncertainty, so that is represented here in this two by two design.
So we've got likelihood, which is narrow, so quite precise, and wide, not very precise,
and the sample prior.
So let me tell you what this looks like in a task, but for now, so it's a two by two
design, two factors, prior and likelihood, two levels, narrow and wide.
So what people have to do, so they told there's somebody throwing a coin at the center of
the screen, and what they see are actually the splashes that the coin makes when it falls
on the water.
So the splashes can be quite spread out or quite concentrated, but regardless, the person's
job is to move the net, so the subject moves the net to the estimated position.
Where do they think that the coin fell based on these splashes?
And then at the end, the coin is shown to the participant, so this was in yellow here,
the true hidden position of the coin.
So what's hidden here is that the likelihood, as I said, can be quite spread out, that's
the case here, or quite precise.
So this is how likelihood information is manipulated.
So again, here the variance is small or narrow, and here the variance is wide or big.
So in these situations, as you see, people have to guess what is causing the dots, that's
their job.
If they only use the information from the likelihood, they will put it bang in the middle
of the dots, but it turns out they're not just doing that, because they were told in
the beginning that the thrower is aiming at the center of the screen.
And they learn by trying an error that that's actually happening, that these dots are more
or less, or the true position of the coin ends up being more or less around the center.
So they actually using, as they saw behaviorally, I'll show you in a minute, that people are
using that information as well.
Now the prior variance is also manipulated, because there are two throwers.
And they can see also, again, by trial and error, that one of the throwers is really
quite precise in aiming at the middle.
And then thrower, say that's thrower A, and thrower B is actually not very precise.
So the true heated position of the coin ends up being quite far away from the screen as
it is here in this snapshot.
So here's the visual description of what the narrow prior would be like, and this will
be what a wide prior would be like.
So that has to do with where the tidal position ended up being at the end, which they see
through feedback.
So what have they shown?
So these graphs, so this is behavioral data from one individual representative of the
population.
And what they plotted here was the centroid position, the actual position of the coin,
and on the y-axis is the estimated position.
So these are people's responses.
Every dot is the participant response in a trial, for, yeah, in a trial, for the four
different conditions.
So narrow, likelihood with narrow prior, wide likelihood narrow prior, narrow, likelihood
wide prior in red, and then wide prior, wide likelihood in orange.
Okay.
So the same conditions as this box over here, and I'll use that thrower.
So what can we see here?
So first of all, we see that the slopes for the different conditions is changing.
So that indicates, and that was proved to be significant.
So that shows that people are taking both likelihood and prior into account.
Also what I want to point out is if people were just using the prior all the time and
ignoring the likelihood, they would always put the estimated position in the middle.
So that's not happening.
If they were always putting the coin, always taking into account simply the likelihood
information, then they would always put the position of the coin exactly in the middle,
and now you would see a regression on the diagonal.
So that's not happening either.
What is actually happening is that the people's estimation of the position of the coin is
somewhere in between the prior and the likelihood.
And as you can see, if you look at these two are the most interesting conditions to highlight
how people are waiting the likelihood and the prior relatively.
So if you look at this one, when the likelihood is wide, so likelihood is not very reliable,
people actually rely more on the prior, and so you see the slope going closer to the flat
line.
On the other hand, when the likelihood is narrow, more precise, people rely more on
the likelihood information than the prior, naturally.
So people rely more on the most reliable source of information.
So that's how it should be.
So again, this is just reiterating that prior sensory reliance depends on the relative reliability.
Now I'm just plotting this again here on the left, and I will just go very quickly through
the measures that this paper offered, which is where we saw an opportunity to test our
ideas.
So first of all is the slope of these plots that indicate the relative reliance of narrow
and likelihood.
And so we thought, well, we could use this sort of measure to test the hypothesis that
autistic individuals rely more on sensory than prior information, so we could quantify
it experimentally.
The second measure that this paper used was the prior variance.
So if you do the maths, you can get into the equation that estimates a subjective prior
variance.
So the prior variance represented in each individual participant, and that has a relationship
with the slope itself, and also the variance of the likelihood, that sigma l.
So that would be very useful to test the idea of a hyperpriorism model whereby Pelican and
Borges say that the prior is flatter, or the variance is bigger.
Then the third measure, which actually this paper didn't have, but that was something that
Roshini and I came up with, which was a way of estimating people's likelihood variance.
So we can assume that people's likelihood variance is the same as by design, so driven
by the dots that they see in the skull.
But of course, we know that, or it's pretty reasonable to assume that our senses are noisy,
and so we don't represent the likelihood exactly as we see it.
And so this is what we postulated as a measure of the variance, which has to do with how
variable people are throughout the experiment in terms of where they put the middle of the
target in a no prior task.
So we ran the same task, but now removing the prior and just having likelihood only,
and that's how we came up with this measure.
So this measure has two purposes.
One purpose is to, rather than assume that people represent the likelihood as it is,
it allows for people to be noisy.
So rather than having an objective likelihood, we can have a subjective likelihood.
And then the second purpose is to test the more precise likelihood model proposed by
Brock, so that then we could have really a measure to test that idea.
Okay, going a bit slower than I had expected, but there's a lot of theory to go through.
So finally, what have we found?
So the first findings were actually quite surprising in a way.
So remember how we, both models, said that autistic individuals would rely more on sensory
information, so we would expect the slopes for autistic individuals to be closer to one
than to zero, okay?
So closer to one again is relying more on likelihood than prior.
What you see here are the slopes for the neurotypical in orange autistic spectrum in
green, and we see absolutely no difference, okay?
So we're like, okay, so actually we managed to reject both models at this stage.
But we carry on, and looking for the other measurements that you saw in the previous
slide, so the prior variance and likelihood variance.
So yeah, this is just to point out that we rejected both models.
So when we look at the different sensory weights by condition, sorry, I'm just getting
a bit ahead of myself there, but even though, so I'll just go back to this slide.
So even though when we put together all the sensory weights of the different conditions,
we see no difference, we thought, okay, let's just have a look at what's happening by condition,
and that's what I'm showing you here in this plot.
So PN, LN, that means prior likelihood narrow-narrow, prior likelihood narrow-wide, so narrow-prior
wide likelihood and so forth.
And again, the same labels, neurotypically in orange and autistic spectrum in green.
So when we put together the different conditions, even though we don't see a main effective group
we do see a group by prior interaction, whereby we show that the neurotypical individuals
have a larger difference in the sensory weights for wide-prior versus narrow compared to the
autistic spectrum group.
So it is a little bit difficult to see here, but what we're saying is that the neurotypical
individuals sort of vary more than the autistic individuals.
And so the fact that they vary more seems to suggest that, the fact that the autistic
individuals vary less relatively to the neurotypical individuals seems to suggest that there is
a poorer context adjustment, right?
Because if autistic individuals were taking into account context, they would adjust to
that context in how they weigh the relative differences in precision of prior and likelihood.
So we rejected those two models, but I think we learned something new.
The other thing that we wanted to test, our second hypothesis, was around priors.
So if you remember the hyper-prior account of Pelikan and Burr said priors are less precise,
expect greater variance.
In fact, we don't see that at all.
What we see is absolutely no difference, and which we carefully reject the hyper-prior's
account, or at least we show no evidence for that account at all.
So it seems to be that they are intact, that priors, prior variance is intact in autism.
Now as I said, we had a no-prior task, and it's a question mark, and I'll tell you in
a minute why, but here we expected to test the more precise likelihood model, but when
looking at the sensory weights, we actually saw something quite surprising.
Remember how both accounts expected the sensory weight to be greater in autism spectrum individuals?
And in the first task where we had the prior and the likelihood, we actually found no difference.
Well in this task, we actually did find a difference, but it was the wrong way around.
So we actually found lower sensory weights for autism than neurotypical individuals.
So that kind of is against both accounts.
And thinking about this, it didn't really make a lot of sense because, well, this was
supposed to have no priors.
However, when we run this task, we're removing the prime, we did that at the end of our task.
We had the main task first with priors and likelihoods, and then we did this one at the
end.
So what we think it's happening here is that actually people managed to carry over some
priors from the first task into the second task, even though they weren't supposed to.
And that was more obvious for the autistic individuals.
So again, this result is against both hyper priors and precisely likelihood models in
the sense that it doesn't predict that sensory weights are closer to the likelihood.
In fact, it's actually quite the opposite.
And we interpret this as a carryover effect from the previous to the second experiment.
And again, we don't see that this prior is less precise, we actually see that it's more
precise.
So this is the final result slide that I want to show you.
When looking at the subjective likelihood variance, so this is the measure that we postulated
for the subjective likelihood, we didn't find a difference when we contrasted the two groups.
And when we put people on the continuum, so whereby we align all the individuals, neurotypical
and autistic, and we also had another group in blue, which was high on the spectrum, but
when we did a diagnostic test with the adults, they really didn't fall onto the autistic,
onto the diagnosis.
They kind of in the middle, but because here we were aligning people on the continuum,
it didn't really matter their diagnosis.
So we put everyone together.
So when we do that, we actually see a significant relationship between the subjective likelihood
variance and the IQ, which is driven by the subscale of attention to detail.
So this is quite interesting because the likelihood variance is decreasing as autistic traits
increase, which is in a sense quite closer to the Brock's model of more precise likelihood.
So as the variance is increasing, so it's more precise for autistic traits, as the autistic
traits increase.
So we sort of tentatively confirm one of the predictions of the precise likelihood model,
although as I said, when we put people in different groups, we don't, that difference
doesn't emerge.
So we carefully confirm with some question mark that hypothesis or that prediction.
So how are we doing with the conundrum?
Can we reject, accept, or perhaps revise the models?
So here is again the Bayesian account for typical learning and the two models, hyper
prize and precise likelihood.
And if you remember, we had three different predictions, one around the sensory weights.
Both of these models, hyper prize and precise likelihood model predicted that people would
rely more on sensory information than priors, that did not happen.
So that hypothesis was kind of rejected for both models, in fact.
So we actually, the first experiment we see that it's pretty much the same.
If anything, the autistic individuals actually rely more on the priors, and that's what we
saw in the second experiment, then what happened to the priors?
So we don't really see any difference in the priors, in the prior variants, so we don't
really find any support for the hyper prize model.
In terms of the likelihood model, again, we don't see a greater sensory weight.
So that prediction isn't correct.
In terms of the prior, we see intact priors, so that seems to be a confirmed prediction.
However, as I said, in the second experiment, we actually see that there is a shift towards
the prior, which could indicate that actually the priors are not less precise but more precise.
And then finally, in terms of the prediction around the likelihood being more precise, we
tentatively say, yes, it is more precise, but only when we align people on the continuum,
we don't see that when we group them according to diagnosis.
So two things that we learned over this study was that perhaps the priors are not less precise
but more precise, and we conclude that through the second experiment where perhaps we see
carryover effects, and we also saw that there is a poorer context adjustment which might
explain rigidity behavior in autistic individuals.
So we sort of confirmed a couple of predictions.
I guess our data is closer to the precise likelihood model of Brock, even if not exactly
the same.
So we propose a revision of the model, but we also have more questions than answers in
a way.
And one of the questions is, are people really Bayesian?
And we kind of assume in this framework, because it's quite useful, but we don't really know
for sure, and we have some follow-up studies in neurotypical individuals at this stage,
actually testing some key principles around being Bayesian.
And also the other question is, are people optimal, actually they're not optimal at all.
They always suboptimal in the studies that we've run, and the question is why are people
suboptimal, and we're currently writing a review paper around trying to explain why
is it that people are suboptimal, and perhaps has to do with the biological constraints that
we have in the brain that make optimality impossible.
And then the last question to me, it's the most exciting one, is so how are these computations
implemented in the brain, so how is it that the brain leads to these sorts of behaviors
where being optimal or not, Bayesian or not, we do see integration of sensory information
and prior information, and the question really is, how does the brain do it?
And there's been a lot said about priors being top-down and likelihood being bottom-up, but
exactly where these things are encoded and how these computations are implemented in the
different parts of the brain and through connectivity, exchanges between these areas
is still unknown.
So that leaves me to thank Roshini Randini who led the study, the sources of funding
and all of you for your attention.
Thanks very much.
Thank you, Marta.
Thank you so much.
Does anyone have any questions?
If you do, can you move to the Q&A podium on the right?
I'm not sure if I stopped sharing my screen or not.
I think Kevin has a question.
Okay.
Hello.
Thank you for this talk.
It was really nice and very interesting.
I guess I have some pedantic questions about the sample size, and I guess, did you do the
power analysis on your term as well?
And also, what was the, maybe you mentioned, what was the kind of diagnostic criteria you
used to try to identify people's autism traits and those were not it?
Yeah.
So in terms of the sample size, it's not a huge sample size.
It's around a 20-something for each.
Although we actually had more neurotypical individuals than we had autistic individuals,
as it's always the case with clinical populations.
And it's just pretty hard to get big samples with special populations.
It's pretty hard to get.
But in comparison to other studies, it's surprisingly big in comparison to the other studies that
have been done with autism.
What was your other question, sorry?
I think there was a couple.
What was about the power analysis done, I guess, kind of beforehand or after planned?
And also, what was the diagnostic criteria you used to figure out if you had autistic
or not autistic individuals in the sample?
Yeah.
So the diagnosis was done with an adult's interview.
So that was run by a clinical psychologist.
So the way we did the recruitment was through different organizations and also on campus.
And so when people came to us, they would have a self-reported diagnosis of autism.
But then we ran a, or the clinical psychologist that was working with us confirmed that diagnosis
for all of them.
And as I said, in my talk, a few of them did not meet criteria for that diagnosis, even
though they were self-reported autistics.
So we left those out.
In terms of power analysis, no, we didn't do a power analysis for this study.
Mostly because we didn't really have anything to base on.
This study had never really been done in autistic individuals.
So the best we could do was to use the same sort of sample size that had been used for
neuro-typical individuals.
Yeah, I know that's not satisfying, but that was really the best we could do.
Of course now, in going into the future, that's something that we can do more confidently.
Awesome, wonderful.
Thank you again and appreciate you answering the questions.
Does anyone, sorry, does anybody else have any more questions?
If not, I will let Pierre come on to the stage for concluding remarks.
And I will thank Dr. Marta Garido for your wonderful presentation that is closing our
conference.
Thank you very much.
