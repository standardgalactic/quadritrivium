or less, or the true position of the coin ends up being more or less around the center.
So they actually using, as they saw behaviorally, I'll show you in a minute, that people are
using that information as well.
Now the prior variance is also manipulated, because there are two throwers.
And they can see also, again, by trial and error, that one of the throwers is really
quite precise in aiming at the middle.
And then thrower, say that's thrower A, and thrower B is actually not very precise.
So the true heated position of the coin ends up being quite far away from the screen as
it is here in this snapshot.
So here's the visual description of what the narrow prior would be like, and this will
be what a wide prior would be like.
So that has to do with where the tidal position ended up being at the end, which they see
through feedback.
So what have they shown?
So these graphs, so this is behavioral data from one individual representative of the
population.
And what they plotted here was the centroid position, the actual position of the coin,
and on the y-axis is the estimated position.
So these are people's responses.
Every dot is the participant response in a trial, for, yeah, in a trial, for the four
different conditions.
So narrow, likelihood with narrow prior, wide likelihood narrow prior, narrow, likelihood
wide prior in red, and then wide prior, wide likelihood in orange.
Okay.
So the same conditions as this box over here, and I'll use that thrower.
So what can we see here?
So first of all, we see that the slopes for the different conditions is changing.
So that indicates, and that was proved to be significant.
So that shows that people are taking both likelihood and prior into account.
Also what I want to point out is if people were just using the prior all the time and
ignoring the likelihood, they would always put the estimated position in the middle.
So that's not happening.
If they were always putting the coin, always taking into account simply the likelihood
information, then they would always put the position of the coin exactly in the middle,
and now you would see a regression on the diagonal.
So that's not happening either.
What is actually happening is that the people's estimation of the position of the coin is
somewhere in between the prior and the likelihood.
And as you can see, if you look at these two are the most interesting conditions to highlight
how people are waiting the likelihood and the prior relatively.
So if you look at this one, when the likelihood is wide, so likelihood is not very reliable,
people actually rely more on the prior, and so you see the slope going closer to the flat
line.
On the other hand, when the likelihood is narrow, more precise, people rely more on
the likelihood information than the prior, naturally.
So people rely more on the most reliable source of information.
So that's how it should be.
So again, this is just reiterating that prior sensory reliance depends on the relative reliability.
Now I'm just plotting this again here on the left, and I will just go very quickly through
the measures that this paper offered, which is where we saw an opportunity to test our
ideas.
So first of all is the slope of these plots that indicate the relative reliance of narrow
and likelihood.
And so we thought, well, we could use this sort of measure to test the hypothesis that
autistic individuals rely more on sensory than prior information, so we could quantify
it experimentally.
The second measure that this paper used was the prior variance.
So if you do the maths, you can get into the equation that estimates a subjective prior
variance.
So the prior variance represented in each individual participant, and that has a relationship
with the slope itself, and also the variance of the likelihood, that sigma l.
So that would be very useful to test the idea of a hyperpriorism model whereby Pelican and
Borges say that the prior is flatter, or the variance is bigger.
Then the third measure, which actually this paper didn't have, but that was something that
Roshini and I came up with, which was a way of estimating people's likelihood variance.
So we can assume that people's likelihood variance is the same as by design, so driven
by the dots that they see in the skull.
But of course, we know that, or it's pretty reasonable to assume that our senses are noisy,
and so we don't represent the likelihood exactly as we see it.
And so this is what we postulated as a measure of the variance, which has to do with how
variable people are throughout the experiment in terms of where they put the middle of the
target in a no prior task.
So we ran the same task, but now removing the prior and just having likelihood only,
and that's how we came up with this measure.
So this measure has two purposes.
One purpose is to, rather than assume that people represent the likelihood as it is,
it allows for people to be noisy.
So rather than having an objective likelihood, we can have a subjective likelihood.
And then the second purpose is to test the more precise likelihood model proposed by
Brock, so that then we could have really a measure to test that idea.
Okay, going a bit slower than I had expected, but there's a lot of theory to go through.
So finally, what have we found?
So the first findings were actually quite surprising in a way.
So remember how we, both models, said that autistic individuals would rely more on sensory
information, so we would expect the slopes for autistic individuals to be closer to one
than to zero, okay?
So closer to one again is relying more on likelihood than prior.
What you see here are the slopes for the neurotypical in orange autistic spectrum in
green, and we see absolutely no difference, okay?
So we're like, okay, so actually we managed to reject both models at this stage.
But we carry on, and looking for the other measurements that you saw in the previous
slide, so the prior variance and likelihood variance.
So yeah, this is just to point out that we rejected both models.
So when we look at the different sensory weights by condition, sorry, I'm just getting
a bit ahead of myself there, but even though, so I'll just go back to this slide.
So even though when we put together all the sensory weights of the different conditions,
we see no difference, we thought, okay, let's just have a look at what's happening by condition,
and that's what I'm showing you here in this plot.
So PN, LN, that means prior likelihood narrow-narrow, prior likelihood narrow-wide, so narrow-prior
wide likelihood and so forth.
And again, the same labels, neurotypically in orange and autistic spectrum in green.
So when we put together the different conditions, even though we don't see a main effective group
we do see a group by prior interaction, whereby we show that the neurotypical individuals
have a larger difference in the sensory weights for wide-prior versus narrow compared to the
autistic spectrum group.
So it is a little bit difficult to see here, but what we're saying is that the neurotypical
individuals sort of vary more than the autistic individuals.
And so the fact that they vary more seems to suggest that, the fact that the autistic
individuals vary less relatively to the neurotypical individuals seems to suggest that there is
a poorer context adjustment, right?
Because if autistic individuals were taking into account context, they would adjust to
that context in how they weigh the relative differences in precision of prior and likelihood.
So we rejected those two models, but I think we learned something new.
The other thing that we wanted to test, our second hypothesis, was around priors.
So if you remember the hyper-prior account of Pelikan and Burr said priors are less precise,
expect greater variance.
In fact, we don't see that at all.
What we see is absolutely no difference, and which we carefully reject the hyper-prior's
account, or at least we show no evidence for that account at all.
So it seems to be that they are intact, that priors, prior variance is intact in autism.
Now as I said, we had a no-prior task, and it's a question mark, and I'll tell you in
a minute why, but here we expected to test the more precise likelihood model, but when
looking at the sensory weights, we actually saw something quite surprising.
Remember how both accounts expected the sensory weight to be greater in autism spectrum individuals?
And in the first task where we had the prior and the likelihood, we actually found no difference.
Well in this task, we actually did find a difference, but it was the wrong way around.
So we actually found lower sensory weights for autism than neurotypical individuals.
So that kind of is against both accounts.
And thinking about this, it didn't really make a lot of sense because, well, this was
supposed to have no priors.
However, when we run this task, we're removing the prime, we did that at the end of our task.
We had the main task first with priors and likelihoods, and then we did this one at the
end.
So what we think it's happening here is that actually people managed to carry over some
priors from the first task into the second task, even though they weren't supposed to.
And that was more obvious for the autistic individuals.
So again, this result is against both hyper priors and precisely likelihood models in
the sense that it doesn't predict that sensory weights are closer to the likelihood.
In fact, it's actually quite the opposite.
And we interpret this as a carryover effect from the previous to the second experiment.
And again, we don't see that this prior is less precise, we actually see that it's more
precise.
So this is the final result slide that I want to show you.
When looking at the subjective likelihood variance, so this is the measure that we postulated
for the subjective likelihood, we didn't find a difference when we contrasted the two groups.
And when we put people on the continuum, so whereby we align all the individuals, neurotypical
and autistic, and we also had another group in blue, which was high on the spectrum, but
when we did a diagnostic test with the adults, they really didn't fall onto the autistic,
onto the diagnosis.
They kind of in the middle, but because here we were aligning people on the continuum,
it didn't really matter their diagnosis.
So we put everyone together.
So when we do that, we actually see a significant relationship between the subjective likelihood
variance and the IQ, which is driven by the subscale of attention to detail.
So this is quite interesting because the likelihood variance is decreasing as autistic traits
increase, which is in a sense quite closer to the Brock's model of more precise likelihood.
So as the variance is increasing, so it's more precise for autistic traits, as the autistic
traits increase.
So we sort of tentatively confirm one of the predictions of the precise likelihood model,
although as I said, when we put people in different groups, we don't, that difference
doesn't emerge.
So we carefully confirm with some question mark that hypothesis or that prediction.
So how are we doing with the conundrum?
Can we reject, accept, or perhaps revise the models?
So here is again the Bayesian account for typical learning and the two models, hyper
prize and precise likelihood.
And if you remember, we had three different predictions, one around the sensory weights.
Both of these models, hyper prize and precise likelihood model predicted that people would
rely more on sensory information than priors, that did not happen.
So that hypothesis was kind of rejected for both models, in fact.
So we actually, the first experiment we see that it's pretty much the same.
If anything, the autistic individuals actually rely more on the priors, and that's what we
saw in the second experiment, then what happened to the priors?
So we don't really see any difference in the priors, in the prior variants, so we don't
really find any support for the hyper prize model.
In terms of the likelihood model, again, we don't see a greater sensory weight.
So that prediction isn't correct.
In terms of the prior, we see intact priors, so that seems to be a confirmed prediction.
However, as I said, in the second experiment, we actually see that there is a shift towards
the prior, which could indicate that actually the priors are not less precise but more precise.
And then finally, in terms of the prediction around the likelihood being more precise, we
tentatively say, yes, it is more precise, but only when we align people on the continuum,
we don't see that when we group them according to diagnosis.
So two things that we learned over this study was that perhaps the priors are not less precise
but more precise, and we conclude that through the second experiment where perhaps we see
carryover effects, and we also saw that there is a poorer context adjustment which might
explain rigidity behavior in autistic individuals.
So we sort of confirmed a couple of predictions.
I guess our data is closer to the precise likelihood model of Brock, even if not exactly
the same.
So we propose a revision of the model, but we also have more questions than answers in
a way.
And one of the questions is, are people really Bayesian?
And we kind of assume in this framework, because it's quite useful, but we don't really know
for sure, and we have some follow-up studies in neurotypical individuals at this stage,
actually testing some key principles around being Bayesian.
And also the other question is, are people optimal, actually they're not optimal at all.
They always suboptimal in the studies that we've run, and the question is why are people
suboptimal, and we're currently writing a review paper around trying to explain why
is it that people are suboptimal, and perhaps has to do with the biological constraints that
