So I want to emphasize that the requirement of stationarity in the probability distribution over
a most likely state does not preclude the system changing.
There can be various alterations and changes in the development towards a steady
state. There can be temporary fluctuations away from the most likely state as long as
they're counteracted by a surprise or minimizing flow back to more likely states
to preserve probability distribution.
So you can occasionally visit states you haven't visited before, you just can't stay there too long
because then it becomes so long that I can describe them as surprising and a probability distribution changes.
There can also be cycles and periodic changes around a set of equivalently likely states
which gets described by this sort of optional solenoidal component, the system's flow, which is that curved
arrow around that landscape.
And it's been suggested that it can be used to formalize a system that's at
non-equilibrium and might be what differentiates living from non-living systems.
So we can have all sorts of wandering around and temporary excursions
from that peak of most likely state. But as Friston, Hobson and Moisey describe it,
a personal particle is never off this manifold. The kind of novelty that would correspond
to a permanent phase transition from one stable track from landscape to another amounts
on this formulation of a system as that system ceases to exist.
The dissolution of the attractor and the potential emergence of a new regime corresponds to the depth of the system
as it's failure to adequately deal with environmental perturbations.
Okay, so to get Friston's reasonable table
it's not enough just to have a stable probability distribution. You also need to split a system
into parts so we can talk of internal states as minimizing Friston with respect to
the sensory ones to control external ones. In a case of brain bound
for humanization, we can just take the sensory mode to interface
but to generalize this to all systems involves formalizing the idea of a boundary
for perception and action. This is done by the Markov-Blinder
which decomposes the system into internal, external and blanket variables
based on the requirement that the probability of internal variables being in particular state is independent
of the safe external variables conditional on knowing the blanket states
and vice versa. So the second presumption of the Frenzy framework
is that any system can be factorized in terms of these kind of conditional statistical
dependencies between internal and external states.
And while Markov-Blinder gets some directive graphs like this are typically constructed based on statistical information
not causal information directly, these graphs can be and then the Frenzy framework
typically are presented as certain patterns of causal influence and examples of things that could be
Markov-Blinder gets a physical boundary such as the membrane of a cell or the states and center of the area.
There are some issues with that but I don't want to get into the sort of
the weeds of the links between statistical and causal influence here.
What is important to me is this claim which is that as a consequence
of requiring a fixed Markov-Blanket is the requirement of stable
patterns of interaction between the parts of the overall system and its environment.
So as Tristan puts it, it does not easily accommodate the fact that the particles that constitute a
Markov-Blanket can over time wander away or be exchanged or we need.
I can only call an example here being a blanket state of a counterplane whose constituent particles
molecules of gas are in constant flux. Because of this flux,
Tristan says, a counterplane cannot be a modelist possessing a Markov-Blanket.
So to kind of summarize
I think the two core moves of the Frenzy principle
that get you this requirement of surprise minimization is to describe the system
in form of two sorts of stability. Is there a requirement of stationarity
that the probability density of the states of the system is invariant every time?
Whatever state the system is most likely to be in today is the state it is most likely to be in
as long as it exists. And the requirement of a Markov-Blanket. So the patterns
of interaction between parts of the system are stable enough. We can identify some fixed
subset separating the system into fixed internal and external parts
from this little on that blanket. And there are some
different ways of formulating this but I take the most of them amount to different ways of
surprising these key stability requirements. So what we have is not an
excuse of how a system biological or otherwise avoids death or ceasing to exist
but as I have described it a formal analysis, a potential formal analysis
of what avoiding extinction is so as to how this is achieved can be described by
specific crisis theories. If we define a system in these terms then the minimization
of surprise will indeed be a necessary principle that they continue to exist
every time. Which are some extra requirements that allow you to model
that system as an active influence agent. But what I want to argue is that
while these requirements may characterize stable physical systems relatively well
they're at odds with the very characteristics that distinguish living ones.
So the first issue of this
formulation is that as it applies to living systems is that not all phase transitions
in an organism correspond to that system dying or ceasing to exist. Organisms
typically undergo many transitions from one steady state regime to another ever before so the lifespan.
Examples like embryogenesis and development can be interpreted as stages on the
path towards a steady state that characterizes the adult organism. But even
once adult form has been achieved organisms are liable to argue further phase transitions that don't
on an ordinary understanding amount to their death. And these midlife crises are not
unique to complex highly cognitive approaches like ourselves and nor do they only occur
at the population level of natural selection. Sometimes reference gets made
to a caterpillar turning into a butterfly is an interesting exception to our surprise
and encouraging. But these phase transitions are ubiquitous. There's the cases of short horned
grasshoppers that went over crowded turns locusts or they apparently
have 500 different species of fish that change sex under a variety of different circumstances.
And we might break these down as parts and treat them as the result of competition between different
sub-organisms each with their own steady state behavior. But even the simplest single cell
organism like an E.coli bacterium can deliberately engage in what can
be observed to survive behavior that
causes a transition from one steady state regime to another. Typically it's flailing
around between glucose molecules to keep its intake stable
could be characterized by the frame principle of steady state formants. When glucose levels drop
and lactose levels rise it can switch its behavior to begin metabolizing lactose instead.
That means a change in the probability distribution characterizing the E.coli's behavior
from a low probability of lactose metabolism to a higher one. And now
the E.coli bacterium looks like it's trying to do is minimize surprise and loss of the lactose intake levels instead.
And so long as lactose remains available, an E.coli bacterium can do very well in its
new regime. So it doesn't seem well characterized as a temporary deviation away from steady state
that needs to be counted. It's this sort of adaptability and phenotypic
plasticity that is not well described by the idea that a system
wanders around if it's attracted. And the analysis of the system's characteristic
states in terms of the stationary probability distribution fails to characterize the continuity
of the organism throughout this transition from one steady state regime to another.
So
that can be made less of a problem if we drop the idea that a stationary
distribution has to characterize the entire existence of the system. And instead
take it to characterize the stability of a temporary phase of the system. An able
process of life is a process of transitioning between steady states.
And we could put that in CUNY in terms to say that the phrase principle might be a good description of how the organism maintains
itself during the normal science phase but not of the paradigm system of that patient.
Still, this leaves perhaps the most interesting properties of organisms unexplained.
As a number of authors have argued, both as criticisms of and independently of the
phrase principle, it's precisely the preservation of a system's identity
who changes in its phase space on the capacity for permanent cumulative change that this
unlocks. It distinguishes the biological from the nearly physical.
An emphasis on this kind of historical change is, as De Palo and Thompson and Bayer recently noted,
the hallmark of the inactive approach to the system. And some of the potential limits of
inequality between these and the phrase principle. Moreover, just as not all phase transitions
are equal-depth, neither are all steady states equal. And the fact that a state
can be stably maintained does not make it optimal that we even buy it.
When a bacterium like E. coli transitions to lactose metabolism in a lactose-raised environment,
it seems like a pretty optimal new steady state. But an alternative response
to new cheap deficiency in other species of bacteria is to enter a dormant
endosporesate. And that dormant state can be maintained for millions of years. While we might
have discovered that E. coli, Charon, Garm's, lactose is thriving in its knees, that doesn't seem
apt for the endospore state. And similarly, the transition from life to
being frozen in psorogenesis is a transition between steady states. But the likely
coming of vegetarianism in this new steady state isn't a viable one for organisms like you and me.
So what we want, and what is not there in the phrase principle, is an explanation of which
steady state is conducive to organisms' survival and which others are not, and why.
So the second stability requirement
is that of a stable boundary. And if we approach that as an idealization,
and I apologize for the A-level biology diagrams here, I just thought they were quite nice and simple.
If we approach that as an idealization, like the requirement of stationarity,
it wouldn't require that the particles constituting the marker blanket never change.
But they are at least stable on long enough time scales to be treated as invariant.
And that their turnover isn't of significance in understanding the features of the system that we're interested in.
The problem for living systems is that this means ignoring the distinctive
side in which they're not only a continuous material turnover on time scales shorter than
the life span, but the ways in which that kind of material turnover is actually
constitutive of the kind of behavior that we see to explain.
For specific examples, we can take the cell membrane, which is often presented as the archetypal example
of a stable marker blanket between the interior of the system
and its exterior. This may be more stable than the candle flame,
but in all cells it will still be in a kind of molecular flux throughout the cell's life cycle.
There's the continual endosatases and exotases of this membrane
for regeneration, for growth and for particle transport in and out of the cell.
And this destructs in a regeneration of the band, which is not an accidental quirk,
but a constitutive part of how the cell imposes itself. In an example, particularly like
of the solenoid slime mold, the regeneration of this membrane could be key to locomotion
as opposed to taking in the membrane from the trailing edge and then regenerating it back out at the forward edge,
which would result in complete turnover of the entire membrane in the space of just a few minutes.
And that turnover of the membrane actually enables the slime mold to move
that material turnover is part of the behavior.
So as in the case of the candle flame, this flux of molecular parts can't easily be
accommodated, and a model that requires fixed relations between stable parts.
But the point isn't just that the Fray and New Principles definition of a system abstracts away
from some specific behaviors of living systems, but that these behaviors
are the way in which biological systems somehow preserved through this material turnover
that are, I'd argue, exactly the properties that are key to understanding the unique
sub-organism behavior of life.
So material turnover is not just a coincidental
quirk of some organismic operations and parts like the membrane, but
constitutive of living systems as metabolic systems that need to continuously regenerate themselves.
Living systems aren't only open and out of equilibrium with the
environment, not just amenable to the possibility of incorporating flows
of matter and energy. They are systems that depend on such a way for their ongoing existence.
At this point about the priority of metabolic turnover in characterizing living systems,
I think that's made by the philosopher Hans Jonas around 70 years ago,
and this could mean he could have asked me cybernetic formulations to be able to just frame, as I said,
in very similar terms with Fray and New Principles. And as Hans Jonas argues, organisms are
distinguished by standing in a kind of needful freedom to matter, both liberated from
any specific physical base, but in need of continual flows to reconstitute themselves.
The Fray and New Principles description of a system describes a stable
coupling between feedback mechanisms very nicely, but as Vanishing Kirschhoff,
who, I don't know if that's the name, but Vanishing Kirschhoff, Michael Gerger, Thomas Van Essen,
and Michael Kirschhoff, there we go, have recently noted, it's a modelling structure
that's not well suited to capturing this precariousness. And this is not due to
the requirement of a stable marker blanket, but a more basic consequence of a general modelling framework
that describes systems in terms of variables and influences of quantity to them to maintain a stable set of states.
And this is, all of this isn't to say that there's no
way to characterize some sort of biological identity that remains invariant
to the chains of both typical states of material substrate.
Pre-theoretically, we do it from the time. It's just that relations of influence between
atemporal fixed networks and variables are not able to capture it.
It's a model of macabolic turnover, as the theorem in biology is Matteo Massio,
Harvard and Reno, and Mayo Montevil describe, and they're building the work of strict government.
What is needed is not just relations of statistical or causal influence between variables,
but relationships of existential dependence between precarious constraints
and catalysts, that both depend on and enable the processes of production that regenerate them.
In altruistic and activist terms, an organism is not just an operationally
closed system, defined by a set of cycle of operations to a fixed set of characteristic states,
but an organizationally closed one. Here, its component
is not constrained by a characteristic state or physical instantiation, but only the role
it plays in the year of all network. And as long as that role of constraint or regeneration is maintained,
as long as its closure is preserved, the parts of the network may exchange and adapt
and evolve into whatever variety, new forms, states, and characteristic behaviors
are compatible with that closure.
So, completely. For energy minimization,
it's a necessary condition only for systems defined by the stability of the probability
distribution over the states and the stability of interactions between the parts.
Organisms may continually meet these requirements at points, but
neither is necessary. The very thing that distinguishes them
