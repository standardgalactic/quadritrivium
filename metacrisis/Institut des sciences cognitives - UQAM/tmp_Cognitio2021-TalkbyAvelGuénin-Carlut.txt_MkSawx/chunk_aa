And for our very first talk, you're going to have Aval getting Karloot, is affiliated
research at Cairo's research in the Active Inference Lab, and will be presenting to
us today, intelligence without creativity, can Active Inference ground our understanding
of life, cognition, and society. The floor is yours.
So the main criticism that is addressed toward the FEP and Active Inference is that it explains
grounds intelligence without creativity, which is it explains a kind of epistemic inference,
kind of information integration from the external world to the agent, but it does not allow any
kind of historical or creative data mix within the agent, which are characteristic of living
and cognitive systems. This criticism comes mainly from an activist, and it has drawn people to
accept that active inference is not a real thing. It's only an instrumental principle that can help
us understand the world, but has no truth or per se explanatory value. What I'm going to
define here is first that this kind of status is, in fact, pretty good. It's pretty useful to have
this principle that helps some things without being true, but the FEP actually grounds the
evolution of cognitive systems and civilization. And however, it can only do so if we revise
basically our interpretation of it and build math that withstand the shock of cognitive evolution.
So what is active inference? Active inference derives from a result known as the Panjik principle
of states. It has been stated a lot of time in the conference that chemical systems that
perhaps sufficiently recover boundaries will self-cognize, so as to minimize informational
value, that's called the VFE version of the FEP. And that implies either both that
the maximize evidence for the model, the world model they embody, or that they constrain the
expected volatility of what they do and perceive. It is expressed in the following math. What is
important to see here is that two values that are actually perceptible by the agent, which is the
complexity of their world model and the density of mistakes, basically, they make. They provide
natural bounds and upper bounds on log evidence, which means that it physically constrains the
amount of surprise they will get. And if they are surprised by bad evidence, they will persist
into existence in virtue of minimizing it. So active inference is basically the idea that
actual cognitive systems do that. They minimize VFE. What it means to minimize VFE is that across
Markov blockets, which is basically a screen, mediating states through which I understand my
world, there is a synchronization. There is the synchronization of a manifold of a structure
in which I self-quinize. And what active inference says basically is that this is equivalent to
saying that there is some kind of commutative agent, which makes implicit inference over
the instrument of flow. So that's what we are talking about. So the presentation, we'll go in
three parts. First, present the integrating instrument of view. Second, present the grounding
how-actually view. And third, present and rest the problem of self-creation in the systems.
So you have basically three kinds of scientific explanation. You have explaining with laws,
explaining with mechanisms, and explaining with functions, which transfer basically to
what a phenomenon is, how does it work, why is it this way? So the etymological is kind of
aside in the sense that there are universal laws that must not ever be falsified, while
mechanical and functional explanations are basically two properties of context-specific
mechanical model. So what you will do with mechanical and functional explanations is basically
check whether they are consistent with the system structure and history. And for mechanical
explanation, see if they predict what the system does, and for functional explanations try to
deduce constraints on the mechanism. While the logical laws explanation, they are basically
related by inductions, and they are relevant if you can deduce from them some phenomenologically
important part of the system. Basically, you do another coordination by setting the system
behave as if some law was respected, was causally efficient. You make an explanation
by saying how actually a system is structured and works for transformation by saying why it
must be this way. The furniture principle does all of these things. It's mainly invoked as a
Nazif explanation for influence-like behavior. It also provides a functional directive on how
committee system must have worked, and it is even related to the theoretical process,
which is specific to mechanical theory of the mission. So what is it? What is important to
understand is that the FEP, unlike what is proposed by some, is not a universal explanation.
What is accepted to pay the intuitive view is that so far Andrews, it is a question that
might go unasked for Friston. It is to provide a guideline to discover and motivate actual
mechanical explanations. Sorry, I have to cut something. What it means is that the account
framework reduced to an ontology, which means a formal language and a set of concepts,
of generative concepts, that allow us to study the equation across scales.
So what it does is that it provides us with a unified theoretical approach of nature
that allows us to integrate different fields at the conceptual level. But it does not
prevent the development of domain-specific mechanical explanation. It does not prevent
integration. So it's a pretty ideal tool for what is considered as the naturalistic approach to
science. Let us see how this works. I can look at a woodlice, I can look at a city which
Blue presented yesterday, and I can look at them as committee agents that enact models of
a niche. I can look at how they minimize pre-energy on various scales, these of behavior, these of
development, these of phylogeny, et cetera, et cetera, et cetera. And I can basically use
this set of language to integrate the mechanism processes ID across scales in a single integrated
understanding of the organism, which is pretty nice. What I say is that, acting in France,
in addition to this, also allows us to ground the study of my intelligence, which is
provide a basic physical explanation for how we get intelligence in the first place.
So first, let us see what is a complete failure at grounding the study of intelligence systems,
which is self-awareness, criticality. There is a widespread agreement in neuroscientists and
systems biologists, including activists, that intelligence systems must be near a critical
phase transition to process information. So what a critical phase transition is, is a transition
between an order and disorder phase, where you have not order, not disorder, multi-scale behavior.
So in the brain, you do have multi-scale behavior. So that's a win for the critical theorist, I guess.
Well, no. Because what they do is basically to provide a law that says primitive systems
must be scale invariance. It is a nomological explanation of pretty shallow magical aspects
of intelligence. It does not say the virtue of what the instructor is predictive. It does not say
how we get intelligence. It does not say why this specific organization matches this specific niche
or provide this specific terminology. It says nothing of this. Active inference precisely
addresses that. Active inference framework proposes basic synchronization across mark of
planets as a process that grounds the emergence of semantic or combative properties, the emergence of
particularly matches between the world, an agent perspective, and what it does in this world.
Let us zoom back to see how it matches with physics. When you have a system that is
at equilibrium, which is that does not exchange information, matter, or energy, it minimizes
something, a value that is called free energy that integrates basically the amount of energy
that is the system and the amount of information it takes to define it. When you expose a system to
a dissipative flow, for example, energy flow that is entailed by hitting the bottom of a pot of a
water pot, then you get exchange of energy and information at the periphery of a system. And
then the landscape of the minimized functional changes and the system integrates in addition to
an intrinsic information geometry that reduces its basically equilibrium state. It integrates an
intrinsic information geometry that translates how the extrinsic flow that is imposed upon it
takes shape physically in its structure. And this extrinsic information geometry drives
meaning from deviation from equilibrium. It drives a change into the actual physical structure of
the system and the extrinsic reference work says basically this. So what is the relation of that
to intelligent opening systems that are much more complicated than pots on a fire?
Basically, it says that this synchronization driven
functional integration happens at all scale at all moments. At any scale, you can look and describe
a system. If you describe it as a set of chemical equations, there is a process of self-organization
that entails the reduction of its dimensionality that entails symmetry breaking and the emergence
of structural constraints that will work outside the scope at which the system is defined, that will
work for example as structural constraints in a disumed in a scale of view of the system.
So this in and of itself does not come pretty far from solving the problem of cognitive
optimization. Because there is in fact a pretty strong disagreement about the hierarchy, the
architecture of living and cognitive systems between FPP theorists and systems biologists.
FPP theorists are interested with control, are interested with statistical inference. So they
talk of hierarchical modularity, fractal hierarchy, of blockets within blockets within blockets
while system biologists are interested in how systems self-produce. So they're interested in how
a set of constraints that is embodied within a physical system manages to produce and create itself.
So the topology is just under silence, fractal versus meshes, but it's not a property of the
basic Markov-Blanket formalism. So it's nothing critical, it's something that can be fixed within
the formalism. Something that is not however is the way commutative systems, living systems,
as inactivists and phasors a lot self-create. So let us demystify this and explain what means
to self-create. In physics we have a basic epistemological construct that is a state space,
that is a mathematical space that we declare has all of the relevant information to explain
the behavior of a system. Often it will be macroscopic thermodynamic variables that are
the only one that matter in virtue of the very strong symmetry of classical physical system
and the basically averaging out of all micro projections. In biological system however you
have much more complicated kind of symmetry breakings. You have multi-scale kind of symmetry
breakings that organize the very specific way without which the system does not keep working,
it dies. And most importantly these symmetries are built through the system history at both
developmental and evolutionary scales and it is built by multi-scale fluctuations that work
basically from quantum and thermal noise so they are not predictable, there is no way to predict them.
And so you have a pretty strong sense of historicity, you have specific events that make
the system break out of a deterministic landscape and do new things, basically be creative.
This is what a creative evolution is and the FEP framework just does not address it because
the way it demonstrates the FEP is to define a specific micro landscape, a specific structural
architecture and then to look at what is attracting dispersion within this space. So
they construct the object that does deflation and the object from which deflation derives
are both historians, they're entailed by how you put the problem. And historical systems
which is formally mixing systems, which is stronger than echo DCT by the way, there are systems that
basically, they dissolve, they get into a specific shape and they stop moving.
So you can have kind of hysteresis or cyclical, interesting behavior but what you cannot have
is a change in the structural condition of the system itself, what you cannot have is death,
what you cannot have is creation, what you cannot have is life. So the FEP is as is formulated
incompatible with the representation of living systems, so it cannot explain them.
What I say is that there is a pretty basic shift, you know, we understand it, that could address
this problem and make the FEP principal, grounding the physics of biological creation.
This derives from the functional interpretation of the FEP. Basically the FEP, the active space
is very considered to represent the cognitive landscape that is subjectively enacted by
cognitive agents. So cognitive agents, they have a straight view, they can change how they relate
to bikes. Most importantly, they cannot know possibly everything that's out here. So their
intrinsic space, that is described within the FEP framework, it cannot be because I closed,
it cannot be a sufficient presentation, it cannot be in set space. And it can actually
write in the exchange information with its extrinsic dynamics. You can have ways that the
intrinsic dynamics feedback into the extrinsic world. This construction, when an agent basically
builds its need into a world, like when a beaver makes a bomb, or by using books to change the
way I think. Or you can have elements of the world outside my cognitive landscape that work back
into my intrinsic landscape. Which is learning, for example, learning how to bike, which changes
basically how I sit bike, or taking psychedelics that will change my neurodynamics to a very
base metal, or ageing, or death, or being hurt. So we can say that synchronization across my
crossblock cats does not speak to self-coinization within a specific set space, but it speaks to how
set space are created by the activity of proto-minds, basically, basic constructs that enact
properties that we associate generally to cognitive systems. And how these proto-minds,
in virtue of their functional organization, and the symmetry breaking that is entailed by it,
build set spaces, unfold measurable symmetries and asymmetries in a specific system,
and create, strictly speaking, biological set spaces. So a question that needs to be asked
is if set spaces are basic to physics, and FEP explains how we get set spaces, is FEP basic
to physics? My answer is that it affords this. I don't know if it's true, but it's a possibility
that acting in France basically gave us a very basic construct, that is, the grounding of all
our physics. The FEP can be understood as grounding the view that, the view that Friston called
Markovian monism, that's called informational monism, and that is the idea that what there is
in the world, what is the antique basis of physical existence, is basically information
fields that do active inference. And if those information fields are prior ontologically
than what we observe as inverting the agents, our life, the existence of specific trajectories
that are survival, will be entailed by synchronization across a Markov blanket, basically synchronization.
This pretty much directly speaks to quantum phenomenology, because the way the coherence,
which is basically when quantum objects lose their quantum properties, it works back in time,
which means that if I observe now a particle that has been
individuated as something in the past, my observation now becomes entangled with the way
events folded out back then, back when the particle collapsed. So what this means is not that you
have backward causation, this is not a consistent notion. What it means is that
the universe keeps evolving as quantum fields until it is forced to stop evolving as quantum fields
through observation, through in the active framework, it's causation across Markov blankets.
And this is even more fundamental than quantum physics, because the very basis of the universe,
cosmological laws, they evolve, they change. And because of Noether's theorem, the cosmological law
reduces the physical symmetries. And those physical symmetries can be demonstrated through God's theory
to be firmly equivalent to the self-organization of specific graphs, which is, by definition,
active inference. So let us disentangle the claim I made here. First, I say that active inference
is pretty close to be a divisional acid solution or a basic set of tools that address all problems,
because it provides an innovative framework, which is a formal and cognitive ontology for study of
cognition and optimization of the states. Define a principle, it provides basically a
grounding principle. So a basic physical explanation for how we get embodied intelligence,
how we get cognitive systems in the world. And if we want a principle to actually do that
efficiently, truly, I don't know, we need to develop a mathematical theory not only of
self-organization within state spaces, but of self-organization of unfolding spaces
on the grounding of active inference. If we do that, we can address the criticism from creativity.
We need to do that to address the criticism from creativity, but it will also make basically
a basic grounding explanation for all of physical reality.
So there is one concern that could be raised about this, which is that the view that the
universe is unfolding, that there are proto-minds that make up the things that we see, it's somehow
opposed to the realistic worldview. And it is indeed opposed to the classical view of realism
of the idea that you can have objective properties in the world that are
uncoupled from interaction, from observation. This is the formulation of Einstein that is
displayed here. And the first principle understood as a grounding principle for the physics of
creation are basically admitting that the physics of creation is a problem. It grounds what is
called anata, which is the Pali word for basically there is nothing in itself. It grounds the view
that there are no individuated things and no individual properties outside interaction,
well, in the French principle formalism, across a map of planets. And the view that
the objects that we talk about are true, not withstanding our subjective way of describing it,
