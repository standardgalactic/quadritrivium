And for our very first talk, you're going to have Aval getting Karloot, is affiliated
research at Cairo's research in the Active Inference Lab, and will be presenting to
us today, intelligence without creativity, can Active Inference ground our understanding
of life, cognition, and society. The floor is yours.
So the main criticism that is addressed toward the FEP and Active Inference is that it explains
grounds intelligence without creativity, which is it explains a kind of epistemic inference,
kind of information integration from the external world to the agent, but it does not allow any
kind of historical or creative data mix within the agent, which are characteristic of living
and cognitive systems. This criticism comes mainly from an activist, and it has drawn people to
accept that active inference is not a real thing. It's only an instrumental principle that can help
us understand the world, but has no truth or per se explanatory value. What I'm going to
define here is first that this kind of status is, in fact, pretty good. It's pretty useful to have
this principle that helps some things without being true, but the FEP actually grounds the
evolution of cognitive systems and civilization. And however, it can only do so if we revise
basically our interpretation of it and build math that withstand the shock of cognitive evolution.
So what is active inference? Active inference derives from a result known as the Panjik principle
of states. It has been stated a lot of time in the conference that chemical systems that
perhaps sufficiently recover boundaries will self-cognize, so as to minimize informational
value, that's called the VFE version of the FEP. And that implies either both that
the maximize evidence for the model, the world model they embody, or that they constrain the
expected volatility of what they do and perceive. It is expressed in the following math. What is
important to see here is that two values that are actually perceptible by the agent, which is the
complexity of their world model and the density of mistakes, basically, they make. They provide
natural bounds and upper bounds on log evidence, which means that it physically constrains the
amount of surprise they will get. And if they are surprised by bad evidence, they will persist
into existence in virtue of minimizing it. So active inference is basically the idea that
actual cognitive systems do that. They minimize VFE. What it means to minimize VFE is that across
Markov blockets, which is basically a screen, mediating states through which I understand my
world, there is a synchronization. There is the synchronization of a manifold of a structure
in which I self-quinize. And what active inference says basically is that this is equivalent to
saying that there is some kind of commutative agent, which makes implicit inference over
the instrument of flow. So that's what we are talking about. So the presentation, we'll go in
three parts. First, present the integrating instrument of view. Second, present the grounding
how-actually view. And third, present and rest the problem of self-creation in the systems.
So you have basically three kinds of scientific explanation. You have explaining with laws,
explaining with mechanisms, and explaining with functions, which transfer basically to
what a phenomenon is, how does it work, why is it this way? So the etymological is kind of
aside in the sense that there are universal laws that must not ever be falsified, while
mechanical and functional explanations are basically two properties of context-specific
mechanical model. So what you will do with mechanical and functional explanations is basically
check whether they are consistent with the system structure and history. And for mechanical
explanation, see if they predict what the system does, and for functional explanations try to
deduce constraints on the mechanism. While the logical laws explanation, they are basically
related by inductions, and they are relevant if you can deduce from them some phenomenologically
important part of the system. Basically, you do another coordination by setting the system
behave as if some law was respected, was causally efficient. You make an explanation
by saying how actually a system is structured and works for transformation by saying why it
must be this way. The furniture principle does all of these things. It's mainly invoked as a
Nazif explanation for influence-like behavior. It also provides a functional directive on how
committee system must have worked, and it is even related to the theoretical process,
which is specific to mechanical theory of the mission. So what is it? What is important to
understand is that the FEP, unlike what is proposed by some, is not a universal explanation.
What is accepted to pay the intuitive view is that so far Andrews, it is a question that
might go unasked for Friston. It is to provide a guideline to discover and motivate actual
mechanical explanations. Sorry, I have to cut something. What it means is that the account
framework reduced to an ontology, which means a formal language and a set of concepts,
of generative concepts, that allow us to study the equation across scales.
So what it does is that it provides us with a unified theoretical approach of nature
that allows us to integrate different fields at the conceptual level. But it does not
prevent the development of domain-specific mechanical explanation. It does not prevent
integration. So it's a pretty ideal tool for what is considered as the naturalistic approach to
science. Let us see how this works. I can look at a woodlice, I can look at a city which
Blue presented yesterday, and I can look at them as committee agents that enact models of
a niche. I can look at how they minimize pre-energy on various scales, these of behavior, these of
development, these of phylogeny, et cetera, et cetera, et cetera. And I can basically use
this set of language to integrate the mechanism processes ID across scales in a single integrated
understanding of the organism, which is pretty nice. What I say is that, acting in France,
in addition to this, also allows us to ground the study of my intelligence, which is
provide a basic physical explanation for how we get intelligence in the first place.
So first, let us see what is a complete failure at grounding the study of intelligence systems,
which is self-awareness, criticality. There is a widespread agreement in neuroscientists and
systems biologists, including activists, that intelligence systems must be near a critical
phase transition to process information. So what a critical phase transition is, is a transition
between an order and disorder phase, where you have not order, not disorder, multi-scale behavior.
So in the brain, you do have multi-scale behavior. So that's a win for the critical theorist, I guess.
Well, no. Because what they do is basically to provide a law that says primitive systems
must be scale invariance. It is a nomological explanation of pretty shallow magical aspects
of intelligence. It does not say the virtue of what the instructor is predictive. It does not say
how we get intelligence. It does not say why this specific organization matches this specific niche
or provide this specific terminology. It says nothing of this. Active inference precisely
addresses that. Active inference framework proposes basic synchronization across mark of
planets as a process that grounds the emergence of semantic or combative properties, the emergence of
particularly matches between the world, an agent perspective, and what it does in this world.
Let us zoom back to see how it matches with physics. When you have a system that is
at equilibrium, which is that does not exchange information, matter, or energy, it minimizes
something, a value that is called free energy that integrates basically the amount of energy
that is the system and the amount of information it takes to define it. When you expose a system to
a dissipative flow, for example, energy flow that is entailed by hitting the bottom of a pot of a
water pot, then you get exchange of energy and information at the periphery of a system. And
then the landscape of the minimized functional changes and the system integrates in addition to
an intrinsic information geometry that reduces its basically equilibrium state. It integrates an
intrinsic information geometry that translates how the extrinsic flow that is imposed upon it
takes shape physically in its structure. And this extrinsic information geometry drives
meaning from deviation from equilibrium. It drives a change into the actual physical structure of
the system and the extrinsic reference work says basically this. So what is the relation of that
to intelligent opening systems that are much more complicated than pots on a fire?
Basically, it says that this synchronization driven
functional integration happens at all scale at all moments. At any scale, you can look and describe
a system. If you describe it as a set of chemical equations, there is a process of self-organization
that entails the reduction of its dimensionality that entails symmetry breaking and the emergence
of structural constraints that will work outside the scope at which the system is defined, that will
work for example as structural constraints in a disumed in a scale of view of the system.
So this in and of itself does not come pretty far from solving the problem of cognitive
optimization. Because there is in fact a pretty strong disagreement about the hierarchy, the
architecture of living and cognitive systems between FPP theorists and systems biologists.
FPP theorists are interested with control, are interested with statistical inference. So they
talk of hierarchical modularity, fractal hierarchy, of blockets within blockets within blockets
while system biologists are interested in how systems self-produce. So they're interested in how
a set of constraints that is embodied within a physical system manages to produce and create itself.
So the topology is just under silence, fractal versus meshes, but it's not a property of the
basic Markov-Blanket formalism. So it's nothing critical, it's something that can be fixed within
the formalism. Something that is not however is the way commutative systems, living systems,
as inactivists and phasors a lot self-create. So let us demystify this and explain what means
to self-create. In physics we have a basic epistemological construct that is a state space,
that is a mathematical space that we declare has all of the relevant information to explain
the behavior of a system. Often it will be macroscopic thermodynamic variables that are
the only one that matter in virtue of the very strong symmetry of classical physical system
and the basically averaging out of all micro projections. In biological system however you
have much more complicated kind of symmetry breakings. You have multi-scale kind of symmetry
breakings that organize the very specific way without which the system does not keep working,
it dies. And most importantly these symmetries are built through the system history at both
developmental and evolutionary scales and it is built by multi-scale fluctuations that work
basically from quantum and thermal noise so they are not predictable, there is no way to predict them.
And so you have a pretty strong sense of historicity, you have specific events that make
the system break out of a deterministic landscape and do new things, basically be creative.
This is what a creative evolution is and the FEP framework just does not address it because
the way it demonstrates the FEP is to define a specific micro landscape, a specific structural
architecture and then to look at what is attracting dispersion within this space. So
they construct the object that does deflation and the object from which deflation derives
are both historians, they're entailed by how you put the problem. And historical systems
which is formally mixing systems, which is stronger than echo DCT by the way, there are systems that
basically, they dissolve, they get into a specific shape and they stop moving.
So you can have kind of hysteresis or cyclical, interesting behavior but what you cannot have
is a change in the structural condition of the system itself, what you cannot have is death,
what you cannot have is creation, what you cannot have is life. So the FEP is as is formulated
incompatible with the representation of living systems, so it cannot explain them.
What I say is that there is a pretty basic shift, you know, we understand it, that could address
this problem and make the FEP principal, grounding the physics of biological creation.
This derives from the functional interpretation of the FEP. Basically the FEP, the active space
is very considered to represent the cognitive landscape that is subjectively enacted by
cognitive agents. So cognitive agents, they have a straight view, they can change how they relate
to bikes. Most importantly, they cannot know possibly everything that's out here. So their
intrinsic space, that is described within the FEP framework, it cannot be because I closed,
it cannot be a sufficient presentation, it cannot be in set space. And it can actually
write in the exchange information with its extrinsic dynamics. You can have ways that the
intrinsic dynamics feedback into the extrinsic world. This construction, when an agent basically
builds its need into a world, like when a beaver makes a bomb, or by using books to change the
way I think. Or you can have elements of the world outside my cognitive landscape that work back
into my intrinsic landscape. Which is learning, for example, learning how to bike, which changes
basically how I sit bike, or taking psychedelics that will change my neurodynamics to a very
base metal, or ageing, or death, or being hurt. So we can say that synchronization across my
crossblock cats does not speak to self-coinization within a specific set space, but it speaks to how
set space are created by the activity of proto-minds, basically, basic constructs that enact
properties that we associate generally to cognitive systems. And how these proto-minds,
in virtue of their functional organization, and the symmetry breaking that is entailed by it,
build set spaces, unfold measurable symmetries and asymmetries in a specific system,
and create, strictly speaking, biological set spaces. So a question that needs to be asked
is if set spaces are basic to physics, and FEP explains how we get set spaces, is FEP basic
to physics? My answer is that it affords this. I don't know if it's true, but it's a possibility
that acting in France basically gave us a very basic construct, that is, the grounding of all
our physics. The FEP can be understood as grounding the view that, the view that Friston called
Markovian monism, that's called informational monism, and that is the idea that what there is
in the world, what is the antique basis of physical existence, is basically information
fields that do active inference. And if those information fields are prior ontologically
than what we observe as inverting the agents, our life, the existence of specific trajectories
that are survival, will be entailed by synchronization across a Markov blanket, basically synchronization.
This pretty much directly speaks to quantum phenomenology, because the way the coherence,
which is basically when quantum objects lose their quantum properties, it works back in time,
which means that if I observe now a particle that has been
individuated as something in the past, my observation now becomes entangled with the way
events folded out back then, back when the particle collapsed. So what this means is not that you
have backward causation, this is not a consistent notion. What it means is that
the universe keeps evolving as quantum fields until it is forced to stop evolving as quantum fields
through observation, through in the active framework, it's causation across Markov blankets.
And this is even more fundamental than quantum physics, because the very basis of the universe,
cosmological laws, they evolve, they change. And because of Noether's theorem, the cosmological law
reduces the physical symmetries. And those physical symmetries can be demonstrated through God's theory
to be firmly equivalent to the self-organization of specific graphs, which is, by definition,
active inference. So let us disentangle the claim I made here. First, I say that active inference
is pretty close to be a divisional acid solution or a basic set of tools that address all problems,
because it provides an innovative framework, which is a formal and cognitive ontology for study of
cognition and optimization of the states. Define a principle, it provides basically a
grounding principle. So a basic physical explanation for how we get embodied intelligence,
how we get cognitive systems in the world. And if we want a principle to actually do that
efficiently, truly, I don't know, we need to develop a mathematical theory not only of
self-organization within state spaces, but of self-organization of unfolding spaces
on the grounding of active inference. If we do that, we can address the criticism from creativity.
We need to do that to address the criticism from creativity, but it will also make basically
a basic grounding explanation for all of physical reality.
So there is one concern that could be raised about this, which is that the view that the
universe is unfolding, that there are proto-minds that make up the things that we see, it's somehow
opposed to the realistic worldview. And it is indeed opposed to the classical view of realism
of the idea that you can have objective properties in the world that are
uncoupled from interaction, from observation. This is the formulation of Einstein that is
displayed here. And the first principle understood as a grounding principle for the physics of
creation are basically admitting that the physics of creation is a problem. It grounds what is
called anata, which is the Pali word for basically there is nothing in itself. It grounds the view
that there are no individuated things and no individual properties outside interaction,
well, in the French principle formalism, across a map of planets. And the view that
the objects that we talk about are true, not withstanding our subjective way of describing it,
it is called scientific realism, and we don't need it to ground a realistic scientific worldview.
We can, the naturalistic worldview derives from the basic idea that you can study the world as
something that derives from causal relation in nature. And this is totally compatible with
some kind of participative realism where the observer participates in shaping reality. You do
not need a solipsistic thing in itself existence to ground it. So there is no problem here.
So I would thank the active inference lab for the infrastructure, let's say, of this work.
Okay, what's research, which is a perspective laboratory for the study of cognitive and
self-considering systems that is meant to electivize research, which is to bring the plazaer to
pragmatic, embody the setting of social political dynamics. And the active inference lab,
straightforwardly, is a lab about active inference. And I'd like to thank people who gave feedback
for some patience, and I'm back for you to check the project in OSF. So thank you. I will be taking
questions now. Well, really, really, really cool stuff. I would like to come and, okay, I see that
Sergio is already on his way. There we go. Hi, very nice talk. I would like to be a little
to ask whether, in terms of Karl Popper, could we falsify the free energy principle?
No, it's not. You can falsify any model that is formulated on the basis of the future principle.
Because it's a model. You cannot falsify the model. This is not how this works.
All right. Okay.
Kevin?
Hello. Thank you, sir. All those are really neat talk. And this is a, actually, this actually
goes into the mathematical aspect things. So I'm curious as to which methodical formalisms are
being used to underpin, I guess, the free energy principle, and maybe active inference,
for instance, the extension. And maybe for context, because I'm coming from the idea of, okay, well,
you have a cleaning geometry and a pair of all non-cleaning geometries. So that's the thing,
right? But also, more fundamentally, you have different axiomatic structures. You have like
thermo-elephantal set three with the axiom choice. And without the axiom choice, within the mathematical
community, you have disagreements about which rules do you want to play with, so to speak.
And then more kind of, you know, in the computer science realm, there is a different set of axioms
that actually don't use the law of the excludable. Like, right? So there's this thing called like
the proof by constriction, where basically, you assume the offset of what you're trying to prove,
show that least some type of logical constriction, and then boom, right? Well, that can't be the case.
So the other proposition, I'm true. But intuitionist mathematics actually says, no, no, no, that's
actually not a rule we want to play with, because what if you have a situation where like, you know,
the algorithm just hasn't finished yet. It's not true or false. It's just like, there's this third
category of unknown. And so you actually have different kind of logical foundations for variations,
a different axiomatic, or different axiomotage, different ways to axiomatize mathematics. So I'm
kind of curious as to what the underlying framework is. I know that's a lot, so forgive me, that wasn't
clear. Okay, so the idea that you cannot, you have, in fact, several possible mathematical
grounding to things, which I agree to. I do not know if you want me to arbitrate between things.
I cannot do this right now, but I want to signal that I am not in the PNG program. I want to get
into it on the math or collective intelligence in the season spot. Right now, I won't know.
There can be links to category theory, for example, there is clear links to God's theory,
I cannot, I do not see how this relates to the foundation of mathematics. So this is
something to develop on. Okay, gotcha. I appreciate that. Thank you.
Hiya, and good morning. Thanks for the great talk. It definitely means I could wake up jolt
in this hour. So, first of all, I really resonate with the point you emphasized. I also agree that
creativity is something that's, I wouldn't say incompatible with PNG principle, but something
that's extremely underlipped and under-emphasized. And it's actually Maxwell, who really reminded me
of this in a conversation that Carl Jesus is more inclined to emphasize the conservative nature of
the FEP. And so I think it's really good that people like you in this talk are kind of doing
the complementary direction, right? What is the creative power that also follows from the FEP,
in my opinion. So I was kind of surprised that you, because I was confused, first for clarification,
when you say creativity, were you just more referring to the creative aspect of auto-polysis
or the the creation of the generation of different trajectories, or are you also including
the more psychological phenomena of creativity? Because you didn't go into that, both, yeah.
As I said, creativity, as I put it here, as I formalize it, is any kind of symmetry breaking
that is not entailed by the system macroscopic and starting conditions. So it's basically
unfolding set spaces, unfolding asymmetries. The fact that they are biological or cognitive,
is not really even because those are organizational features.
Oh, okay. So you're actually looking for just the most general notion of creativity, right?
Yeah. So I think one thing that was of an interesting, so at some point in the slide of
intrinsic to extrinsic and extrinsic to intrinsic, and with a bit of a, well, I'm going to just
flatter Maxwell here, a bit of a Maxwellian point about, you know, beyond internal and external.
I think it's important to acknowledge that if we just take the internal relative to the agents,
that in there that you have a lot of the intrinsic extrinsic dynamics and therefore also
the phenomenon of dealing with hidden states.
And so in a way, when you have within the agents, the processes of mutual active inference,
or mutualistic inference across different scales, you still have to contend with that,
that those subsystems don't know about much of the rest of the system. And more importantly,
the whole ecosystem has like, you kind of regions that are unmodeled, I would say.
And I think it's in these, I'm sorry?
That I did not make a distinction between internal and external. I made a distinction
between intrinsic and extrinsic. The intrinsic part is basically what the agents can understand.
So I can understand that if I chair, get into my head, I'm hurt. I cannot understand how
lesion will affect how I move. So there are facts that
surviennes that invite themselves into the subjective perspective of the agent,
regardless of whether they have a priori epistemic values, whether they're priors.
So what's intrinsic is all that the agent can understand. And what's extrinsic is everything
else. So that's sure that you have an interesting and important play between
intrinsic and extrinsic architecture between scales, because what's intrinsic at my scale,
for example, there is a bike there, there is a computer there, I get it. It's not something that
they sell in my ear, that's another else. As you're processing, understand. There are some other
things that I do not, that I do because I did physics of addition, but I'm not supposed to.
So does this, I think this, I don't think this, I'm sorry, but I think it disintegrates an important
point. I'm a bit lost because I think this is a bit complicated for me to follow, but I think what
I'm getting at is that it's in these interplays that maybe creativity is most interesting to think
about. So yeah, thanks for clarifying. You're talking about interesting extrinsic. I think what
I'm trying to explore is the way that within the agents, there are basically extrinsic geometries
that are acted upon by the agents without being actually internalized. And it's not accessible to
the same degree of systematic instrumentalization, rather there's like an extrinsic geometries that
are attuned to the agents, but not as equipped. How do I say this? It doesn't have the same kind
of agency as if there is like a generative power to a lot of Markleblankens that are not really
the Markleblankens involved in what we would refer to as our kind of conscious executive
attention. So basically, you know, when you folks psychologically talk about creativity and the
artists of, oh, there's something welling up in me. And basically, I'm asking or wondering about
what the source of that is and kind of implying that I think that FEP might still be very
compatible with explaining that, for example, not just exploring state spaces,
but configuration, like how do you connect different Markleblankens or subsystems together
to certain dynamics? And I think the connection is the critical issue.
Exactly, right? So the infrastructures that connect or interweave the different subsystems.
So yeah, I don't know, I'm just rambling a bit, but I definitely get more where you're
getting at. So thank you. Yeah, I think we agree on the coverage of the FEP.
So if there is no line of the question, I'd like to
take more time to answer this of Sergio Rubin. Maxwell, do you want to do it now or can you
wait two minutes? Oh, I mean, it was related to Sergio's point. I just wanted to explain
the whole falsifiability thing. So I mean, on the one hand, I think the idea of falsification
in science is a philosophical gloss on the actual practice of science that doesn't actually add
anything. Scientists aren't trying to falsify their hypotheses. Always model comparison or
hypothesis testing. Even in the minimal case, you're comparing your hypothesis against the
null hypothesis. We never, I mean, except in very gerrymandered circumstances, we don't falsify
in critical experiments or really just fabrication of philosophers, in my view. So that leads me
to say also, when people say the free energy principle can't be falsified, it's because the
free energy principle, of course, is a piece of math. And you don't falsify math, you provide
a counter example, you show that the assumptions lead to a contradiction, but you don't falsify
math. And you wouldn't falsify the FEP itself any more than you would try to falsify calculus.
It's just a category mistake. What can be falsified, as with other applications of the
principle of stationary action, is whether the framework applies to a given empirical system.
That's subject to falsification. You can say, oh, I can use the FEP and active inference to model
this or that, and you can be wrong about that. But the FEP itself is just math. And now, especially
in this new Bayesian mechanics for stationary processes paper, the math has been fully worked
out. There's the existence, there's an existence proof, there's a construction. I mean, everything
is there effectively. The FEP just follows from non-equilibrium. Exactly. It just flows from
the thermodynamics. Okay. So I think it's a pretty critical issue for at least the
development of the FEP because somehow you have, I agree with you that falsification is a very
flawed criterion. If you take falsification seriously, you won't throw away evolution theory
because you saw a butterfly that is, this is not just a consistent thing that you do.
So what you have is a softer, more inductive kind of reasoning that exists, even by poppers
of all these accounts. And you have, basically, ways when you criticize a theory, you cannot,
you will not, you cannot, restate it, just leave it away. You basically look at the
somehow people in the Bayesian science got the idea that falsification
is empiricism, which is specifically what falsification was related against. So they think
that everything that cannot be made into a difficult test is false and wrong. This is
a big problem. I don't know how we got there, but we are there. And people get angry, basically,
when there are bits of theory that cease. Okay, okay, next one. So when people ask whether the FEP
is false or not, they are angry about it. And yes, Marko, it is fair.
Oh, I'll use. Okay, I'm sorry. I will close the chat because I'm just answering people on this
chat and this is inconsistent. So falsification is inconsistent. People believe it is the opposite
empiricism. And so when you have bits of theory that show they are basically angry, but you cannot
say things without a language that is very basic thing that all people that do that all people
know what's on the level. And that is precisely what Popper wanted to emphasize
by the mainstream. So I don't know how to circumvent this because people are just not
willing to engage with theory. And you cannot build empirical predictions that are as if I
am all not serious, a prediction or fast variable without agreeing on why to speak. So
I do not know how to do it, how to make this bridge between the empirical level and the
empirical communities and the more thorough rented communities. But it's critical to do this if you
don't want to keep a behavioral sense that has literally the same standards as 30s rate sense
which is not good standards for this reasons.
The free energy. Can you use the free energy principle to verify things? Let's say if we go
to Mars and we want to know if there is light there we can use the free energy principle as a
test of verification. I'm not sure what the crescendents were. I'm sorry. Can you
rephrase if you were expecting? Right. So there is this confrontation between
falsification and verification. So what stands at the end? It's the verification
rather than falsification. So you verify things. Let's say if a living system is alive or not,
you verify by checking whether it's autopoys, is this still going on or it stops?
So in the realm of mechanical modeling, so what corresponds in my table to mechanical and
functional explanation, you do basically what a good basing agent will do which is that you
provide mechanism, you check consistency with structure, you check consistency with terminology,
you check consistency with system. And in that domain you can validate and you can falsify
this due to a prediction. But in pure formalism I don't know in the way you develop not the models
themselves. But the language with which you develop the model, I do not know if you are
strong at theory ways to ensure you are not wrong. So the position I hold is that you do not have
truth, at least in the sense of resonance. So I'm not worried about this because I don't think we
can solve the issue. But you will not do things in the world without taking some kind of hypothesis
of some kind of speculation of some kind of quantum leap between hypothesis. And actually this is
part of what proper Franciscanism is about. So you will have theories, you will have formalisms
that will compete for cognitive space in the head of scientists. That's it. And I don't know if
trying to formulate a grant encompassing demarcation material for what math is useful is constructive.
Okay, thank you. Thank you.
All right, so we have time for another very quick question if there's anybody.
Stephen.
One question. When you talk about intrinsic and extrinsic, I'm wondering because often we talk
about motivations or teleology. I what's the intrinsic or extrinsic like purpose or aim of a
situation. Now, I don't know how that often extrinsic is then thought to be brought in from an
external source, but it could be extrinsic in terms of what the action policy of that particular
regime of attention is about, if that makes sense, like what's, so how does that fit in,
so it's not necessarily, so it brings in the question of what it means to know, you know,
if you talk about extrinsic or intrinsic knowing, you may fall into the trap of kind of
representationalism, but if it's maybe linked to the teleology of the moment,
then you've got the idea of what it is, what's adjacent to what it is and plausible,
and then something acting bigger than that. Well, at the time, so I'll answer quickly.
We have three kind of distinctions between intrinsic and extrinsic at play. You have the
motivational where it's basically reward versus informational again, what we're seeing. You have
the freestyle definition, which is basically the structural versus what I say, which is
pretty close, but not quite the same because it's basically what is entailed by an agent model
and what is not. So, formally, I don't know how those two fit. I know that not fit will be
motivational. So, I think you will look at me after, so I want to say again that I'd like to
get into a PhD on the math, collect intelligence, please, send my way,
and in event offer, you see, I'm going to be grateful. Thank you. Thank you. Take care.
All right. So, we're going to take a 10-minute break. We will get back at 10.
Thanks so much, Serpa, for your wonderful talk and really cool discussion. Thank you.
