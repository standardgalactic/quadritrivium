I'm just taking the back end of your published bio, talking about that of the Royal Society
of Biology 2012, Weldon Memorial Prize 2013, Embo, Excellence Prize 2014, Academia Euro
Thankfully, you haven't updated since 2016. I'm 10-16, Charles Brunch Award for on Parallel Day Contribution
Grain Research and the Glass Brain Award. Really glad to have you among us, and thank you
over to you for the physics of sentience.
Thank you very much for that wonderful introduction and your kind comments. It's a great pleasure to be here.
It does feel like a very warm community. I'm going to share my screen and then hopefully that will set us all up.
So let me repeat my thanks for being here. I'm going to start with, as usual with this talk, an apology, but a very specific apology now.
I don't have a foundational training in cybernetics, but I have, over the course of the work, largely inspired by neuroscience
but appealing to physics during my career, it has become very clear that cybernetics and the kind of work that I've been engaged with
have very intimate relationships and probably share certain foundations, along with things like perceptual control theory.
But I repeat, I do not have a foundational training in these disciplines. So what I've got to offer in the first hour of this session
is really a view of self-organisation and sentient behaviour through the lens of a physicist and neuroscientist in the fond hope that you will be able to join the dots
and see how it can be translated in terms of the basic principles with which you will be much more familiar.
So I'm going to divide the talk into three parts. First of all, telling a story about behaviour, about self-organisation from the point of view of statistical physics
and information theory with a special focus on Markov blankets and how Markov blankets individuate things that possess attributes such as behaviour
and trying to understand those attributes in terms of something that we refer to as a Bayesian mechanics.
And then I'm going to tell you exactly the same story, but using the concepts and the constructs that come from neuroscience and neurobiology.
So how would these physics-like principles be applied to the brain, to things like you and me, or indeed single cells?
And I'm going to illustrate that in terms of predictive coding and neural networks as a particular instance or application of the physics that we're going to cover in the first part.
And then if we have time, I'd like to just drill down on the nature of agency within this kind of treatment and specifically talk about the difference between mere reflexive behaviours of the kind you might say find in a thermostat
and the sort of planning and deliberate behaviour in agency that we find in things like ourselves.
And I'm looking forward to a conversation about whether that bright line is necessary and how it does relate to cybernetics.
I'm going to start with a question posed by Skrodinger. How can the events in space and time which take place within the spatial boundary of a living organism be accounted for by physics and chemistry?
I'm not going to answer that question and clearly we can't do that.
But what we can do is just highlight the notion of a spatial boundary as being requisite to be able to talk about anything in the sense that to talk about some entity, some particle, some person or something, you need to be able to individuate it from everything else in the universe.
So I'm going to read that thing as a statistical object or the boundary that defines its definitive of that thing as a statistical boundary, specifically a Markov blanket.
So for those of you who are not familiar with the Markov blanket notion, it's a very ubiquitous construct in statistics and causal inference, but plays a foundational role in what I'm about to say.
I repeat simply because it is the device that allows you to separate or individuate the internal states and the blanket states of something from everything else.
So more specifically, I've just tried to cartoon the intuition here in terms of a very simple little universe where these blue circles represent some abstract states of the universe and the arrows denote an influence of one state on another state.
And if I were to pick a particular set of states and to say my states, then we'll call my these states internal states or states that are internal to me.
The Markov blanket is defined in terms of the parents, the children and the parents of the children of the internal states.
And the role of the Markov blanket is to provide a kind of insulation, a kind of separation between the internal states and the remaining states, the external states here.
So technically, what this means is that if I wanted to predict the dynamics or evolution of my internal states, given the rest of the universe, I would only need to know the Markov blanket.
All the information about the entire universe that is pertinent to me to my internal states is contained upon this boundary or this Markov blanket.
Mathematically, that just means that the internal states are conditionally independent of the external states, given the blanket states.
So that's my definition of a thing less.
And I'm going to make a further move here. I'm going to make a bipartisan of the blanket states into sensory states and active states.
According to the very simple rule that the sensory states influence but are not influenced by the internal states.
And similarly, the active states influence but are not influenced by the external states.
So I've now effectively got a partition of all the states in the universe or this particular little universe that enables me to identify a particle or some entity that comprises the internal states and the blanket states that themselves can be divided into active and sensory states.
And you would be asking, why have I done this? Well, it, it organizes a way of thinking about all the kinds of systems that we as scientists and philosophers like to think about two of my favorite systems are here, the brain.
So under this kind of partition defined by these sparse couplings, the arrows, how can we consider the brain while the brain would have internal states or my synaptic activities, my connectivity, everything I need to list in order to define the state of the brain at this point in time.
And the internal states are going to influence the active states in my actuators, my autonomic reflexes that perform actions on the external states that then change my sensory epithelium, my sensory states that are then going to influence my internal brain states.
And so the cycle begins. And exactly the same causal dependency structure or separation or partition of states can be found.
Anyway, you look so for example, a single cell will have intracellular internal states that are internal to say the active filaments of a cell that are themselves beneath the sensory states that are pushed out into the external states that reciprocate in terms of causal influences.
By activating cell surface receptors that change the intracellular states that change the action and so forth.
On both, both of these examples.
You have this notion that the inside is influencing the outside the carelessly through the active states while the outside is influencing the inside again the carelessly through the sensory states.
And this sort of completes a circular causality that as a neuroscientist one could read as your very elementary form of an action perception cycle.
And what I'm going to do now though is just to ask you to forget about the Markov blanket.
We're going to now rehearse one on one physics to the extent that we need to to pursue the argument.
Having established the core physics at hand, we're then going to put the Markov bucket back into play and see what special properties emerge.
And I'm framing it like that because the starting point for this is exactly the same starting point that you would find in all kinds of mechanics, whether it's quantum mechanics, statistical mechanics or classical mechanics.
It starts really with an expression of the dynamics of some universe.
And I've sketched that out here in terms of, in this instance, a large non equation.
So the rate of change of some states is just a function of the state, plus some random fluctuations.
And I've cartoon that here in terms of two states.
And this can be read many, many different scales.
For example, it could be neuronal oscillations in one cell of my brain, as they cause that trajectory of these two states, this two states, states, space, space over very fast time scales, the appropriate gamma oscillations.
It could be my cardiac cycle coming through the phases of the cardiac cycle.
It could be me getting up in the morning, having a cup of coffee, doing my emails and working through the day. It could be an annual cycle.
The point being here, we are interested in describing systems that have a particular characteristic.
In fact, one could say, definitional, definitional of them being existing in the sense that they possess characteristic states.
The characteristic in question is that they always, the system always revisits states it was once in.
And this could be read, in many ways, it could be read as possessing an attracting set or an attracting manifold on which the states evolve.
It can be read as the solution to an unequilibrium steady state.
And it can also be read effectively instead of being tracing out particular trajectories, we can read the density of these trajectories as a probability that you will find me in a particular state if you sampled me at random.
And that's the, if like the interpretation that I'm going to assume.
So why have I focused on that interpretation?
Well, we know a lot about the dynamics, not all the states in and of themselves, but of the density distribution, the probability distribution over those states.
And some of you may or may not be familiar with various expressions of the density dynamics are written down here in terms of a Planck equation.
So now it's a rate of change, not of the states, but of the probability density over the states that is expressed here in terms of the amplitude of the random fluctuations and the flow.
And this equation is, again, ubiquitous in physics and, you know, you could read it as a continuous form of master equation.
It could be the time independent Schrodinger equation.
Wherever you look, it's a fundamental equation that describes deterministically the evolution of the probability distribution.
But I've just said we're interested in describing systems that have a characteristic set of states such that this probability distribution doesn't change with time.
And that's the key move here.
So I'm basically looking for solutions for these density dynamics that are now characteristic of the dynamics of systems of interest that possess an attracting set.
And just by setting this to zero and rearranging it specifically using in this instance the Helmholtz decomposition.
What I can do is express the dynamics, the flow, the way that I change my states over time purely as a function of the amplitude of these random fluctuations and the gradients of these probabilities.
So there's also another term here known as a solenoidal component.
So this is the equation I want to focus on because it's got some really intriguing interpretations.
Before I sort of get into those interpretations, maybe a good idea just to explain why there are two terms here describing these flows on these probability or log probability gradients.
One, this decomposition basically is just describing the fact that you can always split the flow into two orthogonal components.
And the first one, say for example, we think about water flowing down a bath, the plug hole in a bath, then the gradient flow is flowing down the gradients.
Whereas the solenoidal flow, denoted by Q here, circulates on the iso probability contours or solenoidal, shows this kind of solenoidal effect as it circulates around.
So it's just a way of breaking up the dynamics into a gradient flow on the one hand and some circular flow on the other hand.
Both of those have interesting implications.
The gradient flow we're talking about is actually flowing, if you like, up log probability gradients.
It's like gathering, flowing up a concentration of the probability of finding me in a particular state, as if the system is trying to gather itself into its attracting set and resisting the dispersive effect of the random fluctuations.
The circular flow is interesting as well, because it says that these kinds of systems must have a form of oscillation or cyclical aspects, solenoidal aspect to them.
And of course, if you think about biological systems, they're full of biarrhythms and oscillations and indeed you can almost say life cycles themselves are an articulation or an expression of this kind of ubiquitous kind of dynamics.
So that's where we've arrived at the solution to the density dynamics has to have this functional form which can be expressed as a gradient flow on these log probabilities.
What we'll do now is bring the Markov blankets back and see if there is another kind of mechanics that complements or fits in the classical or statistical and quantum mechanics that can be derived from these density dynamics.
So that flow equation holds for all the states and the particular petition that we discussed under the Markov blanket.
So the internal states will be doing a gradient flow on the probability here of the Markov blanket states, as will the active states.
And notice by construction, I can drop the external states because the internal states and the active states are not influenced by construction by the external states.
So this leads to a slightly simpler form of these gradient flows that I'm going to read in terms of perception and action, both in the service or look as if they're in the service of maximizing the log probability of states.
So what are the interpretations of this quantity, this log probability of some sensory states given a Markov blanket or given me.
And I've listed a few interpretations here just to illustrate the, again, the importance of this fundamental kind of dynamics as gradient flow.
If you recall, this probability scores the likelihood you will find me in these states.
They are states that part of my attracting set they are literally those states that attract me. And in that sense, then they are states that are valuable for me, given my Markov blanket.
And all of these, all that's that this equation is saying is it looks as if my internal states and the way I act upon my world or my external states are trying to maximize by flowing uphill.
This quantity, which can be read now as reinforcement learning if you're a control theorist, it would be optimal control theory.
If you're an economist, you could read this in terms of expected utility theory.
And that's nice because the negative of this value.
If you're an information theorist will be known as the self information, the implausibility of this sensory observation or outcome or event, given me, more simply surprise or even more simply just a surprise.
So this we can spin out the principle of maximum mutual information or the information principle equivalently the minimum redundancy principle, and indeed the free energy principle.
Why the free energy principle. Well, the free energy is just a bound or proxy for this, this surprise and I'll unpack the functional form of this later on.
I'm trying to give it, give an intuition as to how one can interpret the components of the free energy, equipping it with, you know, a teleology or a functional interpretation which may or may not be necessary to simulate the behaviors of interest.
The average of self information or surprise is just the entropy, which means that this fundamental gradient flow will look as if it's trying to minimize the dispersion or the entropy of the blanket states and the example, the sensory states.
And of course that's just an expression of the Holy Grail and physics or the physics of self organization as articulated say by Herman Haken's synergetics, and if I was a physiologist.
It would just be a statement of homeostasis it would just be a statement that systems that persist in a physiological sense are those that show a generalized homeostasis they are keeping the essential variables, as it were, within viable bounds that are characteristic of the physiology
kind of thing that this system is. There's a final interpretation that I want to pursue here which is the interpretation that a statistician would bring to the table.
If a statistician saw this expression, she would think are you are now writing down the probability of some sensory observations some data, some sample from the world or generated by some process or world, given not me on my Markov blanket but me considered as a model of the way in which my sensory observations were generated.
And this will be known as statistics as the model evidence, also known as the marginal likelihood of these sensory data and emphasize the model of course because what we're seeing here is that to be to solicit valuable outcomes and to minimize my surprise and to self organize in a way that resists a second law.
The second law applied to open systems of this sort is just to be a good model of my world. And of course this is just a statement of the good regulator theorem from Los Ashby and colleagues, but I'm going to pursue exactly the same notion from the point of view of statistician leading to things like the
basing brain hypothesis, also formulated in terms of evidence accumulation, gathering evidence for my model of the world and predictive coding which is the example that I'll show later on that leads to a specific process theory that many people in the neurosciences subscribe to in terms of trying to understand the dynamics of a brain doing its sense making and prosecuting its actions upon the world.
So that's the, that's the physics part.
I'm now going to tell the same story from the point of view as if I was lecturing to people in psychology or cognitive neuroscience.
It's the same, it's exactly the same same same ideas. And I think nicely illustrated by this 16th century oil painter, famed for painting still lives, but when viewed from a different perspective, give you a very different visual impression.
Previously you saw a bowl of fruit, and now you see a face. The point is making is that you made that face. This is a very active construction, an interpretation, a hypothesis, an explanation, a fantasy that you have used to explain this particular set of impressions on the sensory sector of your Markov blanket.
So just to unpack that a little bit more, it really speaks to the brain literally as a purveyor of fantasies or literally a fantastic organ that is evincing very much an inside out kind of perspective on perception which somewhat contrasts with early 20th century view of a sort of
outside in where the brains, so particularly say visual hierarchies were thought to extract information from the sensory input. This turns that on its head will have done then it's strange inversions and say no, no.
It feels it is a better way of understanding perception and sense making is to treat the problem as an active problem of construction and the active nature will become even more apparent as we get deeper into the notion of active inference.
So this view, I sort of mentioned 20th century sort of outside in perspectives, but in fact they were predated by this inside out perspective by people like Herman von Helmholtz and you could argue right the way back through campus to Plato, but beautifully summarized here by Helmholtz as follows.
Objects are always imagined as being present in the field of vision as would have to be there in order to produce the same impression on the nervous mechanism. So again, he's referring to this notion of imagining something on the inside and then predicting what you would see and then using what you're actually seeing to update, revise your hypothesis until you've got a good account of what's going on.
And he referred to this in terms of unconscious inference or a perceptual inference very closely related to the notions of Richard Gregory in psychology who saw perception as hypothesis testing again emphasizing emphasizing an inactive aspect to to our perceptions and visually palpating the visual scene with our eyes to gather the right kind of evidence to test the hypothesis that this particular
set of visual inputs was caused by this or that. And these ideas have been taken up in machine learning and artificial intelligence research to great effect.
For example, people like Jeffrey Hinton and Peter Diane actually built a Helmholtz machine as a mathematical metaphor image of the Bayesian brain, borrowing explicitly from Bayesian statistics and the work of Richard Feynman, which is where the free energy comes from.
So Feynman, if you like, solved the problem of evaluating that marginal likelihood of model evidence, which is an intractable problem by converting it into an optimization problem by producing a bound upon the log marginal likelihood or that self information that we're talking about earlier on.
In the context of QED or quantum electrodynamics. So putting these two together, they invented the Helmholtz machine, which is formally almost exactly what we would predict from the point of view of this physics understanding of sense making.
And we want to now extend the story to include action.
So let's come back to this notion Helmholtz's notion of impressions on the nervous mechanism. So if that Bayesian interpretation of self organization under a given attracting set that possesses a Markov blanket.
What would that mean? Or how could one describe sense making on the inside on the internal states? Well, it would look as if me on the inside.
I am in receipt of the sensory impressions on my sensory epithelia my sensory veils in my retina, or my skin, or my hearing apparatus, and they will present themselves as shadows sparsely sampled impressions upon my sensory veil.
The sensory sector of my Markov blanket, and it would look as if my internal dynamics were trying to predict or explain what caused those sensory impressions.
So how could we think of that in terms of the internal dynamics? Well, we already know how to describe the internal dynamics, say my brain dynamics, my neuronal dynamics, because it must be an instance of one of these fundamental flow equations.
So I'm going to make a couple of moves here. What I'm going to say is, if I can read my internal states as dramatizing some variational or probabilistic representational beliefs or probability distribution about the external states, then I can interpret this
fundamental gradient flow, which I've now expressed not in terms of the log probabilities but in terms of the free energies that stand in for the self information or the log values.
So we can now express this in a way that somebody in engineering would immediately recognize, and I would imagine also people in say perceptual control theory would immediately recognize the particular form here I've written down as a Kalman filter, or a simple form of Bayesian filtering, where the solenoidal part would be read as the prediction.
Imagine that the internal states mu now stood in for some expected states of the world.
So that the mu was now an expectation of some say a Gaussian probability distribution, which means that if I had some expectation about the state of the world I could predict the rate of change of the state of the world.
Now, I don't know whether that's true or not, but I can now use the gradient flow part, the non solenoidal or the dissipated part of the gradient flow, and I can now interpret these gradients of free energy in terms of a prediction error.
And I can use that prediction error to update my prediction to give me a the best guess about what's going on out there in terms of the external states.
So let me make that try and make that even more intuitive and just ask, well, what is this prediction error? Well, I've just said it mathematically it's just the gradients of the Bayesian free energy on the surprise of the self information, but intuitively what is it?
Well, imagine I had this sensory impression on my eyes on my retina, and I had an internal brain state that stood in for a belief that this particular set of sensory impressions was caused by a howling dog.
Now, if I had a generative model that could generate what I would see if this hypothesis or expectation was correct, I can then compare the ensuing prediction with the actual sensory impressions to produce a prediction error.
And then what this equation is saying is, I'm using that prediction error to drive changes in my internal states by neuronal activity, say, in order to eliminate the prediction error to destroy the free energy gradients to attenuate and resolve the prediction error until I have found the best explanation for this particular pattern in terms of the prediction, hence predicted coding.
Now notice here that this is just describing self organization of internal states in relation to external states and communicated by sensory states in terms of minimizing prediction error.
You'll never actually know what caused your sensation. So in this particular example, it was actually a cat casting the shadow that looked very much like a dog.
But it doesn't matter if I don't know all I need to do is to keep my prediction errors low for as long as I live and then job done.
So that's a very sort of parsimonious and I find a nice way of just describing the imperative sense making and action in the sense we can forget about the physics and just reduce it all now to prediction error.
And, you know, again, for those people in a perceptual control theory, this should be a story and well rehearsed.
So what about this sort of action perception cycle. Well, there are two ways I can minimize prediction error.
I can either change my mind literally by changing my neural activity to change the predictions of my sensory input and make them closer to the sensations to resolve the prediction error in the way that we've just described.
There's another way I can do that. I can actively resample my sensorium to make my sensations more like my predictions.
And this would be action changing sensations to make more like predictions, as opposed to perception, namely changing predictions to make them more like sensations.
So heuristic and what this means is that we would expect to see action fulfilling the prophecies or the predictions afforded by perception in a very, very simple way.
And this is to illustrate the simplicity. I'm not going to sort of talk explicitly about predictive coding and particularly hierarchical predictive coding of the sort that people currently in the neurosciences think is a nice way to think about message passing and dynamics amongst different
populations in the brain. So what I've done here is draw a schematic of the visual system and its entirety. So starting off say with visual signals from the eye reporting visual input.
They come into a nucleus and subcortical nucleus called the lateral geniculate nucleus. And these visual inputs are then in receipt of top down predictions and the difference then is scored by a prediction error that then is sent to drive or update beliefs expectations represented by units encoding what is being predicted to try and eliminate this first order prediction error.
In a hierarchical context, so we can just repeat this process. These are now first order predictions that themselves are being predicted by second order predictions that are used to compare with the first order predictions to produce a second order prediction error that then is used to drive these higher order predictions and then so on recursively to any hierarchical level desired.
So that would be a picture of hierarchical predictive coding or hierarchical message passing or Bayesian belief updating or all words for the same thing that will be consistent with this physics view of self organization.
What about the action? Well, let's consider another kind of input. The kind of input that in neurobiology would call proprioceptive input.
This basically just reports the state of my actuators, the state of my motor plant might say my muscles and this would come in say to the Pontine nuclei in the brain and it could be in receipt of top down predictions about where I feel my eyes pointing and I could use the ensuing prediction error to revise my beliefs about where I'm looking.
But it's a much simpler way of resolving these proprioceptive prediction errors. I can actually just return them to the external world and cause them to contract my muscles until they're reporting exactly what I predicted.
And of course what I've just described is this a classical reflex arc sometimes described in the 1980s and 90s in terms of the equilibrium point hypothesis.
The notion now is that my predictions are now furnishing set points that are reflexively realized in the periphery by using the prediction errors to destroy themselves or the implicit free energy gradients simply by acting upon the external states.
In this instance, the muscles so that I move my eyes so I get a different kind of information. Now notice here this is very much sort of closed loop thing, but it is deeply informed by the predictions that are gathering evidence from all different modalities.
So these predictions are realized in a relatively closed form setting, but the predictions in and of themselves are inherit from some very deep hierarchical sense making if you like under this predictive coding.
So that's the basic story. I just want to end now with a little bit more of a technical nuance on this free energy and just a conceptual proposition that would differentiate between the kind of reflexive behavior that I've just described and the sorts of behavior that you would study in psychology.
Your decision making under the certainty planning to do this versus that.
Just to sort of set the scene. And I've just bought another schematic here that summarizes the generic computational architecture that underwrites this action perception cycle.
So the idea is going to mark off blanket or internal states and external states. We have the sensory sector here providing the inputs that enable the the neural dynamics that are performing gradient flows on the on the variation free energy that look as if they are optimizing beliefs maximizing the
the quality of representations or beliefs about the causes of the six sensory states the external states here to form a expectations about states of affairs out there beyond sensory beyond my mark off blanket.
And then these beliefs are used to generate particular predictions specifically of my motor plant or my propriocept the the the apparatus that I used to act upon the world.
And we can read these in terms of proprioceptive prediction errors that then drive action that changes external states that supply new sensory states.
And so we have our action perception cycle now characterized or described in terms of perceptual inference and the ensuing action selection that is then driven by the predictions of what the motor plant should should be registering or reporting via proprioception.
You can get quite a long way with this with this construct in terms of producing by memetic behavior. This is one of my favorite examples illustrates a few subtle points first of all.
Sometimes the structure that you ascribe to the world actually comes from your own head, even though you think you are trying to just guess the causes of your own sensations under this view or under this description.
So what we've done here is equip a synthetic agent with a generative model in which the agent thinks that there's some autonomous dynamics in this instance a heteroclinic cycle that comes from a lot of Volterra attractor that just circulates with a heteroclinic orbit here.
And the generative model is configured such that the agent thinks that this abstract movement maps to movement in some extra personal Euclidean space and it's pulling an invisible string spring my point is that is connected to her finger.
So she expects to see and feel a finger being pulled around in this itirant orbit.
And of course those expectations now become descending predictions of what she expects to feel and what she expects to see.
But because the reflexes of fulfilling the predictions about what she expects to feel her arm will actually or finger will actually move, thereby generating the visual impressions that she predicted and satisfying those predictions.
And what that looks like from the outside is that the agent is doing a very elemental kind of handwriting generating the sensations that were predicted in both the proprioceptive and the visual domain.
So just to summarize that we have these top down predictions in the proprioceptive domain generating action and what could be called corollary discharge generating visual predictions that are then fulfilled by self authoring the causes of sensations through actually acting and generating what I expected to see.
One nice thing about this is we can actually suppress the proprioceptive prediction errors so there's no information that this agent has available to it that would suggest that she or it is actually moving, which would be a little bit like seeing stuff that's caused by somebody else.
And then by implementing this this adjustment we can now simulate action observation observing somebody else act and compare it to the simulated neural dynamics during action itself.
But from the point of view of the agent very little has changed. She's still got all the machinery to predict this kind of visual input and so can use exactly the same predictive generative model generating the predictions the same neural dynamics to actually explain the visual input.
And indeed if one looks at the activity of the simulated neuronal responses one can reproduce things you find in your barge like place field activity but crucially the same pattern of selective responses are listed during action and the observation of another performing the same action.
So that's that that particular illustration which I repeat is is is not unbiometic rests upon the Markov blanket structure that I described before here detailed in terms of the dependencies.
What I want to do now is just make one very small moon that could have a profound effect on the way that one might describe deliberative behavior.
What I'm going to do is I'm going to remove the influence of the active states on the internal states.
And my motivation for doing this is that if things get bigger and bigger and bigger and bigger at some point the internal states will lose the direct connection from the active states.
And so I'm going to remove that and that has a very interesting consequence.
It means that on the point of view of the internal states, the active states now become a precarious cause of the sensory states, which means that it'll look as if the brain is now encoding the internal states are encoding the active states as if there's a distinction between my physical
realized actions that I can only infer through the sensory consequences of actions.
I just cartoon the fundamental distinction there from the point of view of this Bayesian mechanics or interpretation of internal dynamics in in terms of this self evidencing or Bayesian mechanics of gradient flow on the log model evidence.
I'm drawing a distinction between these the behavior of large particles where the active states are no longer have direct access to the internal states.
And I've drawn that in terms of the, you know, the presumed beliefs of simple things like cells where they don't have to represent their own action.
You know, the action is directly informing and influencing the internal dynamics in contradistinction, things like you and me may well be better described as having beliefs about our own action.
And that's crucial. And I mean, basically it's not propositional beliefs here.
And that's crucial because that takes us into a different world. It takes us into a world of planning and inference where now, because I've got effectively beliefs about what I am doing.
I now have to infer what am I doing. If I'm making an inference, I have to have prior beliefs about what the kinds of things that I do.
And the argument here is what kind of things do I do. Well, I'm a free energy minimizing thing. Therefore, I must, well, I will more likely commit to those actions that minimize the free energy.
I would expect consequent upon that action.
Mathematically, that leads to, this is the other last slide now, a really interesting decomposition of the terms that constitute these, if you like, generalized prediction errors, or the free energy bound on the long evidence.
So forgive the equations, but the reason I put them up is I just want to see what happens to various interpretations of this free energy functional or function of sensory states and active states.
When we move into the future, when we now appeal to the free energy as a way of evaluating the likelihood that I will act in this way or all that way.
So what I've done here is just write out the full expression for the variation free energy.
And I've written it in two different ways. This is the kind of expression that somebody from statistics would be comfortable with. And they would read this as complexity minus accuracy, where the accuracy is just a long probability of some sensory
states, given my belief about their causes, the external states here. The complexity is interesting. It's effectively a divergence, technically a KL divergence, but can be read just as a difference between two kinds of probabilistic beliefs, namely,
what I believe, my beliefs about states of the world, given my exposure and the sensory information, namely my posterior beliefs, after seeing some data under some action, and the prior beliefs.
So it really scores the degree to which I change my mind in receipt of my sensory impressions, its amount of information gain, or the cost I have to pay in order to move my prior beliefs to my posterior beliefs as a result of this updating process driven by these prediction errors.
If you're in machine learning, you'd rearrange these terms, so that you would separate the log evidence that we've been talking about from another KL divergence between my approximate posterior beliefs that come from the free energy and the exact posterior beliefs about external states given the sensory states.
So this, I mean, because this can be never be less than zero, this free energy is often called an evidence bound in machine learning, sometimes with the acronym elbow because he's a negative free energy ELBO and evidence lower bound.
The reason I take you through that is if I now say, well, let's take these quantities and ask, what would they look like in the future before I've actually got any sensations.
So now let's take the probability distribution over the sensations given I'm acting in this way and use them to take the average of these quantities.
And what happens is they, the complexity becomes risk, the accuracy or the inaccuracy becomes ambiguity, and the divergence and the log evidences become intrinsic and extrinsic value respectively.
So what are these quantities? What will they look like? How could one interpret these?
If we just ignore the prior preferences, the attracting states, the log evidence for a moment and assume that I am equally attracted to all states of affairs, what are I left with?
I'm left with something called intrinsic value in robotics. It's also called intrinsic motivation in the visual search literature. It's called Bayesian surprise.
What is it? It's very simple. It's just the degree to which I change my mind about the external states, given my sensory observations under this action in relation to the same beliefs before without seeing the sensory observations.
So this basically scores the information gain or the reduction of uncertainty about the external states. It's, if you like, the imperative for expiration.
It is sometimes known as a scoring the epistemic affordance of acting in this way as opposed to acting in that way, where the epistemic affordance just reflects the amount of information that I will gain if I do this as opposed to that.
From the point of view of information theory, it's just the mutual information between the causes of my sensation and the sensory consequences, the external and sensory states, respectively.
Let me take some uncertainty off the table and see what happens. Let's assume that I can see all the sensory states and therefore the external states become the sensory states and therefore there's no ambiguity.
What am I left with? Well, risk. So what is risk? Well, it's just the difference between what I think will happen if I act like this and what a priori I prefer to happen by attracting external states or indeed sensory states.
So in engineering, this will be known as KL control. In economics, it could be regarded as risk sensitive control where we ignore the ambiguity.
And then finally, if I remove all uncertainty, so there's no reducible uncertainty in this environment, I've become completely familiar with it.
We're just left with the log evidence or the extrinsic value, the expected value, which we started with, which is just scoring the expected log probability of me ending up in my attracting set or sensory subset of those attracting sets.
So the final example is we're just using these equations to simulate another kind of agent that now really thinks about the future and acts in a way, not reflexively to minimize proprioceptive prediction errors, but to minimize the expected fear and the expected prediction
errors in the future by resolving uncertainty. And what we've done here is to simulate a very simple agent whose universe just comes along in three flavors.
All her sensations are caused by an upright face, a sideways face or an inverted face.
The restriction here is that this agent can only see a very small part of the visual field. So it has to choose very carefully where to look and does so in a way that responds to this epistemic affordance, this intrinsic value or expected information
gain and chooses the information rich parts of the image shown here in terms of dynamics and what is actually sampled. And in so doing resolves uncertainty about the three hypotheses that best explain the sequentially sampled
sensorium or visual input, showing a progressive reduction in the uncertainty in terms of the Bayesian confidence intervals and correctly believing now that she is sampling from an upright face.
So that can be much more succinctly expressed, as always by Helmholtz, and indeed he has done that here, each movement we make by which we alter the appearance of objects should be thought of as an experiment designed to test whether we've understood correctly the
relations of the phenomena before us. That is their existence in definite spatial relations. And so with that, it only remains for me to thank those people whose ideas I've been talking about. And of course, thank you for your attention.
Thank you very much indeed.
Thank you, Col. Thank you so much. Wonderful. Thank you. And I think we'll have time for plenty of discussion and questions.
If I just start, please, I can see some questions coming in the chat, but if I just start. So I think we're going to talk some more about the good regulator theorem, so no need for me to cover that off initially.
Let's just maybe explore one point and please don't make the mistake of thinking that maybe all I need here is a repetition of something that you've already said.
Can we decouple the internal states from the active states?
I'm trying to explore the way in which this is reliant on free energy minimization. In other words, this decoupling or disconnection, if I can call it that, of the internal from the active.
In a sense, is it happening because of the principle of free energy minimization, or in a sense, is it required by that principle?
That's a really excellent and deep question, and I did not cover it in this presentation because the answer to that question, if correct, has only become apparent in the past few years prior to much of the preparation of the material and the story that I was telling today.
It has a clear answer. It is not a consequence of the free energy principle. I think, generically speaking, the free energy principle is just a description of things that exist with a careful definition of what you mean by existence,
but also a careful definition of the particular dependencies that underwrite your definition of existence, which is a Markov blanket.
So all the free energy principle says, if you give me a random dynamical system with a particular sparse coupling that permits the existence of a Markov blanket that in turn permits me to identify something as persisting through time,
then the free energy principle can be applied should you want to. And you may ask, well, why would you want to? For fun sometimes, literally, you can have great fun simulating things.
Scientifically, the simulation aspect is very important. Being able to actually write down the dynamics of a system that you think can be explained by this kind of gender model or that kind of gender model is quite useful.
It also has applications as an observation model in phenotyping certain behaviors in psychiatry. But so back to the question. So notice that the dynamics do not inherit from the free energy principle.
The free energy principle is a description of the dynamics of this kind of thing. So the answer now is to your question is, well, what kind of things would, first of all, show gradient flows.
That are precisely these paths of least action. And in particular, the kinds of things where there's a disconnect between a removal of the influence of the active states on the internal states.
The answer to the first question is things that are not subject to lots of random fluctuations. So we're talking about big things.
Things that are certainly bigger than a quantum scale in which the random fluctuations average away. And the bigger they get, the fewer the random fluctuations until you actually get right.
You get to the scale of heavenly bodies, for example, where there are virtually no random fluctuations, those dissipated gradient flows disappear and we're just left with the divergence free cell and idle flow.
The rotation of the heavenly bodies, the earth around the sun, for example.
But on route, as we get bigger and bigger and bigger, there will be a substantial portion and an increasing portion proportion of the internal states that can't see the active states of the of the Markov blanket.
So the supposition here is, if you are big enough, you may be describable as panning, which says that there are small things are unlikely to plan.
So, you know, very, in a very simple, by the way, we wouldn't expect this planning as inference to be a feature or necessarily describe the behavior of a bacterium or a virus.
But you might expect it to apply to amounts and you'd certainly expected to apply to to you and me, just because we are bigger.
So, you know, so the free energy is a method or a description that can be applied to things.
And when applied to big things, then you can certainly then you would be licensed to incorporate this planning as inference into into the description on the application of the method.
Is that the kind of wonderful, very eloquent. Thank you so much.
And I appreciate that. So, Jonathan, shall we have a look at the chat, please.
Yes, sounds good. And what would it would take a couple of questions from chat and then we'll go to you, David.
So, couple of questions chat. So first one's from Clement Vidal. Clement, do you want to read out the question you put in chat or I can do it on your behalf.
Sure, I can do it.
So how many levels of hierarchies of predictions exist in the human brain and do they correspond to the number of brain layers?
I'm smiling because Chris Frith and I make a joke. Yes, there is number. It's six. And then and then somebody asked why six?
I said, well, because we said so. So we say it's a bit of a joke.
But it's also not a joke, really, because again, it comes down to very, very simple arguments about the size of the brain and just appealing in a very coarse grained way to
say renormalization group. What tends to happen as you move from very low level sensory levels in these hierarchical structures, which you can read literally as deep world models or deep
generative models where the deep just is an expression of that you have this hierarchical structure, which I should add depends upon sparsity of connections and Markov blankets.
So you can't define a hierarchy unless other than in terms of which connectors are not there. And that is another instance of a Markov blanket.
So each layer is a blank Markov blanket for for all the in a centripetal kind of hierarchy, all the internal states that are higher than that.
So in these deep architectures, what tends to happen is you get as characteristic of the renormalization group, you get a slowing of the dynamics.
And that and that sort tells you well how many times can you slow down dynamics in a brain that only lasts for, say, 50 to 100 years.
And it's usually about six. So you start off with the cognitive moment, which is about 250 milliseconds. So you keep on increasing it by an order of magnitude, say,
the Napa bound and the number of times you can do that and suddenly we crunch upon the lifetime, the time, you know, the timescale over which this Markov blanket actually exists.
So probably six is a Napa bound, not to be confused with the fact that the.
So what I'm talking about here are levels in a deep world model or generative model that are deployed as you move through increasingly higher levels of your brain.
From V1 to V2, from V2 to V4, it's about here, about here to V5, which would be about here. Yeah, as you get sort of closer to right or frontal regions.
The brain itself can be envisaged like a sort of like a cabbage that's covered with all the, all the, you know, the neuro pill that contains all the nodes that are connected, the gray matter.
Sits like a sort of a layer, which is about three to five millimeters thick on top of this cabbage, where the cabbage itself comprises all the connections of sparse connectivity, called white matter, because they're myelinated with little fatty wire sheets.
That, that, that cortex itself has a layered structure.
So, you, the careful when you ask somebody like me about layers and levels because the levels we're talking about in terms of generating and contextualizing predictions.
So, this notion of a hierarchical generative model that's generating predictions, and you're saying that the deeper levels, click over more slowly in universal or clock time.
You're basically saying that the deeper level to provide a context for fast things at the low level, and the fast things at the lower level, provide a context for even faster things at the level below that.
That notion of a layer is really a level in a hierarchical, in a deep hierarchical architecture.
And that's very distinct from the layers of the cortex. The less the cortex really interesting because when one drills down on the biological implementation of that predictive coding scheme that I illustrated with predictions and prediction error being passed around.
It looks as if the prediction errors live in the top three layers, and the predictions live in the bottom three layers.
And you can actually look at the wiring of the brain and start to try to make sense of the hierarchical message passing that now has a laminar or layer specificity in the context of cortical layers.
So it can be a bit confusing, but it's a fascinating area to get at the competition and has to be applied by the sparse coupling and the predictive coding like interpretations.
Great, thank you.
Go to Chance Mills next and then to you David. So Chance, again, do you want me to read out your question or would you like to read it out yourself?
I think I'm alright with reading it out myself, thanks.
So the American Society for Cybernetics proposes, you know, this move towards ontogenetic resilience in light of the change of environmental factors at an unprecedented pace.
Loss of biodiversity changes, weather patterns, things which kind of anchor our identity and connection to the world.
So my question is this, in light of the free energy principle, what is the adaptive strategy for dealing with such a situation?
A very challenging question would be tempted to answer that on two levels.
First of all, how would you describe adaptation under the free energy principle?
You could also answer it, how would you use the free energy principle to try and ameliorate some of the challenges that are currently facing us in terms of overconnectivity and runaway dynamics and a failure of self-organisation,
which is what would be predicted under the free energy principle.
Perhaps I'll just make that point clear because I think I feel quite passionately about that.
Everything that I have said in terms of being able to describe self-organisation to an attracting set,
which I think is just a description of self-sustaining systems,
that it is a definition of sustainability at the level of, certainly of physics, rests upon the sparsity of coupling.
It rests upon the connections that are not there.
So if you go around globalising and increasing connectivity, you're destroying Markov blankets.
If you destroy Markov blankets, you destroy self-organisation.
Technically, from a dynamical systems perspective, you're inducing oscillated deaths everywhere.
And one could argue that that's what we are potentially confronted with at the moment in terms of overconnectivity
and a destruction of all the sparse coupling that preserves those delicate structures that have self-organised them over millennia, organised themselves over millennia.
So if you wanted to apply the free energy principle to render a particular system, be it an ecosystem, be it a financial market,
be it a meteorological system, if you could intervene on it, to improve its resilience,
what you are looking at is a way of preventing the destruction of sparse connectivity to reclude overconnectivity,
to maintain those boundaries and that segregation in the right kind of way.
Which means, I guess, ideologically, putting more regulation in place.
It means having very clear geopolitical boundaries, Markov blankets in a sustainable way,
finding mechanisms that would preclude breaches of Markov blankets.
If there was an oncologist, these breaches would be basically cancer,
cells growing beyond their natural boundaries because they now become poor regulators or models of their local cellular eco niche.
Or you could look at the wars in Ukraine, for example, as the equivalent kind of failure of a boundary on Markov blanket at a geopolitical level.
So that's how I would apply the free energy. As an academic, how will you describe this?
I think it speaks to something we mentioned before, which is separation of temple scales.
All that I was talking about during the presentation was focusing on one temple scale, which was inferring states of the world, states of affairs out there.
But exactly the same mechanic supplies to the parameters of a geratin model, which as a neurobiologist would be the brain connectivity, for example.
If you're in machine learning, it would be the connection strength or the weights in, say, a transformer model.
And also to the structure of these good models, these geratin models.
By structure, I mean the number of levels in a hierarchical structure, the number of components, the particular spastic structure that endows it with a deep or hierarchical structure.
All of these things have to be optimized in relation to the free energy.
That takes you into the world of evolution in the very simple sense that the free energy in statistics is used to do basic model selection.
But you can also read natural selection as nature's way of doing basic model selection, selecting the right phenotype.
That's a good model of that phenotype's lived world.
So you've got these different different timescales in play.
So I think adaptation of the time, the kinds of timescales that your question intimates would have to, I think, appeal both to parametric learning and structural learning.
Both of which can be expressed as free energy minimizing or evidence maximizing processes in the face of a changing environment.
That in turn speaks to interesting differences between inference and learning, where inference is updating your embodied beliefs about states of affairs, latent states in machine learning talk.
Learning would be basically updating the parameters of your world models and then structure learning or selection will be selecting the right kinds of structures.
Each one nested within the other with a separation of timescales.
For example, I can't make sense of my sensorium unless I've learned the right kinds of contingencies.
And I can't learn the right kinds of contingencies during neurodevelopment unless I've got the right brain structure.
So every one of these scales depends upon all the other ones.
And of course, that also holds in reverse that my brain wouldn't exist unless I had a structure.
And of course, I wouldn't have the wiring in order to do the message passing to do perception.
So all of these different scales depend upon each other.
Is that the kind of answer you were looking for?
Yes, thank you. Thank you very much, Professor.
David will go to you next and after David will go to Trevor Hill there.
Well, thank you very much for elucidating and give me a far better feel for perception information processing and moving towards action.
I don't want to pretend to have understood or digested everything that you've said.
Completely, Professor Princeton, what I'm interested in is how far you see this form of analysis of moving towards kind of dissolving the sensation body problem, the hard problem, the issue of qualia or raw fields.
What is information prior to sensation, is sensation a concept we have no need of or does it emerge out of processing our processing, so to speak.
I just wanted to give you could sort of help me around this area or whether philosophically you regarded it as a non question.
I'm not allowed to regard it as a non question. I have too many philosophy friends, but because I don't do philosophy, it's not a question I can help you with.
But I can point you to the kinds of answers and the literature where people are really focusing on this, but it is a philosophical question.
From my point of view, the question really reduces to what kinds and specifically what structures specifically of the gerontic models would be necessary in order for some artifact natural or otherwise to be sentient in the way that you're implying.
And what most people end up with is a number of different arguments. You can take the agency argument, which I quite like, to be sentient is to be an agent.
So it's me actually gathering my data and possibly experiencing my data or not. But before I can experience it, I have to be me and therefore I have to be an agent.
So immediately you're talking about how would you define agency as a physicist and if you defined agency of a non trivial sort as the kind that inherits from the representing the consequences of my own action.
That tells you a number of things immediately tells you that certain things possibly viruses cannot be sentient in the way that an agent could be.
It also tells you that things that have sentience if they are agents must have a generative model of the future in the sense that in order for me to predict the consequences of my action to plan.
I have to have a generative model of the future in the sense that the consequences are not yet occurred, which means there's a certain temple thickness to these world models that you possibly wouldn't find in a virus or a thermostat, but you might find in me.
So that might be one bright line between the kinds of things that can be sentient and well to have an agentic sentence sentence.
And then you move on to other perspectives.
Some perspectives emphasize as you mentioned the body. So I'm thinking about the work of people like Anil Seth here and Lisa Feldman Barrett.
They, they say that well to have minimal selfhood is just the hypothesis that the best explanation for this myriad of sensations from my eyes and my body, my skin.
The best explanation for it is I am an embodied being and I am me and all of this is the best explanation for what's going on.
So now selfhood itself becomes another becomes another hypothesis, which you have to ask, well, why would you have that hypothesis?
So one advantage of having that hypothesis once you realize I am me is you can now exert mental action over which things you attend to.
There's quite a long story here, but I'm just slipping in the key words that that some people think that it's not any agency that makes you sentient.
It's a particular kind of agency that's on the inside.
It's basically attending to different sectors of your Markov blankets.
That basically allows you to select what information you are going to use to do your updating about myself and my plans.
So there are people usually German philosophers who would focus on mental action as necessary for for that kind of kind of sentence and minimal selfhood.
And then you get into even even more contentious issues about self awareness and having models of me in different states of mind, you know, is the hypothesis that I am a person and I am anxious.
And is that part of my generated model? And what would that look like in terms of James and hanging and sort of formulations of your of emotions and their bodily expressions.
So really fascinating answers a question and lots of fascinating answers, but there are lots of them.
So I think you just have to take your pick from your favorite philosopher.
Yeah. So will turning an artificially intelligent system off ever be morally equivalent to knocking somebody out?
Yeah, if you if you could engineer such such a sense. Yes, I think so.
I mean, that's a little bit.
I don't like knocking people out because that's usually has more sit as a new as a psychiatrist neurologist. This is that you shouldn't really do that if you can avoid it.
But it's certainly like putting something to sleep or anesthetizing them. Yeah, yeah, it would be it would be very much like that.
The argument now is, will you ever get a by memetic intelligence?
You know, in an artifact, I don't see why not provided that artifact is embodied so that, you know, you give it the opportunity to learn, oh, I am embodied and I am a thing.
And I can plan.
And yes, in principle, I would it would be like switching you switching you off when you went to sleep for example.
Yeah.
Thank you.
Thank you, Trevor. Do you want to go next and after treasure? Yeah, thank you.
Thanks so much. Thanks. Thanks, Professor.
I wonder if you could comment on the 1000 brains theory about how the neocortex works.
Yes, I can. Yeah, so Jeff.
I think the venture of the pine palm pilot and for those of you who can remember the palm pilot.
So, yeah, there are lots of similarities but some key differences between the kind of canonical micro circuits that are on offer to, if you like, explain one instance of predictive coding.
The similarities inherit from the sort of a common interest in trying to get above my bone memetic formulation of sense making and action.
So in fact, Jeff Hawkins hosted a meter, it must be 30 years ago now when I was a young man, well, you know, we started talking about these things.
Shortly afterwards he worked with a gentleman called Dyleep George who's still doing quite exciting work.
Together they came up with something called the hierarchical temporal model, the HTM.
And that shares exactly the same fundamental characteristics that we're talking about before in terms of the separation of temporal scales as you move deeper and deeper into generative models.
So there's a shared commitment not just to generative modeling as a constructive view of sense making and action and mnemonics.
But that also extends into the very, very specific architectures that speak to a separation of temporal scales, which was celebrated in Jeff's early work.
The Thousand Brains one does, you know, it's gone off in its own particular direction and I think that the other connection here would be more like a mixture of experts perspective on generative models.
So I think a very plausible notion that you could have a whole bunch of generative models, all competing to explain the lowest level of a sensory hierarchy.
And each one will be fit for purpose for a different context.
And one way that they can, if you like, resolve in further particular context in which they're operating is to compete to see who can explain the sensory input the most.
So in statistics, this is called Bayesian model averaging, where you weight the predictions of each model in proportion to the free energy or the evidence log evidence, sorry, the evidence for each model.
And I think what Jeff has in mind, from my point of view, would be those, you know, there are millions of these little mixtures of experts that are all competing.
So I think it fits very comfortably with the overall free energy principle, probably less comfortably with predictive coding with specific architectures that will be informed by neurobiology.
You know, the Thousand Brains formulation is not quite, doesn't have quite the same commitments as the normal canonical microcircuit formulation of predictive coding.
And the empirical evidence speaks to the canonical microcircuit formulation, just because the canonical microcircuit formulation was designed to account for the empirical evidence, whereas Jeff didn't have to worry about that because he, you know, he's just trying to find the right architectures.
But a lot of shared commitments, some differences, some nuances, and I, I've been to see what it comes up with in the next 10 years.
Great.
Thank you very much.
We'll go to Margaret Heath next, Margaret. I see you've got a couple of questions in there. So you want to cover both of those. That would be brilliant.
Thanks.
Hello. Yes. Thank you, Professor Piston.
Thank you for all your work. It's really, it's, it's yummy.
I have a question that is on two levels, really.
The one is to do you've discussed in other lectures, this notion of temporal death and counterfactual breadth.
And typically theories of the imaginary or the imagination, think of this as, as disconnected from sensory information, or the external, and something that happens internal to the organism.
Curiously, I'm quite interested in Andy's extended mind stuff in the distributed cognition collective cognition where you'd have ensembles of agents doing stuff like this.
So that would change the formulations a little. I was wondering if you could talk to us about those sorts of ideas.
Yeah. I mean, by coincidence, of course, the, the notion of counterfactual breadth.
That is, if you like, another dimension to the temporal depth.
I came from a Neil Seth and Neil Seth has an office next to Andy.
I declare being the author of the extended mind and designer environment.
So I think there's a lot, you know, they clearly have their own views of things, but there's also a lot of synergy between between the two.
So I think there's a very close connection between those perspectives and you can trace the legacy of these ideas. I'm sure you have done, you know, from your historical lightings that have emerged in terms of people like Andy Clark and Neil Seth.
And the like, in terms of the, you know, the, the counterfactual breadth being divorced from the sensorium.
I think that must be right in this because there's no full divorces if you allow for this vicarious sparse connectivity that just is the message passing on the belief updating in a higher architecture we're talking about.
But I think sort of this common sensically, yes, if you are planning what to do, and you're planning in the future, you're planning a rollout, a trajectory, a path into the future.
Clearly, there are no observable outcomes from the future.
So it is purely counterfactual. And as soon as you entertain more than one path into the future, you don't have to. I mean, thermostat doesn't, you know, it just causes one little tiny trajectory into the future.
But if we're now, you know, in the planning as inference kind of active inference or predictive processing, then you're going to have more than one path.
You're going to evaluate that. And of course, the number of paths that you evaluate is exactly the counterfactual depth that Neil was referring to.
And it also introduces interesting semantics which philosophers like, which of course, once you've got more than one path to select from, you induce a problem of selection.
As a mathematician, that's fine. That's based in model selection. I just, I just select the one with the greatest evidence or the least expected free energy.
But of course, if you're a philosopher, you've now got the notion of free will because you've got the act of selecting amongst the counterfactuals, or not free will depending upon if it's prescribed.
Yeah, yeah.
So, yeah, I think, yeah, I think, yes, it has to be imaginal in the sense that it is imagining a future. And you can indeed articulate that on the simulation theory, for example.
And in that sense, it is divorced from the sense from the sensory input, but of course it is underwritten by you by the sensory input because your paths do depend upon where am I at the moment and that is conditioned upon sensemaking.
So, yes.
So, just to then make the link to, if you think about Levin's collective cognition work.
All right, so the mark of blankets and, and then I listened to a really fascinating Chris Fields with you on a philosophy bubble, I think it was, where we spoke about that boundary condition, the information processing on the boundary and then the distinction between two
blankets and how to unpack that, when are they one marker of blankets, and when do you have to compute them as separate entities with separate agency.
Yeah, you're bringing in a whole other fascinating world here, you know, people like Mike Levin Chris Fields.
They would talk about things like distributed cognition and basal cognition and describing the more elemental kind of active influence I was describing as driving them to sort of even molecules or at least macromolecules and cells and asking questions about the emergence of multi cellular
civilizations and the intracellular signaling and would this be described as well it certainly would and could be described as active inference. And of course, once you do that you can use the, the teleology that you get from cognition and
distributed cognition. So I very much encourage that and encourage Chris Fields in his mantra that you're in reality there should be no difference between physics and psychology and biology and philosophy they're all the same thing and we should all be using the same words quite
primarily in an interchangeable way and I would fully subscribe to that. The, just one interesting example of that which I always like to reiterate is, you know, once you understand that you once you allow yourself to with with gay abandon, use cognitive
terms to describe the behavior of cells, either maintaining or destroying their mark of blankets, you can now, as my dozen has done, talk about cancer as a delusion, you know, a false inference.
Think, you know, think in a way which I think is quite an expressive and interesting way to think about your physical phenomena at the cellular or the molecular level, in terms of this kind of
not ascribing intentions to cancer but it's certainly the same kind of collective or situated cognition that societies of people of things like you and me, you might might express.
The two final points here, of course, there isn't just one mark of blanket there are probably not an infinite number but certainly almost uncountable because of all the commentorics.
So any sparsely coupled system, you can draw mark of blankets everywhere.
And of course you can have mark of blankets of mark of blankets. So you really usually have to identify the mark of blanket of interest and that defines you as a psychologist or molecular biologist or sociologist or ethologist or whatever.
You know, that's your scale of mark of blanket and that kind of mark of blanket is what you like to talk about.
So, you know, as we intimated before, just having a deep generative model or a hierarchical generative model means there are multiple mark of blankets in the brain.
And that's because Chris, more recently, as coming back to David's question, is more recently tried to understand what the locus of sentience in terms of consciousness as in terms of an inner screen and the notion of a reducible mark of blankets.
Right in the middle of our brains in the pineal gland that cannot because of its lack of sparsely contain any more mark of blankets within it.
And that has some special characteristics that Chris argues might might, you know, might be associated with consciousness.
You introduce those there in terms of his take on mark of blankets. His take is beautiful and abstract and comes from quantum information theory, where effectively he replaces the mark of blanket with a holographic screen.
And I think that, you know, that's that's what you were you were referring to, which is a wonderful move, sometimes a little bit beyond because I've forgotten all my quantum physics, but it is, it is an interesting move to make to think about the
the relationship between communication and exchange between the internal the external bulk via a holographic screen because the holographic principle tells you all the stuff on the inside, all the information on the inside bulk has to be on the surface on the
blanket on the holographic screen, which basically means that everything I need to know that is no more about you is on your mark of blanket is just how we exchange.
And that means I will never quite know what's going on inside your head and can never know my definition. So that has been interesting consequence I think.
It's just a lot for it. Thank you. Thank you.
Thank you.
We'll go to Harris, you know, fight to next. And then Dave, I see you put a number of comments in Dave so we'll then go to you after after Harris.
So, Harris, you could summarize the question you put in chat that would be great. Thank you.
Great talk and really insightful answers. Thank you. And here is my question.
Scribes in ancient times were tasked with copying text by hand. And it was a rather laborious and time consuming process.
Those scribes aim to minimize the effort, expanded in the copy process, much like physical and biological systems.
The stroke to achieve the most efficient and accurate reproduction of the original text, while minimizing surprise by reducing the likelihood of introducing errors.
The techniques such as using templates employing standardized formats, and even utilizing the money money money money devices to improve efficiency and accuracy.
So Professor Christon, considering the parallels between the least action principle in physics and the free energy principle in cognitive science.
Is it safe to utilize these principles to inform our understanding of human cognitive processes in activities that require this extra meticulous precision and optimization, such as the manuscript copying work of those scribes.
Yes, I think, well, is it safe to apply it? That's a loaded question, a very nice question. I think yes, I think it would be perfectly viable to apply that.
And I think it's very good of you to actually introduce the notion of a principle of least action, because that's just what the free energy principle is.
It's nothing more than a principle of least action. So you can articulate using a path integral formulation, literally, as the understanding both action and perception as evincing or just pursuing paths of least action, which is as you're
intimating paths of maximum efficiency, paths of minimum error, paths of maximum replicability, paths of maximum and sustainable and resilient reliability.
If something was able to persist and exist on its own attractor, in its own preferred states, very, very precisely, you would get exactly the behavior of your scribes.
So I imagine they had a very comfortable and relaxed life with this very, very specific model of what they do, and they did it perfectly.
And in that sense, I think would be an example of something that would easily be described in terms of a path of least action.
And as such, it would be fair to apply the free energy principle to that kind of behavior.
I guess what you'd have to ask, though, is, well, if we are just trying to minimize prediction errors, would your scribes ever become creative?
Would they become poets? Would they start to experiment with different artistic scrolls?
And then one gets into the interesting questions, well, where does that kind of information seeking come from?
And then, of course, the answer from the point of view of the free energy principle, it's only when you get big enough that you now have the opportunity to think about the consequences of your action,
and then that curiosity, that epistemic affordance, that expected information gain starts to come into play.
So, again, you might think that scribes that committed their entire lives just to copying manuscripts were not, probably, got quite bored.
I assume they have quite big brains.
So they probably wanted to automate that and do something that sated their curiosity because you can get a machine to do that because the machine doesn't plan in them.
It doesn't have that epistemic, explorative capacity that a machine does or a calculator would.
And I mean calculator in the original sense of people actually doing calculations at the beginning of the Industrial Revolution.
So a very interesting question. Is that what you meant?
Yes, yes. Thank you so much. Great answer. Thank you.
Thank you. Thank you. After David, we'll then go to Arend van Kampen and then Richard Barry. So David, do you want to go next?
Dave Douglas for me.
Me. Great. Thanks. Okay, welcome Carl.
I've been in many of your presentations at Active Inference Institute.
Now today you've mentioned the richness of the Markov Blanket concept in various contexts.
Now in a paper of yours from a few years ago, I'm sorry I forget the title.
You mentioned that the blanket around an informational regime within a living tissue, particularly neurological tissue, might or might not coincide with cell membranes or tissue boundaries.
Do you have any further thoughts you can share with us about that?
There are some people on this side of the pond who would be very pleased to reflect on your thinking about how one differentiates a psychological process from the people in which that process embeds itself or a meme from the various brain tissues that the
meme embeds itself.
We're updating the work of Professor Gordon Pask, who I think addressed some of these same questions in a very concise or incisive way.
I think simplifies things by simplifies the work to be done by slightly multiplying the number of conceptual tools to be used.
Can you expand upon that last sentence?
I should repeat the gist.
When we talk, there's traditionally, going back to Bergelonfi, there's been a lot of, many, many times people have pointed out that a lower or in your terms a faster level of activity may be controlled or steered or motivated by a higher level or a slower level of control.
So you have this asymmetric mutual influence and control and communication, duality, param.
Now, usually the assumption has been that there's a single way to perform that kind of analysis.
In fact, that it's just a simple, if you have multiple levels that you have two more than two levels to deal with, there is necessarily a strong or weak ordering among levels of control.
Okay, there's the word of God, there's the traditions of men, there's your work as a farmer and there's your physiological needs and there's a strict hierarchy, A controls, B controls, C controls, D.
And that that individuation occurs in one and only one way. It's just controlled. Control is control.
Presupposition is presupposition.
Now, Gordon Pask, working in the 50s, 60s and 70s, along with some, some of our colleagues still around still active in cybernetics, discovered that well in the realm of teaching, of teaching and learning.
It's much simpler to say, no, wait a minute, don't try to conflate all control relations into a single kind. There are after all, psychological processes.
And there are mechanical or physiological processes.
The physiological processes are spatio-temporally distinguished. Machines, you can look at the boundaries, they have a boundary in space, they have origins in time.
But they say, and the psychological processes also have boundedness, but it's not that same kind of boundedness. Where is Beethoven's symphony? I want to know where the exactly the spatiotemporal boundaries of that are.
It's a category error. So Pask just says, look, there's individuation into minds, psychological entities, memes, and there's also individuation into spatiotemporally bounded.
Bounded things, regions.
It is the case that mental entities control and listen to other mental entities. It's the case in, oh, say, the organization of a thunderstorm, perhaps, or, you know, dirty water is a better example, turbulent, dirty water.
There's control of large, the possibilities of small entities by large entities, but the large entities are also dragged around by the small entities. So you have that control.
There's also the case, more importantly, perhaps, that sometimes a mental entity, say a meme, in the classic sense, controls the web browsing activities of a number of individuals. And at that point, the psychologically differentiated individuals acting among themselves control and are influenced by
physical entities. The fact that your electricity went out today knocks out an entire class of mechanical innovation. The computers aren't working.
And I know that in one of your papers explaining the physiology of predictive processing and active inference, you, at the end of one of the sections in about one sentence say it's not clear that the boundaries of the
functional processes always coincide with the boundaries between cells or between tissues. That's the point where my ears stuck out and I said, I remember Gordon Pask telling me about that in 1975.
Here's Carl Friston, please tell us more about that. Is there more than one kind of individuation, either instrumentally in the sense that, oh, I feel like dividing the world up in this way, or I can divide it up that way, or I can divide it up both ways and then see how they fit together.
Or maybe cells and memes and songs and cultures and legal traditions and biological species individuate themselves in various ways.
Dave, I think you posed the question great. Carl, do you want to respond?
Yeah, well, it's a lot to respond to. That was illuminating. I didn't know about that work, but it all sounds very sensible from my point of view and the kind of work that I should know about.
So in brief, the way that you were talking about the separation of temporal scales and the circular causality, I understand that from, say, Herman Haken in terms of the slaving principle and your top-down and bottom-up causation.
I think that view is nicely evinced with the recursive message passing in these deep generative models. It also makes the entire sense that you should be able to apply things like the pre-Henry principle to different kinds of things,
whether they are memes or communication or the products of culture, for example, right down to amoeba and single cells that have spatial temporal boundaries.
Absolutely. The free energy principle is just a principle by which I mean it is a method. It's a tool that you can apply it to. Could you apply it to things with spatial temporal boundaries like a cell? Absolutely.
People do that. Could you apply it to something more abstract, such as the passing of memes on the web, for example? Absolutely. People have done that.
I think that the Markov Blanket there is not really quite so well-defined spatial temporal. It's more, as you would define it, if you're a systems theorist, it would just be input-output relationships.
In terms of systems theory, the Markov Blanket is nothing more than defying the system in terms of its inputs and outputs. You'd have to label the inputs and outputs on your Bluetooth or your Ethernet in a social web.
And that would be the way of defining the Markov Blanket, the sparse connectivity that defines the Markov Blanket. And then it wouldn't quite define Beethoven's symphonies, but it would allow you to then talk about the Markov Blankets of this community
or this social group and the exchange of ideas provided they can be classified or quantified in some form or way as message passing between Markov Blankets and you should be able to apply the free energy principle.
I say it's been done. It's been done in a very mental way by looking at population voting dynamics, by simulating agents, passing messages on the web, but in a very simple way, in proportion or in a way that each agent believes in the veracity of another person's
agent's belief, depending on how similar that agent is to itself. And then you get some really interesting polarization dynamics through this multi-agent active inference that I think you could describe in terms of passing memes.
And the collective commitment to a meme, I think, would start to speak to this more abstract, mindful kind of application that you are intimating.
Thank you. We've only got a few minutes left, so I'd like to squeeze in the last two questions. So, Arend, do you want to go next and then we'll finish off with Richard?
Yes. Thank you, Dr. Friston. Really great to be here and see you live. I watched you on with Lex Friedman a while ago.
My question would be, I worked with Dr. Fritsch of Capra, who I have in a picture I'm going to see here, and he says in 1991, so my question is, would you agree with the observation of Fritsch of Capra that global disorder, social entropy, is caused by a crisis of perception?
I think I will have to go away and think about that. It speaks very much, doesn't it, to the earlier question about, you know, could one use the free energy principle and related formulations to talk about
societal disorder in terms of communication and the way that we perceive others. I think it would be trivial of me to try and give you a clever or informed answer without thinking about this.
It does be one useful thing I think that could be brought to the table here is that the free energy principle is due to James's maximum entropy principle, which of course is, you know, could be cast as what are the constraints on a particular kind of disorder.
But the twist from the point of view of the free energy principle is that the entropy that James was talking about was the entropy of the measurement. It was the observation.
And I think, read as a perception, I think there's a deep connection now between James's maximum entropy principle, which, you know, for him, is how does a physicist perceive by doing her measurements?
And, you know, almost paradoxically saying that the best, the best kind of perception is maximizing the entropy of the measurement representation, which for the free energy principle would be the variance of that Q distribution of the external states that are being measured.
So I think there is some deep connection between perception as measurement and observation and the natural tendency of things to minimize their thermodynamic free energy and maximize their representational entropy.
What that means for the entropy and the disorder of the of the thing and of themselves, I'll have to think about.
Yes, I was just referring to the work of Kenneth Bailey, a social entropy theory, which I've been looking at. And that's why the perception, the observation, the interpretation of reality differs, right?
So that is the, I think, the cause of many, many misinterpretation and many misactions at this time causing this social entropy.
Yes, yeah, we don't have time, but, you know, it would be, it would be really nice to talk about sort of some of the pathologies of perception from the point of view of applying the free energy principle to psychiatric conditions like hallucinations and delusions, sensory attenuation,
and what that would look like in terms of communities talking to each other, making inferences about each other. There's some really fascinating, fascinating issues there.
Thank you.
Thank you, Richard.
Do you want to ask your, do the last question? And if everybody hasn't seen it, there's a question to us all collectively from Paul Pangora, but we won't have time to cover that. So Richard, do you want to go ahead?
Thank you. Thank you, Professor. Fascinating talk. I'll try and use carcimony and minimize my use of free energies.
So we make decisions as a society collectively.
We draw inference from the world and information we are provided, sometimes very inaccurately.
And I'll go back to the Butler inquiry and the decision to go to war on incorrect inference around weapons and mass destruction.
We do it daily in the courtrooms where 12 good citizens will be asked to draw inference from evidence that they perceive has been presented to them and make some some pretty high risk decisions around individuals.
And of course, we get it wrong. And the post office inquiries is a really, really good example of actively getting it wrong. So, so my question really, really straightforward.
Is there a way we can manage what you've described in a more consistent way and draw inference? Sorry, have more confidence in the way we draw inference from the world?
I think the short answer would be you're not going to find a cure, but you can certainly articulate the problem that would reveal strategies to cure.
And I'm using the word cure, presuming that course you don't want to have this extremely unstable and unpleasant situation where you just don't know where to turn for reliable information.
So everybody has lost epistemic trust and everybody else with fake news and the like. And I've also heard the argument just to generalize that in terms of young people nowadays having so much access to different channels of information on social media and elsewhere.
That's an incredible burden on their mental health. And I think that would be useful understood in the same spirit of, you know, you don't know which you and I don't know which news channel to trust if you happen across American news channels.
It's very difficult to know, you know, is this reliable information or not? From the point of view of the free energy principle and applying it to understand what has gone wrong and how it could be remedied.
It's very, very simple that, you know, if you, if the imperatives for a sustainable maintenance of your Mankov blankets and the implicit attracting set rests upon minimizing surprise and the expected surprise that underwrites your
planning is literally uncertainty or entropy. The expected self invasion is the entropy. What that means is we are all in the game of choosing those actions that minimize uncertainty.
And coming back to what we're talking about before about the counterfactual, we have to choose between different actions. And if we have many, many more actions available, then necessarily there's going to be an entropy or uncertainty over what we're going to do.
And that can be crudely and that has been associated with angst. So if I, if I represent that and I have that hypothesis, what state of mind am I in? And I now don't know what to do next.
That is anxiety. And that has direct physiological and neuroendocrine consequences.
So if that is true, what that means is if I've got too many choices, and I cannot trust which, which, what actions to make, I cannot trust the differential reliability of various sources of information because this over connectivity that necessarily
distributes the probability mass over all the things I could do that necessarily increases my anxiety. So you're looking at the, the way that we select sources of information for building our world models and our beliefs as a problem of
activity is selecting the right kind of data places, you know, whether this is just an eye movements, you know, from moment to moment or whether it's actually subscribing to a particular news channel or social group, making that that is an action, and it's an action
that I'm currently in the service of trying to maximize the expected information gain that depends upon the quality on the precision of the information. If that job is made almost impossible, because there are so many people shouting at me as an adolescent.
You can see immediately how one this would lead to a a pernicious and irreducible uncertainty about how to act and select the right, the right sources of information or points of reference or role models that will itself then produce a
self model that is imbued with anxiety and angst and just knowing not knowing what to do next. So that was the kind of pathology I was talking about right at the beginning when I was talking about over connectivity.
If you just, if it's just your teacher and your mother and your father, and your, your priest, depending upon your, your culture, and you in view them with an epistemic trust, then this issue goes away.
But that does require very sparse, much more familial kind of interaction and belief sharing and evidence accumulation. Is that the sort of, yeah, we didn't get as far as talking about juries and the legal systems use of influence. That's itself an interesting issue.
Yeah, absolutely. Thank you. I think it's one to to sort of work through and take forward. So really, really helpful. Thank you.
I think we are done, Jonathan.
We are we are done. Yeah, so thank you, Carl. Brilliant.
We brought the ship in almost a time. Thank you so much. I think Carl, you heard how many people were referencing you from different for around place. So you're certainly leaving an impression. Thank you so much.
Could not ask for more. Thank you and please keep in touch.
Thank you. Wonderful discussions. Thank you so much.
Yes, thank you everyone for the questions and just for listening and participating. Thank you.
Good night. Thank you. Thanks, Carl. Thanks all.
I could go off, but I'm sure the houses are wittling with applause.
Thank you.
Thank you.
Thank you.
