Good morning. Today we're going to talk about information bottleneck techniques and how you
can apply them to test, you know, specific predictions that you make, that you can make
about neural data. I will hope to get through to show you some of our more recent results
from my group. But the goal of today is for this to be more of a lecture than a seminar.
So we'll do some stuff at the board together. And please feel free to interrupt me anytime
if something is not clear. I'd rather that we have a more detailed conversation throughout
than, you know, show you every single last slide. But hopefully we'll get to see some
exciting new stuff. Okay, so enough with the introductions. In case I forget to say it at
the end, this is my group. These are some of the folks in my group. And I'm going to be talking
today particularly about the work of Jared Salisbury, Don Ho, Hannah Torrance, and Heather Yee, who are
all very talented students at the University of Chicago who perform some of the calculations
and measurements that we'll get to towards the end. And this is a list of my collaborators.
And the first grant I ever got when I was a new faculty member was a grant from the
French Chicago Center, which was to have a University of Chicago researchers collaborate
with France. So it was lovely. And I'm very happy to be here. And it facilitated discussions
and work with Olivier Marr at the Vision Institute, which has been very productive.
Okay, so our hero of the day is Claude Shannon. Claude Shannon was born in 1916 in Michigan.
And he spent his career at the University of Michigan at MIT. This is a photo of Claude
Shannon with something that you might not know about him. So most of you will know that he is the
father of information theory. He wrote a beautiful paper called the Mathematical Theory of Communication
that I highly recommend. If you're interested in information theory that you go back to that
source material and read it, it's very easy reading and very, very elegant. Something you
might not know about Dear Claude is that he also was an early inventor of artificial intelligence.
This is actually not, I mean, you might be able to tell from here, this is not a real mouse. This
is a mechanical mouse. And it is called, he called it thesis. And it was his early attempt at machine
learning. So he programmed this mouse to run this maze. And Shannon really was a pioneer in a lot of
different avenues and just, for example, also in artificial intelligence. So why are we talking
about information theory and communications theory? How does this relate to what we'd like to think
about in terms of biology? This is the Shannon Weaver model of communication. And this is what
I'll use to motivate the connection. So here you have a sender and encoder, a noisy channel.
You have a decoder and a receiver. And there is, there might be some feedback from the receiver
back to the sender. And this is the model of communication that Shannon had in mind and let
him write down his source coding and channel coding theorems, which are the foundations of
modern communication theory and influence all sorts of things about how our telephones work,
how our cell phones work and things like that, and how we pass data over large networks.
What does this have to do with biology? Imagine that the sender is the outside world. The encoder
are your early sensory neurons. And then it's being passed through various processing stages in
your brain. So that's a particular example from Vesalius. This is a, you know, if you, I was about
to say if you scooped out your brain and looked at it from the underside. But yes, if you took
out a brain and looked at it from the underside, this is what it would look like. Here are your
eyeballs in your optic tract, crossing the chiasm, making way to your visual thalamus,
and then eventually back to your primary visual cortex. So you have channels of communication
from the outside world to processing areas in your brain. And what you do is you take this
information and you have to make decisions and actions. And so in the sense that neurons in
different brain areas have to communicate with each other and pass signals with high fidelity,
that's the connection we're making with information theory. The eyeballs here have been
viciously chopped off, but they look like this really. So this is a diagram of a human eye.
And at the back of the eye sits your retina. Now your retina is a really exquisite piece of neural
tissue. It's part of your central brain that's conveniently located in your eye. It's not like
your peripheral nervous system, like the touch sensors or temperature sensors in your limbs.
This is really central brain with some sensors on the front end that is sitting out in your eyeball.
So if you take a cut through your retina this way, then you'll see that there is a very
sort of canonical organization of the retina. So light comes in from this side, maybe a little
bit counter-intuitively because the photoreceptors are here at the back of your retina. There is a
lot of guts of the retina that all retinas have these basic pieces. They have horizontal cells,
bipolar cells, and amicron cells. And then they have these cells, the output cells of the retina
that Simone already introduced you to, how these cells fire. So these are the cells that convey
along their axons what the brain sees. And all of these axons bundle together to form your optic
nerve. Eventually this has to punch back through and get out of your eye, and that's why you have
a blind spot, right, where this collection of fibers punches back through your eye. So if you
can understand what's going on in these population of cells, you know what the brain sees. Now,
just from looking at it, I think you can see that this piece of neural tissue is quite complex.
There are many, many different cell types. These are just broad groups, so even within
particular cell types, you have many, many different classes of here, for example, bipolar cells.
So even within this already complex circuitry, there is a lot of functional diversity. So
this is all to motivate and to say that even at the earliest processing stages in your visual
system, in your eye, your retina is potentially doing lots of computation. There's a lot of
machinery there to carry out, to carry out computation. And what we would like to ask is what
is being computed in your eye? What is being sent to the central brain? And how is that message,
which is the external visual world, being transformed and packaged for processing downstream?
Okay, so we're going to, we're going to ask all these questions in the context of information
theory. So let me give you a schematic of how we're going to look at that. Simone already told you
that when we look at responses of spiking neurons in the brain, we often bend time in, in, in,
in short time windows, like 20 milliseconds or something like that. And we just report whether
or not that particular cell fired or not to make it a binary code. So this might be a cartoon of
the responses of, you know, maybe a few dozen cells where cell one fired in this time window,
cell two did not, cell three fired and so on. And what we'd like to understand, if this is a
schematic of some visual signal that's coming in, some stimulus from the past, and this is what the
retina responded now, we'd like to understand how this, how this information from the past was,
was represented in the firing of the retina. Now the light signals that are impinging on the retina,
and let's just be clear, we're talking about the retina here, the light signals that are impinging
on the photoreceptor layer of the retina are very, very high dimensional. And we know that the retina
does some amount of compression. So it takes this signal in, this is the vertical signal from the
photons that are impinging on, on, on the retina. And it, and it throws some information away.
So it does some amount of compression. And we could think about the signal that's being sent
down the optic nerve, simply as a compression problem. What we're going to develop and set up
today is a way of thinking, not just compressing for compression sake, so not just summarizing
in as lossless a manner as possible so that you can convey to the brain exactly what was
happening in the, in the visual field, but to ask some question here, this big question mark,
about relevance. If I now interrogate this code that I have here, have I kept the bits of information
that are most relevant for say behavior? Okay, so this is the stimulus that we're trying to encode.
We're going to do some compression here in the retina. And we want to understand, can we do that
compression with the constraint that we keep information that, that we hypothesize is relevant
to the animal? Okay, so we're going to make the bold assumption that the information that is relevant
to the animal is the stimulus information in the future. So we're asking a question about prediction.
We are making the hypothesis that prediction is a very, very important part of neural computation.
So important that it starts already at the earliest processing stages, that it already starts in the
retina, that when the brain makes a decision about what information to keep and what to throw away,
it's keeping the information preferentially that's relevant for prediction. Okay, so what we're going
to develop is a way mathematically of asking this question of neural data and then we're going to
test it and see how it works. So we'll spend some time at the board looking through how we set that
up and I'll try to, you know, start slowly and then accelerate so people who are familiar with
information theory won't get bored, people who haven't seen it before, you'll get some pointers
to start. But our drive is to be able to test whether or not this is, this hypothesis is true
in real neural data. So why have I made this choice? Why have I said the information from
about the stimulus that's relevant is the stuff that lets me predict what will happen next. The
reason is that when you're interacting in your world, if you're any organism, there are significant
sensory and motor delays and those sensory delays mean that's what's happening now inside your brain
actually lags significantly behind the state of the extrinsic variables in your outside world.
But none of us have the experience or the sort of cognitive feeling that we're in a laggy system.
We feel like we're interacting fluidly and smoothly with our outside world and that's
because our brains actually compensate for these processing delays. So as an example,
let's take a look at Serena Williams, my favorite tennis player. So this is her at the Rogers Cup
in 2013. And to return, so let's talk about some of these processing delays. If we assume that Serena
has in her retina even a modest 50 millisecond lag in processing, which is about the right
order of magnitude for lags in the retina. So if you flash a light on the photoreceptor layer,
how long does it take for a spike to be reported in that output optic nerve trap? It's about 50
milliseconds. So even with a modest, you know, short 50 millisecond delay, you'd say, well,
that's a tiny fraction of a second. What does it matter? But if this ball is traveling just 60
miles per hour, which is some number of kilometers per hour, that translates, that 50 millisecond
delay translates into a distance of 4.4 feet, which is some more than a meter. So that's quite
large. And if you actually, and I can return maybe a ball that's traveling at that speed,
it's not just expert professional tennis players that can do this. We can all interact fluidly
with our world. So if you look at where Serena is looking, and actually this is interesting,
if you look at professional cricket players, professional baseball players, professional tennis
players, she's looking not at where the ball was if she hadn't compensated for this lag. She's
actually not even looking at where the ball is. She's actually looking at where the ball will be.
And that is a combination of processing delay, compensation in the rema, and also her overtraining
to have priors about her sensory world, her particular sensory world, which has been
massively, massively morphed into this world where tennis is all that matters. Okay, good.
So that motivates why we decided to put our flag down in prediction. Here again is some basic
anatomy. If we take now a slice through the retina in this direction, okay, so we flatten,
so this is how you would do an experiment if you were going to record from the retina. You'd
take the eye out of the animal, you'd dissect the retina out of the eye, and you'd squish it down
on a glass slide, say, and maybe you'd see all these cell bodies. These happen to be from
Vasila's lovely review. These are mouse retina for the people in the audience who know about the
retina. These are on alpha cells. And if we look at one particular cell here, then it has a receptive
field. It has a part of the visual space that it responds to. And here I've colored it dark because
it responds to light offsets. All right, so this is the response field of that particular cell,
and now we're going to ask, you know, does the retina do anything interesting with respect
prediction? So I just want to give you a brief introduction to how we think about retinal
processing to motivate this computation happening in the retina. That's where we're at. All right,
so that's the receptive field of the cell. It responds to light offsets in its center,
and it has a larger surround field as well. So if we just take that, and now something we often do
in a neuroscience experiment is that you'll flash a brief stimulus. So could you guys all see the
bar that flashed up there? That was actually played for 20 milliseconds, if my computer behaved
itself. And that is what you do when you interrogate, you know, sort of flash responses. You want to
measure the lag, the processing lag in the retina. And if you do this in the salamander, these are
data from, as Simone also mentioned, Marcus Meister, who innovated this technique from recording the
retina. Michael Berry, who was one of my postdoc collaborators at Princeton. If you look at the
firing rate in that neuron as a function of time relative to that flash, so before the flash happens,
there's no response in the neuron. And then somewhere between 0 and 100 milliseconds after
the flash, you see this big peak in response. You see lots of spikes from that cell. Okay, so this is
the lag, this is exactly the lag that we're trying to compensate for. So if we go back to our picture
of the flattened out retina, and we flash the bar across many cells, then that's just where the bar
was for reference. So say the center of the receptive fields of many cells are over here, like here,
here, here, here, here. And say we're able to record from several cells in this area where we
flash the bar. And now we ask, as a function of time since the flash, not each cell is a function
of time, but at one particular time, which cells were firing. So I look down here in space, and I
ask which cells were firing. And of course, the cells that are mostly firing are going to be under
the bar. The ones farther from the bar whose receptive fields don't overlap with the bar are
not going to respond. So we can plot that like this. So this is position in microns on the retina,
and each line is a different time delay relative to the flash. So from 44 to 62 milliseconds
relative to the flash, you see you get a buildup of a response around the position where the bar
was flashed. And it peaks about 62 milliseconds, and that's the delay in these cells. Okay, so you
get this kind of neural image of the bar. It was around zero, and the edges aren't so sharp
because you're filtering it through with these receptive fields. Something interesting happens,
if instead of flashing the bar, you sweep it across. So everybody saw the bar sweep across.
And now we ask about the firing in this cell relative to the time when the bar would have
reached the position it was when it flashed. Okay, so zero is the time when I run this bar
across, when it reaches the position where I flashed it. And now what you see is that you
have a lot of activity before the bar reaches that point, and you have activity after the bar
crosses the receptive field. And this activity is what's interesting. As you sweep a bar into the
receptive field of the cell, you actually get a lot of response before the bar even gets there.
So if we do that again with the whole population, and I freeze the bar at the point in space where
it would have been flashed, and now I look at these cells again, again, I'm looking at the neural
image down in space here in microns on the retina of where that bar was. Here in red is what we got
when we flashed the bar, and here in blue is what we get when we sweep the bar across from left
to right. And what you can see is that basically what we've done is we've shifted the neural image
over towards the leading edge of the bar motion. So at this same point in time, 62 milliseconds,
relative to the flash or relative to when the bar reached this position here, we've actually got a
build-up of activity anticipating where the bar will be. And this is called the motion
anticipation result, and that's what's highlighted in this paper from Barry and Meister over now 17 years
ago. Okay, and it turns out that this is an important thing that might underlie predictions,
say, in the retina. This is a sculpting of activity that sort of gets pushed in front of the leading
edge of moving objects. And it doesn't work if you just consider the retina to be some collection
of linear filters without putting on linearities. I'm not going to go through the details of this
slide. This is just a point out for the people who have studied neuroscience that you actually
have to add some gain control to the system. So if I think of the retina as just a space-time filter
with some output non-linearity, so these are, this is the stimulus, this is a space filter,
this is that center surround, so there's a hump of positive response and an inhibitory
surround and some time filter that has some width that, say, peaks at the delay. If I just send
everything through these linear filters and then give them some rectifying non-linearity,
I will not get this motion anticipation. I have to add some feedback gain control
non-linearity to this system. Okay, so the retina is doing something interesting. It's
something that we can't predict just from its static response properties and it does some other
neat things. So if I put a bar across the retina like this and again ask what happens at the point
where it would have been where we flashed it or actually the point where the bar reversed
and I look at a single cells response or actually let's look at many cells response. Okay, so some
cells at the time when the bar reverses have not yet seen the full bar. Some cells it's on their
