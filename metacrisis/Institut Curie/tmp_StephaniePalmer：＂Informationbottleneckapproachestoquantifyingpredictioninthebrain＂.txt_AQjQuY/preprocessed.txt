Good morning. Today we're going to talk about information bottleneck techniques and how you
can apply them to test, you know, specific predictions that you make, that you can make
about neural data. I will hope to get through to show you some of our more recent results
from my group. But the goal of today is for this to be more of a lecture than a seminar.
So we'll do some stuff at the board together. And please feel free to interrupt me anytime
if something is not clear. I'd rather that we have a more detailed conversation throughout
than, you know, show you every single last slide. But hopefully we'll get to see some
exciting new stuff. Okay, so enough with the introductions. In case I forget to say it at
the end, this is my group. These are some of the folks in my group. And I'm going to be talking
today particularly about the work of Jared Salisbury, Don Ho, Hannah Torrance, and Heather Yee, who are
all very talented students at the University of Chicago who perform some of the calculations
and measurements that we'll get to towards the end. And this is a list of my collaborators.
And the first grant I ever got when I was a new faculty member was a grant from the
French Chicago Center, which was to have a University of Chicago researchers collaborate
with France. So it was lovely. And I'm very happy to be here. And it facilitated discussions
and work with Olivier Marr at the Vision Institute, which has been very productive.
Okay, so our hero of the day is Claude Shannon. Claude Shannon was born in 1916 in Michigan.
And he spent his career at the University of Michigan at MIT. This is a photo of Claude
Shannon with something that you might not know about him. So most of you will know that he is the
father of information theory. He wrote a beautiful paper called the Mathematical Theory of Communication
that I highly recommend. If you're interested in information theory that you go back to that
source material and read it, it's very easy reading and very, very elegant. Something you
might not know about Dear Claude is that he also was an early inventor of artificial intelligence.
This is actually not, I mean, you might be able to tell from here, this is not a real mouse. This
is a mechanical mouse. And it is called, he called it thesis. And it was his early attempt at machine
learning. So he programmed this mouse to run this maze. And Shannon really was a pioneer in a lot of
different avenues and just, for example, also in artificial intelligence. So why are we talking
about information theory and communications theory? How does this relate to what we'd like to think
about in terms of biology? This is the Shannon Weaver model of communication. And this is what
I'll use to motivate the connection. So here you have a sender and encoder, a noisy channel.
You have a decoder and a receiver. And there is, there might be some feedback from the receiver
back to the sender. And this is the model of communication that Shannon had in mind and let
him write down his source coding and channel coding theorems, which are the foundations of
modern communication theory and influence all sorts of things about how our telephones work,
how our cell phones work and things like that, and how we pass data over large networks.
What does this have to do with biology? Imagine that the sender is the outside world. The encoder
are your early sensory neurons. And then it's being passed through various processing stages in
your brain. So that's a particular example from Vesalius. This is a, you know, if you, I was about
to say if you scooped out your brain and looked at it from the underside. But yes, if you took
out a brain and looked at it from the underside, this is what it would look like. Here are your
eyeballs in your optic tract, crossing the chiasm, making way to your visual thalamus,
and then eventually back to your primary visual cortex. So you have channels of communication
from the outside world to processing areas in your brain. And what you do is you take this
information and you have to make decisions and actions. And so in the sense that neurons in
different brain areas have to communicate with each other and pass signals with high fidelity,
that's the connection we're making with information theory. The eyeballs here have been
viciously chopped off, but they look like this really. So this is a diagram of a human eye.
And at the back of the eye sits your retina. Now your retina is a really exquisite piece of neural
tissue. It's part of your central brain that's conveniently located in your eye. It's not like
your peripheral nervous system, like the touch sensors or temperature sensors in your limbs.
This is really central brain with some sensors on the front end that is sitting out in your eyeball.
So if you take a cut through your retina this way, then you'll see that there is a very
sort of canonical organization of the retina. So light comes in from this side, maybe a little
bit counter-intuitively because the photoreceptors are here at the back of your retina. There is a
lot of guts of the retina that all retinas have these basic pieces. They have horizontal cells,
bipolar cells, and amicron cells. And then they have these cells, the output cells of the retina
that Simone already introduced you to, how these cells fire. So these are the cells that convey
along their axons what the brain sees. And all of these axons bundle together to form your optic
nerve. Eventually this has to punch back through and get out of your eye, and that's why you have
a blind spot, right, where this collection of fibers punches back through your eye. So if you
can understand what's going on in these population of cells, you know what the brain sees. Now,
just from looking at it, I think you can see that this piece of neural tissue is quite complex.
There are many, many different cell types. These are just broad groups, so even within
particular cell types, you have many, many different classes of here, for example, bipolar cells.
So even within this already complex circuitry, there is a lot of functional diversity. So
this is all to motivate and to say that even at the earliest processing stages in your visual
system, in your eye, your retina is potentially doing lots of computation. There's a lot of
machinery there to carry out, to carry out computation. And what we would like to ask is what
is being computed in your eye? What is being sent to the central brain? And how is that message,
which is the external visual world, being transformed and packaged for processing downstream?
Okay, so we're going to, we're going to ask all these questions in the context of information
theory. So let me give you a schematic of how we're going to look at that. Simone already told you
that when we look at responses of spiking neurons in the brain, we often bend time in, in, in,
in short time windows, like 20 milliseconds or something like that. And we just report whether
or not that particular cell fired or not to make it a binary code. So this might be a cartoon of
the responses of, you know, maybe a few dozen cells where cell one fired in this time window,
cell two did not, cell three fired and so on. And what we'd like to understand, if this is a
schematic of some visual signal that's coming in, some stimulus from the past, and this is what the
retina responded now, we'd like to understand how this, how this information from the past was,
was represented in the firing of the retina. Now the light signals that are impinging on the retina,
and let's just be clear, we're talking about the retina here, the light signals that are impinging
on the photoreceptor layer of the retina are very, very high dimensional. And we know that the retina
does some amount of compression. So it takes this signal in, this is the vertical signal from the
photons that are impinging on, on, on the retina. And it, and it throws some information away.
So it does some amount of compression. And we could think about the signal that's being sent
down the optic nerve, simply as a compression problem. What we're going to develop and set up
today is a way of thinking, not just compressing for compression sake, so not just summarizing
in as lossless a manner as possible so that you can convey to the brain exactly what was
happening in the, in the visual field, but to ask some question here, this big question mark,
about relevance. If I now interrogate this code that I have here, have I kept the bits of information
that are most relevant for say behavior? Okay, so this is the stimulus that we're trying to encode.
We're going to do some compression here in the retina. And we want to understand, can we do that
compression with the constraint that we keep information that, that we hypothesize is relevant
to the animal? Okay, so we're going to make the bold assumption that the information that is relevant
to the animal is the stimulus information in the future. So we're asking a question about prediction.
We are making the hypothesis that prediction is a very, very important part of neural computation.
So important that it starts already at the earliest processing stages, that it already starts in the
retina, that when the brain makes a decision about what information to keep and what to throw away,
it's keeping the information preferentially that's relevant for prediction. Okay, so what we're going
to develop is a way mathematically of asking this question of neural data and then we're going to
test it and see how it works. So we'll spend some time at the board looking through how we set that
up and I'll try to, you know, start slowly and then accelerate so people who are familiar with
information theory won't get bored, people who haven't seen it before, you'll get some pointers
to start. But our drive is to be able to test whether or not this is, this hypothesis is true
in real neural data. So why have I made this choice? Why have I said the information from
about the stimulus that's relevant is the stuff that lets me predict what will happen next. The
reason is that when you're interacting in your world, if you're any organism, there are significant
sensory and motor delays and those sensory delays mean that's what's happening now inside your brain
actually lags significantly behind the state of the extrinsic variables in your outside world.
But none of us have the experience or the sort of cognitive feeling that we're in a laggy system.
We feel like we're interacting fluidly and smoothly with our outside world and that's
because our brains actually compensate for these processing delays. So as an example,
let's take a look at Serena Williams, my favorite tennis player. So this is her at the Rogers Cup
in 2013. And to return, so let's talk about some of these processing delays. If we assume that Serena
has in her retina even a modest 50 millisecond lag in processing, which is about the right
order of magnitude for lags in the retina. So if you flash a light on the photoreceptor layer,
how long does it take for a spike to be reported in that output optic nerve trap? It's about 50
milliseconds. So even with a modest, you know, short 50 millisecond delay, you'd say, well,
that's a tiny fraction of a second. What does it matter? But if this ball is traveling just 60
miles per hour, which is some number of kilometers per hour, that translates, that 50 millisecond
delay translates into a distance of 4.4 feet, which is some more than a meter. So that's quite
large. And if you actually, and I can return maybe a ball that's traveling at that speed,
it's not just expert professional tennis players that can do this. We can all interact fluidly
with our world. So if you look at where Serena is looking, and actually this is interesting,
if you look at professional cricket players, professional baseball players, professional tennis
players, she's looking not at where the ball was if she hadn't compensated for this lag. She's
actually not even looking at where the ball is. She's actually looking at where the ball will be.
And that is a combination of processing delay, compensation in the rema, and also her overtraining
to have priors about her sensory world, her particular sensory world, which has been
massively, massively morphed into this world where tennis is all that matters. Okay, good.
So that motivates why we decided to put our flag down in prediction. Here again is some basic
anatomy. If we take now a slice through the retina in this direction, okay, so we flatten,
so this is how you would do an experiment if you were going to record from the retina. You'd
take the eye out of the animal, you'd dissect the retina out of the eye, and you'd squish it down
on a glass slide, say, and maybe you'd see all these cell bodies. These happen to be from
Vasila's lovely review. These are mouse retina for the people in the audience who know about the
retina. These are on alpha cells. And if we look at one particular cell here, then it has a receptive
field. It has a part of the visual space that it responds to. And here I've colored it dark because
it responds to light offsets. All right, so this is the response field of that particular cell,
and now we're going to ask, you know, does the retina do anything interesting with respect
prediction? So I just want to give you a brief introduction to how we think about retinal
processing to motivate this computation happening in the retina. That's where we're at. All right,
so that's the receptive field of the cell. It responds to light offsets in its center,
and it has a larger surround field as well. So if we just take that, and now something we often do
in a neuroscience experiment is that you'll flash a brief stimulus. So could you guys all see the
bar that flashed up there? That was actually played for 20 milliseconds, if my computer behaved
itself. And that is what you do when you interrogate, you know, sort of flash responses. You want to
measure the lag, the processing lag in the retina. And if you do this in the salamander, these are
data from, as Simone also mentioned, Marcus Meister, who innovated this technique from recording the
retina. Michael Berry, who was one of my postdoc collaborators at Princeton. If you look at the
firing rate in that neuron as a function of time relative to that flash, so before the flash happens,
there's no response in the neuron. And then somewhere between 0 and 100 milliseconds after
the flash, you see this big peak in response. You see lots of spikes from that cell. Okay, so this is
the lag, this is exactly the lag that we're trying to compensate for. So if we go back to our picture
of the flattened out retina, and we flash the bar across many cells, then that's just where the bar
was for reference. So say the center of the receptive fields of many cells are over here, like here,
here, here, here, here. And say we're able to record from several cells in this area where we
flash the bar. And now we ask, as a function of time since the flash, not each cell is a function
of time, but at one particular time, which cells were firing. So I look down here in space, and I
ask which cells were firing. And of course, the cells that are mostly firing are going to be under
the bar. The ones farther from the bar whose receptive fields don't overlap with the bar are
not going to respond. So we can plot that like this. So this is position in microns on the retina,
and each line is a different time delay relative to the flash. So from 44 to 62 milliseconds
relative to the flash, you see you get a buildup of a response around the position where the bar
was flashed. And it peaks about 62 milliseconds, and that's the delay in these cells. Okay, so you
get this kind of neural image of the bar. It was around zero, and the edges aren't so sharp
because you're filtering it through with these receptive fields. Something interesting happens,
if instead of flashing the bar, you sweep it across. So everybody saw the bar sweep across.
And now we ask about the firing in this cell relative to the time when the bar would have
reached the position it was when it flashed. Okay, so zero is the time when I run this bar
across, when it reaches the position where I flashed it. And now what you see is that you
have a lot of activity before the bar reaches that point, and you have activity after the bar
crosses the receptive field. And this activity is what's interesting. As you sweep a bar into the
receptive field of the cell, you actually get a lot of response before the bar even gets there.
So if we do that again with the whole population, and I freeze the bar at the point in space where
it would have been flashed, and now I look at these cells again, again, I'm looking at the neural
image down in space here in microns on the retina of where that bar was. Here in red is what we got
when we flashed the bar, and here in blue is what we get when we sweep the bar across from left
to right. And what you can see is that basically what we've done is we've shifted the neural image
over towards the leading edge of the bar motion. So at this same point in time, 62 milliseconds,
relative to the flash or relative to when the bar reached this position here, we've actually got a
build-up of activity anticipating where the bar will be. And this is called the motion
anticipation result, and that's what's highlighted in this paper from Barry and Meister over now 17 years
ago. Okay, and it turns out that this is an important thing that might underlie predictions,
say, in the retina. This is a sculpting of activity that sort of gets pushed in front of the leading
edge of moving objects. And it doesn't work if you just consider the retina to be some collection
of linear filters without putting on linearities. I'm not going to go through the details of this
slide. This is just a point out for the people who have studied neuroscience that you actually
have to add some gain control to the system. So if I think of the retina as just a space-time filter
with some output non-linearity, so these are, this is the stimulus, this is a space filter,
this is that center surround, so there's a hump of positive response and an inhibitory
surround and some time filter that has some width that, say, peaks at the delay. If I just send
everything through these linear filters and then give them some rectifying non-linearity,
I will not get this motion anticipation. I have to add some feedback gain control
non-linearity to this system. Okay, so the retina is doing something interesting. It's
something that we can't predict just from its static response properties and it does some other
neat things. So if I put a bar across the retina like this and again ask what happens at the point
where it would have been where we flashed it or actually the point where the bar reversed
and I look at a single cells response or actually let's look at many cells response. Okay, so some
cells at the time when the bar reverses have not yet seen the full bar. Some cells it's on their
receptive field and some cells it passed them and if we do that again, so if we ask what does the
response of the retina look like at that time, we see something really interesting. So these are
again spike rasters each point is a place where this cell fired and there's many many trials so
there's many lines there and relative to the time of reversal there's a big synchronous firing of
activity across the retina and remember those cells had different receptive fields so when the bar
swept across they fired at different times in response to that bar sweeping but they all fired
at the same time relative to the reversal and that again is a highly nonlinear property these are
data from Greg Schwartz when he was a graduate student Michael Barry's lab these are this is a
highly nonfeature of retinal processing and signaling a reversal is also important you
could think of that as being important for prediction if you have some model of where
things are going to objects are going to be in the world you might want to update that if if the
plan changes things change course okay the receptive field again is the is the point in
space where the neurons are responsive to stimulus by light so you can think of it as the cell's
spatial filter on the visual world okay good so again we want to bring this back to our discussion
today which is about information theory and we're going to ask about prediction in the visual system
so what we'd like to know again is if the we take the stimulus in the past and it gets compressed
into a representation by a population of cells in the retina we want to ask is that compression
organized such that we have as as much we know as much as we could about the future stimulus yes
I want to ask about this reversal sure
you
okay this is a good question so let me unpack that just a little bit so
the the time of the reversal response is longer than the flash delay the flash lag
of of the of the cells so you can see this is about at 200 milliseconds and before we had our
flash lag somewhere in here around 60 milliseconds so it's not it's it's what's interesting is that
these cells are all at different positions and would have different you know the flash lag if
you know if we flashed the bar at different points for them this you know for for example
if we considered the point of the lag where each cell where the where the bar across the center
of the part of the visual field that each cell cares about we would have responses that would be
you know sort of variable like this but here once we reverse everybody fires together so
um how predictive is it is a good question right um what's interesting is that it's uh
is that it's coordinated and it signals something that would let you then do a prediction about
where the bar would be later but the reversal the reversal is it's not a it's not a prediction
of the reversal it's response to the reversal so okay an important thing to remember in all
of this is that we're not hypothesizing that the brain can do fortune telling that the brain
is anticipating things that um are you know unlikely that that are not predictable we're
talking about the things that are predictable so if a if a bar reverses what is predictable
it's predictable that now it won't be going if it's if it's going this way and then it reverses
what's predictable is that it won't be going over there and it'll probably go okay all right so
coming back to our uh our goal of the day uh so what we'd like to do is we'd like to formulate this
compression problem with the idea uh you know more we'd like to develop this a little bit
more formally and put in the idea that we want to retain as much information about the future as
possible so we're going to set up this optimization problem here i've written down this Lagrangian
so we're asking to minimize this quantity so i'm going to unpack what this inframutal information
between the stimulus in the past and this binary word in the retina time t is so we want to we want
to throw away information about the past stimulus but we want to keep um some fixed amount that's
parameterized by beta of information about the future stimulus so that's the tradeoff that we're
going to try to try to look at at this point is that question i mean the idea that you know
what is useful for future prediction no so that's the so this is just this is just hand this is
just conceptual at the moment if we're sitting in the natural world where the stimulus is very very
high dimensional it's a thorny question to ask what what is relevant out of you know what particular
low dimensional representation of that space is relevant so what we're going to do is we're going
to design a stimulus which thank you for is is low dimensional where we can describe everything
that's predictable and everything that's not predictable about it and we actually um will
also use the fact that we can uh describe fully uh analytically the answer to this bound problem
okay so right so here we go again we're going to show a moving bar to the retina like the ones that
i showed you so far but it's going to have some more complex motion yeah in the back
about not having a lot of information about uh why compress uh i see so i mean compress in general
but then maybe it doesn't necessarily mean i need to forward maybe i have some limit on how much
how much i can encode but i don't see right so you have so so remember that the response in the
retina is causal so it's caused it's it's caused by the stimulus that happened in the past and all
i'm saying is that um when you think about compression you're explicitly thinking about
compression of the past stimulus so yes you we're going to we're going to sweep out many such uh
different amounts of so you can think about this in either way you either say you can and it's
completely equivalent either you say i have a fixed amount of information about the future
and i want to know what's the what's the what's the code that that compresses as much as i can
so that i can be as efficient as possible i can use as few spikes because maybe you have a hypothesis
that spikes uh cost you atp it's a metabolic cost to spiking um and it'd be better if i could use
fewer spikes or fewer neurons something like that to do it you can think about it the other way you
can you can think i have some fixed amount of compression that i can do in the retina that i
that i that i do and i want to retain as much information about the future as possible these
are completely equivalent beta parameterizes the trade-off and we'll sweep and there isn't just one
solution there's a whole the family of solutions that we'll talk about okay so let me just do this
one more time so here's a stimulus that's jiggling around and moving and at this point in time it's
made some excursion to the right so now the retina needs we're going to ask the retina how well it
can predict what the stimulus does next and what the stimulus does is reverses and comes back okay
so now we are ready we're ready to go to the chalkboard let's get warmed up a little bit
before um we derive anything that requires too much algebra so let's do a basic refresher of uh
some probability theory so these are just some relationships between probability distributions
so if i have a joint distribution of two variables a and b uh then their joint distribution can be
written down as a product of a of a conditional distribution and um a prior distribution or
a marginal distribution um if i have a joint distribution and i sum over all one variable if
i sort of integrate out that one variable i get my probability of just the the other and um and
there's something called Bayes rule some people call call this Bayes theorem this is this is this
hardly even deserves somebody's name right this is just this is just an identity this is just a
mathematical fact so so i always try to tell my students don't call it Bayes rule just call it
Bayes thing um and and actually you know just remember it because it's useful so it lets you
it's the this joint distribution is symmetric the joint distribution of a and b is the joint
distribution of b and a so we can rewrite this uh conditional distribution of a condition on b is
b conditioned on a and we just have to we just have to multiply uh by these marginals okay all
right so now we are going to take a chalkboard interlude and uh write down a few things so
i told you that we wanted to compute uh mutual information so the mutual information between
two variables x and y and i'm going to try to keep my capitals and lowercase letters consistent
they weren't so great on that slide but i'll try to try to do a little better here at the
board um the mutual information between two variables x and y mutual information is kind
of a generalized form of of correlation it talks about the dependence statistical dependence of
two variables on each other and uh a way conceptually to think about it is that the mutual information
between two variables x and y is the uncertainty that you have about x which i'm writing down
with h some people call this s uh for entropy uh i'm going to call s the stimulus so we're
going to call the entropy h here today so it's the uncertainty i have about my variable x minus
the uncertainty i have left over once i specify y okay so information you can think of as a
reduction in uncertainty and it's symmetric the mutual information between x and y is the mutual
information between y and x these are the same thing uncertainty about y minus the residual
uncertainty i have after i specify x okay and these things are equal now i've written down
entropy as a measurement of uncertainty and if you go back and you look at claud shannon's original
paper you will see a nice uh mathematical justification for using using entropy as your
measurement of uncertainty it has a lot of nice properties and it looks something like this so
the entropy on some distribution of x is minus the sum on all of the states xi i'm going to drop
probably these little labels here i's but just ask me if anything becomes unclear of p log p so
p is the probability that we're that we observe some particular discretized value of x and the
entropy is just minus p log p and um you know you might be tempted to to think about you know
deep analogies to thermodynamics here this is just sort of an equation analogy um if you
want to think about energetic costs of computation and land ours principle and things like that then
this becomes more concrete and and how it relates to the thermodynamic entropy but here it's just
sort of the form of the equation is similar okay so that's our that's our formula for the entropy
and i've put it inside this box because it's important enough that i don't want to erase it
so let's write down let's write down this mutual information between two quantities
just so we get used to manipulating these kinds of equations okay very good okay so the mutual
information between x and y are there any questions so far good so this is a review for
for many of you have any has anybody never seen mutual information before a few of you okay so
let's let's go ahead and write this out so let's just write this out in gory detail
we're going to write the the entropy of x minus the entropy of of p of x given y so if we write
down the entropy of x some of all the states x and c are to your drop the i so you know forgive me
okay so that's that first term and then we have the second part so we know we have to
we know we have to sum over the states of p of x given y log p of x given y
all right so i took a minus a minus there so we need to sum over x here now we do need to average
this quantity so that's for some particular y and then we average this over p of y
okay so if we write this out this is just being excruciatingly specific
holler if you want me to accelerate
okay there we are now what i would like to do is i'd like to manipulate this equation so that
i write it out in terms of the joint distribution my goal is to write it out in terms of the joint
distribution p of x comma y and it'll become clear why i want to do that because i want to
impress upon you that the mutual information is just a special case of the cool back library
divergence between two distributions and we're going to we're going to write this out in terms
of this joint distribution so we can see that relationship and if you don't know what the
cool back library divergence between two distributions is i'm about to show you very good okay
so we want to get we want to write we want to write this guy in terms of a joint distribution
well we're almost already there because we know that p of x given y times p of y is just p of x y
all right so what we want to do is we want to manipulate this around so that we we can we can
put these two terms together and you know when you're manipulating equations there are you know
a few cardinal rules uh physicists if you're you know where lots of us are physicists then
you try to linearize and you try to do Gaussian integrals whenever you can because those are the
only integrals we know how to solve don't tell anyone right um the other thing is when you're
just doing algebra you multiply by one and you add zero so we're going to do a lot of multiplying
by one and adding zero today all right so let's do a little bit of that so right here
i know that if i take this p of x i had some equations up here that might be helpful
so p of x i can just say i summed over y p of x y okay and that's my p of x
okay and then i have a sum on x y here and i already said that p of x y it can be written
of p of x given y times p of y so i've got a p of x y here log p of x given y very good okay
so now now i'm already there i can combine these terms so let's come over here
okay so i'm going to take my sum on x y p of joint distribution of x and y
and now i'm going to take my log terms i've got a log let's write this guy let's write this guy
in terms of the joint distribution so p of x given y is p of x comma y divided by what
p of y very good i think i heard that somewhere and then what's the other guy i've got now
uh a minus so i've got a minus a minus keeping track of all the minus log
p of x so sorry we'll occasionally drop a minus sign hopefully i won't insert any
pies or factors of two but this happens okay so now we have something that's the sum on x y
p of x y log p of x y and then let's combine this together so i divide by p of y minus to bring
this over p of x okay this is my mutual information between my two variables x and y
so it's this ratio of p of x the joint distribution of p of x y compared to the product
of these marginal distributions so if p and x y were independent then this joint distribution
would be equal to this product and i'd have the log of one and i'd have zero right okay
so the mutual information between independent variables is zero good sanity check okay so
what did i want to tell you about this i wanted you to recall or see for the first time as if in
some case the colbeck libeler divergence between two distributions p and q the notation goes like so
and it is just defined as the sum on all say some discretized variables here p of a log p of a q
the colbeck libeler divergence between just two distributions is just the log of their ratio
averaged in the first under the first probability distribution so this is not symmetric okay if
i flip these two i flip the log that's fine but now i have a q in front so the dkl is not
symmetric but it is always greater than or equal to zero so it's always positive it's a decent
distance metric and it's equal to zero if and only if p is equal to q for every value a and you
can prove this you can prove that the dkl is positive using gibbs inequality or using jensen's
inequality so if those things are familiar then i highly recommend you go just work that out it's
kind of nice and it's simple it'll take you half a page all right and so now we can see that if
this is the dkl between two distributions then the mutual information is just a special case
where p is the joint distribution of the variables and q is the product of the marginals so this is
saying we're comparing the joint distribution to what it would have been if the things were
independent it's greater than or equal to zero it's equal to zero if and only if the joint
distribution is equal to the product of the marginals if that's true the mutual information is zero
because the things are independent okay so the mutual information describes the generalized
dependence of two variables or you can think about it as their magnitude of their deviation
from independence okay so that is what mutual information measures let's run through let's
run through a few examples of how to use this in neuroscience and how to compute things so that's
the end of our chalkboard interlude so when is information theory useful so this is a little
warm up to do something slightly more complicated in a second when is information theory useful
it's information it's useful if you want to go beyond linear correlation if you want to describe
the general correlation between two variables you have to have enough data to sample this joint
distribution I've written this down for particular discretization of x and y there are there are
there are ways of writing this down for continuous variables but generally if you think about this
discretized version you have to be able to write down the joint distribution of all of the states
of x and y so if you have n states of x and m states of y this is an n by m matrix and you
have to be able to sample that large matrix it can be useful to decide what your neural code is
we'll talk about that a little bit in a second so here are two variables that are nicely linearly
correlated x and y here are two variables x and y that have no correlation between them
no linear correlation you know you know no regular correlation but here are two variables that also
have no that have zero correlation but they obviously have some statistical dependence on each other
right and mutual information lets you measure this quantity even when your correlation coefficient
would be zero so let me take you through very quickly just a fun example of how you compute
mutual information so we're going to talk about a a student with a very strange form of amnesia
uh before we get to a neural example so this student
has a very strange form of amnesia he wakes up every morning and he doesn't know what day of the
week it is and for some strange reason he's in he's in a very um bad situation where he can't
take in information about what day of the week it is from anything he can't read the newspaper he
can't look at a calendar it nothing gets in he can't ask anyone what day of the week it is except
for one person and that's his advisor his thesis advisor is the only person who can tell him what
day of the week it is um and and she's rather diabolical so so first of all he does know
everything else about his brain is intact he's a thinking rational human being so what is his
uncertainty about what day it is he has no information about what day it is but he knows
there are seven days a week okay so his uncertainty uh is that he's you know he thinks any day of the
week it could be any of the day of the week he has no information is he has he has no reason
to believe that any day is is more likely than any other because he understands that the world
operates the way it does so he has a he has prior distribution or his his assumption about what
day of the week it is is flat and it's just equal equal probability each day of the week and this
is just one seventh one seven one seven one seven okay so what is the entropy of this distribution
we know how to compute that p log p if only if only there were eight days a week
okay then we'd know there would be three bits two two to the three is eight uh of of entropy here
but the entropy uh and here i've written an s we're calling this this is an h the the entropy
of the days of the week is 2.807 bits okay now the professor is a bit i said she was a bit diabolical
so her distribution of uh probability of of of days of the week that she says it is so
he can he can write down you know what day of the week did she say it was and he can develop some
intuition for for what she says and she very often tells him it's wednesday she very rarely tells him
it's sunday or saturday again she's a jerk um and then she also will tell him you know sort of
randomly that it's monday tuesday thursday or friday so he'd like to know what day of the week it is
what's that you would have said monday see but she she she she she wants to be a little bit kind
ah it's wednesday it's a hump day it's the middle you're fine uh and so her this entropy of this
distribution if you work it out if you calculate p log p is 2.665 bits so he can't he can't listen
to the professor and get full information about what day of the week it is because she's you know
manipulating things and she's arranged her answers in such a way that there's no linear correlation
between the day of the week and the day that she says so this is the joint distribution of the actual
day and the day that that the prof says it is so here we've got these bright spots on wednesday
and i tried to make this as best i can a circle all right um and it got a little pixelated so uh
the my my program tried to try to make this look look better but it's supposed to be just blocks
here okay so this is the joint distribution of the actual day of the week and what day it was
according to the prof so we'd like to compute the mutual information between the actual day
and what the prof says so there's no correlation there's no way you can say oh there's no way you
can make some sort of linear shift map where he says when when it's wednesday it's thursday
when she says it's thursday it's friday and so on and so forth because you've got no linear
correlation between between the days and the actual day okay so we'd like to compute the
mutual information between the what the prof says and what day it actually is so let's compute that
like so so let's compute um these conditional distributions so what's the entropy of days of
the week given that the prof says it's sunday well if we go back and we look when the prof says it's
sunday it's actually always wednesday okay so what's the entropy of this conditional distribution
this particular one well there's only one answer she gives there's no entropy there's no there's
no variability here and you can write it out long hand and show that indeed that zero okay what if
what if she says it's monday she says it's monday it's equally probable that it was tuesday or
thursday two options with that are equal probable if we do p log p on that you'll find and we do
this in log two so we're talking about bits i forgot to mention that if you do log two do log two
here it's bits if you do natural log you could call it gnats or nits if you do it base 10 it's
dats or dits okay but bits is the most common one for binary variables so here there's one bit of
information here the same if she says it's tuesday it's equally likely to be monday or friday
she says it's wednesday it's equally likely to be saturday or sunday she says thursday
she says friday if she says it's saturday it's always wednesday there's no entropy there and
if we want to compute the total mutual information between the day of the week and what the prof said
we have to average that conditional distribution over the probability of each day of the week
that it actually was those days of the week so we need to take these conditional entropies that
we just computed for particular days and multiply it by the probability of that day so we need to
know what's the probability that she says it's sunday what's the probability that she says it's
monday and this was the entropy that we started with of the days of the week which is almost three
2.807 and then we subtract what we get what we get from the prof like how how regular are her
answers and we end up with almost two bits of information we could have computed it directly
from the joint distribution here and we get exactly the same answer so you can either look at
look at the marginals or look at the joint distribution the reason so okay so the student
can get almost two bits of information out of the prof if only he knew how to decode what she was
saying so what this mutual information and he could you know maybe you know maybe someone could
compute this for him and tell him ah you could you could actually you could actually know what
day it is but he would have to know code he would have to know how to read that out what she says
so that's a good thing to remember about mutual information it will quantify the amount of statistical
dependence between two variables it doesn't tell you how to how to how to decode okay and you can
compute it either way you can compute it from the joint distribution or you can compute it from
the conditional distributions here and oftentimes when you're working with real biological data
computing this quantity or can or sampling from this joint distribution will be very different
computational problems with different biases for finite size effects in your data and you
should be careful to try both and decide which one is is is more suited to your purpose okay
so let's go into the retina this is a this is a larval tiger salamander that's recorded in the
berry lab these are pictures from Ronan Segev who now has his own lab at Ben Gurion so this is the
larval tiger salamander from which we dissected out the eye and squished the retina down onto
this glass slide with these recording electrodes that are in black the retinal ganglion cells have
been backfilled so they're these green blobs okay and the big streaks are the axons from from the
ganglion cells that are streaming towards and collecting together to form the optic nerve
so the optic nerve would punch through the retina like down here okay come together and what you're
supposed to take away from this picture is that the recording electrode density and the cell body
density is approximately matched so when you get a good squish of the retina onto this glass slide
you have the opportunity at least to record from every single cell in that region of the retina
and the retina is has a has a topographic projection of space so you know this part of the retina
sees that part of the visual world and if you can record every cell in the retina then you have a
complete potential potentially complete picture of what the brain sees in that part of the world
so that's why theorists particularly get excited about these recordings from the retina
you get not just a lot of cells and a convenient little piece in a dish you actually can see what
the brain sees and you can record from a complete neural population i'm also going to show you
recordings from rat retina that are done the same way this is a newer bigger better faster array
with again with the same sort of spacing so you get the good match between the density of the
electrodes and the density of the retinal ganglion cells just has many more it says 252 electrodes
and then the corners are reserved for grounding and this is these are data from olivier mars lab
so i told you that what we want to do is present to the retina a stimulus that has
predictable and non-predictable components and we want to oh yeah good wondering whether you
actually take some signal from the axons as well or just uh you do get so when you when you when
you squish yeah that's a very good question because you can see those axons there and the
question is do you actually pick up spikes from the axons you do they they look different uh on
they're on the on the electrodes so the the voltage trace is very different it's more
completely biphasic the if you're recording that's what a typical spike on an extracellular
electrode from the array looks like from a from a cell body and an axon spike will look more like
that so you can distinguish axon spikes from cell body spikes you also see you'll see that axon
you'll see the the the spike moving all across the array so you do you do pick up both signals and
we tend to throw away all the axon spikes just because but they're they're perfectly reasonable
data it's just convention okay so let's get back to what we wanted to do what we want to do is we
want to ask if the retina is compressing information and now we know what we mean by that uh about
the stimulus in such a way to keep as much about the future as possible so what we want to do is
we want to give the retina an option we want to give it a stimulus that has some amount of
predictable component some amount of non-predictable component and when it compresses we want to ask
does it preferentially keep the predictable part over the non predict and throw away more of the
non-predictable part or does it just do sort of a random compression that would keep a mixture of both
it's okay so we want to make that more concrete uh this moving bar stimulus that i'm showing you
obeys this equation of motion if v is the velocity of the bar x is the position of the bar
then there's some there's some drag characterized by this time constant tau this is a random white
noise variable this gamma of t it has in front of it a diffusion constant and this this uh omega
naught is the characteristic frequency of a fictive spring that's tethering this bar to the
center of the screen okay so most of you probably seen brownie in motion before this is just brownie
in motion this is an orange t nuland back process this part here and this is adding onto that uh a
thing that stabilizes the the position distribution makes it stationary okay because we want to do
this experiment over a retina where we're recording from a particular piece of it so we want this bar
to stay in one place okay so this is the distribution of positions that we have there are two predictable
components to the motion there's the spring part and there's the drag part and there's a non-predictable
part there's noise that comes in so this has both stochastic and deterministic parts of the motion
this is just a typical trace real trace at time and seconds position and pixels on the screen which
you can translate into microns by multiplying by 8.7 or something like that uh microns per pixel
when we project it onto the onto the retina that's for typical trace of this bar center of the bar
and this is the autocorrelation of the position of the bar okay so again as simona already did a
lovely introduction to the retina we're recording from many cells at once and we're writing down
the response of the retina as a binary word spike or not from each one of those cells so we're
just late we're just using ones to indicate which cell spiked as a function of time so these are
our fundamental data these binary strings and here again is a representation a more accurate
representation of the position of the bar as a function of time here is where we recorded some
spikes at time zero and we'd like to compute the mutual information between that binary word at time
zero and the position just the position in one time bin of the bar at time t plus delta t and
then we're going to vary delta t okay so here's the response the retina and we're going to compute
this mutual information like so okay so for single cells if it's well before we spiked the cell has
very little information so this is zero information about the position of the bar so here position of
the bar here also far into the future but if we trace out and we ask how much information does it
have you know a few hundred milliseconds 300 milliseconds before it has some more has more
about 200 milliseconds it has a peak of information a little bit before the the uh spiking the cell
and it has some information about the future position of the bar so if we average over many
cells in our recording this is the kind of curve we get for a single cell how much information does
it have okay we can also look at two cells now here i've normalized by the firing rate so that it's
all in sort of bits per spike yeah w of t yes this is the this is the binary word the response of
the retina so it's it's that vector of values of did that cell spike or not so if you have n cells
there are two to the n possible responses that you could have and it's the correlation that's the
it's the generalized correlation between those responses and the position of the bar okay so um
none this is a published in pns last year okay so uh here is for one cell we can also look at it
for two cells or three cells or four cells or five cells okay and i've written it in bits
per spike so that you can see you know the seven cells are going to have more spikes but how many
per spike you can see that you know the information here is somewhat redundant as we add more cells
we get less information per spike that that relationship might be flipping over here in the
future but that's a little bit thorny question so it's not surprising that we see information
bleeding into the future because there are correlations in the stimulus itself right so if
we have information about where the bar was here in the past it's not surprising that we have some
information about where it will be in the future the question we'd like to ask is a more is a finer
one a more detailed one the question is given that we had this much say so so much information about
the past of the stimulus how much could we possibly have here bleeding into the future and do we do
do we saturate some bound on the maximal amount of information we could have in the future okay
so let's go ahead and and go through that and i just want to say that what we've been talking
about here in uh mutual information and information theory is just the tip of the iceberg there's
the source coding theorem which talks talks about compressibility of signals given their entropy
the channel coding theorem which talks about uh limit of information rates and noisy channels
and so you should you should definitely go check out um uh cover in thomas uh is a good is a good
textbook for this also i'm a chi spoke is a good textbook for this i can write those down at the
end of the lecture if you'd like so we're going to take another chalkboard interlude because i want
to set up the problem that we're going to solve here and then i'll show you how we solve it for
the retina okay so i'm going to erase all this so we want to set up this information this information
bottleneck problem so that we can actually compute what the optimal compression of the stimulus would
be if we want to have as much information about the future as possible okay i think i have more
pages of algebra than we can get through in a half hour right 10 10 30 yeah so uh so we're
going to skip a few steps but um you can you can fill them in you can fill them in yourself so
we're going to imagine that x is now the stimulus that's coming in
and we want to map this on to some x tilde and this is say our representation
in the brain in the retina and recall why the future stimulus
so this is the stimulus in the past and this is the stimulus in the future and there's a
relay and we'd like to know how much information we can have in our in our compressed representation
about why but we know that the the real relationship here is between x and y that's where the information
comes through just to be clear all right so let me remind you a piece of information from from
rate distortion theory so if we have if we compute this mutual information between the past stimulus
and our compressed representation of it of course this is the sum on x and x tilde of p of x
x tilde log p of x x tilde divided by p of x okay so this defines some information rate that's in
our compression the number of average number of bits per message x tilde that we're sending
averaged over x but we'd like to know what we lost when we did this so we could compute some
distortion between x and x tilde so this d is just is just talking about what we lost when we
converted to x tilde and a typical some typical things that you use for this function could
be something like the mean squared error okay so we compute the average distortion
so the average distortion is just p of x is just averaging this distortion metric over the joint
distribution and there's a monotonic tradeoff between the rate of quantization so how you
how what information rate you have how much information you have an x tilde about x and
how much what your expected distortion is so if you have more information you can have less
distortion which kind of makes sense and the rate distortion theorem tells you that given a particular
average distortion d the minimum achievable rate that you can have for passing messages through the
system minimum of x of the mutual information between x and x tilde and the variables that you're
allowed to manipulate are p of x tilde given x but you have to have the condition that the average
distortion is less than or equal to some number d okay so this is you know how much you can compress
so that you so that you only have some amount of distortion or less okay so there's a tradeoff
between distortion and information rate and we can write that as this constrained optimization
problem we want to compress x into x tilde subject to the to the fact
subject to the constraint that we only distort by some amount d which i'm writing down as the
average distortion now you want to solve this so we'll take variational derivatives of this
with the variable we're allowed to vary which is our p of x tilde given x this is what defines our
compression we'll set these equal to zero and what we'll find is that this p of x tilde given x
this mapping that we want to make is exactly this so you can run through this algebra yourself
it's pretty easy there's some normalization okay so we get a solution that comes from
some exponential family and it has in the exponent this distortion metric okay
so this is so let me just tell you if you run through the algebra if you write this out remember
the information value contains entropy entropy contains logs we're with with a with a prefactor
that's this p of x we're taking derivatives with respect to p of x so it's not surprising
that we end up with when we take this condition that we end up something with log of p of x
given x tilde and that's how you get things in this exponential family so in general when you
want to optimize entropy quantities you end up with solutions that have this exponential form
okay so coming back to what we'd like to do i wanted to remind you of this this form this is
what you get when you're just trying to uh when you're trying to minimize your information rate
subject to some distortion wanted to show you that because now we're going to write down
this optimization problem that i've been talking about this information bottleneck and i'm going
to sketch out the form of solution so everybody remember this i'm going to erase it
and then i'm going to sketch out the solution for the information bottleneck problem that we want
to solve okay okay so remember that we are going to compress x into x tilde and we want to retain
an information in x tilde about y some relevant variable and we've decided that a relevant variable
is the future of the stimulus so we're going to solve we're going to solve this optimization problem
so we're going to minimize the following function with respect to p of x tilde given x those are
the variables we're allowed to play with and our optimization function we want to compress
we want to compress our representation of the stimulus into our neural response subject to the
constraint that we retain as much information in x tilde as possible as possible about y
and i'm just going to be really explicit here and also add the constraint that we want this
probability distribution to be normalized so we want so we need some Lagrange multiplier for each
x that says that p of x tilde given x should be normalized okay and this is a sum over x next
so we have a Lagrange multiplier for each x that keeps this p of x tilde given x normalized
okay so you guys are all familiar with this kind of technique for solving constrained equations
i've just written out the two constraints we have here we want to we want to retain a certain
amount of information about the future and we want to make sure our probability distribution
is normalized okay so i want to say right away that we can write down given that we have this
Markov chain condition that y and x have some mutual information and we're going to map from x
to x tilde so that's our Markov chain condition we can write down p of x tilde given y and that's
just a sum on x p of x tilde given x p of x given y if we want to get from x tilde to y we have to
go through x that's all that's saying and p of x tilde is sum on x p of x tilde given x p of x okay
so i'm going to sketch this out for you like i said we're not going to go through all the
algebra together but these equations let you write down something that will be very useful
when you when you want to figure this out so the derivative of p of x tilde given y
given p of x tilde given x is just p of x given y and derivative of p of x tilde
with respect to p of x tilde given x is just p of x okay because what are we going to do
we're going to take a derivative of this guy with respect to the variables we're varying
we're going to write that all out and set it equal to zero and i thought i might have time
to do that with you but we do not but if you use these if you use these guys you'll save yourself
a lot of trouble so what are you going to do you're going to write down the information in terms of
the entropies okay so you're going to write this all out you're going to take derivatives with respect
to x tilde given x and then you're going to set that equal to zero and find the solution
i am going to quote for you the solution which i'm now as i flip through pages i realize i was
quite ambitious in how much board work i could get through today but it's all it's all very simple
it's it's simple algebra and i'm happy to um share it with you if you guys would like to see it in
gory detail so the answer you get is that p of x tilde given x for this constrained optimization
problem is just p of x tilde over partition function our normalization and then we have
something in the exponent and the thing we have in the exponent is minus beta and we get a dkl
colbeck-libler divergence between p of y given x and p of y given x tilde okay
and let me say that just for completeness this partition function is e to the minus k
and k
k is lambda of x over p of x plus beta p of y given x log p of y this is so you can check your work
if you want to go through these details okay so here is our answer
so what we found is that our distortion metric is the colbeck-libler divergence
between p of y given x compared to p of y given x tilde okay so we're comparing what we know about
this relevance variable in our original in our original variable and this relevance variable
in x to the relevance variable in our compressed representation of x and so that's
quite nice and this taken together with these equations give us a set of self-consistency
equations for p of x tilde given x and p of x there are various methods you can use to actually
find p of x tilde given x there's an iterative algorithm that's guaranteed to converge called
the Blau-Hut-Aremoto algorithm for computing this and if x and y have particular forms if the joint
distribution of x and y is Gaussian so the variables are jointly Gaussian you can actually
solve this analytically okay and I refer you to Tishbee uh and Bialik which has some typos in it
that we have corrected here 1999 and there's also Chechik Glaberson
and Tishbee 2005 something like that uh Gaussian information bottleneck okay very good
right absolutely okay so let's go back and talk about how we set this up in y
so the the function that we're trying to minimize we are trying to minimize the mutual information
between x and x tilde that's the compression part there's a minus sign here so we're keeping a fixed
amount of information between x tilde our compressed variable and this relevance variable y the beta
parameterizes that trade-off so here we're compressing here we're retaining relevant information
and this is just the normalization constraint at the end of the day the solution that we get
is one where our distortion metric is a measure of of the distance between the distribution on
y conditioned on x and y conditioned on x tilde so why is this relevance variable
variable this is the original input variable and this is our compressed representation of it so
we're saying how far away are we from representing y in x tilde than representing y in the original
formulation that's the intuition behind where this goes so now what we're actually going to do
is go measure this in ah okay good we have time go measure this in 15 well I I have 12 minutes
okay so we're going to go measure this in the brain so this is the general generalized idea
of information bottleneck you compress but you keep relevant information we said that the relevant
information was how much we can infer from the past of the stimulus about the future of the stimulus
we have correlations in the stimulus so this mutual information between x and y
this distribution constraints how much we can possibly have so if oh here are the here are
the references good and I even got the got the year right just missed an author all right so here
is the problem we solved without the normalization constraint what this lets us do is sweep out
a curve that describes how much we could possibly have about the future given how much
information we retained about the past we can't do any better than that and what we'd like to
know now is does the retina sit close to this bound so we're going to interrogate this part of
the curve this is where the values of the past that we get in the retina live so if we look at
that we compute the mutual information between the spiking of the response of the retina at
present and the stimulus in the past or the spiking of the retina at the present and the
stimulus in the future what we find is that for many groups of cells in the retina these responses
sit close to the bound so what we've been able to show is that actually there are neurons in
the retina that seem to be doing as well as possible all of these values here were open to the retina
for some given amount of information about the past the retina could have could have
could have had no information about the future it could have been representing that noise trace
of the stochastic jittering of the bar but it actually squeezed out as much information about
the future as possible which leads us to you know want to dive deeper into this question of whether
or not the retina is optimized for all prediction problems or just or or just you know a few
particular ones we got lucky with this stimulus that the retina was optimized for this and what
my group has been doing now is to play around play around with this formulation of the problem
now the reason we were able to do this which is coming back to a question we had earlier
is that we could fully describe this bound we could compute that bound because that uh
that bar motion that I showed you was Markovian it was a physical system so current position
velocity determine everything about the next time step so we have a situation where we know
exactly what parts of the stimulus go into this complete representation of the past and complete
representation of the future how you actually compute this in neural data is a little bit
more tricky and subtle and we can we can discuss that at coffee if you like
so let me ask if there are questions now if there aren't I'll show you a few more things
yeah just a short question but you say it's close to the back yes what would be apart from the
like what's the yes it says what is good and what's bad very good um let me let me let me
give you uh an answer to that so let's go here so this was the bar movie uh and remember I said
that there were these ah good okay so I said that there were these uh predictable components of the
bar um this essentially describes uh a damping coefficient of this motion without the noise
so we can move that around and now I can show you things that are close to the bound a bound
and not close to the bound so you get a sense of close what I meant by close there had to do with
those error bars so were were they within error bars of the bound and were there things that were
outside there so okay so we can play around with these parameters so I can make um I can well
this is a little bit much I can make a system with these parameters that is uh sort of close to
critically damped and uh with these parameters something that's underdamped and the intuition
that I'm trying to give you here without explaining it very well is that in a critically damped uh
situation you want to put all your bits into representing position information whereas in
the underdamped case you want to put them you want to squeeze out variance in the velocity
condition you're stuck with some amount of noise that's left over um in your response but if you
you can think about the retinal response is being summarized by its position velocity trade-off
and I can make bar motions where one trade-off is is optimal and over the other and I can play both
of these kinds of motions say to the retina and ask does it solve these prediction problems equally
I think it should be clear why uh when you have an underdamped situation position isn't a good
predictor if I imagine that I say I'm I'm here I could be going this way I could be going that way
position isn't a great predictor where I would be next I actually need to know my velocity
that's some basic intuition to give you now what we see when we look in the rat retina
at these two bounds these are the same neurons from the same rat retina we just showed this movie
where it's optimal to squeeze out variance along in the position direction and here it's optimal
to squeeze it out along velocity we see that these points I think you would agree are not
close to the bound and these points are hugging the bound so this is a rough sense of what I mean
by close maybe there are four or five sort of balls of position I could describe what's nice about
this is that the retina responded to this motion it had lots of information about the past it just
didn't have very much information about the future whereas here it it did so that's part of our
research program is to try to define the sets of uh of motions that are predictable in the
early visual system and to ask next if those are defined uh by the statistics of things that the
brain is most likely to see meaning what does the natural world look like it's not a random collection
of arbitrary motion there are particular kinds of motion that we encounter in our natural world
and do the statistics of our natural world match the prediction problems the brain over
evolutionary time has has evolved to solve optimally um I want to take more questions or I can show
you a little bit about that yeah so is it also possible that the retina system can be trained
like that I mean the for example this example the student I mean that she is much better
right so this is a very good question so the retina unfortunately I mean the retina is a
fairly static piece of their old tissue meaning there's not a lot of uh synaptic plasticity in
the retina itself that said there are a lot of adaptation mechanisms that are also kind of
hardwired in there that would let you maybe flexibly adapt to different situations so what's
going on with serena what does she actually train herself to do so there's two things she's definitely
trained herself to hit the ball so that whole motor program is is exquisitely trained and so while you
and I might be just as good at predicting where the ball will be making contact with a racket is
a whole other game and that's your motor system there's tons of plasticity it also turns out
that professional athletes have better eyes so in the pool of people that get selected to be
and you pull out of them you know professional athletes they happen to be not surprisingly
the people who are on the edge of the distribution for acuity in their vision and reaction times and
things like that so serena's retina is like our retinas maybe a little better but her motor program
is that's the thing that's crazy better okay so I have I have a couple minutes do you mind if I
show you where we're trying to take this next okay good so what I'm showing you here is that
you know we have these simple physical bar movies and we're playing with them because we can solve
this bound we can compute this bound analytically and we can ask does the retina solve this problem
optimally does it solve that problem optimally what we'd actually like to get to at the end of the
day is something that's you know more natural than that so okay let me just go here I think it took
my computer a second to uh no don't freeze no don't freeze right on the cool movie all right
let's see if I can get this to play okay good so what we did is we ran around we ran around Chicago
and we filmed things that were moving and we asked about the natural statistics of motion
because the big idea is that the brain has been tuned to the inputs it's most likely to get
so the question the context of visual prediction is what are the statistics of things you're you're
most likely to see in the world so we did some characterization of of that of that motion we
computed you know Fourier spectrum of temporal frequencies we computed something about contrast
distributions we computed something about higher-order motion a lot Jonathan Victor and co
um but what we really wanted to do was ask what higher-order features of motion are present in
these natural scenes so let's talk about that for a second so here is something that looks a little
odd to begin with but this is a video of some grasses blowing in the wind color is now on that
pixel what direction of motion it's heading and saturation is the magnitude of the flow so this
is like a flow field where instead of a bunch of vectors I've put colors to tell you direction
and instead of a magnitude of the direction I've just put saturation so white is no motion
and something really bright is strong motion in that direction so we can take this natural motion
and we can make a kind of just summary of it just based on flow and I think you guys can kind of
see some grasses blowing around you can pick out things there um you might have noticed that there
was a B movie so here's the B movie in that same representation so you can tell we've gotten rid of
like anything B texture like it's just it's just flow and what we want to ask is what are what are
the higher-order features of motion that that give rise to our to our ability to predict where these
things will be next so let's get rid of everything like texture and stuff like that so here is um
here is the B movie again and I hope now what I've done what Jared in my group did is he took
that flow field and he just applied it to white noise so this is just white noise that's flowing
the way the bees flow and just there's no B in any single frame it's just white noise so all he
kept were the oops correlations between between the pixels and so now we can ask does the retina
code for this kind of motion optimally what are the different ways in which we can filter out
aspects of the motion in natural scenes so that we can ask does the does the brain care about this
or that without having to live in this very very high dimensional space of all the pixels so I'm
gonna leave you with with that and leave you with the the question of trying to understand
how our brain forms predictions in this very abstract reduced space and what insight that
can give us about computation in the brain and how again over evolutionary time our brains have been
organized to do count efficient calculations on our environment okay thanks
so um
um
yes yes
yes
we don't think it's like a useful tool or do we see stuff which is maybe not there because our
brain is starting to interpret so that's a that's a very good question our brain does do a lot of
filling in and that you know again there are there are priors about the natural world that are also
instantiated in our computational system that that lead us to lots of illusions the lucary motion
and which you know sort of gives us a cue about about what priors are you know kind of implicitly
sitting there in our brain now you mentioned you mentioned morphogenesis that's interesting
because we are taking some of these video analysis techniques from lots of different fields because
what we want to be able to do is track track objects and have motion trajectories that are
naturalistic and then show those like I just show you a dot moving and I ask I give you sort of a
Turing test for natural motion was this a marker that was on a real object or did I
did I construct it and we'd like to be able to reproduce those kinds of trajectories it works
for a fair number of our movies so I think that if we stick to simple scenarios we can we can ask
these detailed questions but once you get into the kind of cognitive level the cognitive processing
of what do you see next it gets it gets trickier to to tease that apart one final thing I'll tell
you is that there are some evidence that that some illusions that we get are because of the early
processing in the retina that it's not something we have under volitional control at all that
that some of the ways that the retina filters information give us give us illusions
that's it's a very strange thought that we really don't have control about what we sense
you explained that this minimization function can be interpreted in two ways
yes either retaining as much information as possible or having the best compression as possible
and we showed that the brain seems to retain as much information as possible we also see results
so that's a good point so let me just be clear for each beta these problems are equivalent
so what I showed you what you can you can interpret it in the same way so the two
points on that plane on the on the bound curve which I want that
so beta beta is changing as I go along here and this is not allowed this is the information
about the future this is the information about the past for some given amount of past compression
this is telling me how much I can possibly have about the future the other way to say it is that
if I have some amount of the future what's the you know what's the maximal amount of compression
I can do so your question is about the magnitude of the values we see here how much compression is
the retina doing so far we've only been able to answer that question for small groups of cells
because sampling 2 to the n possible output space is very large what we what we do see is that the
retina does throw a lot away at small neuron levels now if you looked at you know 100 100 200
cells that are really representing that whole part of visual space you can imagine that different
parts of visual space are fairly independent so what's the cold cold pool size and what's the
amount of compression that's an unanswered question it's a very interesting one
so if you can go back to the slide we had the two data sets one close to the bound one far
away from the bound I can do that so the one on the left has a much smaller variance in the
velocity and the data is far away from the bound what I'm representing here is what you're optimal
so this isn't the the the prior distribution on position velocity is the same and it's like
a circle in both of these cases and what I'm trying to represent here is is this isn't about how the
stimulus changes this is how your optimal representation of the stimulus changes so if
you think about you know some prior you know on position velocity so position velocity
okay so here's where here's where the bar stimuli live and both of them have this prior
okay so then what this is saying is that to represent the future most accurately you should
squeeze out position information squeeze out position variance and the other one you should
squeeze out velocity variance but there are still there's still the same amount of position
velocity variance in each in each stimulus so would it be feasible to conclude from these two
plots that the retinal systems are significantly better at squeezing out velocity variance than
they are position variance based on the fact that the right plus so much closer to the bound
that's the conclusion we are initially going for and our our and it's different so the this is from
the rat retina the salamander retina did optimal optimally at this one and we'd like to go back
to the salamander retina and ask it about this problem what's interesting now is we're getting
into a comparative approach where the the salamander is a sit and wait predator it's it's
it's usually when it's in its aquatic state it's sitting in a murky pond and it's waiting for some
small tasty fish or insect to to come by within striking distance and then scrapping it so it
kind of makes sense that position is the relevant variable that it's able to represent now rats
they're in a very different situation right they're running around and they're afraid of getting eaten
by predators that swoop in and and munch them right so um what we think is that perhaps if we
looked at the natural scene statistics of the ecological niche of these animals then they would
have they would have more prediction problems to solve where velocity is the relevant variable
versus position that's the conclusion we're beginning to form but it has to be tested a little bit
more completely just there you're talking about behavioral objectives yeah yeah yeah beyond making
predictions yeah so I was wondering uh sort of raises the question of um so the nice thing about
this framework is just about the statistics of the stimulus and you don't have any extra assumptions
about behavior but is it going to be enough do you think at some point we need to add extra
absolutely so the foray we're making into that um which is a very important question uh
is how how your own behavior influences your representation of the world so to to make an
inroads there we are working with the mclean group at u chicago to record eye movements while a mouse
is viewing a natural scene and then what we'd like to do is play now a movie not of the natural scene
but of the movie convolved with the eye movements you know play the eye movements on top of that
so the the whole scene moves with a way the way that the animal is looking at it while the scene
is moving and now ask about about that kind of compression because there isn't a lot of feedback
in the retina so asking how the retina has been primed to handle statistics that it imposes on
motion as in addition to the natural motion world I think is a very interesting one it's a little
step okay yep let's go have coffee and so wait we have coffee in terms of
