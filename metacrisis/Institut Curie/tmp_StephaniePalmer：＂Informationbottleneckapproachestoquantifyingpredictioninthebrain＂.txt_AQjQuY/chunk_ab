receptive field and some cells it passed them and if we do that again, so if we ask what does the
response of the retina look like at that time, we see something really interesting. So these are
again spike rasters each point is a place where this cell fired and there's many many trials so
there's many lines there and relative to the time of reversal there's a big synchronous firing of
activity across the retina and remember those cells had different receptive fields so when the bar
swept across they fired at different times in response to that bar sweeping but they all fired
at the same time relative to the reversal and that again is a highly nonlinear property these are
data from Greg Schwartz when he was a graduate student Michael Barry's lab these are this is a
highly nonfeature of retinal processing and signaling a reversal is also important you
could think of that as being important for prediction if you have some model of where
things are going to objects are going to be in the world you might want to update that if if the
plan changes things change course okay the receptive field again is the is the point in
space where the neurons are responsive to stimulus by light so you can think of it as the cell's
spatial filter on the visual world okay good so again we want to bring this back to our discussion
today which is about information theory and we're going to ask about prediction in the visual system
so what we'd like to know again is if the we take the stimulus in the past and it gets compressed
into a representation by a population of cells in the retina we want to ask is that compression
organized such that we have as as much we know as much as we could about the future stimulus yes
I want to ask about this reversal sure
you
okay this is a good question so let me unpack that just a little bit so
the the time of the reversal response is longer than the flash delay the flash lag
of of the of the cells so you can see this is about at 200 milliseconds and before we had our
flash lag somewhere in here around 60 milliseconds so it's not it's it's what's interesting is that
these cells are all at different positions and would have different you know the flash lag if
you know if we flashed the bar at different points for them this you know for for example
if we considered the point of the lag where each cell where the where the bar across the center
of the part of the visual field that each cell cares about we would have responses that would be
you know sort of variable like this but here once we reverse everybody fires together so
um how predictive is it is a good question right um what's interesting is that it's uh
is that it's coordinated and it signals something that would let you then do a prediction about
where the bar would be later but the reversal the reversal is it's not a it's not a prediction
of the reversal it's response to the reversal so okay an important thing to remember in all
of this is that we're not hypothesizing that the brain can do fortune telling that the brain
is anticipating things that um are you know unlikely that that are not predictable we're
talking about the things that are predictable so if a if a bar reverses what is predictable
it's predictable that now it won't be going if it's if it's going this way and then it reverses
what's predictable is that it won't be going over there and it'll probably go okay all right so
coming back to our uh our goal of the day uh so what we'd like to do is we'd like to formulate this
compression problem with the idea uh you know more we'd like to develop this a little bit
more formally and put in the idea that we want to retain as much information about the future as
possible so we're going to set up this optimization problem here i've written down this Lagrangian
so we're asking to minimize this quantity so i'm going to unpack what this inframutal information
between the stimulus in the past and this binary word in the retina time t is so we want to we want
to throw away information about the past stimulus but we want to keep um some fixed amount that's
parameterized by beta of information about the future stimulus so that's the tradeoff that we're
going to try to try to look at at this point is that question i mean the idea that you know
what is useful for future prediction no so that's the so this is just this is just hand this is
just conceptual at the moment if we're sitting in the natural world where the stimulus is very very
high dimensional it's a thorny question to ask what what is relevant out of you know what particular
low dimensional representation of that space is relevant so what we're going to do is we're going
to design a stimulus which thank you for is is low dimensional where we can describe everything
that's predictable and everything that's not predictable about it and we actually um will
also use the fact that we can uh describe fully uh analytically the answer to this bound problem
okay so right so here we go again we're going to show a moving bar to the retina like the ones that
i showed you so far but it's going to have some more complex motion yeah in the back
about not having a lot of information about uh why compress uh i see so i mean compress in general
but then maybe it doesn't necessarily mean i need to forward maybe i have some limit on how much
how much i can encode but i don't see right so you have so so remember that the response in the
retina is causal so it's caused it's it's caused by the stimulus that happened in the past and all
i'm saying is that um when you think about compression you're explicitly thinking about
compression of the past stimulus so yes you we're going to we're going to sweep out many such uh
different amounts of so you can think about this in either way you either say you can and it's
completely equivalent either you say i have a fixed amount of information about the future
and i want to know what's the what's the what's the code that that compresses as much as i can
so that i can be as efficient as possible i can use as few spikes because maybe you have a hypothesis
that spikes uh cost you atp it's a metabolic cost to spiking um and it'd be better if i could use
fewer spikes or fewer neurons something like that to do it you can think about it the other way you
can you can think i have some fixed amount of compression that i can do in the retina that i
that i that i do and i want to retain as much information about the future as possible these
are completely equivalent beta parameterizes the trade-off and we'll sweep and there isn't just one
solution there's a whole the family of solutions that we'll talk about okay so let me just do this
one more time so here's a stimulus that's jiggling around and moving and at this point in time it's
made some excursion to the right so now the retina needs we're going to ask the retina how well it
can predict what the stimulus does next and what the stimulus does is reverses and comes back okay
so now we are ready we're ready to go to the chalkboard let's get warmed up a little bit
before um we derive anything that requires too much algebra so let's do a basic refresher of uh
some probability theory so these are just some relationships between probability distributions
so if i have a joint distribution of two variables a and b uh then their joint distribution can be
written down as a product of a of a conditional distribution and um a prior distribution or
a marginal distribution um if i have a joint distribution and i sum over all one variable if
i sort of integrate out that one variable i get my probability of just the the other and um and
there's something called Bayes rule some people call call this Bayes theorem this is this is this
hardly even deserves somebody's name right this is just this is just an identity this is just a
mathematical fact so so i always try to tell my students don't call it Bayes rule just call it
Bayes thing um and and actually you know just remember it because it's useful so it lets you
it's the this joint distribution is symmetric the joint distribution of a and b is the joint
distribution of b and a so we can rewrite this uh conditional distribution of a condition on b is
b conditioned on a and we just have to we just have to multiply uh by these marginals okay all
right so now we are going to take a chalkboard interlude and uh write down a few things so
i told you that we wanted to compute uh mutual information so the mutual information between
two variables x and y and i'm going to try to keep my capitals and lowercase letters consistent
they weren't so great on that slide but i'll try to try to do a little better here at the
board um the mutual information between two variables x and y mutual information is kind
of a generalized form of of correlation it talks about the dependence statistical dependence of
two variables on each other and uh a way conceptually to think about it is that the mutual information
between two variables x and y is the uncertainty that you have about x which i'm writing down
with h some people call this s uh for entropy uh i'm going to call s the stimulus so we're
going to call the entropy h here today so it's the uncertainty i have about my variable x minus
the uncertainty i have left over once i specify y okay so information you can think of as a
reduction in uncertainty and it's symmetric the mutual information between x and y is the mutual
information between y and x these are the same thing uncertainty about y minus the residual
uncertainty i have after i specify x okay and these things are equal now i've written down
entropy as a measurement of uncertainty and if you go back and you look at claud shannon's original
paper you will see a nice uh mathematical justification for using using entropy as your
measurement of uncertainty it has a lot of nice properties and it looks something like this so
the entropy on some distribution of x is minus the sum on all of the states xi i'm going to drop
probably these little labels here i's but just ask me if anything becomes unclear of p log p so
p is the probability that we're that we observe some particular discretized value of x and the
entropy is just minus p log p and um you know you might be tempted to to think about you know
deep analogies to thermodynamics here this is just sort of an equation analogy um if you
want to think about energetic costs of computation and land ours principle and things like that then
this becomes more concrete and and how it relates to the thermodynamic entropy but here it's just
sort of the form of the equation is similar okay so that's our that's our formula for the entropy
and i've put it inside this box because it's important enough that i don't want to erase it
so let's write down let's write down this mutual information between two quantities
just so we get used to manipulating these kinds of equations okay very good okay so the mutual
information between x and y are there any questions so far good so this is a review for
for many of you have any has anybody never seen mutual information before a few of you okay so
let's let's go ahead and write this out so let's just write this out in gory detail
we're going to write the the entropy of x minus the entropy of of p of x given y so if we write
down the entropy of x some of all the states x and c are to your drop the i so you know forgive me
okay so that's that first term and then we have the second part so we know we have to
we know we have to sum over the states of p of x given y log p of x given y
all right so i took a minus a minus there so we need to sum over x here now we do need to average
this quantity so that's for some particular y and then we average this over p of y
okay so if we write this out this is just being excruciatingly specific
holler if you want me to accelerate
okay there we are now what i would like to do is i'd like to manipulate this equation so that
i write it out in terms of the joint distribution my goal is to write it out in terms of the joint
distribution p of x comma y and it'll become clear why i want to do that because i want to
impress upon you that the mutual information is just a special case of the cool back library
divergence between two distributions and we're going to we're going to write this out in terms
of this joint distribution so we can see that relationship and if you don't know what the
cool back library divergence between two distributions is i'm about to show you very good okay
so we want to get we want to write we want to write this guy in terms of a joint distribution
well we're almost already there because we know that p of x given y times p of y is just p of x y
all right so what we want to do is we want to manipulate this around so that we we can we can
put these two terms together and you know when you're manipulating equations there are you know
a few cardinal rules uh physicists if you're you know where lots of us are physicists then
you try to linearize and you try to do Gaussian integrals whenever you can because those are the
only integrals we know how to solve don't tell anyone right um the other thing is when you're
just doing algebra you multiply by one and you add zero so we're going to do a lot of multiplying
by one and adding zero today all right so let's do a little bit of that so right here
i know that if i take this p of x i had some equations up here that might be helpful
so p of x i can just say i summed over y p of x y okay and that's my p of x
okay and then i have a sum on x y here and i already said that p of x y it can be written
of p of x given y times p of y so i've got a p of x y here log p of x given y very good okay
so now now i'm already there i can combine these terms so let's come over here
okay so i'm going to take my sum on x y p of joint distribution of x and y
and now i'm going to take my log terms i've got a log let's write this guy let's write this guy
in terms of the joint distribution so p of x given y is p of x comma y divided by what
p of y very good i think i heard that somewhere and then what's the other guy i've got now
uh a minus so i've got a minus a minus keeping track of all the minus log
p of x so sorry we'll occasionally drop a minus sign hopefully i won't insert any
pies or factors of two but this happens okay so now we have something that's the sum on x y
p of x y log p of x y and then let's combine this together so i divide by p of y minus to bring
this over p of x okay this is my mutual information between my two variables x and y
so it's this ratio of p of x the joint distribution of p of x y compared to the product
of these marginal distributions so if p and x y were independent then this joint distribution
would be equal to this product and i'd have the log of one and i'd have zero right okay
so the mutual information between independent variables is zero good sanity check okay so
what did i want to tell you about this i wanted you to recall or see for the first time as if in
some case the colbeck libeler divergence between two distributions p and q the notation goes like so
and it is just defined as the sum on all say some discretized variables here p of a log p of a q
the colbeck libeler divergence between just two distributions is just the log of their ratio
averaged in the first under the first probability distribution so this is not symmetric okay if
i flip these two i flip the log that's fine but now i have a q in front so the dkl is not
symmetric but it is always greater than or equal to zero so it's always positive it's a decent
distance metric and it's equal to zero if and only if p is equal to q for every value a and you
can prove this you can prove that the dkl is positive using gibbs inequality or using jensen's
inequality so if those things are familiar then i highly recommend you go just work that out it's
kind of nice and it's simple it'll take you half a page all right and so now we can see that if
this is the dkl between two distributions then the mutual information is just a special case
where p is the joint distribution of the variables and q is the product of the marginals so this is
saying we're comparing the joint distribution to what it would have been if the things were
independent it's greater than or equal to zero it's equal to zero if and only if the joint
distribution is equal to the product of the marginals if that's true the mutual information is zero
because the things are independent okay so the mutual information describes the generalized
dependence of two variables or you can think about it as their magnitude of their deviation
from independence okay so that is what mutual information measures let's run through let's
run through a few examples of how to use this in neuroscience and how to compute things so that's
the end of our chalkboard interlude so when is information theory useful so this is a little
warm up to do something slightly more complicated in a second when is information theory useful
it's information it's useful if you want to go beyond linear correlation if you want to describe
the general correlation between two variables you have to have enough data to sample this joint
distribution I've written this down for particular discretization of x and y there are there are
there are ways of writing this down for continuous variables but generally if you think about this
discretized version you have to be able to write down the joint distribution of all of the states
of x and y so if you have n states of x and m states of y this is an n by m matrix and you
have to be able to sample that large matrix it can be useful to decide what your neural code is
we'll talk about that a little bit in a second so here are two variables that are nicely linearly
correlated x and y here are two variables x and y that have no correlation between them
no linear correlation you know you know no regular correlation but here are two variables that also
have no that have zero correlation but they obviously have some statistical dependence on each other
right and mutual information lets you measure this quantity even when your correlation coefficient
would be zero so let me take you through very quickly just a fun example of how you compute
mutual information so we're going to talk about a a student with a very strange form of amnesia
uh before we get to a neural example so this student
has a very strange form of amnesia he wakes up every morning and he doesn't know what day of the
