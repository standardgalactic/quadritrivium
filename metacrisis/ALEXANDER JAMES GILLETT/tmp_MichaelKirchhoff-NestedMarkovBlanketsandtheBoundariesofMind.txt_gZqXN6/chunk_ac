whether it's the same notion of perception and action all the way,
if it kind of seems like it needs to be, for the argument to go through,
I'm sympathetic to the idea that it is, but I think if Dave was here,
he would probably say, well, I understand what you're saying about cells and livers and so on,
but they're not consumers and actors in the sense that I care about.
So you've given us a sense of perception and action,
which is convivial to a best-in-Markov-blanket story,
but can we have more reason to believe it?
Yes, so I don't think that the account that I've given of active and sensory states
at all mirrors, I might think that Chambos was thinking of action and perception.
I don't think so at all.
I think he means me visually perceiving you as you're sitting there.
Maybe even consciousness gets him.
It could be the case, but I don't really want to touch consciousness.
Yes, but that's not the topic.
Okay.
So I think one observation or one remark would be there's no reason for thinking
that you have to have a kind of commonsensical view of perception and action.
That's a way in which to think about where you've got intuitive boundaries
of certain cognitive processes or cognitive states.
We're more than willing to grant that cognitive processes don't fall at the level below experience.
And there I take it that how individual neurons react and act is quite dissimilar
to how we would think you and I perceive an act.
But that doesn't really count against us thinking that these sorts of processes
are part of processes we're willing to call cognitive processes at a sub-personal level.
So that would just be one reaction to why I don't see a deep problem with reformulating
or tinkering with the way Dave Chalmers sets up the perception, action, and distinction
and the way it's worked through, say, the Markov-Lankin formulation.
I also started by saying this is something similar to or akin,
not the same sort of notions as he might operate with.
And just a footnote to that, I think he's more than happy to reformulate
and tinkered with the kind of commonsensical perception and action.
Yeah, I just thought it was one thing in the part that I'm entitled to
and I think there's a difference between bringing with structure the world interview
and just as it were, minimizing your free energy to hang around a bit longer.
Which is what the other stuff is doing.
What sort of difference is that?
So you could, I mean, I guess you could from a certain point of view say
that is just to minimize free energy, couldn't you?
And you have described it in a particular way.
That seems not quite to be the same as straightforward free energy reformization.
Yeah, I have to think about that as a good proposal or comment.
My guess is from the talk you've given,
you don't spend a lot of time lying awake late at night
wondering about whether there really are Markov blankets.
And I'm not sure that I do either,
but de-entertain the possibility there might be sort of approximations of Markov blankets
with big holes in them that change and that need to be sort of improvisational.
I'm thinking about it on the analogy to sort of modules, right?
And the old sort of literature in the 80s when the modularity was really big.
There were the sorts of ways of defining what modules were
which gave a certain kind of insulation of certain units within the head, right?
And there were notoriously sort of leaking and incomplete and they were partial
and there were idealizations that we could, if we made those assumptions
about how language processing would pass, we could make lots of sort of progress
but there were completely idealizations.
I'm going to ask the question is how much of an idealization is built into this idea of Markov blankets?
Sure.
It's the same sort of question as the metaphor questions earlier in the morning, I feel.
I was just kind of using this sort of terminology
shorthand to describe something that's not really there.
I think there's no harm in just thinking about anything that can be separated from something else
giving a set of mediate states can be thought of as a markov.
So that just gives you a kind of grip to speak about if you like statistical relations between states.
And that's all the blanket does.
It's not as if, I mean, if you look up to the standard machine learning textbooks
and you look into the features of the Markov blanket,
you're not going to find it to have sort of causal powers.
It's just the way of separating certain states from other states given a third set of states.
That's all the terminology allows you to do in the initial setup before you start building material
and then you have to justify.
Is that okay? Is that helpful at all?
Yeah, that's okay. It just seems like it's doing a bit more metaphysical sort of work here
in terms of separating the boundaries of the line, for example.
Yes, sure, that's true.
But it's also embedded within a philosophical discussion with that particular blanket plays
or the notion of a blanket plays a particular role,
at least in a certain set of arguments for making that boundary between a mental and a non-mental.
And what I'm trying to do is simply to say,
well, it's not altogether clear where to draw that boundary if you're comprised of a whole heap of these Markov blankets.
Then you might think they're not booking that the bummering can move up and down.
Okay, thanks Michael, that really was very, very good.
I am going to give exactly the idealization objection tomorrow,
so I'm not going to say much about that now.
I think there is an issue about taking the original Markov blanket idea from Judea Pearl
from the machine learning literature,
and then making it do all this kind of causal metaphysical work.
I mean, that Kristen and Rika Allen point that we had, that's causal patterns in there.
Yeah, sure, I understood that.
So look, I'll leave that aside, because we've just discussed it out there.
I'm going to put my Yakub Herbie head on for a minute.
I'm going to turn and just leave you over there if you have an answer to the question.
It's on the list.
It's on the list.
You know, Yakub's point here is that the precision estimation functions of the brain
are always behind a Markov blanket relative to the environment.
So that's the boundary that counts.
And so you can have, you know, extensions of Markov blankets,
you can have Markov blankets within Markov blankets
to do various kinds of self-organizational work.
But really here, to understand those precision estimation functions,
you have to think of the Markov blanket as separating the internal states of the brain
from the external states of the environment.
Yeah, okay.
I take it that that is the argument, at least in part.
But notice that as we're running the argument that sort of leaves the precision estimation,
the machinery is slightly aside.
And that's just the kind of pure self-evidence in Arizona,
where I'm making predictions about what I'm thinking of post my sensory protocol,
and so far I'm all my brains doing a particularly good job here.
Lessening and lessening and lessening the divergence here in KL
or just the minimization of the prediction error.
And in that sense, I'm gaining evidence for my own predictions.
So that shouldn't do something like an epistemic, at least, boundary
between predictions of the internal prediction machinery and then the external states.
But that doesn't apply to the precision estimation machinery.
I imagine you put that back in.
Then you can definitely be skeptical about whether or not you need them to say
it's only internal neural states that can play a role in setting the game
on how reliable something is.
So if you think about if the Markov blanket of Markov blanket U
can be recursively scaled up to include external features of our environment,
then you might think, for instance, the example of the white lines in the road
that has particular regularity, you can always expect it actually reduces
the uncertainty of the error signal itself.
So if you can just gesture it, you don't have an argument for that,
you can think of that as being part of the state's comprise by your Markov blanket.
Then you have an extended notion of a Markov blanket,
and you've got external elements that can play the role of something
that we normally associate with, or something that is associated with
internal neural states, precision estimation.
Paul?
I just didn't understand something.
Can you go back to the third slide, the one with the three pictures on it?
I have, yeah.
It makes it easier to explain what I'm saying.
So when you go from A to B, you switch from, you know,
discord to a little interaction.
But what's actually going on there is just you've introduced spatial structure.
So let's go to the one on the other side.
So if I was thinking about that as a population of organisms
and thinking the same terms, sure, there's a boundary,
but everything in the figure is equally consistent
with being able to re-center to any known and generated new boundary.
So there's another assumption going in there, roughly the existence of the boundary.
The actual causal matrix is one where if you re-center to another,
the actual, in other words, you haven't shown all the little local interaction arrows
and the structure in that causal graph is such that you're getting a boundary.
So what I don't get is I didn't see anything in the formalism
that tells me why, all the way through the rest of the talk,
these things were being strictly nested.
It's not just that they're, apart from maybe that Tristan quote,
it's not just that there are little ones
and there are big ones which have been almost within them.
It's strict nesting. I didn't see anything that,
where the hell is the strict nesting coming from?
I see, I understand.
I don't think you need to have, this is not the strict,
this is not an image of something that's strictly nested.
No, but all the cells are all of the, you know, cells of our local hierarchy stuff.
It's all strict nested hierarchy.
So is that in fact just, does that follow?
Well, it follows in the world of, in the simulation world I guess,
where you can, where you can see how,
what's a different example, take a conventional example.
Yeah, maybe we can talk a little bit about a different example.
So that's, there's a bunch of molecules moving in a particular way.
A certain threshold of temperature gradient
gives rise to a particular rolling motion.
One way of thinking about that is,
you've got a conventional rolling motion
comprised of individual molecules.
Yeah.
That, that okay?
Yeah, that's alright.
That's alright.
This is really, as a journey, I just, I mean, I just,
I don't understand, whether or not the total definition needs to be
some nifty trick.
No, I don't think so.
But here we're just doing sort of something similar to the
convection rules.
An example is you've got, you've got some cells that comprise
the mark of blanket.
That cell can then be part of what organizes something
at a larger scale that has a mark of blanket.
In the same sort of way you've got automatic tools
that can come together in particular way
and form a rolling motion of oil.
Nothing, nothing more complex is going on
and I'm not trying to say anything more.
Have you been to that?
A tiny comment that I didn't understand.
That's not really, I think,
you think I'm objecting to something I'm not.
I'm just trying to wonder if, we end up in the last sort of
slides in which you've got these bounded units
within a bigger boundary unit.
I was trying to find something in the formalism
that stopped the bigger boundary unit from slicing
