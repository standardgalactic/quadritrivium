within a constraint on the trajectory we're on. Yeah, so the predictably part is the
is the constraints of the trajectory. And the unpredictable part is the part that you still
haven't really clarified the origin of, of the little bit of freedom. Yeah. So you're, you're
just arguing, you're basically saying that radical freedom is impossible. You're, you're really
operating in a world of constraints that are constrained by the memory of the trajectory
of the chemistry that led to who you are. Okay. But, you know, even just a tiny bit of freedom,
even if everything, if everywhere you are in cages, if you can move around in that cage
a little bit, you're free. I agree. And so the question is in assembly theory,
if we're thinking about free will, where does the little bit of freedom come from? What is the
eye that can decide to be a rapper? What, why, what is that? That's a cute little
trick we've convinced each other of so we can do fun tricks at parties, or is there
something fundamental that allows us to feel free, to be free?
I think that that's the question that I want to answer. I know you want to answer it.
And I think it's so profound. I'd let me have a go at it. I would say that I don't
take the stance of Sam Harris, because I think Sam Harris, when he said, the way he says it is
almost, it's really interesting. I'd love to talk to him about it. Sam Harris almost thinks
himself out of existence, right? Because do you know what I mean? Yeah, well, I mean, he has
different views on consciousness versus free will. I think he saves himself with consciousness. He
thinks himself out of existence with free will. Yeah, yeah, exactly. So I mean, there's no point,
right? He's a leaf floating on a river. Yeah. I think that he, he's, I don't know, I'd love
to ask him whether he really believes that and then we could play some games. Oh, yeah. No, no,
I then would say, I'll get him to play a game of cards with me. And I'll work out the conditions
on which he says no. And then I'll get him to the conditions he says yes. And then I'll trap
him in his logical inconsistency with that argument. Because at some point, at some point,
when he loses enough money, or the prospect of losing enough money, there's a way of basically
mapping out a series of, so what will is about, let's not call it free will, what will is about
is to have a series of decisions equally weighted in front of you. And those decisions aren't
necessarily energy minimization. Those decisions are a function of the model you've made in your
mind, you're in your simulation, and the way you've interacted in reality, and also other
interactions that you're having with other individuals and happenstance. And I think that
there's a little bit of delay in time. So I think what you're able to do is say, well,
I'm going to do the counterfactual. I've done all of them. And I'm going to go this way.
And you probably don't know why. I think free will is actually very complex interaction between
your unconscious and your conscious brain. And I think the reason why we're arguing about it
is so interesting. And we just, some people outsource their free will to that unconscious brain.
And some people try and overthink the free will in the conscious brain. I would say that
Sam Harris has realized his conscious brain doesn't have free will, but his unconscious brain does.
That's my guess, right? And that he can't have access to the unconscious brain.
And that's kind of annoying. And so he's just, he's going through meditation,
come to acceptance with that fact. Yeah. Which is maybe okay. But I do think that I have
the ability to make decisions and I like my decisions. In fact, I mean, this is an argument I
have with some people that some days I feel I have no free will and it's just an illusion.
And this is one, and it makes me more radical if you like, you know, as a,
I get to explore more of the state space and I'm like, I'm going to try and affect the world now.
I'm really going to ask the question that maybe I dare not ask or dare not or do the thing I dare
not do. And that allows me to kind of explore more. It's funny that if you truly accept that there's
no free will, that is a kind of radical freedom. It's funny, but you're, because the little bit
of the illusion in under that framework that you have that you can make choices, if choice is just
an illusion of psychology, you can do whatever the hell you want. That's the- But we don't, do we?
And I think- But because you don't truly accept that you think that there's
like, you think there's a choice, which is why you don't just do whatever the hell you want.
Like you feel like there's some responsibility for making the wrong choice, which is why you
don't do it. But if you truly accept that the choice has already been made, then you can go,
I don't know what is the most radical thing. I mean, but I don't, I wonder what,
what am I preventing myself from doing that I would really want to do? Probably like humor stuff,
like I would, I would love to, if I could like save a game, do the thing, and then reload it later,
like do undo, it'd probably be humor, just to do something like super hilarious.
That's super embarrassing. And then just go, I mean, it's basically just fun. I would add more
fun to the world. I mean, I sometimes do that as I, you know, I sometimes, I try and, I try and
mess up my reality in unusual ways by just doing things because I'm bored, but not bored. I'm
not expressing this very well. I think that this is a really interesting problem that perhaps the
hard sciences don't really understand that they are responsible for because the question about
how life emerged and how intelligence emerges and consciousness and free will, they're all
ultimately boiling down to some of the same mechanics, I think my feeling is that they are
the same problem again and again and again, the transition from a, you know, a, a boring world
or a world in which there is no selection. So I wonder if free will has something to do with
selection and models and, and also the models you're generating the brain and also your, the
amount of memory, a working memory have available at any one time to generate counterfactuals.
Well, that's fascinating. So like the decision making process is a kind of selection and that
that could be just absolutely yet another, yet another manifestation of the selection mechanism
that's pervasive throughout the universe. Okay. That's fascinating to think about.
Yeah. There's not some kind of fundamental its own thing or something like that that is just
yet another example of selection. Yeah. And in the universe that's intrinsically open,
you want to do that because you generate novelty. You mentioned something about
do cellular automata exist outside the human mind in our little offline conversation.
Why is that an interesting question? So cellular automata complexity,
what's the relationship between complexity in the human mind and trees falling in the forest?
Infrastructure. So the CA, so when John von Neumann and Conway and Feynman were doing
CA, they were doing on paper. CA is cellular automata. Yeah. Just drawing them on paper.
How awesome is that, that they were doing cellular automata on paper. Yeah.
And then they were doing a computer that takes like forever to print out anything and program.
Sure. People are not with the TikTok kids these days with the TikTok,
don't understand how amazing it is to just play with cellular automata arbitrarily changing the
rules as you want to the initial conditions and see the beautiful patterns emerge,
sing with fractals, all of that. Oh, I've got to, you've just given me a brilliant idea.
I wonder if there's a TikTok account that's just dedicated to putting out CA rules and
isn't, we should make one. 100%. And that will get millions of views.
Millions, yes. No, it'll get dozens. Just have them running. So look, I kind of,
CA, I love CA's. Sorry. Yeah, no. We just have to make one. I actually, a few years ago,
I made some robots that talked to each other, chemical robots that played the game of Hex,
invented by John Nash by doing chemistry and they communicated via Twitter,
which experiments they were doing. And they had a, they had a, they had a lookup table of
experiments and robot one said, I'm doing experiment 10. The other robot, okay, I'll do
experiment one then. And they communicated via Twitter and then. Publicly or GMs? Yeah, yeah, yeah.
Oh, can you maybe quickly explain what the game of Hex is?
Yeah, so it's a basically a hexagonal board and you try and basically, you color each
hexing, each element on the board at each hexagon and you try and get from one side to the other
and the other one tries to block you. We, how are they connected? So what are the robots?
So it's a chemical. Yeah, let's go back. So the two robots, each robot was doing
dye chemistry. So making RGB, red, green, blue, red, green, blue, red, green, blue.
And they could just choose from experiments to do red, green, blue. Initially, I said to my group,
we need to make two chemical robots that play chess. And my group were like,
that's too hard. No, go away. But anyways, we had the robot.
People listening to this should probably know that Lee Cronin is an amazing group of brilliant
people. He's exceptionally well published. He's written a huge number of amazing papers. Whenever
he calls himself stupid and is a sign of humility. And I deeply respect that and
appreciate it. So people listening to this should know this is a, this is a world-class
scientist who doesn't take himself seriously, which I really appreciate and love. Anywho,
talking about serious science, we're back to your group rejecting your idea of chemical robots
playing chess via dyes. So you went to a simpler game of hex. Okay. So what else?
The team that did it were brilliant. I really take the, I think they still have PTSD from
doing it. Cause I said, this is a workshop. What I'd often do is I have about 60 people on my team.
And occasionally before lockdown, I would say, I'm a bit bored. We're going to have a workshop
on something. Who wants to come? And they're basically about 20 people turn up to my office.
And I say, we're going to do this mad thing. And then the, it would just self-organize. And
some of them would say, no, I'm not doing this. And then you get, you get left with the happy
dozen. And what we did is we built this robot and doing dye chemistry is really easy. You can
just take two molecules, react them together and change color. And what I wanted to do is have a
palette of different molecules. You could react commentarily and get different colors. So you
got two robots. And I went, wouldn't it be cool if the robots basically shared the same list of
reactions to do? And they said, oh, I'm, and because of, then you could do a kind of multi-core
chemistry, like they weren't, so you could have two chemical reactions going on at once. And
they could basically outsource the problem. But they're sharing the same tape. Exactly. So robot
one would say, I'm going to do, I'm going to do experiment one. And the other robot says,
I'll do experiment a hundred. And then they could cross it off. But I wanted to make it.
That's brilliant, by the way. That is genius. Sorry. Well, I wanted to make it groovier. And I
said, look, let's have them competing to make, so playing a game of hex. And so when the robot
does a, it does an experiment, and the more blue the dye, the more it gets to the chart, the higher
chance it gets to make the move it wants on the hex board. So if it gets a red color is like it's
gets down weighted in the other robot. And so what the robots could do is they play each player move.
And because the fitness function or the optimization function was to make the color blue,
they started to invent reactions we didn't weren't on the list. And they did this by not
cleaning, because we made cleaning optional. So when one robot realized if it didn't clean its
pipes, it could get blue more quickly. And the other robot realized that. So it was like getting
dirty as well. I didn't tell the consequences of super intelligence. Okay. But that was the game.
And we communicate through Twitter, though, they were doing it through Twitter and Twitter
bland them a couple of times. I said, come on, you've got a couple of robots doing chemistry.
It's really cool to stop banning them. But in the end, they had, we had to take them off Twitter
and they just communicated via a server, because it was just, there were people saying you can
still find it cronin lab one and cronin lab two on Twitter. And it was like make move, wait,
you know, mix A and B, wait 10 seconds, answer blue, you know, I really find it super compelling
that you would have a chemical entity that's communicating with the world.
That was one of the things I want to do in my origin of life reaction, right, is basically
have a, have a reactor that's basically just randomly enumerating through chemical space
and have some kind of cycle. And then read out what the molecules reading out using a mass
spectrometer, and then convert that to text and publish it on Twitter. And then wait until it says
I'm alive. I reckon that would get, I reckon that that Twitter account will get a lot of
followers. Yeah. And I'm still trying to convince my group that we should just make an origin of
life Twitter account where it's going blue and it's like, hello, testing. I'm here.
Well, I'll share it. I like it. I particularly enjoy this idea
of a non human entity communicating with the world via a human design social network. It's
quite a beautiful idea. How we were talking about
CAs existing outside the human mind. Yeah. So I really admire Stephen Wolfram. I think he was
a genius, clearly a genius. And trapped in is actually is like a problem with being so smart
if you get trapped in your own, you know, mind, right? And I've, I try to actually, I try to
convince Stephen that assembly theory wasn't nonsense. He was like, no, it's just nonsense.
I was a little bit sad by that. So nonsense applied, even if we applied to the simple
construct of a one dimensional cellular automata, for example. Yeah. Yeah. But I mean,
actually, maybe I'm doing myself a bit too down. It was, it was, it was just as a theory was coming
through and I didn't really know how to explain it. But, but we are going to use assembly theory
and CAs instead of automata. But I'm, I wanted to, what I was really curious about is why
people are marvel. I mean, you marvel at CAs and they're complex. And I said, well,
hang on that complexity is baked in because if you play the game of life
in a CA, you have to run it on a computer. You have to have a, you have to do a number of
operations put in the boundary conditions. So is it surprising that you get this structure out?
Is it manufactured by the boundary conditions? And, and it is interesting because I think
cellular automata running them is teaching me something about what real numbers are and aren't.
And I haven't quite got there yet. I was playing on the aeroplane coming over. I'm just realized
I have no idea what real numbers are really. And I was like, well, I do actually have some
notion of what real numbers are. And I think thinking about real numbers as functions,
rather than numbers is more appropriate. And then if you then apply that to CAs,
then you're saying, well, actually, why am I seeing this complexity in this, in this rule?
Is it, is it, you know, is it, is it, you've got this deterministic system,
and yet you get this incredible structure coming out? Well, isn't that what you'd get with any real
number as you, as you apply it as a function, and you're trying to read it out to an arbitrary
position? And I wonder if CAs are just helping me, well, my misunderstanding is CAs might be
helping me understand them in terms of real numbers. I don't know what you think.
Well, the function is, but the devil's in the function. Like, which is the function that's
generating your real number? Like that, it seems like it's very important, the specific
algorithm of that function, because some lead to something super trivial, some lead to something
that's all chaotic, and some lead to things that are just walked that fine line of complexity.
Yeah, I think we agree. So let's take it back a second. So take the logistic map or something,
logistic equation, where you have this equation, which is, you don't, you don't know what's going
to happen to n plus one. But once you've done n plus one, you know, full time, you can't predict it.
For me, CAs and logistic equation feel similar. And, and I think what's incredibly interesting,
and I share your kind of wonder at running a CA, but also I'm saying, well,
what is it about the boundary conditions and the way I'm running that calculation?
So in my group, with my team, we actually made a chemical CA. We made Game of Life. We actually
made a physical grid. I haven't been able to publish this paper. It's been trapped in purgatory
for a long time. But you wrote up a paper on how to do a chemical formulation of the game of life,
which we made a chemical computer and a little cells. And I was playing Game of Life.
With the BZ reactions, each cell would pulse on and off, on and off, on and off.
We have little stirra bars, and we have little gates. And we actually played Conway's Game of
Life in there. And we got structures in that, we got structures in that game from the chemistry
that you wouldn't expect from the actual CA. So that's kind of cool in that,
because they're, they're, they're interacting outside of the cells. So what's happening is
you're getting annoyed. So the thing is that you've got this BZ reaction that gives on off,
on off, on off, but there's also a wake. And those wakes constructively interfere,
and it's such a non-trivial way that it's a non-deterministic. And the non-determinism
in, in, in the system gives very rich dynamics. And I was wondering if I could physically make
