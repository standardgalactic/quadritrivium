You've invented Bayesian networks that look awfully a lot like they express something like
causation, but they don't, not necessarily. So how do we turn Bayesian networks into
expressing causation? How do we build causal networks? A causes B, B causes C. How do we
start to infer that kind of thing? We start asking ourselves a question. What are the factors
that would determine the value of X? X could be blood pressure, death, hungry, hunger.
But these are hypotheses that we propose first. Hypothesis, everything which has to do with
causality comes from a theory. The difference is only how you interrogate the theory that you have
in your mind. So it still needs the human expert to propose. Right. You need the human expert to
specify the initial model. Initial model could be very qualitative. Just who listens to whom?
By whom listen to I mean one variable, listen to the other. So I say, okay, the tide is listening
to the moon and not to the rooster crow. And so far this is our understanding of the world in
which we live. Scientific understanding of reality. We have to start there because if we
don't know how to handle cause and effect relationship, when we do have a model and we
certainly do not know how to handle it when we don't have a model. So let's start first.
In AI, slogan is representation first, discovery second. But if I give you all the information
that you need, can you do anything useful with it? That is the first representation. How do you
represent it? I give you all the knowledge in the world. How do you represent it? When you
represent it, I ask you, can you infer X or Y or Z? Can you answer certain queries? Is it complex?
Is it polynomial? All the computer science exercises we do once you give me a representation
for my knowledge. Then you can ask me, now I understand how to represent things. How do I
discover them? That's the second thing. So first of all, I should echo the statement that
mathematics and the current, much of the machine learning world has not considered
causation that A causes B just in anything. So that seems like a not obvious thing that you
think we would have really acknowledged it, but we haven't. So we have to put that on the table.
Knowledge, how hard is it to create a knowledge from which to work?
In certain area, it's easy because we have only four or five major variables.
And an epidemiologist or an economist can put them down,
what minimum wage, unemployment, policy, X, Y, Z, and start collecting data and quantify the
parameters that were left unquantified with the initial knowledge. That's the routine work
that you find in experimental psychology, in economics, everywhere, in the health science,
that's a routine thing. But I should emphasize, you should start with the research question,
what do you want to estimate? Once you have that, you have to have a language of expressing
what you want to estimate. You think it's easy? No. So we can talk about two things. I think
one is how the science of causation is very useful for answering certain questions.
And then the other is, how do we create intelligent systems that need to reason with causation?
So if my research question is, how do I pick up this water bottle from the table?
All the knowledge is required to be able to do that. How do we construct that knowledge base?
Do we return back to the problem that we didn't solve in the 80s with expert systems? Do we have
to solve that problem of automated construction of knowledge? You're talking about the task of
eliciting knowledge from an expert. Task of eliciting knowledge from an expert or the self-discovery
of more knowledge, more and more knowledge. So automating the building of knowledge as much as
possible. It's a different game in the causal domain because it's essentially the same thing.
You have to start with some knowledge and you're trying to enrich it. But you don't enrich it
by asking for more rules. You enrich it by asking for the data, to look at the data
and quantifying and ask queries that you couldn't answer when you started.
You couldn't because the question is quite complex and it's not within the capability
of ordinary cognition, of ordinary person or ordinary expert even, to answer.
So what kind of questions do you think we can start to answer?
Even a simple one. I start with easy one.
Let's do it.
What's the effect of a drug on recovery? What are the aspirin that caused my headache to
be cured or what is the television program or the good news I received?
This is already a difficult question because it's find the cause from effect. The easy one is find
the effect from cause. That's right. So first you construct a model saying that this is an
important research question. This is an important question. I didn't construct a model yet. I just
said it's an important question. And the first exercise is express it mathematically. What do
you want to do? Like if I tell you what will be the effect of taking this drug? You have to
say that in mathematics. How do you say that? Can you write down the question? Not the answer.
I want to find the effect of the drug on my headache. Write down. Write it down.
That's where the do calculus comes in. Yes. Do operator. What do you do operator?
Do operator. Yeah. Which is nice. It's the difference in association and intervention. Very
beautifully sort of constructed. Yeah. So we have a do operator. So do calculus connected on the
operator itself connects the operation of doing to something that we can see.
Right. So as opposed to the purely observing you're making the choice to change a variable.
That's what it expresses. And then the way that we interpret it and the mechanism by which we
take your query and we translate it into something that we can work with is by giving it semantics.
Saying that you have a model of the world and you cut off all the incoming error into X
and you're looking now in the modified mutilated model you ask for the probability of Y.
That is interpretation of doing X because by doing things you liberate them from all
influences that acted upon them earlier and you subject them to the tyranny of your muscles.
So you remove all the questions about causality by doing them.
So there's one level of questions. Yeah. Answer questions about what will happen if you do things.
If you do. If you drink the coffee. If you take the asthma. Right. So how do we get the
once how do we get the doing data? Ha. Now the question is if we cannot one experiment.
Right. Then we have to rely on observational study. So first we could start to interrupt.
We could run an experiment where we do something where we drink the coffee and don't and this
the the do operator allows you to sort of be systematic about expressing to imagine
how the experiment will look like even though we cannot physically and technologically conducted.
I'll give you an example. What is the effect of blood pressure on mortality?
I cannot go down into your vein and change your blood pressure. But I can ask the question
which means I can even have a model of your body. I can imagine the effect of your how the
blood pressure change will affect your mortality. How I go into the model and I conduct this
surgery about the blood pressure. Even though physically I can do I cannot do it.
Let me ask the quantum mechanics question. Does the doing change the observation?
Meaning the surgery of changing the blood pressure is I mean no the surgery is
very delicate. It's very infinitely delicate. Incisive and delicate. Which means do means
do X means I'm going to touch only X directly into X. So that means that I change only things
which depends on X by virtue of X changing. But I don't depend things which are not depends
on X. Like I wouldn't change your sex or your age I just change your blood pressure.
So in the case of blood pressure it may be difficult or impossible to construct such an
experiment. No physically yes but hypothetically no. Hypothetically no. If we have a model that
is what the model is for. So you conduct surgeries on a model you take it apart put it back that's
the idea of a model. It's the idea of thinking counter factually imagining and that's the idea
of creativity. So by constructing that model you can start to infer if the higher the
blood pressure leads to mortality which increases or decreases. I construct the model I can still
not answer it. I have to see if I have enough information in the model that would allow me
to find out the effects of intervention from a non-interventional study from observation
hence of study. So what's needed? You need to have assumptions about who affects whom.
If the if the graph had a certain property the answer is yes you can get it from
observational study. If the graph is too messy bushy bushy the answer is no you cannot. Then you
need to find either different kind of observation that you haven't considered or one experiment.
So basically does that put that puts a lot of pressure on you to encode wisdom into that graph?
Correct but you don't have to encode more than what you know. God forbid if you put the like
economists are doing that they call identifying assumptions they put assumptions even they don't
prevail in the world they put assumptions so they can identify things. But the problem is yes
beautifully put but the problem is you don't know what you don't know. So you know what you
don't know because if you don't know you say it's possible it's possible that x affect the traffic
tomorrow. It's possible you put down an arrow which says every arrow in the graph says it's possible.
So there's not a significant cost to adding arrows that the more arrow you add the better the less
like you are to identify things from purely observational data. So if the whole world is bushy
and everybody affects everybody else the answer is you can answer it ahead of time. I cannot
answer my query from observational data. I have to go to experiments.
So you talk about machine learning is essentially learning by association or reasoning by association
and this due calculus is allowing for intervention like that word like action. So you also talk
about counterfactuals and trying to sort of understand the difference in counterfactuals
intervention. First of all what is counterfactuals and why are they useful?
Why are they especially useful as opposed to just reasoning what affect actions have?
Counterfactual contains what we normally call explanations. Can you give an example?
If I tell you that acting one way affects something I didn't explain anything yet
but if I ask you was it the aspirin that cured my headache I'm asking for explanation what cured
my headache and putting a finger on aspirin provided explanation. It was aspirin that was
responsible for your headache going away. If you didn't take the aspirin you would still have a headache.
So by saying if I didn't take aspirin I would have a headache you're thereby saying that aspirin is
the thing that removes the headache. Yes but you have to have another important information.
I took the aspirin and my headache is gone. It's very important information now I'm reasoning
backward and I said what is the aspirin? Yeah by considering what would have happened if everything
else is the same but I didn't take aspirin. That's right so you know that things took place you know
Joe killed Schmo and Schmo would would be alive had John not used his gun.
So that is the counterfactual it had a conflict here or clash between observed fact
that he did shoot and the hypothetical predicate which says had he not shot you have a clash
logical clash they cannot exist together that's the counterfactual and that is the source of our
explanation of our the idea of responsibility regret and free will.
Yes it certainly seems that's the highest level of reasoning right yes and physicists do it all the
time. Who does it all the time? Physicists. Physicists. In every equation of physics
let's say you have a Hooke's law and you put one kilogram on the spring and the spring is
one meter and you say had this weight been two kilogram the spring would have been twice as long.
It's no problem for physicists to say that except that mathematics is only in the form of equation
okay equating the weight proportionality constant and the length of the string.
So you don't have the asymmetry in the equation of physics although every physicist thinks
counterfactually. Ask high school kids had the weight been three kilograms what will be the
length of the spring they can answer it immediately because they do the counterfactual processing
in their mind and then they put it into equation algebraic equation and they solve it okay but
the robot cannot do that. How do you make a robot learn these relationships? Why do you
put learn? Suppose you tell him can you do it? So before you go learning yeah you have to ask
yourself suppose I give him all the information okay can the robot perform a task that I ask him
to perform? Can he reason and say no it wasn't the aspirin it was the good news you received on the
phone. Right because well unless the robot had a model a causal model of the world.
Right right. I'm sorry I have to linger on this. But now we have to linger and we have to say how
do we do it? How do we build? Yes. How do we build a causal model without a team of human experts?
No running around. Why don't you go to learning right away? You're too much involved with learning.
Because I like babies babies learn fast I'm trying to figure out how they do it. Good.
That's another question how do the babies come out with the counterfactual model of the world
and babies do that. They know how to play with in the crib they know which balls hits another one
and so they learn it by playful manipulation of the world. Yes. There's a simple world
involved only toys and balls and chimes but it's a if you think about it's a complex world.
We take for granted how complicated. And the kids do it by playful manipulation plus
parents guidance, pure wisdom and he'll say they meet each other and they say you
shouldn't have taken my toy. Right. But and they these multiple sources of information they're
able to integrate. So the challenge is about how to integrate how to form these causal
relationships from different sources of data. Correct. So how much information is it to play
how much causal information is required to be able to play in the crib with different objects?
I don't know. I haven't experimented with the crib. Okay not a crib picking up manipulating
physical objects on this very opening the pages of a book all the tasks physical manipulation
tasks. Do you have a sense because my sense is the world is extremely complicated. It's
extremely complicated. I agree and I don't know how to organize it because I've been spoiled by easy
problems such as cancer and death. First we have to start. No but it's easy the easy sense that you
have only 20 variables and they are just variables are not mechanics. It's easy. You just put them
on the graph and they speak to you. And you you're providing a methodology for letting them speak.
Yeah. I'm working only in the abstract. The abstract knowledge in knowledge out data in between.
Now can we take a leap to trying to learn in this very when it's not 20 variables but 20 million
variables trying to learn causation in this world not learn but somehow construct models. I mean it
seems like you would only have to be able to learn because constructing it manually would be too
difficult. Do you have ideas of I think it's a matter of combining simple models from many many
sources from many many disciplines and many metaphors. Metaphors are the basics of human
intelligence and basis. Yeah. So how do you think of about a metaphor in terms of its use in human
intelligence? Metaphors is an expert system. An expert it's mapping problem
with which you are not familiar to a problem with which you are familiar. Like I give a good
example the Greek believed that the sky is an opaque shell. It's not really an infinite space.
It's an opaque shell and the stars are holes poked in the shells through which you see the eternal
light. It was a metaphor. Why? Because they understand how you poke holes in the shells.
They're not they were not familiar with infinite space. And so and we are walking on a
shell of a turtle and if you get too close to the edge you're going to fall down to Hades or
whatever. Yeah. Yeah. And there's a metaphor. It's not true but this kind of metaphor enables
Aristoteles to measure the radius of the earth because he said come on. If we are walking on
a turtle shell then the ray of light coming to this angle will be different. This place
will be different angle that's coming to this place. I know the distance. I'll measure the two
angles and then I have the radius of the shell of the of the turtle and he did and he found his
measurements were very close to the measurements we have today through the year
what six thousand and seven hundred seven hundred kilometers of the earth. That's something that
would not occur to Babylonian astronomer even though the Babylonian experiments were the
machine learning people of the time. They fit curves and they could predict the eclipse of the
moon much more accurately than the Greek because they fit curve. That's a different metaphor.
Something that you're familiar with a game a turtle shell.
What does it mean if you are familiar? Familiar means that answers to certain questions are
explicit. You don't have to derive them. And they were made explicit because somewhere in the past
you've constructed a model of that. You're familiar with so the child is familiar with
billiard balls. So the child could predict that if you let loose of one ball the other one will
bounce off. You obtain that by familiarity. Familiarity is answering questions and you store
the answer explicitly. You don't have to derive them. So this is idea of a metaphor. All our life
all our intelligence is built around metaphors mapping from the unfamiliar to the familiar.
