But the marriage between the two is a tough thing which we haven't yet been able to
algorithmatize. So you think of that process of using metaphor to leap from one place to another
we can call it reasoning. Is it a kind of reasoning? It is reasoning by metaphor metaphor.
Do you think of that as learning? So learning is a popular terminology today in a narrow sense.
It is. It is. It is definitely. So you may not. Okay. Right. One of the most important learnings
taking something which theoretically is derivable and store it in accessible format. I'll give you
an example. Chess. Okay. Finding winning starting moving chess is hard. But there is an answer.
Either the user will move for white or there isn't or the user will draw. Okay. So it is.
The answer to that is available through the rule of the games. But we don't know the answer. So
what does the chess master have that we don't have? He has stored explicitly an evaluation of
certain complex pattern of the board. We don't have it ordinary people like me. I don't know about
you. I'm not a chess master. So for me, I have to derive things that for him is explicit. He has
seen it before or you've seen the pattern before or similar pattern using metaphor. Yeah. And he
generalized and said, don't move. It's a dangerous move.
It's just that not in the game of chess, but in the game of billiard balls, we humans are able to
initially derive very effectively and then reason by metaphor very effectively and make it look so
easy and it makes one wonder how hard is it to build it in a machine. So in your sense,
how far away are we to be able to construct? I don't know. I'm not a futurist. I can all I can
tell you is that we are making tremendous progress in the causal reasoning domain. Something that I
even dare to call it revolution, the causal revolution, because what we have achieved in
the past three decades is something that dwarf everything that was derived in the entire history.
So there's an excitement about current machine learning methodologies and there's really important
good work you're doing in causal inference. Where do the what is the future? Where do these
worlds collide and what does that look like? First, they're going to work without collisions.
It's going to work in harmony. Harmony is not the human is going to jumpstart
in the exercise by providing qualitative non-committing
models of how the universe works. How in reality the domain of discourse works. The machine is
going to take over from that point of view and derive whatever the calculus says can be derived,
namely quantitative answer to our questions. These are complex questions. I'll give you some
example of complex questions that will bugle your mind if you think about it. You take result of
studies in diverse populations under diverse conditions and you may infer the cause effect
of a new population which doesn't even resemble any of the one studied. You do that by do calculus,
you do that by generalizing from one study to another. See what's common with Beato? What is
different? Let's ignore the differences and pull out the commonality and you do it over maybe 100
hospitals around the world. From that you can get really mileage from big data. It's not only
you have many samples, you have many sources of data. So that's a really powerful thing I think
for especially for medical applications. I mean cure cancer, right? That's how from data you can
cure cancer. So we're talking about causation which is the temporal relationship between things.
Not only temporal, it was structural and temporal. Temporal presence by itself cannot replace causation.
Is temporal precedence the error of time in physics? It's important and necessary. It's
important. But it's efficient, yes. Is it? Yes, I never see the cause propagate backward.
But if we use the word cause, but there's relationships that are timeless, I suppose that's
still forward in the era of time. But are there relationships, logical relationships
that fit into the structure? Sure, do calculus is logical relationship.
That doesn't require a temporal. It has just the condition that
you're not traveling back in time. Yes, correct. So it's really a generalization of
a powerful generalization of what? Bullion logic. Bullion logic. Yes.
That is simply put and allows us to reason about the order of events, the source.
It's not about between but not deriving the order of events. We are given cause-effect relationship.
They ought to be obeying the time precedence relationship. We are given that and now that
we ask questions about other cause relationship that could be derived from the initial ones,
but were not given to us explicitly. Like the case of the firing squad I gave you
in the first chapter. And I asked what if rifleman A declined to shoot? Would the prisoner still be
dead? Declined to shoot, it means that he disobeyed order. And the rule of the games were that he is
obedient and marksman. That's how you start. That's the initial order. But now you ask
questions about breaking the rules. What if he decided not to pull the trigger? He just became
a pacifist. You and I can answer that. The other rifleman would have killed him.
Okay? I want the machine to do that. Is it so hard to ask the machine to do that?
It's such a simple task. They have a calculus for that. Yes. But the curiosity and the natural
curiosity for me is that yes, you're absolutely correct and important and it's hard to believe
that we haven't done this seriously extensively already a long time ago. So this is really important
work. But I also want to know, maybe you can philosophize about how hard is it to learn.
Okay, let's assume we're learning. We want to learn it. Okay? We want to learn. So what are we doing?
We put a learning machine that watches execution trials in many countries and many locations.
Okay? All the machine can learn is to see shot or not shot. Dead, not dead.
Court issued an order or didn't. Okay? Just the facts. From the fact you don't know who listens to
whom. You don't know that the condemned person listened to the bullets, that the bullets are
listening to the captain. Okay? All we hear is one command, two shots dead. Okay? A triple of
variable. Yes, no. Yes, no. Okay. From that you can learn who listens to whom and you can answer
the question. No. Definitively no. But don't you think you can start proposing ideas for humans to
review? You want machine to learn, right? You want a robot. So robot is watching trials like that.
200 trials. And then he has to answer the question, what if rifleman A, he framed from shooting?
Yeah. So how to do that? That's exactly my point. That looking at the facts don't give you the
strings behind the facts. Absolutely. But do you think of machine learning as is currently defined
as only something that looks at the facts and tries to... Right now they only look at the facts.
Yeah. So is there a way to modify in your sense? Playful manipulation. Playful manipulation.
Yes. Once in a while. Doing the interventionist kind of thing. Yes. Intervention. But it could
be at random. For instance, the rifleman is sick that day or he just vomits or whatever. So machine
can observe this unexpected event which introduced noise. The noise still has to be random to be able
to relate it to randomized experiment. And then you have observational studies from which to
infer the strings behind the facts. It's doable to a certain extent. But now that we expert in what
you can do once you have a model, we can reason back and say what kind of data you need to build a
model. Got it. So I know you're not a futurist, but are you excited? Have you, when you look back at
your life, long for the idea of creating a human level intelligence system? Yeah. I'm driven by that.
All my life, I'm driven just by one thing.
But I go slowly. I go from what I know to the next step incrementally.
So without imagining what the end goal looks like, do you imagine
what an end goal is going to be a machine that can answer sophisticated questions,
counterfactuals of regret, compassion, responsibility, and free will.
So what is a good test? Is a touring test a reasonable test? Free will doesn't exist yet.
How would you test free will? So far we know only one thing.
If robots can communicate with reward and punishment among themselves,
and hitting each other on the wrist and say you shouldn't have done that,
playing better soccer because they can do that. What do you mean because they can do that?
Because they can communicate among themselves. Because of the communication they can do? Because
they communicate like us. Reward and punishment. Yes, you didn't pass the ball the right time.
And so therefore you're going to sit on the bench for the next two. If they start communicating
like that, the question is, will they play better soccer? As opposed to what? As opposed to what
they do now, without this ability to reason about reward and punishment, responsibility.
And how far I can only think about communication. Communication is
not necessarily natural language, but just communication. Just communication. And that's
important to have a quick and effective means of communicating knowledge. If the coach tells
you you should have passed the ball, ping, he conveys so much knowledge to you as opposed to what?
Go down and change your software. That's the alternative. But the coach doesn't know your
software. So how can the coach tell you you should have passed the ball? But our language
is very effective. You should have passed the ball. You know your software. You tweak the right
module. Okay. And next time you don't do it. Now that's for playing soccer or the rules are well
defined. No, they're not well defined. When you should pass the ball is not well defined. No, it's
very soft. Very noisy. Yes, you have to do it under pressure. It's art. But in terms of aligning
values between computers and humans, do you think this cause and effect
type of thinking is important to align the values, values, morals, ethics under which
the machines make decisions? Is the cause effect where the two can come together?
Cause effect is necessary component to build a ethical machine. Because the machine has to
empathize to understand what's good for you to build a model of your of you as a recipient,
which should be very much what what is compassion. They imagine that you
suffer pain as much as me as much as me. I do have already a model of myself.
Right. So it's very easy for me to map you to mine. I don't have to rebuild the model.
It's much easier to say, oh, you're like me. Okay. Therefore, I would not hate you.
And the machine has to imagine it has to try to fake to be human essentially. So you can imagine
that you're that you're like me. Right. And moreover, who is me? That's the fact that that's
consciousness. They have a model of yourself. Where do you get this model? You look at yourself
as if you are a part of the environment. If you build a model of yourself versus the environment,
then you can say, I need to have a model of myself. I have abilities. I have desires and so
forth. Okay. I have a blueprint of myself. Not the full detail because I cannot get the halting
problem. But I have a blueprint. So on that level of a blueprint, I can modify things.
I can look at myself in the mirror and say, hmm, if I change this, tweak this model,
I'm going to perform differently. That is what we mean by free will.
And consciousness. What do you think is consciousness? Is it simply self-awareness?
So including yourself into the model of the world? That's right. Some people tell me,
no, this is only part of consciousness. And then they start telling me what they really
mean by consciousness and I lose them. For me, consciousness is having a blueprint of your
software. Do you have concerns about the future of AI? All the different trajectories of all
of our research? Yes. Where's your hope? Where the movement heads? Where are your concerns?
I'm concerned because I know we are building a new species that has the capability of exceeding
our, exceeding our capabilities and can breed itself and take over the world. Absolutely.
It's a new species that is uncontrolled. We don't know the degree to which we control it. We don't
even understand what it means to be able to control this new species. So I'm concerned.
I don't have anything to add to that because it's such a gray area, that unknown. It never
happened in history. The only, the only time it happened in history was evolution with human
being. It wasn't very successful, was it? Some people say it was a great success.
For us it was, but a few people along the way, a few creatures along the way would not agree.
So it's just because it's such a gray area, there's nothing else to say.
We have a sample of one. Sample of one. It's us. But some people would look at you and say
yeah, but we were looking to you to help us make sure that sample two works out okay.
Actually, we have more than a sample of one. We have theories and that's good. We don't need to
be statisticians. So sample of one doesn't mean poverty of knowledge. It's not. Sample of one
plus theory, conjectural theory of what could happen. That we do have. But I really feel helpless
in contributing to this argument because I know so little and my imagination is limited
and I know how much I don't know and I, but I'm concerned.
You're born and raised in Israel. Born and raised in Israel, yes.
And later served in Israel military, Defense Forces. In the Israel Defense Force.
What did you learn from that experience? From this experience?
There's a kibbutz in there as well. Yes, because I was in the Nakhal, which is
a combination of agricultural work and military service.
We were supposed, I was really idealist. I wanted to be a member of the kibbutz throughout my life
and to live a communal life. And so I prepared myself for that. Slowly, slowly, I wanted a greater
challenge. So that's a far world away. But I learned from that. It was a miracle.
It was a miracle that I served in the 1950s. I don't know how we survived.
The country was under austerity. It tripled its population from 600,000 to a million point eight
when I finished college. No one went hungry. Austerity, yes. When you wanted to buy, to make an
omelette in a restaurant, you had to bring your own egg. And the imprisoned people from bringing
food from the farming here, from the villages to the city. But no one went hungry. And I always
add to it. And higher education did not suffer any budget cuts. They still invested in me,
in my wife, in our generation to get the best education that they could. So I'm really
grateful for the opportunity. And I'm trying to pay back now. It's a miracle that we survived
the war of 1948. They were so close to a second genocide. It was all in plant. But we survived
it by miracle. And then the second miracle that not many people talk about, the next phase,
how no one went hungry. And the country managed to triple its population. You know what it means
to imagine the United States going from 350 million to a million. And believe.
That's a really tense part of the world. It's a complicated part of the world. Israel and all
around. So religion is at the core of that complexity. One of the components. Religion is a
strong motivating course to many, many people in the Middle East. Yes.
In your view, looking back, is religion good for society?
That's a good question for robotic, you know. There's echoes of that question.
A quick robot with a religious belief. Suppose we find out or we agree that religion is good to
you to keep you in line. Should we give the robot the metaphor of a god? The metaphor of the robot
will get it without us also. Why? The robot will reason by metaphor. And what is the most primitive
metaphor a child grows with? Mother smile, father teaching, father image, and mother image. That's
God. So whether you want it or not, the robot will, assuming that the robot is going to have a
mother and a father, it may only have a programmer who doesn't supply warmth and discipline.
Well, discipline it does. So the robot will have this, a model of the trainer. And everything
that happens in the world, cosmology and so on, is going to be mapped into the programmer.
That's God. Man. The thing that represents the origin of everything for that robot.
That's the most primitive relationship. So it's going to arrive there by metaphor.
And so the question is if overall that metaphor has served us well as humans.
I really don't know. I think it did. But as long as you keep in mind, it's only a metaphor.
So if you think we can, can we talk about your son? Yes, yes. Can you tell his story?
A story? Well, Daniel. The story is known. He was abducted in Pakistan by al-Qaeda driven
sect and under various pretenses. I don't even pay attention to what the pretence will.
Originally, they wanted to have the United States deliver some promised airplanes.
It was all made up and all this demands were bogus. I don't know really, but eventually he was
executed in front of a camera. At the core of that is hate and intolerance.
At the core? Yes, absolutely. We don't really appreciate the depth of the hate at which
billions of peoples are educated. We don't understand it. I just listened recently
to what they teach you in Mogadishu.
When the water stopped in the tap, we knew exactly who did it, the Jews.
We didn't know how, but we knew who did it. We don't appreciate what it means to us.
The depth is unbelievable. Do you think all of us are capable of evil?
And the education, the indoctrination is really what creates evil? Absolutely,
we are capable of evil. If you are indoctrinated sufficiently long and in depth, we are capable of
