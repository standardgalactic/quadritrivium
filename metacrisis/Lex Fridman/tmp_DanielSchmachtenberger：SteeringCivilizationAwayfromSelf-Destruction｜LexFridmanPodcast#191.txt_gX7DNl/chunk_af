level of superpowers while building up the military capacity for much much much worse
war the entire time and then now we're at this new phase where the things that allowed us to make
it through the nuclear power are not the same systems that will let us make it through the next
stage so what is this next post Bretton Woods how how do we become safe vessels safe stewards
of many different types of exponential technology is uh a key question when we're thinking about
x-risk okay so and i'd like to try to answer the how a few thought a few ways but first
on the mutually assured destruction do you give credit to the idea of two superpowers
not blowing each other up with nuclear weapons to the simple game theoretic model of mutually
assured destruction or something you've said previously this idea of inverse correlation
which i tend to believe between the now you were talking about tech but i think it's
maybe broadly true the inverse correlation between competence and propensity for destruction so
the better the the the bigger your weapons not because you're afraid of mutually assured
self-destruction but because we're human beings and there's a deep moral fortitude there that's
somehow aligned with competence and being good at your job that like it's very hard to be uh
a psychopath and be good at killing at scale is do you share any of that intuition kind of
i think most people would say that alexander the great and gang is con and napoli and were
effective people that were good at their job uh that were actually maybe asymmetrically
good at being able to organize people and do certain kinds of things that were
pretty oriented towards certain types of destruction or pretty willing to
maybe they would say they were oriented towards empire expansion but pretty willing to
commit certain acts of destruction in the name of it what are you worried about the gang is con
or you could argue he's not a psychopath uh that are you worried about gang is con are you
worried about hitler are you worried about a terrorist who is has a very different ethic which
is not even for uh it's not trying to preserve and build and expand my community it's more about
just destruction in itself is the goal i think the thing that you're looking at that i do agree
with is that there's a psychological disposition towards construction right and a psychological
disposition more towards destruction obviously everybody has both and can toggle between both
and oftentimes one is willing to destroy certain things we have this idea of creative destruction
right willing to destroy certain things to create other things and utilitarianism and trolley
problems are all about exploring that space and the idea of war is all about that and i am trying
to create something for our people and it requires destroying some other people um
sociopathy is a funny topic because it's possible to have very high fealty to your in group and work
on perfecting the methods of torture to the out group um at the same time because you can dehumanize
and then remove empathy um and i would also say that there are types so the reason the thing that
gives hope about the orientation towards construction and destruction being a little different in
psychologies is what it takes to build really catastrophic tech even today where it doesn't
take what it took to make a new a small group people could do it takes still some real technical
knowledge that required having studied for a while and some then building capacity and
there's a question of is that psychologically inversely correlated with the desire to
damage civilization meaningfully uh a little bit a little bit i think um i think a lot i think
it's actually i mean this is the conversation i had like what i think offline with dan carlin
which is like it's pretty easy to come up with ways that any competent like i can come up with a
lot of ways to hurt a lot of people and it's pretty easy like i alone could do it and
like there's a lot of people as smarter smarter than me at least in the creation of explosives
why are we not seeing more insane mass murder i i think there's something
fascinating and beautiful about this yes and it does have to do with some deeply pro-social types
of characteristics in humans and um but when you're dealing with very large numbers you don't
need a whole lot of a phenomena and so then you start to say well what's the probability that x
won't happen this year then won't happen in the next two years three years four years and then how
many people are doing destructive things with lower tech and then how many of them can get
access to higher tech that they didn't have to figure out how to build so uh when i can get
commercial tech and maybe i don't understand tech very well but i understand it well enough to
utilize it not to create it and i can repurpose it when we saw that commercial drone with a homemade
thermite bomb hit the ukraine ukrainian munitions factory and do the equivalent of an incendiary
bomb level of damage that's just home tech that's just simple kind of thing and so the question is
not what is does it stay being a small percentage of the population the question is does can you
bind that phenomena nearly completely and especially now when you as you start to get into
bigger things crisper gene drive technologies and various things like that um can you bind it
completely long term over what period of time not perfectly though that's the thing i'm trying i'm
trying to say that there is some let's call it uh let's uh a random word love that's inherent in
that's core to human nature that's preventing destruction at scale and you're saying yeah
but there's a lot of humans there's going to be eight plus billion and then there's a lot of seconds
in the day to come up with stuff there's a lot of pain in the world that can lead to uh distorted
view of the world such that you want to channel that pain into the destruction all those kinds of
things and it's only a matter of time that anyone individual can do large damage especially as we
create uh more and more democratized decentralized ways to deliver that damage even if you don't
know how to build the initial weapon you can but the thing is it seems like it's a race between
the cheapening of destructive weapons and the capacity of humans to express their love
towards each other and it's a race that's so far i know on twitter you it's not popular to say but
love is winning okay so what is the argument that love is going to lose here against nuclear
weapons of biotech and and ai and uh and drones okay i'm gonna comment the end of this to a how
love wins so i just want you to know that that's where i'm oriented that's the end but i'm i'm
gonna argue against why that is a given because it because it's not a given i don't believe and
i think this is like a good romantic comedy so you're gonna create drama right now but it will
end with a happy ending well it's because it's only a happy ending if we actually understand
the issues well enough and take responsibility to shift it do i believe like there's a reason why
there's so much more dystopic sci-fi than protopic sci-fi and the in the summer protopic sci-fi
usually requires magic is because or at least magical tech right dilithium crystals and warp
drives and stuff because it's very hard to imagine people like the people we have been in the history
books with exponential type technology and power that don't eventually blow themselves up they
make good enough choices as stewards of their environment and their comments and and each
other and etc so like it's easier to think of scenarios where we blow ourselves up than it
is to think of scenarios where we avoid every single scenario where we blow ourselves up and
when i say blow ourselves up i also i mean the environmental versions the terrorist versions
the war versions the cumulative externalities versions um can i and i'm sorry if i'm interrupting
your flow of thought but why is it easier is it could it be a weird psychological thing where we
either i was just more capable to visualize explosions and destruction and then the sicker
thought which is like we kind of enjoy for some weird reason thinking about that kind of stuff
even though we wouldn't actually act on it it's almost like some weird uh like i love playing
shooter games you know uh first person shooters and like especially if it's like murdering zombie
and doom you're shooting demons i play one of my favorite games diabolus like slashing through
different monsters and the screaming and pain and the hellfire and then i go out into the real world
to eat my coconut ice cream and i'm all about love so like i
can we trust our ability to visualize how all it all goes to shit as an actual rational way of
thinking i think it's a fair question to say to what degree is there just kind of perverse fantasy
and um morbid exploration and whatever else that happens in our imagination uh
but i don't think that's the whole of it i think there is also a reality to the combinatorial
possibility space and the difference in the probabilities that there's a lot of ways i could
try to put the 70 trillion cells of your body together that don't make you there's not that
many ways i can put them together that make you there's a lot of ways i could try to connect the
organs together that make some weird kind of group of organs on a on a desk but that doesn't
actually make a functioning human and and you can kill an adult human in a second but you
can't get one in a second takes 20 years to grow one and a lot of things to happen right i could
destroy this building in a couple minutes with demolition but it took a year or a couple years
to build it there is uh calm down co this is just an example it's not he doesn't mean it
there's a there's a gradient where entropy is easier and that there's a lot more ways to
put a set of things together that don't work than the few that really do produce higher order
synergies and so when we look at a history of war and then we look at exponentially more powerful
warfare an arms race that drives that in all these directions and when we look at a history
of environmental destruction and exponentially more powerful tech that makes exponential
externalities multiplied by the total number of agents that are doing it in the cumulative
effects there's a lot of ways the whole thing can break like a lot of different ways and for
it to get ahead it has to have none of those happen and so there's just a probability space
where it's easier to imagine that thing so what so to say how do we have a pro-topic future we
have to say well one criteria must be that it avoids all of the catastrophic risks so can we
understand can we inventory all the catastrophic risks can we inventory the patterns of human
behavior that give rise to them and could we try to solve for that and could we have that be the
the essence of the social technology that we're thinking about to be able to guide bind and
direct a new physical technology because so far our physical technology like we were talking about
the Genghis Khan's and like that that obviously use certain kinds of physical technology and armaments
and also social technology and unconventional warfare for a particular set of purposes but
we have things that don't look like warfare like Rockefeller and Standard Oil and it looked like a
constructive mindset to be able to bring this new energy resource to the world and it did and the
second order effects of that are climate change and all of the oil spills that have happened and
will happen and all of the wars in the Middle East over the oil that have been there and the
massive political clusterfuck and human life issues that are associated with it and on and on
right um and so it's also not just the orientation to construct a thing can have a narrow focus on
what I'm trying to construct but be affecting a lot of other things through second and third order
effects I'm not taking responsibility for and you you often another tangent mentioned second
third and fourth order effects and order and cascading which is really fascinating like starting
with the third order plus it gets really interesting because we don't we don't even acknowledge
like the second order effects right but like thinking because those it could get bigger and
bigger and bigger in ways we're not anticipating so how do we make those so it sounds like part of the
part of the thing that you are thinking through in terms of a solution how to create
an anti fragile a resilient society is to make explicit
acknowledge understand the externalities the second order third order fourth order and the
order effects how do we start to think about those effects yeah the war application is harm
we're trying to cause or that we're aware we're causing right um the externality is harm that
at least supposedly we're not aware we're causing or at minimum it's not our intention right maybe
we're either totally unaware of it or we're aware of it but it is a side effect of what our
intention is it's not the intention itself there are catastrophic risks from both types the direct
application of increased technological power to a rival risk intent which is going to cause
harm for some out group for some in group to win but the out group is also working on growing the
tech and if they don't lose completely they reverse engineer the tech upregulated come back
with more capacity so there's the exponential tech arms race side of in group out group rivalry
using exponential tech that is one set of risks and the other set of risks is the application of
exponentially more powerful tech not intentionally to try and beat an out group but to try to achieve
some goal that we have but to produce a second and third order effects that do have harm to
the commons to other people to environment to other groups uh that might actually be bigger
problems than the problem we were originally trying to solve with the thing we were building
when facebook was building a dating app and then building a social app where people could tag pictures
they weren't trying to build a democracy destroying app uh that would maximize time on site
as part of its ad model through ai optimization of a news feed to the thing that made people spend
most time on site which is usually them being limbically hijacked more than something else
which ends up appealing to people's cognitive biases and group identities and creates no
sense of shared reality they weren't trying to do that but it was a second order effect
and it's a pretty fucking powerful second order effect um and a pretty fast one because the rate
of tech is obviously able to get distributed to much larger scale much faster and with a bigger jump
in terms of total vertical capacity then that's what it means to get to the verticalizing part
of an exponential curve so um just like we can see that oil had these second order environmental
effects and also social and political effects war and so much of the whole like the total
amount of oil used is has a proportionality to total global gdp and this way we have this you
know the petrodollar and um and so the the oil thing also had the externalities of a major
aspect of what happened with military industrial complex and things like that so but we can see
the same thing with with more current technologies with facebook and google um and and other things
so i don't think we can run and the more powerful the tech is we build it for
reason x whatever reason x is maybe x is three things maybe it's one thing right we
we're doing the oil thing because we want to make cars because it's a better method of individual
transportation we're building the facebook thing because we're going to connect people
socially in the personal sphere but it it interacts with it interacts with complex systems with
ecologies economies psychologies cultures and so it has effects on other than the thing we're
intending some of those effects can end up being negative effects but because this technology
if if we make it to solve a problem it has to overcome the problem the problem's been around
for a while it's going to overcome in a short period of time so it usually has greater scale
greater rate of magnitude in some way that also means that the externalities that it creates
might be bigger problems and you can say well but then that's the new problem and humanity will
innovate its way out of that well i don't think that's paying attention to the fact that we can't
keep up with exponential curves like that nor do finite spaces allow exponential externalities forever
and this is why a lot of the smartest people thinking about this are thinking well no i think
we're totally screwed and unless we can make a benevolent ai singleton that rules all of us
you know guys like boss drum and and others uh thinking in those directions because they're like
how do humans try to do multi polarity and make it work and i i have a different answer of what
i think it looks like that does have more to do with the love but some applied social
tech aligned aligned with love because i have a bunch of really dumb ideas i'd prefer to uh
i'd like to hear i'd like to hear some of them first i think the idea i would have is uh to be
a bit more rigorous in trying to measure the amount of love you add or subtract from the world
in second third fourth fifth order effects it's actually i think especially in the world of tech
quite doable you know you just might not like you know the the shareholders may not like that
kind of metric but it's pretty easy to measure like that's not even uh i'm perhaps half joking
about love but we could talk about just happiness and well-being long-term well-being
that's pretty easy from facebook for youtube for all these companies to measure that
they do a lot of kinds of surveys they could do i mean there's very simple solutions here
that you could just survey how i mean servers are in some sense use useless because they're um
a subset of the population you're just trying to get a sense it's very loose kind of understanding
but integrated deeply as part of the technology most of our tech is recommender systems most
of the sorry net tech uh online interaction is driven by recommender systems that learn
very little data about you and use that data based on mostly based on traces of your previous
behavior to suggest future things this is how twitter this has facebook works this is how
adsense for google adsense works is how netflix youtube work and so on and and for them to just
track as opposed to engagement how much you spend in a particular video particular site is also
