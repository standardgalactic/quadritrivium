bets.
And these bets are in areas of fundamental importance to the world, whether it's artificial
intelligence, medical technology, self-driving cars, connectivity through balloons, on and
on and on.
And there's more coming and more coming.
So one way you could express this is that the current business is successful enough
that we have the luxury of making bets.
And another one that you could say is that we have the wisdom of being able to see that
a corporate structure needs to be created to enhance the likelihood of the success of
those bets.
So we essentially turned ourselves into a conglomerate of bets and then this underlying
corporation, Google, which is itself innovative.
So in order to pull this off, you have to have a bunch of belief systems.
And one of them is that you have to have bottoms up and tops down.
The bottoms up, we call 20% time.
And the idea is that people can spend 20% of the time on whatever they want.
And the top down is that our founders in particular have a keen eye on technology and they're
reviewing things constantly.
So an example would be that they'll hear about an idea or I'll hear about something and it
sounds interesting, let's go visit them.
And then let's begin to assemble the pieces to see if that's possible.
And if you do this long enough, you get pretty good at predicting what's likely to work.
So that's a beautiful balance that struck.
Is this something that applies at all scale?
So seems seems to be that the Sergey, again, 15 years ago, came up with a concept called
10% of the budget should be on things that are unrelated.
It was called 70, 20, 10, 70% of our time on core business, 20% on adjacent business
and 10% on other.
And he proved mathematically, of course, he's a brilliant mathematician, that you needed
that 10% to make the sum of the growth work.
And it turns out he was right.
So getting into the world of artificial intelligence, you've talked quite extensively and effectively
to the impact in the near term, the positive impact of artificial intelligence, whether
it's machine, especially machine learning in medical applications and education, and
just making information more accessible, right?
In the AI community, there is a kind of debate, so there's this shroud of uncertainty as we
face this new world with artificial intelligence in it.
And there is some people like Elon Musk, you've disagreed on at least on the degree of emphasis
he places on the existential threat of AI.
So I've spoken with Stuart Russell, Max Tagmark, who share Elon Musk's view, and Yoshio Benjio,
Steven Pinker, who do not.
And so there's a lot of very smart people who are thinking about this stuff, disagreeing,
which is really healthy, of course.
So what do you think is the healthiest way for the AI community to, and really for the
general public to think about AI and the concern of the technology being mismanaged in some
kind of way?
So the source of education for the general public has been robot killer movies.
And Terminator, et cetera.
And the one thing I can assure you we're not building are those kinds of solutions.
Furthermore, if they were to show up, someone would notice and unplug them.
So as exciting as those movies are, and they're great movies, where the killer robots to start,
we would find a way to stop them.
So I'm not concerned about that.
And much of this has to do with the timeframe of conversation.
So you can imagine a situation 100 years from now when the human brain is fully understood
and the next generation and next generation of brilliant MIT scientists have figured all
this out, we're going to have a large number of ethics questions around science and thinking
and robots and computers and so forth and so on.
So it depends on the question of the timeframe.
In the next five to 10 years, we're not facing those questions.
What we're facing in the next five to 10 years is how do we spread this disruptive technology
as broadly as possible to gain the maximum benefit of it?
The primary benefit should be in healthcare and in education.
Healthcare because it's obvious.
We're all the same, even though we somehow believe we're not.
As a medical matter, the fact that we have big data about our health will save lives,
allow us to deal with skin cancer and other cancers, ophthalmological problems.
There's people working on psychological diseases and so forth using these techniques.
I go on and on.
The promise of AI in medicine is extraordinary.
There are many, many companies and startups and funds and solutions and we will all live
much better for that.
The same argument in education.
Can you imagine that for each generation of child and even adult, you have a tutor-educator
that's AI-based, that's not a human but is properly trained, that helps you get smarter,
helps you address your language difficulties or your math difficulties or what have you.
Why do we focus on those two?
The gains societally of making humans smarter and healthier are enormous and those translate
for decades and decades and will all benefit from them.
There are people who are working on AI safety, which is the issue that you're describing.
There are conversations in the community that should there be such problems, what should
the rules be like?
Google, for example, has announced its policies with respect to AI safety, which I certainly
support and I think most everybody would support and they make sense.
It helps guide the research, but the killer robots are not arriving this year and they're
not even being built.
On that line of thinking, you said the timescale, in this topic or other topics, have you found
a useful, on the business side or the intellectual side, to think beyond five, ten years, to
think fifty years out?
Has it ever been useful or productive?
In our industry, there are essentially no examples of fifty year predictions that have
been correct.
Let's review AI, which was largely invented here at MIT and a couple of other universities
in the 1956, 1957, 1958.
The original claims were a decade or two and when I was a PhD student, I studied AI a bit
and it entered during my looking at it a period which is known as AI winter, which went on
for about thirty years, which is a whole generation of scientists and a whole group of people
who didn't make a lot of progress because the algorithms had not improved and the computers
had not improved.
It took some brilliant mathematicians, starting with a fellow named Jeff Hinton at Toronto
in Montreal, who basically invented this deep learning model, which powers us today.
The seminal work there was twenty years ago and in the last ten years, it's become popularized.
So think about the time frames for that level of discovery.
It's very hard to predict.
Many people think that we'll be flying around in the equivalent of flying cars.
Who knows?
My own view, if I want to go out on a limb, is to say that we know a couple of things
about fifty years from now.
We know that there'll be more people alive.
We know that we'll have to have platforms that are more sustainable because the Earth
is limited in the ways we all know and that the kind of platforms that are going to get
billed will be consistent with the principles that I've described.
They will be much more empowering of individuals, they'll be much more sensitive to the ecology
because they have to be, they just have to be.
I also think that humans are going to be a great deal smarter and I think they're going
to be a lot smarter because of the tools that I've discussed with you and of course people
will live longer.
Life extension is continuing apace.
A baby born today has a reasonable chance of living to a hundred.
Right?
Which is pretty exciting.
It's well past the 21st century so we better take care of them.
And you mentioned interesting statistic on some very large percentage, sixty, seventy
percent of people may live in cities.
Today more than half the world lives in cities and one of the great stories of humanity in
the last twenty years has been the rural to urban migration.
This has occurred in the United States, it's occurred in Europe, it's occurring in Asia
and it's occurring in Africa.
When people move to cities, the cities get more crowded but believe it or not their health
gets better, their productivity gets better, their IQ and educational capabilities improve.
So it's good news that people are moving to cities that we have to make them livable
and safe.
So you, first of all, you are, but you've also worked with some of the greatest leaders
in the history of tech.
What insights do you draw from the difference in leadership styles of yourself?
Steve Jobs, Elon Musk, Larry Page, now the new CEO, Sandra Pichai and others.
From the, I would say, calm sages to the mad geniuses.
One of the things that I learned as a young executive is that there's no single formula
for leadership.
They try to teach one, but that's not how it really works.
There are people who just understand what they need to do and they need to do it quickly.
Those people are often entrepreneurs.
They just know and they move fast.
There are other people who are systems thinkers and planners, that's more who I am, somewhat
more conservative, more thorough in execution, a little bit more risk averse.
There's also people who are sort of slightly insane, in the sense that they are emphatic
and charismatic and they feel it and they drive it and so forth.
There's no single formula to success.
There is one thing that unifies all of the people that you named, which is very high
intelligence.
At the end of the day, the thing that characterizes all of them is that they saw the world quicker,
faster, they processed information faster, they didn't necessarily make the right decisions
all the time, but they were on top of it.
The other thing that's interesting about all those people is they all started young.
Think about Steve Jobs starting Apple roughly at 18 or 19.
Think about Bill Gates starting at roughly 20, 21.
Think about by the time they were 30, Mark Zuckerberg, a more good example at 19, 20.
By the time they were 30, they had 10 years, at 30 years old, they had 10 years of experience
of dealing with people and products and shipments and the press and business and so forth.
It's incredible how much experience they had compared to the rest of us who were busy getting
our PhDs.
Yes, exactly.
We should celebrate these people because they've just had more life experience and that helps
inform the judgment.
At the end of the day, when you're at the top of these organizations, all of the easy
questions have been dealt with.
How should we design the buildings?
Where should we put the colors on our product?
What should the box look like?
The problems, that's why it's so interesting to be in these rooms, the problems that they
face in terms of the way they operate, the way they deal with their employees, their
customers, their innovation are profoundly challenging.
Each of the companies is demonstrably different culturally.
They are not, in fact, cut of the same.
They behave differently based on input, their internal cultures are different, their compensation
schemes are different, their values are different.
There's proof that diversity works.
One face with a tough decision, in need of advice, it's been said that the best thing
one can do is to find the best person in the world who can give that advice and find
a way to be in a room with them, one-on-one and ask.
Here we are.
Let me ask in a long-winded way, I wrote this down.
In 1998, there were many good search engines, Lycos, Excite, Altavista, Infoseek, AskJeeves,
maybe, Yahoo even.
Google stepped in and disrupted everything.
They disrupted the nature of search, the nature of our access to information, the way we discover
new knowledge.
So now, it's 2018, actually 20 years later.
There are many good personal AI assistants, including, of course, the best from Google.
So you've spoken in medical and education, the impact of such an AI assistant could bring.
So we arrive at this question.
So it's a personal one for me, but I hope my situation represents that of many other,
as we said, dreamers and the crazy engineers.
So my whole life, I've dreamed of creating such an AI assistant.
Every step I've taken has been towards that goal.
Now I'm a research scientist in human-centered AI here at MIT, so the next step for me as
I sit here facing my passion is to do what Larry and Sergey did in 1998, the simple startup.
And so here's my simple question.
Given the low odds of success, the timing and luck required, the countless other factors
that can't be controlled or predicted, which is all the things that Larry and Sergey faced,
