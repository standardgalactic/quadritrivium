Hey, folks, welcome to the Dark Horse podcast.
I am very pleased today to be sitting with my good friend, Daniel Schmockdenberger,
who is the founder of the Consilience Project.
There's a lot more that I could say about you, Daniel, but I think we will leave it
at that for now.
People can look up your bio if they want to do so.
I should probably start by telling people that when I say that you are my good friend,
I really mean that.
You and I are good friends, although, to be honest, we haven't spent all that much time
together.
This is one of those cases where you meet somebody, somebody who has started from a
very different place, and you discover that you have all kinds of thought processes that
have reached similar conclusions, and every discussion is fascinating.
The more I learn about what you think, the more I realize I've got a lot to learn from
you and that there is essentially infinite ground to be covered.
So welcome, Daniel.
Thank you, Brett.
It's really good to be here.
I feel the same way we were introduced by our friend, Jordan Hall, and we never had
a conversation where I didn't learn something and where I didn't appreciate the good faith
way that you showed up when we had a disagreement to talk through, which is always fun.
It is always fun, and I must say I did a little bit of poking around seeing recent interviews
you'd done, but I deliberately did not overly study for this.
My sense is that the audience will get a great deal out of hearing you and me go back and
forth and finding out what we agree on, where we disagree, and maybe most tellingly, there's
a phenomenon in which anybody who has learned to think more or less independently tends
to have their own language for things, their own set of examples that they use to explain
things that recur over and over again.
And so in order to have high quality conversations, there is this period in which you're effectively
teaching the other person how you phrase things, and seeing those things line up is great.
And in the rare case where they don't line up, it's even better because you know there's
something to be learned one way or the other.
So I'm hoping that will emerge here.
I'm looking forward to it.
All right, good.
So let's start here.
When I say that you and I come from different starting points, I mean to imply something
in particular.
You, as I understand it, were homeschooled, and as you have described it, that was actually
closer to what most people would probably refer to as unschooling.
Somehow this did not mess up your motivational structures, your parents were alert about
what they were doing.
And so you ended up pursuing what you wanted to pursue.
And it did not, you did not get in your own way.
And lo and behold, you end up a wickedly smart, independent first principles thinker.
Now that's not my story at all.
My story is I went to school and it didn't work.
I had something that most people would call a learning disability and it got in the way
of school functioning for me and more often than not, I got dumb tracked.
And basically that complete failure of school to reach me accidentally worked like some
kind of unschooling, I would say.
And so there are maybe many paths, I don't know, but I'd be curious for people who have
traveled some road to the land of high quality, independent thought.
What can they expect the experience to be like when they arrive there?
The experience of high quality, independent thought.
Yes, if you imagine that, well, it would be lovely to think independently and to do so
well.
And the world is going to be a paradise if you start doing that because of course that's
a very desirable thing to do and people will appreciate it.
You're going to be surprised.
That's not necessarily what happens when you arrive there and certain experiences show
up all over the place.
And without telling you what my experiences might have been, I'm curious as to what you
might have encountered and whether or not those things will be similar.
Ah, yeah, that's an interesting question.
I think you will experience, most people will experience a higher degree of uncertainty
than people that are part of any camp that has figured most things out and they can
cognitively offload whoever the authorities or the general group consensus is.
And certainty is certainly comfortable in a particular way.
And if you're really thinking well about what is my basis for what I believe, what is the
epistemic grounding, what's the basis of my confidence margin, and you really think about
your confidence basis clearly, as you try to find more information to deepen the topic,
the known unknowns expand faster, like at least at a second order to what the known
knowns do.
And so you keep being aware of more stuff that you don't know that you know is relevant
and pertains to the situation.
So there's a complexification of thought.
There's an increase in uncertainty.
There's an emotional development and kind of a psychological development where there's
an increased comfort with uncertainty so that you can actually be honest and not defect
on your own sense making into premature certainty that creates confirmation bias.
And there's also a, and I think that's why one of the reasons you use the term independent.
There is a certain aloneness of not having a whole camp of people that think very similarly.
I don't find that to be a painful thing, but it's a thing.
No, it's actually in its own way, it's freeing because the fact is if you follow logic to
natural conclusions, you'll end up saying a lot of things that are alarming or discordant
with the conventional wisdom and the world neatly divides into people who will be so
enraged or thrown by what you're saying that they disappear or maybe they become antagonists
at a distance and the people who have a similar experience and therefore aren't thrown by
the fact that you're saying things that are out of phase and so editing the world down
to those who are comfortable with what they don't know, who are interested in following
things where they lead, irrespective of who that elevates and who it hobbles, those people
are interesting people to hang out with and so yes, the alienation may be a blessing in
disguise in some ways.
There's two other thoughts that came up as you were just talking, one is I wouldn't call
myself an independent thinker.
I'm being particular about the semantic of the word independent, I wouldn't call anyone
an independent thinker because I think in words invented by other people, I think in
concepts invented and discovered by other people.
I don't necessarily have a specific school of orthodoxy from which I take an entire world
view but almost every idea that I believe in I did not discover and so I think that's
a very important concept because I think the ideas we're going to discuss today regarding
democracy and open society have to do with the relationship between an individual and
a collective and I think the idea of an individual is fundamentally a misnomer.
Without everybody else, I wouldn't be who I am and I wouldn't think the way I think,
I wouldn't think in the language I do, I wouldn't have access to the knowledge that came from
the Hubble telescope and the Large Hadron collider and so many things like that.
I can say that there's a certain ultimate authority of what I choose to feel that I
believe in and trust that has an internal locus of control but the information coming
from without and my own internal processing of it are part of the same system.
So this is a perfect example of what I was suggesting up front where two people who do
whatever we're going to call this will have their own separate glossaries.
So if I can translate what you've just said, I Daniel Schmockdenberger am not an independent
thinker because such a thing is inconceivable in human form and I totally agree with that.
The fact is not only are you interwoven with all sorts of humans who are responsible for
conveying to you in one way or another conclusions that you couldn't possibly check, these are
thoughts that would be familiar to Descartes for example.
But you are also building from the entirety of cumulative human culture, all of the tools
with which you can think are almost all of them are too ancient to even know where their
rudiments originated.
So anyway I don't disagree with any of that.
So to me I would say there is such a thing as an independent thinker and in your schema
it has to do with whether or not they are thinking a la carte that is to say using that set of
tools that is most effective, irrespective of the fact that those tools don't all come
from one tradition and you would say there is no independent thought because all a carte
is the most you can do or something like that.
I might say that I like a term like interdependent better because it doesn't mean that there
isn't an individual involved but it means that the individual without everyone else
is also not a thing.
And so the recognition that sovereignty and individuality is a thing and it is conditioned
by, affected by and affecting other groups of people are both necessary in the Hegelian
synthesis to understand what is the nature of a human.
Are they fundamentally individual and then groups emerge?
Are they fundamentally tribal and they are formed by the tribe and it's very much both
and a kind of recursive process between them?
100%.
In fact, I once wrote something I called the Declaration of Interdependence.
It was a sort of proto game B attempt to define what the rules of a functional society would
be like and I also frequently say that the individual is more an illusion than it is real
and what I describe is that an individual is a level of understanding that evolution
has focused us on because historically it has been sort of the limit of that where we
might have some useful control, right?
Evolution might ultimately care about whether or not you are successful, your genes are
still around 100 generations from now, but your focus on 100 generations from now is
unlikely to have any useful impact whatsoever, whereas your focus on your life and your
children is likely to be useful.
So we have been delivered a kind of temporal myopia in order to keep us focused on that
which could be productive for an ancestor.
But of course, we are now living in an era in which we can have dramatic impacts on
the distant future.
In fact, you and I are both quite focused on the strong possibility that our foolishness
in the present will result in the end of our lineage and that that is something that evolution
weren't capable of upgrading would certainly have us concerned about because the hazard
is very real and our tendency not to think about it is a big part of the danger.
I think temporal myopia and the collective action, collective coordination problem is
a good way to describe all of the problems we face or one of the generator functions
of all the problems we face that you have a bunch of game theoretic situations where
each agent within their own agency pursuing the choice that makes most rational sense
to them pursues local optimums where the collective body of that drives local global minimums.
And if anyone tries to orient towards the longer term global maximum, they just lose
in the short term.
That's an arms race.
That's a tragedy of the commons.
And so how do we reorient the game theory outside of those multipolar traps?
I would say is one of our underlying questions that when the biggest harm we could cause
was mediated by stone tools or bronze tools or iron tools or even industrial tools.
We didn't have to cause it immediately because the extent of harm was limited in scope.
When it is mediated by fully globalized exponential tech running up against planetary boundaries
with many different kinds of catastrophe weapons held by many different agents.
We actually have to solve the problem.
Yeah, I of course agree completely with this as well that effectively maybe it really is
every single important problem is a collective action problem of one kind or another.
We've got races to the bottom, we've got tragedies of the commons, we've got these things intermingled.
But once you start to see that on the one hand, it is you could take from it a kind
of reason for despair because these are not easy problems to solve.
On the other hand, the discovery that effectively it's not a thousand distinct problems, it's
a thousand variations on one theme and that that theme is solvable.
In fact, we have for example, Eleanor Ostrom's work, which points to the fact that evolution
itself has solved these problems many times, that that is hopeful.
So I don't know where you are in terms of how hopeful you find yourself about humanity's
future, but I'm quite certain that you and I will align on the idea that yes, if we could
focus on the problem as it was, it's more tractable than many people think it is.
Yeah, I mean, you mentioned hopefulness, you mentioned a bunch of good things there that
rather than a bunch of separate problems, you have a few problems with lots of expressions.
This was a big chunk of the kind of work I engaged in and with a number of people you
were part of looking at when we inventory across all of the catastrophic and existential
risks ones involving AI and problems with biotech and other kind of exponential tech
and environmental mediated issues and things that escalate to large scale war.
Is there anything in terms of the patterns of human behavior that they have in common?
So this kind of race to the bottom collective coordination thing is one way of looking at that.
But there's a few ways of looking at what we'd call the generator functions of catastrophic risk.
And it really is simplifying if you can say are there categorical solutions to those underlying
generator functions?
They're hard, right?
They're hard.
Now, when you talk about hopefulness, I noticed that the way that I relate to the optimism,
pessimism thing is there's an optimism, which is almost like a choice to say,
I'm going to have optimism that there is a solution space worth investigating,
even if I don't know what it is.
And if I'm wrong, it's the right side to be wrong on as opposed to there was a solution.
I didn't look for it.
And then I'm going to have pessimism about my own solution.
So I'm going to try to red team my solution so that I can find out how they're going to
fail before finding out how they fail the hard way in the world, but then not be devastated
by the fact that that solution wasn't it and keep trying.
And I think that's kind of how the committedly inventive, innovative principle works.
So again, we could do almost a one to one mapping of your schema onto mine.
I do this in terms of prototyping rather than red teaming and discovering it's wrong.
It amounts to the same thing.
When you say, actually, it's hard, you and I would have to define two different kinds
of hard, probably, there is hard to make function to stabilize.
And there's hard to figure out what the solution is.
And those are distinct.
We might find elements of both of them here.
But let me just give a, maybe it's the canonical example of a solution to a game theory
problem that everyone will recognize.
I divide you choose, right?
It's the perfect solution to an obvious problem of choice and selfishness, right?
If there is cake and I know that you're going to get your choice and that you are
incentivized to pick the larger piece, then I am incentivized to get the cut as even as
possible.
And the point is it neutralizes the concern.
So we are looking for solutions of that nature.
Now, I don't think they are all that hard to understand in broad terms in general.
It may, there may be a lot of work on the discovery end, but when you see them, they
end up being surprisingly simple.
My biggest fear is that the there is, it is very rare for people to understand how much
danger we're in and why and therefore what solution we are inherently looking for and
how urgently we should be seeking it.
In other words, as long as things function pretty well in the present and people get
fed and housed, it is very easy for them to ignore the evidence that we are in grave
danger, even if we are fat and happy and enjoying a period of good luck.
Yeah, when you, like one of the interesting things in the study of previous civilizations
is that none of the great civilizations of the past still exist.
They all failed even if they had been around for hundreds or thousands of years.
And so to, to understand that civilizations failing is the only thing that's ever happened
and then recognize that since World War Two, we have for the first time a fully globalized
civilization where none of the countries can make their own stuff, that the supply chains
that are necessary to make the industrial and productive base are globalized and that
we're running up against the failure points of a globalized civilization, which it that's
an important thing.
And what's so interesting is that all the previous civilizations that failed had so
much hubris before their fall, because there had been so many generations where they had
succeeded that they had forgotten that failing was a thing.
It was just some ancient myth that didn't feel real.
So we don't have an intuition for things not working or for catastrophe because we
haven't experienced it and our parents didn't experience it and it's only myth.
And as a result, we just make bad choices.
And I mean, this is where studying history and studying civilization and collapse is
really helpful.
And you can see that even as the system starts to fail in partial ways, to me, it seems
very clear that when we look at the George Floyd protests turning into riots over the
summer that happened, they were following the COVID shutdowns and specifically all the
unemployment from it.
When and whenever the unemployment goes up, whenever the homelessness goes up, when
people can't, when the society makes it to where people who are trying can't meet their
basic needs, then it gets a lot easier to recognize there's something wrong with the
system as a whole and go against it.
But we also never had a point in human history where it was like, no matter how
outraged I am, all I have to do is start scrolling for a second.
And I forgot on everything, not to mention the fact that I'm probably on opioids and
benzos.
And so that, that makes it to where the frog can keep boiling in hot water longer.
Yeah.
So I, I often say that people are too comforted by the idea that people are always
predicting the end of the world and it hasn't happened yet, because in fact, it
happens all the time, right, the ends of these civilizations.
But it's even worse than the analysis that you and I appear to agree on here because
many of those civilizations that have ended, in fact, most of them, the
civilization, the organizational structure ended, but the people didn't, right?
So the Romans continued on as other things.
The Maya are still with us, right?
They are not with us as the Maya.
And the point is actually in this case, the jeopardy that we are creating is to our
very capacity to continue as a species, not just to our ability to continue with
the structures that we have built.
So not only are we all in it together this time, but we're all in it in a way
that we never have been before, or at least very rarely have been before.
And that really ought to have people's attention, but you're right, the
capacity to distract ourselves from it has never been better either.
I think something that I find particularly important when thinking about catastrophic
risks now relative to previous examples of civilization collapse is that until
World War II, we couldn't destroy everything.
Like we just didn't have enough technological power for catastrophe weapons.
And so you could fight the biggest, bloodiest war, violate all of the rules of war,
and they would still be a local phenomena.
And with the invention of the bomb, we had now the new technological power to
actually destroy habitability of the planet kind of writ large, or at least
enough of it that it was a major catastrophic risk.
And on the time scales that you think about as an evolutionary biologist of
how long humans have been here and the proto-humans since World War II is no
time at all to have really adapted to understanding what the significance of
that is.
And the only reason we made it through was because we created an entire global
order to make sure we never used that new piece of tech.
And in all of history, we always used the arms that we developed.
And so we made this whole Bretton Woods world and mutually assured destruction
that said, okay, well, let's have so much economic growth so rapidly that
nobody has to fight each other and they can all have more because the pie
keeps getting bigger.
But that starts running up against planetary boundaries and
interconnecting the world so much it gets so fragile that a viper,
a virus in Wuhan shuts the whole world down because of supply chain,
interconnected supply chain issues.
So that thing can't run forever.
And the mutually assured destruction was one catastrophe weapon and two
superpowers.
So mutually assured destruction works, the game theory that works.
Well, as soon as you start to add to that the bio weapons and the chemical
weapons, the fact that bio weapons can be made very, very cheaply now with
CRISPR gene drives and things like that, grown weapons.
We have dozens of catastrophe weapons held by many dozens of actors,
including non-state actors.
And that just keeps getting easier.
Mutually assured destruction can't be put on that situation.
It doesn't actually have a stable equilibria.
So now we have to say, how do we deal with many, many actors having many
types of catastrophe weapons that can't have a forced game
theoretic solution with a history where we always used our power
destructively at a certain point?
How do we deal with that?
It's novel, right?
Like we have no precedent for that.
Yeah, it's absolutely novel.
I mean, when I became cognizant, let's say 1975 is where I first started having
coherent thoughts about the world.
That was only 25 years after the end of World War II.
And it seemed like World War II was a very long time ago.
But of course, we've covered that distance twice since then.
So the ability for the tools with which for us to self-destruct as a result
of aggression are brand new.
And you're absolutely right.
The thing that prevented us from using them, that force disappeared.
It no longer exists.
There's no stable equilibrium here.
So what's protecting us is not well understood at best.
And then add to that all of the various industrial technologies that we are now
using at a scale where they imperil us.
And I don't know about you, but I keep having the experience of a catastrophe
happens, and that's the point that I get alerted to some process that is very
dangerous to humanity that I didn't know about until the catastrophe.
This has happened with the financial collapse of 2008.
It happened with the triple meltdown at Fukushima.
It happened at Alizzo Canyon.
I believe it has now happened with COVID-19 and gain of function research.
And the point is it paints a very clear picture.
We do things because we can't see why we shouldn't.
Or this is also a game theory problem.
Those who can see why we shouldn't don't, and certain number of people don't
see why we shouldn't, and they do.
And we all suffer the consequence of their myopia.
And so on multiple fronts, we are playing, we are rolling the dice year after year.
And the people who can think independently, looking at that picture,
looking at the series of accidents, looking at the hazard of something like
a large-scale nuclear exchange without an equilibrium to prevent it.
Those people wake up, but the problem is the mechanism to actually begin to steer
the ship in a reasonable direction in light of these things doesn't seem to
exist for reasons I've heard to explore many places.
So what does it mean as far as you can tell?
Well, there's one thing that you said that I think is worth us addressing first
is that some of the things that caused the catastrophe either were unknown,
or those who knew them were, game theoretically, less advantaged than those
who were oriented on the opportunity rather than the risk.
Because those who orient towards opportunity usually end up amassing more
resource that equals more ability to keep moving stuff through.
There is an article and a conversation in the less wrong community about
regarding catastrophic risk, a mistake theory versus conflict theory.
What percentage of the issues come from stuff that we knew would cause a problem,
or at least could cause a problem, and game theoretically, we went ahead with it
anyways versus stuff where we just couldn't have anticipated or really didn't anticipate.
And I think it's fair to say these are both issues, right?
There's true mistake theory stuff, like we just couldn't calculate,
and then there's true conflict theory stuff.
We knew that escalating this military capacity would drive an arms race
where the other people would, that if we calculated it,
there's an exponentiation on all arms races that takes us to a very bad long-term global situation.
One of the insights that I think is really interesting is that the fact
that the mistake theory is a thing and everyone acknowledges it,
ends up being a cover, a source of plausible deniability for what's really conflict theory.
So we know there is an issue.
We pretend not to know.
We do a bullshit job of due diligence and risk analysis,
and then afterwards say it was a failure of imagination and we couldn't have possibly known.
I have actually been asked by companies and organizations to do risk analysis for them
where they did not want me to actually show them the real risk.
They wanted me to check a box so they could say they did risk analysis,
so they could pursue the opportunity.
And when I started to show them the real risk, they thought we don't want to know about that.
And so when it comes to the, could we have possibly factored that?
So, I mean, a classic example I like to give, because it's so obvious in retrospect,
is could we have known in the development of the internal combustion engine
that making streetcars, which seemed like a very useful upgrade of having the horse internalized
to the carriage would end up causing climate change and the petrodollar and wars over oil
spills and mass and ocean oil spills, whatever.
It seems like that would have been hard to know 100 years in the future that it would do all that stuff.
And this is a classic example of also where we solve a problem and end up causing a worst
problem down the road in the nature of how we do it, which you can't keep doing forever.
The story is, oh, we cause a worst problem, then that's the new market opportunity to solve that
problem and the ongoing story of human innovation.
But when you start running up against it, the problems are actually hitting catastrophic points.
You don't get to keep doing that ongoingly. You don't get to regulate after the fact,
the way that we always have once a problem hits the world, things that are catastrophic.
Could we have known, well, yeah, in London before that, one, they were already electric
motors and two, people were already getting sick of burning coal from lung disease, from the burning
of the hydrocarbons. If we had tried to do good risk analysis, could we have? Yeah.
But there's so much more incentive on who pursues the opportunity first. And then there's this
multipolar trap of, well, let's say we don't, the other guy is going to, so it's going to get there
anyway. So we might as well be the ones to do it first. And that thing ends up getting us all
the time, which is why collective action again comes in.
Well, it's really interesting how much of this is again, parallel. Heather and I use the example
of somebody, you know, driving the first internal combustion engine and somebody chasing them down
the street saying, don't do that, you'll screw up the atmosphere, right? How crazy is that person
running down the street saying that because, you know, you would have to scale it up to such a degree
before that's even a concern that that person seems like a nervous Nellie. But of course,
they would also have been prophetic. But the other thing I want to ask you about is,
you say that we have these two categories where
sometimes we could have known and we went, we knew in fact, and we went ahead anyway.
And then in other cases, we didn't know and something snuck up on us. And I want to be,
I want to clarify what you just said, because my understanding here is that if you dig deep enough,
somebody always knew, right? In general, there's some mechanism whereby the person
who correctly predicted what was going to happen has been silenced, often they lose their jobs,
they disappear from polite society. At the point they turn out to be right, their
reputations are never resurrected as far as I can tell. So am I wrong that even in the cases where
people who made the decisions may plausibly have not known that the reason they didn't know is
because there's some sort of active process that when there's a profit to be made,
shuts down anything that could be the basis of a logical argument that we shouldn't do it?
I don't know that I'll say always. I'll certainly say most of the time.
And let's say there was a case where we really nobody knew.
My guess is we probably could have had we tried harder. And then let's say there's going to be
some unpredictable stuff, like we know in complex situations, there's going to be unpredictable
stuff. So you do the best job you can to forecast the risks and harms ahead of time.
But then you also have to be ongoingly monitoring. Well, what would the early
indicators that there's a problem be? And when we find that there's something we hadn't anticipated,
how do we factor that into a change of design? Well, once the profit stream is going and the
change of design fucks up the profit stream, how does the recognition of that there's a problem
actually get implemented when those who have the choice implementation power are not the people
who are paying attention to those indices? So yes, I would say, and it's easy to just say,
hey, yeah, there was some there was some wackadoodle who was saying that there was going
to be some risk, but there's always some wackadoodles saying there's going to be risk about every new
tech. And if we really listened to all them, we'd have no progress. That's the story, right?
It's a bullshit story. Could we now let's there's but there's a collective coordination issue,
because it is fair to say, so like, let's take AI weapons right now, specifically,
automated drone weapons. There is an arms race happening on automated drone weapons.
And I think every general and military strategist knows that all of our chance
of dying from AI weapons goes up. They're kids, everybody's, as we progress in that technology,
it's a bad technology, it shouldn't exist. We should create an international moratorium that
says nobody builds AI drone weapons that we don't want automated weapons with high intelligence
out there. But we can't make that moratorium, because if one country doesn't agree, if one
non country, some non state actor doesn't agree that has the technology, or let's say everybody
agrees, how do we know they're not lying and developing it as an underground black project?
So either we don't even make the agreement, or we make the agreement knowing we're going to lie
defect in a black project, spy on their black project and try to lie to their spies,
who are spying on us. And so it's like, how do you get around that thing, where if anyone does
the bad thing in the near term, it can first so much game theoretic advantage that anyone who
doesn't do it loses in the long term. Why it was that the peaceful cultures all got slaughtered by
the warring cultures. And so what ends up making it through is those who end up being effective
enough at war. That's an underlying thing we have to shift. Because that has as its eventual
attractor space self destruction in a finite space. Yeah, I totally agree. And the I think
fascinating thing when you interact with the incarnate aspect of the process you just described,
is that the people who are telling the lies that explain why we're doing something that we know
is reckless, often don't know that that's what they're doing, right, they actually believe their own
press. And instead of saying, well, yes, this is terrible, but we don't really have a choice,
or somehow indicating that they know that what you encounter is a true believer who thinks that
this is safe. And that's very frightening, because it means that the mechanism at the point something
begins to go awry, to do anything about it doesn't exist, right, or at least it's not connected to
the part that you can talk to. And so, again, not not too surprised to find overlap in our map,
I would say the process that you describe of by the time you discover what the hazard is,
that there's a profit that has accelerated the process. I call this the senescence of civilization,
because it's actually exactly a mirror for the process that causes a body to senesce,
the evolution of senescence involves processes that have two aspects, one which benefits you when
you're young, and another which harms you when you're old, and because many individuals don't
live long enough to experience the harms in old age, they get away with it from evolution's point
of view, and evolution favors the trait in spite of the late life harms. So those late life harms
accumulate, and that's the reason that we grow feeble with age and die. And that's an exact mirror
for the way we've set up our economic and political system, where any process that is
profitable in the short term at the consequence of having some dire implication for civilization
later on, those processes are so ingrained by the time we discover what the harm looks like
in its full form, there's nothing we can do to stop them. Okay, so let's use two really important
current examples. So let's take Facebook and social media, and the way they've affected the
information commons and the epistemic commons are at large. So we know that the nature of the
algorithms optimizing for time on site while being able to factor what I pay attention to,
the whole Tristan Harris story, makes very few people wake up and say I'd like to spend six
hours on Facebook. And so I'm going to spend more time on Facebook if I kind of leave executive
function rational brain and get into some kind of limbically hijacked state where I forget that I
don't want to spend my whole day on Facebook. And so time on site maximization appeals to existing
bias and appeals to limbic hijacks. So if I piss off and scare the whole and illicit sexual desire
and whatever of the whole population while doubling down on their bias, and creating stronger
in group identities associated without group identities, the algorithms optimize. Well, it is
an AI of the power that beats Caspar Abit chess, beating us at the nature of the control of our
attention. So we can see that the right got more right, the left got more left, the conspiracy
theories got wackier, the anti conspiracy theory people became more upset at the idea that a
conspiracy could ever exist. Basically, everybody's bias doubles down and they all move apart from
each other faster. Well, society doesn't get to keep working that that is a democracy killer,
right? That's an open society killer. There's a reason China controlled its internet is if you
don't want your society to die, you have to be able to have some shared basis of thought.
So we can say, and the story is, oh, we didn't know that was going to happen. Well, you go back
and look and guys like Jaren Lanier were at the very beginning of Facebook and Google whatever
saying, Hey, guys, this ad model is going to fuck everything up. Like you can't do the ad model
thing, you got to have pay for subscription or, you know, some other kind of thing. And it was
like, shut up, dude. And or just don't even engage in the conversation and then get a say afterwards
failure of imagination. But now, how do you regulate it when those corporations are more
powerful than countries? Because some the regulation is going to be happening in a court where the
lobbyists have to be paid for by somebody, right? So who are the lobbyists paid for by and it has
to be supported by popular attention and those who can control everybody's attention can also
affect what is in popular attention. So this is a very real example where we know the harms were
known. And and it actually got large enough that it killed the regulatory apparatus's capacity.
Absolutely. In fact, again, this is going to be another alignment of our maps. So
what I've been playing with is the idea that we are incorrect in imagining that people necessarily
want their their expectations flattered, that people actually may like to be challenged,
but that it's inconsistent with the well being of advertisers that the very fact is
because advertising is only a tiny fraction informative and is mostly manipulative.
You have to be in your unconscious autopilot phase in order for it to cause you to buy a car you
wouldn't have otherwise bought or buy different deodorant than you would otherwise buy. And so
the point is in order for us to be the thing gets paid for by advertising, in order to be useful to
advertisers, we have to be unconscious. And the only way to keep us unconscious is not to
challenge us basically to tell us what we think we already know rather than what we need to know.
And so they're lulling us into this, even though we would still be interested in the platforms,
if we weren't being advertised to, but we would be interested in having more important
conversations there, which is really, in some sense, what the the growth of heterodox podcast
space is about. Oh my goodness, okay, there's two directions I want to go at the same time,
I'll just pick one. There's a reward circuit on exercise and there's a reward circuit on junk
food, right? And they both have a dopamine, allergic element and reward circuit, but they're
of a very different kind. And the reward circuit on exercise is that it actually feels like shit
at first and is hard and but your baseline of happiness measured in whatever dopamine,
opioid access, whatever gets better over time. And then you start actually feeling over time,
but not quickly. This is another place where temporal myopia ends up mattering because there's
a delayed causation on the healthy one and no delayed causation on the unhealthy one. So I start
getting the reward circuit on exercise when I start seeing results. And then I want to push
hard and then I'm willing to actually go against entropy and put energy into the systems the energy
grows. Whereas the chocolate cake, I get a reward instantly and I don't have to apply any energy.
But as I do it, my baseline gets worse. And this is the like addiction versus health reward
circuit direction. And the same is true for scrolling Facebook compared to reading an
educational book at the end of a month of reading the educational books, my life feels better,
I feel more proud of myself at the end of a month of scrolling Facebook, I'm like, what the fuck
am I doing with my life? And and yet that one will keep winning for the same reason that 70%
of our population is overweight and over a third of them obese. And so but not but my only hope is
that not everyone who has access to too many calories is obese, right? Like, there are some
people who figured out, hey, that's a reward circuit I don't want to do. And I'm going to exercise
and I'm going to not eat all of the fat sugar, salt that evolution program me to have a dopamine
hit for because it's a shitty direction. Now, we need to get that number of people who actually
have taken some sovereignty over their fitness and well being in the presence of the cheaper
reward circuit, we need to get that number up to everybody because right now, obviously,
overweight is one of the main causes of death in the developed world. But we have to then apply
that to the even more pernicious hypernormal stimuli, because salt fat sugar or hypernormal
stimuli on in the Augustatory system, right? We have to apply that to the sensory system that's
coming in through things like social media. And that means less social media, less entertainment,
more study. And it doesn't have as fast a reward circuit, it just doesn't. But it has a much better
longer term reward circuit where your baseline goes up. And this is where enough mindfulness
and enough discipline have to come in. Because otherwise, the orientation of the system is
that it's more profitable for corporations for me to be addicted because you maximize lifetime
value of a customer through addiction. And it's an asymmetric war because they're a billion or
trillion dollar company and I'm me. So how do I win that asymmetric war where it's in their
profit incentive, whether it's McDonald's or Facebook or Fox for me to be maximally addicted?
I have to recognize, holy fuck, right? Like I actually have no sovereignty, even if I claim
to live in a democracy against democracies, who want to control and manipulate my behavior in a
way that is net negative for me holistically while having the plausible deniability that I'm
choosing it because they're coercing my choice. So I have to get afraid of that enough that I
mount a rebellion, right? A revolutionary war in myself against those who want to drive my
hypernormal stimulus reward circuit. So the whole how can everybody become more immune
to the shitty reward circuits and notice them and become immune to them? And how can they
become more oriented to the healthy reward circuits? That's another way of talking about
what we have to do writ large. Yeah, that's beautiful. Completely agree. In fact, it dovetails
with another thought that first time I thought it, I thought it was original and then having said it,
I discovered lots and lots of people had said it before me that there's a very close relationship
between wisdom and delayed gratification, that it's the ability to bypass the short-term reward
circuit in order to get to something deeper and better that is, you know, that is what wisdom is
about. But you didn't include on your list what I consider to be maybe the one of the most important
instances of the failure that you're talking about, which is sex. There's a very direct comparison,
at least for either males who are wired in a normal fashion for a straight guy or women who
are toying with that same programming, which I believe there are many. But the comparison between
casual sex, which is certainly we are as males wired to find that a very appealing notion because
it's such a bargain. If you can produce a baby where you're not expected to contribute to its
raising, that's a huge evolutionary win. And then you have to compare that to the rewards of a deep
romantic lasting relationship with commitment. And the problem is that the deep lasting relationship
stuff has a hard time winning out over the instant gratification thing if the instant
gratification thing is at all common. And so that's really screwing up people's circuitry with
respect to interpersonal relationships and bonding. And I have a sense that it is also
in a way that's much harder to demonstrate contributing to the derangement of civilization
that people, many fewer people have a relationship. You know, it's not like marriage is easy,
right? It's not. It's super complex. But having somebody who you can fully trust, somebody who
you've effectively, you know, fused your identity with to the level that they share your interests.
And, you know, they may be the only person who'll tell you what you need to know at some points.
And the fact that many people are missing that I think is deeply unhealthy.
Yeah. So I would say that
market type dynamics benefit from exploiting the shitty reward circuits across every evolved
reward circuit axis. And so from an evolutionary point of view, survive and mate are the things
that make your genes get through primarily. So we've mentioned the survive the calorie one early
earlier, right? So in an evolutionary environment, I could get plenty of green leafy things in many
environments. It was very hard to get enough fat, enough sugar and enough salt. Those were
evolutionarily rare things. So more dopaminergic hits on those. So fast food ended up figuring
out how to just combine fat, salt, sugar with no other nutrients with maximize ease of palatability
and textures. And there's like a scientific optimization of all of the dopamine hit with
none of the nutrients. So you can actually be obese and dying of starvation, right?
And what that is to nutrition, where you would should have a natural dopamine urge to hit on
something that has nutrients built in for, you know, adaptive purposes is what porn and online
dating is to intimate relationship is what Facebook and Instagram is to tribal bonding.
Is how do we take the hypernormal stimuli part of it out, separate it from the nutrients and
make a maximally fast addictive hit that actually has none of what requires energetic process?
Yeah, I've called this the junkification of everything. And it is a directly an allusion
to junk food where we can most easily see this. But the idea is you will be given a distilled,
so if I can rephrase what you said in terms that are more native to me, when you are wired to seek,
you know, the umami taste that tends to be very tightly correlated with meat,
you will tend to get a lot of nutrients along with it in the ancestral context. In the modern
context, we can figure out how to just trip the circuit that tells you to be rewarded. And it's
no longer a proxy for the things that it was supposed to lead you to. And as you just said,
you can now look at that across every domain where you have these dopamine rewards and understand why
people are, you know, living in the world that pinker correctly identifies we are living in,
where we have just a huge abundance, and yet are so darn unhealthy, certainly unsatisfied,
right? It explains that that paradox of being better off in many ways than any ancestor could
have hoped to be, and yet being effectively ill across every domain.
Yeah, I will say something about this that's important. I mean, briefly, the fact that
life expectancy started going down in the last five years in the US in certain parts of
developed world is really important to pay attention to. But the deeper point I want to
make is the Hobbesian view on the past, I think is one of those like mistake theory information
theory things. I mean, mistake theory conflict theory. I think the dialectic of progress is
such a compelling idea. And we're oriented to the opportunity and not the risk in the same way
we don't want to look at the risk moving forward that would have us avoid an opportunity, we don't
want to look at good things in the past. And we don't want to look at good things of cultures that
we want to obliterate. So we want to call the Native American savages so that we can of course
emancipate them. Historically, and we want this Hobbesian view that people had brutish, nasty,
mean short lived lives in the past so that we don't have to face the fact that advanced
civilizations failed. And that is what our own future most likely portends. I think
that is a convenient wrong belief system in a similar way.
Well, I hope you don't hear me doing that. I certainly don't. I just I have to say it.
You have to say it. So it's clear to our listeners. Well, I appreciate you doing that.
I did want to go back to a couple things you said. And, you know, of course, this happens
every time you and I talk where every every thread, you know, takes on multiple possible
directions we could go and there's no way to cover them all. But in any case, you pointed to
survival and mating being the primary mechanisms to get your genes into the future. And I want to
point out that this is one of these places where our wiring, which is biased in the direction of
those places where our ancestors had agency that was meaningful
upends us. And in fact, this is something I think you and I are struggling against
as we try to compel people of the kind of danger we're in and the necessity to upgrade our system,
you know, before we run into a catastrophe too big to come back from. And so in any case,
within your population, survival and mating makes sense as an obsession. But probably the biggest
factor in whether or not your genes are around 100 generations from now is whether the population
that you were a part of persists. And so, you know, my field has done a terrible job with this.
We have gotten pretty good at thinking about individual level adaptation and fitness. And,
you know, when I say lineage, people still don't know what I'm talking about. And they're
confused about why I'm focused on it. And my sense is it's like two components to an equation.
And, you know, you're either aware of the lineage thing, but you misunderstand it as group selection,
or you're not aware of the lineage thing, and you think group selection is a fiction,
and it's all about individuals. And, you know, both of those are ways to misunderstand
the point. I'm so happy to hear you saying this because
I'm sure in this conversation, I would love to go deeper and understand the
distinctions between lineage and group selection, the way that you see them.
But if I just even take the concept of group selection as opposed to just individual selection,
and take a species like sapiens, and say there was no such thing as an individual that got selected
for, that was not an effective part of a group of people. And the tribe, the band,
was the thing that was being selected for. So there was fundamentally kinds of pro-social behavior
that were requisite. But then we get bigger than the Dunbar number, only like yesterday,
evolutionarily. And that whole, the whole evolutionary dynamics break because that
pro-social behavior only worked up to that scale when everybody could see everybody and
knew everything, right? Like there's, when we start looking at how do we solve collective
action problems, you start realizing, well, how do, if we make some agreement field as to how
nobody does the near term game theoretically advantageous relative to each other long term
bad thing, there has to be transparency mechanisms to notice it. So the beginning of
defecting on the whole, defecting on the law, the agreement field, the morals is the ability to hide
stuff and get away with it. Well, you can't hide stuff in a tiny tribe very well. Even if you
can do it once, twice, 10 times, sooner or later of hide is your instinct you'll be revealed,
and the costs will exceed what you've built up by pulling it off however many times you've done it.
And so there's a forced transparency in that smallness of evolutionary scale.
And when you start to get up to a large scale, and now there have to be systems where everybody
isn't seeing everyone, and I'm smart enough, I can figure out how to play it and fuck the whole
while pretending that I'm not hiding the accounting of it and getting ahead, that's the evolutionary
niche for corruption, for parasitic behavior. So one way I would describe, and as you've
described done here before, if there's a niche with some energy and it's going to get exploited,
we have to rigorously close the evolutionary niches for human parasitic behavior,
humans parasitizing other humans. And the first part of that is a kind of forced transparency
that if someone were to engage in that, it has to be known. And now the question is, that's
all the versions of that we've explored at scale look like dreadful surveillance states.
So how do you make something that doesn't look like a dreadful surveillance state
that also doesn't leave evolutionary niches for parasitic behavior that ends up rewarding and
incenting sociopathy? Absolutely. So a bunch of different threads. One, the L and R Ostrom work
is important, because it does point to the fact that you can scale these mechanisms up. In fact,
selection has scaled up these enforcement mechanisms beyond a tiny number of people who
know each other intimately. Now, it hasn't scaled them way up, but it's proof of concept
in terms of the ability to get there. And it's a model of what these systems
might look like. The other thing though, your focus on corruption I think is absolutely right.
And one way to just detect how stark the difference is, is the recognition of how many times
in an average day you encounter bullshit. In other words, how many advertisements do you
encounter in an average pre COVID day, let's say? These are all cases where somebody you don't know
or almost all of them are cases where somebody you don't know is attempting to manipulate you
into spending resources differently than you would otherwise spend them. So this is an
overwhelmingly dishonest interaction with your world. And there would have been some dishonesty
for an ancient ancestor. You know, obviously there are creatures that attempt to look like
what they are not. But in general, one could see the world as it was, and the deception was the
exception, not the rule. And in some sense, we live in a sea of bullshit, right? And we're so used
to it that we don't even recognize that that's abnormal, that it is the result of a gigantic
niche that has opened up as a simple matter of scale, as you point out. And that restoring a
state where you can actually trust your senses, you can by and large trust the people who you're
interacting with to inform you rather than lie to you, would be a huge step towards
reasonability. Oh, I really hope that we follow all the threads here, because this is getting so
close to the heart of what we have to do. As scale increases, the potential for asymmetry
increases. And as the asymmetry increases, the asymmetric warfare gets more difficult to deal
with. So let's think about this in terms of market theory. Let's think about an early hypothetical
idealized market, like literally people just took their shoes and their cows and their sheep and
their service offerings to a market, and they looked at exchanging them. And then because
trading cows for chickens is hard, we have some kind of currency to mediate a barter of goods and
services, but we're talking about real goods and services. Maybe there's two people, maybe there's
five people that sell shoes, there's not 5,000 of them. And I can go touch the shoes myself,
I can talk with them, I can see what the price is. And there is no hypernormal stimuli of advertising,
it's like somebody yelling from his thing. So there's a symmetry between the supply and the
demand side. The supply side is a guy or a few guys selling something, and the demand side is
a person or a family trying to buy something, and they can kind of tell each other's bullshit
to some degree of symmetry, buy or beware becomes an important idea. But now when this becomes Nike,
and then still one person, there's still a symmetry between supply and demand in aggregate,
meaning the total amount of money flowing into supply equals the total amount flowing out of
demand, but this side is coordinated and this side isn't. You don't have something like a labor union
on all purchasers, where like all Facebook users are part of some union that puts money together
to counter Facebook and lobbying and regulation, you have Facebook as like a close to a trillion
dollar organization against me as a person. And I'm still the same size person that I was in those
early market examples, but there wasn't like a trillion dollar organization. And now when that
happens, manufactured demand kills market theory and classical market theory, which is the idea of
why a market is like evolution, right? It's like some evolutionary process is that the demand is
based on real people wanting things that will actually enhance the quality of their life. And
so that creates an evolutionary niche for people to provide supply and then the rational actor will
purchase the good or service at the best price and the best value. But of course, as soon as we
get to a situation where, and you look at then a reality and all the behavioral economics saying
the homo economicists, the rational actor doesn't exist, we end up making choices based on status
that's conferred with a brand based on the compellingness of the marketing based on all
kinds of things that are not the best product or service at the best price. But you also get
that I want stuff that will not increase the quality of my life. I desperately want shit
because the demand was manufactured into me. So it's not an emergent authentic demand that
represents collective intelligence. It's a supply side saying I want to get them to want more of
my shit. And I actually have the power to do that using applied psychology like actual and as soon
as you get to split testing and the ability to AI split test a gazillion things, we're talking about
radically scientifically optimized psychological manipulation for the supply side to create
artificial demand and then be able to fulfill it. And most of that ends up being of the type
that is actually bad for the quality of the life of the people, but you have the plausible
deniability. They're choosing it. Hey, I don't want to be patriarchal and control what they're
doing. The people are choosing it. I'm just offering the source of supply that they're
wanting bullshit. That's like offering crack to kids. And then when they come back for more of it,
like saying, Hey, so this is that was one of the threads I wanted to address.
Well, I love it. Back in must have been 2013, when Game B was actually a group of people who
met in a room and talked about things. One of the points that I was making in that context
was this inherent asymmetry around unionization and that the problem is unions have gotten a bad
wrap because of the tight association cognitively that we have with labor unions, right? We think
of unions and labor unions as synonymous, but union is actually a category. It's potentially a very
large category. And effectively, management always has the benefit of it. The question is, will
workers have a symmetrical entity, right? That's the labor case, but you can make the same case
with respect to, you know, banking credit unions don't work. They're very bank like, but if they
were structured in such a way to actually, you know, unionize people who utilize the bank,
could be highly effective, could be a complete replacement for the insurance industry, which
doesn't even make sense in a market context. But as a risk pool, you could do a very effective
job. So anyway, yes, the question is, how do you scale up the collective force? And especially,
how do you do it in light of the fact that the entities that are already effectively unionized
see it coming and they disrupt it with all of their very powerful tools? And so,
well, anyway, go ahead. I want to say the beginning of an answer to that, because I think it brings
us to what you've been largely exploring in this show of late of the breakdown of democracy and
open society and what do we do about that and how that relates to breakdown in culture and
breakdown in market. We can look at those, the relationship between those three types of entities.
So, a way of thinking about what the architectural idea of a liberal democracy is,
and why, say, the founders of this country set it up not as a pure laissez-faire market, but as a
state that had regulatory power and the market together, was the idea is that a market will
provision lots of goods and services better than a centralized government will. So, let's
leave the market to do the kind of provisioning of resource and innovation that it does well.
But the market will also do a couple really bad things. It will lead to
increasing asymmetries of wealth inexorably. This is what Piketty's data showed,
but it's just obvious. Having more money increases your capacity to have access
to financial services and you make interest on debt and on compounding interest on wealth.
And so, you end up getting a power law distribution of wealth. So, then a few people
in just the market dynamic would be able to have way outsized control over everyone
else against everyone else's interests. And the market creates opportunities for things
that are really bad. We all know that we want there to be a thing called crime where you don't,
where even though there's a market incentive for child sex trafficking and whatever else,
we say, no, we're going to create some rule of law that binds that thing and
not just have market drive it. So, the idea is that we create a state
that we actually give a monopoly of violence to. So, it has even more power at the bottom of the
stack of what power is than the top of the economic power law distribution. So, the wealthiest people
and the wealthiest corporations will still be bound by this rule of law.
And the rule of law is an encoding of the collective ethics of the people. The ethics
are the basis of jurisprudence. And there is some kind of democratic process of getting to say,
what is it that we consider the good life and important that we want and trying to rule of law?
We give that a monopoly of violence. And really, then the goal of the state is to bind the predatory
aspects of market incentive while leaving the market to do the things that it does well.
But pretty much every law is where someone has an incentive to do something, which is a market type
dynamic that is bad for the whole enough that we make a lot of bind it. Okay, so the purpose of a
state is to bind the predatory aspects of a market. That only works as long as the people
bind the state. And the people bind the state, if you have a government of for and by the people
of an educated populace who are who had a quality of education that were capable of understanding
all the issues upon which we are governing and making law. And a fourth estate, where the news
that they are getting is of adequate quality and unbiased enough that they're informed about what's
currently happening. If you think about that, that's what a republic would require. And you
realize that both public education and the fourth estate have eroded so badly for so long. It's not
that we're close to losing our democracy. It's dead. We don't have a republic. We have a permanent
political class and a permanent economic lobbying class. And the people who aren't really actively
engaged in government in any way at all beyond maybe jury duty now and again, if they can't get
out of it. And if the people to be engaged in government in any meaningful way had to tell the
DOE what they think should be done about grid security and energy policy or tell the DOD what
should be done about nuclear first strike policy or tell the Fed and Treasury what they think about
interest rates, they have no fucking idea how to have a governance of for and by the people.
They don't have that education. They don't have the media basis. So if the culture, if the people
can't check the state, then the state will end up getting captured by the market. And so you'll
end up having the head of the FDA be someone who ran a big drug or a big ag company and the head of
the DOD being somebody who ran Lockheed or some military industrial complex manufacturer. You'll
have just lobbying, just straightforward lobbying gets paid for by somebody who's it get paid for
those who have the money to pay for lots of lobbyists. And so then you end up getting a
crony capitalist structure, which is worse than just an evil market, because now it has the
regulatory apparatus of rule of law and monopoly of violence backing up the market type, the dynamics.
So then we say, okay, well, what do we do here? And we see that civilizations fail towards either
oppression or chaos, right? Those are the two fail states. They fail towards oppression.
If trying to create some coherence happens through a top down forcing function. They fail towards
chaos. If not having enough top down forcing function, everybody kind of believes whatever
they want, but they have no unifying basis for belief. And so then they will end up going into
they'll they'll balkanize, they'll tribalize and then the tribal groups will fight against each other.
If you don't want to so and so either we keep failing towards chaos, which we can see is happening
in the West and in the US in particular right now. And then China, which is happy to do the
oppression thing and oppression beats chaos and war, right? Because it has more ability to execute
effectively, which is why China has built high speed trains all around the world when we haven't
built a single one in our country. So either we lose to China in the 21st century and oppression
runs the 21st century, or we beat China at being China, I mean, be it an oppression or it's like,
fuck, those are both failure modes. What is the what is there other than oppression or
or chaos is order that is emergent, not imposed, which requires a culture of people who can all
make sense of the world on their own and communicate effectively to have shared sense making as a
basis for shared choice making. The idea of an open society is that some huge number of people
can all make choices together, a huge number of people who see the world differently and are
anonymous to each other, not a tribe. That was an Enlightenment era idea, right, born out of the idea
that we could all make sense of the world together, born out of the philosophy of science
and the Hegelian dialectic that we could make sense of base reality, and that we could make
sense of each other's perspective, dialectic, find a synthesis, and then be able to have that be the
basis of governance. So what what I think is this is not an adequate long term structure, because
we can talk about why tech has made nation state democracies obsolete, and it's just not obvious
yet, but it has. But as an intermediate structure, the reboot of the thing that was intended has to
start at the level of the people at culture, and that collective sense making and collective good
faith dialogue, because without that, you can't find state without that, you can't find market
incentive. Okay, I love this riff of yours. Okay, I think there's a tremendous amount that's really
important. And the synthesis is super tight. I know people will have a little bit of trouble
following it, but I actually would advise them to maybe to go back through it and listen to it
again, because it's right on the money as far as I'm concerned. There's one place where I wonder
if it doesn't have two things inverted. So you talk about the two characteristics that are necessary
in order for, what did you call it, liberal democracy or whatever it was that you used as a
moniker to function? One of them had to do with the idea that the state was big enough to bind
the most powerful and well resourced actors. And the second was that the people have to be capable
of binding the state. Now, I understood you to say that what failed first was the people's ability
to bind the state. Is that correct? I'm saying that's at this foundation of the stack that we
have to address the failure with recursion. So as I see it, what happened was the power,
the fact that there is always corruption, it's impossible to drive it out completely.
The corruption self enlarges the loopholes and becomes subtle enough that it's hard to see
directly. The most powerful actors suddenly got an infusion of power and we could trace down the
cause of it. But let's just say somewhere in recent history, the most powerful actors became
more powerful than the state. And what they did with that power was they unhooked the ability
of the state to regulate the market. I believe the reason for this was that each individual
industry had an interest in having its regulations removed in order to create a bigger slice of the
pie for it. And so effectively what you had was each industry agreeing to unregulate every other
industry. You can unregulate, if I'm a pharmaceutical company and you're an oil company and you want
to make money but you have to be able to fuck up the atmosphere to do it, and I want to make money
giving people drugs that they shouldn't have and corrupting the FDA, then we'll partner. And so
what you got was many industries partnering to unhook the ability of the state to bind the market.
But one of the things that they had to do in order to make that work
was they had to eliminate the ability of the people to veto. And so this is where we get this
incredibly toxic duopoly that pretends to do our bidding and pretends to be fiercely opposed,
the two sides of it. But in fact, the thing they're united about is not allowing something else to
compete with them for power. So it's the wolf in sheep's clothing is in charge of the thing that
is supposed to be protecting us from wolves. In any case, we don't have to go too deep there.
This is actually super important. Go for it. This is related to the thing we said about
as the market as a whole gets bigger, then the individual consumer stays an individual consumer,
but the supply side, the company gets much larger. As that happens, the asymmetry of the war between
them of the game theory between them gets larger. And so manufactured demand becomes a more intense
thing. Well, the same thing is true in terms of the market capacity to influence the government
and the market government complexes capacity to keep the population from getting in the way of
the extraction. And so there's a heap of mechanisms that happen. And there's not like five guys at
the top who are coordinating all this. It's a shared attractor or incentive landscape that
orients it. Yeah, largely emergent. Yeah. And where there are people conspiring, it's because
they're shared incentive and capacity to do so, which so the conspiracy is itself an emergent
property of the incentive dynamics, which then in turn doubles down on the types of incentive
dynamics that make things like that succeed. So, okay, let's take a couple examples.
If people haven't read it, they should all read at least the Wikipedia page on public
choice theory, a school of libertarian thought that critiques why representative democracy will
always break down that the founders of the US basically said this, which is
all right, we'll come back to cemetery for a moment. At the time that we were creating the
structure of liberal democracy, the size of choices and the speed of them was smaller and
slower, such that the town hall was a real thing. And when the town hall is a real thing,
the coupling between the representative and the people is way higher, right? Because the people
are actually picking representatives in real time that are really representing their interests and
they get to have a say in it. There was a statement by one of the founders of the country that voting
is the death of democracy, because the idea is we should just be able to have a conversation that
is good enough that we come up with a solution and everyone's like, that's a good idea. If we can't,
then we vote, but that means that some big percentage close to half the population feels
unhappy with the thing that happened. And so it's a sublimated type of warfare. It's a sublimation
of violence, but that leads to a polarization of the population. And so the goal is not voting.
Voting is the last step of when we couldn't just succeed at a better conversation and specking
out what is the problem? What are the adjacent problem? What are the design constraints of a
good solution? Can we come up with a solution that meets everybody's design constraints as best as
possible? Okay, so I disagree with this at one level, as I'm sure you will as well. I'm not sure,
but I suspect, but I love something about the formulation that voting is itself a kind of failure
mode, right? That ideally speaking, if you had a well oiled machine, if you had a, you know,
military is the wrong analogy here, but let's say you had a, you know, a ship of people fighting
impossible odds to make it back to safe harbor, right? The point is, you really shouldn't want a
system in which you're voting between two different approaches to the problem. You should want a
discussion in which everybody by the end is on board. And if you tried to do that in civilization,
we'd never accomplish anything, right? You effectively have to give the majority the ability
to exert a kind of tyranny over the minority in order to accomplish the most basic stuff.
But that's because the system is incapable of doing what a better system would do,
which is to say, this is the compelling answer and you're going to know why by the time we decide to
do it. Wait, there's a cemetery here between the conversation that we had about the market
incenting people who focus on the opportunity and not the risks. That's that it actually
suppresses those who look at the risk. Once you say, Hey, there's always going to be somebody
talking about a risk that isn't going to happen. We'll innovate our way out and that becomes the
story. Now you have plausible deniability to always do that. Once you say, there's no way to
get everybody on the same page. We can't do that. It'd be too slow. Now I don't even have any basis
to try, right? And so I don't ever even try to say, what is it that everyone cares about relative
to this? So I even know what a good solution would look like to craft a proposal. No, we're going to
vote on the proposition having never done any sense making about what a good proposition would be.
And that's just mind blowingly stupid, right? And so then who's going to craft the proposition?
A lawyer, a lawyer is paid for by who some special interest group. And so now, so most of the time,
what happens is you have some situation where one thing that matters to some people has this
proposition put forward that benefits it simply in the short term, but it externalizes harm to
something that matters to other people. But ultimately, all of it matters to everybody,
just differentially weighted. And how do we put all those things together? So, okay, we're going to
do something that's going to benefit the economy, but harm the environment. Well, everybody cares
about the economy and everybody cares about the environment. But if I put forward a proposition
that says, in order to solve climate change, we have to agree to these carbon emission controls
that China won't agree to and therefore China will run the world in the 21st century and we all
have to learn Mandarin or be like the Uyghur or something. Okay, well, now I have a bunch of people
who, because they hate the solution space, because it harms something else they care about,
don't believe in climate change. It has nothing to do with not believing in climate change and
not caring about the environment. It's that they care about that other risk so much as well.
But if I said, okay, well, let's look at- It's a negotiation tactic is what you're saying,
that at the point that you want X prioritized over Y, you'll descend into a state in which
you'll make any argument that results in that happening, including Y doesn't exist.
Exactly, because I'm so motivated by this other thing and the solution has a
theory of trade-offs built in that is not necessary. Sometimes the theory of trade-off is
necessary, but oftentimes a synergistic satisfactor could be found, but we didn't try in the same way
that a way to move forward with the opportunity without the risk could have happened. We could
have found a better way to do the tech that internalized that externality. We just need to
try a little bit more, but there isn't the incentive to do it. So let's say we said, no, we don't care
about climate change by itself. We care about the climate and we care about the economy and we care
about energy independence and we care about geopolitics. And we're going to look at the
adjacent things. We're making a choice in one of the areas necessarily affects the other area.
And we're going to bring those design constraints together and we say, what is the best choice that
affects these things together? Then we could start to think about a proposition intelligently.
We don't do this in medicine either. We make a medicine to solve a very narrow definition of
one molecular target of a disease that externalizes side effects in other areas without addressing
upstream what was actually causing the disease. And then the side effects of that med and of
being another med and then old people die on 20 meds of iotrogenic disease. So in complex systems,
you can't separate the problems that way. You have to think about the whole complex thing better.
So the first part of fixing, one part of fixing democracy that we have to think about
is we have to define the problem spaces better, more complexly. And we have to be able to actually
have a process for coming up with propositions that are not stupid and intrinsically polarizing.
Because almost no proposition ever voted on gets 90% of the vote. It gets 51% of the vote,
which means half of the people think it's terrible. And so what that means is you care about the
environment. I care about the economy on proposition A. Well, you petition to get the thing to go
through because you care about the owls there, but I think that you're making my kids poor.
You're my fucking enemy now, and I'll fight against you. Now all the energy goes into internal
friction fighting against each other. And any other country that's willing to be autocratic
and force all their people onto one side will just win. And we will increasingly polarize
against each other over something where we could have found a more unifying solution.
Now, this is fascinating. For one thing, you blazed by it there. But I think so there's a
place where Jim rut tells me that some place that you and you and he overwhelmingly agree also,
but there's a place in which you and he have hung up where he says that you believe that a
properly architected system can do away with the trade offs. No, right? Right. I think I just heard
you give the answer that he must have understood to be that, but wasn't it? Am I right that the
answer there are lots of times when you don't see a trade off, because you have two characteristics,
both of which are suboptimal, and you could improve them simultaneously. And so it looks
like there's no trade off between them. If you push it far enough, you'll eventually reach the
efficient frontier where you do have to choose. But if you're not near the efficient frontier,
there's no reason to treat it as a trade off. Is that? Yes, I'm not saying that we get out of
having constraints. I'm saying we can do design by constraints much better than we currently do.
And so I'm saying that there's a lot of things that we take as inexorable trade offs that aren't.
Well, so you and I will have to chase this down at some point. My argument will be
any two desirable characteristics have an inherent trade off between them,
even if you never see it, right? There are reasons you wouldn't see it, but that if you push these
things far enough, you'll find that there are no desirable things that can be components of the
same mechanism that will not exhibit a trade off relationship. Right? Interesting. Initially,
I don't agree with that at all, but I'm sure you've thought about it a lot. So I'm curious why you
say it. Well, let me give you let me give you the example I used to battle my friend Scott
Pecour over with this, which is he said, why can't you make a car that's the fastest and the
bluest? Right? And it, you know, the first time I heard that I was like, well, okay, maybe blue is
trivial enough, but it's not. In fact, if you wanted to make a car that was the fastest and by
fastest, let's say fastest accelerating, well, you're going to have to decide how to paint it.
If you also decide that there's some color of blue that is bluest and you want the car to
be that color, well, then it has done a lot of the choosing of what paint you're going to put on it
at the point you decide to paint at that color. That paint will have components that will weigh
something, right? The chances that the bluest, whatever you define that to be is also the
lightest and has the best laminar flow characteristics are essentially zero, right? Because
they're an infinite diversity of colors, they will be made out of a wide variety of materials,
and the chances that the blue just happens to be the one that is lightest and has the best,
you know, slipperiness relative to the wind are going to be vanishingly small. And that means
that if you want to make truly the fastest car, its color will be chosen by whatever paint has
the best characteristics. And if you want to make it the bluest as well, you'll make some tiny compromise
that will, you know, probably not matter to you, but it's there. So the tradeoff is there,
even if we don't see it. But here's the thing, Daniel, I discovered many years after my argument
with Scott was long since put to bed that I was right about this. And the way I found out was that
there is a case where the Navy wanted to set the time to climb record for an aircraft, and they
took an F-15 and they souped it up a little bit. And in order to set the basically the vertical
climb rate of this aircraft, they stripped the paint off it. And so if you look at pictures of
this aircraft in its, you know, its record setting run, it isn't any particular color. It's many
different colors because effectively you've got the bare metal underneath with the paint stripped
off it to save however many pounds of paint they were able to remove. Okay, there are three points
I'm up to address my initial thoughts on this here. So one is
with this particular case of a car, the difference between the blue and the optimal color might be
at the boundary of measurement itself. Yep. And so while it's true that there, it might not be a
perfect optimum of both at the level of like a nanoscale optimization, it is irrelevant to the
scale of choice making for the most part. And when we look at something like 100%. And when we look
at something like Tesla cars that became faster off the line than Ferraris and safer than Volvos
and greener than Priuses at the same time, you could see that ground up design, just doing a
better job of ground up design was able to optimize for many things simultaneously so much better.
Now, had they made it less comfortable, could it be faster still? Sure, of course. So it's
optimizing for a product of a bunch of things together, but still in a whole different league
than things had been previously. Now, this is beautiful. Okay, because this is exactly what
I was hoping for. Okay, this is a question of us tripping over each other's language.
Jim misunderstood what you were saying, right? And he asked me about it. And I said,
yeah, Daniel can't be right about that if he's saying what you think he's saying. But of course,
it wouldn't make sense that you would think that you could. So your point about this being trivial,
you're in complete agreement with me. And I suspect it would take nothing to get
Jim to agree to that formulation as well. There's a difference. There's one more thing I have to say
here. Okay. Of course, I'm not pretending that thermodynamics don't exist. Right. And once you
get down to the quantum scale arrangement of a thing that orientation in one direction doesn't
have effects on other things. There's a difference also between the blue and fast
are two different preferences that are arbitrary that both want to be associated with a car that
don't have some intrinsic unifying function. And we can say blue is a thing that's reasonable
to be preferential about color. Whereas I would say that there are some characteristics that have
a synergistic effect that increasing one increases the other one because of the way they are part of a
overall increase in system integrity. And so synergy is the key concept I'm trying to bring
about here, which is behavior of whole systems, more than the sum of an unpredicted by the parts
taken separately. So when I say I'm looking for synergistic satisfiers, the idea that I have
X amount of input, and that input has to be divided between these various types of output and
it's linear is nonsense. I can have X amount of input and have something where the total
amount of output has increased synergy based on the intelligence of the design. The question of
how do we design in a way that is optimizing synergy between all the things that matter becomes the
central question? Yes, which is of course the central question that selection must be dealing with
in generating complex life. And again, I don't think we have a hair's breadth of difference on
what we turn out to believe about this tradeoff space. But what I would say is, and I don't want
to drag the audience too far down this road, it's probably not worth it for what we need to do here.
But the benefit of being able to say, so let's take your example of there are certain characteristics
that will co maximize not really because of the following thing. Let's say that we figure out
what color is best for making the fastest car. And then we say, well, I want to maximize
gray 37 and speed. Now I can do it. I can maximize gray 37 and speed because it just so happens that
gray 37 is the color that has the best characteristics for speed, right? But then the point is you
can't separate these two things, whatever characteristic it is, you're actually maximizing,
you've just found two aspects of it. So your point about synergy is that perfectly aligned
characteristics, we could describe that joint that fusion of those two things as one thing,
and we could maximize it, right? But then if we take the next one over, right, the next characteristic
that we want to add to the list of things, then again, we're back in trade off space. So my only
point here is that there is a value in order to be able to get the maximum power out of a trade
off theory. What we want to do is make it minimally complex and the ability to say every two desirable
characteristics have a trade off between them. The real question is the slope or the shape of the
curve, right? And that many of these slopes and shapes mean we will see no meaningful variation
on it because one side is a bargain, and we will always see that manifest, right? That's the reason
we don't see trade offs everywhere is that in some cases, a trade off is so dumb that we don't see
anybody exercising variation, everything has made the same decision. Yes, and I think for all practical
purposes, we agree that being able to make a Tesla that is safer than a Volvo and faster than a Ferrari
and greener than a Prius is a possibility, and that we can, if we apply that to all of the problems
in the world, we could do a fuck ton better job. Yeah, I think we also agree, and I love the last
point that you made to the degree that two things can be simultaneously optimized, they can be thought
of as facets of a deeper integrated thing. Yep. Okay, so now to answer the way that I actually
think about it, though this is irrelevant, if people disagree, it doesn't matter at all to the
earlier point, I have to wax mystical a moment. When Einstein said it's a optical delusion of
consciousness to believe there are separate things, there's in reality one thing we call universe,
and everything's a facet of it.
If I look at the real things that we have theory of tradeoffs between in the space,
in the social sphere, and the associated biosphere that we're a part of.
So let's say we talk about in the very beginning of our conversation individual, what would optimize
my individual well-being, and what would optimize the individual, and what would optimize the well
being of all humans. I believe that I only find that those are differently optimized
if I again take a very short term focus. If I take a long term focus, I find that they are one thing,
because the idea that I'm an individual, and the idea that humanity is a separate thing is actually
a wrong idea. They're facets of an integrated reality, and that if I factor all of the things
that are in the unknown unknown set over a long enough period of time, they're simultaneously
optimized. And this is the essence of dialectical thinking, is looking for the thesis and the
antithesis, and not voting between thesis and antithesis, but seeking synthesis that's at
a higher order of integration and complexity. Totally agree. And so I don't know how many
people will be tracking it, but effectively saying on an indefinitely long time scale, these things
converge is an acknowledgement that we are not talking about design space when we make this
recognition. It's more like trajectory, and that is perfectly consistent. And frankly,
I think if everybody understood at some level the kind of picture we're painting,
people would be really comfortable with the degree to which it doesn't do exactly the thing they
most hope it will. In other words, the level of compromise is small. Which is why the compromise
in a healthy democracy even was tolerable, even though that was nowhere near as optimal a system
as we could develop. Okay, there's a point a number of minutes back that I want to return to,
and I want to drop an idea on you. It's actually a place where something you said caused me to
complete a thought that I've been working on for some time. So the thought as it existed is
that markets are excellent at figuring out how to do things, and they are atrocious at telling us
what to do. In other words, they will find every defect in human character and figure out how to
exploit it if you allow them to do that. But when you have a problem that you really want solved,
how can we make a phone that doesn't require me to be plugged into the wall, allows me to get a
message across a distance to report an emergency, whatever. Markets do a better job than we could
otherwise do of figuring out what the best solution is. And so in some sense, the question is,
how can we structure the incentives around the market so that markets only solve problems
that we want them to solve, but they can be free to solve them well? And what I think I realized
in this conversation here is that in some sense, the role of the citizenry in a democracy
is to discuss the values that we want government to deploy incentives around. In other words,
the people by deciding what their priorities are, what their concerns are, which problems are top of
the list to be solved, and which ones could take a backseat, that that's the proper thing that we
are to be discussing. That the role of government freed from corruption would be to figure out what
incentives will result in the best return on our investment, structuring the incentives of the
market, and then the market can be freed to solve the narrowest problems on that list. And I think
we fail at every level here, but from the point of view of what we're actually shooting for, I would
say it's somewhere in that neighborhood, that division of labor between the citizens, the apparatus
of governance, and the market. I'm suffering a little bit here because there's like 10
simultaneous threads that I really think could address that are important, and I know we're
going to open up more in starting. It would be really fun to go through the transcript of this
and come back to the most important threads. Might be worth doing actually. So,
first, I want to say something against heterodox market theory is I don't think the market is
the best system for innovation of a known what. And I think World War II and the Manhattan Project
is a very clear example in the Apollo project. And our failure at fusion, I would say, that the
point you're about to make to me, fusion would be our top priority because it's the only plug and
play solution to a large piece of our problem. And the fact that we decade after decade are
awaiting a proper fusion solution says, despite the fact that the market could potentially solve
it, the problem is the investments are too large on the front end and the reward is too
delayed for the market to actually even recognize the problem correctly.
Venture capital is not going to put up the amount of money that a nation state can
for the amount of time that's necessary. And when you look at the very largest jumps in
innovative capacity, a lot of them happen by nation-state funding, not market funding, and then
a market emerging in association with government contracting. And so, if we look at why the Nazis
were so technologically farther ahead than everyone else going into World War II with the enigma
machine in the beginning of computing with the V-2 rocket, it was not a market dynamic, it was a
state dynamic where they invested in science and technology development for a long time,
which is why this tiny little country with limited industrial supply capacity had more
technological advancement than the Soviets or the US. And it was our ability to steal their
shit and rip it off and then be bigger than them. That was a big part of how we were able to
succeed in the war effort. And so, that's a clear example that like computers were developed by a
state, not the market. Well, hold on a second. I want to be careful because I don't want to
falsify something that isn't false. I again think this is a place where our mappings or at least
the language surrounding them is going to upend us because this sounds like a place where a government
is capable of generating a massive incentive to cause a problem to be solved that the market won't
even find on its own, right? So, that does not strike me as inconsistent with what I was just
saying. The state recognizes there's a problem, creates an incentive big enough to find the solution
and that incentive can be big enough to cause people to get different degrees than they would
otherwise seek. But in these cases, it wasn't like, so let's take the Manhattan Project,
it wasn't private contractors that solved it because the government had made the incentive,
it was actually government that solved it. It was government employees. And so,
this is an important distinction. NASA was not a private space contracting thing that did the
Apollo project, it was a government project. So, I would say the largest jumps we ever made in tech
did not happen in the market for the most part. Well, so then I guess the test of your
falsification here is the following question. If the Manhattan Project had consisted of a state
yanking people out of their beds and standing over them with rifles, would it have worked? I mean,
it may be, you know, the Russian version is closer to that. But I think the point is,
you still have a system of incentives correctly solving a problem that the market would not
have found on its own and no entity in the market would have been big enough to solve.
So, I still see it as consistent. But you might convince me otherwise, especially if it turns
out that a negative incentive would be just as effective at creating the solution.
There's a story that people don't innovate well under duress. The innovation requires executive
function and prefrontal function. And if they're too limbically oriented, they want to innovate
well, which is one of the reasons why we need an open society. And I think there's probably
some truth to this, but less truth than we would hope. I believe it was called the Shoroska system,
which was a Russian, basically, prisoner of war type camps that had scientists that were
doing real innovation up to, you know, early Sputnik like work. So, we know that people
under rifle duress can innovate. We know that people conscripted by draft into an army can
actually innovate on behalf of the military. Now, I think that it's true that something more like
a market will explore more edge cases that are not known what's and come up with interesting
things, whereas the centralized thing can do a better job sometimes of existing what's that
require very high coordination. Because if you look at the Manhattan project, the scale of the
budget and the scale of coordination, no company has that and a bunch of companies competing for
intellectual property and whatever it wouldn't have worked, right? One of the reasons I bring
this up is because there's a whole bunch, you mentioned fusion, whether it's fusion or whether
it's thorium or whether it's closer to room temperature super conduction or any of the
things that could possibly generate, whether it's 65% efficient photovoltaic through nanotech.
There's a bunch of things where we're like, we kind of know the science that could lead to the
breakthrough, but the level of investment just isn't there. And I think there's a heap of examples
like this where the percentage of the budget of the national budget that used to go to R&D
has went down a lot and it shouldn't. And the Apollo project was kind of the last thing of its type.
And then the government starting to shift to government contractors started to be a source
of massive bloat where the government contractors had an incentive to just charge whatever the
fuck they wanted, which is why then Elon could beat Lockheed and Boeing at rockets so much cost-wise
because then in that situation, he didn't have to do the fundamental innovation on rocketry,
he could just out-compete them with market incentive. And then that could create enough
money for iterative innovation. I think fundamental innovation of certain scales does
require larger coordination than markets make easy. Okay, so then I want to modify what I said
because you've convinced me I didn't have it right in the initial one. So the point then is you have
to extend the governmental structure so that it can deal with two types of market failure,
one surrounding the natural system of incentives, which will cause you to innovate things that do
net harm, for example. And the other is a failure where the scale of the market is not sufficient
to solve certain problems that are in our collective interest to solve. Yes, and we don't want to give
the government that much power because we don't trust that kind of authority. But that's because
the people aren't checking the government, which comes back to the thing that we talked about earlier.
And now this becomes one of the central questions of the time is what is the basis of legitimate
authority and how do we know? And what is the basis of warranted trust? Because we all know what it
means to have trust that isn't warranted. Everyone who disagrees with us, we think that their trust
isn't warranted, right? Like if we're on the left, we think people who believe in who trust Trump,
it's unwarranted. And they think that the people who trust the FDA or vaccine scientists or the
CDC have trust it's unwarranted. We also know that legitimate authority, the idea of legitimate
authority is so powerful to be able to be the arbiters of what is true and what is real, that
anyone who is playing the game of power has a maximum incentive, however successful they are,
to be able to capture and influence that for their good. We also know that it's possible to mislead
with exclusively true facts that are cherry picked or framed. So I can cherry pick facts on one side
or the other side of a Gaussian distribution and tell any story I want that will make it through a
fact checker. So fact checking is valuable but not even close to sufficient. So I can lie through
something like the Atlantic as well as I can lie through something like Breitbart through
different mechanisms for different populations. Yeah, this is a super excellent point as well
that a fact checker airs in one direction and if you can build a falsehood out of true
objects that have been edited then the fact checker won't spot it. So love that point.
And so I can do a safety analysis on a drug and I'm not looking at every metric that matters.
I'm looking at some subset of the metrics and it might be that it's safe on those metrics but
all causality increases, life expectancy decreases but I only did the safety study for two years
so I wouldn't notice that. So I can say no methodologically this was perfect and sound. It
just also doesn't matter because I wasn't measuring the right things. Right and so this also
basically what you have just said means that the replication crisis can be understood as a mechanism
for generating data which can be cherry picked to reach any conclusion you want about the effects of
this intervention or that intervention right because effectively what you have is the ability
to choose between experiments where sampling error will result in both outcomes being
evident somewhere. This is another one of those is it conflict theory or information
or mistake theory thing is I can intentionally manipulate an outcome that looks methodologically
sound and then say oh we just didn't know those factors right. I'm not saying that whether that's
happening or not it certainly can happen. Okay so now we get back to so what is the how do you have
a legitimate authority that has the power of being the arbiter of what is true and real and all the
power that's associated and have it not get captured by power interests is a very very important
question. How in the name of the Bible and Christendom and Jesus saying let he who has no sins cast
the first stone did we do the Inquisition right like weird mental gymnastics by which the authority
of that thing was able to be used for the power purposes of the time and so now when you start
to have increasing polarization between the left and the right and historically more academics being
left leaning and the social scientists the social sciences being so complex that you can cherry pick
whatever the fuck you want and do methodologically sound and yet still misrepresentative stuff
then you say is that actually a trustworthy source and then we say okay well do we want
a bunch of wacky theories going out over Facebook and Twitter and whatever do we want to censor it
well if we censor it who is the arbiter of truth that we trust if we don't censor it we're appealing
to the worst aspects of everyone and making them all worse in all directions like those both suck
so bad and that's the oppression or chaos right and the only answer out of the oppression or chaos
is the comprehensive education of everyone in the capacity to understand at least three things
they have to increase their first person second person and third person epistemics
their third person epistemics is the easiest philosophy of science formal logic their ability
to actually make sense of base reality through appropriate methodology and find appropriate
confidence margin second person is my ability to make sense of your perspective can I steal man
where you're coming from can I inhabit your position well and if I'm not oriented to do that
then I'm not going to find the synthesis of a dialectic I'm going to be arguing for one side
of partiality harming something that will actually harm the thing I care about in the long run
and then first person can I notice my own biases and my own susceptibilities and my own
group identity issues and whatever well enough that those aren't the things that run me
when I look at kind of the ancient greek enlightenment the first person was the stoic
tradition the second person was the Socratic tradition the third person was the Aristotelian
tradition there's a mirror of all those in modernity we need a new cultural enlightenment now that
where everyone values good sense making about themselves about others about base reality
and good quality dialogue with other people that are also sense making to emerge to a collective
consciousness and collective intelligence it is more than our individual intelligence
and with so that we have some basis of something that isn't chaos but that also isn't depression
because it's emergent more than imposed so it's like it's cultural enlightenment or bust as far as
I'm concerned all right so I don't disagree with you fundamentally I believe this is a place where
when I say my version of this which is much less sophisticated in some ways and focused
elsewhere but when I say my version of it I lose people because my version of it is something like
what we need to do is doable we can see the trajectory from here you can't see the objective
but you can see the direction to head and it will take three generations to get there right
I agree what you're describing you couldn't just simply take that curriculum and infuse it into any
system we've got and have any hope of people learning it or giving a shit about it or whatever
it wouldn't work so you have to build the scaffolding that would allow a population to be
enlightened in this way such that the governance structure you're imagining might arise out of it
could flourish but let's put it this way it's at least at least three generations out before you
had gotten there even if you started doing things right now and so what I try to say to people
in order that they don't completely lose interest in the possibility of a solution because it's too
far out is things can start getting better right away we are not going to live to be in that world
that is the objective and even if we did we would never be native there right our developmental
trajectory will have been completed in a world that doesn't function like that and so
you know you you can be happy as an expat but we would be expats in the world we're trying
to create and that's fine you know if our grandchildren or our great grandchildren
were native there and we could be expats there that that would be a perfectly acceptable solution
but I think in general people have the sense that a solution sounds like something that we
could have in the next few years and I just don't see the possibility of it no you're going to see
things anything that can be implemented quickly you want a red team and say either how does it
fail or where does it externalize harm and also what arms race does it drive if whoever doesn't
like it and if you factor what arms race it drives where it externalizes harm and where it fails
you'll get much less optimistic about most of those things and if you don't go into despair
you'll start thinking long term um and things that converge in long term direction and when
you start to think about that the thesis and the antithesis are both not true they have partial
truth but they are not actually true synthesis is in the direction of more integration of truth
and still not true but in the direction of if I optimize for one of these
it will externalize harm in a way that messes the whole thing up right um and that's why there's
there's a forcing function of the failure modes on both sides that's why it's important to look at
oppression and chaos and say these both create failure modes so what is it that doesn't orient
in either those directions it's not more power to authorities it's not more pure libertarianism
it's something that's outside of that access or it is going to involve the equivalent of negative
feedback right in other words right thermostat works by virtue of not embracing it being hot
or cold but by pushing it in the right direction as it diverts one way or the other so I very much
like your point about synthesis here um just to make it clearer synthesis is two things even
linguistically speaking we can talk of a synthesis right which is an object you could write it in a
book a synthesis between several different concepts could exist in a book um incidentally that's sort
of what I see myself doing in biology is synthesis um but your point is the most important aspect
of synthesis is it is a process or right and so that process is the thing that takes these
competing failure modes and rescues from them something that suffers neither consequence and
heads towards optimality so I agree we have to get good at it yeah so synthesis is an ongoing
process and let's say I have some bits of true information in a thesis and some bits in the
antithesis so the synthesis will have more bits than either of them higher order complexity but
it will still have radically less bits of information than all of reality about that thing the model
is never the thing right it's just it's the best epistemically we can do at that moment
so now I want to go back to the earlier topic around theory of tradeoffs that you said because
I let it go but as soon as you mentioned optimization I have to bring it back because it
comes back exactly here and it also brings back this question you had of that markets can do a
good job with the what with the how but not the what which is the is-ought distinction that comes
up in science right yes it is science can do a good job of what is but not what ought which
means applied science i.e technology i.e markets can do a good job with make with changing is
but not in the direction of ought and so that is ethics which is to be the basis of jurisprudence
and law that's exactly why you bring those things together the and it's because is is measurable
third person measurable and verifiable repeatable it's objective it's objective right whereas
ought is not measurable in a you can do something like Sam Harris does in moral landscape and say
it relates to measurable things but it doesn't relate to a finite number of measurable things
there's a girdle proof that whatever finite number there are some other things that we
end up finding later that are also relevant to the thing that weren't part of the model
that we were looking at and so the thing that is worth optimizing for when you talked about
that the blue and the fast would be part of the same thing the thing that is worth optimizing
for is not measurable it includes measurables but it is not limited to a finite set of measurables
that you can run optimization theory and have an ai optimize everything for us yeah i agree you will
have a long list of characteristics that you can measure and as you go from the most important to
the least important you'll eventually drop below some threshold of noise where you're not noticing
things that contribute so yes you've got a potentially infinite set of things that matter
less and less and you will inherently concentrate on the biggest most important contributors up top
and that's natural it's a it's an issue of precision at some level but one that we we
shouldn't convince ourselves that we're solving the puzzle completely at a mathematical level
an engineering solution is not a complete mathematical solution right okay so now i'm
come back to the waxing mystical thing and it's i don't think it has to be thought of that way
i don't i think the way einstein was doing it and he says spinoza's god is my god i'm happy
to do it that way so the first verse of the day is the dow that is speakable is not the eternal
dow right the optimization function that is optimizable with a narrow ai is not the thing
to optimize for is a is a corollary statement and the and the jewish commandment about no
false idols is that the model of reality is never reality so take the model as this is useful it's
not an absolute truth the moment i take it as it's an absolute truth and i become some weird
fundamentalist who stops learning who stops being open to new input and in optimizing the model
where the model is different than reality i can harm reality and then defend the model so i always
want to hold the model with this is the best we currently have and in the future we'll see that
it's wrong and we want to see that it's wrong we don't want to defend it against its own evolution
and so what we're optimizing for can't be fully explicated and that's what wisdom is
wisdom is the difference between the optimization function and the right choice
oh i love this this is uh this is great obviously it it dovetails with uh the basic sense of what
metaphorical truth is and the recognition that actually metaphorical truth isn't something that
applies to religious style beliefs it's actually the way we do science also you know we have
approximations and you know things get ugly when people forget that that's what they're dealing
with right and they start really treating it as the object itself uh very important example in my
field is the instantiation of the term fitness right which in most cases has so much to do with
reproductive success that we actually just synonymize them most of the time and we speak
as if they're interchangeable which is great except for all those cases where they go in opposite
directions which we are perennially confused by and so anyway uh sooner or later i will
deliver some work that will take the cases that we can't sort out because we've missed
defined fitness and forgotten that it was a model in the first place and shows how you
would solve it differently if you defined fitness in a in a tighter way but uh story for another day
all right so where shall we go you uh you were on a roll
so
so you'll see conversations from really smart people like nick bostrom and max tagmark and whatever of
because of the collective action problem and the multipolar trap race to the bottom
and yet because of the complexity of the issues that we face that are beyond what the smartest
person could manage by a lot is the only answer to build a benevolent ai overlord that uh can run
a one-world government because it can process the information to make good choices so as you
can guess my answer is vigorously no yeah not just because i think the optimization function
that it would run no matter how many variables would end up becoming a paperclip maximizer but
uh i think its own existential risks are bound up in that process these guys know know this um
but it's easy to pick solutions like that compared to the other ones that seem maybe even more likely
to go terrible so then we say okay we don't want a one-world government run by any of the people
we currently have and we also don't want separate nations where any of them that defect lead everybody
into a race to the bottom so that means that they have to have rule of law over each other because
they affect common spaces so how do you have rule of law over each other without it being one-world
government and then capture oppression or chaos at various scales and the only answer is the
comprehensive education and enlightenment of the people that can check those systems now
obviously the founding of this country was fraught with all the problems that we know of
now in particular and it was still a step forward in terms of a movement towards the
possibility of some freedoms from the feudalism it came from and so uh i i find the study of the
foundation of it the theoretical foundation of it meaningful to what we're doing right now
and famously there's this quote from george washington where he says something to the effect of
i'm going to paraphrase it the comprehensive education of every single citizen in the science
of government should be the main aim of the federal government and i think it is fascinating so
science of government was his term of art and science of government meant everything that you
would need to have a government of formed by the people which is the history the social philosophy
the the game theory and political science and economics as well as the science to understand
the infrastructural tech stack and whatever right the hegelian dialectic the enlightenment ideas of
the time but that the number one goal of the federal government is not rule of law and it's
not currency creation and it's not protection of its borders because if it's any of those things
it will become an impressive tyranny soon it has to be the comprehensive education of the people
if it is to be a government of formed by the people now this is the interesting thing now
i remember where i wanted to go comprehensive education of the people is a force is something
that makes more symmetry possible symmetry of power possible it's a increasing people's information
access and processing is a um symmetry increasing function so everyone who has a vested interest
in increasing asymmetries has an interest in decreasing people's comprehensive education
in the science of government and so now let's look at the education changes that happen following
world war two in the us there is a theory there's a there's a story that i buy that the us started
focusing on stem education science technology engineering math super heavily partly because
it was an existential risk because look what happened with the stem that the Germans did and
now we know that a lot of the German scientists that we didn't get an operation paperclip the
Russians got and split neck and so it's an existential risk to not dominate the tech space so we need
to really double down on stem and we need all the smartest guys we need to find every von Neumann
and Turing and Feynman there is all the smarter you are the more we want to push you into stem
so you can be an effective part of the system that's part of the story but also the thing that
washington said the education in the science of government we start cutting civics radically
and i think it was because social philosophers at the time like marks were actually problematic
to the dominant system and i'm not saying that marks got the right ideas i'm saying the idea of
okay we have a system where let's have the only people who really think about social philosophy
be the children of elites who go to private schools who learn the classics and otherwise
let's have people not fuck the system up as a whole but be very useful to the system by
becoming good at stem i think this is a way of being able to simultaneously advance education
and retard the kind of education that would be necessary to have a self-governing system
that's fascinating that's fascinating because of course if you uh have the elites effectively
in charge of governance they can do exactly what you would imagine the elites would hope for
which is to govern well enough that the system continues on no matter what but to continue
to look out for the distribution of wealth and power and make sure nothing upends it right
they'll do it they won't even realize necessarily that that's what they're doing i also love the
fact you know george washington is one of these characters who it's very easy to misunderstand
how good he was because you know he wasn't the most articulate founder or in you know classical
terms the the smartest founder by far on the other hand an awful lot of wisdom buried in in george
washington and uh this idea of you know ultimately he was looking very deeply into the future
potentially to understand why the education of the populace would be effectively synonymous
with the job of government and it's not because the purpose is the education but it's because
that's the only hope that a democratic system will spit out the kind of uh solution that you
want it to generate um which is uh i don't know it's a very it's a very interesting analysis
so it raises something else here which is on my list of notes arising
which is i i notice this pattern all over the place there's a state which is awesome very
powerful in terms of what it can do but it's fragile and so it falls apart right in other
words we will never have a better system as far as i can tell than science for figuring out what's
true and what is possible so it's the most capable state there are measures by which it is the
strongest state but it is also terrifically susceptible to market forces in fact it can't
be in the same room with them right so um we could look for many examples of this where something
marvelous requires a very careful arrangement of conditions in order for it to survive and i'm
wondering what you make of that in light of this discussion i guess it's not hard to make an argument
for why that those two things go together capacity and fragility but what are we to do about it going
forward because surely we're trying to build these states but do so in a robust form they go together
because of synergy which is you have properties that none of your cells on their own have you
as a whole there's a synergy of those cells coming together that creates emergent properties at the
level of you as a whole thing but if i run all the combinatorial possibilities of a way of putting
those 50 to 100 trillion cells together very few of them produce the synergy of you there's most
of them are just piles of goo yeah right and so it's a it's a very narrow set of things that
actually has the very high synergies and it's lots of things that are pretty entropic um and
entropy is also obviously easier i can i can take this house down in five minutes with a record ball
but it took a year to build yep and i can kill an adult in a second but it takes 20 years to grow
so this is why the first ethic of Hippocrates and of so many ethic systems is first do no harm
then try to make shit better but first do no harm if you if you can succeed at the maintenance
function then you can actually maintain your progress functions um and
and
and connect to where you were going with that well so here's here's what i'm after i agree
with your basic entropic analysis that it is easier to destroy than to build the number of
states that work is vastly exceeded by the organization of the same pieces that don't
but what i'm wondering about is is there
in effect one has to be able to build a system that is resistant to that in other words and
life does this right living creatures manage to fend off entropy beautifully and the fact we need a
governmental structure that has that same trick and we haven't seen it yet
and the question is unfortunately i fear
that it is almost a prerequisite that if you build the the capable structure and you haven't
built the thing that protects it first then it will be captured before the wisdom develops
to preserve it against that force and now i remember why i used the analogy of the body
what i'm going to say here is wrong so let's just take it as a loose metaphor
let's take in the body that the closest thing to top down organization is neuroendocrine system
but there's a bunch of bottom up that is at the level of genetics and
and epigenetics and cellular dynamics and whatever and that there is a relationship
between the bottom up and top dynamics well obviously i can take a cell out of a body and
put it in addition it has its own internal um homeodynamic processes it's dealing with entropy
on its own that they don't need a top down neuroendocrine signal for how they do that so let's say we
tried to make a perfect top down neuroendocrine system and the cells had no cellular immune
systems or redox signaling uh homeodynamics or or anything else you would die so quickly right
there is no way to have a healthy body at the level of the organization of all the cells if the
cells are all unhealthy and that's the comprehensive education of the individual thing we're talking
about can you make a healthy system of government as a system can you just get the cybernetics right
with that is separate than that which develops all of the individuals and the
relationships between them and the answer is definitely not okay agreed but then here's the
problem that i'm i'm trying to articulate okay so we agree that the cells have to be coherent
in and of themselves that there has to be a fractal aspect to this uh this uh organization of
things across many scales from the individual up to the the body politic but if it is true that the
key to making that work is that individuals which are analogous to cells here have to be educated in
the nature of governance the theory of governance in order for this to work how would they end up
that way well they would end up that way because governance will have created the conditions that
would cause that education so are we not now saying that what is necessary in order for the
system to function is that the system is already functional in order that it can generate the
conditions necessary no there's no hole in the bucket situation there is a recursive situation
between bottom-up and top-down dynamics um and so let's take the classic dialectic that relates
to right and left it's not the only one of individual and collective for a moment and
say okay fundamentally the right is more libertarian individual pull yourself up by
your bootstraps we want to have advantage conferred to those that are actually doing uh
they're conferring their own advantage uh and doing well and then the left model the more socialist
model is yeah but people who are born into wealthy areas statistically do better than
people who are born into shitty areas in terms of crime and education and access to early health
care and nutrition and all those things and you can't libertarianly pull yourself up by your
bootstraps as a infant or a fetus and so let's make a system that tends to that well
but then the right would say but we don't want something like a welfare state that makes shitty
people that just meets their needs for them and orients them to lay on the couch all day and
do tv and crack okay i think it's i think it's mind-bogglingly silly that we take these as if they are in
a fundamental theory of trade-offs as opposed to a recursive relationship that can be on a
virtuous cycle what we want to optimize for is the virtuous cycle between the individuals and the
society so that do we want to create social systems that take care of individuals but make
shittier people no do we want to create social systems that condition people that have more
effectiveness and sovereignty and autonomy yes and do we want to condition ones that in turn
add to the quality of society yes so if we don't want to make dumb social systems right
so a social system that is more welfare-like is much dumber than a social system that provides
much better health care and education and orientation towards opportunity for advancement
rather than towards opportunity towards addiction cul-de-sacs and so we already have some people
all the listeners of your show i think we already have some people who are trying to educate themselves
independent of not having a government that is doing that that and this is why i say it has to
start at culture before state or market it has to boot in that direction so those people can
start to work together to say how do we influence the state and two start to then influence better
education for more people better media and news for more people and how do we influence it to
affect market dynamics where the market dynamics are more bound to the society well-being as a
whole rather than extractive oh i like this because we actually do see this dynamic we see people
actually seeking out nuance even though we're told that they won't do it and so the other thing
we're seeing is for various reasons including covid the absurdity of the educational system that we
have is being revealed in a way that it never has been before so many more people are recognizing
that school will flat out waste your time if you give it that opportunity and therefore
they have more license than ever to seek out uh high quality insight and uh exercises or whatever
and to discount the value that we are assured comes along with a standard degree uh et cetera
so yeah i'm i'm favorable to this idea go ahead there's also that you said that's interesting
okay so george washington's quote comprehensive education of every citizen science of government
well how can we afford that when most of them are going to be laborers because them having a
strong background in in history and in political science and social science and the infrastructural
text act does that help them be better farmers not really it helps them be better citizens
and government but not better farmers and so ken how do we afford to pay for all that additional
education and how do they maintain that knowledge when they're just engaged in a labor type dynamic
and so this is why the children of the elite who are actually going to become lobbyists and senators
and whatever go to that private school and get that education well now we have this ai and robotic
technological unemployment issue coming up and it's definitely coming up right well the things
that it will be obsolete first are the things that take the least unique human capabilities
because those are the easiest to automate so labor type things so either this is an apocalypse that
just increases wealth inequality and everybody's homeless and fucked or on the absolute minimum
amount of basic income so the elites can keep running the robots as serfs rather than the
people as serfs and just hook the people up to oculus with a basic income so they don't get in the
way or this actually makes possible a much higher education of everyone so they can be engaged in
higher level types of activities um yeah yeah i agree with that completely and i also agree you
know we should make sure people understand i mean i think it was very clear the way you said it but
we are headed for a circumstance in which a shift in the way the market functions and what
it requires is going to cause an awful lot of people to be surplus to it all at the same time
and that can only play out in a few ways none of them are good if we don't see it coming and plan
for it um it's coming it's not the fault of the people who will be obsoleted um and so
in any case yes uh this makes sense you were mentioned you look at COVID and you look at
how many small businesses shut down and how much unemployment happened and then how much the market
rallied because six companies made all of the money of the market and if you take those companies
out the entire stock market is down but it's cap weighted and you basically have network dynamics
Metcalf law dynamics creating winner take all economies where you have one winner per vertical
the wealth consolidation the wealth inequality has progressed so rapidly that all the that the
measurements of GDP and market success and the measurements of quality of life are totally
decoupled they're moving in opposite directions in really important ways when you combine how
intense that is and that of course the forces with the most money are the hardest to regulate
because they have the best lawyers the ability for offshore accounts and for lobbying and whatever
else so how do you do anything about this combined with the fact that the debt to GDP ratio is unfixable
you realize that a reset of our systems will happen because this system cannot continue
and we can either do a proactive one or we get the reactive one and the reactive one of course
the reactive one is going to inherently be arbitrary and therefore much more violent
in every sense of that term and so yes you are programming some kind of a
unfortunately none of the terms that one would like are still available to us because great reset
has obviously been branded in in somebody's interest but yes we need some sort of a reboot
that takes heed of this dynamic and sets us on a path where it doesn't turn into a catastrophe
or it doesn't turn into a spectacular win at everybody else's expense for some party or other
and unfortunately of course if we circle back to an early part of this discussion
convincing people of the hazard of this the essentially the certainty that something of
this sort will happen if we do nothing that we must do something that that something must be
coordinated that you can't pass it through your inherited lens of is this left leaning is this
right leaning is this for my team is this against my team convincing people of that is
extremely difficult in this environment because for one thing everything we would do to convince
passes through these these platforms that if they haven't flexed their muscle yet as soon as we start
talking about what would need to be done to save civilization in ways that they can recognize it
they will find ways to oppose it and you've had this conversation on here before that
let's say we can we look at a particular group and we can predict how they're going to respond
to something we're going to say with quite high accuracy so we can take a particular woke SJW
group and if we have a conversation of a certain type we can predict that they'll say oh that thing
you're calling dialectic is giving platform to racists when you should be canceling them therefore
you're you know racist by association or whatever you can take a QAnon group and predict that they
are going to say that because we talked to someone that was four steps away from Epstein in a network
that we are probably part of a deep state cabal pedophiles or whatever it is and
to the degree that people have responses that can be predicted better than a GPT-3 algorithm
they can't really be considered a general intelligence they are just an emetic propagator
they are taking in memes rejecting the ones that don't fit with the meme complex taking in the ones
that do fit and then propagating them and I think people should I think if people think about that
they should feel badly about not being someone who's actually thinking on their own and being a
highly predictable memetic propagator and be like I would like to have thoughts that are not
more predictable than a GPT-3 algorithm I would like to know what my own thoughts about this are
and in order to know what my own thoughts about it are do I can I even understand and inhabit
how other people think all the things that they think that so that's that's one thing because
it's not only going through the filters like Facebook it's going through the filters of the
fact that people have these memetic complexes that keep them from thinking and so the cultural value
of trying to understand other people so that we can compromise because politics is a way to
sublimate warfare right and if you don't understand each other and compromise you get war and the
people who are saying yes let's bring on the war they're just fucking dumb they just don't understand
what war is actually like they haven't been in it right well I think you have brought us to the
perfect last topic here now of course I'd like this conversation to go on and we should pick
it up at another date but the point you make about if we can demonstrate that we know what
you're going to say then it isn't a thought worthy of a human right if we can predict you and it's
not by virtue of us having modeled some beautiful thought process of yours it's because your thought
process looks like that of you know an indefinitely large number of other people who are totally
predictable and that's nothing you should be comfortable with I think we this goes back to
the question I asked you at first which is when you engage in what I would call independent first
principles thinking you immediately run into challenges that somebody who's not deeply involved
in such a thing doesn't intuit right and so I'm imagining a person somebody who is decent who has
compassion has all of the basic capacities you would hope they would have who has fallen into
one of these automatic thought patterns and I'm imagining you manage to sit down with them and
show them that their thought pattern is automatic and totally predictable and therefore nothing that
they should be comfortable with and let's say that they walk out of the room and they start
behaving differently and they start thinking for themselves they stay awake right well they're
going to run into some stuff because they are of course going to end up landing on some formulations
that as soon as they say them out loud are going to get them punished right that is inevitable
now those of us who live out here learn how to say things in ways that sometimes the punishments
don't stick we learn where they are best stated we learn what we shouldn't say yet but all of this
speaks to what I think is it's not we don't live in an authoritarian
state but we live in a state in which thought is policed as if we did right not perfectly
but enough that one who wishes to escape from the accepted the sanitized narrative
has to be ready for what happens next and that's something that is it's very hard to
generate that in other words it's a developmental process that causes you to learn how to navigate
that space so somebody who just simply recognizes I don't want to be an automaton and I'm going to
start thinking for myself if their next move is to start thinking for themselves and speaking
openly about it what comes back next is something for which we don't have a good response
earlier you said when you were defining near the beginning of our conversation what you
meant by independent thinker as someone who wants to go wherever the facts and information that are
well verifiable actually leave them I would say that there there's something like the spirit of
science which is a reverence and respect for reality where I want to know what is real and
be with what's real more than I want to hold a particular belief no matter how cherished or
whatever in group it I'm a part of in the the uncomfort of not belonging with the in group
if I want to belong with anything I actually want to have a belonging with reality first
and a belonging with my own integrity and then with those who also share that
and the other belongings that I give up I don't stop caring about those people I care about them
still but I don't necessarily care about their opinion of me enough that I'm willing to distort
my own relationship with reality all right so here's the question I want to ask about this
and I'm basically trying to surface some part of my own process in order to figure out what it is
can it be improved can I teach it to others to the extent that it works
there are so I was on Bill Maher with Heather last Friday and I said something that got an
awful lot of pushback online which I knew was coming I said he asked if I thought the probability
that COVID-19 was the result of a lab leak was at least 50% and I said something quite honest and
shouldn't have been new to anybody who'd been paying attention to my channel which was that I
had said back in June that I thought the chances were at least 90% now I can imagine that that
number would be shocking to many people but I also know that were I in their shoes I would process
it this way I would say all right this person seems intelligent I don't know of a conflict of
interest that number is way off of what I would calculate therefore I need to file this as a flag
do I not know something maybe the person has a conflict of interest and that explains it but
if it's not that how have they arrived at a number that is so far off of what I would calculate and
what does it tell me in other words I would become agnostic at that moment rather than go on the attack
people don't give enough benefit of the doubt to people who agree who think differently and they
give too much trust to those who think the same right but then here's the the place that the
thought goes so is it true that if somebody intelligent says something that is completely
inconsistent with my model of the universe that I will inherently give it enough credence to look
at it it's a tough question because if I if I try some test cases if you told me
that you believed that there was a strong chance that the earth was flat okay that would throw a
huge error for me right because I know a that I've checked right in fact I have years ago and
several times said what are the chances there's anything that these flat earthers that they're
not just a joke and then it's a trivial matter to find out what you need to know from your own
experience that is inconsistent with that possibility and so the answer is okay I'm not
going to spend too much time checking with it right then we get to is the moon landing fake
right this one is tougher right it's tougher because when you look at the actual evidence
that people are motivated to hypothesize that the moon landing is fake there are some things
in it that are hard to know I don't offhand know what the explanation for them is so anyway my
point is there's some ideas I wouldn't be shocked at all to find that you believe there's some ideas
I would be so shocked that I would imagine you're kidding or you've lost your mind or I don't know
what and so we all draw that line somewhere and I guess my point is I think almost everybody even
very very smart people who don't happen to be experienced in first principles independent thinking
draw that line somewhere that creates a fatal error when independence is experimented with
right that the number of things that you know it is the matrix in some sense once you start
experimenting with what would I conclude if I was independent of all incentives and I just went
based on the evidence and I gave everybody a chance to articulate their position
what comes back is so jarring that most people are driven back into conventional automatic
thinking because the the frightening aspects of what what they get in response are enough to drive
them off the instinct yes okay god there's so much in here that's really good
the thing about the flat earth is that it is the hypothesis is formally falsifiable
and the alternate even even by an individual yes and it's the high the alternative hypothesis
formally verifiable with the best methods that we have with the highest confidence we can have
and now one thing I would still say is interesting is I know many people who refer to flat
earthers as the moniker of maximum stupidity who cannot do the Copernican proof so they take
as an article of faith that the earth is round but they actually don't know how to drive it have
never tried and so then they also move to taking as an article of faith similar things that don't
have the same basis so if so does someone even understand what falsifiable and verifiable
mean does someone have a basis for calibrating their confidence margin because if if I start to talk about
the moon landing or then I go a little bit further and talk about long-term autoimmune effects
or epigenetic drift or whatever they come from a vaccine schedule of 72 vaccines together
is the standard narrative falsifiable or verifiable is the alternate narrative falsifiable
in the way flat earth is no so the fact that we put flat earth and anti-vax in the same category
is a intellectually dishonest bad thing to do and but the fact that most people
don't even know how to do verify or falsify and so like with the lab hypothesis when you come to
90% I'm guessing you have a process for that what I would say is I haven't studied it enough to put
a percentage because I don't have enough Bayesian priors to actually come up with a mathematical
number what I would say is I consider the idea of it coming from a lab and some kind of dual
function gain gated function research dual purpose gated function to be very plausible
and I have seen nothing that falsifies that and the few attempts that I saw early to falsify it
were theoretically invalid to me now to be able to go from plausible to a probability number I would
need to apply different epistemic tools than I have already applied well wait a second I'm not
sure that that's the case because the to me as a theoretician there is a hypothesis the there are
multiple hypotheses one is the virus escaped from a lab unmodified another is that it was
enhanced with gain of function research and then it escaped another is that it was weaponized and
deliberately released all of these things each of them is a hypothesis each of them makes predictions
and they are all testable now I am not required to have any guess as to which one will turn out
to be correct nor an assessment of how probable it is it is natural to have a guess but the two
things function independently right as a scientist I am obligated to treat a hypothesis by the formal
rules of science I know what they are I know how they work and therefore I know at what point it's
going to be falsified any one of them and what would be necessary for one of them to become a
theory that is to say for all of its challengers to fall now I can also say look if I had to bet
here's where I put my money but I'm not I'm I happen to be a scientist who would be placing a
bet but my bet is not a scientific bet yeah we're we're aligned clarification agreed yeah okay good
so then that that is that is my hunch that I didn't come to that number through a actual
Bayesian or other kind of mathematical process but if I was actually trying to formally give my
my percentage basis I would go through some epistemic process and the more now if I had to
make a consequential choice based on it the more consequential the choice is the more
process I would want to go through to calibrate my confidence of it because the more problematic
would be for me to be wrong right okay so that that all makes sense but the the ultimate question
here is given that we can see we want people not to behave in an automatic way in a
a way that is below the nature of human cognition's capacity to to think and to react
but we also know that when people experiment with that under the current regime it is not that they
will produce conclusions that are different than they would otherwise produce say them to their
friends and their friends will say oh that's interesting I didn't realize you think that
their friends will say oh my god I can't believe you're one of them right and that that thing is
so powerful that it is artificially depressing the degree of independent thought because anybody
who has experimented with it is likely to have effectively you know touched some third rail
and retreated as a response so we don't know there's a failure mode on both sides
there's a failure mode of not of creating artificial constraints where we don't explore
the search space widely enough which is the one you're mentioning there's another one of exploring
the search space without appropriate vetting and jumping from hypothesis to theory too fast
yes and those two are reacting against each other right there are people who
say because it's plausible it is they jump from hypothesis straight to theory without proof
and then they believe wacky ass shit yes and they insist that it's true and then people over here
are like wow that's really dangerous and dreadful and anything that looks like that I'm going to
reject off hand and similarly people over here believe standard models that end up getting either
captured or at least limited and people over here react against that so this is another place that
I would say the polls are driving each other both to nonsensical positions well yes and the way that
works in practice is there is a team that in principle knows that it is in favor of doing
the analysis but it does not believe itself capable of doing the analysis so effectively it
signs up for the authority of those who claim to have done the analysis and in principle have
the right degrees or whatever but then we run into this thing which goes back to something you've
said in several places in this discussion which has to do with the bias amongst those involved
in certain behavior in other words if you're an epidemiologist at the moment or a virologist
there's a very strong chance that you believe the lab leak hypothesis is uh stands a very
low chance of being true but you also very likely have a conflict of interest you may be directly
involved in the research program that would have generated COVID-19 or you may simply be involved
in social circles in which there is a desire not to have virologists responsible for this pandemic
and therefore there's a circling of the wagons that has nothing to do with analysis but either way
the tendency to converge on a consensus is completely unnatural and those who are trying
who earnestly are trying to follow science end up following consensus delivered by people who
claim the mantle of science while not doing the method and that is a terrible hazard.
Yeah yeah I agree and there's one step worse which is the thing that we mentioned earlier which is
you can do the method have them all of the data coming out of the method be right and still have
the answer be misrepresentative of the whole because you either studied the wrong thing or
you studied something too partial and so this question of what is worth trusting comes up again
and is okay I don't want to defect on my own sense making to just join the consensus so that I
am not rejected at the same time if everyone is sure that I'm wrong and I'm sure that I'm right
I should pay attention to that right because very possibly I have a blind spot and I'm a confused
narcissist every once in a while they are all in an echo chamber and I'm actually seeing something
and it's it both can be the case sometimes so you're like okay do I always stick to my guns or
do I always take whatever the peer review says neither this is again the optimization function
isn't it wisdom ends up being a I don't know the answer to this trolley problem before I get there
right so what I have to say is is the basis by which the other people all agreed that you were wrong
deliberative and methodological and earnest and free of motivated reasoning
does it have a group motivated reasoning that's associated with it are there you know clear
blind spots in the thing you're thinking so I don't think there's an answer to the what actually
is right there there is no methodology it's the Tao that's eternal is not the Tao that
speakles not the eternal Tao the methodology that's formalizable is not the thing that reveals
the Tao right like ultimately you have to end up adding placebo at a certain point and then
double blinding and then randomization the methods have to keep getting better because
there's always something in the letter of the law that doesn't get the spirit of the law
and in the letter of the methodology that doesn't get actual science right right and in fact
so a couple things here one there's a part of the scientific method which is a black box
there's a part that actually I believe literally cannot be taught right it is the part where you
formulate a hypothesis right that is a that is a personal process if I taught somebody to do it
my way that I don't think they do it very well right so the point is that's something that you
learn to do through some process that is mostly not conscious hard to hard to teach and hard to
discover but everybody who does it well does it in some different way and so at that level even
just saying do the method is incomplete because not everybody can do the method see there was something
else uh oh yeah there was there was a missing thing on your list I realized you weren't trying
to be exhausted but there was a missing thing on the list of possible reasons that you could come
up against a consensus and still be right even if you're the only person who disagrees and it has to
do with the non-independence of the data points on the other side based on let's say either a
perverse incentive or a school of thought having won out and killed off all of the diversity of
thought over some issue that turns out to matter and these things can vary easily so I would say
yes if you always think you're right and when everybody's against you they're wrong then yeah
narcissism is a strongly likely reason on the other hand it is as you point out with tesla
and uh their competitors sometimes you find that a field or an industry is easy to beat
that there's something about them that is you know maybe economically very robust but with
respect to their capacity has become feeble and this is true again and again in scientific fields
that scientific fields um go through a process where they a school of thought delivers handsomely
on some insight it wins the power to own the entire field that insight runs its course diminishing
return sets in it stops delivering anything new it doesn't give up the reins and hand them over
to somebody else because there's no mechanism to do that so the people who have the school of thought
that's already burned out its value stick to their you know their power and that means that the field
is wide open to be beaten by an outsider who just simply isn't required to subscribe to
whatever the assumptions of the school of thought are and that happens so frequently
that there is this it's artificially common that you have the experience if you think independently
and you know what you're doing that you'll disagree with just about everybody and they'll
actually turn out to be wrong because they're proceeding from a a bad set of assumptions
so i think this is actually one of the most interesting applications of blockchain or
decentralized ledger technology is this idea of an open science platform so imagine every
time someone did a measurement the fundamental measurement it had to be entered into a blockchain
and then the other places that independently did it was entered into a blockchain so it was
uncorruptible and then the the axioms and the kind of logical propositions get entered in and then
the logical processes of whether i'm using an inductive or deductive or what an abductive process
gets put in and then we get to kind of look at the progression of knowledge then at any point
we come to realize that a previous thing and there was wrong some data was misinterred or a
hypothesis has proved wrong now we can come back to that point and look at everything downstream
from it and reanalyze it um of course you still have the oracle problem of the entry in the first
place so if i'm doing motivated science and i get some answers i don't like and i can hide them and
not enter them then that'll happen so you still have to have then the proper entry into the system
but this address is something with the integrity of science and also the integrity of government
and government spending in the capture of market forces of the regulators rather than the
regulators being able to regulate the market is we only know when the fucked up thing happens if
we can see it and which means that everyone who wants to do something asymmetric or predatory
has a maximum incentive for non transparency so certain kinds of uncorruptibility and transparency
are very interesting in what they can do towards that interesting now this actually comes back to
something i wanted to raise earlier um but didn't get to it which is i started out very focused on
sustainability i believe sustainability is something that the system you can't you can't
measure to finally if you measure to finally then sustainability becomes an absurd block to
progress because you can't dig a hole in your own backyard because you couldn't dig a million such
holes um but if you uh relax the system so that you're measuring processes that actually
potentially matter sustainability has to be a feature of the system long term right it doesn't
have to be the feature of the system in any given time period but overall it has to net uh to a
sustainable mode i wouldn't say a system has to be sustainable i would say the meta system or
increase in orderly complexity has to be sustainable but that might mean a system intentionally
obsolete itself for a new better system okay i accept that but what i've realized uh down this
road is that the system actually or the set of systems or the meta system however you want to
describe it needs a failsafe which i call reversibility right so the point is if you set the
goal of sustainability and you say well we have to measure things that matter sooner or later you're
going to fail to measure something that matters and you're going to deal with it unsustainably
and at the point that you figure it out it's going to be too late so my point would be
and you know this is a tough one people don't like the implications of this if they understand it
but any process that you set in motion has to be something you could undo if it turns out to be
harmful in a way that you didn't see coming right so that is to say you can alter the atmosphere
carbon dioxide is not poisonous right the changes in concentration that change the degree of heat
trapping are not terribly meaningful to the well-being of living creatures
but at the point you discover that the heat trapping is going to massively change the way
the atmosphere functions and the oceans etc etc you have to be able to undo it now undo it
means you could change the concentration back to what it was now what this would mean in practice
was that you would have to slow the process of change down such that you scaled up the process
that would reverse the change in proportion now if you imagine all of the disasters that we have
faced all the ones I named up top and all of the other ones that look like it from you know Fukushima
to Elizo Canyon to financial collapse of 2008 and you imagine that in proportion to the process
that went awry we had scaled up the reversal process so that it was there if we needed it
right we would have been in a very different situation because a the process would have run
away much much slower and b the tools to undo it would have been present and ready
oh before you respond to that I do want to say that the only way that that would work
is if it was over the entire system in other words if one nation for example were to decide
that it had to adhere to a standard of reversibility while other nations weren't restricted in the
same way you didn't you'd get a tragedy of the commons where the atmosphere or whatever other
resource would ultimately be destroyed by the nations that didn't participate in that system
and the nation that was most responsible would pay the cost of building a reversibility system
that wouldn't work in the end but other than that I think the principle makes sense what do you think
there's something like sustainability having a consideration like reversibility as one of the
factors to inform choice making and that that is a is a valuable consideration and that it
doesn't matter at all if we don't have collective coordination capacity to be able to make the
right choices period so yes agreed now regarding reversibility I think reversibility is a valuable
consideration that is impossible and important ways but it's still an important consideration so
can I decrease the amount of CO2 in the atmosphere if we realize we need to kind of yes but the
CO2 in the atmosphere went up along with a lot of mountaintop removal mining for coal
and a lot of species extinction in the process a lot of people who died over wars for oil can I
reverse and get those dead people back and those extinct species back and those pristine ecosystems
back no they're gone and then also reversibility over what time frame will new old growth forests
come back thousands of years from now sure does that time scale matter if I ever extinct a species
is that reversible does every species matter what about killing an individual element within it you
know so it's like I can only think about reversibility on very narrowly defined metrics but the thing
that harms that one metric has lots of other effects simultaneously and so we have to understand
the reversibility by its by itself is an oversimplification because we'll always be thinking
upon metrics that are subsets of all that's affected yep I agree it is a it is a oversimplification
as is sustainability but my sense is that you have to instantiate it in some way in order for the
system to be safe and I would say if it prevents you from removing mountaintops as long as it
prevents everybody else from removing mountaintops it's the right idea in other words if we are allowed
to degrade the earth a little bit at a time by removing mountaintops now and you know drying
up rivers next time then eventually you have a world that isn't very worth living in and I do
believe that we have a moral obligation not to degrade the planet right that that our highest
moral obligation has to be to deliver the capacity to live a complete fulfilling human life to as many
people as we can and that means not um liquidating the planet it means a renewal process which is
the very definition of sustainability and it's inconsistent with um removing mountaintops now
lots of species don't matter right there are lots of little offshoots of species
and they can go extinct and they do go extinct and nobody is harmed by their doing so which
it's not the same thing as losing orcas or you know elephants or eagles or whatever so
obviously you need to have a a rational threshold in which you protect against
against degradation and allowed degradation that doesn't have an important implication
but the question is really is it so compromised by those considerations that it's not worth
considering or is it rescuable if one figures out how to apply a threshold
so we said that one of the dialectics that defines the left and right and its most abstract form
generally has to do with a focus on the individual versus a focus on society or the collective or
the tribe or some kind of group another one is an orientation towards conservation or
conservativeness traditionalness with an orientation on the other side towards
progress or progressiveness and again these are confused all over the place and even what we
call left and right have shifted in the last you know a few decades in a number of ways but
it's interesting here because when you talk about reversibility and sustainability another
synonym is conservation what is it that we want to be able to conserve and so the conservative
principle is focused on what has made it through evolution that is valuable enough that we should
conserve it and not fuck it up and yet so interestingly the people who are often called
conservatives are not focused on critical aspects of conservation but if you you're talking about
biosphere conservation right now oftentimes they're talking about sociosphere conservation the
conservation of social systems and you're saying that underneath it is the capacity for humans to
thrive and have meaningful lives and relationships and we would say that that is a function of the
biosphere the sociosphere and the technosphere and the relationship between them and so and we
can say very clearly it's the technosphere ruining the biosphere most of the time and yet if it ruins
the biosphere enough the technosphere goes because the technosphere depends upon the biosphere so we
have to learn how do we make a technological built environment that is replenishing regenerative with
the biosphere and the sociosphere is another really critical one and I think you'll probably
actually have something to add to this that I haven't thought of when I think of what the
fundamental intuition of a conservative is even if they don't articulate it like this
and the traditionalist kind of impulse which is let's go back to the constitution let's go back to
Christianity or European ideas or the free market or whatever it is or rigorous monogamy whatever
social structure lasted for a long time that there there's an intuition even if they don't
formally think of it this way logically that almost everything didn't make it through evolution in
terms of social systems and the few things that did weren't the things that people thought would so
there's a lot of embedded wisdom that wasn't understood it was very hard earned and we want to
preserve that and not break it because we think we understand it well enough and we might not
and that fundamentally the progressive intuition is that we're dealing with fundamentally novel
situations that evolution didn't already figure out and we need innovation and of course the
synthesis of that dialectic is we need new innovation that is commensurate with that which
should be conserved and not everything should be conserved because some things made it through
because they won short-term battles while fucking up the long-term hole and so what things are worth
being conserved what things are not worth being conserved did we understand it well enough that
we didn't say this isn't worth being conserved out of hubris and then what progress is commensurate
with that i think is a good way of thinking about that dialectic yeah i like it and i think there's
the flip side of it as well which is that captured inside the biblical traditions are some bits of
so basically responses to game theoretic hazards that are consistent with things we've talked about
so for example the christian sense that not only is the world here for humans to make use of but
that we are in effect obligated to do it that belief fits perfectly in a world where if your
population doesn't capture a resource somebody else is going to so in other words that belief
structure travels along with a tendency to capture the resources that are available and to the extent
that what that does is it causes the exploitation of a resource the tools with which those resources
could have been exploited in biblical times almost always left a system that would return
itself to equilibrium given an opportunity which isn't true in the modern circumstance so what we
have is a place where there's lots of stuff that is conservative that there's a very good and often
hidden reason that we should preserve and then there are some places where we'd actually have
to upgrade the wisdom because it doesn't fit modern circumstances and the conservation of
the natural world is i think a clear case
just because you mentioned this case when when people realize that christian
spread largely by holy war not exclusively but largely
you need a religion that makes a lot of people that are willing to die in holy war because of a
good afterlife and who you can spare right a lot large population of people that can die in war
and islam and christianity both had this they both had be fruitful and multiply and proselytize
because they both had war as a strategy for propagation of the memes so you needed numbers
whereas judaism didn't have it right and quakerism and some other ones didn't judaism had to actually
make it hard for people to join the religion because you're not going to lose a lot of people
as soldiers you're going to embed yourself as a diaspora within dominant cultures and end up
affecting the apparatus of those cultures so it's interesting to think about how those different
meme plexus had different evolutionary adaptations but it's important for the reason you mentioned
is that those traditions were influenced by politics and economics and war and philosophy
and culture and a lot of things so you can't wholesale throw them out or keep them or like
you have to actually understand what allowed those memes to propagate and what their memetic
propagation dynamics were and so that conservative impulse it says the things that made it through
made it through for a reason yes but some of the things that made it through for a reason won't
keep making it through dinosaurs were around for a long time and then they weren't right so and as
we've mentioned evolution can be blind and run very effectively into cul-de-sacs and yet the other
side is all too often we will criticize a tradition for being dumb when we don't understand what made
it work well enough and we throw something out that was actually worth not throwing out
so how do you do it deep enough historical understanding to be able to decide what should
be conserved and not is is also a really good question it's a really important question because
it's it's chesterton's fence factory effectively right nobody knows what what actually was functional
and what you know had no function but traveled along with it because they were paired very closely
in a biblical text and you know what functioned in ways that we don't want it to function now
these things are all invisible because the whole thing is encoded in myth so it's not in there
right so yeah that's a huge hazard and it's a tough one for those of us who want to build
reasonably and recognize that there's an awful lot that we have to do that's novel because it
hasn't been accomplished before we have to grapple with the fact that it's not like these traditions
are simply backward some of them are very insightful and non-literal and
we need to exercise great caution in approaching them okay so I want to come back to your three
generations least problem it's easy to look at the nature of the problems and just assume that we
are fucked and usually to tie that to the some conversation about human nature
and to say okay well we were able to figure out technology that was extraordinarily powerful to
speak mythopoetically the power of gods the the nuke was clearly the power of gods right and then
lots of texts since then we can genetically engineer new species gain a function whatever
it without the love and wisdom of gods that goes in a self-terminate direction
is it within the capacity of our nature to move towards the love and wisdom of gods to bind that
power or are we inexorably inadequate vessels for the amount of power we have so then I do a positive
deviant analysis to look at what are the best stories of human nature to see if they converge in
the right direction and then also where there are conditioning factors that we take for granted
because they become ubiquitous and think that their nature so if we if we go back to the bible
for a moment we look at jews and we look at was there a population of people that were able to
educate all of their people at a higher level than most other people around them for a pretty long
time in lots of different circumstances yes you look at the buddhists where there are population
of people that across millennia and different environments were able to make everybody peaceful
enough to not hurt bugs yes across all the genetic variants and across all of the economic
factors and the whatever else do we have examples a very high level of cognitive development and
very high level of ethical development of different populations based on cultures we do
and then we say oh well but you know look at how well the founding fathers ideas failed here
well the the comprehensive education of everyone is not in the interests of the elite that have
the most power as we mentioned and so making it seem like that that's an impossible thing is actually
really good to support the idea that there should be some kind of nobility or aristocracy or something
like that there should be elite to control because they're more qualified i would say that we have
not in modern times ever tried to educate our population in a way that could lead to self
governance because there is no incentive to do so or those who had the most capacity had
incentive to do something else even when they said they were doing that so do i think that it's
possible do i think that we have examples historically of people who developed themselves
cognitively and ethically enough that if we did those together right buddhist jews um have we
want to talk about it do i think that's possible within human nature and basically untried
yes yeah i love that and i agree with you it's dependent on something which we might as well
spell out here which is that the capacities the difference in capacity between human populations
is overwhelmingly if not entirely at the software level which i firmly believe i'm speaking as a
biologist i've looked at this i will have to defend it at length elsewhere but the degree to which
its software that distinguishes us and therefore we can innovate tools we can democratize tools all
of that is at our disposal and i agree with you it hasn't been tried and uh it might be our only
hope but at least we've got prototypes now i was saying why i'm grateful for what happened to never
agree is that you wouldn't be here doing this otherwise and on bill mar and your you and hether
are both exceptional educators and so the fact that your tiny little niche for education got blown
up so that you took this quality of education to all the people who were interested uh this larger
scale i'm really happy about because i my friend this exact thing is the thing that has a chance is
a strange attractor of those who are called to a cultural enlightenment starting to be come to a
come together in a way that can then lead them to coordinate to build systems that can then propagate
those possibilities for other people well i really appreciate that and i uh i must say i feel it as a
calling as i'm certain you do and so uh yes and i also love the point that you made earlier about
the fact that the audience for this really is people uh seeking a kind of uh enlightenment
and community and so yes um as much as you and i both focus on uh existential risks there is hope
in that yeah okay daniel well this is uh i think we've gone more than three hours it's certainly
been a great conversation and there are so many threads that are worth revisiting which we should
do sooner rather than later this was super fun i really enjoyed it yeah it was um so daniel schmocktenburger
where can people find you well you mentioned in the beginning we have something called the
consolence project that'll be launching soon via a newsletter in march and then a website in a few
months um so tune back in on that and it's a it is a project in the space a non-profit project
that is seeking to do a better job of news with education built in so we actually make the epistemics
we look at very complex issues that are polarized and we make the epistemics that we're applying
explicit so we're actually teaching people how do you sense make complex situations in situ
and then if anyone ever thinks we missed any of the data about something wrong they can let us know
and we'll publicly correct it and credit them if that's right and etc so um and the goal there is
helping to catalyze cultural enlightenment of this type and recognizing that both education
and fourth estate are requisite structures for open society and open society being rebooted
has to be rebooted at the cultural level first um right now uh you can find me on facebook
or one of those platforms or uh have a blog an old blog everything's out of date on it
civilizationemerging.com civilizationemerging.com and uh are you not on twitter and does that
explain how you're so clear-headed? I'm not on twitter um and I'm on facebook because it uh
because of matcalflaw because everyone is so it ends up being a useful introduction and messaging
tool but yeah I am I'm not part of the twitter crew. More power too yeah all right Daniel this has
been a pleasure and uh I look forward to our next one uh be well and uh everybody else thanks for
tuning in thanks
