than things had been previously. Now, this is beautiful. Okay, because this is exactly what
I was hoping for. Okay, this is a question of us tripping over each other's language.
Jim misunderstood what you were saying, right? And he asked me about it. And I said,
yeah, Daniel can't be right about that if he's saying what you think he's saying. But of course,
it wouldn't make sense that you would think that you could. So your point about this being trivial,
you're in complete agreement with me. And I suspect it would take nothing to get
Jim to agree to that formulation as well. There's a difference. There's one more thing I have to say
here. Okay. Of course, I'm not pretending that thermodynamics don't exist. Right. And once you
get down to the quantum scale arrangement of a thing that orientation in one direction doesn't
have effects on other things. There's a difference also between the blue and fast
are two different preferences that are arbitrary that both want to be associated with a car that
don't have some intrinsic unifying function. And we can say blue is a thing that's reasonable
to be preferential about color. Whereas I would say that there are some characteristics that have
a synergistic effect that increasing one increases the other one because of the way they are part of a
overall increase in system integrity. And so synergy is the key concept I'm trying to bring
about here, which is behavior of whole systems, more than the sum of an unpredicted by the parts
taken separately. So when I say I'm looking for synergistic satisfiers, the idea that I have
X amount of input, and that input has to be divided between these various types of output and
it's linear is nonsense. I can have X amount of input and have something where the total
amount of output has increased synergy based on the intelligence of the design. The question of
how do we design in a way that is optimizing synergy between all the things that matter becomes the
central question? Yes, which is of course the central question that selection must be dealing with
in generating complex life. And again, I don't think we have a hair's breadth of difference on
what we turn out to believe about this tradeoff space. But what I would say is, and I don't want
to drag the audience too far down this road, it's probably not worth it for what we need to do here.
But the benefit of being able to say, so let's take your example of there are certain characteristics
that will co maximize not really because of the following thing. Let's say that we figure out
what color is best for making the fastest car. And then we say, well, I want to maximize
gray 37 and speed. Now I can do it. I can maximize gray 37 and speed because it just so happens that
gray 37 is the color that has the best characteristics for speed, right? But then the point is you
can't separate these two things, whatever characteristic it is, you're actually maximizing,
you've just found two aspects of it. So your point about synergy is that perfectly aligned
characteristics, we could describe that joint that fusion of those two things as one thing,
and we could maximize it, right? But then if we take the next one over, right, the next characteristic
that we want to add to the list of things, then again, we're back in trade off space. So my only
point here is that there is a value in order to be able to get the maximum power out of a trade
off theory. What we want to do is make it minimally complex and the ability to say every two desirable
characteristics have a trade off between them. The real question is the slope or the shape of the
curve, right? And that many of these slopes and shapes mean we will see no meaningful variation
on it because one side is a bargain, and we will always see that manifest, right? That's the reason
we don't see trade offs everywhere is that in some cases, a trade off is so dumb that we don't see
anybody exercising variation, everything has made the same decision. Yes, and I think for all practical
purposes, we agree that being able to make a Tesla that is safer than a Volvo and faster than a Ferrari
and greener than a Prius is a possibility, and that we can, if we apply that to all of the problems
in the world, we could do a fuck ton better job. Yeah, I think we also agree, and I love the last
point that you made to the degree that two things can be simultaneously optimized, they can be thought
of as facets of a deeper integrated thing. Yep. Okay, so now to answer the way that I actually
think about it, though this is irrelevant, if people disagree, it doesn't matter at all to the
earlier point, I have to wax mystical a moment. When Einstein said it's a optical delusion of
consciousness to believe there are separate things, there's in reality one thing we call universe,
and everything's a facet of it.
If I look at the real things that we have theory of tradeoffs between in the space,
in the social sphere, and the associated biosphere that we're a part of.
So let's say we talk about in the very beginning of our conversation individual, what would optimize
my individual well-being, and what would optimize the individual, and what would optimize the well
being of all humans. I believe that I only find that those are differently optimized
if I again take a very short term focus. If I take a long term focus, I find that they are one thing,
because the idea that I'm an individual, and the idea that humanity is a separate thing is actually
a wrong idea. They're facets of an integrated reality, and that if I factor all of the things
that are in the unknown unknown set over a long enough period of time, they're simultaneously
optimized. And this is the essence of dialectical thinking, is looking for the thesis and the
antithesis, and not voting between thesis and antithesis, but seeking synthesis that's at
a higher order of integration and complexity. Totally agree. And so I don't know how many
people will be tracking it, but effectively saying on an indefinitely long time scale, these things
converge is an acknowledgement that we are not talking about design space when we make this
recognition. It's more like trajectory, and that is perfectly consistent. And frankly,
I think if everybody understood at some level the kind of picture we're painting,
people would be really comfortable with the degree to which it doesn't do exactly the thing they
most hope it will. In other words, the level of compromise is small. Which is why the compromise
in a healthy democracy even was tolerable, even though that was nowhere near as optimal a system
as we could develop. Okay, there's a point a number of minutes back that I want to return to,
and I want to drop an idea on you. It's actually a place where something you said caused me to
complete a thought that I've been working on for some time. So the thought as it existed is
that markets are excellent at figuring out how to do things, and they are atrocious at telling us
what to do. In other words, they will find every defect in human character and figure out how to
exploit it if you allow them to do that. But when you have a problem that you really want solved,
how can we make a phone that doesn't require me to be plugged into the wall, allows me to get a
message across a distance to report an emergency, whatever. Markets do a better job than we could
otherwise do of figuring out what the best solution is. And so in some sense, the question is,
how can we structure the incentives around the market so that markets only solve problems
that we want them to solve, but they can be free to solve them well? And what I think I realized
in this conversation here is that in some sense, the role of the citizenry in a democracy
is to discuss the values that we want government to deploy incentives around. In other words,
the people by deciding what their priorities are, what their concerns are, which problems are top of
the list to be solved, and which ones could take a backseat, that that's the proper thing that we
are to be discussing. That the role of government freed from corruption would be to figure out what
incentives will result in the best return on our investment, structuring the incentives of the
market, and then the market can be freed to solve the narrowest problems on that list. And I think
we fail at every level here, but from the point of view of what we're actually shooting for, I would
say it's somewhere in that neighborhood, that division of labor between the citizens, the apparatus
of governance, and the market. I'm suffering a little bit here because there's like 10
simultaneous threads that I really think could address that are important, and I know we're
going to open up more in starting. It would be really fun to go through the transcript of this
and come back to the most important threads. Might be worth doing actually. So,
first, I want to say something against heterodox market theory is I don't think the market is
the best system for innovation of a known what. And I think World War II and the Manhattan Project
is a very clear example in the Apollo project. And our failure at fusion, I would say, that the
point you're about to make to me, fusion would be our top priority because it's the only plug and
play solution to a large piece of our problem. And the fact that we decade after decade are
awaiting a proper fusion solution says, despite the fact that the market could potentially solve
it, the problem is the investments are too large on the front end and the reward is too
delayed for the market to actually even recognize the problem correctly.
Venture capital is not going to put up the amount of money that a nation state can
for the amount of time that's necessary. And when you look at the very largest jumps in
innovative capacity, a lot of them happen by nation-state funding, not market funding, and then
a market emerging in association with government contracting. And so, if we look at why the Nazis
were so technologically farther ahead than everyone else going into World War II with the enigma
machine in the beginning of computing with the V-2 rocket, it was not a market dynamic, it was a
state dynamic where they invested in science and technology development for a long time,
which is why this tiny little country with limited industrial supply capacity had more
technological advancement than the Soviets or the US. And it was our ability to steal their
shit and rip it off and then be bigger than them. That was a big part of how we were able to
succeed in the war effort. And so, that's a clear example that like computers were developed by a
state, not the market. Well, hold on a second. I want to be careful because I don't want to
falsify something that isn't false. I again think this is a place where our mappings or at least
the language surrounding them is going to upend us because this sounds like a place where a government
is capable of generating a massive incentive to cause a problem to be solved that the market won't
even find on its own, right? So, that does not strike me as inconsistent with what I was just
saying. The state recognizes there's a problem, creates an incentive big enough to find the solution
and that incentive can be big enough to cause people to get different degrees than they would
otherwise seek. But in these cases, it wasn't like, so let's take the Manhattan Project,
it wasn't private contractors that solved it because the government had made the incentive,
it was actually government that solved it. It was government employees. And so,
this is an important distinction. NASA was not a private space contracting thing that did the
Apollo project, it was a government project. So, I would say the largest jumps we ever made in tech
did not happen in the market for the most part. Well, so then I guess the test of your
falsification here is the following question. If the Manhattan Project had consisted of a state
yanking people out of their beds and standing over them with rifles, would it have worked? I mean,
it may be, you know, the Russian version is closer to that. But I think the point is,
you still have a system of incentives correctly solving a problem that the market would not
have found on its own and no entity in the market would have been big enough to solve.
So, I still see it as consistent. But you might convince me otherwise, especially if it turns
out that a negative incentive would be just as effective at creating the solution.
There's a story that people don't innovate well under duress. The innovation requires executive
function and prefrontal function. And if they're too limbically oriented, they want to innovate
well, which is one of the reasons why we need an open society. And I think there's probably
some truth to this, but less truth than we would hope. I believe it was called the Shoroska system,
which was a Russian, basically, prisoner of war type camps that had scientists that were
doing real innovation up to, you know, early Sputnik like work. So, we know that people
under rifle duress can innovate. We know that people conscripted by draft into an army can
actually innovate on behalf of the military. Now, I think that it's true that something more like
a market will explore more edge cases that are not known what's and come up with interesting
things, whereas the centralized thing can do a better job sometimes of existing what's that
require very high coordination. Because if you look at the Manhattan project, the scale of the
budget and the scale of coordination, no company has that and a bunch of companies competing for
intellectual property and whatever it wouldn't have worked, right? One of the reasons I bring
this up is because there's a whole bunch, you mentioned fusion, whether it's fusion or whether
it's thorium or whether it's closer to room temperature super conduction or any of the
things that could possibly generate, whether it's 65% efficient photovoltaic through nanotech.
There's a bunch of things where we're like, we kind of know the science that could lead to the
breakthrough, but the level of investment just isn't there. And I think there's a heap of examples
like this where the percentage of the budget of the national budget that used to go to R&D
has went down a lot and it shouldn't. And the Apollo project was kind of the last thing of its type.
And then the government starting to shift to government contractors started to be a source
of massive bloat where the government contractors had an incentive to just charge whatever the
fuck they wanted, which is why then Elon could beat Lockheed and Boeing at rockets so much cost-wise
because then in that situation, he didn't have to do the fundamental innovation on rocketry,
he could just out-compete them with market incentive. And then that could create enough
money for iterative innovation. I think fundamental innovation of certain scales does
require larger coordination than markets make easy. Okay, so then I want to modify what I said
because you've convinced me I didn't have it right in the initial one. So the point then is you have
to extend the governmental structure so that it can deal with two types of market failure,
one surrounding the natural system of incentives, which will cause you to innovate things that do
net harm, for example. And the other is a failure where the scale of the market is not sufficient
to solve certain problems that are in our collective interest to solve. Yes, and we don't want to give
the government that much power because we don't trust that kind of authority. But that's because
the people aren't checking the government, which comes back to the thing that we talked about earlier.
And now this becomes one of the central questions of the time is what is the basis of legitimate
authority and how do we know? And what is the basis of warranted trust? Because we all know what it
means to have trust that isn't warranted. Everyone who disagrees with us, we think that their trust
isn't warranted, right? Like if we're on the left, we think people who believe in who trust Trump,
it's unwarranted. And they think that the people who trust the FDA or vaccine scientists or the
CDC have trust it's unwarranted. We also know that legitimate authority, the idea of legitimate
authority is so powerful to be able to be the arbiters of what is true and what is real, that
anyone who is playing the game of power has a maximum incentive, however successful they are,
to be able to capture and influence that for their good. We also know that it's possible to mislead
with exclusively true facts that are cherry picked or framed. So I can cherry pick facts on one side
or the other side of a Gaussian distribution and tell any story I want that will make it through a
fact checker. So fact checking is valuable but not even close to sufficient. So I can lie through
something like the Atlantic as well as I can lie through something like Breitbart through
different mechanisms for different populations. Yeah, this is a super excellent point as well
that a fact checker airs in one direction and if you can build a falsehood out of true
objects that have been edited then the fact checker won't spot it. So love that point.
And so I can do a safety analysis on a drug and I'm not looking at every metric that matters.
I'm looking at some subset of the metrics and it might be that it's safe on those metrics but
all causality increases, life expectancy decreases but I only did the safety study for two years
so I wouldn't notice that. So I can say no methodologically this was perfect and sound. It
just also doesn't matter because I wasn't measuring the right things. Right and so this also
basically what you have just said means that the replication crisis can be understood as a mechanism
for generating data which can be cherry picked to reach any conclusion you want about the effects of
this intervention or that intervention right because effectively what you have is the ability
to choose between experiments where sampling error will result in both outcomes being
evident somewhere. This is another one of those is it conflict theory or information
or mistake theory thing is I can intentionally manipulate an outcome that looks methodologically
sound and then say oh we just didn't know those factors right. I'm not saying that whether that's
happening or not it certainly can happen. Okay so now we get back to so what is the how do you have
a legitimate authority that has the power of being the arbiter of what is true and real and all the
power that's associated and have it not get captured by power interests is a very very important
question. How in the name of the Bible and Christendom and Jesus saying let he who has no sins cast
the first stone did we do the Inquisition right like weird mental gymnastics by which the authority
