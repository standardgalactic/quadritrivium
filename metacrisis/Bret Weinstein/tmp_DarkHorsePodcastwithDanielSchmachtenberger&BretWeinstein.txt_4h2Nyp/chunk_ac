You don't get to keep doing that ongoingly. You don't get to regulate after the fact,
the way that we always have once a problem hits the world, things that are catastrophic.
Could we have known, well, yeah, in London before that, one, they were already electric
motors and two, people were already getting sick of burning coal from lung disease, from the burning
of the hydrocarbons. If we had tried to do good risk analysis, could we have? Yeah.
But there's so much more incentive on who pursues the opportunity first. And then there's this
multipolar trap of, well, let's say we don't, the other guy is going to, so it's going to get there
anyway. So we might as well be the ones to do it first. And that thing ends up getting us all
the time, which is why collective action again comes in.
Well, it's really interesting how much of this is again, parallel. Heather and I use the example
of somebody, you know, driving the first internal combustion engine and somebody chasing them down
the street saying, don't do that, you'll screw up the atmosphere, right? How crazy is that person
running down the street saying that because, you know, you would have to scale it up to such a degree
before that's even a concern that that person seems like a nervous Nellie. But of course,
they would also have been prophetic. But the other thing I want to ask you about is,
you say that we have these two categories where
sometimes we could have known and we went, we knew in fact, and we went ahead anyway.
And then in other cases, we didn't know and something snuck up on us. And I want to be,
I want to clarify what you just said, because my understanding here is that if you dig deep enough,
somebody always knew, right? In general, there's some mechanism whereby the person
who correctly predicted what was going to happen has been silenced, often they lose their jobs,
they disappear from polite society. At the point they turn out to be right, their
reputations are never resurrected as far as I can tell. So am I wrong that even in the cases where
people who made the decisions may plausibly have not known that the reason they didn't know is
because there's some sort of active process that when there's a profit to be made,
shuts down anything that could be the basis of a logical argument that we shouldn't do it?
I don't know that I'll say always. I'll certainly say most of the time.
And let's say there was a case where we really nobody knew.
My guess is we probably could have had we tried harder. And then let's say there's going to be
some unpredictable stuff, like we know in complex situations, there's going to be unpredictable
stuff. So you do the best job you can to forecast the risks and harms ahead of time.
But then you also have to be ongoingly monitoring. Well, what would the early
indicators that there's a problem be? And when we find that there's something we hadn't anticipated,
how do we factor that into a change of design? Well, once the profit stream is going and the
change of design fucks up the profit stream, how does the recognition of that there's a problem
actually get implemented when those who have the choice implementation power are not the people
who are paying attention to those indices? So yes, I would say, and it's easy to just say,
hey, yeah, there was some there was some wackadoodle who was saying that there was going
to be some risk, but there's always some wackadoodles saying there's going to be risk about every new
tech. And if we really listened to all them, we'd have no progress. That's the story, right?
It's a bullshit story. Could we now let's there's but there's a collective coordination issue,
because it is fair to say, so like, let's take AI weapons right now, specifically,
automated drone weapons. There is an arms race happening on automated drone weapons.
And I think every general and military strategist knows that all of our chance
of dying from AI weapons goes up. They're kids, everybody's, as we progress in that technology,
it's a bad technology, it shouldn't exist. We should create an international moratorium that
says nobody builds AI drone weapons that we don't want automated weapons with high intelligence
out there. But we can't make that moratorium, because if one country doesn't agree, if one
non country, some non state actor doesn't agree that has the technology, or let's say everybody
agrees, how do we know they're not lying and developing it as an underground black project?
So either we don't even make the agreement, or we make the agreement knowing we're going to lie
defect in a black project, spy on their black project and try to lie to their spies,
who are spying on us. And so it's like, how do you get around that thing, where if anyone does
the bad thing in the near term, it can first so much game theoretic advantage that anyone who
doesn't do it loses in the long term. Why it was that the peaceful cultures all got slaughtered by
the warring cultures. And so what ends up making it through is those who end up being effective
enough at war. That's an underlying thing we have to shift. Because that has as its eventual
attractor space self destruction in a finite space. Yeah, I totally agree. And the I think
fascinating thing when you interact with the incarnate aspect of the process you just described,
is that the people who are telling the lies that explain why we're doing something that we know
is reckless, often don't know that that's what they're doing, right, they actually believe their own
press. And instead of saying, well, yes, this is terrible, but we don't really have a choice,
or somehow indicating that they know that what you encounter is a true believer who thinks that
this is safe. And that's very frightening, because it means that the mechanism at the point something
begins to go awry, to do anything about it doesn't exist, right, or at least it's not connected to
the part that you can talk to. And so, again, not not too surprised to find overlap in our map,
I would say the process that you describe of by the time you discover what the hazard is,
that there's a profit that has accelerated the process. I call this the senescence of civilization,
because it's actually exactly a mirror for the process that causes a body to senesce,
the evolution of senescence involves processes that have two aspects, one which benefits you when
you're young, and another which harms you when you're old, and because many individuals don't
live long enough to experience the harms in old age, they get away with it from evolution's point
of view, and evolution favors the trait in spite of the late life harms. So those late life harms
accumulate, and that's the reason that we grow feeble with age and die. And that's an exact mirror
for the way we've set up our economic and political system, where any process that is
profitable in the short term at the consequence of having some dire implication for civilization
later on, those processes are so ingrained by the time we discover what the harm looks like
in its full form, there's nothing we can do to stop them. Okay, so let's use two really important
current examples. So let's take Facebook and social media, and the way they've affected the
information commons and the epistemic commons are at large. So we know that the nature of the
algorithms optimizing for time on site while being able to factor what I pay attention to,
the whole Tristan Harris story, makes very few people wake up and say I'd like to spend six
hours on Facebook. And so I'm going to spend more time on Facebook if I kind of leave executive
function rational brain and get into some kind of limbically hijacked state where I forget that I
don't want to spend my whole day on Facebook. And so time on site maximization appeals to existing
bias and appeals to limbic hijacks. So if I piss off and scare the whole and illicit sexual desire
and whatever of the whole population while doubling down on their bias, and creating stronger
in group identities associated without group identities, the algorithms optimize. Well, it is
an AI of the power that beats Caspar Abit chess, beating us at the nature of the control of our
attention. So we can see that the right got more right, the left got more left, the conspiracy
theories got wackier, the anti conspiracy theory people became more upset at the idea that a
conspiracy could ever exist. Basically, everybody's bias doubles down and they all move apart from
each other faster. Well, society doesn't get to keep working that that is a democracy killer,
right? That's an open society killer. There's a reason China controlled its internet is if you
don't want your society to die, you have to be able to have some shared basis of thought.
So we can say, and the story is, oh, we didn't know that was going to happen. Well, you go back
and look and guys like Jaren Lanier were at the very beginning of Facebook and Google whatever
saying, Hey, guys, this ad model is going to fuck everything up. Like you can't do the ad model
thing, you got to have pay for subscription or, you know, some other kind of thing. And it was
like, shut up, dude. And or just don't even engage in the conversation and then get a say afterwards
failure of imagination. But now, how do you regulate it when those corporations are more
powerful than countries? Because some the regulation is going to be happening in a court where the
lobbyists have to be paid for by somebody, right? So who are the lobbyists paid for by and it has
to be supported by popular attention and those who can control everybody's attention can also
affect what is in popular attention. So this is a very real example where we know the harms were
known. And and it actually got large enough that it killed the regulatory apparatus's capacity.
Absolutely. In fact, again, this is going to be another alignment of our maps. So
what I've been playing with is the idea that we are incorrect in imagining that people necessarily
want their their expectations flattered, that people actually may like to be challenged,
but that it's inconsistent with the well being of advertisers that the very fact is
because advertising is only a tiny fraction informative and is mostly manipulative.
You have to be in your unconscious autopilot phase in order for it to cause you to buy a car you
wouldn't have otherwise bought or buy different deodorant than you would otherwise buy. And so
the point is in order for us to be the thing gets paid for by advertising, in order to be useful to
advertisers, we have to be unconscious. And the only way to keep us unconscious is not to
challenge us basically to tell us what we think we already know rather than what we need to know.
And so they're lulling us into this, even though we would still be interested in the platforms,
if we weren't being advertised to, but we would be interested in having more important
conversations there, which is really, in some sense, what the the growth of heterodox podcast
space is about. Oh my goodness, okay, there's two directions I want to go at the same time,
I'll just pick one. There's a reward circuit on exercise and there's a reward circuit on junk
food, right? And they both have a dopamine, allergic element and reward circuit, but they're
of a very different kind. And the reward circuit on exercise is that it actually feels like shit
at first and is hard and but your baseline of happiness measured in whatever dopamine,
opioid access, whatever gets better over time. And then you start actually feeling over time,
but not quickly. This is another place where temporal myopia ends up mattering because there's
a delayed causation on the healthy one and no delayed causation on the unhealthy one. So I start
getting the reward circuit on exercise when I start seeing results. And then I want to push
hard and then I'm willing to actually go against entropy and put energy into the systems the energy
grows. Whereas the chocolate cake, I get a reward instantly and I don't have to apply any energy.
But as I do it, my baseline gets worse. And this is the like addiction versus health reward
circuit direction. And the same is true for scrolling Facebook compared to reading an
educational book at the end of a month of reading the educational books, my life feels better,
I feel more proud of myself at the end of a month of scrolling Facebook, I'm like, what the fuck
am I doing with my life? And and yet that one will keep winning for the same reason that 70%
of our population is overweight and over a third of them obese. And so but not but my only hope is
that not everyone who has access to too many calories is obese, right? Like, there are some
people who figured out, hey, that's a reward circuit I don't want to do. And I'm going to exercise
and I'm going to not eat all of the fat sugar, salt that evolution program me to have a dopamine
hit for because it's a shitty direction. Now, we need to get that number of people who actually
have taken some sovereignty over their fitness and well being in the presence of the cheaper
reward circuit, we need to get that number up to everybody because right now, obviously,
overweight is one of the main causes of death in the developed world. But we have to then apply
that to the even more pernicious hypernormal stimuli, because salt fat sugar or hypernormal
stimuli on in the Augustatory system, right? We have to apply that to the sensory system that's
coming in through things like social media. And that means less social media, less entertainment,
more study. And it doesn't have as fast a reward circuit, it just doesn't. But it has a much better
longer term reward circuit where your baseline goes up. And this is where enough mindfulness
and enough discipline have to come in. Because otherwise, the orientation of the system is
that it's more profitable for corporations for me to be addicted because you maximize lifetime
value of a customer through addiction. And it's an asymmetric war because they're a billion or
trillion dollar company and I'm me. So how do I win that asymmetric war where it's in their
profit incentive, whether it's McDonald's or Facebook or Fox for me to be maximally addicted?
I have to recognize, holy fuck, right? Like I actually have no sovereignty, even if I claim
to live in a democracy against democracies, who want to control and manipulate my behavior in a
way that is net negative for me holistically while having the plausible deniability that I'm
choosing it because they're coercing my choice. So I have to get afraid of that enough that I
mount a rebellion, right? A revolutionary war in myself against those who want to drive my
hypernormal stimulus reward circuit. So the whole how can everybody become more immune
to the shitty reward circuits and notice them and become immune to them? And how can they
become more oriented to the healthy reward circuits? That's another way of talking about
what we have to do writ large. Yeah, that's beautiful. Completely agree. In fact, it dovetails
with another thought that first time I thought it, I thought it was original and then having said it,
I discovered lots and lots of people had said it before me that there's a very close relationship
between wisdom and delayed gratification, that it's the ability to bypass the short-term reward
circuit in order to get to something deeper and better that is, you know, that is what wisdom is
about. But you didn't include on your list what I consider to be maybe the one of the most important
instances of the failure that you're talking about, which is sex. There's a very direct comparison,
at least for either males who are wired in a normal fashion for a straight guy or women who
are toying with that same programming, which I believe there are many. But the comparison between
casual sex, which is certainly we are as males wired to find that a very appealing notion because
it's such a bargain. If you can produce a baby where you're not expected to contribute to its
raising, that's a huge evolutionary win. And then you have to compare that to the rewards of a deep
romantic lasting relationship with commitment. And the problem is that the deep lasting relationship
stuff has a hard time winning out over the instant gratification thing if the instant
gratification thing is at all common. And so that's really screwing up people's circuitry with
respect to interpersonal relationships and bonding. And I have a sense that it is also
in a way that's much harder to demonstrate contributing to the derangement of civilization
that people, many fewer people have a relationship. You know, it's not like marriage is easy,
right? It's not. It's super complex. But having somebody who you can fully trust, somebody who
you've effectively, you know, fused your identity with to the level that they share your interests.
And, you know, they may be the only person who'll tell you what you need to know at some points.
And the fact that many people are missing that I think is deeply unhealthy.
Yeah. So I would say that
market type dynamics benefit from exploiting the shitty reward circuits across every evolved
reward circuit axis. And so from an evolutionary point of view, survive and mate are the things
that make your genes get through primarily. So we've mentioned the survive the calorie one early
earlier, right? So in an evolutionary environment, I could get plenty of green leafy things in many
environments. It was very hard to get enough fat, enough sugar and enough salt. Those were
evolutionarily rare things. So more dopaminergic hits on those. So fast food ended up figuring
out how to just combine fat, salt, sugar with no other nutrients with maximize ease of palatability
and textures. And there's like a scientific optimization of all of the dopamine hit with
none of the nutrients. So you can actually be obese and dying of starvation, right?
And what that is to nutrition, where you would should have a natural dopamine urge to hit on
something that has nutrients built in for, you know, adaptive purposes is what porn and online
dating is to intimate relationship is what Facebook and Instagram is to tribal bonding.
Is how do we take the hypernormal stimuli part of it out, separate it from the nutrients and
make a maximally fast addictive hit that actually has none of what requires energetic process?
Yeah, I've called this the junkification of everything. And it is a directly an allusion
to junk food where we can most easily see this. But the idea is you will be given a distilled,
