what does it tell me in other words I would become agnostic at that moment rather than go on the attack
people don't give enough benefit of the doubt to people who agree who think differently and they
give too much trust to those who think the same right but then here's the the place that the
thought goes so is it true that if somebody intelligent says something that is completely
inconsistent with my model of the universe that I will inherently give it enough credence to look
at it it's a tough question because if I if I try some test cases if you told me
that you believed that there was a strong chance that the earth was flat okay that would throw a
huge error for me right because I know a that I've checked right in fact I have years ago and
several times said what are the chances there's anything that these flat earthers that they're
not just a joke and then it's a trivial matter to find out what you need to know from your own
experience that is inconsistent with that possibility and so the answer is okay I'm not
going to spend too much time checking with it right then we get to is the moon landing fake
right this one is tougher right it's tougher because when you look at the actual evidence
that people are motivated to hypothesize that the moon landing is fake there are some things
in it that are hard to know I don't offhand know what the explanation for them is so anyway my
point is there's some ideas I wouldn't be shocked at all to find that you believe there's some ideas
I would be so shocked that I would imagine you're kidding or you've lost your mind or I don't know
what and so we all draw that line somewhere and I guess my point is I think almost everybody even
very very smart people who don't happen to be experienced in first principles independent thinking
draw that line somewhere that creates a fatal error when independence is experimented with
right that the number of things that you know it is the matrix in some sense once you start
experimenting with what would I conclude if I was independent of all incentives and I just went
based on the evidence and I gave everybody a chance to articulate their position
what comes back is so jarring that most people are driven back into conventional automatic
thinking because the the frightening aspects of what what they get in response are enough to drive
them off the instinct yes okay god there's so much in here that's really good
the thing about the flat earth is that it is the hypothesis is formally falsifiable
and the alternate even even by an individual yes and it's the high the alternative hypothesis
formally verifiable with the best methods that we have with the highest confidence we can have
and now one thing I would still say is interesting is I know many people who refer to flat
earthers as the moniker of maximum stupidity who cannot do the Copernican proof so they take
as an article of faith that the earth is round but they actually don't know how to drive it have
never tried and so then they also move to taking as an article of faith similar things that don't
have the same basis so if so does someone even understand what falsifiable and verifiable
mean does someone have a basis for calibrating their confidence margin because if if I start to talk about
the moon landing or then I go a little bit further and talk about long-term autoimmune effects
or epigenetic drift or whatever they come from a vaccine schedule of 72 vaccines together
is the standard narrative falsifiable or verifiable is the alternate narrative falsifiable
in the way flat earth is no so the fact that we put flat earth and anti-vax in the same category
is a intellectually dishonest bad thing to do and but the fact that most people
don't even know how to do verify or falsify and so like with the lab hypothesis when you come to
90% I'm guessing you have a process for that what I would say is I haven't studied it enough to put
a percentage because I don't have enough Bayesian priors to actually come up with a mathematical
number what I would say is I consider the idea of it coming from a lab and some kind of dual
function gain gated function research dual purpose gated function to be very plausible
and I have seen nothing that falsifies that and the few attempts that I saw early to falsify it
were theoretically invalid to me now to be able to go from plausible to a probability number I would
need to apply different epistemic tools than I have already applied well wait a second I'm not
sure that that's the case because the to me as a theoretician there is a hypothesis the there are
multiple hypotheses one is the virus escaped from a lab unmodified another is that it was
enhanced with gain of function research and then it escaped another is that it was weaponized and
deliberately released all of these things each of them is a hypothesis each of them makes predictions
and they are all testable now I am not required to have any guess as to which one will turn out
to be correct nor an assessment of how probable it is it is natural to have a guess but the two
things function independently right as a scientist I am obligated to treat a hypothesis by the formal
rules of science I know what they are I know how they work and therefore I know at what point it's
going to be falsified any one of them and what would be necessary for one of them to become a
theory that is to say for all of its challengers to fall now I can also say look if I had to bet
here's where I put my money but I'm not I'm I happen to be a scientist who would be placing a
bet but my bet is not a scientific bet yeah we're we're aligned clarification agreed yeah okay good
so then that that is that is my hunch that I didn't come to that number through a actual
Bayesian or other kind of mathematical process but if I was actually trying to formally give my
my percentage basis I would go through some epistemic process and the more now if I had to
make a consequential choice based on it the more consequential the choice is the more
process I would want to go through to calibrate my confidence of it because the more problematic
would be for me to be wrong right okay so that that all makes sense but the the ultimate question
here is given that we can see we want people not to behave in an automatic way in a
a way that is below the nature of human cognition's capacity to to think and to react
but we also know that when people experiment with that under the current regime it is not that they
will produce conclusions that are different than they would otherwise produce say them to their
friends and their friends will say oh that's interesting I didn't realize you think that
their friends will say oh my god I can't believe you're one of them right and that that thing is
so powerful that it is artificially depressing the degree of independent thought because anybody
who has experimented with it is likely to have effectively you know touched some third rail
and retreated as a response so we don't know there's a failure mode on both sides
there's a failure mode of not of creating artificial constraints where we don't explore
the search space widely enough which is the one you're mentioning there's another one of exploring
the search space without appropriate vetting and jumping from hypothesis to theory too fast
yes and those two are reacting against each other right there are people who
say because it's plausible it is they jump from hypothesis straight to theory without proof
and then they believe wacky ass shit yes and they insist that it's true and then people over here
are like wow that's really dangerous and dreadful and anything that looks like that I'm going to
reject off hand and similarly people over here believe standard models that end up getting either
captured or at least limited and people over here react against that so this is another place that
I would say the polls are driving each other both to nonsensical positions well yes and the way that
works in practice is there is a team that in principle knows that it is in favor of doing
the analysis but it does not believe itself capable of doing the analysis so effectively it
signs up for the authority of those who claim to have done the analysis and in principle have
the right degrees or whatever but then we run into this thing which goes back to something you've
said in several places in this discussion which has to do with the bias amongst those involved
in certain behavior in other words if you're an epidemiologist at the moment or a virologist
there's a very strong chance that you believe the lab leak hypothesis is uh stands a very
low chance of being true but you also very likely have a conflict of interest you may be directly
involved in the research program that would have generated COVID-19 or you may simply be involved
in social circles in which there is a desire not to have virologists responsible for this pandemic
and therefore there's a circling of the wagons that has nothing to do with analysis but either way
the tendency to converge on a consensus is completely unnatural and those who are trying
who earnestly are trying to follow science end up following consensus delivered by people who
claim the mantle of science while not doing the method and that is a terrible hazard.
Yeah yeah I agree and there's one step worse which is the thing that we mentioned earlier which is
you can do the method have them all of the data coming out of the method be right and still have
the answer be misrepresentative of the whole because you either studied the wrong thing or
you studied something too partial and so this question of what is worth trusting comes up again
and is okay I don't want to defect on my own sense making to just join the consensus so that I
am not rejected at the same time if everyone is sure that I'm wrong and I'm sure that I'm right
I should pay attention to that right because very possibly I have a blind spot and I'm a confused
narcissist every once in a while they are all in an echo chamber and I'm actually seeing something
and it's it both can be the case sometimes so you're like okay do I always stick to my guns or
do I always take whatever the peer review says neither this is again the optimization function
isn't it wisdom ends up being a I don't know the answer to this trolley problem before I get there
right so what I have to say is is the basis by which the other people all agreed that you were wrong
deliberative and methodological and earnest and free of motivated reasoning
does it have a group motivated reasoning that's associated with it are there you know clear
blind spots in the thing you're thinking so I don't think there's an answer to the what actually
is right there there is no methodology it's the Tao that's eternal is not the Tao that
speakles not the eternal Tao the methodology that's formalizable is not the thing that reveals
the Tao right like ultimately you have to end up adding placebo at a certain point and then
double blinding and then randomization the methods have to keep getting better because
there's always something in the letter of the law that doesn't get the spirit of the law
and in the letter of the methodology that doesn't get actual science right right and in fact
so a couple things here one there's a part of the scientific method which is a black box
there's a part that actually I believe literally cannot be taught right it is the part where you
formulate a hypothesis right that is a that is a personal process if I taught somebody to do it
my way that I don't think they do it very well right so the point is that's something that you
learn to do through some process that is mostly not conscious hard to hard to teach and hard to
discover but everybody who does it well does it in some different way and so at that level even
just saying do the method is incomplete because not everybody can do the method see there was something
else uh oh yeah there was there was a missing thing on your list I realized you weren't trying
to be exhausted but there was a missing thing on the list of possible reasons that you could come
up against a consensus and still be right even if you're the only person who disagrees and it has to
do with the non-independence of the data points on the other side based on let's say either a
perverse incentive or a school of thought having won out and killed off all of the diversity of
thought over some issue that turns out to matter and these things can vary easily so I would say
yes if you always think you're right and when everybody's against you they're wrong then yeah
narcissism is a strongly likely reason on the other hand it is as you point out with tesla
and uh their competitors sometimes you find that a field or an industry is easy to beat
that there's something about them that is you know maybe economically very robust but with
respect to their capacity has become feeble and this is true again and again in scientific fields
that scientific fields um go through a process where they a school of thought delivers handsomely
on some insight it wins the power to own the entire field that insight runs its course diminishing
return sets in it stops delivering anything new it doesn't give up the reins and hand them over
to somebody else because there's no mechanism to do that so the people who have the school of thought
that's already burned out its value stick to their you know their power and that means that the field
is wide open to be beaten by an outsider who just simply isn't required to subscribe to
whatever the assumptions of the school of thought are and that happens so frequently
that there is this it's artificially common that you have the experience if you think independently
and you know what you're doing that you'll disagree with just about everybody and they'll
actually turn out to be wrong because they're proceeding from a a bad set of assumptions
so i think this is actually one of the most interesting applications of blockchain or
decentralized ledger technology is this idea of an open science platform so imagine every
time someone did a measurement the fundamental measurement it had to be entered into a blockchain
and then the other places that independently did it was entered into a blockchain so it was
uncorruptible and then the the axioms and the kind of logical propositions get entered in and then
the logical processes of whether i'm using an inductive or deductive or what an abductive process
gets put in and then we get to kind of look at the progression of knowledge then at any point
we come to realize that a previous thing and there was wrong some data was misinterred or a
hypothesis has proved wrong now we can come back to that point and look at everything downstream
from it and reanalyze it um of course you still have the oracle problem of the entry in the first
place so if i'm doing motivated science and i get some answers i don't like and i can hide them and
not enter them then that'll happen so you still have to have then the proper entry into the system
but this address is something with the integrity of science and also the integrity of government
and government spending in the capture of market forces of the regulators rather than the
regulators being able to regulate the market is we only know when the fucked up thing happens if
we can see it and which means that everyone who wants to do something asymmetric or predatory
has a maximum incentive for non transparency so certain kinds of uncorruptibility and transparency
are very interesting in what they can do towards that interesting now this actually comes back to
something i wanted to raise earlier um but didn't get to it which is i started out very focused on
sustainability i believe sustainability is something that the system you can't you can't
measure to finally if you measure to finally then sustainability becomes an absurd block to
progress because you can't dig a hole in your own backyard because you couldn't dig a million such
holes um but if you uh relax the system so that you're measuring processes that actually
potentially matter sustainability has to be a feature of the system long term right it doesn't
have to be the feature of the system in any given time period but overall it has to net uh to a
sustainable mode i wouldn't say a system has to be sustainable i would say the meta system or
increase in orderly complexity has to be sustainable but that might mean a system intentionally
obsolete itself for a new better system okay i accept that but what i've realized uh down this
road is that the system actually or the set of systems or the meta system however you want to
describe it needs a failsafe which i call reversibility right so the point is if you set the
goal of sustainability and you say well we have to measure things that matter sooner or later you're
going to fail to measure something that matters and you're going to deal with it unsustainably
and at the point that you figure it out it's going to be too late so my point would be
and you know this is a tough one people don't like the implications of this if they understand it
but any process that you set in motion has to be something you could undo if it turns out to be
harmful in a way that you didn't see coming right so that is to say you can alter the atmosphere
carbon dioxide is not poisonous right the changes in concentration that change the degree of heat
trapping are not terribly meaningful to the well-being of living creatures
but at the point you discover that the heat trapping is going to massively change the way
the atmosphere functions and the oceans etc etc you have to be able to undo it now undo it
means you could change the concentration back to what it was now what this would mean in practice
was that you would have to slow the process of change down such that you scaled up the process
that would reverse the change in proportion now if you imagine all of the disasters that we have
faced all the ones I named up top and all of the other ones that look like it from you know Fukushima
to Elizo Canyon to financial collapse of 2008 and you imagine that in proportion to the process
that went awry we had scaled up the reversal process so that it was there if we needed it
right we would have been in a very different situation because a the process would have run
away much much slower and b the tools to undo it would have been present and ready
oh before you respond to that I do want to say that the only way that that would work
is if it was over the entire system in other words if one nation for example were to decide
that it had to adhere to a standard of reversibility while other nations weren't restricted in the
same way you didn't you'd get a tragedy of the commons where the atmosphere or whatever other
