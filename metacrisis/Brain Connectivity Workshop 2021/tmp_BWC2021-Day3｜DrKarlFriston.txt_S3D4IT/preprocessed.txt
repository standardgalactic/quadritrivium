We are however at the end finishing with Karl Friston whom I'm sure you all know so I won't
introduce him further. Is there a unifying theory to unify unifying theories so Karl
look very much forward to you unpacking this for us thank you. So it's a great pleasure to
wind up this brilliant workshop. Normally my presentation is taken as a sort of light
entertainment and as I said yesterday it usually degrades into a debrief about how well we've done
so I'm assuming that at some point we're going to get bored of talking about
whole unifying brain theories and I'm going to pass back to Michael who I presume will then pass
back to Randy just to sort of bring things to closure but in the interim I'm going to try
and answer the question and I should say that this title is a wonderful title it is not my title
it's something that Randy spent at least two weekends thinking about and crafting for me
and I've taken it very very seriously so I've done my best to try and find the theoretical frame
that will happily embrace and comfort and validate everybody else's theories not just the
theories that we've been hearing about today but all other theories that could be brought to the
table to explain how we work so if you all enjoy that lovely photograph we'll move on to
slide one so the overarching notion is basically that we are creatures that are compelled to
garner or search out evidence for our existence and where our existence is entailed by our
generative models of the world and I'm articulating that just by saying that there are some internal
brain states which represent expectations about hidden states outside the world and we have some
control variables or action variables you both of which are in the service of maximizing the
probability of any observable outcomes under a given model entailed by our brains and we can
split that into perception and action why is this unifying well if you read that probability of the
outcomes under a model as describing the kinds of outcomes that I as this particular phenotype
expect to encounter then we can read this log of the probability as value as the utility of
particular outcomes that then endorses a description of our active engagement with
the world in terms of reinforcement learning optimal control theory with a lot about control
theoretic approaches but they rest upon a specification of this value function of some
outcomes and the economics it will be expected utility theory and this quantity here is going to
be approximated with free energy which is where the free energy principle gets into the game but
it's usually the free energy is articulated more from the point of view of information theory
where the negative value becomes self-information, surprise or surprise and the free energy now
becomes a bound upon i.e. in this instance the negative free energy is always greater than
the improbability of some outcome that would be very surprising if an outcome occurred to me.
From that we can license or talk about the principle of maximum utility information,
the infamax principle, principles of maximum efficiency, minimum redundancy from Horace Barlow
and indeed the free energy principle. We've seen inspiration from Herman Haykins explicitly on
paper and also implicitly in terms of some of the work that Victor has drawn our attention to
that can be easily motivated by noting the time average of this self-information or surprise's
entropy which means action and perception on this reading of self-evidencing is really in the
service of minimizing the entropy of outcomes so we're talking about the holy grail of self-organization
formally articulated in terms of synergetics and laser physics but if you are a physiologist
we're just talking about homeostasis is keeping outcomes within viable physiological bounds and
and then finally if you're a statistician or from machine learning you would read this quantity as a
probability of some data observable data under a model a Bayesian model and that would be called
Bayesian model evidence and from that we can spin off the Bayesian brain evidence accumulation
and predictive coding on all that good stuff under the watchful eye of Herman Helmholtz.
So what is this evidence? It's usually written down in terms of a variational bound and then
there's an elbow machine learning evidence lower bound or a free energy bound that is simply the
log probability of outcomes given a model of how they were generated but is formed by taking the
thing we want and just putting something that can never be less than zero on top of it to bound it
and that's the divergence between our beliefs cue about states of the affairs generating data
and the true posterior and what's there given I could observe those data and I'm writing that down
just to motivate why this is potentially a very important generic and almost universal way
of defining optimality you've got a gerative model there that leads you to expandable artificial
intelligence if you're in a pragmatic setting you have a principal account of design optimality
and what we'll see in a second is also the way that you go and gather data that the underwrites
are abductive inferences and this cartoon that here with in terms of data foraging and
epistemics but what I want to do is just rearrange those terms at the top
to provide another interpretation which I think is much closer to some of the questions and issues
that we've been contending with I can rearrange those expressions and express evidence or
evidence bound in terms of accuracy and complexity so this is the sort of like the fitness
and you could think of this as basically the the flexibility versus robustness I hope I've
got the right words from Randy's talk in the sense that you know if you want a robust explanation
of your world then that has to be fairly accurate but at the same time it has to be expressive
so this is an interesting relationship because the evidence is the difference between accuracy
and complexity which means that if you want to provide an accurate account of the world
you are compelled to do so in the minimally complex way so what does this complexity term
look like well it's just an expression of Occam's principle in effect finding the simplest explanation
at hand that affords an accurate explanation of some observed outcomes it is interesting also
from the computer science point of view because it scores the degree of belief updating as you move
from your prior beliefs to your posterior beliefs in the light of any new sensory evidence or any
new data which costs both in terms of the computational cost but also in terms of the
thermodynamic cost so there's via the Josinski equality and Landau's principle for every belief
update that is measurable you know say with EEG or fMRI there will be a number of jewels
that you have to expend to do that belief updating so this is coming to Susan's
recurrent focus on the actual thermodynamic and metabolic cost of belief updating and there's a
very simple relationship it just scores the complexity but also the complexity also holds
the expressivity of the model so as you're providing more and more accurate accounts you'll need a more
complex model you need more expressive model so this speaks to this you know many of the talks
not for example I'm going to miss a whole bunch of examples here but what is in my mind is this
sort of notion of hidden repertoires that could be brought to the table when apt explanations for
this particular context in an expressive way another example of this is the increasing hierarchical
depth of generative models endowed both by evolution but also by neurodevelopment in terms
of pruning synaptic homeostasis that lead to these sparse structures and why is sparse important
well it's just an expression of paying avoiding overly complex overly parameterized generative
models if you read synaptic connections as the parameters of those of those generative models
so a lot of if you like the imperatives which would seem beautifully unpacked for the pruning
and the simplification of generative models and their implicit thermodynamic efficacy are basically
written in just the definition mathematical definition of model evidence so I just want to
close by saying that these principles also apply in relation to actively engaging with the world
so that the imperatives to maximize your the accuracy of the explanations whilst minimizing
their complexity translate into effectively maximizing the expected accuracy in terms of optimal
Bayesian decisions whilst the complexity term translates into a
minimizing a cost in the sense of Bayes optimal decisions as opposed to design which is getting
the right kind of data to minimize your minimize your uncertainty about the causes of your data so
just written that out formally here just re-expressing the evidence bound in terms of
a mixture of accuracy and complexity and asking what would this quantity or these imperatives
so written out look like if I didn't actually have the outcomes but I knew what they might
look like under some policy pie some action or move on the world and just by taking the expectations
you can conceive of complexity and accuracy mapping to risk and ambiguity so if I want to
minimize this expected free energy I'm effectively minimizing risk and ambiguity and in terms of a
unifying theory of unifying theories this actually gracefully accommodates a number of
takes on the way that we epistemically forage the world so if I ignore this extrinsic value here
then we're left with this thing which is just the information gain or the reduction of uncertainty
that I would get if I looked over there or made that move in the visual search literature it's
called base in surprise an information theory it's just a mutual information between the causes
and consequences consequent on making that move as opposed to that move if I take another kind of
uncertainty off the table namely the ambiguity I'm left with risk sensitive control which is just
basically scoring the difference between states of affairs out there if I make that behavior
relative to my prior preferences so we've come back this is if you like a grown-ups version of
optional control theory where you're putting on a certain kind of uncertainty into the game
namely the risk if I take away all uncertainty I'm just left with this quantity which is
the the expected value and we have good old fashioned Bellarmine optimality principles and
expected utility theory so I'll close now by trying to say well why is this useful for framing
all the kind of mechanics that we've been talking about network theory graph theory and the like
well I've been talking about generative models if you subscribe to the notion where all in the
game of maximizing the evidence for our models of the world that requires that to be a model or a
generative model you can always write down a generative model in terms of a probabilistic
graphical model if you can do that you can always write that down in terms of a factor graph what
the factor graph gives you is the requisite message passing required to invert or make sense of any
observable outcomes oh here by essentially inverting that generative model in a Bayesian sense which
means that at the heart of understanding computational anatomies and the architectures
on which they live is a graph and implicitly an appeal to graph their formulations of
message passing on graphs that usually are very deep graphs so I just included this as a nod to
the importance of the hierarchical aspects of graphs that we talked about and also as you go
deeper into the hierarchy things you get a separation of temporal scales which we've also
heard about in terms of fast versus slow and their age dependencies you get that essentially for
free just by building these little factor graphs on top of each other or putting slow
transitions and flows on top of faster things lower down at the hierarchical the hierarchical
levels the off-the-shelf message passing schemes that would be apt for those kinds of factor graphs
look very much like the the neural mass models that people use to simulate activity and indeed
understand neural message passing terms perception associative passivity and learning terms and the
parameters of the generative model and indeed action selection you can carve out rough functional
anatomies based upon the functional form of the message passing implied by the factor graph
that inherits from a specification of your hierarchical or deep generative model.
This is the first slide so I've only officially used five slides but what I wanted to do I start off
by saying well look there's an imperative to maximize evidence for our models of the world
how do we actually do that well we do it with these structured flows on manifolds where
those flows via the Helmholtz decomposition can be decomposed into a gradient flow that
optimizes the model evidence the log probability of outcomes given a model that's denoted by gamma
here but is always accompanied in virtue of the Helmholtz decomposition with this irritational
nondisputative or solenoidal flow and this is the thing that does the mixing and of course if you
put this mixing into that hierarchical generative model then you've got hierarchical mixing I've
never used those words before so I hope that Gustavo is there and smiling in the background
and so that would be if you like the practical way of putting these this message passing
on factor graphs into a real-world setting where we now understand neuronal dynamics
as structured flows on manifolds that I repeat are a statistical manifold and therefore equipped
with an information geometry so I'll finish there give the last word to Einstein just as
a nod to remind you that evidence is just simplicity plus accuracy namely everything
should be made as simple as possible but not simpler and with that I just need to thank
those people whose ideas I've been talking about and of course thank you for your attention thank
you very much indeed well once again Carl in the virtual age you just get
the chair clapping but sure there's a chorus of hundreds 208 people who very much enjoyed
the unifying theory of unifying theories just two things come to mind for me while others
collect their thoughts and I know you've already thought and written about this but I'll ask the
question anyway and that is you know given the discussion that Susan just initiated about metabolic
energy and then you're been discussing sort of surprise there's sort of information free energy
how close in terms of a you know omnipresent unifying theory is Gibbs free energy which is all
about work and energy and jewels and things that we can measure with you know thermometers
and um christianian free energy are they are they you know is it always that there's a
metabolic cost that scales in proportion to this um suprisal term in your formulation
you know through synaptic chatter and synaptic plasticity or is that really just a metaphorical
but not necessarily a one-on-one mapping I'm interested in your thoughts on that
you know my thoughts are very simple it's a mathematical isomorphism so very very clearly
any movement on that statistical manifold any belief up a date has a very precise and
exact thermodynamic cost if you measure in jewels you just need to multiply
the distance you move the degree of belief updating and by Boltzmann's constant and temperature
and that will give you in jewels the amount of energy you've used to change your mind
so you know the the beauty of sort of deriving the statistical physics of inference and working
you know sort of on statistical manifolds is that the maths that underwrites the Helmholtz
and Gibbs free energy is exactly the same as the variational free energy you know it's it's
exactly the same maths and I repeat via the via the Jynnski equality you can you can you can
actually compute if you change your mind from this to that in the face of new data you can
compute the thermodynamic cost of that which is the computational complexity
which tells you that a good computer should be very very small very cool and just work on batteries
okay okay so there's some questions appearing in the Q&A and Sofia Zangila would you like and then
a follow-up by Thomas would you like to ask these by unmuting yourself or should I read them out
okay I'll read them out then is the search for one unifying theory motivated only from our
beliefs that such a theory exists or should exist or is there a logical experimental rationale that
supports unifying theory I guess so we just seeking simpler explanations this is a sort of
ontological question I guess or is there really a simple unifying theory out there that we're
approximating with our cognitive beliefs I'm not sure I'm qualified to answer that but you know
if you pursue the free energy principle that's exactly right and you'll use the word approximate I
think is actually very very very appropriate in this context so notice that that free energies
are bound on evidence it's not exact inference it's it's approximate Bayesian inference it's
bounded rationality that is doable and realizable in the physical system and if we as scientists
are compelled to find very simple explanations of the world then then yes you are you you are obliged
to find a unifying theory that's as simple as possible well that's a bit of a philosophical
reason you should you should answer that you should find or find a philosopher who can answer that
question yeah well I mean the complexity of the microscopic movement of the universe has to
collapse onto these synchronization manifolds or these structured flows on on manifolds or
you know we'd never have figured any of it out I mean you know if we were dealing with the
microscopic equations I mean this is statistical thermodynamics you know if the theory was no
more than a metaphor then we would be dealing with the microscopic degrees of freedom and and
everything would be utterly incomprehensible so there definitely are these Herman Harkin
enslaving principles and these things out there that support life and support meaningful action
and support comprehensibility so Thomas Vali your skeptical that evolution would would have a
selection pressure um that would evolve a system to have an aesthetically pleasing solution so I
just kind of must have read that and tried to make a counterfactual out of it but um do you want to
do you want to speak to a contrary view?
I do although I'd like to hear your answer to that the reason I do is I think it nicely speaks to
Alexis and Jean-Pierre's presentation earlier on so I was sort of I thought it was a wonderful
discussion and presentation and music to the eyes of a free energy principal enthusiast because
natural selection is read as based in model selection in my world and the adaptive fitness of the
objective function is just the model evidence of the marginal likelihood so the frequency of
occurrence of a particular phenotype just is the likelihood of finding that particular free
a phenotype in an ensemble that is bounded by the free energy so natural selection just becomes
free energy minimization and literally if you take replicated dynamics or the Fisher
fundamental theorem and you just look at it through a different lens they are simply basing
filters it's basically the phenotype but embodying the evidence for what works in that particular
environment which is very closely related to or provides an evolutionary take on things like
the good regulator theorem so for those people who don't know the good regulator theorems was
one of the key outputs of early formulations of synergetics which just says that if you want to
survive in a controllable world you have to be a model of that world which means that if you are
now looking at natural selection as basing model selection for the good generative models of that
eco niche and that eco niche is encultured and I thought that was a very important thing that
Jean-Pierre brought to the table then you have to have you now have a mathematically precise and
crisp specification of why there is selective pressure for increasing sparsification and
hierarchalization of humanoid brains that are the only brains that have to model an encultured
world with language because you could argue that viruses don't do that and they haven't done that
and they survive very well thank you very much so that would be that would be my argument
but what would what would your counter your push about me can I make a suggestion Michael one of
the Thomas Farre's been trying to to put you on this you know unmute him and allow him to
to also contribute I think he has some thoughts on that yeah I was sorry reading out his question
there sorry thank you Thomas sorry it's very early in the morning here so I'm not operating on all
cylinders first thank you Carl for fascinating talk there's a lot here that I'm interested in
digging into but I get that you've already sort of answered the question before I asked it but
the sort of example that I keep coming back to is if you've ever done like evolutionary
programming you know trying to evolve like a quadratic equation solver and lisp or something
like that you know you almost always end up with a function that a computer programmer would
very much struggle to interpret right you get like what we call like spaghetti code and all
those things so I get what you're saying about you know overall you know the process of natural
selection being you know this very elegant kind of Bayesian structure but it doesn't seem clear
to me that the outputs of that you know elegant Bayesian structure would ever be comprehensible
to us right because like I said in the original question evolution there's no selective pressure
for an aesthetically pleasing or simple or even comprehensible system right like and like I
I'm sorry to ramble so I'll just shut up but hope did you get what I'm saying like the
no no it's an excellent question I think technically and we don't have time to talk
about it it's actually a really interesting question which I haven't heard posed before
my guess is that the genetic algorithms that one were using had an objective function that didn't
include the complexity term so you probably just wrote down how close is this to the solution that
I desire and therefore you've forgotten about the complexity if you put complexity into the
adaptive fitness and energetic algorithm then you should for free get a refactorization of the code
that will become literally more interpretable and sparser and I use the word refactorization
there deliberately because on the one hand that speaks to the other take on free energy minimization
or complexity minimization which is compression so there's a whole literature on minimum description
length and minimum message length and algorithmic complexity which tells exactly the same story it's
a story that underwrites universal computation so if you have the right objective function in your
differential evolution or genetic algorithm or even a sort of you know a Gibbs sampler
then you should get really simple refactored factorized code the other thing that speaks to
in that factorization is a certain modularity which has been a recurrent theme throughout this
meeting that you know some a key aspect of these genetic models and their refactoring
and simplification the minimization of the degrees of freedom the pruning the minimization of the
complex computational complexity is a way of carving a description of the world into a number
of independent factors and that's known as a mean field approximation in physics and just
to speak into michael's point if we didn't have a mean field approximation we wouldn't have temperature
all the good stuff that we know in terms of physics and if we didn't have mean field approximations
in the brain we wouldn't have any functional segregation or modular structure so things like
the water wear system can be thought of as a refactoring of what would otherwise be spaghetti
code that did not conform to the principle of minimum message length and so let me turn the
question back on you if you try and do that if people have tried to do that have they use the
right objective function uh i don't know but i really want to go try that may be my uh a weekend
project okay thank you very much Thomas um athena you have your hand up um do you want to unmute
and um far away yes thank you carl it's always always a pleasure uh hearing your presentations
the more i hear you present and more i read your papers the more i understand it's not completely
there but i i tried to get it um so i wanted to to to comment on the fact that the the fact that
you propose a unifying theory of a unifying theory is it's like it's almost like um uh provocative
to to try find the exception to to to the rule so it's very like um automatic thing to to to do
and i think i had one that actually um bothered me some days now so it seems you're here maybe
can help me clarify it it has to do like if we think if we take like the the we are made to um
to suppress prediction errors in order to survive how come we take drugs and we abuse drugs
see as because they they induce prediction errors so why we do that intentionally
that actually our judgment makes is getting so fuzzy that this is not in our favor
so a challenging and lovely question i'm smiling a little bit because of course it was randy
thought that there was a unifying theory to you it wasn't me that was a title i was given um
i apologize for that i won't i don't take drugs you know i why not
actually i do i smoke don't i so i and i want yes now i want a cigarette um so why do we do that
um i think the the answer um you know it speaks to something which um was in the philosophy of
literature you know a few um years ago which is a dark room problem i think that that you know
there is um and when you think about minimizing your surprise or prediction error in the future
what what does that mean well it the average surprise um or the expected surprise in the
future is called uncertainty so average self-information is called entropy so that just
means the average prediction error is basically uncertainty so what that means is that minimizing
prediction error um in the moment should be distinguished from choosing those behaviors
that are going to minimize the average prediction error after you have committed to a particular
action the kinds of behaviors that do that minimization are exactly those kinds of behaviors
that make us into curious creatures and scientists so it's the epistemic imperatives
that that are responsible for actually guiding our our actions and behavior even though we now
reconfigure and do our structured flows on manifolds to minimize the prediction errors
once we've got the data but in the getting of the data in doing our bungee jumping
and taking your drugs um um you know be the cigarettes or whatever um then you are um compelled
to actually seek out salience and novelty in the service of minimizing expected surprise i.e.
minimizing uncertainty and that that becomes a fundamental understanding the importance of
of doing stuff so this is the inactive aspect of active of active inference which is why i
you know i so picked up on on on rand is you know the special kind of beliefs about the
things we are going to do may be particularly important in terms of defining us as non-cessile
creatures and therefore inherently curious creatures at least when we're young or drug taking
so many thoughts are coming out but i don't want to take over the discussion
but yeah i think it's a kind of uh makes sense the the and at the same time i'm thinking like
evolutionarily do we learn something more like changing our perception changing our
consciousness if you want like we learn something new by that i think we occupy some of these
counterfactual states that we've been discussing because most of the drugs we use are you know
extinct marijuana THC for example is an agonist of one of the brain's most plentiful
neuro receptors so just as we were speaking before about changes in temperature or changes in
pharmacology allow us to explore latent states or the dynamic repertoire or counterfactual states
in an Anil's talk perspective so i know when i take drugs
legal ones like THC you know you do take an alternative perspective there is a slight
dilation or contraction of time there is a you know there's a perspective taking
or that is different so it's probably just what Carl was saying it it decreases your longer term
uncertainty by satisfying or decreasing the latent uncertainty in a state that you can go
and visit and learn about and it's actually very similar to this question that fad yasin has asked
um so fad do you want to ask um mute and ask or do you want me to read out your question
okay i'll read it out then although i just i uh oh great yeah hi am i audible yes
yeah thanks Carl for the lovely talk it did unify a lot of at least my predictions in a
lovely way so you answered my question in many ways in Athena's question about why we would take
drugs if it induces prediction errors but what i want to ask was from a different perspective
like could it be that the systems inside the brain would be competing with itself
like for instance certain areas say like striatum amygdala and all that would have a different
free energy belief that they would like to kind of make survive but other systems like lateral
frontal cortex or say middle orbit of frontal cortex might have a completely different
competitive approach towards that so they're in some ways are generative adversarial networks all
the way and maybe an easier way to say this example would be a little legal way rather than drugs
would be most people when they have some kind of anxiety or depression not in a clinical way
but day to day sense they might open their phone and look at something very novel and very reward
feeling as if the primal brain areas might be wanting to conserve their belief but the other
half of the say cortical neocortical areas might want to go against their belief
i will try and answer that briefly i think it's the kind of question a lot of people here would
like to answer so generative adversarial networks no i personally do not think that's an appropriate
computational science and machine learning metaphor for the brain i think it's much more
like a variational autoencoder having said that you know i won't qualify why i think that's the case
but having said that i do think there's an element of competition in play here in virtue of the fact
that if you commit to the sort of Bayesian gloss on accounting for our sentient behavior
if it's behavior we can only do one thing at a time if we can only do one thing at a time we
have to select among all those hidden repertoire of things we can do that selection is Bayesian
model selection so there's an implicit winner take all like competition in any inference that
leads to an action simply in virtue of the fact that you can only do one thing at any one time
so i certainly think there are going to be competing parts of the brain in terms of
supplying evidence for this hypothesis about what i'm going to do next as opposed to that hypothesis
and one set of competitors will certainly win so i think the notion of competition is you know
absolutely crucial to understanding an inactive inference in the surface of selecting the thing
that i'm actually going to do next and in relation to drugs i'm just mindful you know there are certain
drugs that you could take just to see what would happen if i took this what is it what is it like
to take LSD and that would certainly be sort of consistent with the vanilla epistemic affordance
of taking the drug there are other drugs though that directly direct upon on your own representations
of the stress and uncertainty that the behavior would normally be in play to resolve so certain
drugs of addiction for example would be the sort of poster child children of drugs that get into
the neuromodulatory control of the precision which is just another way of expressing uncertainty so
precision is inverse variance so if you read the representation of uncertainty as being the
representation of precision that's going to have a very very close relationship with the valence of
certain belief states and in that the close relationship between the classical neuromodulators
and valenced and possibly even effective or or emotional states that you can if you like short
circuit your inference just by taking those drugs directly or if you're a lucky mouse doing self
stimulation with with the lectures implanted in the right cells of origin thanks just one
follow-up question if you don't mind why why do you why do you say uh you don't see the brain
as a generative adversarial neural because it implicitly has a discriminator in it right to
choose a select action policies yes yes i i it's just that the the other the physical sorry the
neural anatomical and physiological evidence at hand would suggest a message passing scheme that
doesn't quite have the architecture of of a general adversarial network will have the same
objective as a general adversarial network and it will have the same benefits in terms of
finding the simplest explanation it's just that the architecture it seems to be much more like
a variation autoencoder folded back on itself so you've got the you know the the the compressed
higher or deeper layers of a variation autoencoder can be if you like likened to these cores
described by alex in fact not described by alex's as sort of the global network it says a global
network so somebody i think michael's about hubopathies so it could be deep hubs
so i think this that's the kind of architecture that we're seeing in the wet where the brain
possesses that is evolved by evolution not not sort of right hemisphere left hemisphere trying to
reproduce each other thank you very much interesting okay i'm going to hand back to randy in a moment
but i completely agree kyle with this formulation of say um stimulant drugs in particular just
creating um sort of deep worlds in the free energy valley in the face of boredom boredom
and nui and um you know i worked in the prison for five years and it's like a get to get back to
culture it's like a cultural dark room much much worse than a perceptual dark room the sort of lack
of um cultural variability and the lack of counterfactual spaces are um i guess why we put
people in prison because um you know they're terrible places and they're places where
stimulant drugs are used in copious quantities brought in by you know many many routes into
the prison so um anyway with those vague wanderings randy has his hand up and um i'll allow you and
randy to have the last words for the conference oh thank you uh first of all congratulations carl
i'm i'm holding on to the the title of the talk i gave you and actually doing a very good job of
of uh satisfying its its intentions so and i apologize for the questions that were
criticizing you for trying to even do that so you know there's always a risk randy before you go on
i can sense um i don't think we're gonna have time for a sort of a round table with the audience
about what we got right and got wrong but i i just personally on behalf of the attendees just wanted
to thank you and your team um for for putting this together you know it's really so you know for
those people we can't clap and we can't we can't say it out now because there's too many of us but
on behalf of everybody thank you so much it's been brilliant now um i will i will do closing
arguments but i think it's been a remarkable success given the challenges of this current
situation and then we've managed to at least capture some of the souls for your inclusivity
and i should finish my chairing of the day by thanking the organizers and thanking tanya
and thanking all of the presenters including thank you carl for your lovely last talk
and um thank all six presenters today including alex for jumping in at last moment so um thank
you and thank you to the participants for the day okay then i want to ask a question
well you just you just closed the session so i guess no i'll just shrink into the background
now you asked carl your question and that can be the um dialogue all right all right it's it's it's
i think it's a brief question but it's actually uh kind of thinking about the next steps in terms
of what we want to try and achieve as a as a collective and the notion of trying to um merge
the different scales over which um we exist and one of that whether that can be done in the framework
you put forward carl because one of the challenges i've encountered in thinking about um multi-scale
causation for example and viktor and i talked about a lot as well um how to link up uh
the you know the interactions between different parts of the brain and then you think about that
embedded in the body again and in terms of this it's cultural um social cultural context as well
each of those can be characterized within your framework and then the notion is is that just
simply extending the hierarchy and if that happens then do you sort of lose something again in terms
of what gets sort of glossed over as you try and bridge different scales because i don't know if
there's been a solution that i've seen that actually can do that well without having to
potentially lose some of the um the richness if you will um that's within each of the levels
yeah i um i just make a few general comments to that which speak to the other things like
what has already been mentioned the fact that this group and the presumed the the audience
has a very diverse range of skills implicit in those skills is exactly this sort of multi-scale
approach so my answer to that was it would be to to make any of our theories work
then they have to be unpacked practically in terms of the neuro anatomy and the neurophysiology
and the empiricism and the mechanics and that's just basically our our day job um and what it would
what it would and clearly that's going to be a multi-scale and scale free aspects of sort of
predominated much of our this workshop and all previous workshops um um and you're one i think
once you acknowledge that then you've got your your focus is on basically yeah committing to your
scale but also committing how you relate to the scale above and the scale below and so that's going
to be done collectively it's going to have to be done collectively by people working all the all
the right scales so you know my sort of um platitude in response to you is well we're already doing
that literally uh but also specifically in the um in the attempt of this kind of workshop which is
to get all the different scales talking to each other sure sure sure i mean i guess it's just
question but the formalism that allows us to to to put it together it's not an easy task honestly
and i think you know i appreciate the sentiment curl that this is actually sort of a goal of the
workshop and it is i mean and i think the fact that we've had this workshop going on for almost
20 years that we've made huge uh uh progress uh towards that and it's just uh this is sort of the
next i guess challenge uh it faces us and i think we have a way forward it's just a question of
continuing to do that um as as a group so i actually think that's actually a good way to end this meeting
so uh dr breakspear would you agree uh yeah i um i was just looking through all the other
panelists and all the um speakers from the other days and um well our colleagues and friends so um
you know 20 odd years and every year there are new people and um hopefully all the new people
will come next year um i don't have anything wise to say but do we have any vague theories of where
we might meet probably in person next year so let me let me pass the baton to petra on that
and she's actually part of the group that's thinking about the next bcw right thank you randy
so indeed uh simon eichhoff uh claus hügelthard and myself are the organizers of the next
workshop and we have already booked a building for that in busseldorf so the next brain connectivity
workshop will take place from 13th of june 15th of june 2022 in person
hopefully wonderful thank you petra that's excellent news i'm just going to uh share my screen uh again
huge thanks to all the speakers uh this meeting really inspires me because it does uh
involve discussions that are you typically don't have when you're sitting in your office or not when
you're sitting at your homes under quarantine or lockdown so i'm very pleased that we managed to
capture some of the spirit of brain connectivity randy one one one small comment at the end first
of all totally second your your thanks and it's been we've organized this meeting twice really
so uh we really put put this together a year and a half ago and then had to and then had to
had to skip last year uh one one thought is you know we've done this online for the first time and
as i was witnessing these these sessions there are some aspects of the online format that are
actually positive i think positive and perhaps should be retained i'm wondering whether we might
solicit some feedback from participants and other people in the community as to how should we
how should we think about next year if we do go back to the to the real world i mean one
default option is we just go back to how we've always done it but i but i wonder if some of the
accessibility and interactivity that the online the additional online format might bring could be
retained um to have a uh not a hybrid meeting but but have an in-person meeting with the capacity
of bringing people in who can't travel who don't want to travel or or you know simply you know
joining from from from remote places to contribute and that might be something you want to think
about and i i would say uh we should solicit some feedback from from from people in the room now
but also beyond and and see how we can incorporate that indeed a great point Olaf and just to note
to the attendees that we have a survey prepared that will include some information on that topic
exactly so we'll definitely be anxious to hear uh how your experience was and if this is very strongly
about you know broadening the geographic range of science in general on this planet
and not just limited to to people who are privileged to have the the funds and the capacity to
to to travel to to far off and sometimes remote locations so i think we really should
think more about how we can truly make this a global event each year and in in addition to
having an in-person component obviously which i think is much preferable in many ways to the online
format agreed so we will take care of this i think that makes perfect sense
in the pause in the conversation and since we have the thank you slides still up and Tanya is
there on camera i want to uh again express my sincere gratitude to Tanya who was basically the
lead for pulling all this together two times again this time in person so i'm going to clap
on my side but i think Tanya did a fantastic job for pulling this all together it's incredibly
smooth given the challenges so thanks again Tanya in addition Tanya is now going to be
transitioning potentially to a new job so even though she's been part of bcw
uh going back at least as far as Montreal if i'm not mistaken Tanya um it has helped
to organize at least three or four of these meetings so um so but since she'll be in
Germany next year she'll be able to come as a special guest if not actually a participant so
again thank you Tanya for your help over the years as well i appreciate it absolutely my
pleasure and i look forward to what's to come thank you um just a couple things like the
recordings will be shared i'll leave this up for a second people want to get the
the code scanned we will try and get or we in the oral sense we'll try and get the recordings
edited and up as soon as possible it's a very rich discussion so i like to save those and
in addition for those you don't know we are planning to have a special issue for network
neuroscience to vote it to this meeting i don't know all the details yet of who is going to
contribute but i know that people have at least in principle agreed to contribute and there'll be a
special paper from Carl Susan and myself that will follow from one that we actually did for the
first meeting what does the brain think of the mind and we'll turn it around now and say after
all 20 years what does the mind think of the brain so that'll be a challenging paper to put
together i'm looking forward to working with Carl and Susan on that and finally uh again
and Petra has mentioned we're on Dusseldorf so i'm hoping i will see some of you there uh at least
in person and definitely see some of you virtually so again thank you everybody for participating
and with that i will close the meeting and wish you all happy journeys and enjoy your weekend
that's coming up very soon bye bye thank you very much thank you
you
