Alexis and Jean-Pierre's presentation earlier on so I was sort of I thought it was a wonderful
discussion and presentation and music to the eyes of a free energy principal enthusiast because
natural selection is read as based in model selection in my world and the adaptive fitness of the
objective function is just the model evidence of the marginal likelihood so the frequency of
occurrence of a particular phenotype just is the likelihood of finding that particular free
a phenotype in an ensemble that is bounded by the free energy so natural selection just becomes
free energy minimization and literally if you take replicated dynamics or the Fisher
fundamental theorem and you just look at it through a different lens they are simply basing
filters it's basically the phenotype but embodying the evidence for what works in that particular
environment which is very closely related to or provides an evolutionary take on things like
the good regulator theorem so for those people who don't know the good regulator theorems was
one of the key outputs of early formulations of synergetics which just says that if you want to
survive in a controllable world you have to be a model of that world which means that if you are
now looking at natural selection as basing model selection for the good generative models of that
eco niche and that eco niche is encultured and I thought that was a very important thing that
Jean-Pierre brought to the table then you have to have you now have a mathematically precise and
crisp specification of why there is selective pressure for increasing sparsification and
hierarchalization of humanoid brains that are the only brains that have to model an encultured
world with language because you could argue that viruses don't do that and they haven't done that
and they survive very well thank you very much so that would be that would be my argument
but what would what would your counter your push about me can I make a suggestion Michael one of
the Thomas Farre's been trying to to put you on this you know unmute him and allow him to
to also contribute I think he has some thoughts on that yeah I was sorry reading out his question
there sorry thank you Thomas sorry it's very early in the morning here so I'm not operating on all
cylinders first thank you Carl for fascinating talk there's a lot here that I'm interested in
digging into but I get that you've already sort of answered the question before I asked it but
the sort of example that I keep coming back to is if you've ever done like evolutionary
programming you know trying to evolve like a quadratic equation solver and lisp or something
like that you know you almost always end up with a function that a computer programmer would
very much struggle to interpret right you get like what we call like spaghetti code and all
those things so I get what you're saying about you know overall you know the process of natural
selection being you know this very elegant kind of Bayesian structure but it doesn't seem clear
to me that the outputs of that you know elegant Bayesian structure would ever be comprehensible
to us right because like I said in the original question evolution there's no selective pressure
for an aesthetically pleasing or simple or even comprehensible system right like and like I
I'm sorry to ramble so I'll just shut up but hope did you get what I'm saying like the
no no it's an excellent question I think technically and we don't have time to talk
about it it's actually a really interesting question which I haven't heard posed before
my guess is that the genetic algorithms that one were using had an objective function that didn't
include the complexity term so you probably just wrote down how close is this to the solution that
I desire and therefore you've forgotten about the complexity if you put complexity into the
adaptive fitness and energetic algorithm then you should for free get a refactorization of the code
that will become literally more interpretable and sparser and I use the word refactorization
there deliberately because on the one hand that speaks to the other take on free energy minimization
or complexity minimization which is compression so there's a whole literature on minimum description
length and minimum message length and algorithmic complexity which tells exactly the same story it's
a story that underwrites universal computation so if you have the right objective function in your
differential evolution or genetic algorithm or even a sort of you know a Gibbs sampler
then you should get really simple refactored factorized code the other thing that speaks to
in that factorization is a certain modularity which has been a recurrent theme throughout this
meeting that you know some a key aspect of these genetic models and their refactoring
and simplification the minimization of the degrees of freedom the pruning the minimization of the
complex computational complexity is a way of carving a description of the world into a number
of independent factors and that's known as a mean field approximation in physics and just
to speak into michael's point if we didn't have a mean field approximation we wouldn't have temperature
all the good stuff that we know in terms of physics and if we didn't have mean field approximations
in the brain we wouldn't have any functional segregation or modular structure so things like
the water wear system can be thought of as a refactoring of what would otherwise be spaghetti
code that did not conform to the principle of minimum message length and so let me turn the
question back on you if you try and do that if people have tried to do that have they use the
right objective function uh i don't know but i really want to go try that may be my uh a weekend
project okay thank you very much Thomas um athena you have your hand up um do you want to unmute
and um far away yes thank you carl it's always always a pleasure uh hearing your presentations
the more i hear you present and more i read your papers the more i understand it's not completely
there but i i tried to get it um so i wanted to to to comment on the fact that the the fact that
you propose a unifying theory of a unifying theory is it's like it's almost like um uh provocative
to to try find the exception to to to the rule so it's very like um automatic thing to to to do
and i think i had one that actually um bothered me some days now so it seems you're here maybe
can help me clarify it it has to do like if we think if we take like the the we are made to um
to suppress prediction errors in order to survive how come we take drugs and we abuse drugs
see as because they they induce prediction errors so why we do that intentionally
that actually our judgment makes is getting so fuzzy that this is not in our favor
so a challenging and lovely question i'm smiling a little bit because of course it was randy
thought that there was a unifying theory to you it wasn't me that was a title i was given um
i apologize for that i won't i don't take drugs you know i why not
actually i do i smoke don't i so i and i want yes now i want a cigarette um so why do we do that
um i think the the answer um you know it speaks to something which um was in the philosophy of
literature you know a few um years ago which is a dark room problem i think that that you know
there is um and when you think about minimizing your surprise or prediction error in the future
what what does that mean well it the average surprise um or the expected surprise in the
future is called uncertainty so average self-information is called entropy so that just
means the average prediction error is basically uncertainty so what that means is that minimizing
prediction error um in the moment should be distinguished from choosing those behaviors
that are going to minimize the average prediction error after you have committed to a particular
action the kinds of behaviors that do that minimization are exactly those kinds of behaviors
that make us into curious creatures and scientists so it's the epistemic imperatives
that that are responsible for actually guiding our our actions and behavior even though we now
reconfigure and do our structured flows on manifolds to minimize the prediction errors
once we've got the data but in the getting of the data in doing our bungee jumping
and taking your drugs um um you know be the cigarettes or whatever um then you are um compelled
to actually seek out salience and novelty in the service of minimizing expected surprise i.e.
minimizing uncertainty and that that becomes a fundamental understanding the importance of
of doing stuff so this is the inactive aspect of active of active inference which is why i
you know i so picked up on on on rand is you know the special kind of beliefs about the
things we are going to do may be particularly important in terms of defining us as non-cessile
creatures and therefore inherently curious creatures at least when we're young or drug taking
so many thoughts are coming out but i don't want to take over the discussion
but yeah i think it's a kind of uh makes sense the the and at the same time i'm thinking like
evolutionarily do we learn something more like changing our perception changing our
consciousness if you want like we learn something new by that i think we occupy some of these
counterfactual states that we've been discussing because most of the drugs we use are you know
extinct marijuana THC for example is an agonist of one of the brain's most plentiful
neuro receptors so just as we were speaking before about changes in temperature or changes in
pharmacology allow us to explore latent states or the dynamic repertoire or counterfactual states
in an Anil's talk perspective so i know when i take drugs
legal ones like THC you know you do take an alternative perspective there is a slight
dilation or contraction of time there is a you know there's a perspective taking
or that is different so it's probably just what Carl was saying it it decreases your longer term
uncertainty by satisfying or decreasing the latent uncertainty in a state that you can go
and visit and learn about and it's actually very similar to this question that fad yasin has asked
um so fad do you want to ask um mute and ask or do you want me to read out your question
okay i'll read it out then although i just i uh oh great yeah hi am i audible yes
yeah thanks Carl for the lovely talk it did unify a lot of at least my predictions in a
lovely way so you answered my question in many ways in Athena's question about why we would take
drugs if it induces prediction errors but what i want to ask was from a different perspective
like could it be that the systems inside the brain would be competing with itself
like for instance certain areas say like striatum amygdala and all that would have a different
free energy belief that they would like to kind of make survive but other systems like lateral
frontal cortex or say middle orbit of frontal cortex might have a completely different
competitive approach towards that so they're in some ways are generative adversarial networks all
the way and maybe an easier way to say this example would be a little legal way rather than drugs
would be most people when they have some kind of anxiety or depression not in a clinical way
but day to day sense they might open their phone and look at something very novel and very reward
feeling as if the primal brain areas might be wanting to conserve their belief but the other
half of the say cortical neocortical areas might want to go against their belief
i will try and answer that briefly i think it's the kind of question a lot of people here would
like to answer so generative adversarial networks no i personally do not think that's an appropriate
computational science and machine learning metaphor for the brain i think it's much more
like a variational autoencoder having said that you know i won't qualify why i think that's the case
but having said that i do think there's an element of competition in play here in virtue of the fact
that if you commit to the sort of Bayesian gloss on accounting for our sentient behavior
if it's behavior we can only do one thing at a time if we can only do one thing at a time we
have to select among all those hidden repertoire of things we can do that selection is Bayesian
model selection so there's an implicit winner take all like competition in any inference that
leads to an action simply in virtue of the fact that you can only do one thing at any one time
so i certainly think there are going to be competing parts of the brain in terms of
supplying evidence for this hypothesis about what i'm going to do next as opposed to that hypothesis
and one set of competitors will certainly win so i think the notion of competition is you know
absolutely crucial to understanding an inactive inference in the surface of selecting the thing
that i'm actually going to do next and in relation to drugs i'm just mindful you know there are certain
drugs that you could take just to see what would happen if i took this what is it what is it like
to take LSD and that would certainly be sort of consistent with the vanilla epistemic affordance
of taking the drug there are other drugs though that directly direct upon on your own representations
of the stress and uncertainty that the behavior would normally be in play to resolve so certain
drugs of addiction for example would be the sort of poster child children of drugs that get into
the neuromodulatory control of the precision which is just another way of expressing uncertainty so
precision is inverse variance so if you read the representation of uncertainty as being the
representation of precision that's going to have a very very close relationship with the valence of
certain belief states and in that the close relationship between the classical neuromodulators
and valenced and possibly even effective or or emotional states that you can if you like short
circuit your inference just by taking those drugs directly or if you're a lucky mouse doing self
stimulation with with the lectures implanted in the right cells of origin thanks just one
follow-up question if you don't mind why why do you why do you say uh you don't see the brain
as a generative adversarial neural because it implicitly has a discriminator in it right to
choose a select action policies yes yes i i it's just that the the other the physical sorry the
neural anatomical and physiological evidence at hand would suggest a message passing scheme that
doesn't quite have the architecture of of a general adversarial network will have the same
objective as a general adversarial network and it will have the same benefits in terms of
finding the simplest explanation it's just that the architecture it seems to be much more like
a variation autoencoder folded back on itself so you've got the you know the the the compressed
higher or deeper layers of a variation autoencoder can be if you like likened to these cores
described by alex in fact not described by alex's as sort of the global network it says a global
network so somebody i think michael's about hubopathies so it could be deep hubs
so i think this that's the kind of architecture that we're seeing in the wet where the brain
possesses that is evolved by evolution not not sort of right hemisphere left hemisphere trying to
reproduce each other thank you very much interesting okay i'm going to hand back to randy in a moment
but i completely agree kyle with this formulation of say um stimulant drugs in particular just
creating um sort of deep worlds in the free energy valley in the face of boredom boredom
and nui and um you know i worked in the prison for five years and it's like a get to get back to
culture it's like a cultural dark room much much worse than a perceptual dark room the sort of lack
of um cultural variability and the lack of counterfactual spaces are um i guess why we put
people in prison because um you know they're terrible places and they're places where
stimulant drugs are used in copious quantities brought in by you know many many routes into
the prison so um anyway with those vague wanderings randy has his hand up and um i'll allow you and
randy to have the last words for the conference oh thank you uh first of all congratulations carl
i'm i'm holding on to the the title of the talk i gave you and actually doing a very good job of
of uh satisfying its its intentions so and i apologize for the questions that were
criticizing you for trying to even do that so you know there's always a risk randy before you go on
i can sense um i don't think we're gonna have time for a sort of a round table with the audience
about what we got right and got wrong but i i just personally on behalf of the attendees just wanted
to thank you and your team um for for putting this together you know it's really so you know for
those people we can't clap and we can't we can't say it out now because there's too many of us but
on behalf of everybody thank you so much it's been brilliant now um i will i will do closing
arguments but i think it's been a remarkable success given the challenges of this current
situation and then we've managed to at least capture some of the souls for your inclusivity
and i should finish my chairing of the day by thanking the organizers and thanking tanya
and thanking all of the presenters including thank you carl for your lovely last talk
and um thank all six presenters today including alex for jumping in at last moment so um thank
you and thank you to the participants for the day okay then i want to ask a question
well you just you just closed the session so i guess no i'll just shrink into the background
now you asked carl your question and that can be the um dialogue all right all right it's it's it's
i think it's a brief question but it's actually uh kind of thinking about the next steps in terms
of what we want to try and achieve as a as a collective and the notion of trying to um merge
the different scales over which um we exist and one of that whether that can be done in the framework
you put forward carl because one of the challenges i've encountered in thinking about um multi-scale
causation for example and viktor and i talked about a lot as well um how to link up uh
the you know the interactions between different parts of the brain and then you think about that
embedded in the body again and in terms of this it's cultural um social cultural context as well
each of those can be characterized within your framework and then the notion is is that just
simply extending the hierarchy and if that happens then do you sort of lose something again in terms
