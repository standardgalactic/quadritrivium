and a stimuli, sequence of stimuli.
Right, so how sensitive is this to noise?
It's a good question.
There is certainly a threshold of noise
that can tolerate automatically up to the point
where top K are not changed, for example.
So if the top K itself, let's say, is an approximate top K,
I expect that we should get very similar inspirations
in terms of theorems, but actual theorems,
but it's not proven yet.
So the noise sensitivity of this whole setup
is to be established.
Okay, so in the rest of the talk,
we'll get to sort of higher level things
that you might hope for from this learning course,
sequences of inputs,
which seems to be a very fundamental thing for the brain,
and then giving up control.
Control commands that say inhibit an area,
or inhibit this pair of areas and so on.
And finally, moving away from G and P,
from this complete random graph assumption,
we know the brain has geometry,
and what about it?
And also mention language.
Okay, so how do brains learn?
Well, this is a very important problem for neuroscience,
also for this model.
And the only rules we have are plasticity.
So that's it.
It's just local.
Plasticity is the only change in what's happening.
And so there isn't much evidence
that there's gradient descent going on,
even though it's super successful in machine learning.
And so the natural question is,
is synaptic plasticity an actual effective learning mechanism?
Okay.
So as a first step to demonstrate non-trivial learning,
you can ask, suppose,
so we know that the assembly projection,
you know, projection is effective,
but can it create higher level assemblies
that represent a class of stimuli,
rather than one per stimulus?
So for example, if you draw inputs from a distribution,
can you have one assembly created to represent the distribution,
and then another for a different distribution
that's sufficiently different,
so that when you get something from this distribution,
you get assembly one.
When you get from the second distribution,
you get assembly two, right?
So it's a higher level assembly, but representing the class.
And so the answer is yes.
You know, after you define this stimulus classes properly.
So one definition for which,
now this is the definition of inputs and classes,
not of the brain model.
The definition is just that, suppose you have stimuli,
which let's think of stimuli as zero-one vectors,
you know, sensory vectors,
and two different classes have two different base subsets of neurons
that they're anchor subsets, if you like,
that have very little overlap,
and then the rest of the neurons can fire randomly with some probability.
So half of their weight comes from the base anchor set of neurons,
and then the other half is spread out randomly over the rest.
So if you look at these distributions,
they look focused on these case subsets and spread out randomly.
So they're pretty different from each other.
But any two stimuli are quite different from each other, too.
And now if you present these,
it turns out it forms a higher level assembly for each stimulus class
after a small number of presentations.
So, yeah, what I'm doing here is summarizing the theorems,
and then we'll go over the simulation.
I think we'll have time for that.
Okay, what about a more classical learning theory problem
of learning a half-space or a linear threshold function?
So let's say there is a half-space, so there's an unknown vector v,
so a linear threshold,
and what we're going to do is pick Bernoulli input vectors.
We'll just present five examples that are one side of the threshold
and five from the other side,
or actually we can just do it with one side and the rest.
So it really looks like that.
There is a margin. We're assuming there's a margin.
And then here's what happens.
So this matrix is representing the overlap of two stimuli, right,
as zero-one vectors, the inner product,
from the same class and between classes.
So, of course, it's actually almost all looks random
because there's only one direction in which they are separated.
Okay, and that's a random direction in this example, in the experiment.
So if I look at two random vectors and I look at what their overlap is,
yeah, it's very high, okay, in their plus-minus-one vectors.
On the other hand, after you present these five examples
and create this assembly,
and now you ask what's the overlap of the assembly in the brain area,
the firing activity, then it becomes much more focused within versus across.
And so these firing activities are for the assembly that's formed after five examples.
There is some overlap, certainly,
but it's much smaller than in the input neurons.
So this is what I mean by creating an assembly.
So the overlap is preserved, and this is the theorem for this model.
For under this model of the input, presenting these inputs to this model
that you know exactly the entire setup of,
you will create these two assemblies that have very little overlap,
and therefore classification is easy.
If I give you a new example from the positive, this is the assembly that will fire.
Okay, now let's go to sequences.
You're welcome to keep interrupting.
We'll just stop at noon.
Memorizing and learning sequences seems to be very fundamental and natural to brains.
You know, on a computer, what's the big difference?
Sequence, table, whatever.
But here it's, yes.
Actually, we need crucially that the examples come from,
that's the only label information we're getting.
Everything on one side, you get five examples from the positive side,
and then you get five from the negative side.
Yes, yeah, just the label.
The label has to, yeah.
If I do random, then I don't get a chance to form an assembly.
But if I see a few together, that's enough to form an assembly.
And then from then on, you're okay.
Yeah, because otherwise it looks like an unsupervised problem,
but there is actually label information because of the sequence here.
Okay, but this is, I'm not talking about a different kind of sequence.
You know, I mean anybody who's learned to say A, B, C, D,
you learn it to a tune and much easier.
Whatever we do, we seem to have some kind of mnemonic or a story,
a location, a map, whatever.
Now, assembly sequences, sequences of assemblies are observed
in experiments with various mammals.
This experiment from Busaki's lab, they have these animals
running around this structure and not only do,
and they have to do complicated, you know, non-trivial decisions
at various points to get their rewards and avoid the penalty.
So there's a sequence of assemblies that are created.
And very interestingly, after the animal is trained,
before, as it enters the arena, it pre-placed the sequence
before it starts executing the task.
So, yeah, there's also pre-play.
This has been replicated in modified settings.
Okay, so how do I pose this as a problem for the assembly model?
Here's the simplest sequence problem.
I present not one stimulus, but a sequence of similes.
A, B, C, D, E, and maybe a few times.
A, B, C, D, E, A, B, C, D, E.
And this should create assemblies first of all.
1 for A, 1 for B, 1 for C, 1 for D, 1 for E, sure.
But then, what we also like is if I now fire A,
the assembly for A fires, sure, but it also leads to firing B, C, D, E,
even though I didn't present those.
It triggers the rest of the sequence.
And not only A, if you give me something in the middle,
it should trigger the suffix, the rest of it.
Okay, we'll try it soon.
The theorem is, yes, it does.
And you need log-in presentations to guarantee that it does.
Or at least we can prove that with log-in presentations, it will happen without problem.
Yes, that's a good question in general.
If I have two input, let's say sensory stimuli that have large overlap,
then the projected assemblies also have large overlap.
And it applies also to sequences.
Turns out the overlap just depends on the overlap in the sensory areas.
So not where they are in the sequence.
Yeah, this is single sequences so far.
Okay, now why are sequences fundamental?
Why are they interesting?
Well, there's powerful consequences besides the fact that they're a very human or natural thing.
The first thing is that you can then go to finite state automata.
So, I mean, finite state automata are fantastic.
That's an algorithm.
Every algorithm is in finite state automaton plus memory, plus state.
Just telling you, if you're in this state and you're seeing this input,
you should take this action or produce this.
That's an algorithm.
Or any algorithm is that.
And what we can do now is basically take a finite state machine,
memorize each arc as a short sequence.
You've got a whole set of sequences.
And then just run the machine in the brain model.
I'll show you this.
And in fact, once we do this, we will not need any more control commands.
All we'll need is, yeah, you'll see.
Okay, so both finite state machines and Turing machines will operate without control commands.
What we use are what are called long range interneurons.
So previously we had neurons suppressing activity within an area.
Long range interneurons will be used.
So when they are activated, they will suppress an entire area.
But they are set up already, a priori in the hardware.
There are long range interneurons between area A and area C,
between area whatever.
That's your substrate.
So the way we'll simulate a state machine, these are supposed to be states and transitions,
is that there will be areas for symbols, symbols like stimuli,
areas for states, and areas for transitions or arcs.
