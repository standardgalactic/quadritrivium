That's supposed to be k neurons.
And that results in some top k neurons on the right firing, presumably the ones that have the highest connectivity to that subset.
And now, what happens in the next step is that the input, the sensory area neurons are still firing.
You're still smelling something.
And meanwhile, these k also are firing.
Now, what's the next top k?
Doesn't have to be the same one, right?
So there's some other top k.
And this fires now, and there's some other top k.
And you've got this process.
The question is, will this process lead to any kind of convergence?
So the sensory area is still firing.
You're smelling the same thing consistently.
You have a top k, top k, top k, top k.
Is it going to converge?
The stimulus for now, let's say, is held.
Because top k depends on the previous top k.
The top k is sensing not only the stimulus, but also itself.
There are recurrent connections here.
The k neurons that have the highest total weighted input from the previous round.
Yes, from one step to the next step, if i fires, then j fires right after ij connection will be strengthened.
That's the rule, yes.
You would expect that, OK, the first cap had the highest input from there.
They have the advantage.
And now, if somebody inside also got more from this top k, which is just a random graph,
maybe there should be some small fraction at least that has this advantage.
But then, yeah, I don't want to go back to the big bang, but let's just say there's some current activity.
But the introduction of a stimulus is a huge change to the system.
Because the total firing activity is going from k to 2k, specific one.
For example, to me, that's as good an assumption as it is.
So here's what we can prove about this.
The projection process converges exponentially in a wide range of parameters.
I'm not playing with high probability.
The high probability is only over the initial random graph.
Everything else is deterministic.
It's just the original connect home that's random.
And what does convergence even mean?
It's not going to be the case that you will just get to one subset k that keeps firing.
That's actually false almost always.
What instead will happen, what we'll be able to show, is that the total support,
meaning you fire k and the next time there's another subset, another subset,
if you look at how many total neurons were activated,
not counting the ones that are repeatedly activated,
then that total is only a little bit more than k.
It's k plus little o of k, that's the number that vanishes as a fraction of k.
As long as the plasticity is more than a certain threshold.
So if the plasticity is above a threshold,
you converge with very few additional neurons fired.
And if for any positive plasticity there is convergence,
but you'll see a much larger number of neurons touched in the process.
And the threshold that's provably valid is basically a constant
over something that depends on the density.
So pk is the expected degree, right?
Because there are k neurons firing, p is the probability of an edge,
pk is the expected degree to the firing set.
And as long as pk is bigger than this logarithm, this is a constant,
so we're talking about a constant overall.
So this one, these are both upper bounds.
So it's no more than this and no more than this.
But when beta is less than the plasticity,
you see this number is bigger than this number, right?
At least one very interesting question you're asking,
which is, is there a sharp threshold here?
And that's a question that I'm going to put at the end of my slide too.
Is there a sharp threshold, does the plasticity parameter
give you a sharp threshold for the creation of these stable assemblies?
I do think that if beta goes, and that shouldn't be too hard to prove,
sufficiently smaller than this, maybe by even just a large constant factor,
then it will, the number of neurons you touch does go up.
So the convergence just is in terms of the total number of neurons
that are activated at any point in time in this process.
So the process is there's k sensory neurons that are being fired,
and then the top k are going around.
Every time you do top k, potentially if I do t steps,
there could be k times t neurons touched.
But this is saying no, because of plasticity,
as long as the plasticity is greater than a certain threshold,
the total number of neurons that will fire is actually k plus a tiny bit more.
Yes?
N is the number of neurons in the area, which is typically much larger than k.
No, no, but what, no, no, beta equal to 0 is not obvious.
What happens at beta equal to 0 is that the number of neurons becomes,
and this is not hard to show, at least the polynomial in N,
N to the, like, you start hitting, you know, even if, yeah,
you start hitting a large number of neurons, yeah, good.
Okay, so that's the first step, right?
Very basic thing, creation of memories.
Okay, so this is, assemblies are created,
and now what are these doing?
So it takes about a dozen steps, and these are plots here,
which are showing you how many neurons actually get activated,
and when you have high enough plasticity, you know, it's very close to the k.
As your plasticity becomes smaller and smaller, this is the plasticity value,
you know, you start seeing more and more neurons touched in the process.
Simulation, this is just simulation.
All of the code is publicly available.
I'll put it up.
For those of you who are curious how such a proof might work,
or you see, it's a little bit, how should I say, non-standard,
in the sense that you can't really apply a general principle from dynamical systems,
come up with a Lyapunov function or some nice potential that converges continuously,
because the fixed point is not a fixed point in any standard sense.
So we have to combine some discrete reasoning with this,
and that's what we do with probability about what we know about the random graph,
or what we can prove about the random graph.
And so what happens at every step, the main thing is that there is a competition
between the previous winners who are at an advantage,
because they had the most input from total input,
and a large population of neurons, and just because the population is large,
the best of these are genuine competitors to who will make it to the cap.
And so there is this competition between previous winners
and a much larger population of, I say, not at an advantage players,
and this balance for high enough plasticity tilts in the favor of the previous winners.
Yeah, and you can establish these thresholds.
So the fraction of previous winners that survive as winners
just keeps increasing exponentially fast.
Or the fraction of new winners decreases exponentially fast.
So that's the proof.
I'm happy to maybe save this for discussion later.
Now here's the first property to get out of these assemblies.
First thing is recall, which means that if you five present in the future
the same stimulus which created the assembly in the first place,
then I don't need to wait for these iterations.
It immediately fires the assembly that was created,
because now there's recurrence.
One fire, boom, that's the one that gets lit up.
What about firing only a subset?
This is one of these really nice properties of Hopfield nets,
and this we get this.
In particular, for any epsilon that you can choose up front,
if you present the stimulus sufficiently many times,
you could have stopped when the assembly was, let's say, stabilized,
but go a little bit further, present a few more times, rehearse.
Then igniting an epsilon fraction of the assembly
completes to the whole thing very fast,
just because within the assembly the weights of these connections
will go up with each presentation.
So this is the benefit of recurrent connections.
You don't have this in insects, but you have it in mice.
The next one is association.
If I have two stimuli that are firing, that are co-firing,
and they already have assemblies in here for them,
maybe you learn them separately,
over time their overlap increases.
The number of neurons that are actually in both increases.
There is this experiment that was for us very useful.
It came out around the time, started working on this,
I saw it at all, where they did this on a population of epileptic, yes.
So this is what happened in the experiment.
They were recording from several hundred neurons,
I think about 600 or neurons,
and in the empty of the medial temporal lobe,
and they first presented familiar, well-known places,
and recorded from 10 to 20 neurons they could see
consistently firing for specific images.
And then well-known people,
and also they saw activity and very little overlap.
And then they did this interesting thing
where they are superimposed and presented those.
Okay, fine.
And then presented just the place again.
So they deliberately created this association
between two existing assemblies.
And guess what happened?
Some of the neurons that were previously firing,
only for Obama, also started firing for iPhone.
So there was an actual increase in association
that they noticed from this experiment.
And this is a provable outcome in this model.
It's a theorem in the model that if you do this together,
you will actually increase this.
There are more complicated operations
where you build hierarchies of assemblies using merge.
And so let's just recap.
Here are a few operations.
And now for now, I'm saying there are also a few control commands,
which is something I promise shouldn't be there,
but let's say for now there are,
where you can say activate an assembly,
disinhibit an area like you were asking,
meaning that area is not allowed to,
you can't have activity going into that area,
you know, you cut off and so on.
Okay.
For the moment, using these control commands
and the set of operations that naturally run,
there's no special program for them,
you could ask how powerful is the system?
What can you actually, what computations can you execute?
And the answer is it can perform arbitrary computation,
anything that you can do on a Turing machine.
Using square root and space,
you can do in this model with half a dozen areas
and n neurons per area.
Okay, so that's the general,
that's what we mean by a completeness theorem.
By the end of the talk, I'll show you
that we don't need any control commands,
that everything will be just done using a hardware setup,
which is these brain areas and a random graph,
