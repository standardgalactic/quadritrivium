This is a really exciting framework on the assembly hypothesis.
We'll be hearing about it from Santosh Rampala who's really been pioneering this work for the past,
maybe six, seven years is how long you've been working on it.
And hopefully, every time, so I've seen different iterations of this talk over the last two or three years,
and every time Santosh has a new exciting demo that it makes you really wonder how something so complicated comes out of a really simple model.
Looking forward to hearing what Santosh has been working on recently.
Thanks.
Great.
The talk is a hypothesis, right?
So I'm looking for counter examples and suggestions to build an actual theory.
Yes, I have the word emergent there. I know that's a little controversial, but you'll see what exactly we mean.
Please interrupt lots of questions. It's meant to be a complete model of the brain, so that should already be controversial.
But mathematical, so of course it's a toy model and completely rigorous.
So every detail is specified.
So before that, let me step back a little bit and ask what is computation.
Take a minute to do this.
And I mean something extremely general.
It's just a well-defined sequence of state changes, perhaps with purpose.
That's in brackets, but the state and the change of state.
And so what is a state?
State could be memory content, input, output.
That's your state.
And then there is the Church-Turing thesis, which says that anything computable can be computed by a Turing machine.
It's worthwhile remembering.
Again, this is the model.
It's a thesis, not a theorem.
But it's been very, very useful and powerful.
And Turing machine, maybe we'll discuss a little bit later, it's just a finite state machine plus a tape where you can store stuff along the way.
Now, the idea is computation is universal.
We think of planetary systems as computing their next positions in time.
Weather is computational.
The temperature and pressure right here is something tomorrow, maybe outside, more interesting.
And it will be computed by nature, by change of state.
Changes of state.
Metabolic networks in your body and colonies and of course brains.
At this point, it's completely clear that the brain is a computational system.
Now, here is my, I'm presenting this slide not because I'm a neuroscientist, far from it, but because this, it's useful perhaps for you to know my view of the brain.
So the next model is passable.
So the brain, a network of 80 billion neurons, 1,000 to 10,000 connections.
These connections synapses are directed and have strengths.
Some, they may be new ones and they might, they might disappear.
And then individual neurons spike or fire based on rules that are nonlinear.
And a very common model is a threshold of weighted input, but there are more than a thousand different types.
And these firing, these signals have temporal aspects with rates and patterns.
So that's the, that's the completely, this, this is the nugget from, yeah, neuro.
And the question we're going to be, I should say naive enough to ask is how does the mind, the perception, you know, perception, cognition, higher level thought emerge from the brain,
which we think of as a substrate with neurons and synapses, as we just mentioned on the previous slide.
So just to emphasize again, this is an exciting time to be in this field, as it has been for the past 50 years.
Despite the great accelerating progress and lots of insight that keeps on coming, there's no overarching theory.
It's not like physics or, you know, there is, there is, there is a theory, even if it may not be complete,
and even if it's yet to be tested or there is evolution in biology.
Here in the brain, there isn't really much of a theory.
And so there is this gap, and this quote from about five years ago now was, continues to be a great inspiration for, for us.
So Axel said, we do not have a logic for the transformation of neural activity into thought,
and I view discerning this logic as the most important future direction of neuroscience.
Okay, so what kind of logic would qualify?
You know, what kind of formal theory would, would be reasonable?
Going back a little bit, there are things like Hopfield nets that are specific to, for specific tasks, with very nice properties.
Back in 95, there was a less valiant who also proposed PAC learning, came up with the Neuroidal model,
which is, is, is very interesting and allows for extremely general operations,
such as state changes on individual neurons, individual synapses, in order to capture computation.
So what are we looking for?
We're looking for a computational system that's consistent with our understanding of the brain,
may not capture every aspect, but it should not directly contradict some basic feature.
It explains cognitive phenomena, and then the question is, what are its basic data types and what are its operations?
Okay, so we have to ask, then, what's the right level to think about this?
There's the whole brain, there's neurons and synapses that we can understand in detail, dendrites, molecules,
there's interesting things happening at all these levels, but maybe something intermediate.
And so here's the, the, the, where we're going to take this, we'll call it NEMO, Neural Model.
It's a formal probabilistic model of the brain.
There's one basic data type, just one, right, and a few elementary operations, a handful.
There's a completeness theorem about what can be computed using this,
what, what, what kind of things can be produced, and what you might call a killer app.
So there's a bunch of papers, I'll just, we don't need to read them now, but there's a building theory.
Okay, there's one mathematical background slide I want to put up.
Forgive me if you're already very familiar with it, and that's the notion of a random graph.
So the, the stand, the classical model is the Erdos-Renyi random graph, which is a graph on N vertices,
and every pair is connected by an edge independently with probability p.
So you toss a coin of probability p, if it comes up heads, you put in an edge, otherwise no edge.
That's the model.
I mean, no graph in nature actually behaves like this, but it's a fantastic model for almost anything.
So zero would be an empty graph, one would be the complete graph for clique,
and this model has lots of very nice structure.
For example, you might expect that the maximum degree is concentrated near whatever its expectation is, it is,
but so is the size of the largest clique in the graph.
And as p increases from zero to one, and this is a more surprising property, any edge monotone property,
so a property that once true remains true upon adding edges.
So for example, is the graph Hamiltonian.
If you, if, if, maybe it's not, at some point when you add edges, it becomes Hamiltonian,
and then it will stay Hamiltonian if you keep adding edges, right?
A property that's not monotone will be planarity.
Is the graph planar, you add edges, you might break it.
Any edge monotone property has a sharp threshold, meaning there will be a narrow interval with less than any constant
of probabilities within which this property will go from being true with probability zero to bring true with probability one.
For example, the graph being connected, the existence of a matching, a perfect matching, let's say, or a Hamilton cycle, etc.
We will look at the directed version of this where every pair that, you know, the pairs are ordered,
and the edge from i to j is present with probability p, and j to i might also be present with probability p independently.
So this is a simple unrealistic model of a network, but it's going to be very useful, and we can think of it as a model for the connectome.
Yeah, so this, this, the, the classical model is undirected.
We will also use, we will also use the directed model.
In fact, for the brain, this will be the more relevant one, because as you know synapses are directed.
So in the next two slides, I'll give you the complete model, okay, and then we'll see what, what comes out of it.
Okay, so we think of the brain as a finite number of brain areas.
Finite means a small number, a dozen, half a dozen, brain areas, okay.
This is conceptual, right, doesn't have to be a physical thing, this is about organization.
Each one contains n neurons, n is a parameter.
They could have different numbers, but for the purpose of this model and for everything we've derived so far, we can assume they all have the same number, n.
In each area, so each of these regions is supposed to be a brain area, in each area, only k or the n neurons are allowed to fire.
k is going to be something much smaller than n, and only k or the n neurons are going to be allowed to fire, okay.
This is a sort of a version of plastic, of inhibition.
Some pairs of areas are connected, maybe not all pairs, and they might be directed.
For example, this area is connected to this area only in this direction, that area is connected by directed, so on.
And all areas are recurrently connected.
Everywhere will use edge probability p. Again, this could be different, there could be denser areas and less dense areas,
but let's just say within each area there's probability p of connection from one area to another area, if there are connections, every pair is connected with probability p.
So there's only two parameters, n, p, and the number of areas here, okay.
That's part one. Now what about the activity, the dynamics?
We'll assume that there's discrete time, simplicity, so there's some clock.
Neurons will fire only in these discrete steps, and which ones fire?
At each step, it's the k neurons with the highest input from the previous step, highest weighted input.
So the synapses are also weighted, they're weights, which we assume are non-negative.
And the highest total weighted input, the top k, will fire.
Now connections between areas, so from area one to area two, even though they exist, could be inhibited.
Like this connections are not allowed, nobody feels the firing activity there, or disinhibited, meaning you do feel.
There is no geometry at the moment, this is just a topological setup.
It's a metagraph that's telling you which areas are connected.
So we abstracted that away and just said that only k neurons in each area are allowed to fire, that's by inhibition.
So there is, if you like, for each area there's a population of inhibitory neurons that makes sure that at most k are firing.
How is that? Because the activity of these will stimulate the inhibitory neurons, which will then suppress the firing activity and it will stabilize to k.
At the moment, yeah, k is the same, it could be different, but we'll just assume n, k, p are just same across.
It's just population control, so each area has its own population of inhibitory neurons, which are randomly connected.
And this population of neurons, as you know, inhibitory neurons integrate faster than excited neurons, and this control actually happens very fast in a wide range of sizes.
k, every second k are firing within each area.
Great, now the second aspect of dynamics, so this is firing, the second aspect of dynamics is the weight change, plasticity.
And we'll assume the simplest form of Hebbian plasticity, which is that if neuron i fires and followed by neuron j firing in the next step,
then the connection from i to j is strengthened by a multiplicative factor of 1 plus beta, beta is a fixed plasticity rate, again same across everything.
i fires, then j fires, this connection increases by 1 plus beta.
That's it, and other things, you know, homeostasis is just to make sure that the weights don't go, because everything is non-negative, abstract away.
So every once in a while, each neuron will normalize all its input weights back down to 1, say.
Yes, no, it can happen very infrequently, we just don't want things to go off to infinity.
No, this is the complete model, I have not left out any detail, this is it.
No hidden hyperparameters, no cleverness in the training, every synapse has plasticity, every synapse has plasticity and the same plasticity.
Because we have made time discrete, that's an assumption of the model, time has some clock.
Oh, you know, I mean, is time discrete or not, I mean, I don't know, I mean, it just depends how fine you make it.
Yes, it is, one would like, I don't know, is time discrete or continuous?
In the model, it's discrete, it can be whatever scale it is, but it's discrete.
In reality, I don't know, maybe we have a real physicist here, but...
As far as the model is concerned, forget about inhibition, in each area out of the N, exactly K-fire, that's it.
And then there's a story about why that's realistic, and the story says that you can achieve K out of N-firing by using a population of inhibitory neurons for each area.
That's a back story of why this model is realistic.
How realistic is this? Well, it's reasonably so, because it's a completely precise model.
The discrete step assumption, as somebody asked, is unrealistic for multiple reasons, but hopefully it's not distortive.
We still get something useful.
Plasticity assemblies are used in this model in a rapid time scale, which is true for some aspects of brain activity,
but there's also plasticity at slower time scales, and so on, which is not incorporated.
And so hopefully this is a useful compromise between reality and usefulness, without contradicting some important thing from neuroscience.
But then the question is, will computation and learning emerge from these rules, which don't seem to have anything to do with it, without having to be programmed?
That's the point.
So what is the basic data type? Larger than a neuron, smaller than the brain.
And so the basic data type is something that neuroscientists have proposed for a long time.
It's an assembly of neurons.
And what is an assembly? It's going to be a large and densely interconnected, so more dense than the base density of synapses.
And the point is that this subset has the following interpretation.
Its firing is equivalent to recall of a particular concept.
So there will be an assembly for a person, an assembly for this room, an assembly for this course, every concept, everything that's stored in your memory is an assembly.
So this subset, when it fires, it means you're thinking of a panda, or maybe a specific panda, whatever, that could be different.
Boussaki calls the assemblies the alphabet of the brain, but we're calling it a data type.
He's not a computer scientist.
So what is the assembly hypothesis?
There is an intermediate level of brain computation for, let's say, the assembly calculus.
That's going to be implicated in higher cognitive functions, reasoning, planning, language, etc.
And assemblies of neurons are its basic representation, the data type that's doing this.
So then I have to tell you what are the operations?
And again, the operations should happen by themselves, but what are these operations that we can capture?
Remember, we didn't have anything called assembly in the model I told you.
They have to emerge.
Even the assemblies themselves have to come out somehow, we'll see.
But operations on them also have to come out somehow.
Project, which just means, let's think of some of the areas as sensory areas where the neurons that fire in the sensory area are due to external stimulus.
Maybe odor receptors, maybe things in your visual field, so on.
So that's happening because you smell something.
And that projects to a different area, a higher brain area.
And projection just means that this activity in the sensory area is creating a representation,
meaning an assembly in a different brain area, a copy of itself, if you like, we'll call that projection.
Which later, when you smell again, this will fire again.
Associate, which is this operation of things that co-occur, start increasing their overlap.
And therefore, when you think of two things that seem to co-occur, seeing one or sensing one ignites memories of the other, or fires the other assembly.
Pattern complete.
Seeing a part of an assembly allows you to see the whole thing.
Merge.
Assemblies can be hierarchical.
There's no reason for them to be flat.
You have an assembly for woods whole and for neuroscience.
And you think of, oh, the summer school, and so on.
And a few control commands we'll discuss in more detail.
So here's what projection looks like.
This is an advanced simulation, so please focus.
On the left, you have a sensory area.
And on the right, you have a brain area, some other brain area.
And so here, you have an assembly firing.
