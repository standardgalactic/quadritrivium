I would like to introduce you to the viewers as a professor of neural
science at the University College of London. And you've made substantial theoretical contributions
to neurobiology, including the free energy principle. And you're a fellow of the Academy of
Medical Science, past president of the International Organization of Human Brain Mapping, fellow of
the Royal Society of Biology, Weldon Memorial Prize and Medal for contributions to mathematical
biology. Honor a doctorate, including one from the University of Zurich. I have to say that's
quite impressive CV that you have there. So I think I'd like to start with a few preliminary
questions. And it really is how, in your view, as a preeminent neuroscientist, view the early
and late childhood reading as creating models or frameworks of images of concepts of ideas,
is that something that you have worked into your theory?
In a general way, absolutely. If you cast our job as neonates, as infants, as building models
of the lived world, and our lived world comprises other creatures like us, and in particular when
we're very young, mum and dad and siblings and the like, then it becomes imperative to understand
a world that is encultured. And by that, I mean things that come along, constructs that
shape that world and make it sensible in the sense of making sense of the world. And language is
probably the post child of that thing that has to be learned, has to be instilled in your model
of the world. And in particular, making sense of dadic interactions right from birth. First
law is sorting out whether your mum is me, or I am somehow different from mother, am I in control
of mother, developing a sense of self. So the act of inferring that mother is somehow separate
from me, another creature like me, but not me, depends upon all sorts of communication, initially
a fit of touch. But within months, we now have the machinery of language. And that machinery
really does fast track that model learning, that sort of building apt constructs and models
that you can predict what's going to happen next. And indeed, of course, predict what you're going
to do next, what you're saying next, inferring your intentions, your propositional stances and
the like. So language then, you know, you just look at a school curriculum from the start,
plays a really central role in scaffolding that model learning, that structural learning,
that model building. You know, language is a fascinating terrain. And of course,
it goes from writing to printing to the current internet way of which language and images combined
on screens. And so I think there's been quite a different approach and understanding of language
and accessibility to language. And has that had any impact in terms of just the way our brains
now generate models of reality? Is that substantially different than before the invention of the
printing press? Go back to the ancient Greeks, where it was all oral storytelling.
That's a really interesting question. So I'm just thinking my mind. So from my point of view,
your language is the vehicle that provides a structure to the narratives that we bring to
the table to understand what's happening on the outside of our brains, beyond our skulls.
And what you're effectively asking is, is the written word, is that point of reference,
that consolidation, that crystallization of the cues and the structure instrumental in
disseminating and improving the learnability of these narratives? I think so, absolutely, yes.
Yes, I hadn't really thought about that, but it'd be fascinating to model that,
you know, because language prior to the written word only lives in my head and your head,
but once it gets out to the public's third world, there's a reference and a continuity there
that I would imagine would be best seen as something that is sort of self-selecting in
terms of hierarchical co-evolution that enhances the learnability of language. The learnability
of language in and of itself enhances the learnability of your generative models and your
inference and your making sense, making sense of the world. So yeah, so in a sense of talking about
communication as a heart of the language, we really have to, I guess, look at the medium
in which the communication has occurred, because the, to use Marshall McLuhan, the medium may be
the message that the way we construct our models will depend very much on the boundaries of that
medium, the amplification of that medium, and the way that we can use it for our purposes
and purposes of the community. Yeah, I mean, that speaks this notion or a notion of a shared
narrative. If I'm using my model of the world to understand you and make sense of you,
effectively, if I assume that you've got the same kind of model that I'm using,
then our narrative is literally a shared narrative. It's not mine nor yours. It is something that
we're sort of committed to together. So that shared narrative is something that we have to
aspire to and learn together. So it is defined cooperatively, again, in an encultured way.
And the modalities and the shared commitments to the way that we use language, whether it's in
print or indeed, what could even argue that mathematics is a kind of language that only
works because there's a shared commitment to using this modality, these shapes, these kinds of sensory
cues to enable me to infer what you are thinking and what you're going to say next.
The other preliminary thing I wanted to raise is I've been fascinated because I've seen a number
of your interviews, particularly about the Markov blanket, which is probably would take a whole
show just to go through that. And I'll let you introduce what that concept is, but whether
the kind of generative models that we get as a child from our reading experience,
could it be said that those form a kind of Markov blanket? In a sense, it explains to me
cognitive biases. A cognitive bias are the defenses against basically contrary or hostile
images or thoughts or ideals or principles. And so we have a cognitive bias. We have,
for example, confirmation bias. We look for those articles, those books, those peoples that
confirm our beliefs and values. Yeah, no, I think that's an excellent point. Yeah. I mean,
cognitive biases, you could actually read as sort of Bayes' optional biases. So if you subscribe
to the free energy principle that rests upon Markov blankets, you are in the game,
all of us, anything that exists is in the game of securing evidence for our own existence, which
just means evidence for our models of the world. So you're going to seek out confirmation. And
if you're successful in seeking out confirmation evidence that you exist, and you've got a good
model of the world, you exist for longer. So it's an almost tautological truism that what you just
said is absolutely right. One of the things that I heard you say in another interview, and I love
this in the context, particularly of fiction and novels, if you are constantly surprised,
you've had a bad model of the world. So in a way, you can judge the cognitive equipment that a person
has, how it's been shaped by how surprised they are. So I guess the wider your reading is as a child
in many different genres and styles and periods, the less surprised you're going to be when you see
something, because the range of activity that would have to surprise you would be vastly greater.
Yes, no, absolutely. In fact, we actually use measures of surprise as measured by
electrical brain responses from people with autism or schizophrenia. Just to get a physiological
handle on this, you're absolutely right. People do actually use surprise or oddball responses
to sort of phenotype various conditions where people may have difficulty inferring what's going
on around them. But you also bring to the table the breadth of reading the
the different kinds of outcomes and exchanges with your environment, cultured or not,
will certainly shape and be essential in determining the shape of the model that you take forward
into later life. And if you have a model that generalizes to different situations that you can
predict, synthesize in a way that renders it unsurprising when sufficient information has been
secured, then you're certainly going to have a better model that is more context sensitive
and will underwrite a longevity in a changing world or a very context sensitive world.
I'm just wondering where, again, getting back to reading books and fiction in particular,
where imagination and creativity fit into your view of modeling and generating models,
because although you may be surprised, surprise, for example, if you're an improv musician,
is actually a good thing. You can riff off of that so that you, in a sense, you invite the
surprise. And when you're writing fiction, in some ways, you're looking for the surprise,
because that's what the reader wants. The reader is looking to be surprised,
because if it's all predictable, they say the book is boring.
Yeah, another excellent point and a key issue in the philosophy of the free energy principle,
which we rest upon something called the dark room problem, if we just want to minimize surprise,
why don't we go and seclude ourselves in a dark room and stay there forever,
then we'll never be surprised. But that sort of misses the point. If we are curious creatures
that are always compelled to resolve uncertainty, then the resolution of surprise or expected
surprise as a consequence of our actions is going to be one of the primary drives
for surprise minimization. So we have to look for the opportunity to minimize surprise.
So we listen to stories, we watch TV series, we read books, because we know at the end there
will be a denouement, there will be a resolution of uncertainty. And if you read uncertainties,
expected surprise, you know there's going to be a wonderful opportunity for that aha moment
when your mathematical kind of surprise is actually resolved. And I think it's a great
explanation for music, that you set up an uncertainty in terms of the way that this
riff could go or what's going to happen in the next few bars. And then you're compelled to continue
listening, actively listening in order to resolve that uncertainty. But it's a resolution of uncertainty
that drives novelty seeking and curious behavior. And I repeat, if uncertainty is expected surprise,
the resolution of uncertainty is a minimization of this mathematical kind of surprise.
Right. So one of your papers I would certainly recommend that viewers have a look at is neural
science and bio behavioral reviews November 2020 issue. It's a brilliant paper that looks very
closely at the whole notion of generating models and the commitment of the brain as this
constructive organ that we are constructing models and testing them against reality at every stage.
And when somehow the model isn't quite working well, as I understand from the paper,
this then we go into a question and answer. What are we missing in the context of this thing?
Why is it a little bit off? Or is our model off? Do we have to adapt it in order that we see more
clearly the reality that's there? In other words, it's not anything other than we have low
information. And what we're seeking is to increase the level of information so that we have a better
understanding and explanation of what happens next or what may happen next.
Yeah. That is a beautiful summary of the essence of active inference.
Absolutely. And I think it touches on the last exchange in relation to why we are
compelled to be curious. Why are we curious creatures? And it all boils down to this
minimization of a resolution of uncertainty entailed by our current models and states of affairs
in the world. So how do you resolve that? You resolve that uncertainty by gaining information.
How do you do that in the optimal way? Well, you basically respond to epistemic affordances.
You know where to find the right kind of information that's going to resolve your
uncertainty. So you listen to that news channel, you read that author, you go to that Wikipedia
service. So you know what you don't know. And asking questions querying the world
is the optimal way to minimize your uncertainty. So you can actually write this down in terms of
an expected free energy or an expected surprise. And again, I ask you to read
expected surprise of uncertainty minimizing this expected free energy. Following an action,
following a move on the world, inevitably compels you to gain the most information that
resolves your uncertainty about the world. And interestingly, of course, the degree of epistemic
attractiveness or affordance of a particular move, a particular question, a particular query,
the choice of things that you might read depends upon your current belief state. It depends upon
what you know, what you don't know. So of course, you could get bored when you've been foraging
epistemically and there's no more uncertainty. So then you'd move on to move on to something else.
Our work suggests that that sort of epistemic motivation in neuro robotics, for example,
is known as intrinsic motivation. Just what would happen if I did that? Resolving uncertainty
about the way that the world works. That's probably much, much more important than simple
sort of utilitarian pragmatic pairs, like you're being rich, or if you're a monkey,
getting fruit, fruit drops in an experiment. So I think that resolution of uncertainty,
that information gain is underwrites most sentient behavior in systems like, like us.
And, you know, not every system needs this, you know, viruses and thermostats,
wouldn't have this epistemic. But I think at a certain level, when your generative model is
sufficiently deep and prospective, and it has to be in order to cope with living in a world
that is constituted by other things like you that are also very deep and prospective,
you know, then you become equipped with a model that entertains the consequences
of your action. And of course, if you measure the consequences in terms of what matters,
then the only thing that matters is getting down that expected surprise, that expected free energy,
which just is being curious. I'm glad you mentioned the word curious,
because it seems to me that curiosity is not equally distributed. Some people seem to be
far more curious than others, maybe to their Darwinian disadvantage, but there is a range
of curiosity. And I'm wondering if that correlates with creativity and imagination.
Yeah, I'm sure it does. So technically, what I think we are talking about here
is in the cognitive neuroscience is something called structure learning. So we're talking about
the structure of our models. If you're in machine learning, and you're doing deep learning, for
example, how many layers would you have in a hierarchical model? If you're a neurodevelopmental
psychologist, and you want to know what point to different levels in the auditory hierarchy,
or the language system, come online. What we're talking about is building models,
literally by wiring in different components. So you have to know the structure. And of course,
you can't know the structure. All you can do is explore different structures, see whether they're
fit for purpose, see whether they explain the data at hand. But therefore, you have to explore
different models. And I think this is where creativity and imagination comes in. It's the
ability to think about counterfactual structures in the world. What would happen if the world was
like this or like that? You've got these counterfactuals implanted, these differential hypotheses.
You can then use your sensory exchanges with the world or with others or with books to actually
evaluate one model in relation to another, literally using the model evidence, the evidence
of that model inherent in the sensory data. So that's how statisticians and people in machine
learning actually optimise the structure of their models. And I think that's exactly what we do
during neurodevelopment and subsequent experience dependent learning. And what would that look like?
It would look like a creature, a system, an agent who entertains in a very creative way
different compositions, different structures, different constructs that could possibly explain
their world and then testing out the evidence for these different constructs. And if you're an artist,
the way that you might do that is by looking at the reactions of other people or indeed your own
reactions to something that's now out there. It's been realised physically in terms of a story
or in terms of a picture. So imagination would be, if you like, sort of online structure learning
and creativity that allows you just to, on the fly, moment to moment, just consider different
hypotheses about what's going on now, but exactly the same sort of mathematical imperative, I think
underlies the building of the structures themselves during neurodevelopment and during our ongoing
reorganisation of our brains and the concepts that are entailed by that structural learning.
Yeah, counterfactuals are interesting. And I'm wondering if that's something that is taught
along with early childhood reading as well. In a way, you could say Shakespeare may have had a
right is that, you know, all life is a stage and we're all actors on it. And that childhood reading
is a series of scripts in which you see the human drama unfolding in front of you. And by
understanding that, you understanding what's expected of you socially, you understand what are
the boundaries of behaviour, what you can expect from others. So in some ways, it prepares you
to enter society because you don't have to have experience directly, you can experience
indirectly thousands of relationships going back hundreds of years and have a whole
generative model of the human condition from that early reading. So part of it is,
can you teach things like counterfactuals? For example, can you teach your child,
take Hamlet, put him in Waiting for God, take God, put him in Hamlet. How does it change the story?
Yeah, I think that's absolutely right. And he started off that thesis with the notion of scripts.
I think scripts is, you know, a very nice way of thinking about the different kinds of models
that are going to be plausible, going to be allowable when self-modelling. Because the most
