So you don't know a, but you know s, and by observing x,
you get some information about what a is.
So in this case, you're trying to build a model of the
medium through which your signal is propagating.
So sometimes one would call problems of this kind, let's
say system identification.
In a different version of an inference problem that comes
with this picture, you've done your modeling.
You know your a, you know the medium through which the
signal is going, but it's a communication system.
This person is trying to communicate something
to that person.
So you send the signal s, but that person receives a noisy
version of s.
So that person tries to reconstruct s based on x.
So in both cases, we have a linear relation between x and
the unknown quantity.
In one version, a is the unknown, and we know s.
In the other version, a is known, and we try to infer s.
Mathematically, you can see that it's essentially the same
kind of problem in both cases, although the kind of
practical problem that you're trying to solve is a
little different.
So we will not be making any distinctions between problems
of the model building type as opposed to models where you
try to estimate some unknown signal and so on, because
conceptually, the tools that one uses for both types of
problems are essentially the same.
Next, very useful classification of inference problems.
The unknown quantity that you're trying to estimate could
be either a discrete one that takes a small number of
values.
So this could be discrete problems, such as the radar
problem we encountered back a long time ago in this class.
So there's two possibilities.
An airplane is out there, or an airplane is not out there.
And you're trying to make a decision between these two
options, or you can have other problems in which you have,
let's say, four possible options.
You don't know which one is true, but you get data, and
you try to figure out which one is true.
In problems of this kind, usually you want to make a
decision based on your data, and you're interested in the
probability of making a correct decision.
You would like that probability to be as high as possible.
Estimation problems are a little different.
Here you have some continuous quantity that's not known, and
you try to make a good guess of that quantity, and you would
like your guess to be as close as possible to the true
quantity.
So the polling problem was of this type.
There was an unknown fraction f of the population that had
some property, and you try to estimate f as
accurate as you can.
So the distinction here is that usually here the unknown
quantity takes a discrete set of values.
Here the unknown quantity takes a
continuous set of values.
Here we're interested in the probability of error.
Here we're interested in the size of the error.
Broadly speaking, most inference problems fall either in
this category or in that category, although if you
want to complicate life, you can also think or construct
problems where both of these aspects are
simultaneously present.
OK, finally, since we're in classification mode, there's a
very big, important dichotomy into how one goes about
inference problems.
And here there's two fundamentally different
philosophical points of view, which is how do we model the
quantity that is unknown?
In one approach, you say there's a certain quantity that
has a definite value.
It just happens that I don't know it, but it's a number.
There's nothing random about it.
So think of trying to estimate some physical quantity.
Let's say you're making estimates, and you're making
measurements, you try to estimate the mass of an
electron, which is a sort of universal physical constant.
There's nothing random about it.
It's a fixed number.
You get data because you have some measuring apparatus.
And that measuring apparatus, depending on what the results
that you get, do are affected by the true mass of the
electron, but there's also some noise.
You take the data out of your measuring apparatus, and you
try to come up with some estimate of that quantity
theta.
So this is definitely a legitimate picture, but the
important thing in this picture is that this theta is
written as lower case, and that's to make the point that
it's a real number, not a random variable.
There's a different philosophical approach,
which says, well, anything that I don't know, I should
model it as a random variable.
Yes, I know.
The mass of the electron is not really random.
It's a constant, but I don't know what it is.
I have some vague sense, perhaps, what it is, perhaps
because of the experiments that some other people carried out.
So perhaps I have a prior distribution on the possible
values of theta.
And that prior distribution doesn't mean that nature is
random, but it's more of a subjective description of my
subjective beliefs of where do I think this constant number
happens to be.
So even though it's not truly random, I model my initial
beliefs before the experiment starts.
In terms of a prior distribution, I view it as a
random variable.
Then I observe another related random variable through some
measuring apparatus, and then I use this again to create an
estimate.
So these two pictures, philosophically, are very
different from each other.
Here we treat the unknown quantities as unknown numbers.
Here we treat them as random variables.
When we treat them as random variables, then we know pretty
much already what we should be doing.
We should just use the Bayes rule based on x, find the
conditional distribution of theta.
And that's what we will be doing mostly over this lecture
and the next lecture.
Now in both cases, what you end up getting at the end is an
estimate.
But actually, that estimate is what kind of object is it?
It's a random variable in both cases.
Why?
Even in this case, where theta was a constant, my data are
random.
I do my data processing, so I calculate a function of the
data, the data random variables.
So out here, we output something which is a
function of a random variable.
So this quantity here will be also random.
It's affected by the noise in the experiment that I have
been doing.
That's why these estimators will be denoted by upper case
thetas.
And we will be using hats.
Hats usually in estimation means an estimate of something.
All right, so this is the big picture.
We're going to start with the Bayesian version.
And then the last few lectures, we're going to talk about the
non-Bayesian version or the classical one.
By the way, I should say that statisticians have been
debating fiercely for 100 years whether the right way to
approach statistics is to go the classical way or the
Bayesian way.
And there have been tides going back and forth between the
two sides.
These days, Bayesian methods tend to become a little more
popular for various reasons.
We're going to come back to this later.
All right, so in Bayesian estimation, what we got in our
hands is Bayes' rule.
And if you have Bayes' rule, there's not a lot that's left
to do.
We have different forms of the Bayes' rule, depending on
whether we're dealing with discrete data and discrete
quantities to estimate or continuous data and so on.
In the hypothesis testing problem, the unknown quantity
theta is discrete.
So in both cases here, we have a p of theta.
We obtain data, the x's, and on the basis of the x that we
observe, we can calculate the posterior distribution of
theta given the data.
So to apply to use Bayesian inference, what do we start
with?
We start with some priors.
These are our initial beliefs about what theta might be.
That's before we do the experiment.
We have a model of the experimental apparatus.
And the model of the experimental apparatus tells
us, if this theta is true, I'm going to see x's of that kind.
If that other theta is true, I'm going to see x's that are
somewhere else.
That models my apparatus.
And based on that knowledge, once I observe, I have these
two functions in my hands.
We have already seen that if you know those two functions,
you can also calculate the denominator here.
So all these functions are available.
So you can compute, you can find a formula for this
function as well.
And as soon as you observe the data, the x's, you plug in
here the numerical value of those x's.
And you get a function of theta.
And this is the posterior distribution of theta given the
data that you have seen.
So you've already done a fair number of
exercises of this kind.
So let me not say more about this.
And there's a similar formula, as you know, for the case where
we have continuous data.
If the x's are continuous random variable, then the
formula is the same, except that x's are described by
densities instead of being described by
probability mass functions.
OK.
