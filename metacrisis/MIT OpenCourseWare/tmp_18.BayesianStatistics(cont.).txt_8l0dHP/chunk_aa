The following content is provided under a Creative
Commons license.
Your support will help MIT OpenCourseWare
continue to offer high quality educational resources for free.
To make a donation or to view additional materials
from hundreds of MIT courses, visit MIT OpenCourseWare
at ocw.mit.edu.
So today we're going to close this chapter on the short chapter
on Bayesian inference.
Again, this was just an overview of what
you can do in Bayesian inference.
And last time, we started defining
what's called Geoffrey's priors.
So when you do Bayesian inference,
you have to introduce a prior on your parameter.
And we said that usually it's something
that encodes your domain knowledge
about where the parameter could be.
But there's also some principle way
to do it if you want to do Bayesian inference without really
having to think about it.
And for example, one of the natural priors
were those non-informative priors.
If you're on a compact set, it's a uniform prior over this set.
If you're on an infinite set, you can still
think of taking the old ones prior.
And that's called a prior that's always equal to 1.
And that's an improper prior if you're an infinite set
or proportional to 1.
And so another prior you can think of
in the case where you have Fisher information, which
is well-defined, is something called Geoffrey's prior.
And this prior is a prior which is
proportional to square root of the determinant
of the Fisher information matrix.
And if you just have, if you're in one dimension,
it's basically proportional to square root
of the Fisher information coefficient, which we know,
for example, is the asymptotic variance
of the maximum likelihood estimator.
And it turns out that it's basically,
so square root of this thing is basically
1 over the standard deviation of the maximum likelihood
estimator.
And so you can compute this, right?
So you can compute for the maximum likelihood estimator.
We know that the variance is going to be p1 minus p
in the Bernoulli statistical experiment.
So you get this 1 over square root of this thing.
And for example, in the Gaussian setting,
you actually have the Fisher information,
even in the multivariate one is actually
going to be something like the identity matrix.
So this is proportional to 1.
It's the improper prior that you get in this case.
Meaning that for the Gaussian setting,
no place where you center your Gaussian
is actually better than any other.
All right, so we basically left on this slide
where we saw that Geoffrey's prior satisfied
a reparameterization.
They're invariant by transformation
of your parameter, which is a desirable property.
And the way it says that, well, if I have my prior on theta,
and then I suddenly decide that theta is not
the parameter I want to use to parametrize my problem,
actually what I want is phi of theta.
So think, for example, as theta being
the mean of a Gaussian, and phi of theta
as being this mean to the cube.
This is a one to one map phi, right?
So for example, if I want to go from theta to theta cube,
and now I decide that this is the actual parameter that I want,
well, then it means that on this parameter,
my original prior is going to induce another prior.
And here it says, well, this prior is actually also
Geoffrey's prior.
So it's essentially telling you that for this new parametrization,
if you take Geoffrey's prior, then you actually
go back to having exactly something
that's of the form of the determinant
of the Fisher information.
This thing with respect to your new parametrization.
And so why is this true?
Well, it's just this change of variable theorem, right?
So it's essentially telling you that if you call,
let's call pi tilde of eta prior over eta,
and you have pi of theta as the prior over theta,
then just by, since eta is of the form phi of theta,
just by change of variable, right?
So that's essentially a probability result.
It says that pi tilde of eta is equal to pi of eta
times pi of theta times d theta over d eta.
And sorry, is that the one?
Actually, I'm going to have to write it,
because I always forget this.
So if I take a function.
OK, so what I want is to check.
OK, so I want a function of eta that I can put here.
And what I know is that this is h of phi of theta, right?
So sorry, eta is phi of theta, right?
Yeah.
So what I'm going to do is I'm going
to do the change of variable.
Theta is phi inverse of eta.
So eta is phi of theta, which means that d eta is equal to phi
prime of theta d theta.
So when I'm going to write this, I'm
going to get integral of h.
Actually, let me write this as, I'm more comfortable writing
this as e with respect to eta of h of eta, OK?
So that's just eta according to being drawn from the prior.
And I want to write this as the integral of h of eta
times some function, right?
So this is the integral of h of phi of theta pi of theta d theta.
Now I'm going to do my change of variable.
So this is going to be the integral of h of eta.
And then pi of theta is phi inverse of eta.
And then d theta is phi prime of theta d theta, OK?
And so what is pi of phi theta?
So this thing is proportional.
So we're in, say, dimension one.
So it's proportional of square root of the Fisher information.
And the Fisher information we know
is the expectation of the square of the derivative
of the log likelihood, right?
So this is square root of the expectation of d over d theta
of log of, well, now I need the density.
Well, let's just call it log.
Let's call it l of theta.
And I want this to be taken at phi inverse of eta squared.
And then what I pick up is the, so I'm
going to put everything under the square.
So I get phi prime of theta squared d theta, OK?
So now I have the expectation of a square.
This does not depend.
So this is, sorry, this is l of theta.
This is the expectation of l of theta of nx, right?
That's for some variable.
And the expectation here is with respect to x.
That's just the definition of the Fisher information.
So now I'm going to squeeze this guy into the expectation.
It does not depend on x.
It just acts as a constant.
And so what I have now is that this
is actually proportional to the integral of h eta
times the square root of the expectation with respect
to x of what?
Well, here I have d over d theta of log of theta.
And here, this guy is really d eta over d theta, right?
Agreed?
So now what I'm really left by, so I get d over d theta times d,
sorry, times d theta over d eta.
So that's just d over d eta of log of eta x.
And then this guy is now becoming d eta, right?
OK, so this was a mess.
This is a complete mess because I actually want to use phi.
I should not actually introduce phi at all.
I should just talk about d eta over d theta type of things.
And then that would actually make my life so much easier.
OK, I'm not going to spend more time on this.
This is really just the idea, right?
You have square root of a square in there.
And then when you do your change of variable,
you just pick up a square.
You just pick up something in here.
And so you just move this thing in there.
You get a square.
It goes inside the square.
And so your derivative of the log likelihood with respect
to theta becomes the derivative of the log
likelihood with respect to theta.
And that's the only thing that's happening here.
I'm just being super sloppy for some reason.
OK.
And then, of course, now what you're left with
is that this is really just proportional.
Well, this is actually equal.
Everything is proportional, but this
is equal to the Fisher information tilde
with respect to eta now, right?
You're doing this with respect to eta.
And so that's your new prior with respect to eta.
OK, so one thing that you want to do once you have,
so remember, when you actually compute your posterior,
you're right rather than having, so you start with a prior.
And you have some observations, let's say x1 to xn.
When you do Bayesian inference, rather than spitting out
just some theta hat, which is an estimator for theta,
you actually spit out an entire posterior distribution,
pi of theta given x1, xn.
So there's an entire distribution on the candidates theta.
And you can actually use this to perform inference,
rather than just having one number.
And so you could actually build confidence regions
from this thing.
And so a Bayesian confidence interval,
so if your set of parameters is included in the real line,
then you can actually, it's not even
guaranteed to be an interval, so let
