The following content is provided under a Creative
Commons license.
Your support will help MIT OpenCourseWare continue to
offer high-quality educational resources for free.
To make a donation or view additional materials from
hundreds of MIT courses, visit MIT OpenCourseWare at
ocw.mit.edu.
So we're going to finish today our discussion of Bayesian
inference, which we started last time.
As you probably saw, there's not a huge lot of concepts
that we're introducing at this point in terms of specific
skills of calculating probabilities, but rather it's
more of an interpretation and setting up the framework.
So the framework in Bayesian estimation is that there is
some parameter which is not known, but we have a prior
distribution on it.
These are beliefs about what this variable might be.
And then we obtain some measurements, and the
measurements are affected by the value of that parameter
that we don't know.
And this effect, the fact that x is affected by theta, is
captured by introducing conditional probability
distribution.
The distribution of x depends on theta.
It's a conditional probability distribution.
So we have formulas for these two densities, the prior
density and the conditional density.
And given that we have these, if we multiply them, we can
also get the joint density of x and theta.
So we have everything that there is to know in this
setting.
And now we observe the random variable x.
Given this random variable, what can we say about theta?
Well, what we can do is we can always calculate the
conditional distribution of theta, given x.
And now that we have the specific value of x, we can
plot this as a function of theta.
And this is the complete answer to a Bayesian inference
problem.
This posterior distribution captures everything there is
to say about theta.
That's what we know about theta.
Given the x that we have observed, theta is still
random.
It's still unknown.
And it might be here, there, or there, with several
probabilities.
On the other hand, if you want to report a single value for
theta, then you do some extra work.
You continue from here.
And you do some data processing on x.
Doing data processing means that you apply a certain
function on the data.
And this function is something that you design.
It's the so-called estimator.
And once that function is applied, it outputs an
estimate of theta, which we call theta hat.
So this is sort of the big picture of what's happening.
Now, one thing to keep in mind is that even though I'm
writing single letters here, in general, theta or x could be
vector random variables.
So think of this.
It could be a collection theta 1, theta 2, theta 3.
And maybe we obtain several measurements.
So this x is really a vector x1, x2, up to xn.
All right, so now how do we choose a theta to report?
There are various ways of doing it.
One is to look at the posterior distribution and report the
value of theta at which the density or the PMF is highest.
This is called the maximum posteriori
probability estimate.
So we pick a value of theta for which the posterior is
maximum and we report it.
An alternative way is to try to be optimal with respect to a
mean squared error.
So what is this?
If we have a specific estimator, g, this is the
estimate it's going to produce.
This is the true value of theta, so this is our
estimation error.
We look at the square of the estimation error and look at
the average value.
We would like this squared estimation error to be as
small as possible.
How can we design our estimator g to make that error as
small as possible?
It turns out that the answer is to produce as an estimate the
conditional expectation of theta given x.
So the conditional expectation is the best estimate that you
could produce if your objective is to keep the mean
squared error as small as possible.
So this statement here is a statement of what happens on
the average over all thetas and all x's that may happen in
our experiment.
Actually, the conditional expectation as an estimator
has an even stronger property.
Not only it's optimal on the average, but it's also optimal
given that you have made a specific observation.
No matter what you observe, let's say you observe the
specific value for the random variable x.
After that point, if you're asked to produce a best
estimate theta hat that minimizes this mean squared
error, your best estimate would be the conditional
expectation given the specific value that you have observed.
These two statements say almost the same thing, but this
one is a bit stronger.
This one tells you no matter what specific x happens, the
conditional expectation is the best estimate.
This one tells you on the average over all x's that
may happen, the conditional expectation is the best
estimator.
Now this is really a consequence of this.
If the conditional expectation is best for any specific x,
then it's the best one even when x is left random and you are
averaging your error over all possible x's.
OK, so now that we know what is the optimal way of
producing an estimate, let's do a simple example to see how
things work out.
So we start with an unknown random variable, theta, which
is uniformly distributed between 4 and 10.
And then we have an observation model that tells us that
given the value of theta, x is going to be a random variable
that ranges between theta minus 1 and theta plus 1.
So think of x as a noisy measurement of theta plus
some noise, which is between minus 1 and plus 1.
So really the model that we are using here is that x is equal
to theta plus u, where u is uniform on minus 1 and plus 1.
So we have the true value of theta, but x could be theta
minus 1, or it could be all the way up to theta plus 1.
And x is uniformly distributed on that interval.
That's the same as saying that u is uniformly distributed
over this interval.
So now we have all the information that we need.
We can construct the joint density.
And the joint density is, of course, the prior density times
the conditional density.
We got both of these.
Both of these are constants.
So the joint density is also going to be a constant, 1, 6
times 1 half.
This is 1 over 12.
But it is a constant, not everywhere, only on the range
of possible x's and theta's.
So theta can take any value between 4 and 10.
So these are the values of theta.
And for any given value of theta, x can take values from
theta minus 1 up to theta plus 1.
So here, if you can imagine a line that goes with slope 1,
and then x can take that value of theta plus or minus 1.
So this object here, this is the set of possible x and
theta pairs.
So the density is equal to 1 over 12 over this set.
And it's 0 everywhere else.
So outside here, the density is 0.
The density only applies at that point.
All right, so now we're asked to estimate theta in terms of
x.
So we want to build an estimator, which is going to be a
function from the x's to the theta's.
That's why I chose the axis this way, x to be on this axis
theta on that axis.
Because the estimator we're building is a function of x.
Based on the observation that we obtained, we want to
estimate theta.
So we know that the optimal estimator is the conditional
expectation given the value of x.
So what is the conditional expectation?
If you fix a particular value of x, let's say in this range,
so this is our x, then what do we know about theta?
We know that theta lies in this range.
Theta can only be somewhere between those two values.
And what kind of distribution does theta have?
What is the conditional distribution of theta given x?
Well, remember how we built conditional distributions from
joint distributions.
The conditional distribution is just a section of the joint
distribution applied to the place where we're conditioning.
So the joint is constant, so the conditional is also going
to be a constant density over this interval.
So the posterior distribution of theta is uniform
over this interval.
So if the posterior of theta is uniform over that interval,
the expected value of theta is going to be the midpoint of
that interval.
So the estimate which you report if you observe that
theta is going to be this particular point here.
It's the midpoint.
The same argument goes through even if you obtain an x
somewhere here.
Given this x, theta can take a value between these two
values.
Theta is going to have a uniform distribution over this
interval.
And the conditional expectation of theta given x is going to
be the midpoint of that interval.
So now if we plot our estimator by tracing midpoints in
this diagram, what you're going to obtain is a curve that
goes, it starts like this.
Then it changes slope so that it keeps track of the midpoint.
And then it goes like that again.
So this blue curve here is our g of x, which is the
conditional expectation of theta given that x is equal to
little x.
So it's a curve because it consists of, in our example,
it consists of three straight segments.
But overall, it's nonlinear.
It's not a single line through this diagram.
And that's how things are in general.
g of x, our optimal estimate, has no reason to be a linear
function of x.
In general, it's going to be some complicated curve.
So how good is our estimate?
I mean, you reported your estimate of theta based on
x, and your boss asks you, what kind of error do you
expect to get?
Having observed a particular value of x, what you can
report to your boss is what you think the mean squared
error is going to be.
We observed a particular value of x.
So we're conditioning, and we're living in this universe.
Given that we have made this observation, this is a true
value of theta.
This is the estimate that we have produced.
This is the expected squared error given that we have made
a particular observation.
Now, in this conditional universe, this is the expected
value of theta given x.
So this is the expected value of this random variable inside
the conditional universe.
So when you take the mean squared of a random variable
minus the expected value, this is the same thing as the
variance of that random variable, except that it's the
variance inside the conditional universe.
Having observed x, theta is still a random variable.
It's distributed according to the posterior
distribution.
Since it's a random variable, it has a variance.
And that variance is our mean squared error.
So this is the variance of the posterior distribution of
theta, given the observation that we have made.
So what is the variance in our example?
If x happens to be here, then theta is uniform over this
interval.
And this interval has length 2.
Theta is uniformly distributed over an
interval of length 2.
This is the posterior distribution of theta.
What is the variance?
Then you remember the formula for the variance of a uniform
random variable.
It is the length of the interval squared divided by 12.
So this is 1 third.
So the variance of theta, the mean squared error, is going
to be 1 third whenever this kind of picture applies.
This picture applies when x is between 5 and 9.
If x is less than 5, then the picture is a little different.
And theta is going to be uniform over a smaller interval.
And so the variance of theta is going
to be smaller as well.
So let's start plotting our mean squared error.
Between 5 and 9, the variance of theta, the posterior
variance, is 1 third.
Now, when x falls in here, theta is uniformly distributed
over a smaller interval.
The size of this interval changes linearly over that
range.
And so when we take the square of that, the square size of
that interval, we get a quadratic function of how
much we have moved from that corner.
So at that corner, what is the variance of theta?
Well, if I observe an x that's equal to 3, then I know
with certainty that theta is equal to 4.
Then, in a very good shape, I know exactly
what theta is going to be.
So the variance, in this case, is going to be 0.
If I observe an x that's a little larger, then theta is
now random, takes values on a little interval.
And the variance of theta is going to be proportional to
the square of the length of that little interval.
So we get a curve that starts rising quadratically from
here and goes up towards 1 third.
At the other end of the picture, the same is true.
If you observe an x which is 11, then theta can only be
equal to 10.
And so the error in theta is equal to 0.
There's zero error variance.
But as we obtain x's that are slightly less than 11, then
the mean squared error again rises quadratically.
So we end up with a plot like this.
What this plot tells us is that certain measurements are
better than others.
If you're lucky and you see x equal to 3, then you're lucky
because you know theta exactly what it is.
If you see an x which is equal to 6, then you're sort of
unlucky because it doesn't tell you theta with great
precision.
Theta could be anywhere on that interval.
And so the variance of theta, even after you have observed
x, is a certain number, 1 third in our case.
So the moral to keep out of that story is that the error
variance, or the mean squared error, depends on what
particular observation you happen to obtain.
Some observations may be very informative.
And once you see a specific number, then you know exactly
what theta is.
Some observations might be less informative.
You observe your x, but it could still leave a lot of
uncertainty about theta.
So conditional expectations are really the cornerstone of
Bayesian estimation.
They're particularly popular, especially in engineering
contexts.
They're used a lot in signal processing, in
communications, control theory, and so on.
So that makes it worth playing a little bit with their
theoretical properties and get some appreciation of a few
subtleties involved here.
No new math in reality in what we're going to do here, but
it's going to be a good opportunity to practice
manipulation of conditional expectations.
So let's look at the expected value of the estimation
error that we obtain.
So theta hat is our estimator.
It's the conditional expectation.
Theta hat minus theta is what kind of error do we have?
If theta hat, if our estimate is bigger than theta, then we
have made a positive error.
If it's on the other side, we have made a negative error.
Then it turns out that on the average, the errors cancel
each other out on the average.
So let's do this calculation.
Let's calculate the expected value of the error given x.
Now by definition, the error is expected value of theta hat
minus theta given x.
We use linearity of expectations to break it up as
expected value of theta hat given x minus expected value of
theta given x.
And now what?
Our estimate is made on the basis of the data of the x's.
If I tell you x, then you know what theta hat is.
Remember that the conditional expectation is a random variable
which is a function of the random variable on which
you're conditioning on.
If you know x, then you know the conditional expectation
given x.
You know what theta hat is going to be.
So theta hat is a function of x.
If it's a function of x, then once I tell you x, you know
what theta hat is going to be.
So this conditional expectation is going to be theta hat
itself.
Here, this is just by definition theta hat.
And so we get equality to 0.
So what we have proved is that the conditional, no matter
what I have observed, and given that I have observed
something, on the average, my error is going to be 0.
This is a statement involving equality of random variables.
Remember that conditional expectations are random
variables because they depend on the thing you're
conditioning on.
0 is sort of a trivial random variable.
This tells you that this random variable is identically
equal to the 0 random variable.
More specifically, it tells you that no matter what value for
x you observe, the conditional expectation of the error is
going to be 0.
And this takes us to this statement here, which is an
equality between numbers.
No matter what specific value for capital X you have
observed, your error on the average is going to be equal
to 0.
So this is a less abstract version of this statement.
This is an equality between two numbers.
It's true for every value of x.
So it's true for, in terms of this random variable, being
equal to that random variable.
Because remember, according to our definition, this random
variable is the random variable that takes this specific
value when capital X happens to be equal to little x.
Now, this doesn't mean that your error is 0.
It only means that your error is as likely in some sense to
fall on the positive side as to fall on the negative side.
So sometimes your error will be positive, sometimes negative.
And on the average, these things cancel out and give you a 0
on the average.
So this is a property that's sometimes giving the name.
We say that theta hat is unbiased.
So theta hat, our estimate, does not have a tendency to be
on the high side.
It does not have a tendency to be on the low side.
On the average, it's just right.
So let's do a little more playing here.
Let's see how our error is related to an arbitrary
function of the data.
Let's do this in a conditional universe and look at this
quantity.
Now, when you know x in a conditional universe where x
is known, then h of x is known.
And so you can pull it outside the expectation.
In the conditional universe where the value of x is given,
this quantity becomes just a constant.
There's nothing random about it.
So you can pull it out of the expectation and write things
this way.
And we have just calculated that this quantity is 0.
So this number turns out to be 0 as well.
OK.
Now, having done this, we can take
expectations of both sides.
And now let's use the law of iterated expectations.
Expectation of a conditional expectation gives us the
unconditional expectation.
And this is also going to be 0.
So here, we use the law of iterated expectations.
OK.
OK.
Why are we doing this?
We're doing this because I would like to calculate the
covariance between theta tilde and theta hat.
That is, ask the question, is there a systematic relation
between the error and the estimate?
So to calculate the covariance, we use the property
that we can calculate its covariances by calculating the
expected value of the product minus the product of the
expected values.
And what do we get?
This is 0 because of what we just proved.
And this is 0 because of what we proved earlier, that the
expected value of the error is equal to 0.
So the covariance between the error and any function of x
is equal to 0.
Let's use that to the case where the function of x who
we're considering is theta hat itself.
Theta hat is our estimate.
It's a function of x.
So this 0 result would still apply.
And we get that this covariance is equal to 0.
So that's what we proved.
Let's see.
What are the morals to take out of all this?
First is you should be very comfortable with this type of
calculation involving conditional expectations.
The main two things that we're using are that when you
condition on a random variable, any function of that
random variable becomes a constant and can be pulled
out the conditional expectation.
The other thing that we're using is the law of
iterated expectations.
So these are the skills involved.
Now on the substance, why is this result interesting?
This tells us that the error is uncorrelated with the
estimate.
What would happen if that were, what's a hypothetical
situation where this would not happen?
Whenever theta hat is positive, my error tends to be
negative.
Suppose that whenever theta hat is big, then you say, oh, my
estimate is too big.
Maybe the true theta is on the lower side, so I expect my
error to be negative.
That would be a situation that would violate this
condition.
This condition tells you that no matter what theta hat is,
you don't expect your error to be on the positive side or on
the negative side.
Your error will still be 0 on the average.
So if you obtain a very high estimate, this is no reason for
you to suspect that the true theta is lower than your
estimate.
If you suspected that the true theta was lower than your
estimate, you should have changed your theta hat.
If you make an estimate, and after obtaining that estimate,
you say, I think my estimate is too big, and so the error is
negative.
If you thought that way, then that means that your estimate
is not the optimal one, that your estimate should have
been corrected to be smaller.
That would mean that there's a better estimate than the one
you used, but the estimate that we are using here is the
optimal one in terms of mean squared error.
There's no way of improving it, and this is really captured
in that statement.
That is, knowing theta hat doesn't give you a lot of
information about the error and gives you, therefore, no
reason to adjust your estimate from what it was.
Finally, a consequence of all this.
This is the definition of the error.
Send theta to this side, send theta tilde to that side, you
get this relation.
The true parameter is composed of two quantities, the
estimate, and then the error that I got with a minus sign.
These two quantities are uncorrelated with each other.
Their covariance is 0, and therefore, the variance of
this is the sum of the variances of these two quantities.
So what's an interpretation of this equality?
There is some inherent randomness in the random
variable theta that we're trying to estimate.
Theta hat tries to estimate it, tries to get close to it, and
if theta hat always stays close to theta, since theta is
random, theta hat must also be quite random, so it has
uncertainty in it.
And the more uncertain theta hat is, the more it moves
together with theta, so the more uncertainty it
removes from theta.
And this is the remaining uncertainty in theta.
The uncertainty that's left after we've done our estimation.
So ideally, to have a small error, we want this quantity
to be small, which is the same as saying that this quantity
should be big.
In the ideal case, theta hat is the same as theta.
That's the best we could hope for.
That corresponds to zero error, and all the variance, all
the uncertainty in theta is absorbed by the
uncertainty in theta hat.
Interestingly, this relation here is just another variation
of the law of total variance that we have seen at some
point in the past.
I will skip that derivation, but it's an interesting fact,
and it can give you an alternative interpretation of
the law of total variance.
OK, so now let's return to our example.
In our example, we obtained the optimal estimator, and we
saw that it was a nonlinear curve, something like this.
I'm exaggerating the corner a little bit to show that it's
nonlinear.
This is the optimal estimator.
It's a nonlinear function of x, which means nonlinear
generally means complicated.
Sometimes, the conditional expectation is really hard to
compute, because whenever you have to compute
expectations, you need to do some integrals.
And if you have many random variables involved, it might
correspond to a multi-dimensional integration.
We don't like this.
Can we come up maybe with a simpler way of estimating
theta, of coming up with a point estimate, which still
has some nice properties?
It has some good motivation, but is simpler.
What does simpler mean?
Perhaps linear.
Let's put ourselves in a straight jacket and restrict
ourselves to estimators that are of this form.
My estimate is constrained to be a linear
function of the axis.
So my estimate, my estimator is going to be a curve, a
linear curve.
It could be this.
It could be that.
Maybe it would want to be something like this.
I want to choose the best possible linear function.
What does that mean?
It means that I write my theta hat in this form.
If I fix a certain a and b, I have fixed the functional
form of my estimator.
And this is the corresponding mean squared error.
That's the error between the true parameter and the
estimate of that parameter.
We take the square of this.
Now the optimal linear estimator is defined as one
for which this mean squared error is smallest possible
over all choices of a and b.
So we want to minimize this expression
over all a's and b's.
How do we do this minimization?
Well, this is a square.
You can expand it, write down all the terms in the
expansion of the square.
So you're going to get a term expected value of theta squared.
You're going to get another term a squared
expected value of x squared, another term which is b
squared.
And then you're going to get various cross terms.
What you obtain, or what you have here, is really a
quadratic function of a and b.
So think of this quantity that we're minimizing as some
function h of a and b.
And it happens to be quadratic.
How do we minimize a quadratic function?
We set the derivative of this function with respect to a and
b to 0, and then do the algebra.
After you do the algebra, you find that the best choice for
a is this one.
So this is the coefficient next to x.
This is the optimal a.
And the optimal b corresponds of the constant terms.
So this term and this times that together are the
optimal choices of b.
So the algebra itself is not very interesting.
What is really interesting is the nature of the result that
we get here.
If we were to plot the result on this particular example, you
would get a curve that's sort of something like this.
Sort of it goes through the middle of this diagram and
is a little slanted.
In this example, x and theta are positively correlated.
Bigger values of x generally correspond to
bigger values of theta.
So in this example, the covariance between x and
theta is positive.
And so our estimate consists.
It can be interpreted in the following way.
The expected value of theta is the estimate that you would
come up with if you didn't have any information about theta.
If you don't make any observations, this is the
best way of estimating theta.
But I have made an observation, x.
And I need to take it into account.
I look at this difference, which is the piece of news
contained in x.
That's what x should be on the average.
If I observe an x which is bigger than what I expected
it to be, and since x with theta are positively
correlated, this tells me that theta should also be bigger
than its average value.
Whenever I see an x that's larger than its average value,
this gives me an indication that theta should also probably
be larger than its average value.
And so I'm taking that difference and multiplying it
by a positive coefficient.
And that's what gives me a curve here that
has a positive slope.
So this increment, the new information contained in x, as
compared to the average value we expected a priori, that
increment allows us to make a correction to our prior
estimate of theta.
And the amount of that correction is guided by the
covariance of x with theta.
If the covariance of x with theta were 0, that would mean
there's no systematic relation between the two.
And in that case, obtaining some information from x doesn't
give us a guide as to how to change the estimate of theta.
If that were 0, we would just stay with this particular
estimate.
We're not able to make a correction.
But when there's a non-zero covariance between x and theta,
that covariance works as a guide for us to obtain a better
estimate of theta.
Then how about the resulting mean squared error?
In this context, it turns out that there's a very nice
formula for the mean squared error obtained from the best
linear estimate.
What's the story here?
The mean squared error that we have has something to do with
the variance of the original random variable.
The more uncertain our original random variable is, the more
error we're going to make.
On the other hand, when the two variables are correlated, we
exploit that correlation to improve our estimate.
And the bigger that correlation is, this row here is the
correlation coefficient between the two random variables.
When this correlation coefficient is larger, this
factor here becomes smaller.
And our mean squared error becomes smaller.
So think of the two extreme cases.
One extreme case is when rho is equal to 1.
So x and theta are perfectly correlated.
When they're perfectly correlated, once I know x,
then I also know theta.
And the two random variables are linearly related.
In that case, my estimate is right on the target.
And the mean squared error is going to be 0.
The other extreme case is if rho is equal to 0, the two
random variables are uncorrelated.
In that case, the measurement does not help me estimate
theta.
And the uncertainty that's left, the mean squared error, is
just the original variance of theta.
So the uncertainty in theta does not get reduced.
So moral, the estimation error is a reduced version of the
original amount of uncertainty in the
random variable theta.
And the larger the correlation between those two random
variables, the better we can remove uncertainty from the
original random variable.
I didn't derive this formula, but it's just a matter of
algebraic manipulations.
We have a formula for theta hat.
Subtract theta from that formula.
Take squared, take expectations, and do a few lines of
algebra that you can read in the text.
And you end up with this really neat and clean formula.
Now, I mentioned in the beginning of the lecture
that we can do inference with theta and x is not just
being single numbers, but they could be
vector random variables.
So for example, we might have multiple data that give us
information about x.
This discussion here, there are no vectors here.
So this discussion was for the case where theta and x were
just scalar one-dimensional quantities.
What do we do if we have multiple data?
Suppose that theta is still a scalar.
It's one-dimensional.
But we make several observations.
And on the basis of these observations, we want to
estimate theta.
The optimal least mean squares estimator would be again the
conditional expectation of theta given x.
That's the optimal one.
And in this case, x is a vector.
So in the general estimator we would use would be this one.
But if we want to keep things simple and we want our
estimator to have a simple functional form, we might
restrict estimators that are linear functions of the data.
And then the story is exactly the same as we discussed before.
I constrain myself to estimating theta using a
linear function of the data.
So my signal processing box just applies a linear function.
And I'm looking for the best coefficients, the coefficients
that are going to result in the least possible squared error.
This is my squared error.
This is my estimate minus the thing I'm trying to estimate,
squared, and then taking the average.
How do we do this?
Same story as before.
This quantity, the x's and the theta's get averaged out
because we have an expectation.
Whatever is left is just a function of the
coefficients of the a's and of b.
As before, it turns out to be a quadratic function.
Then we set the derivatives of this function of a's and b's
with respect to the coefficients.
We set it to 0.
And this gives us a system of linear equations.
It's a system of linear equations that's satisfied by
those coefficients.
It's a linear system because this is a quadratic function of
those coefficients.
So to get closed formulas in this particular case, one
would need to introduce vectors and matrices and
matrix inverses and so on.
The particular formulas are not so much what
interests us here.
Rather, the interesting thing is that this is simply done
just using straightforward solvers of linear equations.
The only thing you need to do is to write down the correct
coefficients of those nonlinear equations.
And the typical coefficient that you would get would be what?
Let's say a typical coefficient would be, let's take a
typical term of this quadratic when you expand it.
You're going to get a term such as a1 x1 times a2 x2.
When you take expectations, you're left with a1 a2 times
expected value of x1 x2.
So a typical, so this would be, it would involve terms
such as a1 squared, expected value of x1 squared.
You would get terms such as a1 a2, expected value of x1 x2.
And lots of other terms here would have a 2.
So you get something that's quadratic in your
coefficients, and the constants that show up in your
system of equations are things that have to do with
expected values of squares of your random variables or
products of your random variables.
To write down numerical values for these, the only thing
you need to know are the means and variances of your
random variables.
If you know the mean and variance, then you
know what this thing is.
And if you know the covariances as well, then
you know what this thing is.
So in order to find the optimal linear estimator in the
case of multiple data, you do not need to know the entire
probability distribution of the random variables that are
involved.
You only need to know your means and covariances.
These are the only quantities that affect the
construction of your optimal estimator.
We could see this already in this formula.
The form of my optimal estimator is completely
determined once I know the means, variance, and covariances
of the random variables in my model.
I do not need to know the detailed distribution of
the random variables that are involved here.
So as I said, in general, you find the form of the optimal
estimator by using a linear equation solver.
There are special examples in which you can get closed
form solutions.
The nicest simplest estimation problem one can think of is
the following.
You have some uncertain parameter, and you make
multiple measurements of that parameter in the
presence of noise.
So the w i's are noises.
i corresponds to your i-th experiment.
So this is the most common situation that you
encounter in the lab.
If you're dealing with some process, you're trying to
measure something, you measure it over and over.
Each time your measurement has some random error, and then
you need to take all your measurements together and come
up with a single estimate.
So the noises are assumed to be independent of each other,
and also to be independent from the value of the true
parameter.
Without loss of generality, we can assume that the noises
have zero mean, and they have some variances that we
assume to be known.
Theta itself has a prior distribution with a certain
mean and a certain variance.
So the form of the optimal linear estimator is really
nice.
Well, maybe you cannot see it right away, because this
looks messy, but what is it really?
It's a linear combination of the x's and the prior mean,
and it's actually a weighted average of the x's and the
prior mean.
Here, we collect all the coefficients that we have at
the top.
So the whole thing is basically a weighted average.
This is the 1 over sigma i squared is the weight that we
give to xi, and in the denominator, we have the
sum of all the weights.
So in the end, we're dealing with a weighted average.
If mu was equal to 1, and all the xi's were equal to 1, then
our estimate would also be equal to 1.
Now, the form of the weights that we have is interesting.
Any given data point is weighted inversely proportional to
the variance.
What does that say?
If my ith data point has a lot of variance, if wi is very
noisy, then xi is not very useful, is not very reliable,
so I'm giving it a small weight.
Large variance, a lot of error in my xi, means that I should
give it a smaller weight.
If two data points have the same variance there of
comparable quality, then I'm going to give them equal
weight.
The other interesting thing is that the prior mean is
treated the same way as the x's.
So it's treated as an additional observation.
So we're taking a weighted average of the prior mean and
of the measurements that we're making.
The formula looks as if the prior mean was just another
data point.
So that's a weight of thinking about Bayesian estimation.
You have the real data points, the x's that you observe.
You also had some prior information.
This plays a role similar to a data point.
Interesting note that if all random variables are normal
in this model, this optimal linear estimator happens to
be also the conditional expectation.
That's a nice thing about normal random variables, that
conditional expectations turn out to be linear.
So the optimal estimate and the optimal linear estimate
turn out to be the same.
And that gives us another interpretation of linear
estimation.
Linear estimation is essentially the same as
pretending that all random variables are normal.
So that's sort of a side point.
Now, I'd like to close with a comment.
You do your measurements and you estimate theta on the
basis of x.
Suppose that instead you have a measuring device that
measures x cubed instead of measuring x.
And you want to estimate theta.
Are you going to get a different estimate?
Well, x and x cubed contain the same information, telling
you x is the same as telling you the value of x cubed.
So the posterior distribution of theta given x is the same
as the posterior distribution of theta given x cubed.
And so the means of these posterior distributions are
going to be the same.
So doing transformations to your data does not matter if
you're doing optimal least squares estimation.
On the other hand, if you restrict yourself to doing
linear estimation, then using a linear function of x is not
the same as using a linear function of x cubed.
So this is a linear estimator, but where the data are the
x cubes.
And we have a linear function of the data.
So this means that when you're using linear estimation, you
have some choices to make, linear on what?
Sometimes you want to plot your data on an ordinary scale
and try to plot a line through them.
Sometimes you plot your data on a logarithmic scale and try
to plot a line through them.
Which scale is the appropriate one?
Here it would be a cubic scale.
And you have to think about your particular model to decide
which version would be a more appropriate one.
Finally, when we have multiple data, sometimes these
multiple data might contain the same information.
So x is one data point, x squared is another data point,
x cubed is another data point.
The three of them contain the same information, but you can
try to form a linear function of them.
And then you obtain a linear estimator that has a more
general form as a function of x.
So if you want to estimate your theta as a cubic function of
x, for example, you can set up a linear estimation model of
this particular form and find the optimal
coefficients, the a's and the b.
All right, so the last slide just gives you the big picture
of what's happening in Bayesian inference.
It's for you to ponder.
Basically, we talked about three possible estimation
methods, maximum posteriori, where we mean squared error
estimation and linear mean squared error estimation, or
least squares estimation.
And there's a number of standard examples that you
will be seeing over and over, restation tutorial, homework,
and so on, perhaps on exams even, where we take some nice
priors on some unknown parameter, we take some nice
models for the noise or the observations, and then you need
to work out posterior distributions and the various
estimates and compare them.
