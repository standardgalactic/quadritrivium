The following content is provided under a Creative
Commons license.
Your support will help MIT OpenCourseWare continue to
offer high-quality educational resources for free.
To make a donation or view additional materials from
hundreds of MIT courses, visit MIT OpenCourseWare at
ocw.mit.edu.
We're going to continue today with our discussion of
classical statistics.
We'll start with a quick review of what we discussed
last time.
And then talk about two topics that cover a lot of the
statistics that are happening in the real world.
So two basic methods.
One is the method of linear regression.
And the other one is the basic methods and tools for how to
do hypothesis testing.
OK, so these two are topics that any scientifically
literate person should know something about.
So we're going to introduce the basic ideas and concepts
involved.
So in classical statistics, we basically have, essentially,
a family of possible models about the world.
So the world is a random variable that we observe.
And we have a model for it, but actually not just one
model, but several candidate models.
And each candidate's model corresponds to a different
value of a parameter, theta, that we do not know.
So in contrast to Bayesian statistics, this theta assumes
to be a constant that we do not know.
It is not modeled as a random variable.
There's no probabilities associated with theta.
We only have probabilities about the axis.
So in this context, what is a reasonable way of choosing a
value for the parameter?
One general approach is the maximum likelihood approach
which chooses the theta for which this quantity is
largest.
So what does that mean intuitively?
I'm trying to find the value of theta under which the data
that I observed are most likely to have occurred.
So the thinking is essentially as follows.
Let's say I have to choose between two choices of theta.
Under this theta, the x that I observed would be very
unlikely.
Under that theta, the x that I observed would have a
decent probability of occurring.
So I choose the latter as my estimate of theta.
It's interesting to do the comparison with the Bayesian
approach, which we did discuss last time.
In the Bayesian approach, we also maximize over theta.
But we maximize a quantity in which the relation between
x's and theta's runs the opposite way.
Here in the Bayesian world, theta is a random variable.
So it has a distribution.
Once we observe the data, it has a posterior distribution.
And we find the value of theta, which is most likely under
the posterior distribution.
As we discussed last time, when you do this maximization,
now the posterior distribution is given by this
expression.
The denominator doesn't matter.
And if you were to take a prior, which is flat, that is a
constant independent of theta, then that term would go away.
And syntactically, at least, the two approaches
look the same.
So syntactically, or formally, maximum likelihood
estimation is the same as Bayesian estimation, in which
you assume a prior, which is flat, so that all possible
values of theta are equally likely.
Philosophically, however, they're very different things.
Here I'm picking the most likely value of theta.
Here I'm picking the value of theta, under which the
observed data would have been more likely to occur.
So maximum likelihood estimation is a general
purpose method.
So it's applied all over the place in many, many different
types of estimation problems.
There's a special kind of estimation problem in which
you may forget about maximum likelihood estimation and come
up with an estimate in a sort of straightforward way.
And this is the case where you're trying to estimate the
mean of the distribution of x, where x is a random variable.
You observe several independent, identically
distributed random variables, x1 up to xn.
All of them have the same distribution as this x.
So they have a common mean.
We do not know the mean we want to estimate it.
What is more natural than just taking the average of the
values that we have observed?
So you generate lots of x's, take the average of them, and
you expect that this is going to be a reasonable estimate of
the true mean of that random variable.
And indeed, we know from the weak law of large numbers that
this estimate converges, in probability, to the true mean
of the random variable.
The other thing that we talked about last time is that
besides giving a point estimate, we may want to also
give an interval that tells us something about where we might
believe theta to lie.
And 1 minus alpha confidence interval is an interval
generated based on the data.
So it's an interval from this value to that value.
These values are written with capital letters because they
are random, because they depend on the data that we have
seen.
And this gives us an interval, and we would like this
interval to have the property that theta is inside that
interval with high probability.
So typically, we would take 1 minus alpha to be a quantity
such as 95%, for example, in which case we have a 95%
confidence interval.
As we discussed last time, it's important to have the right
interpretation of what 95% means.
What it does not mean is the following.
The unknown value has 95% probability of being in the
interval that we have generated.
That's because the unknown value is not a random variable.
It's a constant.
Once we generate the interval, either it's inside or it's
outside, but there's no probabilities involved.
Rather, the probabilities are to be interpreted over the
random interval itself.
What a statement like this says is that if I have a
procedure for generating 95% confidence intervals, then
whenever I use that procedure, I'm going to get a random
interval, and it's going to have 95% probability of
capturing the true value of theta.
So most of the time when I use a particular procedure for
generating confidence intervals, the true theta will
happen to lie inside that confidence interval with
probability 95%.
So the randomness in this statement is with respect to
my confidence interval.
It's not with respect to theta because theta is not random.
How does one construct confidence intervals?
There's various ways of going about it.
But in the case where we're dealing with the estimation of
the mean of a random variable, doing this is straightforward
using the central limit theorem.
Basically, we take our estimated mean, that's the
sample mean, and we take a symmetric interval to the
left and to the right of the sample mean.
And we choose the width of that interval by looking at the
normal tables.
So if this quantity 1 minus alpha is 95%, we're going to
look at the 97.5% tile of the normal distribution, find the
constant number that corresponds to that value from
the normal tables, and construct the confidence
interval according to this formula.
So that gives you a pretty mechanical way of going about
constructing confidence intervals when you're
estimating the sample mean.
So constructing confidence intervals in this way involves
an approximation.
The approximation is the central limit theorem.
We are pretending that the sample mean is a normal random
variable, which is more or less right when n is large.
That's what the central limit theorem tells us.
And sometimes we may need to do some extra
approximation work because quite often we do not know the
true value of sigma.
So we need to do some work either to estimate sigma from
the data.
So sigma is, of course, the standard deviation of the
x's.
We may want to estimate it from the data, or we may have an
upper bound on sigma, and we just use that upper bound.
So now let's move on to the new topic.
A lot of statistics in the real world are of the following
framework, of the following framework.
So suppose that x is the SAT score of a student in high
school, and y is the MIT GPA of that same student.
So you expect that there is a relation between these two.
So you go and collect data for different students, and you
record for a typical student, this would be their SAT score,
that could be their MIT GPA.
And you plot all these data on an x, y diagram.
Now you may believe, it's reasonable to believe, that
there is some systematic relation between the two.
So people who had higher SAT scores in high school may
have higher GPA in college.
Well, that may or may not be true.
You want to construct a model of this kind and see to what
extent a relation of this type is true.
So you might hypothesize that the real world is described
by a model of this kind, that there is a linear relation
between the SAT score and the college GPA.
So it's a linear relation with some parameters theta0 and
theta1 that we do not know.
So we assume a linear relation for the data, and
depending on the choices of theta0 and theta1, it could be
a different line for those data.
Now we would like to find the best model of this kind to
explain the data.
Of course, there's going to be some randomness.
So in general, it's going to be impossible to find a line
that goes through all the data points.
So let's try to find the best line that sort of best
describes, that comes closest to explaining those data.
