would be to put a threshold and make decisions one way
to the right, one way to the left.
But it might not necessarily tell us
where to put the threshold.
Still, it's useful enough to know
that the way to make a good decision
would be in terms of a particular threshold.
Let me make this more specific.
We can take our inspiration from the solution
to hypothesis testing problem that we
had in the Bayesian case.
In the Bayesian case, we just pick
the hypothesis which is more likely given the data.
These posterior probabilities using Bayes' rule
are written this way.
And this term is the same as that term.
They cancel out.
Then let me collect terms here and there.
I get an expression here.
I think the version you have on your handout
is the correct one.
The one on the slide was not the correct one,
so I'm fixing it here.
So this is the form of how you make decisions
in the Bayesian case.
What you do in the Bayesian case,
you calculate this ratio.
Let's call it the likelihood ratio.
And compare that ratio to a threshold.
And the threshold that you should be using in the Bayesian
case has something to do with the prior probabilities
of the two hypotheses.
In the non-Bayesian case, we do not have prior probabilities,
so we do not know how to set this threshold.
But what we're going to do is we're
going to keep this particular structure anyway
and maybe use some other considerations
to pick the threshold.
So we are going to use a likelihood ratio test.
That's how it's called, in which we
calculate a quantity of this kind
that we call the likelihood and compare it with a threshold.
So what's the interpretation of this likelihood?
We ask, the x is that I have observed.
How likely were they to occur if h1 was true?
And how likely were they to occur if h0 was true?
This ratio could be big.
If my data are plausible, they might occur under h1,
but they're very implausible, extremely unlikely to occur
under h0.
Then my thinking would be, well, the data that I saw
are extremely unlikely to have occurred under h0.
So h0 is probably not true.
I'm going to go for h1 and choose h1.
So when this ratio is big, it tells us
that the data that we're seeing are better explained
if we assume h1 to be true rather than h0 to be true.
So I calculate this quantity, compare it with a threshold,
and that's how I make my decision.
So in this particular picture, for example,
the way it would go would be the likelihood ratio in this
picture goes monotonically with my x.
So comparing the likelihood ratio to the threshold
would be the same as comparing my x to the threshold.
And we got the question of how to choose the threshold.
The way that the threshold is chosen
is usually done by fixing one of the two
probabilities of error.
That is, I say that I want my error of one particular type
to be a given number.
So I fix this alpha.
And then I try to find where my threshold should be
so that this probability, tail probability out there,
is just equal to alpha.
And then the other probability of error,
beta will be whatever it turns out to be.
So somebody picks alpha ahead of time,
the probability of a false rejection.
Based on alpha, I find where my threshold is going to be.
I choose my threshold.
And that determines, subsequently, the value of beta.
So we're going to continue with this story next time.
And we'll stop here.
Thank you.
