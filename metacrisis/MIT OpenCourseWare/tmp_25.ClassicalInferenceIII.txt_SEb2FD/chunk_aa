The following content is provided under a Creative
Commons license.
Your support will help MIT OpenCourseWare continue to
offer high quality educational resources for free.
To make a donation or view additional materials from
hundreds of MIT courses, visit MIT OpenCourseWare at
ocw.mit.edu.
OK, if you have not yet done it, please take a moment to go
through the course evaluation website and enter your
comments for the class.
So what we're going to do today to wrap things up is we're
going to go through a tour of the world of hypothesis
testing.
See a few examples of hypothesis tests, starting from
simple ones, such as the one, the setting that we discussed
last time, in which you just have two hypotheses you're
trying to choose between them.
But also look at more complicated situations in which
you have one sort of basic hypothesis, let's say that
you have a fair coin, and you want to test it against the
hypothesis that your coin is not fair, but that alternative
hypothesis is really lots of different hypotheses.
So is my coin fair, is my die fair, do I have the correct
distribution for random variable, and so on?
And I'm going to end up with a few general comments about
this whole business.
So the setting in simple hypothesis testing problems
is the following.
We have two possible models.
And this is the classical world, so we do not have any
prior probabilities on the two hypotheses.
Usually we want to think of these hypotheses as not
being completely symmetrical, but rather one is the
default hypothesis.
And usually it's referred to as the null hypothesis.
And you want to check whether the null hypothesis is true,
whether things are sort of normal, as you would have
expecting them to be, or whether it turns out to be false,
in which case an alternative hypothesis would be correct.
So how does one go about it?
No matter what approach you use, in the end you're going to
end up doing the following.
You have the space of possible observations
that you may obtain.
So when you do the experiment, you're going to get an x
vector, a vector of data that's somewhere.
And for some vectors, you're going to decide that you
accept h0, for some vectors that you reject h0, and you
accept h1.
So what you will end up doing is that you're going to have
some division of the space of all x's into two parts.
And one part is the rejection region, and one part is the
acceptance region.
So if you fall in here, you accept h0.
If you fall here, you reject h0.
So to design a hypothesis test, basically you need to come
up with a division of your x space into two pieces.
So figuring out how to do this involves two elements.
One element is to decide what kind of shape do I want for
my dividing curve.
And having chosen the shape of the dividing curve, where
exactly do I put it?
So if you were to cut this space using, let's say, a
straight cut, you might put it here, or you might put it
there, or you might put it there.
Where exactly are you going to put it?
So let's look at those two steps.
The first issue is to decide the general shape of your
rejection region, which is sort of the structure of your
test.
And the way this is done for the case of two hypotheses is by
writing down the likelihood ratio between the two
hypotheses.
So let's call that quantity l of x.
It's something that you can compute given the data that you
have.
A high value of l of x basically means that this
probability here tends to be bigger than this probability.
It means that the data that you have seen are quite likely
to have occurred under h1, but less likely to have occurred
under h0.
So if you see data that are more plausible, can be better
explained under h1, then this ratio is big, and you're going
to choose in favor of h1 or reject h0.
That's what you do if you have discrete data.
You use the PMFs.
If you have densities, in the case of continuous data,
again, you consider the ratio of the two densities.
So a big l of x is sort of evidence that your data are
more compatible with h1 rather than h0.
Once you accept this kind of structure, then your decision
is really made in terms of that single number.
That is, you had your data that was some kind of vector, and
you condense your data into a single number, as statistic
as it's called, in this case, the likelihood ratio.
And you put a dividing point somewhere here, call it xi.
And in this region, you accept h1.
In this region, you accept h0.
So by committing ourselves to using the likelihood ratio in
order to carry out the test, we have gone from this
complicated picture of finding a dividing line in x space to
a simpler problem of just finding a dividing point on
the real line.
OK, how are we going?
So what's left to do is to choose this threshold xi, or
as it's called, the critical value for making our decision.
And you can place it anywhere, but one way of deciding where
to place it is the following.
Look at the distribution of this random variable, l of x.
It has a certain distribution under h0, and it has some
other distribution under h1.
If I put my threshold here, here's what's going to happen.
When h0 is true, there is this much probability that I'm
going to end up making an incorrect decision.
If h0 is true, there's still a probability that my likelihood
ratio will be bigger than xi.
And that's the probability of making an incorrect decision
of this particular type.
That is, of making a false rejection of h0.
Usually, one sets this probability to a certain
number, alpha.
For example, alpha being 5%.
And once you decide that you want this to be 5%, that
determines where this number xi is going to be.
So the idea here is that I'm going to reject h0 if the
data that I have seen are quite incompatible with h0 if
they're quite unlikely to have occurred under h0.
And I take this level 5%.
So I see my data, and then I say, well, if h0 was true,
the probability that I would have seen data of this kind
would be less than 5%.
Given that I saw those data, that suggests that h0 is not
true, and I end up rejecting h0.
Now, of course, there's the other type of error
probability.
If I put my threshold here, if h1 is true, but my
likelihood ratio falls here, I'm going to make a mistake of
the opposite kind.
h1 is true, but my likelihood ratio turned out to be
small, and I decided in favor of h0.
This is an error of the other kind.
This probability of error, we call it beta.
And you can see that there's a trade-off between alpha and
beta.
If you move your threshold this way, alpha becomes smaller,
but beta becomes larger.
And the general picture is in your trade-off, depending on
where you put your threshold, is this follows.
You can make this beta to be 0 if you put your threshold out
here, but in that case, you're certain that you're going to
make a mistake of the opposite kind.
So beta equals 0, alpha equals 1 is one possibility.
Beta equals 1, alpha equals 0 is the other possibility if
you send your threshold complete to the other side.
And in general, you're going to get a trade-off curve of
some sort.
And if you want to use a specific value of alpha, for
example, alpha being 0.05, then that's going to determine
for you a probability for beta.
Now, there's a general and quite important theorem in
statistics, which we're not proving, which tells us that
when we use likelihood ratio tests, we get the best
possible trade-off curve.
You could think of other ways of making your decisions,
other ways of cutting off your x space into a rejection and
acceptance region, but any other way that you do it is
going to end up with some probabilities of error that are
going to be above this particular curve.
So the likelihood ratio test turns out to give you the
best possible way of dealing with this trade-off between
alpha and beta.
We cannot minimize alpha and beta simultaneously.
There's a trade-off between them.
But at least we would like to have a test that deals with
this trade-off in the best possible way.
For a given value of alpha, we want to have the smallest
possible value of beta.
And the theorem is that likelihood ratio tests do have
this optimality property.
For a given value of alpha, they minimize the probability of
error of a different kind.
So let's make all these concrete and look at a
simple example.
We have two normal distributions with different
means.
So under H0, you have a mean of 0.
Under H1, you have a mean of 1.
You get your data.
You actually get several data drawn from one of the two
distributions, and you want to make a decision which one of
the two is true.
So what you do is you write down the likelihood ratio.
The density for a vector of data, if that vector was
generated according to H0, which is this one, and the
density if it was generated according to H1.
Since we have multiple data, the density of a vector is the
product of the densities of the individual elements.
Since we're dealing with normals, we have those
exponential factors.
A product of exponentials gives us an
