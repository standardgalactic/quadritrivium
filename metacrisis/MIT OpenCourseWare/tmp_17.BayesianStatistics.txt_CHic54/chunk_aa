The following content is provided under a Creative
Commons license.
Your support will help MIT OpenCourseWare
continue to offer high quality educational resources for free.
To make a donation or to view additional materials
from hundreds of MIT courses, visit MIT OpenCourseWare
at ocw.mit.edu.
So today we'll actually just do a brief chapter
on Bayesian statistics.
And there's entire courses on Bayesian statistics.
There's entire books on Bayesian statistics.
There's entire careers on Bayesian statistics.
So admittedly, I'm not going to be
able to do it justice and tell you
all the interesting things that are happening
in Bayesian statistics.
But I think it's important as a statistician
to know what it is, how it works,
because it's actually a weapon of choice
for many practitioners.
And because it allows them to incorporate their knowledge
about a problem in a fairly systematic manner.
So if you look at, like, say, the Bayesian statistics
literature, it's huge.
And so here I give you sort of a range
of what you can expect to see in Bayesian statistics
from your second edition of a traditional book, something
that involves computation, some things that involve
rethinking.
And there's a lot of Bayesian thinking.
There's a lot of things that talk about sort
of like philosophy of thinking Bayesian.
This book, for example, seems to be one of them.
This book is definitely one of them.
This one represents sort of a broad literature
on Bayesian statistics for applications, for example,
in social sciences.
But even in large-scale machine learning,
there's a lot of Bayesian statistics happening,
particularly using something called Bayesian parametrics
or hierarchical Bayesian modeling.
So we do have some experts at MIT in the C cell.
Tamara Broderick, for example, is a person who does quite
a bit of interesting work on Bayesian parametrics.
And if that's something you want to know more about,
I urge you to go and talk to her.
So before we go in those more advanced things,
we need to start with what is the Bayesian approach?
What do Bayesians do?
And how is it different from what we've been doing so far?
So to understand the difference between Bayesians
and what we've been doing so far is
we need to first put a name on what we've been doing so far.
It's called Frequentist Statistics.
So it's usually Bayesian versus Frequentist statistics.
I mean, by versus, I don't mean that there's naturally
an opposition to them.
Actually, often you will see the same method that
comes out of both approaches.
So let's see how we did it.
The first thing, we had data.
We observed some data.
And we assumed that this data was generated randomly.
The reason we did that is that because this
would allow us to leverage tools from probability.
So let's say by nature, measurements, you do a survey,
you get some data.
Then we made some assumptions on the data generating process.
For example, we assumed there were
IID that was one of the recurring things.
Sometimes we assumed it was Gaussian
if we wanted to use, say, t-test.
Maybe we did some non-parametric statistics.
So we assumed it was a smooth function
or maybe linear regression function.
So those are our modeling.
And this was basically a way to say,
well, we're not going to allow for any distributions
for the data that we have, but maybe a small set of distribution
that index by some small parameters, for example.
Or at least remove some of the possibilities.
Otherwise, there's nothing we could learn.
And so, for example, this was associated
to some parameter of interest, say,
data or beta in the regression model.
All right, then we had this unknown problem
and this unknown parameter, and we wanted to find it.
We wanted to either estimate it or test it
or maybe find a confidence interval for this object.
So far, I should not have said anything that's new.
But this last sentence is actually
what's going to be different from the Bayesian part.
In particular, this unknown but fixed thing
is what's going to be changing.
So in the Bayesian approach, we still
assume that we observe some random data.
But the generating process is slightly different.
It's sort of a two-layer process.
And there's one process that generates the parameter,
and then one process that, given this parameter,
generates the data.
So what the first layer does, I mean,
nobody really believes that there's
some random process that's happening about generating
what is going to be the true expected number of people who
turn their head to the right.
When they kiss, but this is actually
going to be something that brings us some easiness for us
to incorporate what we call prior belief.
So we'll see an example in a second.
But often, you actually have prior belief
of what this parameter should be.
When we did, let's say, these squares,
we looked over all of the vectors in all of r to the p,
including the ones that have coefficients equal to $50 million.
And so those are things that maybe we might be able to roll out.
And maybe we might be able to roll out
at a much smaller scale.
For example, well, I mean, I don't know.
I'm not an expert on turning your head to the right or to the left.
But maybe you can roll out the fact
that almost everybody is turning their head
in the same direction, or almost everybody's
turning their head to another direction.
So we have this prior belief.
And this prior belief is going to play, say,
hopefully, less and less important role
as we collect more and more data.
But if we have a smaller amount of data,
we might want to be able to use this information rather
than just shooting in the dark.
And so the idea is to have this prior belief.
And then we want to update this prior belief
into what's called a posterior belief
after we've seen some data.
Maybe I believe that there's something that
should be in some range.
But maybe after I see data, maybe it's
comforting me in my belief.
So I'm actually having maybe a belief that's more.
So a belief encompasses basically what you think
and how strongly you think about it.
That's what I call belief.
So for example, if I have a belief about some parameter
theta, maybe my belief is telling me where theta should be
and how strongly I believe in it in the sense
that I have a very narrow region where theta could be.
And so the posterior belief says, well, you see some data.
And maybe you're more confident or less confident about what
you've seen.
You've shifted your belief a little bit.
And so that's what we're going to try to see
and how to do this in a principal manner.
So of course, to understand this better,
there's nothing better than an example.
So let's talk about another stupid statistical question,
which is let's try to understand p.
Of course, I'm not going to talk about politics from now on.
So let's talk about p, the proportion of women
in the population.
OK?
And so what I could do is to collect some data, x1, xn,
and assume that they're Bernoulli with some parameter p
unknown.
Right?
So p is in 0, 1.
OK?
Let's assume that those guys are i, d.
So this is just an indicator for each of my collected data,
whether the person I randomly sample is a woman,
I get a 1, and if it's a man, I get a 0.
OK?
And so now the question is, I sample these people randomly.
I denote their gender.
And the frequentist approach was just saying, OK,
let's just estimate p hat being xn bar.
And then we could do some tests.
Right?
So here there's a test.
I want to test maybe if p is equal to 0.5 or not.
That sounds like a pretty reasonable thing to test.
But we want to also maybe estimate p.
But here this is a case where we definitely
have for our belief of what p should be.
Right?
We are pretty confident that p is not going to be 0.7.
We actually believe that p should be extremely close to 1.5.
OK?
But maybe not exactly.
Maybe I don't know.
Maybe this population is not the population in the world,
but maybe this is the population of, say, some college.
And we want to understand if this college has half women or not.
Right?
So maybe we know it's going to be close to 1.5,
but maybe we're not quite sure.
And so we're going to want to integrate that knowledge.
All right?
So I could integrate it in a blunt manner
by saying discard the data and say that p is equal to 1.5.
