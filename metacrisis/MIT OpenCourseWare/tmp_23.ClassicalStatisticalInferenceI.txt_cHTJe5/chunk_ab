We write down the formula for the probability of a
particular x vector given a particular value of theta.
But again, when I use the word given here, it's not in the
conditioning sense.
It's the value of the density for a particular
choice of theta.
Here I wrote down, I define maximum likelihood estimation
in terms of PMFs.
That's what you would do if the x's were discrete random
variables.
Here the x's are continuous random variables, so instead
I'm using the PDF instead of the PMF.
So this definition here generalizes to the case of
continuous random variables.
And you use f's instead of x's, or a usual recipe.
So the maximum likelihood estimate is defined.
Now, since the x i's are independent, the joint density
of all the x's together is the product of the
individual densities.
So you look at this quantity, this is the density or sort
of probability of observing a particular sequence of x's.
And we ask the question, what's the value of theta that
makes the x's that we observe most likely?
So we want to carry out this maximization.
Now, this maximization is just a
calculation problem.
We're going to do this maximization by taking the
logarithm of this expression.
Maximizing an expression is the same as
maximizing the logarithm.
So the logarithm of this expression, logarithm of a
product is the sum of the logarithms.
You get contributions from this theta term.
There's n of these, so we get an n log theta.
And then we have the sum of the logarithms of these terms.
It gives us minus theta, and then the sum of the x's.
So we need to maximize this expression with respect to theta.
The way to do this maximization is you take the
derivative with respect to theta.
And you get n over theta equals to the sum of the x's.
And then you solve for theta, and you find that the maximum
likelihood estimate is this quantity.
Which sort of makes sense?
Because this is the reciprocal of the sample mean of the x's.
Theta in an exponential distribution, we know that it's
1 over the mean of the exponential distribution.
So it kind of looks like a reasonable estimate.
So in any case, this is the estimate that the maximum
likelihood estimation procedure tells us that we
should report.
This formula here tells you what to do if you have already
observed specific numbers.
If you have observed specific numbers, then you observe
this particular number as your estimate of theta.
If you want to describe your estimation procedure more
abstractly, what you have constructed is an estimator,
which is a box that takes in the random variables, capital
x1 up to capital xn, and produces out your estimate,
which is also a random variable, because it's a
function of these random variables, and is denoted by
an uppercase theta to indicate that this is now
a random variable.
So this is an equality about numbers.
This is a description of the general procedure, which is
an equality between two random variables.
And this gives you the sort of more abstract view of what
we are doing here.
All right, so what can we tell about our estimate?
Is it good or is it bad?
So we should look at this particular random variable and
talk about the statistical properties that it has.
What we would like is this random variable to be close to
the true value of theta with high probability, no matter
what theta is, since we don't know what theta is.
Let's make a little more specific the
properties that we want.
So we cook up an estimator somehow.
So this estimator corresponds again to a box that takes
data in the capital X's and produces an estimate theta hat.
This estimate is random.
Sometimes it will be above the true value of theta.
Sometimes it will be below.
Ideally, we would like it to not have a systematic error on
the positive side or the negative side.
So a reasonable wish to have for a good estimator is that on
the average, it gives you the correct value.
Now here, let's be a little more specific about what that
expectation is.
This is an expectation with respect to the probability
distribution of theta hat.
The probability distribution of theta hat is affected by the
probability distribution of the X's, because theta hat is a
function of the X's.
And the probability distribution of the X's is
affected by the true value of theta.
So depending on which one is the true value of theta, this
is going to be a different expectation.
So if you were to write this expectation out in more detail,
it would look like something like this.
You need to write down the probability distribution of
theta hat, and this is going to be some function.
But this function depends on the true theta, is affected by
the true theta.
And then you integrate this with respect to theta hat.
What's the point here?
Again, theta hat is a function of the X's.
So the density of theta hat is affected by the
density of the X's.
The density of the X's is affected by the true value of
theta, so the distribution of theta hat is affected by the
true value of theta.
Another way to put it is, as I mentioned a few minutes ago,
in this business, it's as if we are considering different
possible probabilistic models, one probabilistic model for
each choice of theta, and we're trying to guess which one of
these probabilistic models is the true one.
One way of emphasizing the fact that this expression
depends on the true theta is to put a little subscript here,
expectation under the particular value of the
parameter theta.
So depending on what value the true parameter theta takes,
this expectation will have a different value.
And what we would like is that no matter what the true value
is, that our estimate will not have a bias on the positive
or the negative sides.
So this is a property that's desirable.
Is it always going to be true?
Not necessarily.
It depends on what estimator we construct.
Is it true for our exponential example?
Unfortunately not.
The estimate that we have in the exponential example turns
out to be biased.
And one extreme way of seeing this is to consider the case
where our sample size is 1.
We're trying to estimate theta, and the estimator from the
previous slide in that case is just 1 over x1.
Now x1 has a fair amount of density in the vicinity of
0, which means that 1 over x1 has significant probability of
being very large.
And if you do the calculation, this ultimately makes the
expected value of 1 over x1 to be infinite.
Now infinity is definitely not the correct value.
So our estimate is biased upwards.
And it's actually biased a lot upwards.
So that's how things are.
Maximum likelihood estimates in general will be biased.
But under some conditions, they will turn out to be a
sympathetically unbiased.
That is, as you get more and more data, as your x vector is
longer and longer, with independent data, the
estimate that you're going to have, the expected value of
your estimator is going to get closer and
closer to the true value.
So you do have some nice asymptotic properties, but
we're not going to prove anything like this.
Speaking of asymptotic properties, in general, what
we would like to have is that as you collect more and more
data, you get the correct answer in subsense.
And the sense that we're going to use here is the limiting
sense of convergence in probability, since this is
the only notion of convergence of random variables
that we have in our hands.
This is similar to what we had in the Polster problem.
For example, if we had a bigger and bigger sample size, we
would be more and more confident that the estimate
that we obtain is close to the unknown true parameter of the
distribution that we have.
So this is a desirable property.
And if you have an infinitely large amount of data, you
should be able to estimate an unknown parameter more or
less exactly.
So this is a desirable property of estimators.
It turns out that maximum likelihood estimation given
independent data does have this property under mild
conditions, so maximum likelihood estimation in this
respect is a good approach.
So let's see, do we have this consistency property in our
exponential example?
In our exponential example, we used this quantity to
estimate the unknown parameter theta.
What properties does this quantity have as n goes to
infinity?
Well, this quantity is the reciprocal of that quantity
up here, which is the sample mean.
We know from the weak law of large numbers that the sample
mean converges to the expectation.
So this property here comes from the weak law of large
numbers.
In probability, this quantity converges to the expected
value, which for exponential distributions is 1 over theta.
Now, if something converges to something, then the reciprocal
of that should converge to the reciprocal of that.
That's a property that's certainly correct for numbers.
But here we're not talking about convergence of numbers.
We're talking about convergence in probability,
which is a more complicated notion.
Fortunately, it turns out that the same thing is true when
we deal with convergence in probability.
One can show, although we will not bother doing this, that
