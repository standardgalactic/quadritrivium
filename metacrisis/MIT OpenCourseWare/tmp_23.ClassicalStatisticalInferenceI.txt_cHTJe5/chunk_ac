indeed the reciprocal of this, which is our estimate,
converges in probability to the reciprocal of that.
And that reciprocal is the true parameter theta.
So for this particular exponential example, we do
have the desirable property that as the number of data
becomes larger and larger, the estimate that we have
constructed will get closer and closer to the true parameter
value.
And this is true no matter what theta is.
No matter what the true parameter theta is, we're
going to get close to it as we collect more data.
OK, so these are two rough qualitative properties that
would be nice to have.
If you want to get a little more quantitative, you can
start looking at the mean squared error that your
estimator gives.
Now once more, the comment I was making up there applies
namely that this expectation here is an expectation with
respect to the probability distribution of theta hat that
corresponds to a particular value of little theta.
So fix a little theta, write down this expression, look at
the probability distribution of theta hat under that little
theta, and do this calculation.
You're going to get some quantity that
depends on little theta.
And so all quantities in this equality here should be
interpreted as quantities under that particular value of
little theta.
So if you wanted to make this more explicit, you could
start throwing little subscripts everywhere in those
expressions.
And let's see what those expressions tell us.
The expected value squared of a random variable, we know
that it's always equal to the variance of this random
variable, plus the expectation of the random
variable squared.
So the expectation value of that random variable squared.
So we are just applying this equality here is just a
familiar formula that the expected value of x squared is
the variance of x plus the expected value of x squared.
So we apply this formula to x equal to theta hat minus theta.
Remember that in this classical setting, theta is just a
constant.
We have fixed theta.
We want to calculate the variance of this quantity under
that particular theta.
When you add or subtract the constant to a random variable,
the variance doesn't change.
So we obtain this is the same as the variance of our
estimator.
And what we got here is the bias of our estimate.
It tells us on the average whether we fall above or
below, and we're taking the bias to be squared.
If we have an unbiased estimator, the bias term
will be zero.
So ideally, we want theta hat to be very close to theta.
And since theta is a constant, if that happens, the variance
of theta hat would be very small.
So theta is a constant.
If theta hat has a distribution that's concentrated
just around little theta, then theta hat would
have a small variance.
So this is one desire that we have.
We want to have a small variance, but we also want to
have a small bias at the same time.
So the general form of the mean squared error has two
contributions.
One is the variance of our estimator.
The other is the bias.
And one usually wants to design an estimator that
simultaneously keeps both of these terms small.
So here's an estimation method that would do very well with
respect to this term, but badly with respect to that term.
So suppose that my distribution is, let's say,
normal with unknown mean theta and variance 1.
And I use as my estimator something very dumb.
I always produce an estimate that says my estimate is 100.
So I'm just ignoring the data and report 100.
What does this do?
The variance of my estimator is 0.
There's no randomness in the estimate that I report.
But the bias is going to be pretty bad.
The bias is going to be theta hat, which is 100 minus the
true value of theta.
And for some thetas, my bias is going to be horrible.
If my true theta happens to be 0, my bias squared is a huge
term, and I get a large error.
So what's the moral of this example?
There are ways of making that variance very small.
But in those cases, you pay a price in the bias.
So you want to do something a little more delicate, where
you try to keep both terms small at the same time.
So these types of considerations become
important when you start to try to design sophisticated
estimators for more complicated problems.
But we will not do this in this class.
This belongs to further classes on statistics and
inference.
For this class, for parameter estimation, we will
basically stick to two very simple methods.
One is the maximum likelihood method we've just discussed.
And the other method is what you would do if you were still
in high school and didn't know any probability.
You get data, and you try to, these data come from some
distribution with an unknown mean, and you want to
estimate that unknown mean.
What would you do?
You would just take those data and average them out.
So let's make this a little more specific.
We have axes that come from a given distribution.
We know the general form of the distribution, perhaps.
But we do know, perhaps, the variance of that distribution,
or perhaps we don't know it.
But we do not know the mean.
And we want to estimate the mean of that distribution.
Now, we can write this situation.
We can represent it in a different form.
The x-sides are equal to theta.
This is the mean, plus a zero mean random variable that you
can think of as noise.
So this corresponds to the usual situation you would have
in a lab where you go and try to measure an unknown quantity.
You get lots of measurements.
But each time that you measure them, your measurements
have some extra noise in there.
And you want to kind of get rid of that noise.
The way to try to get rid of the measurement noise is to
collect lots of data and average them out.
This is the sample mean.
And this is a very, very reasonable way of trying to
estimate the unknown mean of the axis.
So this is the sample mean.
It's a reasonable, plausible, in general, pretty good
estimator of the unknown mean of a certain distribution.
We can apply this estimator without really knowing a lot
about the distribution of the axis.
Actually, we don't need to know anything about the
distribution.
We can still apply it, because the variance, for example,
does not show up here.
We don't need to know the variance to
calculate that quantity.
Does this estimator have good properties?
Yes, it does.
What's the expected value of the sample mean?
The expectation of this, it's the expectation of this sum
divided by n.
The expected value of each one of the axis is theta.
So the expected value of the sample mean
is just theta itself.
So our estimator is unbiased.
No matter what theta is, our estimator does not have a
systematic error in either direction.
Furthermore, the weak law of large numbers tells us that
this quantity converges to the true
parameter in probability.
So it's a consistent estimator.
This is good.
And if you want to calculate the mean squared error
corresponding to this estimator, remember how we
defined the mean squared error.
It's this quantity.
Then it's a calculation that we have done a fair number of
times by now.
The mean squared error is the variance of the distribution of
the axis divided by n.
So as we get more and more data, the mean squared error
goes down to zero.
In some examples, it turns out that the sample mean is also
the same as the maximum likelihood estimate.
For example, if the axes are coming from a normal
distribution, you can write down the likelihoods, do the
maximization with respect to theta.
You'll find that the maximum likelihood estimate is the same
as the sample mean.
In other cases, the sample mean will be different from the
maximum likelihood.
And then you have a choice about which one of the two you
would use.
Probably in most reasonable situations, you would just
use the sample mean, because it's simple, easy to compute,
and has nice properties.
All right, so you go to your boss, and you report and say,
OK, I did all my experiments in the lab.
And the average value that I got is a certain value.
It's a certain number, 2.37.
So is that informative to your boss?
Well, your boss would like to know how much they can trust
this number, 2.37.
Well, I know that the true value is not going to be
exactly that, but how close should it be?
So give me a range of what you think are possible
values of theta.
So the situation is like this.
So suppose that we observe axes that are coming from a
certain distribution, and we're trying to estimate the mean.
We get our data, maybe our data looks something like this.
You calculate the mean, you find the sample mean.
So let's suppose that the sample mean is a number, for
some reason, take 2.37, but you want to convey something to
