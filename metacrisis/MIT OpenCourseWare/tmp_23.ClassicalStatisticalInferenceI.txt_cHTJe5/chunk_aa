The following content is provided under a Creative
Commons license.
Your support will help MIT OpenCourseWare continue to
offer high-quality educational resources for free.
To make a donation or view additional materials from
hundreds of MIT courses, visit MIT OpenCourseWare at
ocw.mit.edu.
So for the last three lectures, we're going to talk
about classical statistics, the way statistics can be done
if you don't want to assume a prior distribution on the
unknown parameters.
Today, we're going to focus mostly on the estimation side
and leave hypothesis testing for the next two lectures.
So there's one generic method that one can use to carry out
parameter estimation.
That's the maximum likelihood method.
We are going to define what it is.
Then we're looking at, we will look at the most common
estimation problem there is, which is to estimate the mean
of a given distribution.
And we're going to talk about confidence intervals, which
refers to providing an interval around your estimate,
which has some properties of the kind that the parameter is
highly likely to be inside that interval.
But we will be careful about how to interpret that
particular statement.
OK, so the big framework first.
The picture is almost the same as the one that we had in the
case of Bayesian statistics.
We have some unknown parameter.
And we have a measuring device.
There is some noise, some randomness.
And we get an observation x, whose distribution depends on
the value of the parameter.
However, the big change from the Bayesian setting is that here
this parameter is just a number.
It's not modeled as a random variable.
It does not have a probability distribution.
There's nothing random about it.
It's a constant.
It just happens that we don't know what that constant is.
And in particular, this probability distribution
here, the distribution of x, depends on theta.
But this is not a conditional distribution in the usual
sense of the word.
Conditional distributions were defined when we had two
random variables.
We conditioned one random variable on the other.
And we used the bar to separate the x from the theta.
To make the point that this is not a conditional
distribution, we use a different notation.
We put a semicolumn here.
And what this is meant to say is that x has a distribution.
That distribution has a certain parameter.
And we don't know what that parameter is.
So for example, this might be a normal distribution with
variance 1.
But a mean theta, we don't know what theta is.
And we want to estimate it.
Once we have this setting, then your job is to design this
box, the estimator.
The estimator is some data processing box that takes the
measurement and produces an estimate of the unknown
parameter.
Now, the notation that's used here is as if x and theta were
a single one-dimensional quantities.
But actually, everything we say remains valid if you
interpret x and theta as vectors of parameters.
So for example, you may obtain several measurements, x1 up
to xn.
And there may be several unknown parameters in the
background.
Once more, we do not want to assume a prior
distribution on theta.
It's a constant.
And if you want to think mathematically about this
situation, it's as if you have many different
probabilistic models.
So a normal with this mean or a normal with that mean or a
normal with that mean, these are alternative candidate
probabilistic models.
And we want to try to make a decision about which one is
the correct model.
In some cases, we have to choose just between a small
number of models.
For example, you have a coin with an unknown bias.
The bias is either 1 1⁄2 or 3⁄4.
You're going to flip the coin a few times.
And you try to decide whether the true bias is this one or
is that one.
So in this case, we have two specific alternative
probabilistic models from which we want to distinguish.
But sometimes things are a little more complicated.
For example, you have a coin.
And you have one hypothesis that my coin is unbiased.
And the other hypothesis is that my coin is biased.
And you do your experiments.
And you want to come up with a decision that decides whether
this is true or this one is true.
In this case, we're not dealing with just two
alternative probabilistic models.
This one is a specific model for the coin.
But this one actually corresponds to lots of possible
alternative coin models.
So this includes the model where theta is 0.6, the model
where theta is 0.7, theta 0.8, and so on.
So we're trying to discriminate between one model and lots of
alternative models.
How does one go about this?
Well, there's some systematic ways that one can approach
problems of this kind.
And we will start talking about these next time.
So today we're going to focus on estimation problems.
In estimation problems, theta is a quantity which is a real
number, a continuous parameter.
We are going to design this box.
So what we get out of this box is an estimate.
Now notice that this estimate here is a random variable.
Even though theta is deterministic, this is random
because it's a function of the data that we observe.
The data are random.
We are applying a function to the data to construct our
estimate.
So since it's a function of random variables, it's a
random variable itself.
The distribution of theta hat depends on the
distribution of x.
The distribution of x is affected by theta.
So in the end, the distribution of your
estimate theta hat will also be affected by whatever theta
happens to be.
Our general objective when designing estimators is that
we want to get, in the end, an estimation error, which is not
too large.
But we'll have to make that specific again, what exactly
we mean by that.
OK, so how do we go about this problem?
One general approach is to pick a theta under which,
the data that we observe, that is the x's, are most likely
to have occurred.
So I observe x.
For any given theta, I can calculate this quantity, which
tells me under this particular theta, the x that you
observed had this probability of occurring.
Under that theta, the x that you observed had that
probability of occurring.
You just choose that theta, which makes the data that you
observed most likely.
It's interesting to compare this maximum likelihood
estimate with the estimate that you would have if you were
in a Bayesian setting, and you were using maximum
posteriori probability estimation.
In the Bayesian setting, what we do is, given the data, we
use the prior distribution on theta, and we calculate the
posterior distribution of theta given x.
Notice that this is sort of the opposite from
what we have here.
This is the probability of x for a particular value of theta,
whereas this is the probability of theta for a
particular x.
So it's the opposite type of conditioning.
In the Bayesian setting, theta is a random variable, so we
can talk about the probability distribution of theta.
So how do these two compare, except for this syntactic
difference that the order of x's and theta's are reversed?
Let's write down in full detail what this posterior
distribution of theta is.
By the Bayes rule, this conditional distribution is
obtained from the prior and the model of the measurement
process that we have, and we get this expression.
So in Bayesian estimation, we want to find the most likely
value of theta, and we need to maximize this quantity
overall possible, theta's.
First thing to notice is that the denominator is a constant.
It does not involve theta.
So when you maximize this quantity, you don't care
about the denominator.
You just want to maximize the numerator.
Now here things start to look a little more similar, and they
would be exactly of the same kind if that term here was
absent, if the prior was absent.
The two are going to become the same if that prior was just
a constant.
So if that prior is a constant, then maximum likelihood
estimation takes exactly the same form as Bayesian maximum
posteriori probability estimation.
So you can give this particular interpretation of
maximum likelihood estimation.
Maximum likelihood estimation is essentially what you have
done if you were in a Bayesian world and you had assumed a
prior on the thetas, that's uniform, or the thetas being
equally likely.
So let's look at a simple example.
Suppose that the x i's are independent identically
distributed random variables with certain parameter theta.
So the distribution of each one of the x i's is this
particular term.
So theta is one dimensional.
It's a one dimensional parameter, but we have several
data.
