your boss about how we spread out these data where.
So the boss asks you to give him or her some kind of
interval that on which theta, the true parameter, might lie.
So the boss asked you for an interval.
So what you do is you end up reporting an interval, and you
somehow use the data that you have seen to construct this
interval, and you report to your boss also the end points of
this interval.
Let's give names to these end points.
Theta n minus and theta n plus.
OK, the ends here just play the role of keeping track of how
many data we're using.
So what you report to your boss is this interval as well.
Are these thetas here, the end points of the interval, lower
case or upper case?
What should they be?
Well, you construct these intervals after you see your
data.
You take the data into account to construct them, to
construct the interval.
So these definitely should depend on the data, and
therefore, they're random variables.
Same thing with your estimator.
In general, it's going to be a random variable, although when
you go and report numbers to your boss, you give the
specific realizations of the random variables given the
data that you got.
OK, so instead of having just a single box that produces
estimates, so our previous picture was that you have
your estimator that takes x's and produces theta hats.
Now, our box will also be producing theta hat minus
and theta hat plus.
It's going to produce an interval as well.
The x's are random, therefore, these quantities are random.
Once you go and do the experiment and obtain your
data, then your data will be some lower case x, specific
numbers, and then your estimates and estimator
become also lower case.
What would we like this interval to do?
We would like it to be highly likely to contain the true
value of the parameter.
So we might impose some specs of the following kind.
I pick a number alpha.
Usually, that alpha, think of it as a
probability of a large error.
Typical value of alpha might be 0.05, in which case this
number here is 0.95.
And your given specs that say something like this, I would
like, with probability at least 0.95, I would like this to
happen, which says that the true parameter lies inside the
confidence interval.
Now, let's try to interpret this statement.
Suppose that you did the experiment and that you ended
up reporting to your boss a confidence interval from 1.97
to 2.56.
That's what you report to your boss.
And suppose that the confidence interval has this
property.
Can you go to your boss and say, with probability 95%, the
true value of theta is between these two numbers?
Is that a meaningful statement?
So the tentative statement is, with probability 95%, the
true value of theta is between 1.97 and 2.56.
Well, what is random in that statement?
There's nothing random.
The true value of theta is a constant.
1.97 is a number, 256 is a number.
So it doesn't make any sense to talk about the probability
that theta is in this interval.
Either theta happens to be in that interval, or it happens
to not be.
But there are no probabilities associated with this,
because theta is not random.
Syntactically, you can see this, because theta here is a
lower case.
So what kind of probabilities are we talking about here?
Where is the randomness?
Well, the random thing is the interval.
It's not theta.
So the statement that is being made here is that the
interval that's being constructed by our procedure
should have the property that with probability 95%, it's
going to fall on top of the true value of theta.
So the right way of interpreting what a 95%
confidence interval is, is something like the following.
We have the true value of theta that we don't know.
I get data.
Based on the data, I construct a confidence interval.
I get my confidence interval.
I got lucky, and the true value of theta is in here.
Next day, I do the same experiment.
Take my data, construct a confidence interval, and I get
this confidence interval.
Lucky once more.
Next day, I get data, use my data to come up with an
estimate of theta and the confidence interval.
That day, I was unlucky.
And I got a confidence interval out there.
What the requirement here is, is that 95% of the days where
we use this as a certain procedure for constructing
confidence intervals, 95% of those days we will be lucky
and we will capture the correct value of theta by your
confidence interval.
So it's a statement about the distribution of these random
confidence intervals.
How likely are they to fall on top of the true theta, as
opposed to how likely they are to fall outside?
So it's a statement about probabilities associated with
the confidence interval.
They're not probabilities about theta because theta
itself is not random.
Right.
So this is what the confidence interval is in general, and
how we interpret it.
How do we construct a 95% confidence interval?
Let's go through this exercise in a particular example.
The calculations are exactly the same as the ones that you
did when we talked about the laws of large numbers in the
central limit theorem.
So there's nothing new calculationally, but it's
perhaps new in terms of the language that we use and the
interpretation.
So we got our sample mean from some distribution, and we
would like to calculate a 95% confidence interval.
We know from the normal tables that the standard normal has
2.5% on the tail that's after 1.96.
By this time, the number 1.96 should be pretty familiar.
So if this probability here is 2.5%, this number here is
196.
Now look at this random variable here.
This is the sample mean, a difference from the true mean
normalized by the usual normalizing factor.
By the central limit theorem, this is
approximately normal.
So it has probability 0.95 of being less than 1.96.
Now take this event here and rewrite it.
This is the event, well, that theta hat minus theta is
bigger than this number and smaller than that number.
This event here is equivalent to that event here.
And so this suggests a way of constructing our 95% confidence
interval.
I'm going to report the interval which gives this as the
lower end of the confidence interval and gives this as the
upper end of the confidence interval.
In other words, at the end of the experiment, we report the
sample mean, which is our estimate, and we report also
an interval around the sample mean.
And this is our 95% confidence interval.
The confidence interval becomes smaller when n is larger.
In some sense, we are more certain that we're doing a
good estimation job, so we can have a small interval and
still be quite confident that our interval captures the true
value of the parameter.
Also, if our data have very little noise, when you have
more accurate measurements, you are more confident that your
estimate is pretty good.
And that results in a smaller confidence interval, smaller
length of the confidence interval, and still you have
95% probability of capturing the true value of theta.
So we did this exercise by taking 95% confidence intervals
and the corresponding value from the normal tables, which is
1.96.
Of course, you can do it more generally if you set your
alpha to be some other number.
Again, you look at the normal tables and you find the value
here so that the tail has probability alpha over 2.
And instead of using 1.96, you use whatever number you get
from the normal tables.
And this tells you how to construct a confidence interval.
Well, to be exact, this is not necessarily a 95%
confidence interval.
It's approximately a 95% confidence interval.
Why is this?
Because we've done an approximation, we have used
the central limit theorem.
So it might turn out to be a 95.5% confidence interval
instead of 95, because our calculations are not entirely
accurate.
But for reasonable values of n, using the central limit
theorem is a good approximation.
And that's what people almost always do, is to just take the
value from the normal tables.
OK, except for one catch.
I use the data.
I obtain my estimate.
And I want to go to my boss and report this theta minus and
theta hat, which is the confidence interval.
What's the difficulty?
I know what n is, but I don't know what sigma is, in
general.
So if I don't know sigma, what am I going to do?
Here there's a few options for what you can do.
And the first option is familiar from what we did when we
talked about the Polster problem.
We don't know what sigma is, but maybe we have an upper
bound on sigma.
For example, if the x i's are Bernoulli random variables,
we have seen that the standard deviation is at most 1 half.
So use the most conservative value for sigma.
Using the most conservative value means that you take
