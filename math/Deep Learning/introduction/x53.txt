22Which is equal to using a mini-batch of size 1.

4.7
A Complete Feedforward Neural Network
103
includes_a_book,purchase_after_21,total,user_action
1,1,13.43,1
1,0,23.45,1
0,0,45.56,0
1,1,56.43,0
1,0,44.44,0
1,1,667.65,1
1,0,56.66,0
0,1,43.44,1
0,0,4.98,1
1,0,43.33,0
This will be our dataset. You can actually substitute this for anything, and as
long as values are numbers, it will still work. The target is the user_action
column, and we take 1 to mean that the purchase was successful, and 0 to mean that
the user has abandoned the basket. Notice that we are talking about abandoning a
shopping basket, but we could have put anything in, from images of dogs to bags
of words. You should also make another CSV file named new_data.csv that has
the same structure as data.csv, but without the last column (user_action).
For example:
includes_a_book,purchase_after_21,total
1,0,73.75
0,0,64.97
1,0,3.78
Now let is continue to the Python code file. All the code in the remainder of this
section should be placed in a single file, you can name it ffnn.py, and placed
in the same folder as data.csv and new_data.csv. The first part of the code
contains the import statements:
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers.core import Dense
TARGET_VARIABLE ="user_action"
TRAIN_TEST_SPLIT=0.5
HIDDEN_LAYER_SIZE=30
raw_data = pd.read_csv("data.csv")
The first four lines are just imports, the next three are hyperparameters. The
TARGET_VARIABLE tells Python what is the target variable we wish to predict.
The last line opens the file data.csv. Now we must make the train–test split. We
have a hyperparameter that currently leaves 0.5 of the datapoints in the training set,
but you can change this hyperparameter to something else. Just be careful since we
have a tiny dataset which might cause some problems if the split is something like
0.95. The code for the train–test split is:

104
4
Feedforward Neural Networks
mask = np.random.rand(len(raw_data)) < TRAIN_TEST_SPLIT
tr_dataset = raw_data[mask]
te_dataset = raw_data[∼mask]
The first line here defines a random sampling of the data to be used to get the
train–test split and the next two lines select the appropriate sub-dataframes from
the original Pandas dataframe (a dataframe is a table-like object, very similar to
an Numpy array but Pandas focuses on easy reshaping and splitting, while Numpy
focuses on fast computation). The next lines split both the train and test dataframes
into labels and data, and then convert them into Numpy arrays, since Keras needs
Numpy arrays to work. The process is relatively painless:
tr_data = np.array(raw_data.drop(TARGET_VARIABLE,
axis=1))
tr_labels = np.array(raw_data[[TARGET_VARIABLE]])
te_data = np.array(te_dataset.drop(TARGET_VARIABLE,
axis=1))
te_labels = np.array(te_dataset[[TARGET_VARIABLE]])
Now, we move to the Keras specification of a neural network model, and its
compilation and training (fitting). We need to compile the model since we want
Keras to fill in the nasty details and create arrays of appropriate dimensionality of
the weight and bias matrices:
ffnn = Sequential()
ffnn.add(Dense(HIDDEN_LAYER_SIZE, input_shape=(3,),
activation="sigmoid"))
ffnn.add(Dense(1, activation="sigmoid"))
ffnn.compile(loss="mean_squared_error", optimizer=
"sgd", metrics=[’accuracy’])
ffnn.fit(tr_data, tr_labels, epochs=150, batch_size=2,
verbose=1)
The first line initializes a new sequential model in a variable called ffnn. The
second line specifies both the input layer (to accept 3D vectors as single data inputs),
and the hidden layer size which is specified at the beginning of the file in the variable
HIDDEN_LAYER_SIZE. The third line will take the hidden layer size from the
previous layer (Keras does this automatically), and create an output layer with one
neuron. All neurons will be having sigmoid or logistic activation functions. The
fourth line specifies the error function (MSE), the optimizer (stochastic gradient
descent) and which metrics to calculate. It also compiles the model, which means
that it will assemble all the other stuff that Python needs from what we have specified.
The last line trains the neural network on tr_data, using tr_labels, for 150
epochs, taking two samples in a mini-batch. verbose=1 means that it will print
the accuracy and loss after each epoch of training. Now we can continue to analyze
the results on the test set:

4.7
A Complete Feedforward Neural Network
105
metrics = ffnn.evaluate(te_data, te_labels, verbose=1)
print("%s: %.2f%%" % (ffnn.metrics_names[1],
metrics[1]*100))
The first line evaluates the model on te_data using te_labels and the second
