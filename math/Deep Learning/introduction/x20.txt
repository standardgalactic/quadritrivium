Of course, just as f (x, y) has a partial derivative with respect to x, it also has one
with respect to y: ∂f (x,y)
∂y
= 2(y − x). So if we have a function f taking as arguments
x1, x2, . . . , xn (or, we can say that f takes an n-dimensional vector), we would have
n partial derivatives ∂f (x1,x2,...,xn)
∂x1
, ∂f (x1,x2,...,xn)
∂x2
, …, ∂f (x1,x2,...,xn)
∂xn
. If we store them
in a vector and get
(∂f (x)
∂x1
, ∂f (x)
∂x2
, . . . , ∂f (x)
∂xn
)
We call this structure the gradient of the function f (x) and write it as ∇f (x).
To denote the i-th component of the gradient, we write ∇if (x) = ∂f (x)
∂xi ). If we have
a function f of n variables, it has to live in n + 1-dimensional space as an n + 1-
dimensional surface. This surface in 3D space is called a plane, and in four or more
dimensions it is called a hyperplane. The gradient then is simply a list of slopes in
each of the n + 1 dimensions.
Building on this idea of a gradient being a list of slopes, let us see how we can
find the minimum of an n-ary function using its gradient. Each input component of
the function is a coordinate, to which the final function maps an input coordinate
(which shows where the hyperplane given those inputs is). Since each component
of a gradient is a slope along each of the dimensions of the hyperplane, we can
subtract the gradient component from its respective input component and recalculate
the function. When we do so and feed the new values to the function, we will get a
new output, which is closer to the minimum of the function. This technique is called
gradient descent, and we will be using it often. In Chap.4, we will be providing a
full calculation for a simple case, and all of our deep learning models will be using
it to update their parameters.
Let us see an example of how function minimization with gradient descent looks
like. Suppose we have a simple function, f (x) = x2 + 1. We need to find the value of
x which shall result with the minimal f (x).19 From basic calculus, we know that this
point will be (0, 1). The gradient of f will have a single component ∇f (x) = ( ∂f (x)
∂x ),
corresponding with x.20 We start by choosing a random starting value for x, let it
be x = 3. When x = 3, f (x) = 10 and ∂f
∂x = df
dx = f ′(x) = 6. We take an additional
scaling factor of 0.3. This will make us take only 30% of the step along the gradient
we would normally take, and it will in turn enable us to be more precise in our quest
for minimization. Later, we will call this factor the learning rate, and it will be an
important part of our models.
19To get the actual f (x) we just need to plug in the minimal x and calculate f (x).
20In the case of multiple dimensions, we shall do the same calculation for every pair of xi and
∇if (x).

32
2
Mathematical and Computational Prerequisites
We will be making a series of steps towards the x which will produce a minimal
f (x) (or more precisely, a good approximation of the actual minimal point21), we will
denote the initial x by x(0), and we will denote all the other xs on the road towards the
minimum in a similar fashion. So to get x(1) we calculate x(0) − 0.3 · f ′(x(0)), or, in
numbers, x(1) = 3 − 0.3 · 6 = 1.2. Now, we proceed to calculate x(2) = x(1) − 0.3 ·
f ′(x(1)) = 1.2 − 0.3 · 2.4 = 0.48. By the same procedure, we calculate x(3) = 0.19,
x(4) = 0.07 and x(5) = 0.02 where we stop and call it a day.22 We could continue to
get better and better approximations, but we would have to stop eventually. Gradient
descent will take as closer and closer to the value of x for which the function f has the
minimal value, which is in our case x(5) ≈ argmin f (x) = 0. Note that the minimum
of f is actually 1 which we get if we plug in the argmin as x in f (x) = x2 + 1. The
interested reader may wonder what would happen if we used addition instead of
subtraction: then we would be questing for a maximum not a minimum, but all the
mechanics of the process would remain the same.
We make a short remark before moving on to statistics and probability.
Mathematical knowledge is often considered to be common knowledge and as such
it is not cited. That being said, most good math textbooks cite and provide historical
remarks about the ideas and theorems proven. As this is not a mathematical book,
we will no do that here. We will instead point the reader to other textbooks that do
give a historical overview. We suggest that the reader interested in calculus starts her
journey with [4], while for linear algebra we recommend [5]. One fantastic book that
we believe any deep learning researcher should work her way through is [6], and we
strongly recommend it.
2.3 Probability Distributions
In this section, we explore the various concepts from statistics and probability theory
which we will be needing for deep learning. We will explore only the bits we will need
for deep learning, but we point the interested reader towards two great textbooks,
viz. [7]23 and [8].
Statistics is the quintessential data analysis: it analyses a population whose mem-
bers have certain properties. All these terms will be rigorously defined later when
we introduce machine learning, but for now we will use an intuitive picture: imagine
the population to be the inhabitants of a city, and their properties24 can be height,
21Note that a function can have many local minima or minimal points, but only one global minimum.
Gradient descent can get ‘stuck’ in a local minimum, but our example has only one local minimum
which is the actual global minimum.
22We stop simply because we consider it to be ‘good enough’—there is no mathematical reason for
stopping here.
23This book is available online for free at https://www.probabilitycourse.com/.
24Properties are called features in machine learning, while in statistics they are called variables,
which can be quite confusing, but it is standard terminology.

2.3
