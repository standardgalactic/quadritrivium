Please note one interesting thing: if the first die gives a 6 and the second gives a 1,
this is one outcome, while if the first gives a 1 and the second gives a 6, this is another
outcome. Also, there is only one combination which gives 2, viz. the first die gives
a 1 and the second die gives a 1.
Now that we have an intuition behind the basic probability calculation,30 let us
turn our attention to probability distributions. A probability distribution is simply a
function which tells us how often does something occur. To define the probability
distributions, we first need to define what is a random variable. A random variable is
a mapping from the probability space to a set of real numbers, or in simple words, it is
a variable that can take random values. The random variable is usually denoted by X ,
and the values it takes are usually denoted by x1, x2, etc. Note that this ‘random’ can
be replaced by a more specific probability distribution, which gives a higher chance
for some values to occur (a lower-than-random chance for others). The simple, truly
random case is the following: If we have 10 elements in the probability space, a
random variable would assign to each the probability of 0.1. This is in fact the
first probability distribution called uniform distribution, and in this distribution, all
members of the probability space get the same value, and that value is 1
n, where n
is the number of elements. We have seen another probability distribution when we
analysed the coin toss called the Bernoulli distribution. The Bernoulli distribution
is the probability distribution of a random variable which takes the value 1 with the
probability p and the value 0 with the probability 1 − p. In our case, p = P(heads) =
0.5, but we could have equally chosen a different p.
To continue, we must define the expected value. To build up intuition, we use the
two D6 dice example. If we have a single D6 die, we have
EP[X ] = x1 · p1 + x2 · p2 + . . . + x6p6,
(2.7)
where X is the random variable and P is a distribution of X (the xs come from X
and ps belong to P). Since there are six outcomes, each one has the probability of 1
6
this becomes
Euniform[X ] = 1 · 1
6 + 2 · 1
6 + 3 · 1
6 + 4 · 1
6 + 5 · 1
6 + 6 · 1
6
(2.8)
It seems rather trivial, but if we have two D6 dice, it becomes more complex,
because the probabilities become messy, and the distribution is not uniform anymore
(recall that the probability of rolling a 5 on two D6 is not 1
36):
EnewDistribution[X ] = 2 · 1
36 + 3 · 2
36 + 4 · 3
36 + 5 · 4
36 + 6 · 5
36 + 7 · 6
36 + 8 · 5
36 + 9 · 4
36 + 10 · 3
36 + 11 · 2
36 + 12 · 1
36
(2.9)
30What we called here ‘basic probabilities’ are actually called priors in the literature, and we will
be referring to them as such in the later chapters.

36
2
Mathematical and Computational Prerequisites
Butletusseewhatishappeninginthebackgroundwhenwetalkabouttheexpected
value. We are actually producing an estimator,31 which is a function which tells us
what to expect in the future. What the future will actually bring is another matter.
The ‘reality’ (also known as probability distribution) is usually denoted often by an
uppercase letter from the back of the alphabet such as X , while an estimator for that
probability distribution is usually denoted with a little hat over the letter, e.g. ˆX . The
relationship between an estimator and the actual values we will be getting in the
future32 is characterized by two main concepts, the bias and the variance. The bias
of ˆX relative to X is defined as
BIAS( ˆX , X ) := EP[ ˆX − X ]
(2.10)
Intuitively, the bias shows by how much the estimator misses the target (on aver-
age). A related idea is the variance, which tells how wider or narrower are the
estimates compared to the actual future values:
V AR( ˆX ) := EP[( ˆX − EP[ ˆX ])2]
(2.11)
The standard deviation is defined as:
STD( ˆX ) :=
�
V AR( ˆX )
(2.12)
Intuitively, the standard deviation keeps the spread information from the variance,
but it rescales it to be directly useful.
We return now to probability calculations. We have seen how to calculate a basic
probability (prior) like P(A), but we should develop a calculus for probability. We
will provide both the set-theoretic notation and the logical notation in this section,
but later we will stick to the less intuitive but standard set-theoretic notation. The
most basic equation is the calculation of the joint probability of two independent
events:
P(A ∩ B) = P(A ∧ B) := P(A) · P(B)
(2.13)
If we want the probability of two mutually exclusive events, we use
P(A ∪ B) = P(A ⊕ B) := P(A) + P(B)
(2.14)
If the events are not necessarily disjoint,33 we can use the following equation:
P(A ∨ B) := P(A) + P(B) − P(A ∧ B)
(2.15)
31All machine learning algorithms are estimators.
