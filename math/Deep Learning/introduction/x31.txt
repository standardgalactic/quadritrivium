0
1
Dog
54
17
1
0
0
Dog
78
28
0
0
1
Dog
…
…
…
…
…
…
We conclude this section by giving a brief description of all supervised machine
learning algorithms in terms of input and output. Every supervised machine learning
algorithm receives a set of training datapoints and labels (they are row vectors). In this
phase, the algorithm creates a hyperplane by adjusting its internal parameters. This
phase is called the training phase: it receives as inputs row vectors with corresponding
labels (called training samples) and does not give any output. Instead, in the training
phase, the algorithm simply adjusts its internal parameters (and by doing so creates
the hyperplane). The next phase is called the predicting phase. In this phase, the
trained algorithm takes in a number of row vectors but this time without labels and
creates the labels with the hyperplane (depending on which side of the hyperplane
the row vectors end up). The row vectors themselves are simply rows from a table
like the one above, so the row vector which corresponds to the training sample in the
third line is simply (54, 17, 1, 0, 0, Dog). If it were a row vector for which we need
to predict a label, it would look the same except it would not have the ‘Dog’ tag in
the end.8
5Think about how one-hot encoding can boost the understanding of n-dimensional space.
6Deep learning is no exception.
7Notice that to do one-hot encoding, it needs to make two passes over the data: the first collects the
names of the new columns, then we create the columns, and then we make another pass over the
data to fill them.
8Strictly speaking, these vectors would not look exactly the same: the training sample would be
(54,17,1,0,0, Dog), which is a row vector of length 6, and the row vector for which we want to

3.2
Evaluating Classification Results
57
3.2 Evaluating Classification Results
In the previous section, we have explored the basics of classification and we left the
hard part (producing the hyperplane) largely untouched. We will address this in the
next section. In this section, we will assume we have a working classifier and we
want to see how well it behaves. Take a look at Fig. 3.4.
This image illustrates a classifier named C for classifying Xs. This is the task for
this classifier and it is important to keep this in mind at all times. The black line is the
hyperplane, and the grey region is what C considers to be the region of X. From the
perspective of C, everything inside the grey region is X, while everything outside is
not an X. We have marked the individual datapoints with X or O depending whether
they are in reality an X or O. We can see right away that the reality differs from what
C thinks and this is the usual scenario when we have and empirical classification task.
Intuitively, we see that the hyperplane makes sense, but we want to define objective
classification metrics which can tell us how good a classifier is and, if we have two
or more, which classifier is the best.
We can now define the concepts of true positive, false positive, true negative and
false negative. A true positive is a datapoint for which the classifier says it is an X
and it truly is an X. A false positive is a datapoint for which the classifier thinks it
is an X but it is an O. A true negative is a datapoint for which the classifier thinks
it is not and X and in fact it is not, and a false negative is a datapoint for which the
classifier thinks it is not an X but in fact it is. In Fig. 3.4, there are five true positives
(Xs in the grey), one false positive (the O in the grey), six true negatives (the Os in
the white) and two false negatives (the Xs in the white). Remember, the grey area
is the area where the classifier C thinks all are Xs and the white area is what the
classifier thinks all are Os.
The first and most fundamental classification metric is accuracy. Accuracy simply
tells us how good is the classifier at sorting Xs and Os. In other words, it is the
Fig.3.4 A classifier C for
classifying Xs
predict the label would have to be of length 5 (without the last component which is the label), e.g.
(47,15,0,0,1).

58
3
Machine Learning Basics
number of true positives, added to the number of true negatives and divided by the
total number of datapoints. In our case, this would be 5+6
14 = 0.785714 . . . but we
will be rounding off to four decimal points.9
We might be interested in how good is a classifier at avoiding false alarms. The
metric used to calculate this is called precision. The precision of a classifier on a
dataset is calculated by
truePositives
truePositives+ f alsePositives =
5
5+1 = 0.8333. If we are con-
cerned about missing out and we want to catch as many true Xs we can, we need
a different metric called recall to measure our success. The recall is calculated by
taking
truePositives
truePositives+ f alseNegatives =
5
5+2 = 0.7142.
