is the previous value of
the weight and wolder
i
was the value of the weight before that. μ is the momentum
rate and ranges from 0 to 1. It directly controls how much of the previous change
in weight we will keep in this iteration. A typical value for μ is 0.9, and should
be adjusted usually to a value between 0.10 and 0.99. Momentum is as old as the
last discovery of backpropagation, and it was first published in the same paper by
Rumelhart, Hinton and Williams [9].
There is one final interesting technique for improving the way neural networks
learn and reduce overfitting, named dropout. We have chosen to define regularization
as adding a regularization term to the cost function, and according to this definition
dropout is not regularization, but it does lower the gap between the training error
and the testing error, and consequently it reduces overfitting. One could define reg-
ularization to be any technique that reduces this spread, and then dropout would be
a regularization technique. One could call dropout a ‘structural regularization’ and

116
5
Modifications and Extensions to a Feed-Forward Neural Network
Fig.5.5 Dropout with π = 0.5
the L1 and L2 regularizations ‘numerical regularizations’, but this is not standard
terminology and we will not be using it.
Dropout was first explained in [10], but one could find more details about it in [11]
and especially [12]. Dropout is a surprisingly simple technique. We add a dropout
parameter π ranging from 0 to 1 (to be interpreted as a probability), and in each epoch
every weight is set to zero with a probability of π (Fig. 5.5). Returning to the general
weight update rule (where we need a wold
k
for calculating the weight updates), if
in epoch n the weight wk was set to zero, the wold
k
for epoch n + 1 will be the wk
from epoch n − 1. Dropout forces the network to learn redundancies so it is better
in isolating the necessary properties of the dataset. A typical value for π is 0.2, but
like all other hyperparameters it has to be tuned on the validation set.
5.4 Stochastic Gradient Descent and Online Learning
So far in this book, we have been a bit clumsy with one important question5: how
does backpropagation work from a ‘bird’s-eye view’. We have been avoiding this
question to avoid confusion until we had enough conceptual understanding to address
it, and now we know enough to state it clearly. Backpropagation in the neural network
works in the following way: we take one training sample at a time and pass it through
the network and record the squared error for each. Then we use it to calculate the
mean (squared) error. Once we have the mean squared error, we backpropagate it
using gradient descent to find a better set of weights. Once we are done, we have
5We have been clumsy around several things, and this section is intended to redefine them a bit to
make them more precise.

5.4
Stochastic Gradient Descent and Online Learning
117
finished one epoch of training. We may do this for as many epochs we want. Usually,
we want to continue either for a fixed number of epochs or stop it if it does not help
with decreasing the error anymore.
What we have used when explaining backpropagation was a training set of size 1
(a single example). If this is the whole training set (a weirdly small training set), this
would be an example of (full) gradient descent (also called full-batch learning). We
could however think of it as being a subset of the training set. When using a randomly
selected subset of from the training set of the size n, we say we use stochastic gradient
descent or minibatch learning (with batch size n). Learning with a minibatch of size
1 is called online learning. Online learning can be either ‘stationary’ with fixed
training set and then selecting randomly6 one by one, or simply giving new training
samples as they come along.7 So we could think of our example backpropagation
from the last chapter as an instance of online learning.
Now we are also in position to introduce a terminological finesse we have been
neglecting until now. An epoch is one complete forward and backward pass over the
whole training set. If we divide the training set of the size 10000in 10 minibatches,8
then one forward and one backward pass over a batch is called one iteration, and ten
iterations (the size of the minibatch) is one epoch. This will hold only if the samples
are divided as we stated in the footnote. If we use a random selection of training
samples for the minibatch, then ten iterations will not make one epoch. If, on the
other hand, we shuffle the training set and then divide it, then ten iterations will make
one epoch and the forces fighting for order in the universe will be triumphant once
more.
Stochastic gradient descent is usually much quicker to converge, since by random
sampling we can get a good estimate of the overall gradient, but if the minimum is not
pronounced (the bowl is too shallow) it tends to compound the problems we have seen
previously in Fig. 5.3 (the middle part) in the previous section. The intuitive reason
behind it is that when we have a shallow curvature and sample the surface randomly
we will be prone to losing the little amount of information about the curvature that
we had in the beginning. In such cases, full gradient descent couple with momentum
might be a good choice.
6We could use also a non-random selection. One of the most interesting ideas here is that of learning
the simplest instances first and then proceeding to the more tricky ones, and this approach is called
curriculum learning. For more on this see [13].
7Thisissimilartoreinforcementlearning,whichis,alongwithsupervisedandunsupervisedlearning
one of the three main areas of machine learning, but we have decided against including it in this
volume, since it falls outside of the the idea of a first introduction to deep learning. If the reader
wishes to learn more, we refer her to [14].
8Suppose for the sake of clarification it is non-randomly divided: the first batch contains training
samples 1 to 1000, the second 1001 to 2000, etc.

118
5
Modifications and Extensions to a Feed-Forward Neural Network
5.5 Problems for Multiple Hidden Layers:Vanishing
and Exploding Gradients
Let us return to the calculation of the fully functional feed-forward neural network
from the last chapter. Remember it was a neural network with the configuration
(2, 2, 1), meaning it has two input neurons, two hidden neurons9 and one output
