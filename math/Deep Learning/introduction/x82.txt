w23 = −3
Hopfield networks have a global measure of success, similar to the error function
of regular neural networks, called the energy. Energy is defined for each stage of
network training as a single value for the whole network. It is calculated as:
E N E = −
�
i, j
wi j yi y j +
�
i
bi yi
(10.3)
The as learning progresses, E N E either stays the same or diminishes, and this
is how Hopfield networks reach local minima. Each local minimum is a memory
of some training samples. Remember logical functions and logistic regression? We
needed two input neurons and one output neurons for conjunction and disjunction,
and an additional hidden one for XOR. We need three neurons in Hopfield networks
for conjunction and disjunction and four for XOR.
The next model we briefly present are Boltzmann machines first presented in
1985 [2]. At first glance, they are very similar to Hopfield networks, but have input
neurons and hidden neurons as well, which are all interconnected with weights.
These weights are non-recurrent and symmetrical. A sample Boltzmann machine
is displayed in Fig. 10.2a. Hidden units are initialized at random, and they build a
hidden representation to mimic the inputs. These form two probability distributions,
which can be compared with the Kullback-Leibler divergence KL. The main goal
then becomes clear, calculate ∂KL
∂w , and backpropagate it.

10.1 Energy-Based Models
177
Fig.10.2 Boltzmann machines and restricted Boltzmann machines
We turn to a subclass of Boltzmann machines, called restricted Boltzmann
machines (RBM)[3]. Structurally speaking, restricted Boltzmann machines are just
Boltzmann machines where there are no connections between neurons of the same
layer (hidden to hidden and visible to visible). This seems like a minor point, but
this actually makes it possible to use a modification of the backpropagation used in
feed-forward networks. The restricted Boltzmann machine therefore has two layers,
a visible, and a hidden. The visible layer (this is true for Boltzmann machines in
general) is the place where we put in inputs and read out outputs. Denote the inputs
with xi, the biases of the hidden layer with b[h]
j . Then, during the forward pass (see
Fig. 10.2b), the RBM calculates y = σ(x⊤w + b[h]). If we were to stop here, RBMs
would be similar to autoencoders, but we have a second phase, the reconstruction
(see Fig. 10.2c). During the reconstruction, the y are fed to the hidden layer and then
passed to the visible layer. This is done by multiplying them with the same weights,
and adding another set of biases, i.e. r = y⊤w + b[v]. The difference between x and r
is measured with KL and then this error is used in backpropagation. RBMs are frag-
ile, and every time one gets a nonzero reconstruction, this is a good sign. Boltzmann
machines are similar to logical constraint satisfaction solvers, but they focus on what
Hinton and Sejnowski called ‘weak constraints’. Notice that we moved away quite
a bit from the energy function, and well back into standard neural network territory.
The final architecture we will briefly discuss is deep belief networks (DBN), which
are just stacked RBMs. They were introduced in [4] and in [5]. They are conceptu-
ally similar to stacked autoencoders, but they can be trained with backpropagation
to be generative models, or with contrastive divergence. In this setting, they may
be even used as classifiers. Contrastive divergence is simply an algorithm that effi-
ciently approximates the gradients of the log-likelihood. A discussion on contrastive
divergence is beyond the scope of this book, but we point the interested reader to [6]
and [7]. For a discussion about the cognitive aspects of energy-based models, see
[8].

178
10
An Overview of Different Neural Network Architectures
10.2 Memory-Based Models
The first memory-based model we will explore are neural Turing-machines (NTM)
first proposed in [9]. Remember how a Turing-machine works: you have a read-write
head and a tape which acts as a memory. The Turing-machine then is given a function
in the form of an algorithm and it computes that function (takes in the given inputs
and outputs the result). The neural Turing-machine is similar, but the point is to have
all components trainable, so that they can do soft computation, and they should also
learn how to do it well.
The neural Turing-machine acts similarly to an LSTM. It takes input sequences
and outputs sequences. If we want it to output a single result, we just take the last
component and discard everything else. The neural Turing-machine is built upon
an LSTM, and can be seen as an architecture extending the LSTM similarly how
LSTMs builds upon simple recurrent networks.
A neural Turing-machine has several components. The first one is called a con-
troller, and a controller is simply an LSTM. Similar to an LSTM, the neural Turing-
machine has a temporal component, and all elements are indexed by t, and the state of
the machine at time t takes as inputs components calculated at t − 1. The controller
takes in two inputs: (i) raw inputs at time t, i.e. xt and (ii) results of the previous step,
rt. The neural Turing-machine has another major component, the memory, which is
just a tensor denoted by Mt (it is usually just a matrix). Memory is not an input to
the controller, but it is an input to the step t of the whole neural Turing-machine (the
input is Mt−1).
The structure of a complete neural Turing-machine is shown in Fig. 10.3, but
we have omitted the details.1 The idea is that the whole neural Turing-machine
should be expressed as tensors, and trainable by gradient descent. To enable this,
all crisp concepts from regular Turing-machines are fuzzified, so that there is no
single memory location which is accessed in separation, but all memory locations
are accessed to a certain degree. But in addition to the fuzzy part, the amount of the
accessed memory is also trainable, so it changes dynamically.
To reiterate: the neural Turing-machine has an LSTM (controller) which receives
the outputs from the previous step, and a fresh vector of inputs, and uses them and
a memory matrix to produce outputs and everything is trainable. But how do the
components work? Let us now work our way from the memory upward. We will be
needing three vectors, all of which the controller will produce: add vector at, erase
vector et, and weighting vector wt. They are similar but used for different purposes.
We will be coming back to them later to explain how they are produced.
