only axes x and z and we drop a marble. We want our gravity to behave like physical
gravity in the sense that it will automatically generate the direction the marble has to
move (looking from the top, the x and z view) so that it moves along the curvature
of the bowl which is, hopefully, the direction of the bottom of the bowl (the global
minimum value for y).
We want it to be different to physical gravity so that the amount of movement in
this direction is not determined by the exact position of the minimum for y, i.e. it does
not settle in the bottom but may move on the other side of the bowl (and remains there
as if it became a sticky object again). We leave the amount of movement unspecified
at the moment, but assume it is rarely the exact amount needed to reach the actual
minimum: sometimes it is a bit more and it overshoots and sometimes is a bit less and
it fails to reach it. One very important point has to be made here: the curvature ‘points’
at the minimum, but we are following the curvature at the point we currently are,
and not the minimum. In a sense, the marble is extremely ‘short-sighted’ (marbles
usually are): it sees only the current curvature and moves along it. We will know we
have found the minimum when we have the curvature of 0. Note that in our example
we have an ‘idealized bowl’, which has only one point where the curvature is 0, and
that is the global minimum for y. Imagine how many more complex surfaces there
might be where we cannot say that the point of curvature 0 is the global minimum,
but also note that if we could have a transformation which transforms any of these
complex surfaces into our bowl we would have a perfect learning algorithm.
Also, we want to add a bit of imprecision, so imagine that the direction of our
gravity is the ‘general direction’ of the curvature of the bowl—sometimes a bit to the
left, sometimes a bit to the right of the minimum, but only on rare occasions follows
precisely the curvature.
Now we have the perfect setting for explaining learning in the abstract sense.
Each epoch of learning is one move (of some amount) in the ‘general direction’ of
the curvature of the bowl, and after it is done, it sticks where it is. The second epoch

114
5
Modifications and Extensions to a Feed-Forward Neural Network
‘unfreezes’ the situation, and again the general direction towards of the curvature is
followed. this second move might either be the continuation of the first, or a move
in an almost opposite direction if the marble overshot the minimum (bottom). The
process can continue indefinitely, but after a number of epochs the moves will be
really small and insignificant, so we can either stop after a predetermined number of
epochs or when the improvement is not significant.3
Now let us return to the learning rate. The learning rate controls how much of the
amount of movement we are going to take. A learning rate of 1 means to make the
whole move, and a learning rate of 0.1 means to make only 10% of the move. As
mentioned earlier, we can have a global learning rate or parametrized learning rate
so that it changes according to certain conditions we specify such as the number of
epochs so far, or some other parameter.
Let us return a bit to our bowl. So far we had a round bowl, but imagine we have
a shallow bowl of the shape of an elongated ellipse (Fig. 5.3). If we drop the marble
near the narrow middle, we will have almost the same situation as before. But if
we drop it on the marble at the top left portion, it will move along a very shallow
curvature and it will take a very large number of epochs to find its way towards the
bottom of the bowl. The learning rate can help here. If we take only a fraction of the
move, the direction of the curvature for the next move will be considerably better
than if we move from one edge of a shallow and elongated bowl to the opposing
edge. It will make smaller steps but it will find a good direction much more quickly.
This leaves us with discussing the typical values for the learning rate η. The values
most often used are 0.1, 0.01, 0.001, and so on. Values like 0.03 will simply get lost
and behave very similarly to the closest logarithm, which is 0.01in case of 0.03.4
The learning rate is a hyperparameter, and like all hyperparameters it has to be tuned
on the validation set. So, our suggestion is to try with some of the standard values
for a given hyperparameter and then see how it behaves and modify it accordingly.
We turn our attention now to an idea similar to the learning rate, but different
called momentum, also called inertia. Informally speaking, the learning rate controls
Fig.5.3 Learning rate
3This is actually also a technique which is used to prevent overfitting called early stopping.
4You can use the learning rate to force a gradient explosion, so if you want to see gradient explosion
for yourself try with an η value of 5 or 10.

5.3
Learning Rate,Momentum and Dropout
115
Fig.5.4 Local minimum
how much of the move to keep in the present step, while momentum controls how
much of the move from the previous step to keep in the current step. The problem
which momentum tries to solve is the problem of local minima. Let us return to our
idea with the bowl but now let us modify the bowl to have local minima. You can
see the lateral view in Fig. 5.4. Notice that the learning rate was concerned with the
‘top’ view whereas the momentum addresses problems with the ‘lateral’ view.
The marble falls down as usual (depicted as grey in the image) and continues along
the curvature, and stops when the curvature is 0 (depicted by black in the image). But
the problem is that the curvature 0 is not necessarily the global minimum, it is only
local. If it were a physical system, the marble would have momentum and it would
fall over the local minimum to a global minimum, there it would go back and forth a
bit and then it would settle. Momentum in neural networks is just the formalization
of this idea. Momentum, like the learning rate is added to the general weight update
rule:
wnew
i
= wold
i
− η ∂E
∂wold
i
+ μ(|wold
i
− wolder
i
|)
Where wnew
i
is the current weight to be computed, wold
i
