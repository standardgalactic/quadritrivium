The ability to find solvable ML problems
First, hardware has continued to progress on an exponential curve for many decades. While Moore’s law might cease very soon to be valid in its current form [5], the explosive development of hardware capabilities—processing speed, data storage capacity—has made ML possible at scale. Second, data is everywhere around us, to the point where in some applications it is no longer possible to even store the data, and one has to resort to stream processing. So the raw material for machine learning—large amounts of data—is copiously available thanks to physical sensory devices that transform the dynamics of our world into electric signals. Third, ML has a strong grounding in existing formal methods, Mathematics and Statisticschief among them. The availability of many statistical techniques thus can turn large amounts of data into patterns and other types of useful information. This is not without caveats and dangers, as data biasor assumptions about statistical distributions exemplify, but it has allowed decent progress on learning language, image classification, text processing etc. Finally, it was critical to restrict targets for ML to solvable problems. As technology progressed, the front of solvable problemswas continuously expanding, from early game learning, to the most difficult games like Chess and Go today, just to name the class of board games. In many other categories of problems, a similar trajectory was followed by ML researchers.
Evolutionary Computation (EC), much like machine learning, has an extensive history. In 1957, Fraser [34] simulated a genetic system using a computer, which is likely to be the first evolutionary algorithm. Friedberg’s work in 1958 [35] is acknowledged as the first application of an evolutionary approach to program solving, specifically automated programming. By the 1960s, most of the foundations of what we now know as EC were already laid. Fogel et al. introduced Evolutionary Programming as an alternative to classical AI between 1962 and 1966 [30, 31]. Concurrently, Holland presented Genetic Algorithms in 1962 [45], while Rechenberg et al. developed Evolution Strategies in 1965 [83]. The fourth cornerstone for EC was only laid in 1989, when Koza invented Genetic Programming in 1989 [54].
These fields of research remained independent until the early 1990s, when the efforts to promote collaboration between these different tribes paid off, resulting in the establishment of scientific events that welcomed contributions from all these streams. Created in 1991, ‘Parallel Problem Solving from Nature’ (PPSN) is the most notable example of this trend. By 1993 the term ‘Evolutionary Computation’ had gained recognition, and a journal with the same name was created. The merge of conferences dedicated to independent tribes gave rise to ‘Genetic and Evolutionary Computation Conference’ (GECCO) and ‘IEEE Congress on Evolutionary Computation’ (IEEE CEC) that encompass any flavor of EC and many other EC conferences have arisen.
The main contributions that Evolutionary Computation can bring to ML, thus leading to the field of Evolutionary Machine Learningare, first, its ability to create novel and, therefore, unforeseen solutions to ML problems. The element of surprise is enabled by the stochastic nature of these algorithms, which allows solutions to emerge from noisy beginnings, under the guidance of selection. Second, the inherent stochasticity in producing solutions can generate more robust solutions, solutions that can persist in the presence of noise. While again stochasticity is a key contributor to this feature, the fact that normally populations of solutions are considered in EC contributes substantially to this strength. Third, the unforeseen character of many solutions can be used to discover logical flaws in systems and tools designed by humans or other algorithms. It is well known that evolution exploits all kinds of shortcuts if it is able to discover them. That frequently leads to surprising results, uncovering untested or unforeseen loopholes in the human designs [58]. Finally, because evolution can be used very well to optimize processes, it brings to the table an ability to streamline systems. By not only targeting the accuracy of a solution, but also simplicity, speed of achievement, or other efficiency measures in a multi-objective setting, EML can serve multiple purposes at the same time [17, 61].
The promise of Evolutionary Machine Learning is thus that it can lead to better solutions faster, while exhibiting a surprising ability to come up with creative and robust features of these solutions. These are characteristics that every machine learning algorithm should strive to possess.
We now want to step back for a moment and consider how to define EML.
1.2 A Definition of Evolutionary Machine Learning
A definition of Evolutionary Machine Learning (EML) has to look at all three ingredients to the term—evolution, machine and learning. From a distant point of view, EML is a method of adaptation, where we understand ‘adaptation’ as the continuous improvement of a system’s performance over time and with experience. By improved performance we mean that the system is able to react to its environment in a more appropriate way over time. There are other types of adaptation, like the adaptation of organisms to environmental trends (‘epigenetic adaptation’), or the adaptation of defense mechanisms of an organism in its immune system to outside attacks. But here we want to focus on evolution and learning as the main components of adaptation under consideration.
What, then, do we understand under evolutionary adaptation? Evolutionary adaption is adaptation governed by the evolutionary principles of inheritance and cumulative selection of beneficial variations in individuals. Thus, it is fundamentally a process that takes place over generations of individuals, i.e., on a timescale whose smallest unit is the expected lifetime of an individual. This should be seen in contrast to the adaptive processes in learning [71], where the timescale of the adaptive process is much shorter, as learning has to take place withinthe lifetime of an individual. Learning is an extension of adaptive processes effective in organisms that are provided with the necessary pre-requisite ‘hardware’ which comes about by evolution and development.
What is a machine? There are various definitions and some scholars count even organisms as machines [96]. Here we want to define a machine as an artificial (‘man-made’) system that can perceive its environment in some way and can act on it. The emphasis is on the fact that a machine can act, which requires the ability to adjust its complexity (both for behavior and for the processing of input information). It is a system, i.e., it can only work in its entirety. While it has parts that might or might not be necessary, the assembly of the parts in itself does not constitute the machine. It requires, in addition, some dynamics that we can call its behavior and which comes about only if the parts interact appropriately. In some sense, it is a weak emergent process [9] that leads to the function/behavior of the machine.
And what do we want to understand under the term ‘learning’? Learning is the adaptation that an organism exhibits over its lifetime. Transferred into the realm of artifacts, it is the adaptation of the behavior of an agent over its existence. Learning requires a number of functionalities that can be listed as follows: 
1.
Input (data from sensors or other devices)
2.
Output (actions/behaviors exerted on the environment or itself)
3.
Feedback from the environment (external)
4.
Error/value measurements (internal)
5.
Flexibility to change the interaction of its parts
6.
An improvement (or even optimization) algorithm that enables adaptation
Learning is one of the most fascinating abilities of living organisms and has for a long time been an inspiration for engineers and tinkerers. It is also the fastest and most efficient way organisms can adapt to their environment.
If we now put the definition together, we can say: The field of Evolutionary Machine Learning concerns itself with the application of evolution to Machine Learning problems and methods and the application of machine learning to evolutionary computation (problems and) methods.
1.3 A History of EML
In this section we lay out a historical timeline of some of the contributions that played an important role in the emergence and development of EML. These events are presented chronologically in Figs. 1.1, 1.2and 1.3
1.3.1 EC Applied to ML Methods
We shall start with the development of evolutionary computation principles being applied to ML methods. This history really begins with Turing’s essay on computers and intelligence [101] (see Fig.  1.1). Turing argues that a key part of intelligence is the ability to make errors. In fact, in a presentation at a radio program Turing [102] had clear words about this:
My contention is that machines can be constructed which will simulate the behavior of the human mind very closely. They will make mistakes at times, and at times they may make new and very interesting statements, and on the whole, the output of them will be worth attention to the same sort of extent as the output of a human mind.
He also introduces the idea of random elements into consideration when discussing intelligent machines, saying:
There is, however, one feature that I would like to suggest should be incorporated in the machines, and that is a ‘random element’. Each machine should be supplied with a tape bearing a random series of figures, e.g., 0 and 1 in equal quantities, and this series of figures should be used in the choices made by the machine. This would result in the behavior of the machine not being by any means completely determined by the experiences to which it was subjected, and would have some valuable uses when one was experimenting with it.
This latter point, that a stochastic element is necessary to provide some type of creative solutions has therefore been identified at the beginning of AI by one of the pioneers of computing as being an important element.
Friedberg [35] in 1958 then uses random variations in his algorithms to produce a variety of responses. Tragically, Friedberg missed the second important ingredient when using randomness selection. So when Samuel worked on his Checkers program which is the first demonstration of the power of ML [87], he was emphasizing this aspect of selection more than the aspect of randomness (he provided highly structured systems to make progress toward playing Checkers).
But it was the combination of randomness and selection, variation and cumulative selection, that made evolutionary principles available for ML. Fogel and co-workers proposed as material for evolution finite state machines, automata that at the time were the predominant way to formalize computing methods. In their seminal contribution [30, 31] they introduce a system that can be used to discern and react to time seriesof states.
Fig. 1.1
Timeline of the application of EC techniques to ML methods—Part 1
Fig. 1.2
Timeline of the application of EC techniques to ML methods—Part 2
Fig. 1.3
Timeline of the early applications of EC techniques to classical ML problems
While Holland more or less at the same time conceptualized the genetic algorithm [46], a key contribution of Holland to machine learning was rule-based systems.
under evolution [47], what later would become ‘learning classifier systems’. Rules here were composed of condition/action pairs, with the condition having to be fulfilled for the action to be taken.
Then, from the mid-1980s to the early 1990s, Genetic Programming was invented and established. First, it appeared rather inconspicuously at the ICGA conference [18], already in two different representations. But the importance of these proposals was first not recognized, and only became established with John Koza’s work later in the 1980s [54] and early 1990s [55, 56], in particular with Koza’s seminal book on Genetic Programming.
During the same time, neural networks were examined more closely in connection with genetic approaches. Montana and Davis [69] and Chalmers [16] are concerned with the training of neural networks, either the error reduction process or the invention of learning rules. Phanendra et al. [77] use GAs to evolve centroidpositions in a K-means clustering algorithm. At around the same time, the concept of evolutionary neural networks, or neuroevolutionis introduced by Yao [108].
Further ideas were developed around the same time, like Gruau’s method to grow neural network by a kind ofdevelopmental process [41] or Sims’ seminal work on hybridizing evolution with neural networks for behavioral control of virtual creatures[91, 92].
Further developments are listed in Fig.  1.2
1.3.2 EC Applied to ML Problems
Besides the merging of methods from EC and ML, EC has also been applied to typical ML problems, which could be termed another branch of EML (see Fig.  1.3).
Clustering was first as a task where an evolutionary approach was considered [81]. This happened in 1979, at a time when genetic algorithms were not yet widely known, though Holland’s book was already published a few years earlier [46]. Then, in a quick succession of developments, evolutionary computation methods were tried out on classical tasks like classification [32] and regression [52].
Goldberg’s thesis is likely the first to apply GAs to dynamic systems control problems [38]. Evolutionary robotics in the form of first EC algorithms applied to adaptation tasks for robots was introduced in 1985 [99]. Another pioneer in GAs, Schaffer, proposes more complex data structures to address multiclass pattern discrimination [88].
Broader areas of application of EC were examined by Englander [27] who examined computer vision tasks, and Koza [55, 56] who showed that several classical tasks can be solved by Genetic Programming. It was thus emphasized and explained that GP is a technique [7, 56].
Then in the early 1990s, reinforcement learningwas hybridized with evolution [1]. From the 1990s onward, one after the other of typical ML tasks was subjected to EC examination, often showing surprising performance.
1.4 A Taxonomy of EML
In this section, we introduce a taxonomy for EML based on our analysis and understanding of the field. More than aiming at classifying algorithms and approaches in rigid categories, we aim at providing a structured perspective that guides newcomers and experienced practitioners, and should contribute to the discovery of related work and the identification of new research opportunities. Furthermore, we recognize that alternative classification schemes and gray areas may exist (see, e.g., [2, 98]). We divide our classification into three main categories: 
1.
The use of EC to enhance, support, expand, or amplify ML methods;
2.
The reciprocal, employing ML techniques to enhance, support, expand, or amplify EC methods;
3.
The application of EC to problems typically considered ML problems and traditionally solved by other ML approaches;
These categories are addressed, respectively, in the following subsections.
1.4.1 EC for ML Methods
In this section we focus on the contributions of EC in the context of ML approaches. These are summarized in Fig. 1.4
Fig. 1.4
EC for ML methods
At the initial level of analysis, we examine the stage of the ML pipeline where EC plays a role: (i) Data or Input for the ML algorithm, (ii) the ML algorithm itself, (iii) and the resulting outcome.
Specifically focusing on the ‘Data/Input’ stage, we further categorize it into ‘Data Preparation’ and ‘Data Transformation’, acknowledging that the boundary between these subcategories may sometimes be blurry. Data preparation tasks typically involve filtering, cleaning, selection, anonymization, balancing, and other forms of preprocessing such as missing dataimputation. On the other hand, data transformation involves processes like feature selection, feature construction(including feature extraction), data augmentation, and dimensionality reduction
The application of EC to ML algorithms offers numerous and diverse opportunities. Here we identify three key levels of application: ‘parameter,’ ‘topology,’ and ‘learning algorithm.’ At the ‘parameter’ level, the goal is to optimize the parameters or coefficients of a given model with a predetermined structure/topology. At the ‘topological’ level, no predefined model structure exists. The objective is to automatically learn an adequate model structure/topology for a given problem. Lastly, at the ‘learning algorithm’ level, the task involves either selecting or developing an algorithm capable of learning and optimizing the model’s topology, parameters, or a combination of both.
Examples of hybridization at the ‘parameter’ level encompass the evolutionary optimization of neural network weights and hyperparameters. The ‘topological’ level includes the area now known as Neural Architecture Search (NAS). Lastly, at the ‘learning algorithm’ level, we can consider applications such as the evolution of the weight update function, loss function, and reward function. When focusing solely on neural networks, the techniques discussed at the ‘parameter’ and ‘topological’ levels are collectively known as neuroevolution
While our examples lean toward connectionist approaches due to their current popularity and relevance of neuroevolution, it is important to note that EC has also been applied successfully to other ML algorithms. For instance, at the ‘parameter’ level, parameterization can be applied to tree classifiers (e.g., number of levels, node split criteria), clustering algorithms (e.g., centroidinitialization, cluster number selection), and the optimization of hyperparameters in Support Vector Machines (e.g., choice of kernel type, kernel parameters, and regularizationparameter).
At the ‘topological’ level we can mention the evolution of kernel functions and support vector selection, as they impact the structure of the space. However, we acknowledge that these can also be seen as interventionsat the ‘algorithm’ level. Examples of EC applications at the ‘learning algorithm’ level include the evolution of linkage criteria, distance metrics, and node split functions.
The application of EC to the ‘Results/Output’ of ML algorithms is less common than its application to the ‘data/input’ or ‘ML algorithm’. Nonetheless, we identified several opportunities and examples of application, including:
Using EC to analyze the results of ML methods, such as evaluating their robustness by generating adversarial examplesthat aim to exploit vulnerabilitiesin ML models, helping auditors to identify potential weaknesses, understand the limitations, and assess its susceptibility to adversarial attacks.
Use EC to select among several results of ML algorithms, e.g., optimize the creation of ensembles by evolving diverse combinations of base ML models;
Optimizing or fine-tuning the results of ML by EC methods;
Validating ML solutions by generating novel test instances;
Creating EC gray-box or white-box surrogate models for the behavior of black-box ML models;
Contributing to ‘auditing’ ML applications for trustworthy AI, e.g., evaluating the fairness of ML models by evolving instances that represent different demographic groups or protected attributes, contributing to the identification of potential biases or disparities in how the model treats different groups.
1.4.2 ML for EC Methods
While in the previous subsection, we focused on the application of EC in non-evolutionary ML pipelines, our focus now shifts to the use of ML algorithms within EC approaches.
Fig. 1.5
ML for EC methods
We identify three primary levels of ML application in the context of EC: parameterization of the EC method, selection or replacement of specific EC algorithm components, and processing of the results. Fig. 1.5provides an overview of this classification.
When it comes to the parameterization of EC, ML can be employed to determine the values for various parameters and hyperparameters. This may include selecting appropriate crossover and mutation rates, determining the population and tournament sizes, making choices regarding operator selection, population structure, or even EC algorithm selection (e.g., deciding based on the characteristics of the problem which EC variant to use). In most cases, the parameterization is performed offline before the beginning of the runs. However, the online adaptation of EC parameters and hyperparameters by ML means is a promising opportunity for hybridization.
The use of ML techniques to replace or adapt specific components of an EC approach is promising. We identify four key types of components: ‘Operators,’ ‘Population Management,’ ‘Fitness’ and ‘Selection.’
For the ‘Operators’ component, there are several opportunities where ML can be applied, including:
Learning to perform crossover and mutation using techniques such as reinforcement learning;
Developing repair operators that can correct invalid phenotypes generated during the evolutionary process;
Learning genotype to phenotype mapping schemes, which can promote evolvability;
Employing ML algorithms as local search operators, for instance using Adam as a local search operator when exploring a latent spacethrough evolutionary means;
Population management also offers several opportunities for ML use, including:
Using ML solutions as seeds or selecting previously evolved solutions to initialize new runs, improving the starting point of the evolutionary run.
Controlling migration of individuals in multi-population EC models, determining when and how individuals are transferred between populations.
Regulating population diversity, promoting a balance between exploration and exploitation.
Determining the replacement strategy, optimizing the selection and replacement of individuals.
The most common application of ML in EC is fitness assignment. A typical scenario is using ML to learn an objective function that is difficult to formally express, such as subjective or esthetic criteria. The ML model is then used to assign fitness. Another scenario arises when the exact objective function exists but is too computationally expensive, prompting the use of ML methods to approximate its value for fitness assignment. When the ML models are also too costly, surrogate modelscan be employed as approximations.
The automated design of fitness functions is an area that holds great promise but remains relatively unexplored. Recent advancements in Large Language Modelsoffer exciting possibilities. For instance, one notable application is using CLIP [80] to calculate the cosine similaritybetween a natural language prompt and an evolved image, and using this similarityas a fitness measure.
It is important to acknowledge that using an ML model for fitness assignment has its limitations. Most notably, EC algorithms tend to exploit shortcomings of an ML model, maximizing fitness without necessarily improving the desired objective function. This issue has been consistently reported since the early days of EML and persists in the Deep Learning era [6, 70, 94].
