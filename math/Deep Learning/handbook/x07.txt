(2)
Cognizant AI Labs, San Francisco, CA  94501, USA
Risto  Miikkulainen
Email: risto@cs.utexas.edu
Abstract
This chapter provides an overview of evolutionary approaches to supervised learning. It starts with the definition and scope of the opportunity, and then reviews three main areas: evolving general neural network designs, evolving solutions that are explainable, and forming a synergy of evolutionary and gradient-based methods.
2.1 Introduction
In supervised learning problems, in principle, the correct answers are known for each input. In the most general sense, the learner has access to a supervisor who tells what needs to be done for each input; in practice, such information is collected into a dataset ahead of time and sampled during the learning, and the dataset may be noisy and incomplete. The challenge in supervised learning is to construct a model that accurately predicts the outputs for new samples that are not in the dataset. Thus, the model imitates known behavior in a way that generalizes to new situations as well as possible (Fig. 2.1).
Fig. 2.1
A general setup for supervised learning.Each input example in the dataset is pairedwith the desired output . The dataset is split into a training set that is used to modify the model over time, a validation set that is used to decide which model to choose as the final result of learning, and a test set that is used to estimate performance of the model on future examples. The system thus learns a model that imitates the known behavior and generalizes to future situations as well as possible
Examples of supervised learning include classifying objects in visual images; diagnosing pathologiesin X-rayimages; predicting the next word in a stream of text; predicting future values of stocks; predicting the weather. Given that data is now collected routinely across various human activities in business, healthcare, government, education, and so on, many opportunities exist for using supervised learning in the real world.
The standard approach is gradient descent on neural networks, i.e., making small changes to the network weights (or parameters) in order to reduce the error (or loss) on known examples as quickly as possible. This approach has been commonplace since the 1980s [69]. However, given a million-fold increase in computing power from just a couple of decades ago [67], it has recently become possible to scale supervised learning techniques to much larger datasets and architectures. Much of the power of modern supervised learning lies in this scale-up [11]. While the basis for this success still needs to be understood better, it has already revolutionized the field of artificial intelligence.
Evolutionary machine learning constitutes a distinctly different approach to supervised learning. It is not an incremental improvement method based on gradients, but instead a search method guided by fitness feedback, or reinforcement. It is therefore more general, but also cannot as naturally take advantage of massive datasets as gradient-based methods can. On the other hand, many domains in the real world do exist where such a scale-up is not possible. Datasets are sometimes very specific to the application (e.g., in a business domain, or medicine, or engineering design) and consist of thousands, instead of millions, of samples. In such domains, evolutionary supervised learning can provide two advantages, leading to two opportunities for advancing supervised machine learning.
The first opportunity is to take into account other goals than simply accuracy, i.e., to evolve general neural network designs. Note that a supervised signal (i.e., a gradient vector), can be converted to a fitness signal (i.e., a scalar, such as a norm of the gradient). Specific information will be lost; on the other hand, it is then possible to combine the accuracy goal with other goals. For instance, the networks evolved can be small enough to be transparent. It may be possible to improve regularizationin such networks at the same time. Such networks can potentially take better advantage of minimal computing resources, and even fit better to hardware constraints
The second opportunity is explainability. That is, gradients are inherently opaque, and machine learning systems based on them are essentially black boxes. This opaqueness makes it difficult to deploy them in many applications in the real world. For instance, in domains like health care and finance, it is important to be able to verify that the information used to draw the conclusion was relevant, unbiased, and trustworthy. In contrast, evolutionary machine learning can be used to discover solutions that are transparent. For instance, a solution can be represented in terms of decision trees, classifiers, programs, and rule sets.
A third opportunity for evolutionary supervised learning has emerged with the scale-up itself. Deep learning systems have become extremely large and complex, with many elements that interact nonlinearly. Like in many areas of system design, it is no longer possible for humans to design them optimally. However, evolutionary metalearning can be used to configure the architectures, hyperparameters, loss functions, activation functions, data selection and augmentation, and even learning methods so that the resulting deep learning models perform as well as possible. In this manner, it is possible to use evolution synergetically with gradient descent. Such automatic machine learning makes deep learning systems accessible to more people, and the designs can be optimized for size and data, making it possible to apply it more broadly.
These three opportunities will each be reviewed in the sections that follow.
2.2 Evolving General Neural Network Designs
In evolving general neural network designs, gradient descent is replaced entirely with evolutionary optimization. Fitness is still at least partially based on the loss or accuracy on the supervised dataset, but only as a scalar value. Most importantly, evolution can be used to optimize other aspects of the design at the same time, such as explainability(e.g., through complexification), size (e.g., to improve regularization, or to fit within computational constraints), of hardware fit more generally (e.g., using threshold units or other non-differentiable components). These benefits currently apply to compact neural networks but could extend to deep learning as well.
2.2.1 Compact Neural Networks
Neural networks have evolved for a long time, starting from the direct approaches of [54]. Most of the techniques were developed for sequential decision tasks, especially those that are POMDP (Partially Observable Markov Decision Processes), i.e., tasks where the state is not fully observable and where recurrency thus matters. However, they can be used in supervised learning as well.
One example is the NEAT method [58, 80], which optimizes both the architecture and the weights of a neural network. The main idea is to start small and complexity, which results in compact networks that are possible to understand. NEATstarts with a population of networks where the inputs are connected directly to the outputs. As evolution progresses, hidden nodes and recurrent as well as feedforward connections are added. Such architectural innovationsare protected through specialization, i.e., they do not have to compete with other architectures until their parameters have been sufficiently optimized. Each innovation receives a unique identifier that allows taking advantage of crossover even among population of diverse architectures. As a result, NEATevolves compact architectures where every complexification isevaluated and found useful or not.
Such compact networks are very different from deep learning networks in that they often employ principled and interpretable designs. For instance, in a combined foraging–pursuit–evasion task of simulated Khepera robots [81], evolution first discovered a simple follow-the-opponent behavior that was often successful by chance: The agent occasionally crashed into the opponent when it had more energy than the opponent (Fig. 2.2a). It then evolved a hidden node that allowed it to make an informed switch between behaviors: Attack when it had high energy, and rest when it did not (Fig. 2.2b). Another added node made it possible to predict the agent’s own and its opponent’s energy usage from afar and attack only when victory was likely (Fig. 2.2c). The most complex strategy, with several more nodes and complex recurrent connections between them, allowed the agent to predict also the opponent’s behavior, encourage it to make mistakes, and take advantage of the mistakes to win (Fig. 2.2d).
Fig. 2.2
Evolutionary Discovery through ComplexificationAs the NEAT neuroevolution method [80] complexifies networks, the behaviors that these networks generate become more complex as well. It is thus possible to identify how the network generates the behavior it does. In the simultaneous pursuit–evasion–foraging task for simulated Khepera robots, the approach discovered aopponent following, bbehavior selection, copponent modeling, and dopponent control through several such complexificationsteps [81]. Nodes are depicted as red squares and numbered in the order they were created. Positive connections are black and negative are blue, recurrent connections are indicated by triangles, and the width of the connection is proportional to its strength. Complexifying evolution thus provides a way of understanding network performance.
Figures from [78]
Although this example illustrates a sequential decision task, the same principles apply to supervised learning with NEAT. Note that these principles are very different from those in deep learning. Performance with very large networks is based on overparameterization where individual components perform only minimal operations: for instance, the residual modulein ResNet architectures combines bypassing the module with the transformation that the module itself computes [32]. In contrast, in NEATevery complexificationis there for a purpose that can in principle be identified in the evolutionary history. It thus offers an alternative solution, one that is based on principled neural network design.
This kind of compact evolved neural network can be useful in four ways in supervised learning:
1.
They can provide an explainable neural network solution. That is, the neural network still performs based on recurrency and embeddings, but its elements are constructed to provide a particular functionality, and therefore its behavior is transparent [1, 38, 40, 81].
2.
They can provide regularized neural network solutions, instead of overfitting to the dataset. The networks are compact, which generally regularization[19, 57, 66], and they are chosen based on their overall performance instead of fine-tuned to fit individual examples. This property should be particularly useful when the datasets are relatively small, which is the case in many practical applications. Thus, they can extend the scope of machine learning applications.
3.
They can utilize minimal hardware resources well. The advantages of deep learning networks do not emerge until a very large number of parameters. If the hardware does not allow that scale (e.g., in edge devices), evolved networks provide an alternative principle that can be optimized to the given resources.
4.
They can be constructed to fit hardware constraints. Gradient descent in principle requires high-precision weights and differentiable activation functionsthat are expensive to implement in hardware. In contrast, evolution can be used to optimize the performance of networks with, e.g., quantized weights, linear threshold units, or FPGA-compatible componentsthat are easier to implement [18, 48, 73].
While examples of each of these advantages exist already, their large-scale applications are still future work and an interesting research opportunity. Another interesting opportunity is to scale them up to large networks, discussed next.
2.2.2 Deep Networks
As discussed above, evolution of entire networks usually focuses on small, recurrent architectures with up to hundreds of thousands of parameters. Evolutionary operations can still search such a space effectively. At the outset, it seems difficult to scale this approach to deep learning networks, which routinely contain hundreds of millions of parameters, and sometimes up to hundreds of billions of them.
There are special techniques that may make it possible to optimize solutions in such very high-dimensional spaces. For instance, [15] showed that in the specific case of metal casting scheduling, it was possible to establish a constrained search, and solve problems with up to a billion parameters. It may be possible to develop similar techniques for neuroevolutionas well and thereby scale up to deep learning networks.
Another approach is to utilize indirect encodings. Instead of optimizing each parameter independently, a coding is evolved that is then mapped to the final design through a developmental or a generative process. For instance, in the HyperNEAT approach[79], such a decoding neural network is evolved to output weight values for another neural network that actually performs the task. The performance network is embedded into a substrate where each of its neurons is located at particular coordinates; given the coordinates of the source and target neuron as input, the decoding neural network generates the weight of the connection between them as its output. Importantly, it is possible to sample the substrate at different resolutions, i.e., embed a very large number of neurons in it, and thus use the same decoding network to generate very large performance networks. The decoding networks are termed compositional pattern-producing networks because the weights they generate often follow regular patterns over the substrate. This observation suggests that the HyperNEAT approachcould be used to generate structures over space, such as 2D visual or 1D time seriesdomains. Whether it can be extended to layered structures and general architectures remains an open question.
Fig. 2.3
Compact Indirect Encoding of Deep Neural Networks.In the approach of [82], a population of initial networks with parameters are first created through an initialization function . Subsequent generations are created through mutations seeded . Only the seeds need to be stored and evolved; the current population can be created by applying the same sequence of mutations to . In this way, indirect encodingmakes it possible to represent deep neural networks compactly enough so that they can be evolved in their entirety.
Figure from [82]
Evolving such structured deep learning networks may be achieved by other means. For instance, [82] developed a method where each individual network is represented indirectly as a sequence of mutation operators performed on an initial set of weight parameters (Fig. 2.3). The initial set may have millions of parameters, but they only need to be stored once for each individual lineage. The mutations can be encoded efficiently as a sequence of seeds that generate the changes through a precomputed table. Thus, the compression rate depends on the number of generations but is in the order of -fold. It thus makes it possible to evolve deep learning networks with millions of parameters, as was demonstrated in several tasks in the Atari game-playing domain.
While evolution of entire very large networks is still a new area, these initial results suggest that it may indeed be possible. The benefits of general design, reviewed in the previous section, may then apply to them as well.
2.3 Evolving Explainable Solutions
Most AI today is based on neural networks. Given the vast amount of available data and compute, impressive performance is indeed possible in many real-world classification and prediction tasks. However, neural networks are inherently opaque. The knowledge they have learned is embedded in very high-dimensional vector spaces, with a lot of redundancy and overlap, and with nonlinear interactions between elements. Even though they may perform well on average, it is difficult to deploy such a system when we do not understand how it arrives at a particular answer in any individual case. The system may be overfitting, fooled by adversarial input, missing an important factor, or utilizing unfair biasto make its decision [13, 37, 72]. Explainabilityhas thus emerged as one of the main challenges in taking AI to the real world.
Evolving compact neural networks through complexificationmay make their function transparent. However, explainabilityin supervised learning requires more: For each new example, the system should be able to identify the information and principles used to arrive at the decision. Structures different from neural networks are thus needed, such as decision trees, classifiers, programs, and rules. While they cannot be easily modified by gradients, evolutionary machine learning can be used to construct them, as reviewed in this section.
2.3.1 Decision Trees
Decision trees are a classical supervised learning method with low computational overhead and transparent, explainable performance [9, 60, 61]. In its most basic form, samples are represented as vectors of features, and the tree is used to classify them into discrete categories. Each node of the tree looks at one feature, and based on its value, passes the sample down to one of the nodes below it; the leaf nodes each assign a category label.
The traditional approach to constructing a decision tree is to do it top down in a greedy fashion: At each step, a feature that is deemed most useful for branching is chosen, and the process continues recursively in each branch until all training samples in a branch have the same category label. The choice can be based, e.g., on the information gainin the branching, which is a heuristic aimed at constructing simple and shallow trees, which in turn are likely to generalize better.
However, the greedy construction is often suboptimal. It is difficult to take into account interactions between features, and construct trees that are balanced, and often trees end up complex and prone to overfitting [4]. Evolutionary search provides an alternative: it can search for optimal trees globally, taking into account both accuracy and size objectives [4].
A natural approach to evolving decision trees is to represent them, indeed, as trees where the nodes specify a comparison of a particular feature with a constant value, or a label if the node is a leaf [2]. Fitness can then consist of accuracy in the training set but also include complexity of the tree, such as depth and balance. Such approaches achieve competitive performance, e.g., in the UCI benchmarks, especially in tasks that are prone to overfitting [39].
One way to improve generalization with decision trees is to form ensembles of them, including methods such as random forests, where different trees are trained with different parts of the dataset [8]. Evolutionary optimization can be applied to such ensembles as well: The nodes of the tree (represented, e.g., as feature+value pairs) can be concatenated into a vector, and multiple such vectors representing the entire ensemble can then be used as an individual in the population. The resulting evolutionary ensembles can outperform, e.g., the standard random forests and AdaBoostmethods of forming decision tree ensembles [16].
Thus, evolutionary optimization provides a potentially powerful way to overcome some of the shortcomings of decision trees, thus having a large impact in domains with few examples, meaningful features, and the need for transparent decision-making.
2.3.2 Learning Classifier Systems
The two classic evolutionary machine learning approaches, learning classifier systems (LCS)andgenetic programming (GP), can be applied to supervised learning tasks as well. They may perform well on specific domains, especially when there is too little data to take advantage of deep learning. However, like decision trees, their solution structure is transparent and they can thus be used to construct explainable solutions.
LCShas a long history of development, and includes many variations [10, 14, 34, 88]. The approach was originally developed for reinforcement learningproblems, and a more thorough overview of it will be given in that context in Chap.  4. Often a distinction is made between the Michigan-style LCS, where the population consists of individual classifiers and the solution of the entire population, and Pittsburgh-style LCS, where the population consists of sets of classifiers and the solution is the best such set. Pittsburgh-style LCSis often referred to as ruleset evolution and will be discussed in Sect. 2.3.4
In Michigan-style LCS, the population consists of individual IF–THEN rules whose antecedents specify feature values (0, 1, don’t_care) in the environment, and the consequence is a binary classification (0, 1). In a supervised setting, the rules that match an input example are assigned fitness based on whether their classification is correct or not. The fitness is accumulated over the entire training set, and fitness is then used as the basis for parent selection. Offspring rules are generated through crossover and mutation as usual in a genetic algorithm. The population can be initialized to match training examples, and it is grown incrementally, which makes learning and performance easier to understand.
For instance, LCSmethods of supervised learning have been developed for data mining in noisy, complex problems such as those in bioinformatics [89]. Expert knowledge can be encoded as probability weights and attribute tracking, guiding search toward more likely solutions. Applied to a large number of single-nucleotide polymorphismdatasets, the approach proved to be effective across a range of epistasis and heterogeneity.
The final set of LCSrules is transparent, although it can grow very large and difficult to interpret. Methods for compacting and filtering it have been developed to improve interpretability. However, Pittsburgh-style rule evolution often results in smaller and more interpretable rule sets, as will be discussed in Sect. 2.3.4
2.3.3 Genetic Programming
Along the same lines, GP is primarily a method for reinforcement learningdomains and will be reviewed in detail in that context in Chap.  4. The main idea in GP is to evolve programs, usually represented by trees of elementary operations [41]. This idea is very general, and also applies to the supervised learning context. The program can represent a function that transfers inputs to outputs. Those inputs and outputs can originate from a supervised dataset, and fitness for a program is measured based on how often the output labels are correct. GP can thus evolve programs that perform well in the supervised task.
The idea is that domain knowledge about the features and operations can be encoded in the search space of the program. While in deep learning approaches, such knowledge is usually extracted from the examples, GP only needs to find how to use it. Therefore, it is possible to learn from much fewer examples. Also, the programs are transparent, and therefore it is possible to explain how the system arrives at an answer.
For instance, in the evolutionary deep learning GP (EDLGP) system [5], GP was used to classify images in standard object datasets CIFAR-10, SVHN, FashionMNIST, and two face image datasets. Starting from images as input, the programs consisted of several layers of processing, including image filtering, feature extraction, concatenation, and classification. At each level, a number of operators were provided as elements, and the goal was to find a tree that utilizes these operators at the appropriate levels most effectively. Thus, much knowledge about image processing was provided to the search, making it possible to construct effective functions with only a few training examples. Indeed, the best-evolved trees performed much better than standard deep learning approaches such as CNNand ResNet when only one to eight training examples were available for each class; when 10–128 were available, the two approaches were roughly comparable.
Moreover, the resulting trees are transparent, taking advantage of operations that make sense in the domain (Fig. 2.4). Thus, the example demonstrates once again that evolutionary supervised learning makes sense in low-data environments in general, and also provides a level of explainabilitythat is missing from the standard deep learning approaches.
Fig. 2.4
An image classificationtree discovered by GP.The tree was evolved with a training set of 80 images per class in CIFAR-10, reaching accuracy of 52.26%, which is better than deep learning approaches [5]. The gray nodes at the bottom indicate input channels; green nodes perform filtering operations; yellow nodes extract features; purple nodes form combinations of features; red modes make classification decisions. Taking advantage of image processing knowledge given in terms of layers and elements, the operations are chosen and the tree structure is formed through GP. It results in effective classification even with very few examples, and the classification decisions are transparent.
Figure from [5]
2.3.4 Rulesets
Compact neural networks, decision trees, classifier populations, and programs may be transparent, but the most natural and clear form of explainabilityis in terms of rules. Indeed, AI has a rich tradition of rule-based systems [31]. Within their scope, they provide a rigorous inference mechanism based on logic. Importantly, they also provide explainabilityin that the rules specify exactly what knowledge is used to arrive at a decision, and how the decision is made. In other words, they provide precisely what is missing from current neural network-based AI.
On the other hand, rule-based systems are usually constructed by hand, to encode knowledge of human experts, instead of learning such knowledge from supervised datasets. Rule-based systems are thus an important opportunity for evolutionary machine learning. Whereas rules cannot be learned through gradient descent, they can be learned through evolution.
First, rules are represented in a structure that can be evolved with, e.g., crossover and mutation operators. For instance, an individual in a population can consist of a set of rules, each with a left-hand side that consists of logical clauses and/or arithmetic expressions based on domain features, and a right-hand side that specifies a classification or prediction [71, 76]. Then, the number of rules, their order, the number of features, and the features themselves, the logical and arithmetic operations between them, and coefficients are evolved, as are the actions and their coefficients on the right-hand side. Furthermore, there can be probabilities or confidence values associated with each rule, and ways of combining outputs of multiple rules can be evolved as well.
In other words, rule-set evolution can take advantage of existing representationsin Turing-complete rule-based systems. As usual in supervised learning, the fitness comes from loss, or accuracy, across the dataset. Instead of coding the rule-based system by hand, the entire system can then be evolved. The result, in principle, is explainable machine learning.
This general approach has already been demonstrated in several decision-making tasks, including stock trading, game playing, robotic control, anddiabetes treatment recommendation [70, 71]. However, it has also been applied to the supervised task of blood-pressure predictionin intensive care(Fig.  2.5; [33, 71]). Based on a time seriesof blood-pressure measurements, that task was to predict whether the patient will go into a septic shockin the next 30 minutes, while there is still time to prevent it. Indeed, the evolved rulesets achieved an accuracy of 0.895 risk-weighted error on the unseen set, with a true positive rate of 0.96 and a false positive rate of 0.39 (Fig.  2.5). Most importantly, the rules were evaluated by emergency-room physicians who found them meaningful. Without such explicit rules, it would be very hard to deploy the prediction system. With rules, human experts can check the AI’s reasoning and decide whether to trust it, thus making the AI helpful as a first indicator of potential problems. Evolution of rulesets in this supervised task makes it possible.
Fig. 2.5
A transparent and explainable rule set evolved to predict blood pressure.EVOTER discovered sets of features at specific time points to provide a useful signal for prediction. For instance, Std[4] specifies the standard deviation of the aggregated mean arterial pressure (MAP) over 4 minutes earlier. The evolved rules predict sepsis within 30 mins with a 0.895 risk-weighted error on the unseen set, with a true positive rate of 0.96 and a false positive rate of 0.394. Most importantly, the rules are interpretable and meaningful to experts, which makes it much easier to deploy in practice compared to, e.g., black-box neural network models.
Figure from [71]
2.4 Evolutionary Metalearning
The idea of metalearning is to enhance the general setup of the supervised learning system through a separate learning process. The two systems thus work synergetically; for instance, the fitness of an evolved neural network design is based on the performance of supervised training of that network. Metalearning is useful, and even necessary, because modern learning systems have become too large and complex for humans to optimize [17, 35, 45, 74]. There are many dimensions of design, such as network topology, components, modularity, size, activation function, loss function, learning rate and other learning parameters, data augmentation, and data selection. These dimensions often interact nonlinearly, making it very hard to find the best configurations.
There are many approaches to metalearning, including gradient-based, reinforcement learning, and Bayesian optimization methods [17, 68]. They can be fast and powerful, especially within limited search spaces. However, the evolutionary approach is most creative and versatile [44, 47, 53]. It can be used to optimize many of the design aspects mentioned above, including those that focus on optimizing discrete configurations that are less natural for the other methods. It can also be used to achieve multiple goals: It can be harnessed not only to improve state-of-the-art performance but also to achieve good performance with little expertise, fit the architecture to hardware constraints, take advantage of small datasets, improve regularization, find general design principles as well as customizations to specific problems. There is also an incipient and future opportunity to find synergies between multiple aspects of optimization and learning.
This section reviews the various aspects of evolutionary metalearning. Interestingly, many of the techniques originally developed for evolving entire networks (e.g., those in Sect. 2.2.1) have a new instantiation as metalearning techniques, evolving network architectures synergetically with learning. In addition, new techniques have been developed as well, especially for other aspects of learning system design.
2.4.1 Neural Architecture Search
The most well-studied aspect of metalearning is Neural Architecture Search (NAS), where the network wiring, including potentially overall topology, types of components, modular structure and modules themselves, and general hyperparameters are optimized to maximize performance and other metrics [17, 47]. NASin general is a productive area in that many approaches have been developed and they work well. However, even random search works well, suggesting that the success has less to do with the methods so far but rather with the fact that architectures matter and many good designs are possible. It also suggests that further improvements are still likely in this area—there is no one dominant approach or solution.
One of the early and most versatile approaches is CoDeepNEAT[44, 52]. This approach builds on several aspects of techniques developed earlier for evolving complete networks. In SANE, ESP, and CoSYNE, partial solutions such as neurons and connections were evolved in separate subpopulations that were then combined into full solutions, i.e., complete neural networks, with the global structure specified, e.g., in terms of a network blueprint that was also evolved [21, 22, 55]. Similarly, CoDeepNEATco-evolves multiple populations of modules and a population of blueprints that specifies which modules are used and how they are connected to a full network (Fig. 2.6a). Modules are randomly selected from the specified module population to fill in locations in the blueprint. Each blueprint is instantiated in this way many times, evaluating how well the design performs with the current set of blueprints. Each module participates in instantiations of many blueprints (and inherits the fitness of the entire instantiation each time), thus evaluating how well the module works in general with other modules. The main idea of CoDeepNEAT isthus to take advantage of (and scale up with) modular structure, similarly to many current deep learning designs such as the inception network and the residual network [32, 86].
Fig. 2.6
Discovering Complex Neural Architectures through Coevolution of Modules and Blueprints.aIn CoDeepNEAT[52], the blueprints represent the high-level organization of the network and modules fill in its details. The blueprint and module subpopulations are evolved simultaneously based on how well the entire assembled network performs in the task. This principle was originally developed for evolving entire networks [21, 55], but it applies in neural architecture search for deep learning as well. bThe overall structure of a network evolved for the image captioningtask; the rectangles represent layers, with hyperparameters specified inside each rectangle. One module consisting of two LSTM layers merged by a sum is repeated three times in the middle of the network. The approach allows the discovery of a wide range of network structures. They may take advantage of principles different from those engineered by humans, such as multiple parallel paths brought together in the end of this network.
Figures from [52]
The modules and the blueprints are evolved using NEAT(Sect. 2.2.1), again originally designed to evolve complete networks and adapted in CoDeepNEATto evolving network structure. NEAT starts with a population of simple structures connecting inputs straight to outputs, and gradually adds more modules in the middle, as well as parallel and recurrent pathways between them. It thus prefers simple solutions but complexifies the module and blueprint structures over time as necessary. It can in principle design rather complex and general network topologies. However, while NEATcan be used to create entire architectures directly, in CoDeepNEAT, it is embedded into the general framework of module and blueprint evolution; it is thus possible to scale up through repetition that would not arise from NEATnaturally.
The power of CoDeepNEATwas originally demonstrated in the task of image captioning, a domain where a competition had been run for several years on a known dataset [52]. The best human design at that point, the Show &Tell network [91], was used to define the search space; that is, CoDeepNEATwas set to find good architectures using the same elements as in the Show &Tell network. Remarkably, CoDeepNEAT was able to improve the performance further by 15%, thus demonstrating the power of metalearning over the best human solutions [52]. Interestingly, the best networks utilized a principle different from human-designed networks: They included multiple parallel paths, possibly encoding different hypotheses brought together in the end (Fig. 2.6b). In this manner, the large search space utilized by CoDeepNEATmay make it possible to discover new principles of good performance.
Similar CoDeepNEATevolution from a generic starting point has since then been used to achieve a state of the art in text classification [44] and image classification[44]. The experiments also demonstrated that, with very little computational cost, it is possible to achieve performance that exceeds standard architectures, making it possible to quickly and effectively deploy deep learning to new domains. CoDeepNEAThas since then been extended with mechanisms for multiobjective optimization, demonstrating that the size of the network can be minimized at the same time as its performance. Indeed, size can sometimes be minimized to 1/12 with only a small (0.38%) cost in performance [44]. Another useful extension is to multitask learningby incorporating task routing, i.e., coevolution of task-specific topologies instead of a single blueprint, all constructed from the same module subpopulations [42]. In multitask learning, it is possible to learn accurate performance even with small datasets. Simultaneous learning of multiple datasets utilizes synergies between them, resulting in performance that exceeds learning in each task alone. Multitask evolution finds architectures that best support such synergies. The approach achieved state of the art in, e.g., multialphabet character recognition [42], as well as multiattribute face classification [51]. These extensions again make it possible to apply deep learning to domains where hardware or data is limited, as it often is in real-world applications.
An important question about evolutionary NAS, and about metalearning in general, is whether it really makes a difference, i.e., results in architectures that advance the state of the art. Such an argument is indeed made below in Sect. 2.4.2.5wrt synergies of different aspects of metalearning. However, perhaps a most convincing case wrt NAS is the AmoabaNet [64]. At its time, it improved the state of the art in the ImageNetdomain, which had been the focus of deep learning research for several years.
There were three innovations that made this result possible. First, search was limited to a NASNet search space, i.e., networks with a fixed outer structure consisting of a stack of inception-like modules(Fig. 2.7a). There were two different module architectures, normal and reduction; they alternate in the stack, and are connected directly and through skip connections. The architecture of the modules is evolved, and consists of five levels of convolution and pooling operations. The idea is that NASNet represents a space of powerful image classifiers that can be searched efficiently. Second, a mechanism was devised that allowed scaling the architectures to much larger numbers of parameters, by scaling the size of the stack and the number of filters in the convolution operators. The idea is to discover good modules first and then increase performance by scaling up. Third, the evolutionary process was modified to favor younger genotypes, by removing those individuals that were evaluated the earliest from the population at each tournament selection. The idea is to allow evolution to explore more instead of focusing on a small number of genotypes early on. Each of these ideas is useful in general in evolutionary ML, not just as part of the AmoebaNetsystem.
Indeed, AmoebaNet’saccuracy was the state of the art in the ImageNetbenchmark at the time, which is remarkable given how much effort the entire AI community had spent on this benchmark. Experiments also demonstrated that evolutionary search in NASNet was more powerful than reinforcement learningand random search in CIFAR-10, resulting in faster learning, more accurate final architectures, and ones with lower computational cost(Fig. 2.7b). It also demonstrates the value of focusing the search space intelligently so that good solutions are in that space, yet it is not too large to find them.
Fig. 2.7
Evolutionary Discovery in the NASNet Search Space Compared RL and Random Search.aThe AmoebaNetmethod [64] focuses evolution to a particular stacked architecture of inception-like normal and reduction modules (cells); these networks are then scaled to larger sizes algorithmically. AmoebaNetalso promotes regularizationby removing the oldest individuals in the population. bAs a result, it discovers architectures that are more accurate than those discovered through random search and RL, reaching state-of-the-art accuracy in standard benchmarks like ImageNet
Figures from [64]
Evolutionary NAS is rapidly becoming a field of its own, with several new approaches proposed recently. They include multiobjective andsurrogate-based approaches [49], Cartesian genetic programming[83, 92], variable-length encodings and smart initialization [84, 85], and LSTM design[63], to name a few; see Chap.  X for a more detailed review. The work is expanding from convolutional networks to transformersand diffusion networks, and from visual and language domains to tabular data. An important direction is also to optimize design aspects other than the architecture, as will be reviewed next.
2.4.2 Beyond Architecture Search
