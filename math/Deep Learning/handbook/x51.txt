Single
Parametric
Static
Image
2020
[215] Zaltron et al.
GA
Single
Parametric
Dynamic
Image
2021
[38] Colton
GA
Single
Parametric
Static
Image
2021
[110] Liapis et al.
GA
Multi. (colab.)
Procedural
Static
Image
2022
[73] Grabe et al.
GA
Single
Parametric
Static
Image
2022
[135] Machín et al.
GA
Single
Parametric
Static
Music
2011
[136] Manaris et al.
GA
Single
Procedural
Static
Other
2018
[210] Volz et al.
ES
Single
Parametric
Dynamic/Static
Other
2020
[160] O’Reilly et al.
GP
Single
Procedural
Dynamic
10.7 Machine Learning Aided by  Evolutionary Computation
In this section, we include the approaches where evolutionary computation is used to enhance the functionality or performance of the machine learning model. As an example, latent variable evolution belongs in this section because these approaches use evolutionary computation to explore a latent spacepreviously built using a machine learning model. Table  10.3contains examples of evolutionary generative modelswhich we consider to belong to the category machine learning aided by evolutionary computation. The listed publications are grouped by application domain (first column) and then sorted by year (second column) and by authors (third column).
The idea of latent variable evolution was introduced by Bontrager et al. [22, 23] to explore the latent spaceof inputs to the generatornetwork of a GAN using a CMA-ESapproach to generate fingerprints that maximise the number of imposter matches. Concerning genetic algorithms, Schrum et al. [178] evolved parameters for CPPNs, which in turn generated a variety of different latent vectors for GANs.
Other examples concerning the application of genetic algorithms to latent variable evolution include the work by Grabe et al. [73], who used Gaussian mixture models to explore possible latent vectors to evolve distinct images, along with interactive methods to perform the evolutionary search by Zaltron et al. [215], among others [21, 64, 135]. Outside of latent variable evolution but still pertaining to image generation, Colton [38] also proposed a system to generate image filters using a genetic algorithm with MAP-elitesor the work by Korde et al.  [99], which uses an evolutionary algorithm to train in the initial iterations to stabilise the weights before using normal optimisation techniques to train GANs.
Concerning other applications, an approach combining genetic algorithms and Markov chains was proposed by Manaris et al. [136] to evolve musical phrases. Volz et al. [210] worked on the generation of game levels using latent variable evolution with adversarial training. Moreover, the work by O’Reilly et al. [160] in cyber-attacks and defence mechanisms using genetic programming in an adversarial setting, among other techniques, explored generating and evolving executable adversarial programs. Lastly, we mention the work of Liapis et al. [110] for the creation of suitable spaceships for arcade-style games using CPPN-NEAT and novelty search
One of the most noticeable aspects of this section lies in the fact that, when compared to other ones, the bodyof work concerned with aiding machine learning with evolutionary computation is significantly less, especially when compared to Sect.  10.5. Moreover, in terms of representation, we can observe that most approaches are parametric, with just a few being procedural (in  total, there are 3 procedural, 11 parametric and no descriptive representations). This is because the analysed works mostly use latent variable evolution, which evolves parameters to generative machine learning models.
10.8 Machine Learning Evolved by  Evolutionary Computation
This section addresses approaches where evolutionary computation is used to evolve one or more populations of generative machine learning models. We present direct applications of evolutionary computation to machine learning or parts thereof. These applications are direct in the sense that the evolutionary computation techniques are applied as is, i.e. without modifications, over the set of machine learning individuals. As an example, here we include the NEAT-like approaches because the NEAT algorithm evolves a population of artificial neural networks. Table  10.4presents examples of evolutionary generative modelswhich we consider to belong to the category machine learning evolved by evolutionary computation. The listed publications are grouped by application domain (first column) and then sorted by year (second column) and by authors (third column).
Table 10.4
Examples of evolutionary generative models categorised as machine learning evolved by evolutionary computation
Domain
Year
Authors
EA
Population
Represent.
Fitness
Image
2007
[190] Stanley
GA
Single
Procedural
Dynamic
Image
2008
[181] Secretan et al.
GA
Single
Procedural
Dynamic
Image
2011
[182] Secretan et al.
GA
Single
Procedural
Dynamic
Image
2015
[216] Zhang et al.
