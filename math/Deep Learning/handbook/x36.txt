The executable component of an agent could be a program or a neural network.
10
Agent context divides the input space into a region and associates its region with an action. As multiple programs appear in the same ensemble, multiple regions–actions appear.
11
Support for real-valued actions introduces an action program at each agent [23, 106].
12
Implies that the agents can only solve a task by forming decisions from the internal state (memory) as well as the external state as provided by the environment.
13
Decreases to as the dimension of the visual state space increases [107].
Part IIIEvolution and Neural Networks
In which we set neural networks in the context of evolution. We’ll address hardware needs of deep neural networks, large language models, generative models, and adversarial learning.©  The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.  2024
W. Banzhaf et al.(eds.)Handbook of Evolutionary Machine LearningGenetic and Evolutionary Computationhttps://doi.org/10.1007/978-981-99-3814-8_9
9.  Evolutionary Neural Network Architecture Search
Zeqiong  Lv1, Xiaotian  Song1, Yuqi  Feng1, Yuwei  Ou1, Yanan  Sun1and Mengjie  Zhang2
(1)
College of Computer Science, Sichuan University, Chengdu, 610064, China
(2)
Centre for Data Science and Artificial Intelligence and School of Engineering and Computer Science, Victoria University of Wellington, Wellington, 6140, New Zealand
Yanan  Sun
Email: ysun@scu.edu.cn
Abstract
Deep Neural Networks (DNNs) have been remarkably successful in numerous scenarios of machine learning. However, the typical design for DNN architectures is manual, which highly relies on the domain knowledge and experience of neural networks. Neural architecture search (NAS) methods are often considered an effective way to achieve automated design of DNN architectures. There are three approaches to realizing NAS: reinforcement learningapproaches, gradient-based approaches, and evolutionary computation approaches. Among them, evolutionary computation-based NAS(ENAS) has received much attention. This chapter will detail ENAS in terms of four aspects. First, we will present an overall introduction to NAS and the commonly used approaches to NAS. Following that, we will introduce the core components of ENAS and discuss the details of how to design an ENAS algorithm with a focus on search space, search strategy, and performance evaluation of the ENAS algorithm. Moreover, detailed implementations of these components will be presented to help readers implement an ENAS algorithm step by step. We will discuss state-of-the-art ENAS methods with the three core components. Finally, we will provide five major challenges and identify corresponding future directions.
9.1 Introduction
Deep Neural Networks (DNNs), as the cornerstone of machine learning  [30], have achieved great success in many real-world applications, ranging from image and video processing  [29] to artificial language processing  [9]. Many observations have demonstrated that the architectures of DNNs have a significant impact on their performance  [29, 43]. Therefore, the design of DNN architectures has always been an important research topic. For a long time, the architectures of promising DNNs have been manually designed, such as ResNet  [21] and DenseNet  [23]. Although these DNNs can achieve state-of-the-art performance at development time, their architectures are designed by researchers with rich expertise in neural networks and data. However, in practice, most interested users do not have such knowledge. Moreover, the architectures of DNNs are often problem-dependent. When the problem changes, a new DNN architecture is required to be redesigned manually. Particularly, promising architectures for different datasets are significantly different, e.g., the best ResNet for CIFAR-10[28] is ResNet110 and the best for ImageNet[42] is ResNet152. As a result, more and more researchers are trying to figure out how to automatically design the architecture of DNNs. This has led to a new field of research known as Neural Architecture Search (NAS). Formally, NAS is a technique that can automatically design high-performance DNN architectures without expert experience  [68].
NASis often formulated as an optimization problem represented by Eq.  9.1:
(9.1)
where denotes a set of network architectures and Adenotes a single architecture in the set. measures the performance of Aon the fitness evaluation dataset after Ahas been trained on the training dataset . For example, when Convolutional Neural Networks (CNNs)are used for image classificationtasks, Ais a CNN architecture, and is the classification error on the dataset to which Ais applied. Generally, NASis considered an optimization problem facing multiple challenges, such as expensive computation, complex constraints, and multiple conflicting objectives. To solve the NAS problem in Eq.  9.1, researchers have proposed a variety of effective optimization algorithms. Existing NAS methods can be generally classified into Reinforcement Learning(RL)  [26] based NAS algorithms, gradient-based NASalgorithms, and Evolutionary Computation (EC)  [2] based NAS algorithms (ENAS).
In the early stages, NAS was mostly based on RL algorithms. The initial work of NASis commonly viewed as NAS-RL  [68], which was proposed by Google researchers and accepted for publication by the International Conference on Learning Representations (ICLR) in 2017. As shown in Fig.  9.1, the NAS-RL algorithm is an iterative process with two parts, with the iterative process continuing until the termination condition is satisfied. In the first part, the NAS-RL algorithm uses a Recurrent Neural Network (RNN) controllerto sample an architecture. In the second part, NAS-RL uses the trained architecture to update the controller. Through this process, NAS-RL can automatically generate a neural network without manual design, and the designed network can achieve success on the corresponding dataset. However, RL-based algorithms have two major shortcomings. Firstly, they are very time-consuming and resource-consuming. For example, NAS-RL used 800 Graphic Processing Units (GPUs)for four weeks to find a promising CNNarchitecture on the CIFAR-10dataset. Secondly, RL-based algorithms are often not completely automatic and rely on expertise. For example, NAS-RL only searched for the hyper-parameters of the convolution layers, while other layers were still set manually. In general, using hundreds of GPUsis impractical for most universities and research labs. In addition, domain expertise in designing architectures limits the application of RL-based NAS
Fig. 9.1
An overview of NAS-RL
In recent years, gradient-based NAShas been proposed by researchers to improve search efficiency. Gradient-based NAS algorithms relax the discrete search into a continuous optimization problem and then use a gradient-based algorithm  [41] to solve it. The classical gradient-based NASalgorithm is DARTS  [32], which was proposed by Google researchers and accepted for publication at ICLR in 2019. Figure  9.2shows the search process of DARTS, which contains three main steps. First, a continuous space known as a supernetis manually constructed, which contains a set of operations on each edge. After that, a gradient descent algorithm is used to optimize operation probabilities and network weights. The final architecture is obtained from the adapted operation probabilities. During this process, DARTS only used one GPUfor four days to find the superior CNNarchitecture on the CIFAR10 dataset, which is a significant improvement over NAS-RL regarding time and resource consumption. Unfortunately, gradient-based NAStechniques require prior manual construction of the supernet, which needs considerable expertise. In addition, the convergence of the optimization algorithm is not guaranteed, and ill-conditioned architectures will be searched, which often results in poor performance.
Fig. 9.2
An overview of DARTS
EC is another major approach to solving the NAS problem. Specifically, EC is a class of population-based meta-heuristic optimization paradigms inspired by the evolution of species and the behaviors of creatures in nature. It has been used to solve complex problems and real-world optimization problems by evolving multiple solutions at the same time. The most popular EC techniques include Evolutionary Algorithms (EAs) and Swarm Intelligence (SI). EAs are mainly inspired by the process of natural evolution, such as Genetic Algorithms (GAs) and Genetic Programming (GP), while SI is motivated by the behavior of flocking and swarming, such as Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO). Compared to other existing optimization algorithms, EC algorithms do not require gradient information and extensive domain knowledge. Also, EC algorithms have the potential to generate globally optimal solutions. Due to these characteristics, EC methods have been widely used in practice.
In fact, EC algorithms have been already used to search for neural networks over 30 years and the period can be divided into three stages  [65]. The first stage is termed “evolving neural networks”, which ended in 1999 with a survey  [62]. During this stage, the algorithms were often used to search for both neural architectures and optimal weight values. The neural networks in this stage were often small-scale, i.e., only a couple of normally hidden layers in the evolved networks. The second stage runs from 2000 to 2016 and is known as “neuroevolution”  [18]. Different from the first stage, neuroevolution focused on median-scale neural networks. A series of works on the Neuroevolutionof Augmenting Topologies (NEAT)  [48], such as rtNEAT  [46] and HyperNEAT[47], serve as prime examples of neuroevolution. Since 2017, EC has been used to solve the NASproblem, with the third stage being called ENAS. This stage is different from the previous two stages. To begin, previous stages of work frequently used EC to evolve either architectures or weights, or a combination of them, which is very time-consuming. In contrast, ENAS mainly focuses on searching for architectures, and good weight values are obtained by applying efficient gradient-based algorithms. Furthermore, the previous two stages are commonly applied to small-scale and medium-scale neural networks, whereas ENAS generally works on DNNs, such as deep CNNs[40, 52] and deep stacked autoencoders[49], which are stacked with building blocks of deep learning techniques  [30]. In general, the seminal work of ENAS is often viewed as the LargeEvo algorithm  [40], which was proposed by Google researchers and finally accepted into the 24th International Conference on Machine Learning (ICML) in 2017. The LargeEvo algorithm employed a GA to search for the best architecture of a CNN, and the experimental results on CIFAR-10and CIFAR-100  [28] have demonstrated their effectiveness. Since then, ENAS algorithms have continued to make breakthroughs in various tasks, such as image classificationand signal processing  [52].
This chapter aims to provide an introduction to ENAS algorithms, to help readers to learn the basic knowledge of ENAS and design ENAS algorithms for different kinds of application tasks. To achieve this goal, the rest of this chapter is organized as follows. Section  9.2documents the fundamentals of ENAS and gives a step-by-step example to develop an ENAS algorithm. Section  9.3discusses the state-of-the-art ENAS algorithms in terms of search space, search strategy, and fitness evaluation. Section  9.4shows advanced topics with challenges and prospects.
9.2 ENAS Algorithms: Fundamentals and  Step-by-step Example
In this section, we first introduce the core components of ENAS in Sect.  9.2.1and then detail the step-by-step design of an ENAS algorithm in Sect.  9.2.2. To help readers better understand how to build an ENAS algorithm, we will provide an overall flowchart of a common ENAS, after which we document a framework with details for designing each step.
9.2.1 Core Components of  ENAS
In general, an ENAS algorithm is composed of three components  [14]: search space, search strategy, and performance evaluation. Specifically, the search process takes place in the predefined search space. By using EC as the search strategy, the ENAS algorithm continuously iterates the search-evaluation process in a loop. Each iteration will first search for architectures from the search space and then evaluate their performance in turn. For illustration purposes, we refer to Fig.  9.3, a core component relationship map of an ENAS algorithm.
Fig. 9.3
Abstract illustration of the ENAS
9.2.1.1 Search Space
The search space consists of all possible architectures that we want to examine, which are determined by the task at hand. It is often exponentially large or even unbounded. In the following, we will introduce how to define a search space.
Search Space: It defines the form and scope of the DNN architectures that the ENAS algorithm can search for. Generally, DNN architectures are composed of different basic units and the connections between the units. Table  9.1shows the possible architecture configurations of basic units, connections, and other parameters. According to the configurations, the search space can be designed differently by considering a combination of different parameters. Specifically, we can derive different search spaces by considering the configuration of the basic structural units (e.g., layer, block, and cell), the connections between units (e.g., topology), the operations (e.g., convolution, pooling), and other parameters. In addition, the constraints on the search space are important to restrict the search space and lighten the burden of the search process. Constraints mainly focus on fixed depth, rich initialization, and partial fixed structure. In general, there are many different ways to define the search space, and regardless of how it is designed, the goal is to define a set containing potentially good and diverse DNN architectures.
Table 9.1
Common parameters optimized in different DNNs  [35]
Parameters
CNN
Global parameters
Number of layers, connections between layers
Convolution layer
Filter size (width and height), stride size (width and height),
feature map size, convolution type, standard deviation, and mean
value of the filter elements
Pooling layer
Filter size (width and height), stride size (width and height),
and pooling type
Fully connected layer
Number of neurons, standard deviation, and mean value of weights
DBN, AE
Number of hidden layers, neurons per layer
RNN
Number of hidden layers, neurons per layer, number of time slots
Encoding Strategy: It aims to represent a neural network architecture as an individual in the population. Each ENAS method needs to determine its encoding strategy before starting the first stage of the ENAS method. One of the key issues in encoding DNN architectures is to decide how much information about architecture should be encoded  [62]. According to the neural network encoding method, the encoding strategies can be divided into direct encodingand indirect encoding. Direct encoding is a method that can directly encode the architecture parameters in the chromosome, e.g., every connection and node of an architecture are encoded as binary with the help of a connection matrix. Indirect encodingonly represents the important parameters of architecture, such as the hidden layers, while other details are predefined and fixed to reduce the search space. In addition, another encoding strategy category is based on whether all encoded individuals are of the same length. Generally, encoding strategies can be divided into fixed-length encodingsand variable-length encodings. The fixed-length encoding strategy makes it easy to use standard evolutionary operations, which are originally designed for individuals of equal length. In contrast, the variable-length strategy breaks the length limit but possesses stronger capabilities to find close-to-optimal solutions. This is because the flexibilityintroduced by the variable length makes the depth, which affects the architecture’s performance, more adaptable. After the encoding strategy has been chosen, the ENAS algorithm can start the evolution of architectures.
Initial Space:It is composed of all the individuals that could be part of an initial population, which can be generated by the initialization procedure. Generally, there are three types of architecture initialization approaches: starting from trivial initial conditions  [40], random initialization in the search space  [51], and starting from a well-designed architecture (also termed as rich initialization)  [19]. These three types of initialization correspond to three different initial spaces: trivial space, random space, and well-designed space. The trivial spacecontains only networks with few primitive layers. The reason for using as little experience as possible is to justify the advantage of the EC-based methods in discovering novel architectures, and the majority of the discovery differs from the manually designed DNN architectures. On the contrary, the well-designed spacemay contain state-of-the-art architectures. In this way, a promising architecture can be obtained at the beginning of evolution, whereas it may hardly evolve to other novel architectures. In fact, many ENAS methods adopting this initial space focus on improving the performance of the well-designed architecture. A random spaceis made up of individuals randomly generated by sampling the search space. This type of initial space aims to reduce human interventionin the initial population.
After the initialization of the population, ENAS algorithms start to search for architectures in the search space. Generally, the search space is the same as the initial space when the random initial space is adopted. For the other two types of initial spaces, however, due to the relatively small initial space, the search space will become much larger with the expectation that promising architectures are included. It is worth noting that many ENAS methods indirectly define the search space by restricting it through evolutionary operators. For example, Irwin-Harris  et al.   [24] did not specify the maximum depth of the architectures; instead, they used evolutionary operations to extend the architecture to any depth.
9.2.1.2 Search Strategy
The search strategy details how to explore the search space. ENAS algorithms explore the search space by exploiting EC techniques as the optimization approach. These strategies affect the quality and speed of finding well-performing architectures. Based on the strategy adopted, ENAS algorithms can be subdivided to introduce different evolutionary search strategies. Figure 9.4provides an illustration under three aspects: EA, SI, and others.
Fig. 9.4
Categories of ENAS from the EC methods regarding the search strategies
EA-based methods account for the majority of the existing ENAS algorithms. Generally, the EA-based search strategy mainly includes the selection strategy and evolutionary operations, which collectively update the population. In practice, GA-based ENAS is the most popular approach, which is largely owed to the convenience of architecture representation in GA. Other categories of EC methods are also important for realizing ENAS algorithms, such as GP, evolutionary strategy (ES), PSO, ACO, memetic algorithm, and evolutionary multiobjective optimization (EMO).
9.2.1.3 Performance Evaluation
The performance evaluation aims to derive the performance (such as accuracy on unseen data) of a given architecture A. The simplest way of evaluating architecture is to train Aon training data and estimate its performance on unseen fitness evaluation data.
Model training aims to find the global optimal model parameters based on training data. It can be regarded as an optimization problem:
(9.2)
where is the modal parameters (e.g., weights) of architecture A, represents the training dataset, and measures the performance of training on dataset 
Performance evaluation of architecture Ausually refers to estimating the trained model on a fitness evaluation dataset . It can be represented as
(9.3)
Note that the fitness dataset should not be used for training to guarantee the evaluation of the generalization ability of the model.
9.2.2 Step-by-Step Design of  an  ENAS Algorithm
This section describes the steps of designing an ENAS algorithm for a real case in detail.
9.2.2.1 Overall Flowchart of  a  Common ENAS
The process of utilizing GA to automatically evolve neural network architectures involves a series of iterations, and during each iteration, numerous architectures will be trained to evaluate their performance to guide the direction of the next iteration.
Fig. 9.5
Flowchart of a common ENAS algorithm
Figure  9.5shows a complete illustration of the flowchart of a common ENAS algorithm using standard GA, composed of three parts: population initialization, fitness evaluation, and population updating. In the rest of the subsection, the key steps of the three parts are documented in detail.
9.2.2.2 Population Initialization
At the beginning of the evolutionary process, population initialization creates a base population with multiple individuals. Generally, before designing the detailed population initialization process, the search space and encoding strategy need to be defined based on the type of DNN one wishes to evolve. In this section, we take the CNNsas an example and describe the initialization process of the population in detail. In the following, the search space is layer-based and the initialization procedure randomly samples this search space, while the direct encoding strategy is used for individual initialization.
A CNNarchitecture is constructed using multiple convolutional layersand pooling layers arranged in a specific order, along with their corresponding parameters (e.g., the feature maps of the convolutional layerand the pooling type). Particularly, all filter and stride sizes use the same settings, i.e., 3 3 and 1 1, respectively. To this end, the encoding information only has the layer type and one parameter setting. In the designed encoding strategy, each layer is abstracted as a node and is encoded as two parts, i.e., the node.typeand the node.parameter. If the layer type is convolutional, its node parameter (denoted as M) is the number of feature maps, and its value is an integer; otherwise, the layer type is pooling, and its parameter (denoted as P) is the pooling type, e.g., max-pooling or mean-pooling. Thus, a CNNarchitecture encoding can be described as a list of nodes where each node stores the node type and node parameter. Figure  9.6gives an example of a CNNarchitecture encoding that contains five nodes.
Fig. 9.6
Example of the indirection and fixed-length encoding strategy encoding a CNNwith five nodes
The population initialization steps are summarized in algorithm  1individuals are initialized with the same node length L(line 1), and each individual randomly generates Lnodes (line 1). During the node-generating process, two types of labels can be marked for each node (lines 1–1). Specifically, the assigned node with label represents that it is a convolutional layerwith Mfeature maps (lines 1–1), whereas label represents the node is a pooling layer with Pas the pooling type, where the pooling type is abbreviated as maxor mean(lines 1–1).
9.2.2.3 Population Updating
The population updating process includes two steps: offspring generation and environmental selection. Based on the adopted GA, the evolutionary process for offspring generation includes parent selection, crossover operation, and mutation operation. The conventional mutation strategy employed in GAs includes the bit modification that is achieved by flipping the bit of the encoding, while in the ENAS algorithm, there are three distinct types of mutation strategies: 
1.
Addition: adding any unit to the selected position;
2.
Removal: removing the unit at the selected position;
3.
