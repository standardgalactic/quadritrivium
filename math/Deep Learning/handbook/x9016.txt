22.5.3 Summary of Current Major Challenges for EML in Control
Following the no-free lunch theorem, no algorithm can solve all optimization problems and is on average more efficient than other algorithms. Thus, EML methods cannot be expected to outperform methods of control theory built for linear or linearizable problems. they are, however, efficient in deriving solutions for nonlinear, non-convex, non-differentiable, multimodal, noisy search spaces [128]. Nonetheless, there are major opportunities for improvement.
Although current studies work on the development of these topics, the need for control guarantees is fundamental to demonstrate the methods in industrially relevant environments and thus increase the technology readiness level. For systems with linear dynamics, optimality, stability, and robustness results are well-known. Whereas for nonlinear dynamics, optimized solutions are obtained for given operating conditions. Stability and robustness can be improved by including different conditions and transients in the learning process. Thus, transfer learningpresents an opportunity to generalize and improve the performance of optimized control laws to out-of-design conditions. EML methods oriented for transfer learningpurposes are a promising path toward learning more efficient controllers
Another challenge is related to the human interpretabilityproblem of machine-learned solutions. Contrary to reinforcement learningmethods, for example, GP has the advantage of proposing solutions in the shape of mathematical expressions. However, these expressions are not directly interpretable as they are often bloated expressions whose simplification is limited by the protected operations. A method for analysis, interpretation, and simplification of EML solutions is still needed.
A way to limit the bloated expressions is to learn control laws based on relevant features of the plant. Current methods consist of scaling the plant outputs, including past measurements, and are often based on engineering wisdom. So far, good results are achieved with such approaches but better performances can be expected with control-oriented features. Although control-oriented featuredesign is not specific to EML, it will certainly accelerate learning and enable better solutions. More generally, the efficiency of EML methods for control needs to integrate domain-specific knowledge for improved efficiency.
The learning process of EML methods tends to generate lots of data. The exploitation of this large data set to orient the learning process is still an untapped opportunity for EML. Thus, building a surrogate modelof the plant based on the evaluated controllersmay help to predict the next controller to evaluate. Moreover, the analysis of the data during the learning process enables online adjustment of the algorithms. Genetic operator’s probabilities can then be tuned during the optimization to promote explorationor exploitation following the situation., Likewise, different genetic operators can be selected based on the learning stage. For control, the online analysis of the best and worst control laws may help to reduce the search space by selecting only the relevant control inputs, or by activating only the beneficial actuators. The generated data can also help to characterize the search space for selecting adequate optimization algorithms. Inthis manner, Exploratory Landscape Analysis [105, ELA] and its R implementation FLACCO [75] propose an automatic and quick extraction of low-level features for automatic algorithm selection.
22.6 Conclusions and Outlook
In this chapter, we reviewed Evolutionary Machine Learning (EML) to solve control tasks. Control presents the most difficult challenges in regression problems such as nonlinearities, high dimensionality, time delays, and external noises. Model-free methods such as the ones of EML are particularly fitted to tackle those challenges. EML has been successful in deriving or optimizing controllersin many fields like engineering, robotics, fluid mechanics, and industrial processes to cite a few examples. EML is employed at all stages of control fault detection, robustness analysis, and design of reliable systems [48]. EML has also been employed to design the plant, prior to its solving. Thus, evolutionary methods solve complex combinatorial problems such as sensor and actuator placement. Although EML algorithms are easy to develop and code, their implementation requires domain-specific knowledge to define rich enough controllerspaces. Indeed, the design of the plant features is a critical step in turbulence control [17]. Again, evolutionary algorithms are used forfeature construction [3]. Thereby, control is slightly drifting toward fully automated EML tasks, including model identification, feature design, control, stability, and robustness analysis. Yet, any new task solved with evolutionary algorithms requires additional evaluations thus the need for accelerated learning.
Accelerated learning is pursued with the combination of EML with other optimization methods [23, 119]. In [96] and [33], GA and GP have both benefited from intermediate downhill simplex steps to exploit the local gradients in the search space and converge faster toward the minimum of the basin of attraction. Another approach to accelerate the learning is the use of digital twinslearned during the optimization process. The idea is to leverage the huge amount of data generated during the learning to build a surrogate modelof the plant. The number of evaluations can virtually be augmented by testing new controllerson the model. [48] already envision evolutionary adaptive control in the ’00s with an online adaptation of the controller with a fast evaluation of models. Nowadays, with advances in artificial intelligence and deep neural networks, this is all the more relevant, in particular, since Moore’s law is still valid. The learning acceleration opens the door to control with distributed-input distributed-put control. Indeed, as sensors and actuators become cheaper, more powerful, and reliable, large-scale multiple input and multiple output control become an attractive opportunity. So far, EML has been employed to learn controllerswith O(10) actuators and sensors, and new methods need to be developed for plants including O(100) inputs and outputs. New challenges arise such as the explosion of the combinatorial complexity and improving the learning rate of EML is one of the keys to tackling it.
One of the most challenging issues to be tackled by EML in control is still the stability and robustness of controllers. In order to implement EML controllers in transport vehicles, energy systems, or production, control guarantees need to be certified. So far, there is no general methodology to analyze these machine-learned solutions. Especially, in the case of structure-free algorithms like GP, the solutions are generally complex and contain many redundancies. Human interpretabilitymust be reintroduced afterward via simplification, analysis, and extraction of key terms that explain the controlled dynamics
The fast growth of machine learning and artificial intelligence capabilities leads to a paradigm shift in control where controllersare learned directly from the plant or from data. Domain-specific knowledge is required afterward to interpret and generalize the solutions. The latter is an essential step for the widespread integration of EML results in alltypes of industries.
Acknowledgements
This work is supported by the National Natural Science Foundation of China under grants 12302293, 12172109, and 12172111, by the Guangdong Basic and Applied Basic Research Foundation under grant 2022A1515011492, and by the Shenzhen Science and Technology Program under grant JCYJ20220531095605012.
References
1.
Adánez, J.M., Al-Hadithi, B.M., Jiménez, A.: Multidimensional membership functions in T-S fuzzy models for modelling and identification of nonlinear multivariable systems using genetic algorithms. Appl. Soft Comput. 75, 607–615 (2019)
2.
Ajani, O.S., Mallipeddi, R.: Adaptive evolution strategy with ensemble of mutations for reinforcement learning. Knowl. Based Syst. 245, 108624 (2022)
3.
Al-Sahaf, H., Bi, Y., Chen, Q., Lensen, A., Mei, Y., Sun, Y., Tran, B., Xue, B., Zhang, M.: A survey on evolutionary machine learning. J. R. Soc. N. Z. 49(2), 205–228 (2019)
4.
Alrashdi, Z., Sayyafzadeh, M.: () Evolution strategy algorithm in well placement, trajectory, control and joint optimisation. J. Pet. Sci. Eng. 177, 1042–1058 (2019)
5.
Asai, S., Yamato, H., Sunada, Y., Rinoie, K.: Designing machine learning control law of dynamic bubble burst control plate for stall suppression. In: 2019 AIAA SciTech Forum, San Diego, CA. Paper 1899 (2021)
6.
Barlow, G.J., Oh, C.K., Grant, E.: Incremental evolution of autonomous controllers for unmanned aerial vehicles using multi-objective genetic programming. In: IEEE Conference on Cybernetics and Intelligent Systems, 2004, vol. 2, pp. 689–694 (2004)
7.
Barrios Aguilar, M.E., Vinicius Coury, D., Reginatto, R., Machado Monaro, R.: Multi-objective PSO applied to PI control of DFIG wind turbine under electrical fault conditions. Electr. Power Syst. Res. 180, 106081 (2020)
8.
Benard, N., Pons-Prats, J., Periaux, J., Bugeda, G., Braud, P., Bonnet, J.P., Moreau, E.: Turbulent separated shear flow control by surface plasma actuator: experimental optimization by genetic algorithm approach. Exp. Fluids. 57(2):22, 1–17 (2016)
9.
Bersini, H.: Immune network and adaptive control. In: Proceedings of the 1st European conference on artificial life (ECAL), pp. 217–226. MIT Press (1991)
10.
Bilal Pant, M., Zaheer, H., Garcia-Hernandez, L., Abraham, A.: Differential evolution: a review of more than two decades of research. Eng. Appl. Artif. Intell. 90, 103479 (2020)
11.
Binh, T.T., Korn, U.: An evolution strategy for the multiobjective optimization. In: Proceedings of the 2nd International Conference on Genetic Algorithms, pp. 23–28 (1996)
12.
Blondin, M.J., Sanchis, J., Sicard, P., Herrero, J.M.: New optimal controller tuning method for an AVR system using a simplified ant colony optimization with a new constrained Nelder-Mead algorithm. Appl. Soft Comput. 62, 216–229 (2018)
13.
Blume, C., Jakob, W.: GLEAM—an evolutionary algorithm for planning and control based on evolution strategy. In: GECCO Late Breaking Papers, pp. 31–38 (2002)
14.
Boumediene, S., Chouraqui, S., Belkacem, S.: A genetic algorithm-based neuro-fuzzy controller for unmanned aerial vehicle control. Int. J. Appl. Metaheuristic Comput. 13(1), 1–23 (2022)
15.
Bounar, N., Labdai, S., Boulkroune, A.: PSO-GSA based fuzzy sliding mode controller for DFIG-based wind turbine. ISA Trans.85, 177–188 (2019)
16.
Brameier, M., Banzhaf, W.: Linear Genetic Programming. Springer Science & Business Media (2006)
17.
Brunton, S.L., Noack, B.R.: Closed-loop turbulence control: progress and challenges. Appl. Mech. Rev. 67(5):050801, 01–48 (2015)
18.
Brunton, S.L., Noack, B.R., Koumoutsakos, P.: Machine learning for fluid mechanics. Ann. Rev. Fluid Mech. 52, 477–508 (2020)MathSciNetzbMATH
19.
Bufu, B., Zhancheng, W., Yangsheng, X.: Multi-objective genetic algorithm for hybrid electric vehicle parameter optimization. In: 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 5177–5182 (2006)
20.
Bull, L., Sha’Aban, J., Tomlinson, A., Addison, J.D., Heydecker, B.G.: Towards distributed adaptive control for road traffic junction signals using learning classifier systems. In: Bull, L. (eds.) Applications of Learning Classifier Systems. Studies in Fuzziness and Soft Computing, vol. 150. Springer, Berlin, Heidelberg (2004)
21.
Burbidge, R., Walker, J.H., Wilson, M.S.: Grammatical evolution of a robot controller. In: 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 357–362 (2009)
22.
Burbidge, R., Wilson, M.S.: Vector-valued function estimation by grammatical evolution for autonomous robot control. Inf. Sci. 258, 182–199 (2014)MathSciNetzbMATH
23.
Castellanos, R., Cornejo Maceda, G.Y., de la Fuente, I., Noack, B.R., Ianiro, A., Discetti, S.: Machine learning flow control with few sensor feedback and measurement noise. Phys. Fluids. 34(4):047118, 1–17 (2022)
24.
Cha, Y.-J., Agrawal, A.K., Kim, Y., Raich, A.M.: Multi-objective genetic algorithms for cost-effective distributions of actuators and sensors in large structures. Expert. Syst. Appl. 39(9), 7822–7833 (2012)
25.
Cha, Y.-J., Raich, A.M., Barroso, L., Agrawal, A.: Optimal placement of active control devices and sensors in frame structures using multi-objective genetic algorithms. Struct. Control. Health Monit. 20(1), 16–44 (2013)
26.
Chao, K.-H., Rizal, M.N.: A hybrid MPPT controller based on the genetic algorithm and ant colony optimization for photovoltaic systems under partially shaded conditions. Energy. 14(10) (2021)
27.
Chen, C., Li, M., Sui, J., Wei, K., Pei, Q.: A genetic algorithm-optimized fuzzy logic controller to avoid rear-end collisions. J. Adv. Transp. 50(8), 1735–1753 (2016)
28.
Cheong, F., Lai, R.: Constraining the optimization of a fuzzy logic controller using an enhanced genetic algorithm. IEEE Trans. Syst. Man Cybern. Part B (Cybern.) 30(1), 31–46 (2000)
29.
Cheong, F., Lai, R.: Simplifying the automatic design of a fuzzy logic controller using evolutionary programming. Soft Comput. 11(9), 839–846 (2007)
30.
Chipperfield, A.J., Dakev, N.V., Fleming, P.J., Whidborne, J.F.: Multiobjective robust control using evolutionary algorithms. In: Proceedings of the IEEE International Conference on Industrial Technology (ICIT’96), pp. 269–273 (1996)
31.
Choi, Y.-K., Park, J.-H., Kim, H.-S., Kim, J.H.: Optimal trajectory planning and sliding mode control for robots using evolution strategy. Robot. 18(4), 423–428 (2000)
32.
Chovet, C., Keirsbulck, L., Noack, B.R., Lippert, M., Foucaut, J.-M.: Machine learning control for experimental shear flows targeting the reduction of a recirculation bubble. In: The 20th World Congress of the International Federation of Automatic Control (IFAC), Toulouse, France, pp. 1–4 (2017)
33.
Cornejo Maceda, G.Y., Li, Y., Lusseyran, F., Morzyński, M., Noack, B.R.: Stabilization of the fluidic pinball with gradient-enriched machine learning control. J. Fluid Mech. 917:A42, 1–43 (2021)
34.
Cornejo Maceda, G.Y., Lusseyran, F., Noack, B.R.: xMLC—A Toolkit for Machine Learning Control, vol. 2. Machine learning tools in fluid mechanics. Technische Universität Braunschweig, Braunschweig, first edition (2022)
35.
Cornejo Maceda, G.Y., Noack B.R., Lusseyran, F., Deng, N., Pastur, L., Morzyński, M.: Artificial intelligence control applied to drag reduction of the fluidic pinball. Proc. Appl. Math. Mech. 19(1):e201900268, 1–2 (2019)
36.
Cornejo Maceda, G.Y., Varon, E., Lusseyran, F., Noack, B.R.: Stabilization of a multi-frequency open cavity flow with gradient-enriched machine learning control. J. Fluid Mech. 955, A20 (2023)
37.
Debien, A., von Krbek, K.A.F.F., Mazellier, N., Duriez, T., Cordier, L., Noack, B.R., Abel, M.W., Kourta, A.: Closed-loop separation control over a sharp-edge ramp using genetic programming. Exp. Fluids.57(3):40, 1–19 (2016)
38.
Deepak, B.B.V.L., Parhi, D.R.: Control of an automated mobile manipulator using artificial immune system. J. Exp. & Theor. Artif. Intell. 28(1–2), 417–439 (2016)
39.
del Valle, Y., Venayagamoorthy, G.K., Mohagheghi, S., Hernandez, J.-C., Harley, R.G.: Particle swarm optimization: basic concepts, variants and applications in power systems. IEEE Trans. Evol. Comput. 12(2), 171–195 (2008)
40.
Denisova, L.A., Meshcheryakov, V.A.: Control system synthesis based on multicriteria optimization using genetic algorithm. In: 2017 Dynamics of Systems, Mechanisms and Machines (Dynamics), pp. 1–5 (2017)
41.
Diveev, A., Shmalko, E.: Machine Learning Control by Symbolic Regression. Springer, Cham (2021)
42.
Diveev, A., Sofronova, E., Prisca, D.M.C.: Synthesised optimal control for a robotic group by complete binary genetic programming. In: 2021 IEEE 16th Conference on Industrial Electronics and Applications (ICIEA), pp. 100–105 (2021)
43.
Doyle, J.C.: Guaranteed margins for LQG regulators. IEEE Trans. Autom. Control. 23(4), 756–757 (1978)
