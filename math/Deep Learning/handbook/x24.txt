56.
Saxena, A., Prasad, M., Gupta, A., Bharill, N., Patel, O.P., Tiwari, A., Er, M.J., Ding, W., Lin, C.T.: A review of clustering techniques and developments. Neurocomputing 267, 664–681 (2017)Crossref
57.
Shirakawa, S., Nagao, T.: Evolutionary image segmentation based on multiobjective clustering. In: IEEE Congress on Evolutionary Computation, pp. 2466–2473 (2009)
58.
Shukla, P.K., Braun, M.A., Schmeck, H.: Theory and algorithms for finding knees. In: International Conference on Evolutionary Multi-Criterion Optimization, pp. 156–170. Springer (2013)
59.
Talbi, E.G.: Metaheuristics from design to implementation. Wiley (2009)
60.
Thorndike, R.L.: Who belongs in the family. In: Psychometrika. Citeseer (1953)
61.
Tibshirani, R., Walther, G., Hastie, T.: Estimating the number of clusters in a data set via the gap statistic. J. R. Stat. Soc.: Ser. B (Stat. Methodol.) 63(2), 411–423 (2001)
62.
Wahid, A.,  Gao, X.,  Andreae, P.: Multi-view clustering of web documents using multi-objective genetic algorithm. In: 2014 IEEE Congress on Evolutionary Computation (CEC), pp. 2625–2632. IEEE, Beijing (2014)
63.
Zhang, Q., Li, H.: MOEA/D: A multiobjective evolutionary algorithm based on decomposition. IEEE Trans. Evol. Comput. 11(6), 712–731 (2007)Crossref
64.
Zhou, K., Martin, A., Pan, Q.: A similarity-based community detection method with multiple prototype representation. Phys. A 438, 519–531 (2015)Crossref
65.
Zhu, S., Lihong, X., Goodman, E.D.: Evolutionary multi-objective automatic clustering enhanced with quality metrics and ensemble strategy. Knowl.-Based Syst. 188, 105018 (2020)
Footnotes
1
Cluster validityindices can be external or internal, depending on whether or not they depend on knowledge of the correct partition (ground truth) to determine solution quality.
©  The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.  2024
W. Banzhaf et al.(eds.)Handbook of Evolutionary Machine LearningGenetic and Evolutionary Computationhttps://doi.org/10.1007/978-981-99-3814-8_7
7.  Evolutionary Classification
Bach  Nguyen1, Bing  Xue1, Will  Browne2and Mengjie  Zhang1
(1)
Centre of Data Science and Artificial Intelligence & School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand
(2)
School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, Australia
Bach  Nguyen
Email: Hoai.Bach.Nguyen@ecs.vuw.ac.nz
Bing  Xue
Email: Bing.Xue@ecs.vuw.ac.nz
Will  Browne
Email: Will.Browne@qut.edu.au
Mengjie  Zhang(Corresponding author)
Email: MengjieZhang@ecs.vuw.ac.nz
Abstract
Classification is a supervised machine learning process that categories an instance based on a number of features. The process of classification involves several stages, including data preprocessing (such as feature selectionand feature construction), model training and evaluation. Evolutionary computation has been widely applied to all these stages to improve the performance and explainabilityof the built classification models, where term for this research area is Evolutionary Classification. This chapter introduces the fundamental concepts of evolutionary classification, followed by the key ideas using evolutionary computation techniques to address existing classification challenges such as multi-class classification, unbalanced data, explainable/interpretable classifiers andtransfer learning.
7.1 Introduction
Classification is one of the most important tasks in machine learning as it addresses many real-world problems [39, 120]. The task of classification is to assign a known categorical value (also known as a class label) to an instance based on the instance’s properties (also known as features). An example of classification is email spam detection where the class labels are spamor non-spamand the features are the word frequencies in an email [22].
The label assignment is achieved by building a classifier model that takes features as inputs and outputs the class label. The classifier is built based on a set of labelled instances, called a training set. The quality of the built classifier is then examined by another set of instances, called a test set. Classification problems can be divided into two categories: binary classification and multi-class classification. A binary classification problem has only two class labels, while a multi-class classification problem has more than two class labels.
7.2 Evolutionary Computation (EC) for  Classification: Fundamentals
Generally, the process of building a classifier can be considered a learning process that searches for an optimal classifier model based on a given training set. Since evolutionary computation (EC) has a potential global search ability, it has been widely applied to build classifiers for many real-world applications, such as text classification [48], medicaldiagnosis [89] and image classification[2, 3, 29].
The classification performance depends significantly on the quality of the dataset. However, many datasets contain irrelevant or redundant featuresand noisy instances, which severely deteriorate the classification performance. To address these issues, EC has been applied to preprocess the dataset and/or remove associated negative artefacts during the training process, which can significantly improve the classification performance.
In this section, we will firstly discuss how two established EC approaches: Genetic Programming (GP) and Learning Classifier System (LCSs)can be used to perform classification directly. We will next show how EC can optimise parameters/hyperparameters of standard classification algorithms, and thus improving their classification performance. Finally, we will introduce typical evolutionary data reductionapproaches, which are commonly used as preprocessing steps for classification.
7.2.1 GP for  Classification: Binary Versus Multi-class Classification
GP has a great capacity for classification thanks to its flexible representation which can construct the necessary decision boundaries. GP can be utilised to construct different classifiers such as decision trees [14, 52, 99], classification rules [27, 92, 107] and discriminant functions[119, 129, 132]. Among these classifiers, evolving discriminant functionsis the most common approach so will be the main focus of this chapter.
Discrimination functions are simply a mathematical function whose variables are the features. To classify an instance, the instance’s feature values are passed to the function that then outputs a single output value from the root node (assuming tree-based GP). The output value is compared with a threshold value (or values) to determine the class label of the instance. In binary classification, there are only two class labels, thus a single threshold is sufficient. Particularly, if the output value is greater than a given threshold, the instance belongs to one class, otherwise the instance belongs to the other class. Usually, the threshold is set to zero. Figure  7.1presents a discriminant functionevolved by GP for a binary classification problem. Notice that the evolved discriminant functiondoes not use all features. In other words, GP can select only discriminative features to address a classification task, which is known as the “embedded” feature selectionability of GP.
Fig. 7.1
GP for binary classification. For an instance, if the output of the tree (discriminant function) is greater than 0, the instance is assigned to class . Otherwise, the instance is assigned to class . Note that the tree uses only 4 features {} out of the 9 original features
For multi-class classification problems, GP needs to cope with more than two class labels, which is more challenging than binary classification. There are two main approaches extending GP for multi-class classification problems. The first approach is to treat an n-class classification problem (nis the number of class labels) as nbinary classification problems [51]. Each binary classification problem is to separate one class from the remaining classes, which is handled by a discriminant functionwith a threshold [60, 129, 132]. Thus, for an n-class classification problem, ndiscriminant functionsare evolved. The second approach is to evolve a single discriminant functionwith () threshold values. The () threshold values define nintervals, and each interval represents a class. Therefore, the class of an instance is determined by the corresponding interval that the output value belongs to. More details on GP for multi-class classification will be presented in Sect.  7.3
7.2.2 Learning Classifier Systems for  Classification
Learning classifier systems (LCSs)are one of the few EC algorithms that can perform classification directly. LCSsrepresents a rule-based agent that typically consists of two main components: a discovery component(for example genetic algorithms) and a learning component (e.g., reinforcement learning) [108]. Rules are fundamental knowledge blocks in LCSs, which can be presented in many ways. In this section, we will describe the basic representation for data containing binary features, i.e., the feature value is either 0 or 1. Figure  7.2shows some examples of LCSsrules, which have two main parts: conditionof the feature values and actioncorresponding to the class label. The condition is a vector in which each vector element corresponds to a feature in the data. The element value has three possible values: 0, 1, or “don’t care” (denoted as #). The “don’t care” value can match any value of the corresponding feature, i.e., the corresponding feature will be considered to match both 0 and 1. If all the entries in a rule’s condition match all the corresponding feature values of an instance, the instance is considered to match the rule. Note that, matching does not require the class label of the instance and the action of the rule to be the same, i.e., LCSscan form a complete map that includes incorrect classifiers. Occasionally, it is easier to identify when an input state does not belong to a class than identify the class it does belong to. Figure  7.2gives three examples of LCSs rules, where the first two rules match the instance while the last rule does not match the instance due to the difference in the second feature. It should be noted that LCSsrules can be interpreted as the following expression: “IF conditionTHEN action”. For example, the left most rule in Fig.  7.2: {1 0 # 1 # 0: 1} can be interpreted as:
IF {first bit is 1 AND second bit is 0 AND fourth bit is 1 AND sixth bit is 0}
THEN {the class label is 1}
Fig. 7.2
Examples of LCSs rules presented in a classification problem with 6 features. Each rule has two parts: conditioncorresponding to the feature values and actioncorresponding to the class label [108]
Generalisation refers to the ability of a classifier in covering input samples, which assists to classify unseen/future sample. LCSs, unlike most machine learning algorithms, have an explicit generalisation measure, which is the number of “#” values in the condition. In Fig.  7.2, the left most rule is overspecificsince too many features are specified (i.e., too few “#” values) while the middle rule is overgeneralsince too few features are specified (i.e., too many “#” values). The overgeneral rule may match many instances, but the class labels of at least one instance is predicted wrongly due to the incorrectly removes feature information.
Since an LCSmatches its rules with data instances, LCSsneed to discover a set of collaborative rules to well cover the instance space. The number of rules usually depends on several factors including the problem complexity and the representation. Noting multiple alphabets exist for classifying different types of real-world problems from bioinformatics to sleep patterns [109]. The training process of LCSsconsists of a number of iterations. For each iteration, a single training instance is selected from the training set and the parameters of the matching rules will be adjusted to reflect the knowledge gained and a new rule will be added if no matching rules pre-exist. Once all the training instances have been considered, the training process returns to the first instance and selects from the training set again. Once the training process is finished, the last set of rules is returned as the set of classification rules.
To classify an unseen instance, the instance will be compared against all the rules in the set of classification rules. Each matched rule predicts a class label for the instance. A voting mechanism combines all the predicted classes and outputs the final class for the instance. A key advantage of LCSsis its learning technique with the highly desired benefit of transparencywhere its rules are human-interpretable, which is essential to eXplainable AI.
7.2.3 Vector-Based EC Algorithms for  Classification
This subsection shows how to use EC algorithms with vector-based representations, such as Genetic Algorithms (GAs), Particle Swarm Optimisation (PSO) and Differential Evolution (DE) to tune the parameters of classification algorithms including Support Vector Machines, K-nearest Neighbour and Artificial Neural Networks.
7.2.3.1 Evolutionary Support Vector Machines (SVMs)
The main idea of SVMs is to build hyperplanes (decision boundaries in linear SVMs) that separate instances from different classes. The hyperplane is usually represented by a weight vector w, in which each vector element corresponds to an original feature. Therefore, the size of the weight vector is equal to the number of features. In case the instances are not linearly separable, SVMs will map the original data to high-dimensional data with an expectation that the instances are linearly separable in the high-dimensional space [40, 64]. Such a mappingis usually embedded in a kernel function. One of the most common kernel functions is the following Radial Basis Functions (RBFs):
(7.1)
where and are two training instances and is the kernel width of the RBFs kernel.
The optimal weight vector wcan be obtained by optimising the following objective function:
(7.2)
where wis the weight vector to be optimised, Cis an essential parameter that controls the trade-off between the training performance and the generalisation, and is the allowable margin boundary for the ith class.
Vector-based EC algorithms, such as PSO and DE, can be applied to optimise Cand . For multi-class classification, SVMs learn multiple hyperplanes and each hyperplane separates one class from all the other classes. If there are nclasses, npairs: (), (), ..., () can be optimised. Thus, a candidate solution can be represented as a -vector consisting of parameters. The fitness value of the candidate solution is the classification performance of the SVMs trained with the parameters [31, 33, 44, 64]. This method has been applied to many real-world applications such as cloud computing [134], analog circuits design [125], electricity price forecasting [94] and healthcare [126].
7.2.3.2 Evolutionary K-Nearest Neighbour
K-nearest Neighbour (KNN) is a simple but effective classification algorithm [20]. KNN is known as a lazy classification algorithm since it does not build any model. The performance of KNN relies on three important factors: the distance function, the number of nearest neighbours kand the importance of the neighbours, features and classes [13]. Usually, the importance is represented by a weight vector where the larger weights indicate more important neighbours/features/classes. GAs, DE and PSO have been widely applied to tune these factors since they do not require a well-formulated objective function unlike mathematical optimisation algorithms.
A typical example of evolutionary KNNis proposed by Biswas et al. [13], where class-specific feature weight vectors are optimised by DE. The rationale is that different classes have different feature distributions, and thus their feature importances(i.e., feature weight vectors) are also different. Therefore, each class has its own feature weight vector, also known as a class-specific feature weight vector. Suppose there are cclasses and dfeatures, each candidate solution of DE is a vector consisting of () elements. The last element is to optimise the number of neighbours k. Figure  7.3illustrates the representation of a candidate solution in DE. The fitness value of each candidate solution is obtained by calculating the accuracy of KNN (with the parameters represented by the candidate solution) on the training set. It has been shown that the performance of KNN can be significantly improved by optimising the weight vectors and the number of neighbours ksimultaneously [5, 13, 24].
Fig. 7.3
Representation to optimise parameters for KNN: the first part consisting of weights and the second part is to optimise the number of nearest neighbours k
7.2.3.3 Evolutionary Neural Networks
Artificial neural networks (ANNs) are inspired by simplified learning models of the human brain. An ANN has an input layer that contains a number of input nodes and each input node corresponds to a feature. When applied to classification, an ANN also has an output layer consisting of multiple output nodes and each output node typically shows the likelihood of an instance belonging to a class. Between the input layer and the output layer, there are usually several hidden layers. The nodes or “neurons” in the ANN are connected by connection weights. The main focus of training ANNs is to find the optimal set of connection weights plus a biasterm. The classification performance of an ANN depends on two aspects: its architecture and its connection weights (i.e., the number of hidden layers and the number of neurons in each layer) [63].
The connection weights of ANNs are often optimised by a back-propagation learning process. Firstly, a loss functionis used to measure the difference between an ANN’s output and the desired one. The difference (i.e., error) is propagated back by a gradient-based algorithm to adjust the connection weights. The training process is repeated for a pre-defined number of iterations. A main disadvantage of the back-propagation process is the potential of being trapped at local optima due to its gradient-based nature [21, 45, 46]. EC algorithms have a well-known global search ability, and have been applied to optimise an ANN’s connection weights. Each candidate solution is a vector consisting of the connection weights. The fitness of a candidate solution is the ANN’s classification performance. The results show that vector-based EC algorithms such as GAs, PSO and DE can outperform the back-propagation learning [32, 35, 71]. However, when the networks are larger, especially for deep neural networks (DNNs), the number of weight vectors is significantly increased, which is a challenging task for evolutionary algorithms to address. Recent works have reduced the search space by considering only the biases instead of all the weights [34] or converting large weight vectors set to a small set of orthogonal basis vectors [97]. Besides optimising connection weights, EC algorithms have also been also applied to automatically design or search for the architecture(s) of an ANN, especially DNNs. More details will be given in Sect. 7.7.3
7.2.4 Evolutionary Data Reduction for  Classification
Inthe era of big data, many classification problems have a large number of features and/or instances. Unfortunately, the quantity improvement does not usually lead to a quality improvement [59]. Among a large number of features, many of them do not provide any useful information to distinguish different classes, which are known as irrelevant features. Some features provide the same information as other features, so are known as redundant features. On the instance level, there might be outliers/noisy instances. Any classification algorithm, which overfits such instances, will not generalise well to unseen data, and thus the classification performance will be deteriorated significantly.
The above issues can be addressed by three main data reduction approaches: feature selection, feature constructionand instance selection. Feature selectionaims to select a small subset of relevant features from the original feature set [77]. Feature constructionbuilds new high-level features based on the original low-level features. The number of new features is typically smaller than the number of original features, so feature constructioncan be considered a feature reduction approach. Instance selection, on the other hand, aims to remove noisy instances [83]. The key challenges of the three data reduction tasks are the large, discrete and rough search spaces, where EC algorithms usually cope well. The literature has shown that evolutionary data reductionapproaches have achieved great classification performance while significantly reducing the amount of data [122]. The following subsections briefly explain how EC algorithms can be applied to achieve feature selection, feature constructionand instance selection.
7.2.4.1 Evolutionary Feature Selection
Suppose there are doriginal features, thetotal number of possible feature subsets is , which exponentially increases with respect to the number of features. Each feature subset is a candidate solution and the key question to enable EC to address these tasks is how to represent a feature subset. Generally, there are three main feature selection representations: vector-based representations, tree-based representations and graph-basedrepresentations[77].
Among the three representations, the vector-based representation is the most common one. Figure  7.4shows an example of a vector-based representation, where each vector element corresponds to an original feature. The element’s value shows whether the corresponding feature is selected or not. Vector-based representations can be further divided into two main sub-categories: binary vectors and continuous vectors. In the binary one, each vector element is a binary value, where “1” indicates that the corresponding feature is selected while “0” indicates that the corresponding feature is discarded. In the continuous one, each vector element is a continuous value in the range [0, 1]. If the vector element is greater than a threshold value (set to 0.6 in Fig.  7.4), the corresponding feature is selected. Otherwise, the corresponding feature is discarded. While the binary one has been widely used by GAs [4, 123], the continuous one has been widely used by PSO [23, 75, 78] and DE [116].
The tree-based representation is mostly used in GP. The idea is that if a feature appears in a GP-based classifier (Sect. 7.2.1), it indicates that the feature can provide relevant information to distinguish different classes. Thus, on top of explicit feature construction, feature selectioncan be achieved by selecting all or some of the features in a tree-based classifier as shown in Fig.  7.5
In graph-based representations, each feature is a node in the graph. If a node is visited, the corresponding feature is selected. Figure  7.6shows an example of graph-based representationwhere the solid arrow path connects the selected features. Graph-based representations are mostly used by ant colony optimisation (ACO) [66, 85].
Fig. 7.4
Vector-based representation for feature selection
Fig. 7.5
Tree-based representation for feature selection
Fig. 7.6
Graph-based representationfor feature selection
Figure  7.7illustrates the overall feature selectionsystem consisting of two main components: subset discovery and subset evaluation. The subset discovery component is responsible for generating new feature subsets. Depending on the representation, the subset discovery can be performed by a suitable evolutionary algorithm. For example, PSO, DE and GAs are usually used to generate candidate solutions represented by a vector-based representation. The subset evaluation component then measures the goodness of the generated subsets. Based on the feedback from subset evaluation, subset discovery is expected to generate more promising feature subsets. The “generating-evaluation” process is repeated until a stopping criterion is met, and then the best feature subset is the final solution. Two common stopping criteria are the maximum number of generations and the maximum number of evaluations.
Fig. 7.7
Overall feature selection system
Based on the evaluation criterion, feature selectionmethods can be divided into three categories: wrapper, filter and embedded approaches. The wrapper approach trains a classification algorithm multiple times to evaluate all the candidate subsets, which considers the interactions between the classification algorithm and the feature subsets. In contrast, the embedded approach trains an embedded classification algorithm and selects features based on the trained classifier. For example, we can train a GP-based classifier and then select features appearing in the final tree. Instead of using classification algorithms, the filter approach uses statistical or distance measures to evaluate feature subsets. Some common filter measures are Relief [110], mutual information [80] and correlation measures [38]. Among the three approaches, the wrapper one usually achieves the highest classification performance but requires intensive computational resource. The filter one is the most efficient one but usually achieves the lowest classification performance. The embedded one comes between the wrapper and the filter in terms of the classification performance and the computational cost
7.2.4.2 Evolutionary Feature Construction
