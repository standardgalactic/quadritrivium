8.1 Introduction
Evolutionary Ensemble Learning (EEL) is taken to encompass the development of teambehaviours that collectively solve a problem through a process of ‘divide-and-conquer’. As such the terms teamand ensemblewill be used interchangeably. Team members will be referred to as participantsor agentsand a teammust have more than one participant. The definition we will assume for a participant will take the following form:
Definition 8.1
Each participant (agent) performs an independent mappingfrom input (state) space to output (action) space.
Such a definition is adopted in order to distinguish participants from other approaches to ‘divide-and-conquer’ such as modularity, e.g. automatically defined functions [115]. In short, the above definition implies that all participants are modules (because a participant never acts outside of a team), but not all modules are participants. Indeed, most instances of modularityfollow a sequence of a callee referencing the module, passing a set of arguments, the module performing some computation and the callee using the returned variable(s) in some larger calculation. As such modules are typically representation-specific, whereas teamparticipants are generally agnostic to the representation. Given such a stance, the focus of the chapter will be on the mechanisms which define the relationships between participants and therefore facilitate the processes of problem-solving through divide-and-conquer.
Historically, prior assumptions were often made about task decomposition and therefore teamcomplement. For example, entirely homogeneous teams in a herding task [168] or requiring heterogeneous teams to consist of one instance of each agent ‘type’, e.g. writing and reading to memory [32] or classes in a classification task [147]. The ‘level of selection’represents a reoccurring theme (Sect.  8.3), which is to say, does selection/variation/replacement appear at the level of teamor participant? Initially, two basic approaches for evolving teams became established: the teamas a single unit of selectionversus sampling a participant from independent cooperative populations each time a teamis composed.1Early examples in which teams were the unit of selectionassumed a multi-tree representation, e.g. [81, 134]. At the same time, multi-population models (e.g. [87, 201]) increasingly became associated with cooperative coevolutionand multi-agent systems(Sect.  8.4).
Diversitymaintenance also represents a reoccurring theme, with different state representations having an impact on preferences for heterogeneous versus homogenous teamcompositions[134]. However, diversitymaintenance is also linked to a desire to solve tasks of increasing difficulty [15, 133]. Hence, there is no need to use an ensemble if a single participant can solve the task, but if an ensemble is necessary, how can a meaningfuldivision of duties across participants be achieved?
This chapter develops the topic of EEL through two basic perspectives that initially developed independently:
Ensemble learning as applied to regression and classification or a supervised learning perspective, hereafter supervised EEL or sEEL(Sect.  8.2).
Cooperative coevolutionas applied to multi-agent systemsor a form of reinforcement learning, hereafter maEEL(Sect.  8.4)
Participants in sEEL are always heterogeneous, whereas maEEL places more emphasis on finding mtypes of agent to appear in a team of nagents where . The concept of a team alsointroduces the topic of ‘level of selection’(Sect.  8.3) to the team or the agent (or both). Section  8.5reviews research that attempts to extend the concept of an ensemble to variable-sized ensembles (hereafter vEEL), with the objective of further scaling the scope of tasks that EEL can be applied to. The chapter concludes with a summary of applications that potentially benefit from assuming ensemble formulations (Sect.  8.6) and a concluding discussion (Sect.  8.7).
8.2 Ensembles for  Supervised Learning
An ensemble under a supervised learning context is taken to imply a partnership between ndecision-makers to solve a supervised learning task such as regression or classification. Classically, a bias–variance decomposition [33, 118] might be used to establish the extent to which error can be attributed to:
the average behaviour differing from the desired function. Typically denoted the biasin which case under-fitting the data is said to result in a solution with ‘high bias’.
the ensemble is sensitive to the data set used to train the model. Typically denoted the variancein which case overfitting on training leads to high variance on test data.
Ensemble learning in general, therefore, attempts to compose a teamof agents that exhibit diversity intheir respective behaviours to optimize the bias–variance tradeoff. Such a framework has seen use with neural networks [29, 73, 78], genetic programming [2, 99, 100, 158] and ‘wide’ neural networks [24] as well as providing early insightsto ensemble construction. With this in mind, ensemble learning as practiced outside of evolutionary learning often enforces diversity using one of three mechanisms:
Bagging:nagents are independently constructed from ndifferent samples (or ‘bags’) taken from the original training partition [33].
Boosting:constructs nagents sequentially with the performance of earlier agents used to biasthe selection of data to appear in the training partition for the next agent [34].
Stacking:agents comprising the ensemble are trained on training folds. A ”meta agent” is then trained from the agents” predictions to define the ensemble’s overall prediction [221]. Other variants include cascading in which nagents are added sequentially, augmenting the data with their prediction [70].
Successful ensembles identify participants that are sufficiently accurate, yet ‘disagree’ with each other [118, 156]. As a consequence, many approaches have been proposed for maintaining ensemblediversity [119, 120]. However, diversity in itself is not a guarantee for an effective ensemble, i.e. diversityis relative to the behaviour of other participants comprising the ensemble. Moreover, ensemble learning as defined above implicitly assumes that only one candidate solution is developed at a time. Conversely, evolutionarylearning algorithms maintain multiple candidate solutions simultaneously (the population). This implies that there are potentially more avenues for pursuing diversity and participant composition than under non-evolutionary approaches to ensemble learning. Assuming a broader perspective on diversityand/or composition enables us to identify five themes that sEEL might support exclusively or collectively, Fig.  8.1. We detail each of the five themes in Sect.  8.2.1and make summary observations on sEEL in Sect.  8.2.2
Fig. 8.1
Properties of significance to Supervised Evolutionary Ensemble Learning (sEEL). aDiversity maintenance takes the form of data diversity (what data is an ensemble participant constructed from) and reward diversity(what is the performance function each participant experiences). Ensemble composition reflects (1) the diversity of mechanisms assumed for aggregating participants’ predictions, (2) the degree of segregation appearing in the operation of participants and (3) the diversity in representations assumed for participants. bLevel of Selectionhas an impact on segregation and representation (Sect.  8.3)
8.2.1 Diversity Maintenance in  Supervised Evolutionary Ensemble Learning
Figure  8.1divides sources of diversity insEEL as applied to supervised learning tasks such as regression and classification into explicit ‘diversity maintenance’ versus ‘ensemble composition’. Diversitymaintenance is divided further into diversity through the data that different ensemble participants experience during training versus adaptation of the performance (reward) function, i.e. each participant potentially experiences a different performance function. Ensemble composition reflects different mechanisms by which the ensemble might be constructed. We divide this concept into three themes. Aggregation defines the mechanism assumed for combining the predictions from individual participants into an overall ensemble recommendation. Segregation characterizes how the role of participants might be revised during evolution and is related to credit assignmentbut reflects properties specific to evolutionary computation (e.g. the role of selection). Finally, representational diversitycaptures the ability of evolutionary computation to develop unique topologies as well as parameterize them. That said, most sEEL as applied to supervised learning tasks assume that the number of participants, n, is known a priori. The case of evolved participant complements and consequently context-specific participant deployment will be developed later (Sect.  8.5). In the following, we detail each theme in more detail.
Data diversity:implies that different participants of an ensemble are trained with different distributions of data. Adopting baggingstrategies for ensemble learning represents a reoccurring theme [27, 68, 88]. Bagging might also be used with massively parallel computing platforms in order to accelerate the evolution of multiple participants from different partitions of the data, thus scaling sEEL to large regression and classification datasets [17, 18, 212]. Baggingmethods were recently revisited for outlier reduction using niching [50], coevolutionof participants and ensembles [170] and assessing participants over multiplebootstrapsamples [214]. Likewise, partitioning the data into nfolds (one fold held out from each data subset) enables nensemble participants to be independently trained [90]. Competitive coevolution[69, 72, 126, 192] or active learning [83, 111, 185] have been used to adapt the data that ensemble participants experience duringthe course of evolution. That is to say, during evolution the most discriminatory exemplars will change as a function of the performance of the ensemble. In a further development, Lexicase selectionrepresents a recent evolutionary selection mechanism for diversitymaintenance using as little as a single exemplar to identify a parent [82]. Support for explicitly modular representations, such as sEEL, appears to provide a more effective mechanism for utilizing the available diversity [165]. Finally, ensembles have been incrementally constructed with the first participant evolved against the entire training partition. Thereafter, each additional ensemble participant is only evolved against the data that could not previously be labelled. This focuses each additional participant on what the ensemble cannot previously label [228].
Reward diversity:manipulatesthe performance function so that different participants of the ensemble experience different rewards. Early examples include boosting[68, 88, 162], cascade correlation [166], fitness sharing [172, 184] and negative correlation [128].2Other natural extensions include the use of multi-objective methods to trade off diversityand accuracy of ensemble participants [40, 41, 63, 123] and the simultaneous minimization of the resulting ensemble complexity [42]. Moreover, multi-objective performance criteria may represent a more robust predictor of (post-training) ensemble performance than ranking using a single objective [129]. Recently, novelty measures [37] and surrogate models[36] have been used to evolve ensembles for computer vision benchmarks such as CIFAR and SVHN. Under streaming tasks, other properties such as participant age have been used to prioritize participant replacement [67, 111]. Cooperative coevolutionary formulations imply that ensemble participants are sampled from ndifferent populations [166]. The fitness that ensemble participants receive is used to direct development within each of the ndifferent populations. This introduces issues regarding the fitness of ensembles versus participants (level of selection, Sect.  8.3) and a range of advantages and potential pathologies[159].
Ensemble aggregator:recognizes that once the participants of an ensemble are identified, then mechanisms need to be adopted to map from the nindependent (participant) recommendations to a single (ensemble) recommendation [31]. Depending on the task, the optimal approach for combining recommendations might differ, i.e. majority voting, winner takes all [31, 85, 194] or Bayesian networks [198] in classification versus weighted average [47] and Bayesian model averaging [3] in regression. For example, an averaging assumption might penalize the development of specialists in regression tasks [161]. One potential approach for addressing this issue is to augment the ensemble with an additional participant (the ‘gate’). Such a participant learns how to switch or blend the output from the nensemble ‘experts’ [161]. Such a ‘mixtures of experts’ architecture can be deployed hierarchically [96] and has seen widespread use with neural networks [226]. Nguyen et al. go a step further and actively coevolve ensembles using the mixtures of experts framework [150, 151]. More recently, the concept of a convex hull has been deployed to identify the ensemble participants with Boolean operators defining the ensemble aggregation function [123]. Tsakonas and Gabrys use grammatical evolution to optimize a hierarchyof aggregation functions deployed to different combinations of ensemble participants [208]. The aggregator itself can be evolved [31, 121], where this would be synonymous with wrapper approaches to feature construction, i.e. the aggregator would be a regressor or classifier [77]. Evolving either linear or non-linear aggregators has been shown to be more effective than a ‘fixed’ voting scheme [31, 121]. However, there is a computational overhead associated with the case of evolved non-linear aggregators [121]. Finally, we note that solution interpretabilityis likely to be impacted by the choice of aggregator, i.e. a ‘winner-takes-all’ (versus majority) operator attributing a prediction to a single (versus all) participant(s) of an ensemble.
Participant segregation:captures the degree to which the nparticipants evolveindependently and is influenced by the approach to selection (level of selection, Sect.  8.3). This is distinct but related to the degree to which the data (or performance function) is manipulated to establish ndistinct behaviours. For example, nindependent populations could be evolved on the same data (e.g. [90]) as opposed to evolving nindependent populations on different samples from the training partition (bagging). This also leads to the use of libraries or archivesof previous behaviours so that an evolutionary method can identify: (1) the participants to include in the ensemble from the library; and (2) how to weigh their respective contributions [27, 94]. Hybrid approaches have also been proposed in which: (1) a spatial embedding is used to define the migration protocol between independent populations [68]; or (2) variation is allowed between populations associated with different partitions of the data [27]. Alternatively, the champions from each of the nindependent runs can be compared for their relative diversityand entire populations pruned should their champions be deemed too similar [38]. Rebuli and Vanneschi propose a model for multi-class classification with ndemes, i.e. variation takes place between demes [167]. Later, a ‘phase change’ takes place after which the ndemes are treated as islands, i.e. variation limited to the same population. Multifactorial evolutionary algorithms solve multiple optimization problems using a single population in which different ‘tasks’ are present. Unlike cooperative coevolution, sharing takes place between participants associated with different tasks, i.e. soft segregation. The approach has been demonstrated in the context of evolving ensembles for multi-class classification problems [217]. Finally, ensemble participants might instead be strictly organized as a stack/cascade with a participant evolved to make a prediction or defer judgement to a later participant(s) [228]. Different subsets of the dataset are then labelled by different ‘levels’ of the stack/cascade.
Representational diversity:impliesthat participants comprising the ensemble are free to adopt different types of representation. We distinguish between coarse- and fine-grained representational differences. Coarse-grained representational differencesimply that entirely different machine learning paradigms were deployed to develop participants, e.g. decision tree induction, Naive Bayes, multi-layer perceptron. Such an approach has been demonstrated for non-evolutionary machine learning [132], but could be achieved using a cooperative coevolutionary approach (different populations for each representation). Neural networks potentially benefit from assuming different architectures, thus diversityin the networks appearing within ensembles has been considered [128] as has diversityin the activation function[209]. In addition, rather than assume a behavioural performance metric to select ensemble participants, a genotypic performance metric might be preferred. As such, ensemble participants are selected for those that have the most unique representations [68, 85, 112]. Likewise, grammatical evolution has been used to evolve ensembles with different types of representation for rule induction [95]. Cloud-based computing services have also been used to simultaneously evolve multiple participants with different representations in parallel for solving large classification problems, e.g. learning classifiers versus genetic programming [18]. In a related approach, Fletcher et al. assume that multiple ensembles are trained, each with a different ‘base classifier’ and an evolutionary multi-objective approach is adopted to select the best ensemble [63]. Note that the base classifier is common to the same ensemble, but different across ensembles.
Fine-grained representational differencesacknowledges the ability of the same evolutionary computational paradigm to evolve the topology of individuals as well as parameterize them. As such this will be impacted by the approach to selection or the level of selection, Sect.  8.3. Two general approaches have been widely adopted: multi-trees[31, 147, 194] (i.e. specific to genetic programming) or cooperative coevolution[159, 166] (i.e. agnostic to the underlying participant representation). Both approaches assume that the number of participants, n, is known a priori. For example, it might be assumed that the number of participants and classes requiring classification are the same. Section  8.5reviews representations that evolve ensembles/teams that support a variable number of participants. This ultimately implies that participants can be deployed depending on input context rather than always simultaneously deploying all participants.
8.2.2 Discussion
Section  8.2.1established that sEEL for supervised learning provides multiple paths by which diversity inensemble learning can be maintained/introduced. Baggingand boostingcan be considered specific mechanisms by which data andreward diversitymight be supported. Stacking—the third form of diversity classically recognized in non-evolutionary ensemble learning—appears as an instance ofrepresentational diversity. However, assuming that participants are ‘evolved’ using variable length representations such as genetic programming means that unique participant topologies can be discovered.3Representational diversitymightadditionally be considered when the number of participants, n, is not defined a priori as a hyper-parameter. Section  8.5will develop this topic further. The property of participant segregation is specific to evolutionary computation on account of multiple participants being developed simultaneously. Diversityin the aggregation operation has seen a wide range of approaches, ranging from methods developed for Bayesian and neural networks to evolving the aggregator itself. We note, however, that such approaches are still limited to the ‘classical’ model of ensemble deployment: an ensemble consists of nparticipants and all participants participate in each prediction. We consider the implications of relaxing this constraint in Sect.  8.5.2when graph-based representationsare adopted.
A further set of observations can also be made independently of the specific diversitymethods adopted, as follows:
Strong ensemble performance does not imply that individual participants are also strong [31, 195]. Thus, there could be orders of magnitude differences between the performance of the ensemble and the participants comprising the ensemble. Indeed, selection for explicitly strong yet complementary ensemble members, as opposed to the original emphasis on ensembles composed from weak learners alone (e.g. [177]), represents a recent theme in sEEL [180–182].
Participants of an ensemble are typically much simpler than when single ‘monolithic’ solutions were evolved for the same task. Depending on the task, the ensemble might also be collectively simpler than single monolithic solutions evolved for the same task [31, 88, 127]. Indeed, the participants of the ensemble might be more effective when simplicity is emphasized [123, 171].
Assuming pairwise diversity measures does not necessarily lead to system-wide diversity [62]. Conversely, system-wide metrics, such as measuring the expected failure rate [90], have to date only been applied post-training. Using multi-objective formulations may benefit from defining the dominance relation on the basis of an entire performance characteristic, as opposed to single operating points [123], or modifying multi-objective formulations to incorporate validation data [176].
Methods based on segregation and/or fixed partitions of training data are not able to adapt performance to changes in the behaviour of different ensemble participants. Adaptive reward functions might only be able to achieve this by rendering the training process serial, i.e. cascade correlation [166]. Conversely, serialization of the training process can result in considerable speedups when participants are able to distinguish between making a prediction versus deferring to another participant [228].
The multi-tree representation assumes that performance is evaluated at the ‘level’ of the team (Sect.  8.3). Constraints can potentially be enforced to ensure context between different participants. For example, under a class classification problem, crossover might be limited to exchanging material between participants labelling the same class [147]. Additional participant-specific performance functions might be included in order to penalize unwanted participant properties [205, 223], although the ability to do this might be limited to specific applications. Multi-trees can also be evolved to provide multiplelayers of abstraction. Such an approach has been demonstrated to be particularly effective for designing operators for image processing [89].
Coevolutionary formulations for composing an ensemble have to sample one participant from ndifferent populations in order to construct a single ensemble. Fitness then needs to be interpreted at the level of individual ensemble participants, resulting in various potential pathologies. This is discussed further in Sect.  8.3and potential solutions are reviewed in Sect.  8.4
Finally, we note that an ensemble actually presents multiple decisions regarding the ‘level of selection’, i.e. the teamversus the participant. This represents a theme common to both sEEL and maEEL. Section  8.3will therefore develop this topic specifically before ensembles are discussed from the perspective of multi-agent systems(Sect.  8.4).
8.3 Level of  Selection
The concept of level of selectionreflects the two levels at which credit assignment operateswhen multiple agents are involved in making decisions. As per Definition 1, an ‘agent’ (or ensemble participant) in this context is a fully functional decision-making partner that performs a mappingfrom input (state) to output action. Such an agent might be a neural network, genetic program, decision tree, etc. Thus, given a pool of agents and a team/ensemble comprising of nagents, the level of selectionproblem reflects the following two issues.
Definition 8.2
Team composition:isthe likelihood of mappingan agent to a ‘position’ in the team/ ensemble consisting of a fixed number of agents.4There are two extremes: all participants of a teamare unique (heterogeneous team composition) or all participants of a teamare the same (homogeneous team composition), Fig.  8.2
Definition 8.3
Unit of selection:operates at the level of agentsappearing within a teamor at the level of a team, as shown in Fig.  8.2. Naturally, this implies that it is possible to express performance objectively at the level in question. Generally, the performance of a team can always be expressed objectively. However, depending on the task, expressing performance at the level of agents participating with a teammay or may not be possible. In the worst case, team and agent performance might not be aligned.
Fig. 8.2
Level of selection [215]. Full homogeneity (a) and (b) assume that all nagents per team are cloned from one of Pgenotypes. Full heterogeneity (c) and (d) assume Mteams by nagents. Fitness evaluated at the level of individuals (a) and (c) versus team-level fitness evaluation (b) and (d). Reproduction at the level of individuals implies that two agents are chosen and an offspring agent results. Reproduction at the level of teams implies that two teams are chosen and variation operates at the level of team and possibly agent as well
The previous discussion of ensembles (Sect.  8.2) implicitly assumed that agents participating within an ensemble were all different (heterogeneous). Moreover, when the multi-tree representation is assumed the unit of selectionis typically that of the team[147]. Two parents are selected using team performance and crossover swaps teamparticipants to create offspring, i.e. performed at the level of the team. In addition, ‘strong typing’ might also be assumed to direct the action of crossover such that only agents (sub-trees) with the same type are interchanged. Thus, for example, multi-trees applied to classification tasks might limit sub-tree crossover to classes of the same type [147]).
However, this need not be the case. Assuming that suitably informative performance functions could be designed for participants as well as at the complete ensemble/team, then the Orthogonal Evolution of Teams (OET) is able to [173, 204, 205]: 
1.
select parents at the level of participants but replace at the level of teams (OET1), or;
2.
select parents at the level of teams but replace at the level of participants (OET2).
Such an ‘orthogonalization’ of the processes of selection and replacement was motivated to have credit assignmentoperate on the two levels simultaneously. Given an ensemble of size nthere are nparticipant populations. Teams potentially represent columns sampled across the nparticipant populations [173]. Benchmarking with different classification tasks indicated preferences for different OET configurations [205]. However, OET2 appeared to be more effective at ‘repair’ when applied to a multi-agent foraging task [204]. We also note that the OET approach was independently discovered and used to evolve neural networks with an a priori fixed architecture [76], where each participant population was associated with a specific weight population and the ensemble was a complete network. A similar ‘orthogonalized’ process for the level of selectionwas used to direct the action of selection and replacement.
The concept of level of selectionimplies that decisions made regarding the teamcompositioncould have an impact on the degree of specialization versus the generality of agents supported in a team. For example, cooperative coevolution(Sect.  8.4) often assumes fully heterogeneous teams, making it difficult to establish teams composed of multiple instances of different types of agents. Moreover, as the level of selectionis often that of the team, coevolutionary pathologiesmay arise such as:
mediocre stable states:a form of deception in which agents collaborate to lead progress away from the global optima [74, 159].
relative overgeneralization:agents with specialist behaviours are explicitly selected against [159].
loss of fitness gradient:the performance of a few ‘affective’ agents is hidden by the poor performance of the majority of agents within a team. Also referred to as the ‘signal-to-noise’ problem [6].
hitchhikers:in this case is synonymous with agents that exist within a team that does not contribute anything. Such agents reproduce, but do not contribute to the performance of the team [138, 141].
Section  8.4revisits these pathologiesin more detail under the context of multi-agent systems(cooperative coevolutionis frequently used with multi-agent systems). Figure  8.2summarizes the level of selectionconcept, albeit assuming 4 ‘types’ of agent and teams of size . Waibel et al. performed a series of empirical evaluations of all four discrete parameterizations ofteam compositionand level of selectionusing three tasks [215]. The tasks were designed to reward: (1) individual foraging, (2) cooperative foraging and 3) altruistic foraging. Agent specialization was not considered in these tasks. Heterogeneous teams with individual selection (Fig.  8.2c) were preferable when no cooperation was necessary. When cooperation is necessary, homogenous teams are preferable. However, the study came with some caveats, in particular teams were entirely homogeneous or heterogeneous. This means that it was not possible to construct teams with ainstances of agent type i. Such hybrid team compositions mightbe considered the norm for composing optimal solutions to many tasks, such as multi-agent robotics.
A further study considered the impact of variation operators under hybrid team compositions[124]. The authors set themselves the goal of attempting to evolve teams consisting of 1,000 agents, in which specific combinations of agent types have to be found given 10,000 distinct types of agents. Uniform crossover with free or restricted gene transfer (FAR and RAS respectively) was assumed (Fig.  8.3). The underlying conclusions were that RAS would converge quickly, where this would enable it to solve tasks involving many different teams (highly heterogeneous team compositions). However, when more homogeneous teams were required, the diversitymaintenance provided by FAS was the most effective. In addition, the authors show that by deploying FAS for the early generations and RAS in the latter generations, then hybrid team compositionscan be discovered. This topic will be particularly important when composing teams for multi-agent systems(Sect.  8.4).
Fig. 8.3
Level of crossover [124]. Agent-level crossover aand bidentify two agents within two teams and recombine the agent’s genotypic material. Team-level crossover cand didentifies two agents within two teams and swaps the (entire) agent genomes. Restricted crossover aand cassume the position of the first agent. Free crossover band dmay choose agents from different team positions
Questions left unanswered include the relative impact of attempting to evolve both agent and team compositionsimultaneously and the impact of gene linkageduring the course of evolving team composition. Also left unanswered is the effect of reinventing agent policies. Lichocki et al. concentrated on team composition [124], whereas agent discovery might benefit from the tradingof generic abilities.
8.4 Multi-agent Systems and  Cooperative Coevolution
Multi-agent systemsattempt to solve a task cooperatively using a finite set of agents and are typically applied to reinforcement learning5(RL) tasksinvolving more than one decision-making agent. On the one hand, it is possible that a task might be solved optimally with the same agent deployed across the entire teamor a purely homogeneous deployment. Conversely, at the other extreme, a task might be solved optimally with each agent comprising the team being unique (a purely heterogeneous deployment). Naturally, the number of agents, n, comprising the (multi-agent) teamis known a priori. Thus, when describing the players participating in a soccer team, the number of players is known. Likewise, the number of robots available for performing a collective task might well be known. Under the sEEL context (Sect.  8.2) these issues are not as prevalent because the only teamcompositionsthat are appropriate are purely heterogeneous. Figure  8.4summarizes the reoccurring themes that will be developed from an explicitly maEEL perspective.
Fig. 8.4
Properties of significance to Multi-agent Evolutionary Ensemble Learning (maEEL). aTwo major themes are identified: (1) Diversity maintenance is parameterized from the perspective of genotypic/phenotypic diversity, task transferand reward shaping. (2) Cooperative evolution which is impacted by the level of selection(Sect.  8.3), coevolutionary pathologiesand also reward shaping
Under a homogeneous deployment, one population is sufficient for sourcing the agents, and the concept of fitness at the level of team versus individual agent is aligned (Sect.  8.3). However, under heterogeneous settings, a multitude of possible mappingsexist between population(s) sourcing the agents, and team composition(Sect.  8.3). At one extreme, a single population exists with each agent representing a participant of the multi-agent team. Under such a setting, incremental models of selection and replacement are assumed in order to gradually turn over the content of the population and speciation/fitness sharing used to maintain population diversity, e.g. [197]. At the other extreme, each agent is associated with an independent population, this is the case of cooperative coevolutionas formulated by Potter and De Jong [166].
To date, the cooperative coevolutionary formulation represents the typical starting point, Fig.  8.5. As such, one agent is sampled from each population in order to construct a single multi-agent teamof nagents [166]. Thus, population ionly ever source agents for ‘position’ iin the multi-agent team. Put another way, population ionly ever source agents of ‘type’ i; therefore, the contextbetween agent and position within the team is explicit. Reproduction and replacement only occur between participants of the same population. Moreover, cooperative coevolutionis agnostic to the representation assumed to define the agents. Indeed, the populations associated with each agent (type) could have entirely different representations.
Fig. 8.5
Cooperative Coevolution[166]. Populations A, B and C only provide agents for team positions 1, 2 and 3, respectively. The context/type for each agent is therefore explicit. However, this forces teams to be heterogeneous. Evolving hybrid compositions requires the introduction of different team-level representations (Sect.  8.4.3)
Naturally, performance is evaluated at the level of a team. However, fitness of agent ifrom an nagent team is a function of the other agents participating within the multi-agent team. As a consequence, Nsamples (and therefore fitness evaluations) are made of the agents from the other populations in order to establish the fitness of agent i. However, cooperative coevolutionrequires a measure of fitness to be returned to individual agents in order to direct the population-specific process of reproduction and replacement. At this point, pathologiescan appear during credit assignment. For example, it became apparent that using the average (team) fitness from the Npartnerships used to quantify the performance of agent iresults in team compositionsthat favour mediocre stable states [74, 159]. In addition, relative overgeneralization may appear, where many individuals represent ‘jack-of-all-trades’ style solutions. This in turn precludes the development of specialists that could improve the overall collective performance of a team [159].
An early mechanism adopted for reducing these biases was to assign an agent its best fitness from the Npartnerships as opposed to the average of all Npartnerships [220]. This was later refined to using an annealing schedule to reduce the number of partnerships assessed as the number of generations increased [160]. Most recently, the issue of premature convergence in cooperative coevolutionary approaches to multi-agent systemshas been addressed through the use of diversitymeasures (Sect.  8.4.1) and/or task variation (Sect.  8.4.2).
A related pathology that multi-agent systemscan experience is with regards to a loss of fitness gradient. Specifically, as the teamsize increases, then the performance of one ‘good’ agent can be lost in the ‘noise’ created by all the poor-performing agents, i.e. a signal-to-noise problem. Attempting to address this problem by increasing the number of partners that agent iis evaluated with will not scale as the team size increases.
Agogino and Tumar proposed to address this problem by adopting factored (difference) performance functions [6]. This implies that for any state, the runner-up solution is known such that the effect of substituting the runner-up for the target agent can be estimated. Such functions have been demonstrated for a cross-section of applications involving agent deployments, e.g. sensor networks [4], air traffic control [5], multi-rover co-ordination [6].
Factored performance functions effectively reshape the reward such that improvements by a single agent also improve the multi-agent reward [44]. Shaping the reward in this way is easier to achieve when the agents are ‘loosely coupled’. Loose coupling implies that the actions of one agent are not closely dependent on another, i.e. a form of gene linkage. It is more difficult to formulate factored performance functions when agents are tightly coupled [51]. For example, should one agent be doing something useful, such as attempting to push a highly valued object, unless the other agents also perform the same action, there might be no reward. This plays into being able to more explicitly control the degree of homogeneity/heterogeneity so that there are ainstances of agent type iand binstances of agent type k. Hence, rather than attempting to evolve all agents independently, it might only be necessary to evolve 2 different agent types in a teamof 20. Evolving teams with a hybrid mix of homogeneity/heterogeneity is discussed further in Sect.  8.4.3
8.4.1 Diversity Maintenance
Diversityin cooperative coevolutioncan be promoted using behavioural (phenotypic) or genotypic properties at the level of team and/or agent. Diversity in the underlying teamobjective is often achieved by adopting multi-objective formulations in which several possibly conflicting objectives describe the underlying goal [43, 227]. Pareto formulations encourage tradeoffs between the different objectives to be investigated by different teamcomplements. Moreover, they can also be used to provide a sequence of objectives of incremental difficulty that can lead to solving some (more difficult) overall objective [207].
Diversitymaintenance represents a general challenge when evolving multi-agent systems. As such multi-objective methods have been widely adopted in an attempt to simultaneously develop task-specific objectives and promote diversity[144, 145]. Several approaches have appeared, including initially developing diverse behaviours on a set of source tasks using multiple novelty objectives. The non-dominated individuals are used to seed the population for the target task(s) [143]. Conversely, Doncieux and Mouret include the task-specific objective throughout, but switch between different diversity objectives [54]. Such task switching has been recognized as a potential mechanism for promoting ‘modular’ solutions in general [164].
Several studies have demonstrated their applicability across a range of benchmark tasks: predator–prey [74], herding [74], multi-rover [74], half-field offence soccer [103] and Ms Pac-Man [103]. Genotypic diversitycan be captured by measuring the pairwise similarityof teamcontent between teams [74]. Moreover, such metrics can also be formulated for variable size teams [103]. Novelty metrics have been evaluated at the level of individual participants of a teamas well as at the team level. A distinct preference for maintaining diversityat the level of the team has been reported [74, 152]. Moreover, experiments with and without behavioural diversity, genotypic teamdiversity and multiple source tasks indicate that the most general solutions appear when multiple forms of diversity appear [74, 103, 152].
8.4.2 Task Transfer
Task transfer(or layered learning)represents a mechanism for scaling learning algorithms in general and multi-agent (or cooperative coevolutionary) systems in particular to tasks that cannot be solved directly (tabula rasa), e.g. [178, 199, 202, 219]. This is also referred to as the bootstrapproblem [143, 207]. As such, one or more source task(s) need identifying, typically a priori, with the evolution of the multi-agent systemfirst performed on the source task(s). Policies or entire teams are then used as a ‘run transferable library’ for use during an independent evolutionary cycle conducted against a target task [101, 103]. The library might be used as seed material for initializing the population evolved against the target task, i.e. the agent-teams discovered under the source task are modified. For example, participants taking the form of code fragments6have been evolved using learning classifier systems on small-scale Boolean tasks and scaled to solve Boolean problems of larger dimension [13, 91]. Conversely, the solutions from the source task might be referenced by agents as evolved against the target task [101, 103], i.e. the solutions identified under the source task are not subject to variation during the development of the target task. The end result is an ensemble with a variable-sized structure that deploys solutions to source tasks in innovative ways to solve target tasks [108, 189] or the evolution of ensembles for solving multiple target tasks simultaneously [104, 108, 109] (reviewed in Sect.  8.5). In some cases, configurations of the task can be specified by members of an independent population. Competitive coevolutioncan then be used to establish an ‘arms race’ between candidate solutions (the teams) and the task [117]. This leads to a more open-ended process of teamdevelopment [186, 190].
To date, task transferunder neural evolution tends to assume a population-seeding approach to task transfer[149]. Early examples evolved a neural network under a lower dimensional input space7and transferred this to a higher dimensional version of the task [22]. The HyperNEAT frameworkwas assumed for this purpose, and teams were not explicitly present. However, this set the scene for use of a ‘bird’s eye’ representation in which an explicitly multi-agent task (e.g. evolution of agents to play keepaway soccer) could be evolved to transfer between unrelated tasks [213]. One element of the approach was to reformulate the original egocentric task description to that of a two-dimensional global ‘grid world’ representation as viewed from above. HyperNEATcould then be used to scale to increasing numbers of players for the keepaway soccer benchmark task without target task training by adding a third dimension to the original bird’s-eye view [45, 46]. The concept of a teamis now a continuum. HyperNEATrepresents an example of a developmental framework in which neural networks evolved with cyclic activation functions(denoted a Composite Pattern Producing Network, CPPN) describing the parameters appearing in the target architecture. The inputs to the CPPN represent the co-ordinates of the input and output of the target architecture. Adding a further HyperNEATinput to index the number of teams effectively scales the approach to arbitrary numbers of agents per team [45, 46]. Diversitywas again a significant issue, with the combination of (task-specific) performance objectives and novelty searchresulting in the most effective agents under the keepaway soccer task [152]. Such an approach rests on the use of (1) a bird’s-eye representation and (2) HyperNEAT. For example, the bird’s-eye representation removes some of the properties of the keepaway soccer task that made it challenging (e.g. navigationusing an egocentric representation). HyperNEATalso composed solutions in the form of a 160,000 parameter feed-forward neural network, therefore losing solution transparency
8.4.3 Hybrid Homogeneous–Heterogeneous Multi-agent Systems
The ‘signal-to-noise’ pathology in multi-agent systems(cooperative coevolution)can potentially be addressed by explicitly supporting the evolution of hybrid teamcompositions(see also Sect.  8.3). Thus, a team of 11 soccer-playing agents could be parameterized by specifying four types of agents (goalie, defender, mid-field and striker) and the number of each type of agent evolved. Nitschke et al. adapted the classic cooperative coevolutionary framework of Potter and De Jong [166] (fully heterogeneous) to address this issue by introducing an inter-population crossover operator [153, 154]. To do so, the genotypic and behavioural similarities between different populations are measured. This implied that a particular neural encoding had to be adopted. When the inter-population similaritypasses a threshold, then crossover of material between populations can take place. There are still as many populations as agents, but subsets of populations can now influence each other.
Early examples of evolving hybrid team compositionsspecific to genetic programming include the use of an ‘automatically defined group’ [79] and the ‘Legion system’ [30], both of which assume a tree-structured representation. Automatically defined groups rely on special purpose crossover operations to manage the development of teams over multiple level of selection. The Legion system not only relied on specialized crossover operators (specific to tree-structured genetic programming) but also introduced an entropy based heterogeneity measure in order to encourage/reward the division of labour between agents.
More recently, Gomes et al. explicitly define a team encodingto distinguish between agent type and the number of instances of each agent [75]. Specifically, the Potter–De Jong cooperative coevolutionary framework is still assumed, but this time the number of independent populations reflects the number of agent types. One set of variation operators functions at the team level and another set operates at the agent level [75]. Team-level variation can decrease or increase the number of agent types, thus merges or splits the corresponding agent populations. The approach is still independent of the agent representation, but the same representation has to be employed throughout.
A further aspect of the signal-to-noise pathology is that there are two components to the reward function: a ‘high-frequency’ component and a ‘low-frequency’ component. The high-frequency component is associated with the agent to environmental interaction, i.e. reinforcement learning[200]. The low-frequency component is associated with satisfying multi-agent components of the reward. With this in mind, neuro-evolutionary approaches have been proposed in which gradient-based temporal difference methods are used to optimize properties of individual agents, while evolutionary computation is employed to design the team [110]. Naturally, such an approach assumes a real-valued numerical representation [218] in order to support both high-frequency (gradient decent) and low-frequency (evolutionary computation) credit assignment
Finally, we also note the use of ‘tagging’ to dynamically identify which teama participant belongs to [86, 169]. Thus, participants are assigned on the basis of thesimilarity8of their respective tag values. This method of dynamic teamselection has been extensively analysed within the context of the iterated prisoners dilemma [20]. In particular, only members of the same group play each other, resulting in participants increasingly adopting altruistic strategies as opposed to defector strategies as the number of tags increases. This is to say, the altruistic participants learn to increase the number of teams in order to decrease the likelihood of their team including a defector. More recently, Lalejini et al. used tags to identify the conditions under which agents were associated with states. This enabled agents to evolve ‘event driven’ decompositions of tasks [122].
8.5 Ensembles with  Variable Size-Structures
All the above research assumed ensembles/multi-agent systemsin which the number of participants/agents per teamwas specified a priori. However, it might actually be desirable for this to evolve as well. Figure  8.6highlights themes of significance for evolving variable-sized evolutionary ensemble learners (vEEL).
One approach to vEEL might be to repeatedly evolve a fixed-sized ensemble approach (Sect.  8.2) over a range of ensemble sizes. Naturally, this would incur a significant computational overhead. Multi-tree representations have been proposed for evolving teams of up  to nparticipants by introducing a ‘null’ program at the sub-tree level [21]. Multi-objective archiving has also been used to cooperatively evolve ensembles of classifiers for multi-class [139] and binary [25, 26] classification problems. As such the complexity of the resulting archiveis a function of the task difficulty, i.e. the number of participants per class is an evolved property. Such an approach deploys participants in parallel (or ‘Flat’ in Fig.  8.6). Conversely, at the other extreme, participants might be organized as a hierarchyor a cascade [70]. Potter and De Jong assumed the specific case of cascade correlation in order to let cooperative coevolutionincrementally evolve a neural network without a priori specifying the number of hidden layer neurones [166]. However, this solution was specific to the case of neural networks with a cascade correlation topology [61], so the coevolutionary process was no longer agnostic to the representation assumed for participants. A further approach to cascade/stack construction has been proposed in which participants distinguish between making a prediction or not [228]. If a prediction is made, no further participants need to make a decision. If a prediction is not made, then the next participant in the hierarchyis queried.
Fig. 8.6
Properties of significance to Variable-sized Evolutionary Ensemble Learning (vEEL). Flat implies that the ensemble is organized with all agents participating in every decision. Graph/Tree implies that ensemble participants are organized hierarchically with different subsets of individuals participating in decisions depending on the input state
Sections  8.2and 8.4for the most part assumed that all participants collaborated at the same level (parallel/flat agent deployment). Conversely, graphs have the ability to describe hierarchical relationships and enforce spatial and/or temporal dependencies between different participants. Graphs have previously been used as an organizing principle for instructions within programs (e.g. [135, 193]) or state machines (e.g. [16, 91]). However, two works have also considered using conditional statements attached to a ‘header’ of ensemble participants to define which out of several ‘following’ participants to execute: PADO [203] and Linear Graph GP [97]. In both cases, given a start or root participant, the participant is executed and the participant’s conditional statement is assessed. Depending on the conditional statement, either another participant is executed or not. The conditional statements from PADO assess the state defined in a common memory (to all participants), whereas the conditionals of Linear Graph GP assess the register values of the parent participant. As such, a single participant is associated with graph nodes and arcs are associated with each condition statement. The concept of a teamis therefore ‘distributed’ across the graph as a whole. Note, that a participant’s action is now either a reference to another participant or a task-specific action, i.e. the number of actions has increased. This is still consistent with Definition 1 because a participant is completely executed (without transfer of execution to different participants) before action selection can take place. In effect, by adopting a graph, hierarchical relationships now exist so that a participant can defer task-specific action selection to a more specialist participant. We identify these approaches as ‘rule based’ in Fig.  8.6
More recently, graphs have been evolved for which each node represents a teamand each participant an arc. Given a start or root node, a subset of the teams in the graph is visited, depending on the state of the environment. The process of visiting nodes (teams) continues until an arc is selected that ends in a task-specific action as opposed to another team. In the following, we review attempts to evolve variable-sized ensembles (including trees of teams) using this process (Sect.  8.5.1) and then generalize this to the case of graphs (Sect.  8.5.2).
8.5.1 Variable Size Ensembles Through Symbiosis
Symbiotic models ofcooperative coevolutionprovidea generic approach for discovering the composition of variable-size ensembles / multi-agent teams using only two populations [84]. Thus, unlike the Potter–De Jong formulation of cooperative coevolution(Sect.  8.4), the number of populations is independent of the number of participants appearing in the team. Specifically, there is a team (host) population and a participant/ agent (symbiont) population, Fig.  8.7. The teampopulation attempts to discover useful team compositionswhereas the agent population provides the pool of participants that may appear within a team. Participants may appear in multiple teams, and the team compositionhas to be unique. An early example of symbiosiswas used to evolve fixed topology neural networks, i.e equivalent to a fixed size team[142].
