Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition (2014). arXiv:​1409.​1556
44.
So, D., Le, Q., Liang, C.: The evolved transformer. In: International Conference on Machine Learning, pp. 5877–5886. PMLR (2019)
45.
Song, D., Chang, X., Jia, X., Chen, Y., Chunjing, X., Wang, Y.: Efficient residual dense block search for image super-resolution. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, pp. 12007–12014 (2020)
46.
Stanley, K.O., Bryant, B.D., Miikkulainen, R.: Real-time neuroevolution in the NERO video game. IEEE Trans. Evol. Comput. 9(6), 653–668 (2005)
47.
Stanley, K.O., D’Ambrosio, D.B., Gauci, J.: A hypercube-based encoding for evolving large-scale neural networks. Artif. Life 15(2), 185–212 (2009)
48.
Stanley, K.O., Miikkulainen, R.: Evolving neural networks through augmenting topologies. Evol. Comput. 10(2), 99–127 (2002)
49.
Sun, Y., Xue, B., Zhang, M., Yen, G.G.: A particle swarm optimization-based flexible convolutional autoencoder for image classification. IEEE Trans. Neural Netw. Learn. Syst. 30(8), 2295–2309 (2018)
50.
Sun, Y., Xue, B., Zhang, M., Yen, G.G.: Completely automated CNN architecture design based on blocks. IEEE Trans. Neural Netw. Learn. Syst. 31(4), 1242–1254 (2019)
51.
Sun, Y., Xue, B., Zhang, M., Yen, G.G.: Evolving deep convolutional neural networks for image classification. IEEE Trans. Evol. Comput. 24(2), 394–407 (2019)
52.
Sun, Y., Xue, B., Zhang, M., Yen, G.G., Lv, J.: Automatically designing CNN architectures using the genetic algorithm for image classification. IEEE Trans. Cybern. 50(9), 3840–3854 (2020)
53.
Sun, Y., Yen, G.G., Zhang, M.: Internet protocol based architecture design. In: Evolutionary Deep Neural Architecture Search: Fundamentals. Methods, and Recent Advances, pp. 181–192. Springer, Cham (2023)
54.
Sze, V., Chen, Y.H., Yang, T.J., Emer, J.S.: Efficient processing of deep neural networks: a tutorial and survey. Proc. IEEE 105(12), 2295–2329 (2017)
55.
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–9 (2015)
56.
Wang, B., Sun, Y., Xue, B., Zhang, M.: Evolving deep convolutional neural networks by variable-length particle swarm optimization for image classification. In: 2018 IEEE Congress on Evolutionary Computation (CEC), pp. 1–8. IEEE (2018)
57.
Wang, B., Xue, B., Zhang, M.: Particle swarm optimisation for evolving deep neural networks for image classification by evolving and stacking transferable blocks. In: 2020 IEEE Congress on Evolutionary Computation (CEC), pp. 1–8. IEEE (2020)
58.
Wu, T., Shi, J., Zhou, D., Lei, Y., Gong, M.: A multi-objective particle swarm optimization for neural networks pruning. In: 2019 IEEE Congress on Evolutionary Computation (CEC), pp. 570–577. IEEE (2019)
59.
Xie, L., Yuille, A.: Genetic CNN. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1379–1388 (2017)
60.
Xie, X., Liu, Y., Sun, Y., Yen, G.G., Xue, B., Zhang, M.: Benchenas: a benchmarking platform for evolutionary neural architecture search. IEEE Trans. Evol. Comput. (2022)
61.
Yang, Z., Wang, Y., Chen, X., Shi, B., Xu, C., Xu, C., Tian, Q., Xu, C.: Cars: continuous evolution for efficient neural architecture search. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1829–1838 (2020)
62.
Yao, X.: Evolving artificial neural networks. Proc. IEEE 87(9), 1423–1447 (1999)Crossref
63.
Ying, C., Klein, A., Christiansen, E., Real, E., Murphy, K., Hutter, F.: Nas-bench-101: towards reproducible neural architecture search. In: International Conference on Machine Learning, pp. 7105–7114. PMLR (2019)
64.
Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: European Conference on Computer Vision, pp. 818–833. Springer (2014)
65.
Zhang, M.: Evolutionary deep learning for image analysis. Talk at World Congress on Computational Intelligence (WCCI) (2018). Published on July 2, 2020
66.
Zhang, X., Zhou, X., Lin, M., Sun, J.: Shufflenet: an extremely efficient convolutional neural network for mobile devices. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6848–6856 (2018)
67.
Zhou, Z.-H., Yang, Yu., Qian, C.: Evolutionary Learning: Advances in Theories and Algorithms. Springer, Singapore (2019)CrossrefzbMATH
68.
Zoph, B., Le, Q.V.: Neural architecture search with reinforcement learning (2016). arXiv:​1611.​01578
69.
Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V.: Learning transferable architectures for scalable image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8697–8710 (2018)©  The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.  2024
W. Banzhaf et al.(eds.)Handbook of Evolutionary Machine LearningGenetic and Evolutionary Computationhttps://doi.org/10.1007/978-981-99-3814-8_10
10.  Evolutionary Generative Models
João  Correia1, Francisco  Baeta1and Tiago  Martins1
(1)
Department of Informatics Engineering, Centre for Informatics and Systems of the University of  Coimbra, University of  Coimbra, 3004-531  Coimbra, Portugal
João  Correia(Corresponding author)
Email: jncor@dei.uc.pt
Francisco  Baeta
Email: fjrbaeta@dei.uc.pt
Tiago  Martins
Email: tiagofm@dei.uc.pt
Abstract
In the last decade, generative models have seen widespread use for their ability to generate diverse artefacts in an increasingly simple way. Historically, the use of evolutionary computation as a generative model approach was dominant, and recently, as a consequence of the rise in popularity and amount of research being conducted in artificial intelligence, the application of evolutionary computation to generative models has broadened its scope to encompass more complex machine learning approaches. Therefore, it is opportune to propose a term capable of accommodating all these models under the same umbrella. To address this, we propose the term evolutionary generative modelsto refer to generative approaches that employ any type of evolutionary algorithm, whether applied on its own or in conjunction with other methods. In particular, we present a literature review on this topic, identifying the main properties of evolutionary generative modelsand categorising them into four different categories: evolutionary computation without machine learning, evolutionary computation aided by machine learning, machine learning aided by evolutionary computationand machine learning evolved by evolutionary computation. Therefore, we systematically analyse a selection of prominent works concerning evolutionary generative models. We conclude by addressing the most relevant challenges and open problems faced by current evolutionary generative modelsand discussing where the topic’s future is headed.
10.1 Introduction
In recent years, the growth of interest in artificial intelligence research and development has sparked the development of increasingly more complex systems in many fields. In particular, generative models have seen widespread use in the fields of machine learning and evolutionary computation for their ability to generate new instances that follow the probabilistic distribution of a set of pre-existing ones. Due to their recent advancements and impressive results, generative models have become a hot topic. Their outputs can be diverse and applied to a broad range of application domains, e.g. image, music, text, engineering and game design.
Within generative machine learning, the proposal of generative adversarial neural networks (GANs) in 2014 by Goodfellow et al. [72] dramatically changed the landscape in research on generative models by proposing an effective adversarial way of training them. Consequently, GANs quickly gained acclamation to the extent of being coined as “the most interesting idea in the last 10 years in Machine Learning” by Yann LeCun. However, before the advent of GANs, evolutionary computation was the de factoapproach employed in generative modelling[171]. With the rapid surge of interest around GANs and other deep learning generative approaches, most machine learning-based approaches surpassed what most evolutionary computation generative approaches and models have achieved. This was the case until the last few years when a paradigm shift happened propelled by the maturity of the field of evolutionary machine learning, where methods from evolutionary computation and machine learning are combined as a unified solution.
This chapter surveys the work on evolutionary generative models. We propose this term to identify generative models that use evolutionary computation in any part of the generative process. This definition of evolutionary generative modelmeans that a substantial bodyof the surveyed work includes plain evolutionary computation approaches that date back to the 1980s, although authors such as Richard Dawkins and Karl Sims have never described their work as evolutionary generative models. Given the increasing adoption of evolutionary machine learning techniques by the research community as well as the rise of the popularity of generative models, the study of evolutionary generative modelsis ever more frequent in the literature. Despite this, to the best of our knowledge, there is still no comprehensive review focussed on the existing literature for evolutionary generative models. Therefore, in this chapter, we survey the existing literature related to this type of model and analyse existing work from both a historical and scientific point of view.
During the survey, we found that the evolutionary generative modelcan be divided into four different categories based on the role of machine learning in the generative process: evolutionary computation without machine learning, evolutionary computation aided by machine learning, machine learning aided by evolutionary computation, and machine learning evolved by evolutionary computation. The division along the four categories is central to the structure and narrative of this chapter.
The document outline is as follows. In Sect.  10.2, we introduce the core concepts and definitions regarding evolutionary generative models andoutline the main properties of these models, thus providing a knowledge base for the chapter and defining its scope. Then, in Sect.  10.3, we propose a taxonomy to classify evolutionary generative models. Next, in Sect.  10.4, we provide a brief historical overview to contextualise research on this type of generative model, describing the most relevant works and presenting a visual timeline. The following four Sects.  10.5, 10.6, 10.7and 10.8, analyse the collected papers of the four defined categories. Then, in Sect.  10.9, we overview open problems in the area of evolutionary generative modelsand identify new research opportunities. Finally, Sect.  10.10lays the closing remarks by enumerating the main contributions, opportunities and the conclusion of this chapter.
10.2 Fundamentals
We define an evolutionary generative modelas a generative model that employs evolutionary computation in any part of the generative process. Although the evolutionarypart of this definition is explicit, we believe that generative modelmay have different interpretations.
When we look at the broader concept of generative model and generative modelling, we can encounter different definitions. For instance, in machine learning, generative models are considered models capable of generating new data instances. More formally, given a set of data instances Xand a set of labels Y, generative models capture the joint probability p(X,  Y), or just p(X) if there are no labels. Therefore, a generative model describes how a dataset is generated in terms of a probabilistic model that can create instances from a distribution similar to the training data instances. In statistics, a generative model is a statistical model of the joint probability distribution p(X,  Y) of a given observable variable Xand target variable Y. In graphic design, a generative process is concerned with the creation of an algorithm, or model that produces multiple designs that instantiate a concept. Considering these definitions and our analysis of varied works in this area, we can define a common ground in what concerns the specifications that characterise generative models.
A generative model typically implements an algorithmic process that generates outputs that serve a certain objective or concept. This way, the generated outputs tend to follow a given distribution within an objective class, thus forming a space where the outputs share common characteristics. In addition, the generative model can often receive input information that influences the generative process and consequently changes the outputs. This generative process can be implemented using evolutionary computation or enhanced by it.
During our analysis of existing evolutionary generative models, we identified five properties which we consider relevant to study in each model: application domain, evolutionary algorithm, population, representation and fitness. These 1properties are outlined in Fig.  10.1and described in the following paragraphs.
Fig. 10.1
Main properties of evolutionary generative models
Domaincorresponds to the application domain of the model being analysed: image, music, textor otherapplications such as engineering, architecture and even less common disciplines such as dance [59] and culinary recipes [152]. It can be argued that this property pertains to the applications of the model and not to the model itself. However, as far as evolutionary computation is concerned, we found that most algorithms follow specific representations and parameterisations according to the application domain.
Evolutionary Algorithmestablishes which evolutionary paradigm is employed by the evolutionary generative model, namely, genetic algorithms, genetic programming or evolutionary strategies.
Populationrelates to the fact of the generative model having a singleor multiplepopulations of individuals being evolved. Within approaches with multiplepopulations, we have two different types: cooperativeand adversarial. In a cooperativesetup, multiple populations collaborate to achieve a common goal, where typically each population specialises in a specific task or sub-problem, and their combined efforts contribute to the overall solution. On the other hand, in an adversarialsetup, different populations are evolved and compete with each other.
Representationrefers to the structure of the genotype. Based on the categorisation of evolutionary art systemsby Machado [123], we generalised the categorisation and divided the representations used in the analysed works into three main types: descriptive, parametricand procedural. In a descriptiverepresentation, we evolve values that directly define the properties of each individual. In a parametricrepresentation, we also evolve values, but they are used as input parameters for a model that generates each individual. This way, individuals are defined explicitly by the parametric model and the properties of these individuals are controlled by varying the parameter values of the model, which are encoded in the genotype. In a proceduralrepresentation, on the other hand, we evolve a sequence of procedures or rules, which can be seen as a model that is then used to generate the individual. In summary, while descriptiveand parametricrepresentations are data oriented, as they encode values, proceduralrepresentations are process oriented, since the evolutionary algorithm evolves, for instance, mathematical expressions, networks or rules.
Fitnessevaluation in the generative process is crucial, and according to the literature, there are several ways of doing it and it depends on many factors. However, in this chapter, we are mainly interested in whether the fitness evaluation changes throughout the evolutionary process or not. Thus, we divided the surveyed works into two categories: staticand dynamic. In the case of staticfitness, if the individual is the same, no change should occur to its fitness throughout the evolutionary process. As for dynamicfitness, we consider cases where the output of the evaluation may vary during the evolutionary process, i.e. when different fitness values can be assigned to the same individual in different moments of the evolutionary process. Among the approaches that implement dynamic fitness, we can find, for instance, those that employ user feedback to guide the evolutionary process, i.e. interactive evolutionary computation approaches. We consider that fitness assignment based on user feedback, i.e. interactive evolutionary computation, is dynamic
Table 10.1
Examples of evolutionary generative modelscategorised as evolutionary computation without machine learning
Domain
Year
Authors
EA
Population
Represent.
Fitness
Image
1986
[52] Dawkins
GA
Single
Procedural
Dynamic
