Email: cathy@openai.com
Abstract
This chapter pursues the insightthat large language models(LLMs) trained to generate code can vastly improve the effectiveness of mutation operators applied to programs in genetic programming (GP). Because such LLMs benefit from training data that includes sequential changes and modifications, they can approximate likely changes that humans would make. To highlight the breadth of implications of such evolution through large models(ELM), inthe main experiment ELM combined with MAP-Elitesgenerates hundreds of thousands of functional examples of Python programs that output working ambulating robots in the Sodaracedomain, which the original LLM had never seen in pretraining. These examples then help to bootstraptraining a new conditional language model that can output the right walker for a particular terrain. The ability to bootstrapnew models that can output appropriate artifacts for a given context in a domain where zero training data was previously available carries implications for open-endedness, deep learning, and reinforcement learning. These implications are explored here in depth in the hope of inspiring new directions of research now opened up by ELM.
Kamal Ndousse work done at OpenAI.
11.1 Introduction
For many in the evolutionary computation (EC) community, the rise of deep learning (DL) has raised questions on its implications for EC. Both approaches scale well with compute and both can yield useful discoveries and meaningful surprises. Yet are they ultimately competing paradigms, or rather are they complementary? In this chapter, we explore the latter possibility, of considerable synergy, by highlighting an untapped implication of large language models(LLMs; [7, 13]) for both genetic programming (GP; [4, 31]) and open-endedness[5, 59, 63].
In particular, in this new Evolution through Large Models (ELM)approach, an LLM trained on code can suggest mutations that are intelligent, thereby facilitating a dramatically more effective mutation operator that sidesteps many of the challenges that previously existed for evolving programs [48]. Interestingly, the benefits of ELM are also reciprocal back to deep learning: the set of samples generated through the LLM can eventually constitute a new training set in a novel domain that can then fine-tune the LLM to perform well in the new domain, a novel data-generation procedure. Furthermore, this approach ultimately opens up new opportunities in the pursuit of open-endednessby increasing the generative capabilities of the LLM solely through its own generated data.
LLMs have recently yielded impressive results in automated code generation [15, 40]. These models bootstrapfrom human knowledge by learning from very large datasets to achieve general coding competency. The fact that such bootstrapping is possible is clearly relevant to GP. After all, GP is in effect a generative approach to programming. While it might seem at first glance that LLMs therefore might out-compete or subsume GP, in fact GP does still offer an advantage in situations where the particular class of programs targeted by the search is far (or even completely lacking) from the training distribution of the LLM. In such cases, the LLM offers limited recourse (prompt engineering to learn an entirely new domain would be prohibitive), while GP can in principle evolve in any space (though in practice some spaces may be intractable due to the amount of mutation necessary to get consistent signal on fitness).
Interestingly (and perhaps surprisingly), the best of both worlds is easily attainable by combining them: simply by prompting the LLM to generate changes the LLM can serve as a highly sophisticated mutation operator embedded within an overarching evolutionary algorithm. This way, the LLM in concert with evolution can steer each other toward the right region of the solution space even though neither evolution with a conventional mutation operator nor the LLM on its own could generate anything close. In effect, program evolution using LLM-based perturbation begins to bridge the divide between evolutionary algorithms and those that operate on the level of human ideas. That is, LLMs can be trained to approximate how humans intentionally change programs, while staying on the manifold of functionality. Furthermore, such LLMs can be further fine-tuned on successful perturbations for the purposes of self-improvement, culminating in a novel technique for iteratively enhancing the performance of ELM.
To highlight the potential of this approach, in this chapter, an entire dataset in a novel domain is generated from only a single mediocre starting example designed by hand by humans. In particular, the domain is called Sodarace[41, 67], where two-dimensional ambulating robots of arbitrary morphology are constructed for diverse terrains. Sodaraceis cheap to simulate, allowing fast iteration, and also makes it easy to appreciate the sophistication of designs intuitively by simply watching the robot walk. In this way, it facilitates quick assessment of whether a design is successful both quantitatively and qualitatively.
To make the contribution of ELM explicit in the experiments in this chapter, the Sodaracersare encoded as raw Python programs that output an enumeration of the ambulating robots’ components. That way, it is possible to demonstrate that ELM is a form of GP that can operate on a modern programming language directly, with no special provisions needed beyond the generic (i.e., notpreviously trained in Sodarace)existingcode-generating LLM.
A final important insightunlocked by this approach is that the ability to generate diverse solutions in a domain or part of the search space where there was little to no training data is foundational to bootstrapping an open-ended process [5, 59, 61]. After all, open-endednessis fundamentally about searching outside the distribution of previous experience, which is exactly what ELM helps the LLM to do. Because this novel capability has potentially far-reaching implications, we have chosen in this work to focus on the implications of the generated data that can be produced by ELM. Of course, ELM is applicable in many other contexts that will undoubtedly be explored in the future.
More specifically, experiments that follow show that generated data is sufficiently rich that it can serve as training data for fine-tuning LLMs to generate code for viable new Sodaracersconsistently, and furthermore that reinforcement learning(RL) can even fine-tune an augmented LLM to output Sodaracers conditionally, depending on the terrain. In the future, such conditional invention has the potential to unlock entirely new kinds of open-ended processes, just as humans have open-endedly built civilization over centuries by conditionally inventing its constituents.
In short, the main contributions of this chapter are (1) the ELM method for efficiently evolving programs through LLMs, (2) a technique for improving ELM’s ability to search over time by fine-tuning its LLM-based mutation operator, (3) a demonstration of ELM in a domain not included in the training data of the LLM, and (4) validation that data generated through ELM can bootstrapenhanced LLMs that offer a novel path toward open-endedness
11.2 Background
This section reviews previous work in genetic programming, large language models, and open-endedness
11.2.1 Genetic Programming
The field of genetic programming (GP) applies evolutionary algorithms to evolve computer programs to solve problems [4, 31, 34]. The promise of GP is that computer code is a computationally universal representation that underlies much modern technology, including artificial intelligence itself. Therefore, it is conceivable for GP to automatically evolve programs that achieve human-level (or beyond) performance across diverse application domains [32]. However, there are obstacles in practice to its successful and widespread application to challenging problems.
One obstacle is that scaling GP to evolve increasingly complicated programs can be challenging [48], and that effectively applying GP to a new domain can require significant domain expertise. A researcher often must explicitly specify what functions, variables, and control structures are available to evolution [10, 31], which limits what ultimately can be evolved. In contrast, a human programmer can open-endedly decide what libraries to import and how to write many interdependent subroutines or classes. Research aims to lift these constraints, often through enabling modular reuse of code, e.g., through automatically defined functions [31], data-mining populations to find common sub-components [29], or attempts to use solutions to previous problems when solving new ones [56]. However, no method yet enables GP to scalably operate on human-designed programming languages with a minimum of domain-specific tweaking.
A second obstacle is that nearly all GP methods explore through random perturbations of code, unlike humans, who through active practice improve their proficiency in making deliberate, complex, and coupled modifications to programs [25, 38]. Unlike perturbing, e.g., neural network weights, wherein continuous parameters subject to small enough perturbations can predictably generate small changes in functionality [35, 53], perturbing code requires discrete changes that often dramatically shift functionality [23], thereby complicating search. While there exist approaches toward more directed generation of offspring (e.g., building probabilistic models of high-performing programs [52], evolving reproduction operators [58], or applying less-impactful mutation operators [23]), the problem remains at core unsolved.
In contrast to GP, humans learn to reason about code in its full complexity through experimentation and learning. This iterative effort leaves a permanent signature in repositories of code, such as GitHub. The next section describes progress in training large language modelsupon such repositories as a potential way to bypass the above obstacles.
11.2.2 Large Language Models
Large language models(LLMs; [7, 13, 21]), trained on Internet-scale data, have progressed at an impressive pace in recent years. The main idea (in auto-regressive models such as GPT-3 [13] and GPT-4 [46]) is to train increasingly large neural networks (built on the popular transformer architecture[70], sometimes with billions of parameters) on the seemingly simple task of next-token prediction (i.e., given a sequence of tokens seen so far, predict the proceeding token). Scaling such LLMs (and formulating problems of interest as natural language processing tasks) has resulted in groundbreaking performance across a wide range of tasks [13, 16, 46], including program synthesis [15, 28, 39, 40].
In particular, by training LLMs on large-scale coding data, e.g., from GitHub, it is possible to produce models with impressive function-synthesis capabilities [15, 39, 40], highlighting the possibility to bootstrapthe ability to fluently code from large-scale data. Further developments are diffmodels that are trained on diffs from GitHub [9, 51]. A diff is an incremental change to a file that is committed to a version control system such as GitHub, accompanied by a commit messagedescribing the intent of the change. In this way, diff modelsare trained how, given a piece of code and any potential commit message, to suggest an informed change. Through the lens of evolutionary algorithms, such diff modelscan be viewed as intelligent perturbation operators, providing a way to walk over the manifold of code (in a controllable way) through mimicking human programmers. An interesting further possibility is that such models are amenable to further training through gradient descent, implying a potentially powerful mechanism for self-adaptation (e.g., through reinforcing successful diffs during evolution). Both diff modelsand their capacity for self-adaptation are explored in this work as a way to improve GP. However, it is also important to note that general language models not trained directly on diffs can also act in effect like diff modelswhen given the right kinds of prompts (see Sect.  11.3.1).
11.2.3 Open-Endedness
With origins in the open-endedevolution community [5, 59, 68, 69] within artificial life, the field of open-endednessseeks to create algorithmic systems that produce never-ending innovation [63]. Given the primacy of search with ML, research within open-endednessnaturally has focused on refining algorithms for open-ended search, such as those driven by novelty [37, 44] or curiosity [49, 64]. While such focus has indeed lead to algorithmic progress, there is a growing awareness of the criticality of the environmentin which open-ended algorithms are applied [22, 24, 57, 84].
That is, the environment limits what can arise within the system and for how long its products can remain interesting. As a result, some have argued for more complex environments for open-endedness, such as video games [22, 24], and others have argued that features of the environment should co-evolve with agents [20, 84]. Yet a theory for what specific forms of additional such complexity is needed for enduring open-endednesshas been lacking. This chapter contributes a possible theory, arguing that agents outputting inventions into the environment in response to previous inventions may be a principled route to such continuing open-endedness
One challenge in evolving aspects of the environment (such as inventions) is how they are encoded. Most research applies encodings that are specifically fit to describe some fixed part of a larger environment, e.g., a fixed way of describing edges within a maze [11] or the shape of a 2-D landscape [84]. While sometimes the encodingsof these parts are universal (e.g., the CPPN encoding of landscapes in [84] can describe any landscape, and the RNN encoding of [20] can describe any maze), it is unclear how to expand the representation to include more of the environment without relying upon ad hoc principles. This chapter argues that computer programs are a general and powerful encoding for continually expanding the richness of an existing environment.
11.3 Approach: Evolution Through Large Models
Three distinct components facilitate ELM. First is the novel mutation operator driven by an LLM. Second is an evolutionary outer loop that calls this mutation operator. Finally, the third component is a method for updating the LLM to improve based on its preceding performance. Each of these is detailed in this section.
11.3.1 Mutation Through Diff
The main idea behind ELM centers on rethinking the mutation operator for code by exploiting the capabilities of LLMs. In conventional GP, the language of the code and the types of changes allowed through mutation are both chosen intentionally to yield a reasonable chance that perturbations can lead to useful functional changes [31]. In contrast, LLMs unlock an entirely different basis for mutation: it would be more ideal if the mutation operator understoodthe code and how it can be changed in interesting ways, more like a human than a stochastic event.
LLMs can indeed be trained to output code in an auto-regressive manner by exposing them to extensive programming examples [15, 40]. A diff model[51] can similarly be auto-regressively trained on a collection of code diffs (e.g., from GitHub). Each diff targets a single file, where the file and diff are short enough to fit into the context of the LLM. The model is trained to predict the diff (formatted, for example, in unified diff format [1]) from the concatenation of the file and the commit message, where the loss includes only the tokens that make up the diff, thereby encouraging the model to predict the diff but not to memorize the file and commit message. In other words, the model learns to predict plausible changes to code from examples of changes made to code by human programmers. It is important to note that the idea of diff models(or their initial training) [51] is not a contribution of this chapter, but diff modelsare rather a tool applied here in a new context (to produce mutations).
To achieve meaningful mutations, ELM can choose among a set of commit messages, which convey to the LLM the details of the operation it should perform in lieu of mutation. These messages offer significant power and nuance for calibrating mutation operators that is likely highly novel to anyone familiar with implementing mutation in GP or evolutionary algorithms in general. In the experiment in this chapter, the three commit messages and their respective probabilities of being chosen are
Changed make_walker function(40% chance).
Changed parameters in make_walker function(30% chance).
Small change to make_walker function(30% chance).
Of course, any commit message is conceivable. The LLM’s ability to interpret general natural language means that the scope for research exploration(and domain-specificity) here is vast.
As a simple experiment to highlight diff models’ ability to intelligently modify code, an implementation of a function with an adjustable amount of bugs is perturbed with either a simple GP mutation operator or with a 300  M-parameter diff model. The hypothesis is that an intelligent perturbation operator will be better able to make multiple correlated changes to code (in this case to correct the bugs). The 4-Paritytask (which is inspired by a standard GP benchmark [31]) serves as a representative test bed. Note that a correct implementation of 4-Parity returns the sum of the four input bits, modulo two. Up to five bugs are introduced to 4-Parity, first by incrementally misnaming each of the variables in the sum calculation, and for the fifth bug, the modulo is changed from two to three. Then, perturbation operators are tested for their ability to (in one perturbation step) change the buggy version of the code to one that successfully passes unit tests. Results in figure Fig.  11.1highlight how with increasing bugs GP mutation becomes exponentially more unlikely to produce a successful solution (note that nomutation from GP solves all five, given 100,000 trials). In contrast, the diff operator is able to fix all five bugs, and its performance is impacted more by the number of differenttypes of bugs (i.e., the fifth bug affects the modulo calculation rather than renaming variables) than by the raw number of bugs itself. Further details (including a supporting experiment with another task with similar results) are given in Appendix A of [36],  p. 42.
Fig. 11.1
Comparing diff mutation to GP mutation in fixing 4-Parity bugs.The figure shows how the ability of a single mutation to produce correct solutions changes as bugs are incrementally added to a working 4-Parity implementation. Note that success percentage is shown in log scale, i.e., success for GP mutation decreases exponentially in the number of mutations (and produces no solutions when there are five bugs). In contrast, diff mutation degrades only with the fifth bug. The conclusion is that LLM-based mutation can indeed make multiple sensible coupled changes to code
Because the tools involved in an ELM implementation are unconventional, we finally wanted to highlight here several alternatives for implementing such systems in practice today. One option is to use models available on the OpenAI API that can edit through following instructions [2, 47]. A second option is to create an intelligent mutationoperator through few-shot prompting instead of through explicit training (as in the diff model). That is, one could design prompts for a model trained on code (like Codex[15] or GPT-6-J [82]). To show the potential to replicate (or improve upon) the results in this chapter, we conducted a simple experiment comparing (on the 4-Parity problem) prompt engineering and edit mode to the diff model. Figure  11.2shows how models from the API outperform the diff modelused in the chapter. Further experimental details can be found in Appendix A of [36],  p. 42.
Fig. 11.2
Comparing alternate LLM-based mutations in fixing 4-Parity bugs.The performance of different mutation operators in fixing bugs is shown as bugs are incrementally added to a working 4-Parity implementation. Both edit mode and prompt-engineering approaches outperform the diff modelapplied in this chapter’s experiments. The conclusion is that both prompt engineering on LLMs trained on code and using edit mode models from the OpenAI API are viable options to build upon the work in this chapter
11.3.2 The Evolutionary Algorithm and Implications for  Open-Endedness
Becausethe mutation operator is effectively a modular component for many evolutionary algorithms [19, 43], ELM can be implemented within a diversityof contexts. Of course, the approach is most applicable to a case where the genetic encoding is through a known programming language, because that is how the benefits of the LLM will be realized. Genetic encodings in natural language or any other language at which LLMs excel are also conceivable, but of course the utility of such encodings would depend on how they are applied and their mappingto a potentially useful phenotype. The experiments in this chapter focus on Python 3 genotypes, which are also by their nature variable in length. The ability to use modern programming languages as genotypes without the need for any special accommodation is a key benefit of ELM.
While there are many options for the evolutionary algorithm in the outer loop, we have chosen in this chapter toimplement ELM within a quality diversity(QD) algorithm [45, 50]. An important motivation for this choice is that the emergence of the ability to search intelligently for arbitrarily complex programs is tantalizingly close to overcoming some of the key obstacles to open-endedness[61], and ELM is an opportunity to highlight this opportunity.
Recallthat we do not yet know how to make an algorithm that exhibits genuinely open-ended divergence. While there has been progress toward open-endednessin recent years, the state of the art remains weak open-endedness, wherein novel and interesting discovery continues only for a brief time, eventually ending in a plateau as the possibilities are exhausted [3, 11, 12, 63, 83, 84]. In contrast, in strong open-endedness, the process would never plateau—if we left and returned a year later, or even a millionyears later, its products would continue to become more interesting over time. No algorithm comes close to such an achievement, though it is evidently possible in nature.
The question then is what stands between today’s algorithms and tractable strong open-endedness. This gap remains despite that recent work in open-endednessappears to make progress. For example, the Enhanced POETalgorithm continues to generate diverse and increasingly complex terrains for bipedal robots to solve [84]. In their hide-and-seek experiment, [3] show agents discovering increasingly complex strategies like assembling blocks into a hideout. Yet despite such algorithms clearly demonstrating the capability to continue to invent new solutions, all such demonstrations share a singular downfall: they slow down and eventually end. Formalizing ELM within a QD framework in effect offers a novel opportunity to address this challenge.
This opportunity connects to the difficulty of formulating an artificial environment that imposes no limit on what even the most capable open-ended algorithm can achieve, as noted in the Background. The challenge of devising artificial environments with unbounded potential raises the intriguing question of what property our universe and planet possess that is lacking in current artificial environments. This question is critically important for open-endednessbecause in the absence of that property, open-ended algorithms cannot demonstrate their full potential. If the problem indeed stems from the fact that artificial environments to date offer only finite possible experiences until their potential is exhausted, then to overcome this bottleneck the environment itself needs to possess the potential to change forever.
Since the emergence of intelligence in nature, much environmental change has been driven by the intelligent agents themselves. Eventually, humans acquired the ability to leave detachedartifacts in the environment that radically alter its potential for themselves and other agents, like a house, a vehicle, or even a program. Unlike new organisms that are evolved over generations, such detached conditional things(DCTs) are generated intentionally as a condition of the observations of the agent. Once DCTs enter the world, open-endednessaccelerates because the environment is rapidly updating even within the course of a single lifetime.
Each DCT creates an opportunity for further DCTs. For example, the invention of the door creates the opportunity for keys to be invented, which then sets the stage for lock picks, and so on. And because they are detached, DCTs can leave a permanent legacy in the environment well beyond the lifetime of their inventor. In this way, invention in the era of DCTs is open-ended, and accordingly has continued for thousands of years, from fire and wheels tospace stations and computers.
This theory of DCTs supplies an abstract answer to the problem of a limited environment: Agents must be able to imprint the environment with DCTs in response to those already present within it. However, realizing DCTs in practice requires addressing a separate question: how can agents be enabled to efficiently invent DCTs of limitless complexity in a new domain?
Interestingly, computer programs are universal representations, meaning that the procedure of assembling new artifacts can naturally be described algorithmically. For example, programmers have leveraged code to help create enormously complex artifacts (like the layouts of computer chips or instructions for 3-D printers to produce complex physical objects). Of course, programs themselves can function as DCTs. In this way, a procedure that can search through modern program space and ultimately generate such programs conditionally is a candidate for creating open-ended environments of unlimited capacity. The experiment in this chapter will demonstrate in more detail how ELM makes such a construct conceivable; the significance of QD is that its ability to generate a diverse space of artifacts can serve as the bootstrapto obtaining agents capable of generating DCTs. In short, the QD algorithm is generating training datathat can transform the LLM into a kind of DCT generator
While any QD algorithm can work with ELM, the specific algorithm in the experiment in this chapter is MAP-Elites[18, 45] (Fig.  11.3). The core of MAP-Elitesis a uniformly spaced grid of niches(called the map) that spans user-specified dimensions of solution diversity, called the behavior characterization. Upon initialization, a single pre-existing (hand-designed in this chapter) solution is evaluated and placed into the map. In each iteration thereafter, an inhabited nicheis randomly chosen and the solution within that nicheis perturbed by the diff modeland evaluated. The new candidate solution is assigned its nichefrom its behavior characterization, and if that nicheis unfilled or the new solution outperforms the niche’scurrent inhabitant, it becomes the champion of that niche; otherwise, the candidate is discarded. In this way, over iterations of search, the map gradually fills with increasingly diverse and high-quality solutions.
Fig. 11.3
MAP-Elites with ELM.In each iteration, an existing Python solution is sampled from the map of solutions for each independent replica of a diff model. Each replica generates a batch of diffs that are applied to the sampled solution to generate modified candidate solutions. These candidates are evaluated and are then inserted into the map if they either establish a new nicheor outperform the niche’s current champion. Over iterations, a single initial seed program gives rise to a diversity of high-performing Python programs
11.3.3 Fine-Tuning the Diff Operator
Interestingly, because the mutation (diff) operator is itself an LLM, it has the potential to be improved with respect to the domain. While self-adaptation [26, 33, 42] has a long tradition in evolutionary computation, including algorithms such as CMA-ES[26] and natural evolution strategies [85], the kinds of improvements possible in ELM are unique by offering the possibility of the LLM learning how to think about change. That is, ideas for changes that are most promising in one domain might be different than in another, and the richness of the LLM offers the potential to capture such nuance through experience. In particular, the pretrained diff modelcan be trained further (which is called fine-tuning) with accepted diffs (by MAP-Elites)from initial iterations or runs of ELM. That way, the diff operator updates to understand better the kinds of modifications that lead to either higher quality, more novelty, or both. This fine-tuning technique can cause ELM itself to improve over iterations. Of course, over a long run, the ideal kinds of changes might change; continually fine-tuning based on recent experience can potentially track such drifting opportunities. In this chapter, the potential of fine-tuning is demonstrated through a single fine-tuning iteration, but the investigation of such continual refinement is an open research opportunity. Note that the prompt-engineering approach to LLM mutation described at the end of Sect.  11.3.1can also benefit from fine-tuning in this way.
11.4 Experiment and Results
The primary motivation for the experiment that follows is to give a taste of the breadth of implications of ELM, to evolutionary computation, to deep learning, and to open-endedness. For this purpose, this experiment focuses on the problem of the inventionof complex artifacts (which could eventually serve as DCTs in a future more ambitious experiment). While the potential scope of applications for ELM is broad, the opportunity to learn to invent complex artifacts in an arbitrary domain extends directly from the augmented ability to search through programs; seeing this inventive capability realized thereby highlights novel opportunities opening up.
Fig. 11.4
An Example Sodaracer.The objective in the Sodarace domain is to design a Sodaracer that locomotes effectively across the ground terrain. Labeled in the image are examples of a mass and a spring that connects two masses together. A Sodaracer design consists of a variable number of masses and springs, where springs also have oscillatory parameters that determine Sodaracer’s motion
The experiment will aim to bootstrapfrom a few hand-written (and barely functional) examples of an invention into an LLM-based inventor that can fluidly output appropriate inventions conditioned on its environment. This concept is demonstrated in the domain of Sodarace[41, 67], a physics-based invention domain that serves as a cheap-to-simulate microcosm of invention. The goal in Sodaraceis to construct from collections of masses and oscillating springs two-dimensional robots that can locomote competently. A wide range of interesting Sodaracer robots are possible, as highlighted by previous ML research [67] and the origins of the domain: Sodarace began as a web application called Sodaconstructor, wherein the human design of Sodaracers was sufficiently compelling for an online community to form around the endeavor [41].
An individual Sodaracer (Fig.  11.4) is composed of a variable-sized collection of point masses (each fully described by its initial 2-D position) and oscillating springs that connect masses together. The motion of the robot is driven by the oscillation of its springs, and each spring has parameters specifying the amplitude and phase of its oscillation (by convention all springs have the same period). To evaluate a particular Sodaracer, it is simulated in a specific terrain for a fixed amount of time and its ability to traverse that terrain is measured (i.e., how far Sodaracer’s center of mass moves along the x-axis); additionally, to measure the diversityof solutions for MAP-Elites, features capturing gross aspects of the robot’s morphology (i.e., its initial height, width, and total mass) are recorded. While a search algorithm could operate directly in the space of masses and springs, here instead LLMs output Python code that describes the morphology of the Sodaracer. For examples of such source code, see Appendices B and G of [36],  p. 45 and p. 53, respectively. In this way, the programs evolved by ELM are ineffect indirect encodings[6, 8, 60, 62] for Sodaracers. That is, in principle, any indirect encoding expressible through code could be evolved from scratch or modified by ELM.
More ambitiously than only generating a repertoire of Sodaracer designs, the experiment will attempt to implement an entire invention pipelinethat ultimately yields a novel kind of conditional LLM that can input a terrain and output an appropriate Sodaracer for that terrain. ELM thereby serves as the initial data-generation phaseof this pipeline, showing in this way how ELM can serve in general as a way of generating domain data for downstream deep learning where it did not previously exist. Furthermore, in the future, the ability to train such conditional inventors could serve as a foundation for an open-ended world of DCT-generating agents.
In practice, the aim of the invention pipeline is to create an agent that can output complex artifacts conditionally, based on its observation of the environment. If inventionis conceived as an action, then learning to invent conditionally can be viewed as a reinforcement learning(RL) problem [66]. That is, for any given observation, the agent can be rewarded depending on the success of the resultant invention. For example, in Sodarace, the agent might observe a specific terrain such as a hill and then output a design for a Sodaracer artifact. The reward then depends upon the performance of the Sodaracer in the observed terrain.
This approach sounds straightforward—it is simply RL with complex outputs—but there is a problem. If the agent has no prior experience in the domain (e.g., in Sodarace), then outputting even a valid (let alone working) artifact is effectively impossible. As a result, there is no gradient for RL and it cannot bootstrapinto the new domain.
Therefore, to get RL started, some form of pretraining is necessary. In effect, the RL fine-tuning described above is actually the last step in a pipeline, where the preceding step is to teach the agent something preliminary about its domain. For that purpose, an LLM can be trained on a large set of examplesfrom the target domain. For example, these examples could be Sodaracewalker designs. After exposure to enough such designs, in principle, the LLM knows something about the domain and can output sample artifacts from the training distribution. With such knowledge later passed on to RL, it should now be possible to bootstrapinto conditional fine-tuning.
However, there is stilla problem: where did all the examples come from for training the LLM? If the hope is for the conditional inventor eventually to invent in a novel domain like Sodaracewhere a generic LLM is unlikely to have any exposure, then the source for all the examples needed to train the LLM is itself elusive. As a consequence, the pipeline needs yet one more preceding step—which is where ELM comes in—to generate a set of example artifacts from scratch, which could then train the LLM that will eventually bootstrapRL.
Generating a diverse and large set of initial training examples is a search problem. However, because no LLM yet has any exposure to the right kind of data, it is a search problem within the invention space rather than within the weight space of neural networks. Searching for diverse functional examples (to get a wide pretraining distribution) within the space of artifacts is the natural role of QD (i.e., MAP-Elites in this chapter). Combined with the diff function, the result is ELM, which yields a novel approach to generating training examples, thereby bootstrapping the entire process.
To recap, what emerges is a three-stage invention pipelinefor training conditional inventors (Fig.  11.5): 
1.
ELM.Search for a diverse set of example artifacts (e.g., Sodaracers on flat ground).
2.
Pre-train the LLM with examples from ELM.The LLM accordingly learns to output example inventions from the training distribution.
3.
Learn to invent conditionally.Splice new conditional inputs onto the LLM and fine-tune it through RL to produce appropriate inventions for the conditions it observes.
Fig. 11.5
The Invention Pipeline.(left) A three-staged training pipeline bootstrapsfrom a single example of an invention to an LLM that can output an invention tailored to its current condition. The hope for the future is for such a conditional inventor agent to help seed an open-ended process, wherein interactions between agents and their inventions spur continual innovation. (right) In the Sodaracedomain, the conditional inventor observes the terrain, which conditions the LLM to output the specification of the desired invention
11.4.1 Encoding Sodaracers with Python
Previous experiments targeting Sodaracehave leveraged specialized evolutionary encodings [67]. Instead, in this work, plaintext Python code acts as a generic representation for inventions. By showing how Python can be used to represent artifacts in an arbitrary domain, it opens up the possibility of using it as a generic encoding in diverse future domains. More specifically, in the experiments, an individual is evaluated by executing its code through the Python interpreter. The product of the interpreter (for a viable individual) is a data structure containing the description of a Sodaracer (i.e., a Python dictionary containing lists of both point masses and springs), which can then be passed to the Sodaracesimulatorto evaluate the encoded Sodaracer’s behavior. Note that Sodaracers are encoded in Python throughout the invention pipeline, i.e., ELM evolves Python programs and the language models in both latter stages of the pipeline are trained to output Python programs (Figs.  11.6and 11.7).
Preliminary experiments showed that the diff model’sinitial performance (i.e., before fine-tuning) in creating useful perturbations depended upon the design of the “interface” through which Sodaracers were procedurally constructed. That is, while a Sodaracer can be constructed in Python by directly adding elements to a Python dictionary with keys such as “joints” and “muscles,” a more Pythonic interface (which was more effective and is what is used in the experiments) is to create a simple class with two methods: “add_joint” (to add a spring) and “add_muscle” (to add a point mass.) The idea is that such an interface (here encapsulated in a class called “walker_creator”) is closer to the training distribution of Python code (although still no Sodaraceexamples in this format exist). For example, below is the encoding of a simple hand-designed square Sodaracer (that is also used in the experiments as a seed), as well as its translation after being executed into a dictionary of joints and muscles. The interface also includes logic for ensuring that the Sodaracer will not break the underlying Box2D physics engine, e.g., that each joint is connected only to so many muscles, that the strength of muscles is limited, and that there is a minimum distance between joints. Note that the benefit of evolving a program that produces a data structure rather than directly evolving the data structure itself relates to the benefits of indirect encoding(i.e., a program can leverage regularities through loops, conditionals, and functions, to efficiently encode large complex structures) [62]. Figure  11.8shows an image of this walker when instantiated.
Fig. 11.6
Listing 1:Example Sodaracer-generating program
Fig. 11.7
Listing 2:Intermediate Sodaracer representation from running the above Python seed program
Fig. 11.8
Instantiation of a hand-designed square Sodaracer.
A video of this walker is available [71]
11.5 Pipeline Stage 1: Data Generation Through ELM
Recallthat the aim in this first stage is to generate a large variety of high-quality examples from a single example starter program through ELM. In this stage of the pipeline, the Sodaraceenvironment is a simple flat terrain.
Recallthat ELM in this experiment will evolve through MAP-Elites(Fig.  11.3) [45]. The core of MAP-Elitesis a uniformly spaced grid of niches(called the map) that spans user-specified dimensions of solution diversity, called the behavior characterization. In experiments here, the behavior characterization consists of the height, width, and mass of Sodaracers, and the map is a grid into which any behavioral characterization can be mapped. Upon initialization, a single hand-designed solution is evaluated and placed into the map. In each iteration thereafter, an inhabited niche is randomly chosen and the solution within thatnicheis perturbed by the diff modeland evaluated. The new candidate solution is assigned its nichefrom its behavior characterization, and if that niche is unfilled or the new solution outperforms the niche’scurrent inhabitant, it becomes the champion of that niche; otherwise, the candidate is discarded. In this way, over iterations of search, the map gradually fills with increasingly diverse and high-quality solutions.
To address the need for seed solutions, four simple seeds were written that explore different architectural motifs: the Square seed, the Radial seed, and two CPPN-like seeds (CPPN stands for compositional pattern-producing network[60]); note that source code for these seeds is provided in Appendix B of [36],  p. 45. The Square seedinstantiates a polygon-like bias, by including a function that creates a square composed of four masses from two coordinates, and code that calls that function and connects the masses together with a for-loop. The Radial seedinstead implements a radial biasby replacing the square-generating function with a function that places a given number of masses in a circular shape. Finally, the CPPN-like seeds roughly implement the CPPN-based encoding used by previous work in Sodarace[67], i.e., it places masses and connects springs between them as a mathematical function of their coordinates. The CPPN-based seed’s code can be neatly divided into (1) implementing the core functionality of a CPPN and (2) describing a particular instantiation of a CPPN, and thus enables exploring the consequences of letting core functionality of the encoding itself evolve. To this end, there are two CPPN seeds, one in which the CPPN encoding is fixed, called the CPPN-fixed seed, and one where it is mutable, called the CPPN-Mutable seed. Note that these seed programs were not highly tuned as the videos in Fig.  11.9highlight.
Fig. 11.9
The three seed solutions.From top to bottom: CPPN seed, radial seed, and square seed.
Same video as for Fig.  11.8[71]
11.5.1 Experimental Details and Results
Three independent runs of ELM were conducted with each seed, running for 1,024,000 evaluations each (composed of 2,000 iterations of 512 diffs per iteration). A 300  M-parameter pretraineddiff model[51] served as the perturbation operator in these experiments.
One metric of success for ELM is the number of nichesfilled, which represents the diversityof data generated by ELM, under the hypothesis that such diverse data will benefit later pipeline stages. Figure  11.10shows that runs of ELM tend to discover a large proportion of niches, highlighting how the system can bootstrapfrom a single user-provided example to fill the space of desired possibilities. However, the speed of spreading through nichesvaries across seeds; in particular, introducing loops and/or function composition is required for the Square seedto spread into high-mass niches (e.g., to connect many squares together), which emerges slowly in some runs.
