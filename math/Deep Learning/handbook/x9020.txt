To no surprise, researchers delved into the issue of agent bodyoptimization; such topic is relevant for EML as it is deals with problems of RL, itself a part of ML. With respect to controlleroptimization, the body places an additional challenge: most agent bodiesare not differentiable and thus cannot be optimized by the means of gradient-based optimization methods. [57] explored policysearch to jointly optimize the control and body parameters of simulated bipedal walkers, but restricted the search to different configurations of the same morphology (e.g., length of the pedals). To fully unleash its potential, bodyoptimization must be capable of open-ended complexity. EAs fit this goal, since they can evolve any artifact given an appropriate representation and a fitness function.
Starting from the seminal work of [166]—the “father” of ER—who first unveiled the power of evolution for optimizing the bodiesof virtual creatures, researchers have increasingly relied on EC also for bodyoptimization and body-brain optimization. Both of them pose unique challenges when compared to controlleroptimization, as we shall see in the following.
23.3.1 EML for Body Optimization
As representing a bodyis non-trivial, body optimization propelled researchers to put effort into conceiving representations that are (a) scalable, in terms of the solution complexity, and (b) effective, in terms of the quality of the solutions. The literature usually groups body representations into two categories: directand indirect(sometimes also called generative). Direct representations provide a one-to-one mappingbetween genotype and solution, whereas indirect representations, on the other hand, evolve a data structure that we can map to a solution in a non-trivial procedure. In a certain sense, indirect representations evolve the blueprint that can generate a solution by decoding the instructions contained in the genotype (hence the name “generative”).
23.3.1.1 Direct Body Representations
Direct representations provide a one-to-one mapping betweengenotype and solution. They are, in general, easy to craft, but potentially less scalable than indirect ones, as the complexity of the genotype directly depends on the complexity of the solution. Examples include graphs and numeric vectors.
Numeric vectors are the most direct of the representations. In that case, every gene (i.e., scalar) encodes a specific trait of the solution. For example, [142] evolved the morphologies of2D voxel-based soft robotsencoding each voxel (given a maximum enclosing grid) with a real number in a vector (see Fig.  23.14). Albeit simple, this representation proved effective to evolve a variety of shapes and behaviors, also using a speciation mechanism  [172].
Fig. 23.14
A schematic view of the grid-based, fixed-length direct representation for evolving the bodyof 2D voxel-based soft robotsused by [120]; image taken from  [120]. A fixed-length real vector is first reshaped in a matrix; then, starting from the cell with the largest values, subsequent voxels are added in correspondence with cell with next largest values that are adjacent to already visited cells. Similar representations have been used, e.g., in  [46, 142, 143]
Sims [166] first evolved virtual creaturesby encoding their morphology as a directed graph, with nodes being the rigid parts and the edges being the connections among those. The resulting creatures not only evolved life-like patterns for locomotion, but also for competitive co-evolution, where individuals belonging to different populations (forming species) evolve to win a one-on-one fight for the control of a resource (a cube in the arena where the simulated creatures fight)  [165]. As testified by adoption of open-source platforms, graphs (including trees  [69]) have proved an intuitive representation for modular robots  [3, 195].
23.3.1.2 Indirect Body Representations
Indirect representations evolve a data structure that we can map to a solution in a non-trivial procedure.
Indirect representations attracted the most interest in the community. In fact, they bear similarities to what happens in biological organisms, whose complexity and diversityare the result of an astonishing data compression feat, the “genomic bottleneck”  [151]: just a handful of genes in the DNA encode the instructions to build a complex organism (humans, with 30 trillion cells and all their cerebral complexity, just have 30,  000 genes in their genome  [189]). As a result, indirect representations might provide a bridge toward more complex robotic systems.
Examples of indirect representations include
Compositional Pattern Producing Networks (CPPNs);
sequences mapped to strings belonging to languages defined by grammars;
Gene Regulatory Networks (GRNs).
Indirect representations allow great freedom to the designer and are suitable to evolve properties we know are beneficial a priori. As a matter of fact, CPPNs  [169]—univariate function networks resulting in multivariate functions expressing repetitions and symmetries—evolved to express multi-material 3-D morphologies with life-like patterns, e.g., symmetry  [4] (see Fig.  23.15). On the same research line evolved CPPNs expressed effective morphologies for 3-D voxel-based soft robotsfor squeezing through tight spaces  [21], underwater locomotion[28], and recovering from damages  [96]. Most notably, evolved CPPNs expressed—in silico—the morphologies for organisms to be assembled—in vivo—from cells of Xenopus laevis(a frog); such organisms (the xenobots) can locomote by themselves  [95] as well as self-replicate  [93] and are, to date, one of the most impressive simulation-to-reality feats within the robotics EML community.
Fig. 23.15
Schematic view (on the left) of an indirect representation based on CPPNs for optimizing the bodyof3D voxel-based soft robots; in the middle, an example of an evolved bodythat is effective in locomotion and exhibits life-like patterns as repetitions and symmetries; on the right, a robot evolved with a direct representation (conceptually similar to the one of Fig.  23.14)—all the three images are taken from  [23]. [23] used NEAT as the EA driving the evolution of the CPPNs describing the robot bodies. The controllerhere simply consists in different phases of the expansion-contraction cycle of the voxel composing the body, here visually encoded with different colors
Similarly to CPPNs, grammars allow the designer to bias thesearch space, but in a different way: grammars specify the building blocks of a solution and what relationships are admissible among those blocks. There exists a rich literature on the evolution of solutions defined in languages described by grammars, starting from Grammatical Evolution (GE), a form of GP  [92], and its more recent variants, as Probabilistic Structured GE  [109] or Weighted Hierarchical GE  [7]. Lindenmayer systems (L-systems)  [99]—first developed to model the biological development of multi-cellular organisms—consist of an alphabet of symbols to be replaced with replacement rules (see Fig.  23.16): symbols can be robot modules and instructions on how to assemble them  [65]. As a result, L-systems have succeeded at evolving modular robots  [113, 114] on the Revolve framework  [69].
Fig. 23.16
A schematic overview of an indirect bodyrepresentation for modular robots based on L-systems; image taken from  [115]. There is a symbol in the grammar for each available module and a few symbols for operating on the current expression, by replacing symbols, and for changing the reference point. [115] used this representation for evolving (simulated) modular robots composed of three possible modules: a controller, a joint actuated by a servo-motor, and a passive structural module
When evolving embodied agents, the effect of mutations is non-trivial and hampers evolvability  [41]. To this end, [13] conceived GRNs as linear genotypes that, through differential gene expression and the diffusion of gene products, transform a single structural unit into a complete robot morphology via a development process: mutations expressed earlier in development tend to have a more variable effect than mutations expressed later, lending to the evolvability of the representation.
23.3.1.3 Comparisons Among Representations
Considering how important the choice of the representation is, some works did consider comparing different representations; most of them considered the scenario of modular robots, because they allow for great expressive power in describing the bodies, due to their inherent nature of systems composed of many components (see Fig.  23.17).
Fig. 23.17
A visual summary of the outcome of three studies comparing different representations for the bodyof modular robots. In all the cases, the figure shows a few individuals obtained by the means of evolutionary optimization using one or two representations. aVeenstra et al. [185] considered modular rigid robots composed of up to 20 modules and found that, in particular at the initial stage of the evolution, a generative representation is better than a direct representation. Modules are of two kinds: a fixed cube and a cube-like one with a face that can be displaced with respect to the others by actuating a rotational joint. The generative representation is based on L-systems. Image taken from [185]. bMiras [111] compared a representation based on CPPN and one based on L-systems for evolving the bodyof modular rigid robots composed of four kinds of modules. The authors considered not only the impact on the effectiveness, i.e., the ability of the robot to move, but analyzed how the two representation biasand constrain the search space. They found that CPPN gives slower but more stable gaits. Image taken from [111]. cFerigo et al. [46] compared two representations, a grid-based direct one and an indirect based on Gaussian-mixtures, and two EAs in terms of their ability to foster the evolvability of found solutions, in the context of 2D voxel-based soft robots. The authors found that the evolvability is mostly influenced by the EA, while the representation largely affects the fitness. They also found an evident biastoward larger robots with the indirect representation (bottom in this figure).
Image taken from [46]
Extending the work of [4, 23] showed that evolution of CPPNs is more effective than a direct representation at expressing morphologies for multi-material voxel-based agents, as it produces regular patterns as seen in nature (see Fig.  23.15). Also using modular robots, [185] argued that indirect representations are more suitable for evolving small-sized robots, a conclusion that we find counter-intuitive. [32] found an indirect L-system representation to underperform a tree-based direct one in terms of locality of the representation  [152], since many genes needed to align to create a positive effect on the solution (epistatic effects).
In the context ofvoxel-based soft robots, both [120] and [46] compared different representations (a direct and indirect ones) for the bodyof the robots. In the former study, the authors considered the case of morphological development of robots, i.e., the addition of new voxels to the bodyduring the life of the individual, as dictated by the genotype according to the chosen representation. In  [46] (see Fig.  23.17c), the aim was to compare the representations in terms of their ability to favor the evolvability, i.e., the possibility to produce fit offspring, of found solutions.
Despite the efforts devoted by the authors of the studies surveyed above, a comprehensive comparison among representations is arduous, given the abundance of them; even indirect ones can differ wildly in terms of properties of the representation  [153]. Moreover, the works mentioned so far consider different robot types and frameworks. Thus, the community still misses a full understanding of the trade-offs among representations.
23.3.2 EML for Body-and-Brain Optimization
Body-and-brain optimization has historically been difficult  [80], due to the deep entanglement between the brain and the body. The seminal work of [100] suggested the reason to be the ruggedness of the fitness landscape: they proved that evolving the morphology of voxel-based agents for a fixed controllerresults in more premature convergence to local minima than evolving the controllerfor a fixed morphology. Controllers need to adjust to their morphology  [39], as the bodymodulates the communication (motor and sensory) between the brain and the environment.
Researchers have since then tackled body-and-brain optimization either by joiningthe body and the brain in the same optimization or decouplingthe two (e.g., with two nested optimization loops). Both approaches have benefits and costs: the former simplifies the optimization, while the latter explicitly takes into account how brains need to adapt to their bodies
23.3.2.1 Joining Body-and-Brain Optimization
Joining body-and-brain optimization allows to solve two (entangled) optimization problems as one single optimization problem.
When the representation is direct (as in Sect.  23.3.1.1) that amounts to joining the two representations (for brain and body)into one single representation [142]. For instance, [133] successfully evolved real four-legged robots (see Fig.  23.18) using one single numerical genotype for both morphological (leg lengths) and control (gait) parameters and showed adaptation as physical conditions changed. Going back, [166] evolved the neural network controllersof his virtual creaturesas graphs embedded inside the nodes of the morphology graph (see Sect.  23.3.1.1), with mutations applying to both types of graphs.
Fig. 23.18
The four-legged robot used by [133] for the joint evolution of morphology and control; image taken from [133]. The robot can (slowly) change the length of the legs: since the time-scale of this variation is much longer than that of the gait, the change is made offline, i.e., between subsequent fitness evaluations, and is hence considered a form of morphological evolution
Indirect representations (as in Sect.  23.3.1.2), on the other side, can potentially encode bodyand brain with the same data structure. [22] evolved voxel-based agents with two CPPNs, one to express the morphology and one to express the distributed open-loop controller, and reducing selection pressure on individuals with recent morphological mutations: evolution was free to mutate one CPPN or the other, while having time to “readapt” to new morphologies. Their approach showed potential to avoid local optima. Finally, [144] evolved one single neural cellular automaton for developing the bodyand functioning as the brain for multi-material car racers and is a promising line of research (see Fig.  23.19).
Fig. 23.19
A schematic overview of the approach proposed by [144] for the concurrent evolution of the bodyand the brain of a simulated robotic mobile agent composed of a few modules with different roles. The key contribution of this work is in the neural cellular automaton used for determining both the way the body develops, in an initial instantaneous stage at the beginning of the agent life, and how it behaves during its life: in the latter stage, actuable modules (i.e., those equipped with wheels) wheels are controlled based on the state of the automaton.
Image taken from [144]
23.3.2.2 Decoupling Body-and-Brain Optimization
Decoupling approaches usually cast the body-and-brain optimization problem as a nested optimization problem. An outer evolutionary loop searches in the space of bodies, while an inner optimization loop searches—for each body—in the space of brains; intuitively, that is how nature shaped animal life on Earth. Approaches then differ according to the algorithm employed at the inner loop. Interestingly, both evolution and learning (the slowest and the fastest time-scales of adaptation, respectively  [167]) appear.
Some works adopted RL to learn the brains, as RL is a sample-efficient optimization over the lifetime of a robot. Most notably, [56] evolved bodieswith a genetic algorithm and learned their brains with RL to master a wide gamut of tasks for tree-based simulated robots, verifying that such environmental complexity fosters the ability of a body tofacilitate learning of novel tasks. Additionally, bodiesthat are more physically stable and energy efficient facilitate learning the most.
On the other side, the inner loop need not consist of learning, but may be evolutionary just like the outer loop. In particular, every bodycomes with a population of brains that evolve and whose best individual determines the fitness to the body-brain pair. Using this approach, [78] compared a Darwinian and Lamarckian approach for the inner loop and found that the latter considerably reduces the time to learn a good solution. Similarly, [97] showed that initiating learning from a brain inherited from an archiveof learned brains, rather than from a randomly initialized one, both the speed and magnitude of learning increased over time. Subsequently, [112] found that indeed the inner evolutionary loop produces robots that perform better on a given task and [102] quantified the learning delta—the performance difference between inherited and “learned” brains—in terms of morphological descriptors.
23.4 Other Combined Usages of EC and ML in Robotics
There are many other cases in which EC has been successfully used for optimizing other components of scenarios involving robots than “just” bodyand brain. These cases include other parts of the robots, such as the sensory apparatus ofvoxel-based soft robots[43, 45] or the object recognition part of robot grippers  [67], the way robot develops during their life  [94, 120, 124], as well as the task itself  [132, 187], or even the simulatorused for optimizing, in simulation, a real robot  [11]. While all these approaches can be encompassed in the field of ER, they hardly fit the definition of EML, since they do not directly and explicitly employ ML.
In a few other cases, ML and EC “met” in contexts where they both concurred in determining a solution for a broader problem. For example, [142] studied what are the key evolutionary factors (namely, the employed EA) affecting the diversityofevolved voxel-based soft robots: the authors interpreted the notion of diversitytaking the inspiration from biology, where a human observer categorizes individuals within a predefined structure of categories (species). In the cited work, the authors used a supervised ML pipeline to replace the human observer with a model learned from a few data points labeled by an actual human observer. The model is hence used for measuring the diversityof a large number of evolved populations of robots that, for the scale, could not have been manually inspected by an actual human. The authors found that those EAs that are designed to promote diversityare indeed able to achieve this goal, in particular when behavioral traits are used for telling apart individuals. However, they also found that external conditions (i.e., the environment) may have an even greater impact on observed diversity: e.g., robots evolved for doing locomotionon a downhill terrain very often ended up having a rounded shape which facilitated rolling.
A similar approach, i.e., one in which ML powers a component of a larger system in which at least another part is based on EC, has been adopted by [91]. For the aim of fighting the reality gap(see Sect.  23.5), the authors trained a ML model for estimating the transferabilityof robot controllersevolved in simulation, i.e., the degree to which their performance, as seen in simulation, do not change when moved in reality. The evolution itself was bi-objective, with one objective being the transferability and the other being the effectiveness. According to the authors, evolving for transferabilityand effectiveness together is practical way for fighting the reality gapproblem.
23.5 The Reality Gap Problem
As already mentioned inthe previous sections of the chapter, in ER an EA operates on a population of robots plunged into an environment. The ultimate goal is that of designing a robot (its brain, body, or both) which maximizes all the desired performance when involved in a given task.
Since EAs are loosely inspired by natural evolution, which has been quite successful in evolving various kinds of biological agents, i.e., living creatures, they appear promising for optimizing artificial agents, i.e., robots, too  [101]. However, their stochastic nature implies that multiple executions have to be performed to assess their outcome in practice, and calls for a solid statistical analysis for determining the best strategy to be adopted  [8, 36]. Unfortunately, repeating several (often thousands) experiments on real robotic platforms can be hugely expensive, time-consuming, and often potentially dangerous. For this reason, most ER applications focus on evolving robots using simulated robot-environment interactions, and then transfer the obtained results to the real robot-environment system (i.e.,  simulator-to-reality transfer, otherwise known as sim-to-realtransfer)  [91]. Only few works evolve controllersdirectly on the robot, and often optimize few individuals during few generations, which reduces the effectiveness of the evolutionary methods  [37, 53, 101, 148].
Simulation is therefore considered a very powerful and useful tool in the context of evolution of robots, since a long time  [184]. However, at the same time, it carries some disadvantages that often result in an under-performing, or, in the worst case, completely ineffective solutions when applied on the real system  [40, 62]. This effect is often called reality gap[76], i.e., the difference between the effectiveness measured in simulation and the one measured in reality of a solution that has been obtained in simulation (see Fig.  23.20).
Fig. 23.20
Example of reality gap, from  [139]. The robot effector reaches the target (the red circle) in simulation (left), but fails to reach it in the real application (right)
Although the term reality gapis widely used in the ER community, this problem is not limited only to applications of EAs in robotics. Instead, as a matter of fact, it can occur on any system designed and developed using simulators, and then implemented in reality. RL applications, for example, can also be affected by this problem when trained using simulators  [156, 157]. More generally, in the control system community, where dynamic systems are controlled typically relying on model-based approaches—i.e., where the way the simulation models the real system is known and exploited in the control strategy—the reality gapproblem is for example referred to as model-plant mismatch  [5, 6, 88, 135, 162]. In this section, however, we focus our attention on the reality gapin ER.
The main questions one needs to ask when dealing with a reality gapare: 
1.
what are the differences between simulators and reality that affect the effectiveness of the solution found in the simulation?
2.
how can the mismatch be reduced?
Of course, as one might expect, the above questions are interrelated, often dependent on the problem addressed, and thus have no one-size-fits-all answers.
From a practical point of view, the mismatches between simulatorand reality, being the cause of the reality gap, can be classified into three macro-categories  [134]:
robot-robotcorrespondence,
robot-environmentcorrespondence,
environment-environmentcorrespondence.
The former refers to the physical differences between the simulated robot and the real one, such as morphological differences. Robot-environment differences refer to errors, or approximations, in the dynamic interactions between the robot and the environment, and include both perception and actuation. On the other hand, the latter, i.e., environment-environment correspondence, concerns the misrepresentation of significant features of the environment.
Clearly, once the source of such differences is recognized, there is a trivial solution to reduce the gap: improving the simulatorby bringing it as close as possible to the real system. In  [110], for example, simulatoris integrated with real data, in  [76] with noise on sensor level, while in  [11, 192] the robot model is directly learned online. [90] presented a broad comparison of model improvement approaches in dealing with the reality gap
However, this general solution has a negative impact on the efficiency of EAs even when applied in simulation: the time or computational effort needed for finding a solution increases. Simulatorswith higher accuracy tend to be more demanding in terms of computational time, thus losing one of the main advantages of using simulators. Hence, a trade-off exists between the effectivenessof an optimization technique (i.e., the quality of the solution it finds for a given task), and its efficiency. Assuming, therefore, that a certain amount of reality gapmust be tolerated, it is necessary to build or tune optimization techniques (including evolutionary ones) in such a way that they match the user expectation in terms of reality gap, effectiveness, and efficiency.
There are different works in the literature proposing approaches able to mitigate the reality gapeffect in ER. Although we cannot discuss each of them in-depth, we provide below a categorization of those which work in the optimization phase—i.e., the vast majority of them. A rather different approach is to try to fill the reality gapby building robots that can adapt to changes while they operate. For example, [168] employed ES to realize a form of meta-learning that allows a real legged robot to adapt to changes in its bodydynamics (due to robot load and battery voltage change). In principle, this kind of adaptation could be achieved also with controllersthat exhibit plasticity, such as SNNs or ANNs with Hebbian learning
23.5.1 Domain Randomization
The idea of domain randomizationis to improve the simulatorrobustness by providing sufficient simulated variability at the training time, such that the model is able to generalize to real-world data in test. The result is a more robust solution to model variation, and it can be achieved following different strategies: performing adaptive feedback control[117, 147, 182], i.e., closed-loop control strategies in which some measurements are fed back to the controllerto properly adapt the control law to instantaneous changes in the environment or in the robot itself, developing robots within a variety of different environments  [9, 12, 52], or randomly perturbing model parameters during the evolution  [74, 75, 178].
23.5.2 Simulator Flaws Avoidance
Avoid the exploitation of simulatorflaws is grounded on the idea that, if the solution search space during evolution is such that it exploits the defects of thesimulator, then the learned solution will necessarily be subject to the reality gapwhen transferred to the real robot. Therefore, the approaches that address the reality gapout of this point of view try to reduce the exploitation of simulatorpitfalls automatically adjusting hyper-parameters  [47, 48, 180], or slowly increasing the representative power of the search space  [49].
23.5.3 Fostering Rransferability
A promising idea is the one that consists in learning a model that can roughly quantify the reality gapbetween a simulatorand a real robot for each investigated design, i.e., to estimate the design (non-)transferability, and use the estimate to constrain the design process. This is the main idea of  [91], where authors formulated the transferabilityapproach, i.e., a bi-objective algorithm in which a task-dependent performance metric is maximized, while a disparity measure between performance in simulation and in reality (i.e., a non-transferability measure) is simultaneously minimized (see Fig.23.21). The cited work is particularly relevant to this chapter because the authors use a classical ML pipeline for estimating thetransferabilitybased on some features that can computed for each possible solution being evolved.
Fig. 23.21
An overview of the algorithm proposed by [91] for evolving robot controllersavoiding to fall in the reality gap problem. The designer needs to identify a few behavioral descriptors that can be computed both in simulation and reality; based on these descriptors, an estimation of the (non-)transferability (STR, i.e., sim-to-real, disparity) of each solution evaluated in simulation is produced using a supervised ML model. The evolution is bi-objective, with one objective being the non-transferability, to be minimized, and the other being the task-dependent effectiveness. The ML model for estimating the non-transferability is maintained and updated by assessing in reality some of the solutions found in simulation at regular intervals.
Image taken from  [91]
The same idea has been subsequently pursuit in other works in which, for example, the discrepancy between simulatorand real robot has been monitored in morphology  [95, 158, 183].
23.6 Concluding Remarks and Open Challenges
The field of robotics offers a plethora of opportunities for applying evolutionary optimization. Many components of robots and their tasks can be optimized, rather than manually designed, and the corresponding search spaces are often very large and hardly amenable to be searched with more traditional search methods: hence EAs can deploy their potential as universal search techniques. Moreover, the combination of EC and ML appears to be particularly effective when used to tackle different facets of a larger problem.
There are, however, some open challenges. We believe they are well captured by the recent work of [40], who suggested that future research in ER should attempt to 
1.
Target more realistic robots and real tasks: this will require to (i) focus on robotic subsystemsthat are currently overlooked, such as sensors, (ii) consider more complex tasks, such as, e.g., object transportationinstead of the simple locomotion, and (iii) make assessment more scalable, in such a way that it can actually be executed for many candidate solutions. We think that the latter point is a particularly fertile terrain for the combined use of EC and ML.
2.
Increase sample efficiency, i.e., reduce the number of assessments that are needed to obtain a given solution quality upon optimization.
3.
Provide amore solid formalization of the properties  ofa robotic system that can affect the success of evolutionary optimization. In particular, we think that a finer characterization of the body-brain duality, i.e., their ability to host the cognition that the robot needs to perform its task, would be beneficial.
References
1.
Akinci, K., Philippides, A.: Evolving recurrent neural network controllers by incremental fitness shaping. In: Volume ALIFE 2019: the 2019 Conference on Artificial Life of Artificial Life Conference Proceedings, pp. 416–423 (2019)
2.
Albrigtsen, S.I., Imenes, A., Goodwin, M., Jiao, L., Nunavath, V.: Neuroevolution of actively controlled virtual characters—an experiment for an eight-legged character. In: Pimenidis, E., Jayne, C. (eds.) Engineering Applications of Neural Networks, pp. 94–105. Springer International Publishing, Cham (2018)
3.
Auerbach, J., Aydin, D., Maesani, A., Kornatowski, P., Cieslewski, T., Heitz, G., Fernando, P., Loshchilov, I., Daler, L., Floreano, D.: Robogen: robot generation through artificial evolution. In: Volume ALIFE 14: the Fourteenth International Conference on the Synthesis and Simulation of Living Systems of Artificial Life Conference Proceedings, pp. 136–137 (2014)
4.
