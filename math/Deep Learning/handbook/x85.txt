17.3.1 The Pareto Optimisation Approach
This approach aims atfinding a set of non-dominated individuals (candidate solutions) based on the concept of Pareto dominance, as follows. An individual idominates another individual jif iis better than jin at least one objective and is not worse in all other objectives. An individual iis deemed non-dominated if no other individual dominates i. At each generation of the EA, every generated individual is compared against all others in the population to check if it is a non-dominated solution
Fig. 17.1
Example Pareto front for two objectives to be maximised. The non-dominated solutions are shown in blue circles and the dominated solutions in red triangles
Figure  17.1shows an example set of candidate solutions for a two-objective problem, where each objective is represented as an axis on the graph. Assuming both objectives are to be maximised, the Pareto frontis formed by the non-dominated solutionsrepresented by blue circles, whilst the solutions represented by red triangles are dominated solutions. A very popular type of EA for multi-objective optimisation based on Pareto dominanceis the NSGA (Non-dominated Sorting Genetic Algorithm) series of algorithms [12, 36].
In general, in EAs based on the Pareto approach, the solution returned by the EA is the best Pareto frontfound by the algorithm. This front will usually contain a large number of non-dominated solutions, representing different trade-offs between the different objectives. In real-world applications, in general, there is a need to choose just one or perhaps a few non-dominated solutionsto be implemented in practice (e.g. choose a single classification model to predict the credit status of new customers). Usually, this choice is left for users, based on their subjective preference for different trade-offs of objectives.
17.3.2 The Lexicographic Optimisation Approach
Unlikethe Pareto approach, the lexicographic approach to multi-objective optimisation requires that an order of priority (importance) for the objectives be defined by the user. Importantly, it is usually easier and more natural for users to specify an ordering of objectives than an ad hoc numeric value for the weight of each objective in the weighted sum approach.
The lexicographic approach works by considering each objective in turn, in their decreasing order of priority, i.e. starting with the most important objective to be optimised. For each objective, the system compares two individuals in terms of their values for that objective. If there is a ‘substantial’ difference in their objective values—i.e. if the difference is greater than a pre-defined parameter, then the best individual based on that objective is selected. However, if the difference between the objective values is within , the difference is considered ‘negligible’ and the two individuals are considered ‘equivalent’ based on that objective. In this case, the next objective in the priority order is considered in the same way, and so on. This is repeated until a substantial (greater than ) difference is observed and the best individual is selected. If there is no substantial difference between two individuals for all objectives, then the individual with the best value of the first, most important, objective is selected.
Note that the use of the parameter in the lexicographic approach is in theory somewhat analogous to the use of weights assigned to objectives in the weighted-sum approach. However, in practice the parameters can be considered ‘less critical’ than the weights of objectives in the weighted-sum approach, as follows. In the weighted-sum approach, all the weights of the objectives will always affect the evaluation of the quality of all candidate solutions, whilst, in the lexicographic approach, the values of lower priority objectives will be less important, since their value is irrelevant when evaluating many candidate solutions. In particular, when a solution s1 has a significantly better value of the highest priority objective than solution s2 (i.e. their difference is greater than ), solution s1 is selected over s2 regardless of the values for the lower priority objectives. In addition, in practice, since is just a ‘difference threshold’, often the same value of is used for all objectives, reducing the number of parameters.
It should also be noted that, unlike the Pareto approach (which returns many non-dominated solutions), the lexicographic approach returns a single best individual to the user.
17.3.3 Pros and Cons of the Pareto and Lexicographic Multi-objective Optimisation Approaches
Overall, the Pareto and lexicographic approaches have different pros and cons depending on the application, as follows.
First, the fact that the Pareto approach returns many non-dominated solutionsgives users the flexibilityto choose their favourite non-dominated solution, which could be an advantage in many applications. However, in applications where users are extremely busy, they might prefer to have a single solution returned by the system, as provided by the lexicographic approach.
In addition, among the three multi-objection optimisation approaches discussed here, the Pareto approach is the only one which has the advantage of not requiring any parameter to cope with the trade-offs between the different objectives. Recallthat the lexicographic approach requires the specification of a parameter (threshold) to determine whether or not the difference between two values of an objective is substantial, as mentioned earlier. Although it is common to use the same value of for all objectives (particularly when all objectives take values in the same range), in some cases, a different value can be used for different objectives (e.g. if the objectives take values in different ranges), which would increase the number of parameters.
Moreover, in some applications, users clearly consider some objective(s) as more important than other(s), but the Pareto approach has the limitation that it does not allow the system to take the user’s priorities about objectives into account during the search—i.e. those priorities would be considered only after the search, when the user chooses the best non-dominated solution
For example, in the classification task, when maximising model accuracy and minimising model size, nearly all users would clearly consider accuracy more important than size. This is important background knowledge that is not considered during the search in the Pareto approach. Consider, for example, a solution which is the smallest model but has low accuracy. In the Pareto approach, this solution could be a non-dominated solutionin the Pareto frontfor many generations, which would be an inefficient use of computational resources, since that solution would never be selected by the user as the preferred non-dominated solutionafter the search.
In the lexicographic approach, the EA would directly take into account the background knowledge (user preference) that model accuracy is more important than model size, so the smallest model with low accuracy would never be selected over a substantially more accurate solution (as the highest priority objective).
17.4 Evolutionary Algorithms for Fair Machine Learning
This section reviews six EAs for fair classification. The first one is a Genetic Programming (GP) method, whilst the others are in general Genetic Algorithms (GAs). In general, these EAs optimise predictive accuracyand some measure(s) of fairness. In addition, two other EAs for fair classification are mentioned in [17, 33], although these articles focus mainly on multi-objective optimisation issues, rather than focusing specifically on EAs.
17.4.1 A Genetic Programming Algorithm for Fair Feature Construction
La Cava and Moore [26] proposed a GP algorithm for feature constructionthat optimises predictive accuracyand fairness. This GP essentially consists of extending another GP for feature construction, called FEAT [27], to the context of fairnesswith multi-objective optimisation
The individual representation is basically the same used by FEAT, where each individual is a set of trees consisting of continuous and/or boolean features in the terminal set (leaf nodes) and a number of mathematical operations in the function set (internal nodes). Hence, each tree combines original features into a new constructed feature so that a single individual represents multiple constructed features. The constructed features are then fed to a classification algorithm. For example, logistic regressionwas the algorithm used in [26].
The GP minimises the classification error and the unfairness of logistic regressionmodels learned with the features constructed by the individuals. The overall goal is to minimise these two objectives across groups of instances, where each group contains instances with a given value of a sensitive (protected) feature. For example, consider a dataset with two sensitive features, Gender (with value male or female) and Age (with value old or not-old). In this case, there are four groups based on these features’ values, namely, the groups containing instances where Gender male, Gender female, Age old and Age not-old.
The fitness of an individual is computed by considering such groups of instances. The goal is essentially to minimise two objectives in each group: (a) the error (loss) of a classifier (logistic regression)in the group; and (b) a measure of unfairness given by the difference of false positive (FP) rate or false negative (FN) rate between that group and the full training set of instances.
For minimising these two objectives, La Cava and Moore [26] proposed two main approaches. The first one is to use the Pareto approach, where they extend the GP (FEAT) to use the procedure for selecting non-dominated solutionsin the well-known NSGA-IIalgorithm [12].
The second approach proposed [26] modifies the GP (again, FEAT) to use lexicase selection, which is a selection method broadly analogous to the lexicographic approach. However, instead of ordering the objectives based on user-defined priorities (which is typically the case when using the lexicographic approach), lexicase selectionuses randomised lexicographic orderings of different groups of instances (with different sensitive features’ values).
The basic idea of lexicase selectionis that the selection procedure considers one ‘training case’ at a time, but considering different random orders of cases for each parent-selection event [19]. For each parent-selection event, it starts with a full pool of individuals (typically the entire population), and then for each training case, the pool of individuals is filtered to retain only the individuals with the smallest error in that case. The pool is often reduced to a single individual, which then becomes the selected individual. If the procedure runs out of cases and multiple individuals survived this filtering process, then the parent is selected at random among the surviving individuals.
Usually, each training instance (or example) is a ‘case’, but in this GP for constructing fair features, each group of instances, as defined above, is considered a case. Hence, for each parent-selection event, the algorithm tries to pass an individual through all groups, but an individual is allowed to pass through one of these groups only if its fitness is within a threshold (epsilon) of the best (using the -lexicase variant of lexicase selection). Note that a random sequence of groups effectively represents a logical conjunction of sensitive features’ values (e.g. Gender female andAge old). Hence, the GP has to evolve features that lead to accurate and fair classifiers for subgroups defined by intersections of the original groups.
Lexicase selectionpromotes diversityin the selected parents, because it can select individuals that perform very well on a small number of ‘hard training cases’ (in this context, hard-to-classify (sub)groups of instances) even if those individuals do not perform well on most of the training cases. This means this method can select ‘specialist’ individuals, contributing to the diversity of the selected parents [19, 26].
In addition, the fact that the GP considers a logical conjunction of sensitive features’ values helps to mitigate the problem of ‘fairness gerrymandering’ [20], mentioned around the end of Sect.  17.2
The experiments reported in [26] used four datasets often used as benchmarks in fair-classification research, and compared the results of six different selection or survival methods for the GP, including random search. The results were evaluated using the well-known hyper-volume measure, which estimates the area of the objective space covered by the solutions in a Pareto front. Overall, the GP variants performed better than a baseline approach for improving fairness[21]. However, surprisingly, the overall best rankings were obtained by random search, followed by the two versions of lexicase selection—with and without fairnessas an objective (with no significant difference between the results of these two versions). The fact that the GP variants did not outperform random search seems to be due to the GPs overfitting the training data.
17.4.2 Optimising the Hyper-parameters of a Fair Classifier with a Genetic Algorithm
Valdivia et al. [39] proposed a fairness-aware multi-objective GA for optimising the hyper-parameters of a classification algorithm, in order to produce a set of non-dominated classification models that trade-off accuracy and fairnessperformance. The GA is again based on the popular NSGA-IIalgorithm [12] for multi-objective optimisation.
The authors referred to the hyper-parameter optimisation process as a meta-learning approach. However, since that term is very broad, in this review, we prefer to describe this process as a type of Automated Machine Learning (Auto-ML). Auto-ML systems aim at automatically selecting the best algorithm and/or the best hyper-parameter settings of an algorithm to a given input dataset [46]. Hence, the task of automatically optimising the hyper-parameter settings of a given classification algorithm, performed by this GA, matches well the goal of Auto-ML.
One advantage of this Auto-ML approach is that any generic classification algorithm, even those that are fairnessunaware, can be used as the base classifier. Each classifier only requires its own hyper-parameter coding scheme and initialisation procedure to be defined in the Auto-ML framework before it can be used.
The GA uses two genetic operators, as follows. The crossover operator is a variant of uniform crossover operating on each gene. For each gene —where kis the iteration and irefers to a specific individual—one of two outcomes is realised, based on the probability : either the values of the parents, and , are simply copied from the parent to the children or the values from the parents are combined using the following equation:
(17.5)
This pair of equations creates two individuals that have their parents’ average gene values perturbed by some proportional value of the difference between the parents’ gene values, where is a uniformly distributed random value between 0 and 1.
The second genetic operator is a mutation procedure that modifies the hyper-parameter values encoded in an individual’s genes; and an individual undergoes mutation based on the user-defined probability . When mutation is performed, a random gene is selected and mutated based on the following equations:
(17.6)
and
(17.7)
where and are the allowed ranges for the i-th hyper-parameter, and are uniformly distributed random numbers and is a user-defined mutation parameter.
The GA optimises a single measure of fairness alongsidethe geometric mean of sensitivity (the true positive rate) and specificity (the true negative rate). The fairness measureused is the FPERBS shown in Eq.  17.2
Valdivia et al. [39] have tested the hyper-parameter optimisation framework using two base classifiers: a logistic regressionclassifier and a decision tree classifier, on five datasets. The analysis of the Pareto frontshowed that with the base decision tree classifier modest reductions in predictive performanceallowed large gains in the fairnessmetric. However, the logistic regressionbase learner required significantly higher losses in predictive performanceas a trade-off for improvements to the fairness measure
When investigating the complexity of the decision trees, it was found that increased levels of fairnessalso led to an increase in the number of leaf nodes in the models. This allows the model to split the data into increasingly finer divisions to equalise the false positive rates between the protected and unprotected groups. Note that more complex models are less interpretable, which may conflict with the goal of making machine learning algorithms fairer.
The experiments reported in [39] have not compared the GA against any other Auto-ML method for hyper-parameter optimisation of classification algorithms, which would be an interesting comparison for further validating the GA’s performance.
17.4.3 A Lexicographic Optimisation-Based Genetic Algorithm for Fair Feature Selection (LGAFFS)
LGAFFS [3] isa lexicographic optimisation-based GA that performs feature selectionin a pre-processing phase, i.e. before learning the final classification model. It aims to select a subset of features that lead to the construction of a fairer model by the base classification algorithm whilst retaining predictive performance
Unlike most EAs in this chapter, which perform multi-objective optimisation using the Pareto dominanceapproach, LGAFFS selects individuals for reproduction based on the principle of lexicographic optimisationto combine predictive accuracyand fairness measures
Each individual in the population represents a candidate feature subset. More precisely, each individual consists of a string of Nbits (genes), where Nis the number of features in the dataset, and the i-th gene takes the value 1 or 0 to indicate whether or not (respectively) the i-th feature is selected.
LGAFFS follows a wrapper approach to feature selection[29], where a base classification algorithm is used to learn a classification model based on the feature subset selected by an individual, and that model’s quality (in terms of accuracy and fairness)isused to compute that individual’s fitness. Hence, the GA aims at finding the best subset of features for the base classification algorithm. Fitness computation is performed using an internal cross-validationroutine that uses only the training set (i.e. it does not use the test set).
LGAFFS uses two standard genetic operators, uniform crossover and bit-flip mutation to create new individuals in each generation. However, it uses a non-standard, ramped population initialisation procedure. In this procedure, each i-th member of the initial population has a different probability of having a feature turned on (activated). These probability values are bounded by two user-specified parameters, MIN_Pand MAX_P. This procedure creates a more diverse initial population, where different individuals can have very different numbers of activated (selected) features. By contrast, if a standard population initialisation was used, all individuals would have the same expected number of activated features, which would be normally distributed around pN, where Nis the number of features and pwould be the probability of activating a feature if that was kept fixed for all individuals.
LGAFFS uses a lexicographic tournament selection procedure, with a tournament size of two, in order to select individuals for undergoing crossover and mutation. This lexicographic tournament selection procedure is a direct application of the lexicographic optimisation approach (described in Sect.  17.3.2) to the two individuals competing in the tournament.
As mentioned earlier, the lexicographic approach requires the objectives to be ordered in decreasing order of priority. LGAFFS optimises two objectives. The first, highest priority objective is a measure of predictive accuracy, namely, the geometric mean of sensitivity and specificity (). The second, lower priority objective is an aggregated value of the four fairness measuresdefined in Sect.  17.2
It should be noted that there is no consensus in the literature about what is the best fairness measure, and so it would be ‘unfair’ to prioritise one fairness measureover the others. Hence, the need to aggregate the fairness measuresinto a single objective without preference to a particular measure. This aggregation is achieved by computing all possible 24 (4!) permutations of the four fairness measuresand comparing individuals across all permutations. Each of the 24 possible permutation defines a lexicographic order of measures that can be evaluated to find the first substantial difference of fairness(i.e. a difference greater than ) between the two individuals in the tournament, at which point the best individual is given a win. Once all permutations of fairness measureshave been evaluated, the individual with the higher number of wins is declared the best individual overall (i.e. the tournament winner) as long as this difference is greater than some for the number of wins—a user-defined parameter.
Experiments reported in [3] compared LGAFFS against two other approaches on seven datasets, using random forest as the classifier. The results can be summarised as follows. First, in the comparison against the baseline approach of not performing feature selectionin a pre-processing step, overall LGAFFS obtained similar predictive accuracies but better values for three of the four measures of fairness. Second, in the comparison against a local search method that optimises accuracy only, overall LGAFFS obtained slight better accuracies and substantially better values of all the four measures of fairness.
17.4.3.1 Experimental Results Comparing LGAFFS to a Weighted-Sum GA
In these experiments, we compare LGAFFS to a simpler GA using the weighted-sum approach for multi-objective optimisation, hereafter called Weighted GA (WGA) for short. WGA uses a simple weighted formula that allows the user to alter the search biasbetween accuracy and the average value of four fairness measures(the same four measures used by LGAFFS).
The comparison of LGAFFS to WGA is a controlled experiment, as both GAs use the same population-initialisation procedure, genetic operators, operator probabilities, population size and number of generations. They also use the same predictive accuracyand fairness measuresfor fitness computation including the same aggregation of four fairness measuresinto a single objective. In addition, both GAs follow a wrapper approach for feature selectionusing the random forest algorithm as the base classifier.
On the other hand, LGAFFS and the WGA vary in their multi-objective optimisation approach. Hence, the observed differences in performance between the two algorithms (reported below) reflect mainly the differences in the effectiveness of the lexicographic and weighted-sum approaches.
The parameters required by these two algorithms can be divided into three groups: (a) parameters specific to LGAFFS; (b) parameters specific to WGA; and (c) parameters used by both algorithms—which were set to the same values for both algorithms, to make their comparison as fair as possible. The parameter values in each group are as follows:
LGAFFS-specific lexicographic parameters: accuracy_and fairness_: 0.01, fair_rank_and fair_test_: 1 (for details of these parameters, see [3])
WGA-specific parameters: weights for the accuracy and fairness objectives in the weighted-sum fitness function: 0.5
GA-related parameters, shared by LGAFFS and WGA: population_size: 100, MAX_P: 0.5, MIN_P: 0.1, number of folds for internal cross-validation: 3, max_iterations: 50, tournament_size: 2, crossover_probability: 0.9, mutation_probability: 0.05 (again, see [3] for details)
Table  17.1mentions, for each of the seven datasets used in all experiments, its number of instances and features, as well as the features used as sensitive features in the experiments. Recallthat a sensitive feature represents a protected characteristic or a group that is unfairly treated. When a dataset has multiple sensitive features, the algorithm is run multiple times using a different sensitive feature each time. All these are binary classification datasets. The first six datasets are from the UCI Machine Learning repository [13]; and the ProPublica dataset involves biasin predictions of which criminals would re-offend [1].
Table 17.1
Datasets used in all experiments, detailing the number of instances, features and the sensitive features for each dataset
Dataset
Instances
Features
Sensitive features
Adult income (US Census)
48842
14
Race, Gender, Age
German credit
1000
20
Age, Gender
Credit card default
30000
24
Gender
Communities and crime
1994
128
Race
Student (Portuguese)
650
30
Age, Gender, Relationship
Student (Maths)
396
30
Age, Gender, Relationship
ProPublica recidivism
6167
52
