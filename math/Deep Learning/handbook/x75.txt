Tomassini, M.: Introduction to evolutionary game theory. In: Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation, pp. 877–890 (2014)
103.
Toutouh, J., Esteban, M., Nesmachnow, S.: Parallel/distributed generative adversarial neural networks for data augmentation of covid-19 training images. In: Latin American High Performance Computing Conference, pp. 162–177. Springer (2020)
104.
Toutouh, J., Hemberg, E., O’Reilly, U.-M.: Spatial evolutionary generative adversarial networks. In: Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, New York, NY, USA, pp. 472–480. ACM (2019)
105.
Toutouh, J., Hemberg, E., O’Reilly, U.-M.: Analyzing the components of distributed coevolutionary gan training. In: Bäck, T., Preuss, M., Deutz, A., Wang, H., Doerr, C., Emmerich, M., Trautmann, H. (eds.) Parallel Problem Solving from Nature - PPSN XVI. pp, pp. 552–566. Springer International Publishing, Cham (2020)
106.
Toutouh, J., Hemberg, E., O’Reilly, U.-M.: Data dieting in gan training. In: Iba, H., Noman, N. (eds.) Deep Neural Evolution: Deep Learning with Evolutionary Computation, pp. 379–400. Springer Singapore, Singapore (2020)Crossref
107.
Toutouh, J., Hemberg, E., O’Reilly, U.-M.: Re-purposing heterogeneous generative ensembles with evolutionary computation. In: Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’2020, New York, NY, USA. Association for Computing Machinery (2020)
108.
Toutouh, J., O’Reilly, U.-M.: Signal propagation in a gradient-based and evolutionary learning system. In: Proceedings of the Genetic and Evolutionary Computation Conference, pp. 377–385 (2021)
109.
Tygar, J.D.: Adversarial machine learning. IEEE Internet Comput. 15, 4–6 (2011)Crossref
110.
Wang, C., Xu, C., Yao, X., Tao, D.: Evolutionary generative adversarial networks. IEEE Trans. Evol. Comput. 23(6), 921–934 (2019)Crossref
111.
Wang, G.L.M., Thite, A., Talebi, R., D’Achille, A., Mussa, A.W., Zutty, J.: Evolving simgans to improve abnormal electrocardiogram classification. In: Proceedings of the Genetic and Evolutionary Computation Conference Companion (2022)
112.
Wang, H., Won, D., Yoon, S.W.: An adaptive neural architecture optimization model for retinal disorder diagnosis on 3d medical images. Appl. Soft Comput. 111, 107686 (2021)Crossref
113.
Wang, X., Miikkulainen, R.: Mdea: malware detection with evolutionary adversarial learning. In: 2020 IEEE Congress on Evolutionary Computation (CEC), pp. 1–8 (2020)
114.
Wilkerson, J.L., Tauritz, D.: Coevolutionary automated software correction. In: Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation, GECCO ’10, New York, NY, USA, pp. 1391–1392. ACM (2010)
115.
Williams, N., Mitchell, M.: Investigating the success of spatial coevolution. In: Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation, pp. 523–530. ACM (2005)
116.
Wu, Z., He, C., Yang, L., Kuang, F.: Attentive evolutionary generative adversarial network. Appl. Intell. 51, 1747–1761 (2020)Crossref
117.
Ying, G., He, X., Gao, B.-B., Han, B., Chu, X.: Eagan: efficient two-stage evolutionary architecture search for gans (2021)arXiv:​abs/​2111.​15097
118.
Yu, X., Gen, M.: Introduction to Evolutionary Algorithms. Springer Science & Business Media (2010)
119.
Zhang, C., Ma, Y.: Ensemble Machine Learning: Methods and Applications. Springer (2012)
120.
Zhao, F., Lu, Y., Li, X., Wang, L., Song, Y., Fan, D., Zhang, C., Chen, X.: Multiple imputation method of missing credit risk assessment data based on generative adversarial networks. Appl. Soft Comput. 126, 109273 (2022)Crossref
121.
Zheng, W., Gou, C., Yan, L., Wang, F.-Y.: Differential-evolution-based generative adversarial networks for edge detection. In: 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW), pp. 2999–3008 (2019)
Footnotes
1
Computational costis shown for two populations of size N
Part IVEvolutionary Computation for Machine Learning
In which we explain how evolutionary computation methods can help improve and augment machine learning algorithms: For AutoML, model validation, explainable AI, and fair machine learning.©  The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.  2024
W. Banzhaf et al.(eds.)Handbook of Evolutionary Machine LearningGenetic and Evolutionary Computationhttps://doi.org/10.1007/978-981-99-3814-8_14
14.  Genetic Programming as an Innovation Engine for Automated Machine Learning: The Tree-Based Pipeline Optimization Tool (TPOT)
Jason  H.  Moore1, Pedro  H.  Ribeiro1, Nicholas  Matsumoto1and Anil  K.  Saini1
(1)
Cedars-Sinai Medical Center, Los Angeles, CA, USA
Jason  H.  Moore
Email: jason.moore@csmc.edu
Abstract
One of the central challenges of machine learning is the selection of methods for feature selection, feature engineering, and classification or regression algorithms for building an analytics pipeline. This is true for both novices and experts. Automated machine learning (AutoML)has emerged as a useful approach to generate machine learning pipelineswithout the need for manual construction and evaluation. We review here some challenges of building pipelines and present several of the first and most widely used AutoMLmethods and open-source software. We present in detail the Tree-based Pipeline Optimization Tool (TPOT)that represents pipelines as expression trees and uses genetic programming (GP) for discovery and optimization. We present some of the extensions of TPOT andits application to real-world big data. We end with some thoughts about the future of AutoMLand evolutionary machine learning.
14.1 Challenges of Machine Learning
A central goal of machine learning is to make predictions from multiple measured variables or features using mathematical functions that accurately model underlying patterns in the data. Ideally, those predictions would be accompanied by human-understandable reasoning. Machine learning excels over other analytical approaches when the relationship between the feature patterns and the outcome is nonlinear and/or heterogeneous among different subsets of the instances. Complex patterns in big data are often encountered in real-world problems such as predicting health outcomes or forecasting economic measures.
Machine learning algorithms fit internal parameters to minimize a specified loss functionbetween their predictions and the observed target feature. Models often come in the form of composite pipelines of several steps, including feature selection, feature pre-processing, feature engineering, and at least one classifier or regressor algorithm such as Decision Trees or Linear Regression. The primary challenge of a data scientist is to discover an optimal set of algorithms and hyperparameters that balance predictive performanceand interpretability. This often involves a lengthy and time-consuming process of trial and error that AutoMLseeks to automate.
We review here several challenges of designing a machine learning pipelineand then discuss genetic programming (GP) as an innovation engine for machine learning with big data. Figure  14.1provides an overview of these challenges. More detail on each challenge is provided below.
Fig. 14.1
Overview of the many decisions that need to be made when choosing feature selection, feature engineering, machine learning, and model evaluation algorithms. Also shown are the components ofmodel explainabilitythat are often necessary for real-world problem-solving and model deployment. The first three steps are typically targeted for automation
14.1.1 Designing a Machine Learning Pipeline
Machine learning pipelinesare a sequence of steps by which data is analyzed to arrive at a prediction. There are numerous algorithms and methods that could be included in a pipeline including data cleaning, feature selection, feature engineering, and classification and regression methods. Each can have a wide variety of different hyperparameters, and the models generated by these pipelines can be evaluated and explained in many different ways. We briefly review below some of the components and decisions that go into pipeline construction, application, evaluation, and deployment.
14.1.1.1 Data Cleaning and Quality Control
One of the challenges of machine learning is that the data do not always present in a format that is ideal for analysis. Data may come with noise, bias, missing values, outliers, unbalanced labels, and other issues. Data cleaningand quality control is the process of identifying and correcting errors and biases in data. Each of these steps may require different algorithms or statistical methods, and success or failure can have a big impact on the quality of the machine learning results [1].
14.1.1.2 Feature Selection
A significant challenge comesfrom applying machine learning algorithms to big data where there can be thousands or millions of features. For example, it is common in human genetics to measure more than one million DNA sequence variations in genome-wide association studies (GWAS) to identify the risk factorfor common diseases. A large number of features can make it harder to detect the signal from noise, increase the probability of overfitting, and add enormous computational complexity raising concerns about compute time and carbon footprint. Feature selectionis an integral first step to addressing these issues in machine learning. Fewer features can yield simpler, more interpretable models, but this must be balanced against the potential cost of predictive performancefrom training with incomplete data
Feature selectioncan take several different forms. The quality or characteristics of features can be used to prune out those that are not of sufficient quality (i.e. too many missing values), lack information (i.e. every instance has the same value), or contain redundant information (i.e. correlated). Domain knowledge can be used to select features most likely to be important based on prior literature. For example, a genetic study of diabetes could focus on DNA sequence variations located in or near genes related to insulin or glucose metabolism as a way to reduce the feature set. Algorithms can estimate the importance of features from preliminary machine learning results or special algorithms such as ReliefF [2] and select a subset for further investigation. Some machine learning algorithms, such as deep learning neural networks or lasso-based logistic regression, can perform feature selectionfrom within the algorithm. This can eliminate the need for this step. Others such as random forests can select features using feature importancescores that assess the relative contribution of each feature to the predictive accuracyFeature selectionis an art in and of itself adding to the complexity of building a machine learning pipeline
14.1.1.3 Feature Engineering
Feature Engineeringis the process of transforming raw data for use in machine learning. Data transformations can increase performance, interpretability, or, in some instances, both. Machine learning algorithms may sometimes be able to account for these issues; however, this often increases the complexity of the models and lowers interpretability. Feature Engineeringcan handle these issues more clearly, allowing the algorithm to be focused on the prediction. As with feature selection, care must be taken not to overfit the data if the predicted outcome is used to engineer the features. Validation data may be needed to prevent overfitting in this step.
Transformations can leverage expert knowledge or be done automatically by specialized algorithms. When there is expert knowledge of the interactions of specific features, data scientists can manually transform the data into new features that better represent a biological or physical process being studied. Automated dimensionality reductionmethods such as principal component analysis (PCA) or deep learning autoencodersmay effectively isolate signals from noisy data. Other feature transformations may be based on simple arithmetic that allows simpler algorithms to model more complex functions. For example, polynomial transformations allow linear regression to quickly model nonlinear trends. Good feature engineeringcan also reduce the total number of features being studied leading to computational efficiency.
14.1.1.4 Classifier or Regressor Selection
Oneof the most difficult challenges for experts and non-experts alike is choosing a machine learning model in the form of a classifier (for binary outcomes) or regressor (for continuous outcomes) and setting its hyperparameters. There are dozens of commonly used methods, and each models the features-outcome relationship differently. For example, some methods are better at modeling linear patterns, and some are better with nonlinearities. Some methods produce more explainable models, while some are more computationally efficient. Compounding this problem is that one rarely knows what the patterns in the data are until after extensive analysis and evaluation. Furthermore, each method often has multiple hyperparameters that govern how the algorithm works.
14.1.1.5 Assessing Predictive Performance
Keyto any machine learning algorithm is the assessment of model quality. At its core, machine learning seeks to make accurate predictions, as measured by a loss functionwhen applied to a training dataset. Evaluating predictive performanceis challenging. Machine learning models can easily memorize entire datasets, leading to perfect in-sample prediction. However, this is often accomplished through an overly large and complex model that memorizes the particularities of the specific dataset rather than finding broader trends. The result is a model that does not generalize well to new data. This is a phenomenon known as overfitting.
Cross-validationis a popular algorithm to estimate the out-of-sample error by averaging the out-of-sample scores on kdifferent training/validation splits of the data. However, evaluating a large number of pipelines can lead to overfitting the cross-validationscore itself due to the correlation between the training splits of the data and multiple looks at the testing data. Therefore, the spectrum of models with low to high cross-validation scores may range from underfit (underperforming) to a good fit to overfit. The data scientist’s job is to make this distinction and select an appropriately fit model. Ideally, predictive performancewould be assessed on independent data once a final model has been selected. This is sometimes referred to as the testing data
14.1.1.6 Multi-objective Optimization
Additional measures of model quality beyond predictive accuracymight be needed for some problems or use cases. For example, there has been a growing push for interpretable machine learning models that provide human-understandable reasoning for their predictions. For example, models that predict health outcomes from medical data would be more desirable if the reasoning behind them identifies effective interventions. Improvement in one metric often results in a trade-off, causing performance to decline in another. For example, simpler models may be more interpretable, though usually at the cost of predictive performance. Geng et al. [3] survey objective and subjective measures of model quality. Specifically, they review the idea of model interestingness, which can be domain- and user-specific. Several algorithms, such as Pareto optimization [4] have been developed to tune models toward multiple quality measures efficiently. The selection of the loss functionand other measures of model quality can have a big impact on the value of a model.
14.1.1.7 Model Explainability
Thegrowingfield of explainable artificial intelligence (XAI) or machine learning aims to develop models that produce human-understandable reasoning for predictions [5]. While the underlying algorithms powering machine learning are often simple and easy to understand with the right mathematical knowledge, their models can be highly complex and inscrutable. These models may produce accurate predictions, but the basis for those decisions is often obscured. Understanding the reasoning within the models and their domain-specific application opens the door to new insightsand applications. Combi et al. [5] decompose XAI into model interpretability, understandability, usability, and usefulnessWereview their definitions below.
The interpretabilityof a model refers to the ability of the user to have a general understanding or intuition of how a particular decision came about, without necessarily needing to know the exact mathematics leading to the solution. For example, a deep learning model that identifies cancerin MRI images may highlight regions that inform their decisions. From this, a doctor may understand the general patterns the model looks for, without necessarily understanding the complex math behind defining such patterns. In addition, there are methods such as permutation feature importancescores that assess the relative contribution of each feature to the final prediction that can be applied more generally to any machine learning model. This allows the user to say which features the model focuses on, which may lead to additional hypotheses.
The understandability of a model refersto the user’s ability to comprehend and follow the inner workings and mathematics of the underlying algorithm. For example, a human can easily read a decision tree and understand the flow of logic used to arrive at a decision or prediction. However, humans are generally not wired to understand the abstract prediction logic hidden away in the matrix transformations of deep learning models. A model can be understandable but not interpretable. While decision trees can be understandable, they may not be interpretable when the complexity is too high for humans to grasp intuitively. Understandability can be particularly important in the medical domain, where these can be a high cost in terms of patient suffering for incorrect decisions. Clinicians can fact-check the reasoning of the model with their own expert knowledge to make a more informed decision. Understanding a model can lead to new hypotheses and perhaps interventionsto perturb the system in a beneficial way. For example, a decision tree model that predicts disease riskfrom genetic data could identify rules not previously considered by science which could lead to the hypotheses about new gene-based drug targets for disease treatment.
Combi et al. [5] also discuss usability, which refers to the practical ability to easily implement the solution in the real world. There are several factors that inform whether or not a model could be practically implemented. These include, but are not limited to, the practicality of collecting, digitizing, and inputting the required data; the financial cost of installing, running, and maintaining the solution; the ease of training users to utilize the solution and whether it can be incorporated into their workflow. A technology’s usefulness may be dependent on context and relative to alternatives and problems at hand.
The final component of XAI is usefulness. This refers to whether the technology meets a user’s need. In machine learning, this often means accurate, or at least actionable, predictions. The utility of a model is often enhanced if it is also interpretable, understandable, and usable. Interpretabilityand understandability both can lead trust to the underlying predictions leading to more efficient evaluationand decision-making as well as providing insightsinto new directions. Usabilityis required for people to actually use the technology in the first place, but strong usabilitycan also make workflows more efficient.
14.2 Automated Machine Learning
Automated machine learning or AutoMLarose after 2010 to address the complexity of choosing methods, tuning hyperparameters, and building analytical pipelines [6]. One of the first AutoML methods was Auto-WEKA[7] which was built on top of the popular WEKA machine learning package [8]. Auto-WEKAuses a Bayesian optimization algorithm to choose the best machine learning algorithm and hyperparameter settings from the WEKA software package. Auto-WEKAhas been used, for example, to predict intracerebral hemorrhage in patients with features derived from demographics, laboratory tests, and imaging [9].
Fig. 14.2
Overview of the Auto-sklearn method that includes a meta-learning algorithm trained on public data and a machine learning pipelinewith pre-processor, feature selector, and classifier components. The pipelines are generated using a Bayesian optimization algorithm with prior information from the meta-learner. Ensembles of pipelines are possible
Another early and widely used AutoMLmethod is Auto-sklearn [10] which uses the scikit-learn machine learning library [11]. Like Auto-WEKA, Auto-sklearn uses a Bayesian optimization algorithm to select a pipeline consisting of a data pre-processing algorithm, a feature selector, and a machine learning classifier (Fig.  14.2). This was the first AutoMLmethod to build a pipeline that is enhanced by meta-learning and ensemble classification. Interestingly, Auto-sklearn uses results from the analysis of a large number of public datasets as meta-data for optimizing its pipelines on new data. Auto-sklearn has been widely used on problems such as prioritization of social media posts about suicide [12].
The third early and widely used method is the Tree-based Pipeline Optimization Tool (TPOT), which represents machine learning pipelinesas expression trees with discovery and optimization by genetic programming [13–15]. The TPOTapproach also uses the scikit-learn library as a source of algorithms. However, the expression tree representation gives it more flexibilityfor pipeline construction. We review this approach in detail below.
14.3 The Tree-Based Pipeline Optimization Tool (TPOT)
Central to TPOTis the representation of machine learning pipelinesas expression trees. The TPOTdiscovery and optimization algorithm comes from a subdomain of AI called evolutionary computation, which derives its motivation from evolution by natural selection in biology. Specifically, the application of evolutionary computation to computer programs is referred to as genetic programming or GP [16]. A benefit of developing TPOTusing the GP framework is that there is an extensive base of literature exploring a variety of methods and strategies for applying GP to complex problems. Further, expression trees are easily integrated into a GP framework. Key to TPOTis the use of Pareto optimization [4] which allows pipelines to be evaluated using multiple objectives such as predictive accuracy andpipeline complexity. TPOTis implemented using the open-source Distributed Evolutionary Algorithms in Python (DEAP) software package [17].
The basic components of TPOTare illustrated in Fig.  14.3. The algorithm starts by generating Nexpression tree-based pipelines randomly from a set of scikit-learn operators (e.g. feature selectors and classifiers) and their hyperparameter settings. New pipelines are generated using variation operators that mutate pipeline components and recombine branches between pipelines. The Nold and the Nnew pipelines are evaluated, and the best Nare selected to move forward. The variation, evaluation, selection, and iteration steps continue until a stopping criterion is reached. This is usually set to be Ggenerations or iterations of the algorithm (e.g. G100 or 1000).
Fig. 14.3
An overview of the TPOTalgorithm. The first step is to represent machine learning pipelinesusing expression trees. Pipeline trees are initialized randomly, diversified using several variation operators, evaluated, and selected using quality metrics such as an error-based loss function and the complexity of the pipelines. This process is iterated until a stopping criterion is reached
14.3.1 Pipeline Representation
One of the key differences between TPOTand other methods is the representationof machine learning pipelinesusing expression trees. Tree-based data structures are ideal for this purpose, given the stepwise data processing that occurs in a pipeline. Here, the tree nodes are selected from feature selection, feature engineering, and machine learning algorithms from the scikit-learn library. The terminals of the tree represent the hyperparameters of the various algorithms and data inputs. At evaluation, a scikit-learn pipeline is constructed by initializing models with their respective hyperparameters and using the feature unions to create the branching structure. To execute a tree, the data are passed into the leaves of the tree and propagated through the nodes of the tree up through the root node, which serves as the final classifier or regressor. We summarize in Fig.  14.3the steps of the TPOTalgorithm. Each step is described in more detail below.
14.3.2 Pipeline Initialization
The first step of TPOTis to initializea set of Npipelines where Nis referred to as the population size (e.g. N100 or 1000). TPOThas a default set of algorithms from the scikit-learn library. This can be modified or constrained using a configuration file. Each expression tree starts with a machine learning algorithm (e.g. classifier or regressor) at the root node. This ensures that the pipeline’s output is a set of predicted values that can be compared to observed values using a loss function. Each child node is selected from the set of all allowable methods, including feature transformation, feature selection, feature engineering, and machine learning algorithms (i.e. the function set). The terminals of each node are used to specify randomly selected hyperparameter values (i.e. the terminal set). Each of the Ntrees a to b layer trees is generated randomly for the initial population from a distribution of possibilities.
14.3.3 Pipeline Variation
The firststep in each generation is to generate new pipelines from the current population. Just as mutation and recombination generate variation for natural selection during evolution, TPOTuses similar operators to generate variation in machine learning pipelines. This is done in a few different ways (Fig.  14.4). New individuals in each population are generated either by mutation of an existing tree, with probability M, or recombination through crossover of selected subtrees (i.e. branches) or hyperparameters between two individuals with probability R. A mutation is equally likely to insert, remove, or replace nodes. In crossover, subtrees of two trees are randomly swapped.
Fig. 14.4
