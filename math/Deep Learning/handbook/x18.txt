Marcin, S., Wojciech, J., Krzysztof, K.: Coevolutionary temporal difference learning for othello. In: 2009 IEEE Symposium on Computational Intelligence and Games, pp. 104–111 (2009)
166.
Szubert, M., Jaśkowski, W., Krawiec, K.: On scalability, generalization, and hybridization of coevolutionary learning: A case study for othello. IEEE Trans. Comput. Intell. AI Games 5(3), 214–226 (2013)
167.
Tan, H., Zhou, Y., Tao, Q., Rosen, J., van Dijken, S.: Bioinspired multisensory neural network with crossmodal integration and recognition. Nat. Commun. 12(1), 1120 (2021)
168.
Yujin, T., Yingtao, T., David, H.: Evojax: Hardware-accelerated neuroevolution. arXiv preprint arXiv:​2202.​05008(2022)
169.
Rohan, T., Danilo, P.M., Anthony, G.C.: Pearl: Parallel evolutionary and reinforcement learning library (2022)
170.
Taylor, M.E., Stone, P.: Transfer learning for reinforcement learning domains: A survey. J. Mach. Learn. Res. 10, 1633–1685 (2009)
171.
Stone, P.: Layered Learning in Multiagent Systems: A Winning Approach to Robotic Soccer. MIT Press, Cambridge, MA, USA (2000)
172.
Sutton, R.S., Precup, D., Singh, S.: Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning. Artif. Intell. 112(1), 181–211 (1999)MathSciNetzbMATH
173.
Szubert, M., Jaśkowski, W., Krawiec, K.: On scalability, generalization, and hybridization of coevolutionary learning: A case study for othello. IEEE Trans. Comput. Intell. AI Games 5(3), 214–226 (2013)
174.
Tan, H., Zhou, Y., Tao, Q., Rosen, J., van Dijken, S.: Bioinspired multisensory neural network with crossmodal integration and recognition. Nat. Commun. 12(1), 1120 (2021)
175.
Taylor, M.E., Stone, P.: Transfer learning for reinforcement learning domains: A survey. J. Mach. Learn. Res. 10, 1633–1685 (2009)MathSciNetzbMATH
176.
Adam, T., Kourosh, N.: Evolving neural network agents to play atari games with compact state representations. In: Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion, GECCO ’20, pp. 99–100. Association for Computing Machinery, New York, NY, USA (2020)
177.
Zdenek, V., Lukas, S.: Hardware accelerators for cartesian genetic programming. In: Michael, O., Leonardo, V., Steven, G., Anna  Isabel, E.A., Ivanoe, D.F., Antonio, D.C., Ernesto, T. (eds.) Genetic Programming, pp. 230–241. Springer, Berlin (2008)
178.
Vassiliades, V., Chatzilygeroudis, K., Mouret, J.-B.: Using centroidal voronoi tessellations to scale up the multidimensional archive of phenotypic elites algorithm. IEEE Trans. Evol. Comput. 22(4), 623–630 (2018)
179.
Vassiliades, V., Chatzilygeroudis, K., Mouret, J.-B.: Using centroidal voronoi tessellations to scale up the multidimensional archive of phenotypic elites algorithm. IEEE Trans. Evol. Comput. 22(4), 623–630 (2018)
180.
Verbancsics, P., Stanley, K.O.: Evolving static representations for task transfer. J. Mach. Learn. Res. 11, 1737–1769 (2010)MathSciNetzbMATH
181.
Vernon, B.M.: The columnar organization of the neocortex. Brain 120, 701–722 (1997)
182.
Wang, J., Zhang, Y., Kim, T.-K., Yunjie, G.: Shapley q-value: A local reward approach to solve global reward games. Proceed. AAAI Conf. Artif. Intell. 34, 7285–7292 (2020)
183.
Rui, W., Joel, L., Jeff, C., Kenneth, O.S.: Poet: Open-ended coevolution of environments and their optimized solutions. In: Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, pp. 142–151. Association for Computing Machinery, New York, NY, USA (2019)
184.
Wang, J., Zhang, Y., Kim, T.-K., Yunjie, G.: Shapley q-value: A local reward approach to solve global reward games. Proceed. AAAI Conf. Artif. Intell. 34, 7285–7292 (2020)
185.
Watson, R.A., Pollack, J.B.: Modular interdependency in complex dynamical systems. Artif. Life 11(4), 445–457 (2005)
186.
Whiteson, S., Kohl, N., Miikkulainen, R., Stone, P.: Evolving soccer keepaway players through task decomposition. Mach. Learn. 59(1), 5–30 (2005)
187.
Whiteson, S., Kohl, N., Miikkulainen, R., Stone, P.: Evolving soccer keepaway players through task decomposition. Mach. Learn. 59(1), 5–30 (2005)zbMATH
188.
Whitley, D., Dominic, S., Das, R., Anderson, C.W.: Genetic reinforcement learning for neurocontrol problems. Mach. Learn. 13(2–3), 259–284 (1993)
189.
Geraint, A.W.: A preliminary framework for description, analysis and comparison of creative systems. Knowl. Based Syst. 19(7), 449–458 (2006) Creative Systems
190.
Williams, R.J.: Simple statistical gradient-following algorithms for connectionist reinforcement learning. Mach. Learn. 8(3–4), 229–256 (1992)
191.
Williams, R.J.: Simple statistical gradient-following algorithms for connectionist reinforcement learning. Mach. Learn. 8(3–4), 229–256 (1992)zbMATH
192.
Georgios, N.: Yannakakis and Julian Togelius. Artificial Intelligence and Games. Springer (2018)
193.
Aspen, H.Y., Anne, G.E.C.: How working memory and reinforcement learning are intertwined: a cognitive, neural, and computational perspective. J. Cogn. Neurosci. 34(4), 551–568 (2022)
194.
Wenhao, Y.C., Karen, L., Greg, T.: Policy transfer with strategy optimization. In: International Conference on Learning Representations (2019)
195.
Shanglin, Z., Michael, S., Jiannis, T., Peyman, G., Dean, V.B.: Multiplexing working memory and time in the trajectories of neural networks. In: Nature Human Behaviour (2023)
196.
Zdenek, V., Lukas, S.: Hardware accelerators for cartesian genetic programming. In: Michael, O., Leonardo, V., Steven, G., Anna Isabel, E.A., Ivanoe, D.F., Antonio, D.C., Ernesto, T. (eds.) Genetic Programming, pp. 230–241. Springer, Berlin (2008)
Footnotes
1
In real-world tasks, observations and actions are likely to be multidimensional and expressed as a mix of discrete and continuous values.
2
In this case ES might be considered a form of neuroevolution.
Part IIEvolutionary Computation as Machine Learning
In which we discuss long existing evolutionary computation methods from the point of view of machine learning: Clustering, classification, regression and modeling, and ensembles.©  The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.  2024
W. Banzhaf et al.(eds.)Handbook of Evolutionary Machine LearningGenetic and Evolutionary Computationhttps://doi.org/10.1007/978-981-99-3814-8_5
5.  Evolutionary Regression and Modelling
Qi  Chen1, Bing  Xue1, Will  Browne2and Mengjie  Zhang1
(1)
Evolutionary Computation Research Group at the School of Engineering and Computer Science, Victoria University of Wellington, Wellington, 6140, New Zealand
(2)
Faculty of Engineering, School of Electrical Engineering and Robotics, Queensland University of Technology, Brisbane, Australia
Qi  Chen
Email: qi.chen@ecs.vuw.ac.nz
Bing  Xue
Email: Bing.Xue@ecs.vuw.ac.nz
Will  Browne
Email: will.browne@qut.edu.au
Mengjie  Zhang(Corresponding author)
Email: Mengjie.Zhang@ecs.vuw.ac.nz
Abstract
Regression and modelling, which identify the relationship between the dependent and independent variables, play an important role in knowledge discovery from data. Symbolic regressiongoes a step further by learning explicitly symbolic models from data that are potentially interpretable. This chapter provides an overview of evolutionary computation techniques for regression and modelling including coefficient learning and symbolicregression. We introduce the ideas behind various evolutionary computation methods for regression and present a review of the efforts on enhancing learning capability, generalisation, interpretabilityand imputationof missing datain evolutionary computation for regression.
5.1 Introduction
Regression, which is originally from statistical modelling, is an inductive learning task that extracts general law from a set of observed data and studies the relationship between the independent/explanatory/input variablesand the dependent/response/output variable(s). The input variablesare also called features or attributes in machine learning. In recent years, regression has been the standard approach to modelling the relationship between input variablesand the outcome variable(s). Unlike classification to predict discrete class labels, regression predicts numeric/continuous values. Regression models, which represent the most well-understood models in numerical simulation, are typically denoted as , where represents the minput variablesand Yrefers to the output variable(s), while is the error term that captures all kinds of errors. A regression analysis typically has two objectives of explanatory analysis, which aims to weigh and understand the effect of the input variableson the output variable(s)and predictive analysis to predict the outputs with a combination of the input variables. Traditionally, these objectives are achieved by finding the (near-) optimal coefficients with a predefined model structure for regression, e.g. find the optimal values for a linear regression model . Regression analysis is often the starting point of data science and machine learning as through which it becomes possible to understand how the varied input variableslead to the change of the response variable(s).
A range of machine learning approaches can perform regression. These approaches often assume various relationships between the explanatory and dependent variables. The most common regression models include simple or multiple linear regression, polynomial regression, etc. There are also many techniques for parameter/coefficient estimation for these regression models, e.g. least-squared estimation and gradient descent. However, the least squared-based approaches are often not able to solve some complex nonlinear regression models. It is desired to develop effective and efficient approaches to estimate parameters for complex regression tasks. Moreover, in the era of big data, with the increase in the dimensionality and volume of regression data, it becomes more and more difficult to assume the underlining distributions and corresponding model structures for regression. Evolutionary computation techniques, which can free users from these assumptions, are highly demanded.
5.2 Evolutionary Computation for Regression: Fundamentals
Many evolutionary computation (EC) algorithms have been proposed for regression analyses in several ways. According to their tasks, these techniques can be classified into two groups: (1) EC to estimate the coefficients of predefined/assumed regression models, and (2) EC to identify both the model structure and the coefficients for regression.
5.2.1 Evolutionary Computation for Learning Coefficients for Regression
Many of the existing EC methods for regression can be counted in the aforementioned group of coefficient learning. Consider the general nonlinear regression task as follows:
(5.1)
where ydenotes the target variable, xdenotes the input variables, are the parameters to be estimated. Once the model structure and the error metric have been decided (or selected), regression becomes an optimisation problem with the coefficients as the decision variables.
Different from conventional search techniques, EC methods are population-based search methods. They are typically stochastic and use a cost/fitness function that does not require derivatives. Each solution in the population is typically encoded as a vector of real values. Each element in the vector corresponds to one coefficient in the regression model. A fitness value is obtained for each solution to measure how well the corresponding regression model fits the given data. These fitness values are the basis for the evolutionary process of EC methods, which mimic natural evolution by following the survival of the fittest theory.
Fig. 5.1
An example of GA for coefficient learning for a regression model 
Genetic algorithms (GAs) have been used for coefficient learning for regression as early as 1990 [37, 39]. Figure 5.1shows an example of the evolutionary process of a GA method for learning coefficients for a regression model. Another EC technique, Particle swarm optimization (PSO), has also been used for coefficient learning for regression more recently [50, 64]. Compared with many other EC techniques such as GAs, PSO has several attractive attributes. PSO has a memory where all particles can retain the knowledge from the good solutions/particles. Moreover, there is cooperation between particles as the swarm share information. Differential evolution (DE) and its enhanced versions [51] have also been utilised for coefficient learning for nonlinear regression. These researches show that many of the drawbacks associated with the conventional coefficient estimation methods can be circumvented when using EC methods instead. For example, there is no need for a good initial guess of the coefficients since it is not a critical requirement for convergence anymore. A broad range for the coefficients is enough for a reasonably good estimation.
