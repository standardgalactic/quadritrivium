Besides model size, there are several other complexity measures for GP such as structural complexityand behavioural/functional complexity. Most structural complexity measures consider the shape of a tree. Given two trees with the same number of nodes, a balance tree with fewer nested nodes is considered simpler than a skew and deep tree [47, 68]. On the other hand, the behavioural/functional complexity focuses on the complexity of the evolved functions/programs, especially the non-linear functions that are much less interpretable. An example is the degree of the polynomial functions [113]. A more complex one is the VC dimension which illustrates the ability to learn from any given data [17, 18].
Another way to improve the explainabilityof GP-based classifier is to reduce the number of features, which can be achieved by feature selectionand feature construction. GP has a built-in feature selectionability where the features, which appear frequently in good tree, are considered good features and should be selected. Tran et al. [105] show that GP can select only 1% of the original features and still improve the classification performance over using all features. Given its flexible representation, GP has also been widely applied to achieve feature construction. The main goal of GP-based feature constructionmethods is to build informative high-level features from low-level features. It has been shown that GP can significantly improve the classification performance over the original features [105]. Depending on the difficulty of a learning problem, GP can build a single high-level feature [73, 112] or multiple high-level features [1, 101]. An advantage of GP-based feature constructionis its explicit high-level features, which can explainhow the original features interact to achieve high learning performance [57].
7.6.2 Post-hoc Interpretability GP for  Classification
Post-hoc interpretabilityGP approximatesa (complex) pre-trained classifier by a GP-based classifier that is more explainable than the original classifier. Firstly, the complex classifier is used to generate a dataset where the output is the prediction of the classifier. An interpretable GP-based classifier is then trained on the generated dataset. For example, Evans et al. [28] approximate a 200-layer neural network model or an ensemble of 500 decision trees by a 4-layer decision tree, which is much more interpretable while still maintaining the learning performance. However, in comparison with the model-based methods, there is still very limited work on post-hoc interpretabilityGP.
7.7 Advanced Topics7.7.1 Evolutionary Transfer Learning for  Classification
Transfer learningaimsto address a target classification problem by applying knowledge learned from other related classification problems [84]. Since EC is a population-based family and does not require any assumption of the objective function types, EC has been widely applied to achieve transfer learning, also known as evolutionary transfer learning. In general, evolutionary transfer learning can be divided into three main categories: evolutionary sequential transfer learning, evolutionary multi-taskingand evolutionary multiform learning/optimisation[37].
Evolutionary sequential transfer learning tacklesthe target classification problem when all other related classification (source) problems have been addressed and the knowledge from the source problems has been extracted. For example, Nguyen et al. [74, 76, 79] apply EC to build a latent feature space on which the projected source data and projected target data follow the same distribution, and thus the projected source data can improve the classification performance on the target classification task.
In contrast to sequential transfer learning, evolutionary multi-taskingaddresses all the classification problems simultaneously. Each task is typically addressed by a sub-population. During the training process, the sub-populations continuously share their knowledge. A well-known framework of evolutionary multi-taskingis MFEA (Multi-Factorial Evolutionary Algorithm) [36], in which the assortative mating allows parents of different classification problems to exchange their knowledge, but with low probability to avoid negative transferlearning.
While the two former ones deal with multiple different classification problems, evolutionary multiform learning/optimisation deal with a single classification problem, which is viewed under different objective formulations. Each objective formulation forms one learning task and MFEA can be applied to address the set of obtained learning tasks. For example, Jiao et al. [41] view multi-objective feature selection(for classification) as a multiform learning problem where different objective formulations use different weight vectors to combine the classification performance and the number of selected features. The proposed algorithm can evolve better feature subsets than other evolutionary multi-objective algorithms.
7.7.2 Evolutionary Surrogate Models
To addressa problem, EC usuallyrequires a large number of evaluations to obtain sufficiently good solutions. However, in many real-world problems, the evaluation can be computationally intensive. For example, each evaluation in designing vehicle shape can take several hours [111]. Surrogate models are proposed to reduce the computation cost of EC on computationally intensive problems, which is particularly useful for intensive classification on large datasets. The key idea of a surrogate modelis to simulate the behaviour of the true fitness function while requiring much less computational resource. Thus, using the surrogate modelto evaluate the candidate solutions can significantly reduce the computation cost. In general, designing a surrogate model has three main steps:
Model construction: This step builds a surrogate model based on a set of candidate solutions and their fitness values. The solution set can be obtained after a number of generations or by applying some sample strategies. Usually, building a surrogate modelis a classification or regression problem, and the solution set is considered a (surrogate) training set. The classification-based model aims to rank the candidate solutions, which is known as a relative fitness model[78]. In contrast, the regression-based model aims to predict the fitness values of the candidate solutions, which is known as an absolute model[100].
Interaction: This step regards how to use the surrogate modelduring the evolutionary process. In general, there are two main ways: pre-selectionand estimation. The pre-selectionway generates a large number of candidate solutions which are evaluated by the surrogate model [98]. From the large set of solutions, a small number of promising solutions are selected, which are then re-evaluated by the true fitness function. The estimationway directly evaluates offspring by the surrogate model.
Re-evaluation:This step regards when to re-evaluate candidate solutions using the true fitness function, which avoids the convergence to a false optima. The two most common strategies are: individual-based and generation-based. The individual-based strategy re-evaluates a part of the population in every generation [62, 96]. In contrast, the generation-based strategy re-evaluates the whole population in some generations [6, 82].
Evolutionarysurrogate modelshave been successfully applied to many expensive real-world classification problems such as health system [115].
7.7.3 Evolutionary Deep Structures
Deep neural networks (DNNs) havehad great success in many real-world classification applications. However, the performance of DNNs relies heavily on their network architectures which usually requires rich expertise. Recently, EC has been widely applied to automatically search for the optimal DNNs architecture. The main reason is that EC algorithms can deal with various challenges of neural architecture search such as complex constraints, discrete search space and multiple conflicting criteria [63]. In general, each individual of an evolutionary population represents a network architecture. The connection weights of the architecture are optimised by a gradient-based optimisation technique. The performance of the obtained network (constructed by the combination of the architecture and the connection weights) is used as the individualâ€™s fitness. However, the architecture of DNNs is usually large and complex which requires an effective representation for EC. An effective representation should consider three aspects: the hyperparameters of each layer, the depth of the architecture and the connections between layers [91, 121]. A typical encoding scheme uses a set of integer numbers to denote all possible options of the above aspects. These integer numbers are converted to binary values, and the task is to optimise a vector of binary values. Therefore, vector-based evolutionary algorithms have been widely applied to neural architecture design [16, 42, 69, 93, 114]. The results show that the evolved architectures are not only effective but also much simpler than existing manual designs [63]. More discussions on evolutionary neural architecture search can be seen from later chapters of this handbook.
7.8 Conclusions
Given the potential global search ability, EC has been widely applied to many classification problems including challenging characteristics such as high-dimensional data, irrelevant/redundant data, missing dataand unbalanced data. Evolutionary classification applications range from optimising parameters for standard classification algorithms to performing classification directly. Evolutionary classification can also improve the quality of the training data by various preprocessing steps such as feature selection, feature constructionand instance selection, which can significantly increase the classification performance. Furthermore, EC builds interpretable classifiers such as classification rules/trees/graphs by GP and LCSs, which is particularly important in eXplainable AI.
Recently, in evolutionary classification, several emerging directions have been investigated such as evolutionary cost-sensitive learning, evolutionary transfer learning, evolutionary surrogate modelsandevolutionary deep structures. We expect to see more work to consolidate these directions. In addition, the lack of theoretical analysis and intensive computation cost are major concerns in evolutionaryclassification, which need to be addressed in the future.
References
1.
Ain, Q.U., Al-Sahaf, H., Xue, B., Zhang, M.: Generating knowledge-guided discriminative features using genetic programming for melanoma detection. IEEE Trans. Emerg. Top. Comput. Intell. 5(4), 554â€“569 (2020)
2.
Ain, Q.U., Xue, B., Al-Sahaf, H., Zhang, M.: Genetic programming for skin cancer detection in dermoscopic images. In: 2017 IEEE Congress on Evolutionary Computation (CEC), pp. 2420â€“2427. IEEE (2017)
3.
Al-Sahaf, H., Song, A., Neshatian, K., Zhang, M.: Two-tier genetic programming: towards raw pixel-based image classification. Expert Syst. Appl. 39(16), 12291â€“12301 (2012)
4.
Albuquerque, I.M.R., Nguyen, B.H., Xue, B., Zhang, M.: A novel genetic algorithm approach to simultaneous feature selection and instance selection. In: IEEE Symposium Series on Computational Intelligence (SSCI), pp. 616â€“623 (2020)
5.
AlSukker, A., Khushaba, R., Al-Ani, A.: Optimizing the k-nn metric weights using differential evolution. In: International Conference on Multimedia Computing and Information Technology (MCIT), pp. 89â€“92. IEEE (2010)
6.
Bajer, L., Pitra, Z., Repická»³, J., HoleÅˆa, M.: Gaussian process surrogate models for the cma evolution strategy. Evol. Comput. 27(4), 665â€“697 (2019)
7.
Bhowan, U., Johnston, M., Zhang, M.: Developing new fitness functions in genetic programming for classification with unbalanced data. IEEE Trans. Syst. Man, Cybernet. Part B (Cybernetics) 42(2), 406â€“421 (2011)
8.
Bhowan, U., Johnston, M., Zhang, M.: Ensemble learning and pruning in multi-objective genetic programming for classification with unbalanced data. In: Australasian Joint Conference on Artificial Intelligence, pp. 192â€“202. Springer (2011)
9.
Bi, Y., Xue, B., Zhang, M.: An automatic feature extraction approach to image classification using genetic programming. In: International Conference on the Applications of Evolutionary Computation, pp. 421â€“438. Springer (2018)
10.
Bi, Y., Xue, B., Zhang, M.: An automated ensemble learning framework using genetic programming for image classification. In: Proceedings of the Genetic and Evolutionary Computation Conference, pp. 365â€“373 (2019)
11.
Bi, Y., Xue, B., Zhang, M.: Genetic programming with image-related operators and a flexible program structure for feature learning in image classification. IEEE Trans. Evol. Comput. 25(1), 87â€“101 (2020)
12.
Bi, Y., Xue, B., Zhang, M.: Genetic programming with a new representation to automatically learn features and evolve ensembles for image classification. IEEE Trans. Cybernet. 51(4), 1769â€“1783 (2021)
13.
Biswas, N., Chakraborty, S., Mullick, S.S., Das, S.: A parameter independent fuzzy weighted k-nearest neighbor classifier. Pattern Recogn. Lett. 101, 80â€“87 (2018)
14.
Bot, M.C., Langdon, W.B.: Application of genetic programming to induction of linear classification trees. In: European Conference on Genetic Programming, pp. 247â€“258. Springer (2000)
15.
Brameier, M., Banzhaf, W.: Linear genetic programming, vol.  1. Springer (2007)
16.
Byla, E., Pang, W.: Deepswarm: Optimising convolutional neural networks using swarm intelligence. In: UK Workshop on Computational Intelligence, pp. 119â€“130. Springer (2019)
17.
Chen, Q., Xue, B., Shang, L., Zhang, M.: Improving generalisation of genetic programming for symbolic regression with structural risk minimisation. In: Proceedings of the Genetic and Evolutionary Computation Conference, pp. 709â€“716 (2016)
18.
Chen, Q., Xue, B., Zhang, M.: Improving generalization of genetic programming for symbolic regression with angle-driven geometric semantic operators. IEEE Trans. Evol. Comput. 23(3), 488â€“502 (2018)
19.
Cheng, F., Chu, F., Zhang, L.: A multi-objective evolutionary algorithm based on length reduction for large-scale instance selection. Inf. Sci. 576, 105â€“121 (2021)MathSciNet
20.
Cover, T., Hart, P.: Nearest neighbor pattern classification. IEEE Trans. Inf. Theory 13(1), 21â€“27 (1967)zbMATH
21.
Cui, X., Zhang, W., TÃ¼ske, Z., Picheny, M.: Evolutionary stochastic gradient descent for optimization of deep neural networks. Adv. Neural Inf. Process. Syst. 31(2018)
22.
Dada, E.G., Bassi, J.S., Chiroma, H., Abdulhamid, S.M., Adetunmbi, A.O., Ajibuwa, O.E.: Machine learning for email spam filtering: review, approaches and open research problems. Heliyon 5(6), e01802 (2019)
23.
Demir, K., Nguyen, B.H., Xue, B., Zhang, M.: Particle swarm optimisation for sparsity-based feature selection in multi-label classification. In: Proceedings of the Genetic and Evolutionary Computation Conference Companion, pp. 232â€“235 (2022)
24.
Derrac, J., Chiclana, F., GarcÃ­a, S., Herrera, F.: Evolutionary fuzzy k-nearest neighbors algorithm using interval-valued fuzzy sets. Inf. Sci. 329, 144â€“163 (2016)
25.
Downey, C., Zhang, M., Liu, J.: Parallel linear genetic programming for multi-class classification. Genet. Program Evolvable Mach. 13(3), 275â€“304 (2012)
26.
Ekart, A., Nemeth, S.Z.: Selection based on the pareto nondomination criterion for controlling code growth in genetic programming. Genet. Program Evolvable Mach. 2(1), 61â€“73 (2001)zbMATH
27.
Espejo, P.G., Romero, C., Ventura, S., HervÃ¡s, C.: Induction of classification rules with grammar-based genetic programming. In: Conference on Machine Intelligence, pp. 596â€“601 (2005)
28.
Evans, B.P., Xue, B., Zhang, M.: Whatâ€™s inside the black-box? a genetic programming method for interpreting complex machine learning models. In: Proceedings of the Genetic and Evolutionary Computation Conference, pp. 1012â€“1020 (2019)
29.
Fan, Q., Bi, Y., Xue, B., Zhang, M.: Genetic programming for image classification: A new program representation with flexible feature reuse. IEEE Trans. Evolut. Comput. 1â€“1 (2022). https://â€‹doi.â€‹org/â€‹10.â€‹1109/â€‹TEVC.â€‹2022.â€‹3169490
30.
Fogelberg, C., Zhang, M.: Linear genetic programming for multi-class object classification. In: Australasian Joint Conference on Artificial Intelligence, pp. 369â€“379. Springer (2005)
31.
Friedrichs, F., Igel, C.: Evolutionary tuning of multiple SVM parameters. Neurocomputing 64, 107â€“117 (2005)
32.
Giri, R., Chowdhury, A., Ghosh, A., Das, S., Abraham, A., Snasel, V.: A modified invasive weed optimization algorithm for training of feed-forward neural networks. In: IEEE International Conference on Systems, Man and Cybernetics, pp. 3166â€“3173 (2010)
33.
Gomes, T.A., PrudÃªncio, R.B., Soares, C., Rossi, A.L., Carvalho, A.: Combining meta-learning and search techniques to select parameters for support vector machines. Neurocomputing 75(1), 3â€“13 (2012)
34.
Gong, M., Liu, J., Li, H., Cai, Q., Su, L.: A multiobjective sparse feature learning model for deep neural networks. IEEE Trans. Neural Netw. Learn. Syst. 26(12), 3263â€“3277 (2015)MathSciNet
35.
Gudise, V., Venayagamoorthy, G.: Comparison of particle swarm optimization and backpropagation as training algorithms for neural networks. In: IEEE Swarm Intelligence Symposium, pp. 110â€“117 (2003)
36.
Gupta, A., Ong, Y.S., Feng, L.: Multifactorial evolution: toward evolutionary multitasking. IEEE Trans. Evol. Comput. 20(3), 343â€“357 (2015)
37.
Gupta, A., Ong, Y.S., Feng, L.: Insights on transfer optimization: because experience is the best teacher. IEEE Trans. Emerg. Top. Comput. Intell. 2(1), 51â€“64 (2017)
38.
Hall, M.A.: Correlation-based feature selection for discrete and numeric class machine learning. In: Proceedings of the Seventeenth International Conference on Machine Learning, p. 359-366 (2000)
39.
Han, J., Pei, J., Kamber, M.: Data Mining: Concepts and Techniques. Elsevier (2011)
40.
