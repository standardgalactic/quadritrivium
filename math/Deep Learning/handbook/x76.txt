Overview of the process by which variation is introduced into TPOT pipelines via recombination of subtrees and mutation of nodes. Mutation and recombination occur separately on different trees in the same generation
14.3.4 Pipeline Evaluation
Eachtree is evaluated based on two objectives. First, a standard loss functionis used to evaluate the predictive error of classifiers using k-fold cross-validation. Second, the complexity of the expression tree is approximated by counting the number of nodes in a tree. Other complexity measures could be developed and evaluated that take into account the complexity of the individual algorithms and their hyperparameters. For example, different weights could be giving to machine learning methods such as XGBoost that have higher complexity than simpler methods such as decision trees or logistic regression. Assessing complexity allows TPOTto consider simpler pipelines that might be more interpretable, less likely to overfit the data, and more likely to generalize to independent data. Different or additional criteria could be developed within the TPOTsoftware allowing for customized multi-objective optimization.
14.3.5 Pipeline Selection
Key to TPOTisthe method by which the best trees or pipelines in the current population are selected to pass into the next population. An ideal model has low complexity but high performance. In practice, there is often a trade-off between interpretabilityand performance, with simpler models sacrificing some performance. Similarly, there is a trade-off between generalizability and overfitting the objective function performance. Cross-validationaddresses this to some degree but is not perfect (TPOTmodels can become overly complex and overfit the cross-validation score itself). This is of particular concern when exploring many pipelines. Left unrestricted, TPOTwould form overly complex pipelines that greatly overfit the data. If too limited, TPOTmay not explore better solutions.
As the balance for interpretabilityversus performance is subjective and domain-specific, TPOTattempts to optimize a Pareto frontof non-dominated models defined by both performance and complexity. During training, TPOTselects the set of non-dominated models from a Pareto frontusing the non-dominated sorting genetic algorithm II or NSGA-II [18]. Thesemodels will then be mutated or recombined in the next generation. Other selection methods, such as lexicase selection[19], should be explored.
14.3.6 Picking the Best Model
There are several ways to pick the best model following a TPOTrun. The easiest is to return the pipeline from the final iteration with the best loss (e.g. predictive accuracy)determined by cross-validation. Another approach is to select the Pareto optimal models and select the one that balances accuracy and complexity according to the wishes of the user.
14.3.7 Scaling TPOT to Big Data
One of the challenges of AutoMLis the computational complexity of generating and evaluating millions of machine learning pipelines, which is compounded by big data with many features and instances. Le et al. [20] addressed this with two extensions to TPOT. First, they introduced a template option to specify a fixed linear pipeline structure. The template option can be used to constrain TPOTto just a feature selector and classifier, for example, which would execute faster than more complex trees. Second, they introduced a feature set selector (FSS) operator (see Fig.  14.5), which functions as an expert knowledge feature selector. Here, expert knowledge is used to group features into Ssubsets. The FSS operator includes a hyperparameter pointing to one of the subsets that is then used to select a subset of the data for the next operator in the tree. Combining the simple template tree structure with smaller feature sets can greatly improve the execution time of TPOT, which is important for working with big data and minimizing the carbon footprint.
Fig. 14.5
The inclusion of a Feature Set Selector (FSS) allows TPOT to select a subset of features for analysis in a pipeline. In the example pipeline shown, the FSS operator has a hyperparameter set to 3 which in turn selects data subset 3. This subset of the data is then passed to the Random Forest (RF) algorithm to develop a predictive model
14.3.8 Neural Networks with TPOT
Deep learning has popularized neural networks (NN) for analyzing big data. An area of current investigation is whether methods such as TPOTcan be used to build machine learning pipelinesby combining simple NN classifiers or regressors. Romano et al. [21] specifically compared the performance of TPOT, NNs, and an implementation of TPOT with only shallow NN classifiers referred to as TPOT-NN (see Fig.  14.6) applied to several publicly available datasets. This study showed that TPOT-NN performed better on several datasets but did not ever perform worse than standard TPOT, which had access to the full set of scikit-learn classifiers. It is interesting to speculate about the maximum deep learning model complexityTPOT-NN could approximate because it has access to feature transformers, feature selectors, and feature engineeringalgorithms. It is commonly believed that the first layer or two of a deep learning NN is likely performing some of these functions. A high-performing TPOT-NN pipeline could be easier to interpret and/or understand because the NN classifiers would be simpler and focus more on the classification task. This will be an exciting area to explore in future studies.
Fig. 14.6
A hypothetical TPOT-NN pipeline. Here, two different Feature Selector operators (FS1 and FS2) select different subsets of features that are then passed to multilayer perceptron neural networks. The predictions made by these feed-forward neural networks are passed to a decision tree that makes the final prediction as a type of ensemble
14.3.9 Real-World Applications
There have been a number of real-world applications of TPOTwith an emphasis in the biomedical domain, especially genetics and genomics [22]. These include predicting depression using genomic data [20], coronary artery diseaseusing metabolomics data [23], schizophrenia using genomics data [24], predicting renal cell carcinoma grade using radiologic images [25], childhood dental carries using metabolomics data [26], and coronary artery diseaseusing genetics data [27]. We focus here on the study by Manduchi et al. [27] that illustrates several of the concepts reviewed above.
Manduchi et al. [27] studied over 19,000 subjects with coronary artery disease(CAD) and more than 320,000 health controls ascertained from the UK Biobankdata resource. This resource provided more than one million measured genetic variants from across the human genome. The goal of the study was to develop a predictive model of CAD using more than one million genetic features. The authors faced several machine learning challenges with these big data. First, the CAD class (disease vs. no disease) was severely imbalanced, which can lead to predictive accuracies that favor the larger class. The authors randomly downsampled the larger class to balance the dataset. A total of 50 datasets were created by repeating this process 50 times to prevent chance partitions of the data. Second, the size of the dataset (more than one million features) presents computational and carbon footprint challenges forAutoML. The authors focused their analysis by creating smaller sets of features using expert knowledge about genes believed to be promising drug targets for CAD. Finally, the sample size permitted a 5-fold cross-validationto assess generalizability of the models along with holdout datasets used to assess the predictive ability of final models.
Figure  14.7shows one of the best pipelines generated by TPOTfor predicting CAD. In the first step of the pipeline, a feature selector based on feature percentile is selected for reducing the total number of features. The second operator employs a variance threshold as an additional feature selector. The third operator uses a stackingestimator with a stochastic gradient descent classifier to engineer a new feature which is then added back to the feature list. The fourth operator carries out an additional round of feature selectionby employing an extra tree classifier and using feature important scores to select a subset. This final list of selected and engineered features is then passed to the final operator, which uses an extra tree classifier to do the final classification of subjects with and without CAD. This pipeline was statistically significant () based on a permutation test and had a testing accuracy on holdout data of 0.55, which is in line with other predictive studies using genetics-based features. Importantly, TPOT wasable to automatically identify a machine learning pipelineconsisting of feature selection, feature engineering, and classification algorithms. It is unlikely that any human user would have constructed a pipeline like this manually for these data.
Interpretation of this model using a game-theoretic approach called Shapley values [28] estimated that different features contributed differently to the predictive values for different subsets of human subjects. This suggests a phenomenon known as genetic heterogeneity, where different subjects have different underlying riskfactors for the same disease representing a hypothesis to be investigated in future studies. An advantage of machine learning over linear methods such as regression is that they can detect and model complex relationships between features and outcomes such as this heterogeneity pattern. TPOTwas able to find a pipeline that could model these relationships automatically.
Fig. 14.7
A TPOT-generated machine learning pipeline for predicting riskof CAD. This pipeline contains a combination of feature selector (first, second, and fourth), feature engineering(third), and classification (fifth) algorithms
14.4 Future Directions
We have reviewed several challenges associated with building a machine learning pipeline. Some of these challenges can be addressed through AutoMLalgorithms designed to select optimal combinations of algorithms and hyperparameter settings for a particular dataset [6]. Early and popular methods include Auto-WEKA[7], Auto-sklearn [10], and TPOT[13, 14].
The TPOTalgorithm is unique in that it represents machine learning pipelinesas expression trees. The ability to represent pipelines as trees and to generate new trees using genetic-inspired variation operators such as mutation for changing nodes and recombination for swapping subtrees provides a powerful platform for building complex machine learning pipelines. Despite these advantages, TPOT could be improved in a number of different ways. We briefly mention some of these ideas below.
First, although the tree-based representation has a number of advantages, there are other representations used in GP that should be explored. For example, a graph-based data structure might reduce the computational complexity of a pipeline by passing the same transformation on to multiple different classifiers. A graph-based representationmight also be more amenable to ensembling which requires the outputs of multiple classifiers to be processed.
Second, there is a rich literature base for GP with numerous creative and effective ways to initialize populations, generate variation, evaluate solutions, and perform selection. These are too numerous to list here. However, the Genetic Programming Theory and Practice workshop has explored a number of advances for solving hard problems [29]. The most promising of these GP advances should be evaluated for TPOT
Third, one of the promises of AutoMLis that it is able to bring advanced machine learning methods and technology to non-experts. Although TPOTcan build a pipeline from scratch, it does not include a graphic user interface (GUI). An intuitive GUI designed for non-experts could be important for bringing this tool and others to the masses. This will help ensure that everyone who can benefit from machine learning is able to do so with as few barriers as possible. Aliro AI is an example of a user-friendly AutoML[30].
Fourth, TPOTis not directly aware of domain-specific knowledge. Current approaches include using manual selection of features as input for TPOTor the Feature Set Selector mentioned above. Some real-world problems may require a more intimate relationship between a knowledgebase and the AutoMLso that a method such as TPOTcan automatically use the knowledge to select features, select models, design pipeline architectures, and assist with explainability. There is currently little work in this area across AutoMLmethods, and domains such as biomedicine could greatly benefit.
Fifth, TPOTdoes not include any advanced tools for explainabilitythat are designed for non-experts. As mentioned above, connection to a knowledgebase could help with interpretation and understanding by providing a domain basis for the results being considered. Automation of XAI for pipelines generated by TPOTcould greatly improve their usefulness.
Finally, TPOTuses GP to discover and optimize pipelines. However, there are other areas in which GP can be integrated into the machine learning process. For example, the Feature Set Selector in TPOTrequires users to predefined subsets, and then it randomly selects between them. Instead, the FSS could use GP to dynamically create subsets by crossing over features with other pipelines in a process. TPOTmay also benefit from the inclusion of GP-based classification or regression methods such as symbolic discriminant analysis [31] orsymbolic regression [16]. It would be interesting to provide scikit-learn compatible GP methods or to include arithmetic operators individually to TPOTas a complement to the many other methods available.
Automated machine learning is in its infancy, having been an active area of investigation for less than 10 years. These methods show tremendous promise for accelerating discovery using machine learning pipelines. Genetic programming is a powerful innovation engine for building AutoMLpipelines as has been demonstrated with TPOT. Its flexibilitywith solution representation through expression trees and genetic operators makes it a tool that could be applied to other problems in this space.
References
1.
Chicco, D., Oneto, L., Tavazzi, E.: Eleven quick tips for data cleaning and feature engineering. PLoS Comput. Biol. 18, e1010718 (2022)Crossref
2.
Urbanowicz, R.J., Meeker, M., La Cava, W., Olson, R.S., Moore, J.H.: Relief-based feature selection: introduction and review. J. Biomed. Inform. 85, 189–203 (2018)Crossref
3.
Geng, L., Hamilton, H.J.: Interestingness measures for data mining: a survey. ACM Comput. Surv. 38(2006)
4.
Smits, G.F., Kotanchek, M.: Pareto-front exploitation in symbolic regression. In: O’Reilly, U.-M., Yu, T., Riolo, R., Worzel, B. (eds.) Genetic Programming Theory and Practice II. pp. 283–299 (2006)
5.
Combi, C., Amico, B., Bellazzi, R., Holzinger, A., Moore, J.H., Zitnik, M., Holmes, J.H.: A manifesto on explainability for artificial intelligence in medicine. Artif. Intell. Med. 133, 102423 (2022)Crossref
6.
Hutter, F., Kotthoff, L., Vanschoren, J. (eds.): Automated Machine Learning: Methods, Systems, Challenges. Springer International Publishing (2019)
7.
Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms. In: Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 847–855. ACM, New York, NY, USA (2013)
8.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.H.: The WEKA data mining software: an update. ACM SIGKDD Explor. Newsl. 11, 10–18 (2009)Crossref
9.
Wang, H.-L., Hsu, W.-Y., Lee, M.-H., Weng, H.-H., Chang, S.-W., Yang, J.-T., Tsai, Y.-H.: Automatic machine-learning-based outcome prediction in patients with primary intracerebral hemorrhage. Front. Neurol. 10, 910 (2019)Crossref
10.
Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efficient and robust automated machine learning. In: Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Processing Systems, vol. 28. pp. 2962–2970. Curran Associates, Inc. (2015)
11.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)MathSciNetzbMATH
12.
Howard, D., Maslej, M.M., Lee, J., Ritchie, J., Woollard, G., French, L.: Transfer learning for risk classification of social media posts: model evaluation study. J. Med. Internet Res. 22, e15371 (2020)Crossref
13.
Olson, R.S., Urbanowicz, R.J., Andrews, P.C., Lavender, N.A., Kidd, L.C., Moore, J.H.: Automating biomedical data science through tree-based pipeline optimization. In: Squillero, G., Burelli, P. (eds.) Applications of Evolutionary Computation, pp. 123–137. Springer International Publishing, Cham (2016)Crossref
14.
Olson, R.S., Bartley, N., Urbanowicz, R.J., Moore, J.H.: Evaluation of a tree-based pipeline optimization tool for automating data science. In: Proceedings of the Genetic and Evolutionary Computation Conference 2016, pp. 485–492. ACM, New York, NY, USA (2016)
15.
Olson, R.S., Moore, J.H.: TPOT: a tree-based pipeline optimization tool for automating machine learning. In: Hutter, F., Kotthoff, L., Vanschoren, J. (eds.) Automated Machine Learning: Methods, Systems, Challenges, pp. 151–160. Springer International Publishing, Cham (2019)Crossref
16.
Koza, J.R.: Genetic Programming: On the Programming of Computers by Means of Natural Selection. MIT Press, Cambridge, MA, USA (1992)zbMATH
17.
Fortin, F., De Rainville, F., Gardner, M.A., Parizeau, M., Gagné, C.: DEAP: evolutionary algorithms made easy. J. Mach. Learn. Res. 13, 2171–2175 (2012)MathSciNet
18.
Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Trans. Evol. Comput. 6, 182–197 (2002)Crossref
19.
Helmuth, T., McPhee, N.F., Spector, L.: Lexicase selection for program synthesis: a diversity analysis. In: Riolo, R., Worzel, W.P., Kotanchek, M., Kordon, A. (eds.) Genetic Programming Theory and Practice XIII, pp. 151–167. Springer International Publishing, Cham (2016)Crossref
20.
Le, T.T., Fu, W., Moore, J.H.: Scaling tree-based automated machine learning to biomedical big data with a feature set selector. Bioinforma. Oxf. Engl. 36, 250–256 (2020)Crossref
21.
Romano, J., Le, T., Fu, W., Moore, J.: TPOT-NN: augmenting tree-based automated machine learning with neural network estimators. Genet. Program. Evolvable Mach. 1–21 (2021)
22.
Manduchi, E., Romano, J.D., Moore, J.H.: The promise of automated machine learning for the genetic analysis of complex traits. Hum. Genet. 141, 1529–1544 (2022)Crossref
23.
Orlenko, A., Kofink, D., Lyytikäinen, L.-P., Nikus, K., Mishra, P., Kuukasjärvi, P., Karhunen, P.J., Kähönen, M., Laurikka, J.O., Lehtimäki, T., Asselbergs, F.W., Moore, J.H.: Model selection for metabolomics: predicting diagnosis of coronary artery disease using automated machine learning. Bioinforma. Oxf. Engl. 36, 1772–1778 (2020)Crossref
24.
Manduchi, E., Fu, W., Romano, J.D., Ruberto, S., Moore, J.H.: Embedding covariate adjustments in tree-based automated machine learning for biomedical big data analyses. BMC Bioinform. 21, 430 (2020)Crossref
25.
Purkayastha, S., Zhao, Y., Wu, J., Hu, R., McGirr, A., Singh, S., Chang, K., Huang, R.Y., Zhang, P.J., Silva, A., Soulen, M.C., Stavropoulos, S.W., Zhang, Z., Bai, H.X.: Differentiation of low and high grade renal cell carcinoma on routine MRI with an externally validated automatic machine learning algorithm. Sci. Rep. 10, 19503 (2020)Crossref
26.
Heimisdottir, L.H., Lin, B.M., Cho, H., Orlenko, A., Ribeiro, A.A., Simon-Soro, A., Roach, J., Shungin, D., Ginnis, J., Simancas-Pallares, M.A., Spangler, H.D., Zandoná, A.G.F., Wright, J.T., Ramamoorthy, P., Moore, J.H., Koo, H., Wu, D., Divaris, K.: Metabolomics insights in early childhood caries. J. Dent. Res. 100, 615–622 (2021)Crossref
27.
Manduchi, E., Le, T.T., Fu, W., Moore, J.H.: Genetic analysis of coronary artery disease using tree-based automated machine learning informed by biology-based feature selection. IEEE/ACM Trans. Comput. Biol. Bioinform. 19, 1379–1386 (2022)Crossref
28.
Lundberg, S.M., Lee, S.-I.: A unified approach to interpreting model predictions. In: Advances in Neural Information Processing Systems. Curran Associates, Inc. (2017)
29.
Sipper, M., Moore, J.H.: Genetic programming theory and practice: a fifteen-year trajectory. Genet. Program Evolvable Mach.21, 169–179 (2020)Crossref
30.
La Cava, W., Williams, H., Fu, W., Vitale, S., Srivatsan, D., Moore, J.H.: Evaluating recommender systems for AI-driven biomedical informatics. Bioinforma. Oxf. Engl. 37, 250–256 (2021)Crossref
31.
Moore, J.H., Parker, J.S., Olsen, N.J., Aune, T.M.: Symbolic discriminant analysis of microarray data in autoimmune disease. Genet. Epidemiol. 23, 57–69 (2002)Crossref©  The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.  2024
W. Banzhaf et al.(eds.)Handbook of Evolutionary Machine LearningGenetic and Evolutionary Computationhttps://doi.org/10.1007/978-981-99-3814-8_15
15.  Evolutionary Model Validation—An Adversarial Robustness Perspective
Inês  Valentim1, Nuno  Lourenço1and Nuno  Antunes1
(1)
